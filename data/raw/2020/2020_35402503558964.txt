Metadata-Based Retrieval for Resolution Recommendation in
AIOps
Harshit Kumar
harshitk@in.ibm.com
IBM Research
IndiaRuchi Mahindru
rmahindr@in.ibm.com
IBM T.J. Watson Research Center
USADebanjana Kar
debanjana.kar1@ibm.com
IBM Research
India
ABSTRACT
For a cloud service provider, the goal is to proactively identify
signals that can help reduce outages and/or reduce the mean-time-
to-detect and mean-time-to-resolve. After an incident is reported,
the Site Reliability Engineers diagnose the fault and search for a
resolution by formulating a textual query to find similar historical
incidents - this approach is called text-based retrieval. However,
it has been observed that the formulated queries are inadequate
and short. An alternate approach, presented in this paper, inte-
grates information spread across heterogeneous and siloed datasets,
as a ready-to-use knowledge base for metadata-based resolution
retrieval. Additionally, it exploits historical problem context for
building metadata prediction models which are used at run-time
for automatically formulating queries from log anomalies detected
by the Log Anomaly Detection module. The query, thus formed,
is run against the metadata-based index, unlike the text-based in-
dex in text retrieval, resulting in superior performance, in terms
of relevancy of the resolution documents retrieved. Through ex-
periments on web application server applications deployed on the
cloud, we show the efficacy of metadata-based retrieval, which not
only returns targeted results as compared to text-based retrieval
but also the relevant resolution document appear amongst the top
3 positions for 60% of the queries.
CCS CONCEPTS
‚Ä¢Information systems ‚ÜíInformation integration ;Query
reformulation ;‚Ä¢Software and its engineering ‚ÜíCloud com-
puting .
KEYWORDS
incident remediation, metadata-Based retrieval, cloud, AIOps
ACM Reference Format:
Harshit Kumar, Ruchi Mahindru, and Debanjana Kar. 2022. Metadata-Based
Retrieval for Resolution Recommendation in AIOps. In Proceedings of the
30th ACM Joint European Software Engineering Conference and Symposium
on the Foundations of Software Engineering (ESEC/FSE ‚Äô22), November 14‚Äì
18, 2022, Singapore, Singapore. ACM, New York, NY, USA, 11 pages. https:
//doi.org/10.1145/3540250.3558964
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
ESEC/FSE ‚Äô22, November 14‚Äì18, 2022, Singapore, Singapore
¬©2022 Association for Computing Machinery.
ACM ISBN 978-1-4503-9413-0/22/11. . . $15.00
https://doi.org/10.1145/3540250.35589641 INTRODUCTION
While cloud computing offers IT (Information Technology) infras-
tructure at a low cost, it comes with the complexity of having loosely
coupled micro-services to enable agile development, dynamic de-
ployment, and fast continuous improvement [ 22]. Therefore, the
role of operators (IT Operation Engineers or Site Reliability Engi-
neers (SREs)) towards availability, latency, performance, efficiency,
change management, monitoring, emerging response, and capacity
planning has become even more challenging due to the a) com-
plexity and scale of the software and hardware system, and b) the
vast amount of machine-generated data [ 7,17]. Even the most ex-
perienced SRE teams face challenges, especially with the rapidly
proliferating data generated by hybrid cloud and cloud-native tech-
nologies. Artificial Intelligence for IT Operations (AIOps) empow-
ers SREs by providing a platform infused with AI that supports
development and operations practices in an open, hybrid cloud
environment to enable free collaboration. The AIOps platform pri-
marily includes mining a voluminous amount of disparate data
sources to extract events (logs, metrics, alerts, incidents, anom-
alies), correlate and group them by inferring patterns to localize
the fault and use these to find similar historical incidents for action
recommendation. Figure 1 illustrates the components in a typical
AIOps pipeline [ 25] for applications deployed on cloud: Log Aggre-
gation normalizes[ 15] poorly structured log data into streams of
structured event objects, Event Detection [26] includes log anom-
aly detection and metric anomaly detection from log and metric
data, Event Correlation [16] groups different events such as alerts
and anomalies into homogeneous related clusters, Fault Localiza-
tion[1,2] localizes a fault to a particular service or component of
the application, and finally Incident Similarity allows an SRE
to formulate a query to retrieve resolutions using a text-based re-
trieval. There are several key challenges that require attention, as
discussed below.
(1)Cloud service providers manage data centers that serve a wide
variety of applications across a large number of customers while
keeping the cost low with minimum downtime. However, to
scale the operations, they are utilizing general practitioners and
investing in AI based solutions, such as AIOps. SREs may be
general practitioners with expertise in certain domains, hence
they may not be highly efficient in performing the problem
diagnosis and remediation for applications where they lack
expertise. Also, SREs work with complex systems generating
volumes of logs and metrics data, which may be hard to infer
for a non-domain expert. As an example, consider a sample
anomalous log line, DMxZ0302E: RAException occurred. Error
code is: RMFAIL (-7). Exception is: . . . RA exception: . . . Invalid
operation: Connection is closed. ERRORCODE=-4x8, STATE=0834 ,
1379
ESEC/FSE ‚Äô22, November 14‚Äì18, 2022, Singapore, Singapore Harshit Kumar, Ruchi Mahindru, and Debanjana Kar
Figure 1: Flow of a typical AIOps pipeline for applications deployed in cloud
where DMxZ0302E is the MessageCode ; and, RAException oc-
curred. Error code is: RMFAIL. Exception is: . . . RA exception: . . .
is the MessageString . To comprehend the above LogLine can
be a little challenging for a non-expert, and a lot more diffi-
cult to identify and resolve the underlying problem. The above
mentioned challenges lead to the following inefficiencies:
(a) Inadequate Query Formulation for Resolution Retrieval : In
order to find the resolution to a problem, SREs formulate a
query. However, without a thorough understanding of the
problem domain, it may be highly ineffective and a chal-
lenging task for them to create a viable query[ 34]. There-
fore, this may lead to a highly inefficient trial and error
based problem diagnosis and resolution retrieval.
(b) Incorrect Problem Routing : One of the key pain points that
SREs report is related to problems getting bounced around
from one team to another due to insufficient details and
misunderstanding of the problem[ 7]. In turn, this may lead
to increased Mean-Time-To-Resolve (MTTR) and business
Service Level Objective (SLO) violations.
(c) Ad-hoc Problem Diagnosis and Resolution Application : Lack
of problem understanding, leads to incomplete and incor-
rect query formulation. Therefore, the resolutions retrieved
would be irrelevant, if not incorrect. Hence, leading to ad-
hoc problem diagnosis and remediation.
(2)IT operations data, such as tickets, resolution articles, log data,
resolution taxonomy, etc., are distributed, heterogeneous, and
available in silos. Data in silos is incomplete because it cannot
be used effectively[33], for example, for resolution retrieval.
(3)Traditionally, SREs would switch between a variety of tools for
problem diagnosis and resolution. For example, they would use
aLog Aggregator to manually identify anomalous log lines[ 20],
which are grouped together for fault isolation, followed by the
identification of relevant cues, such as message code(s), in each
group. A query is formulated from the cues, which is run against
historical incidents to return resolution articles that can help an
SRE to resolve the fault. The aforementioned steps require an
SRE to switch between multiple tools and do manual processing
which is highly inefficient and time-consuming.
The aforementioned challenges may lead to lower productivity
of SREs, lack of confidence in problem-solving and longer MTTR,
and violated SLAs (Service Level Agreements), in turn leading to
lower customer satisfaction. To address the above challenges, we
propose to build an augmented metadata-based knowledge base
(KB), which will allow a faster matching of the identified fault and
recommend relevant resolution articles for fault remediation. The
key attributes of the augmented metadata-based KB are extracted
from disparate data sources, such as tickets, resolution taxonomy,
product catalog, and log data. In addition, we propose an automatedquery formulation mechanism from detected log anomaly events
and predicted context - models are proposed to predict values of
contextual attributes - to retrieve targeted and relevant resolution
documents from the augmented KB. The key contributions of this
paper are 1) Augmented metadata-based KB creation, and building
Metadata Prediction Models, 2) Metadata Prediction for Problem
Explainability and Query Formulation, 3) Metadata-based Retrieval
(MBR) for resolution recommendation, 4) an industrial case study
showcasing an insurance application deployed on our organization
cloud with AIOps integration for anomaly detection feeding into
the proposed MBR based resolution recommendation. One of the
key contributions that must be emphasized is that via MBR for
40% of the queries the most relevant document appears in the top-
ranked position. And, for 60% of the queries, the correct result is
within the top 3. This is a key element to be noted because it may
lead to a significant improvement in SREs‚Äô productivity and MTTR,
as the resolution recommendations are pre-populated along
with explanations of the auto detected log anomalies.
The rest of the paper is structured as follows. Section 2 describes
our proposed approach. Section 3 describes the datasets, experimen-
tal settings, discussion of quantitative and qualitative results, and a
case study in Section 4. Section 6 includes a brief summary of re-
lated work with respect to text-based retrieval and metadata-based
retrieval. Finally, Section 7 concludes the paper.
2 APPROACH
In order to address the above limitations, this paper contributes a
semi-supervised approach for resolution retrieval (refer Figure 2),
described as follows:
Figure 2: Metadata-Based Retrieval
(1)Augmented Dataset Creation : The augmented dataset
with metadata attributes is created at build time. In addition
to bringing structure to the heterogeneous unstructured data
1380Metadata-Based Retrieval for Resolution Recommendation in AIOps ESEC/FSE ‚Äô22, November 14‚Äì18, 2022, Singapore, Singapore
(such as historical tickets, support documents, etc.) this step
helps build an integrated ready-to-use KB. Such an integrated
dataset exploits and combines information nuggets spread
across multiple siloed datasets, leading to comprehensive and
richer resolution recommendations. Indexing the augmented
KB (Section 2.1) enables Metadata-Based Retrieval (MBR) and
metadata prediction model training.
(2)Metadata Prediction for Problem Explainability and
Query Formulation : SREs typically receive large volumes
of historical data, in the form of tickets, that are created
due to problems/issues reported by clients seeking support
for problem diagnosis of their IT operational issues. The
historical ticket data typically contains problem categories
annotated by SREs as a way to summarize the problem in
simpler terms (similar to tags used in forums). Such data is a
rich source of information that can be exploited in various
ways, one of them being problem explanation. As mentioned
earlier, some of the log message may be difficult to absorb
for non-experts, but annotations Database Connection as
Category andJ2C-JDBC-Driver asSub-Category may lead
to an easier comprehension. Such annotations help provide
the context of the problem to the SRE, for example, that the
problem is related to database connection due to driver is-
sue. The proposed system exploits the historical annotations
associated with anomalous LogLines that were referenced
in the ticket data to train the metadata prediction models.
At run-time, given an auto-detected log anomaly via Anom-
aly Detection component shown in Figure 1., the first step
is to predict the metadata (i.e. problem Category and sub-
Category ) using the metadata prediction model, as shown
in Figure 2 and described in Section 2.2. Next, it uses the
predicted metadata and the detected log anomaly to automat-
ically formulate a query without SRE intervention, in turn
addressing the inefficiency of Inadequate Query Formulation
for Resolution Retrieval , discussed earlier in Section 1.
(3)Metadata-Based Retrieval - MBR : Finally, perform an
MBR (Section 2.4) on the Metadata-Based Augmented KB us-
ing the automatically formulated query to retrieve targeted
and relevant resolutions for solving the underlying problem.
The results are presented with the explanation of the anoma-
lous LogLine using contextual information, such as Category
andSub-Category , to describe the problem in simpler terms.
Presenting explainable results containing resolutions boosts
SREs‚Äô confidence, gaining their trust, and thereby improving
SREs‚Äô efficiency with a more systematic and comprehensive
problem diagnosis.
2.1 Metadata Extraction and Indexing
We leverage information spread across four different siloed datasets,
described in Table 1, for an application server product. We explain
below why and how these datasets are combined together to pre-
pare an augmented dataset that is indexed for MBR. We begin with
a discussion of the challenges in using these datasets. Firstly, as the
datasets exist in silos, each contains information nuggets that if
integrated provide a more holistic and contextual view of the events
to aid in the improvement SREs‚Äô productivity for faster and moreTable 1: Sample IT Datasets and the corresponding Metadata
Dataset Metadata
Ticket Data TicketNumber ,ReportedTime ,ProductName ,ProductVer-
sion,Severity ,Ticket ,TicketBody
Resolution
TaxonomyTicketDescription ,ResolutionTitle ,ResolutionUrl ,Cate-
gory,Sub-Category
Product Con-
tentMessageCode - alphanumeric Identifier, MessageString ,
ResolutionDescription ,ResolutionUrl
Log Data TimeStamp ,LogLine (contains LogLevel ,MessageType ,
MessageCode )
effective resolution derivation. Secondly, as log lines could run into
hundreds of millions per system/application/component, associat-
ing anomalous log lines with historical ticket data to retrace the
actual time when the event happened is non-trivial. Thirdly, resolu-
tion taxonomy is maintained by Subject Matter Experts (SMEs) and
hence, the same resolution may be categorized in different Category
andSub-Category metadata based on their experience and under-
standing of an event, leading to data ambiguities. When a new ticket
is created in support, it is manually annotated by the SMEs with
the problem Category andSub-Category metadata, hence during
run-time, when a log anomaly is detected, its problem Category and
Sub-Category needs to be predicted. Therefore, machine learning
models are exploited to predict such metadata, which is explained
in Sub-Section 2.2. The algorithm below provides steps to prepare
an augmented dataset for 1) metadata prediction model training
and 2) index creation for resolution retrieval, refer to Figure 3.
(1)For each event , from Ticket Data andResolution Taxonomy
extract the metadata (see Table 1) for the corresponding Ticket-
Number , where ResolutionUrl is a SME identified resolution
related to the event reported.
(2)For each event , check if the corresponding logs for the affected
entity are available.
(a)Use the ReportedTime from step 1 to identify the time window
within the +/- delta of the ReportedTime to extract logs (Note:
This may still be thousands of LogLine s).
(b)Run the extracted log lines through the Log Anomaly Detec-
tion (LAD) model [ 18] to identify anomalous log lines (Output
may be a couple of anomalous log lines).
(3)Extract LogLine s from the TicketBody , which contains a full tran-
script of interactions between the client and SMEs, including a
small number of curated erroneous log lines.
(4)Combine Category ,Sub-Category from Step 1, and LogLine s from
Step 2(b) and Step 3 as training data for metadata prediction
model, described in Sub-Section (2.2).
(5)Use custom defined rules to extract metadata from the dataset
Product Content. Additionally, define a new attribute IsAction-
able, which is set to Yif an actionable keyword (Semantic Role
Labeling[ 13]) is present in ResolutionDescription else set it to N.
(6)Combine data extracted in Step 1, Step 2(b), Step 3 and Step 5
using MessageCode as the common attribute.
(7)We observed that ResolutionUrl andMessageCode exhibit many-
to-many relationship. Therefore, we compute the Resolution-
SpecificityScore(RSS) that indicates the confidence on the Res-
olutionUrl for each MessageCode . Assume that the frequency
1381ESEC/FSE ‚Äô22, November 14‚Äì18, 2022, Singapore, Singapore Harshit Kumar, Ruchi Mahindru, and Debanjana Kar
ofResolutionUrl ùë¢ùëñforùëÄùëíùë†ùë†ùëéùëîùëíùê∂ùëúùëëùëí ùëó(ùëÄùê∂ùëó) isùëêùëñùëó, then RSSis
calculated as follows,
ùëÖùëÜùëÜ=ùëêùëñùëó√ç
ùëóùëêùëó‚àóùëôùëúùëî|ùëÄùê∂|
|ùëÄùê∂ùëó‚ààùëÄùê∂ :ùë¢ùëüùëôùëñ‚ààùëÄùê∂ùëó|(1)
whereùëÄùê∂is a set of all MessageCode s. The first term,ùëêùëñùëó√ç
ùëóùëêùëó, cap-
tures the importance of the ResolutionUrl ùë¢ùëñforùëÄùëíùë†ùë†ùëéùëîùëíùê∂ùëúùëëùëí ùëó
(ùëÄùê∂ùëó). The second term,|ùëÄùê∂|
|ùëÄùê∂ùëó‚ààùëÄùê∂:ùë¢ùëüùëôùëñ‚ààùëÄùê∂ùëó|, captures the im-
portance of the ùëÄùëíùë†ùë†ùëéùëîùëíùê∂ùëúùëëùëí ùëó(ùëÄùê∂ùëó) for the ResolutionUrl ùë¢ùëñ.
Figure 3: Metadata-Based Augmented KB Creation
2.2 Metadata Selection and Prediction
Sub-Section 2.2.1 explains how to identify metadata attribute(s) that
are relevant for the task of resolution retrieval. Some of these at-
tributes may be readily available at run-time as part of the input log
anomaly, for example, operating system, version, etc. While others,
such as problem Category andSub-Category (which are tradition-
ally manually annotated by the SREs), are not readily available at
run-time. Hence, it is prudent to build prediction models from the
historical annotated data as explained in Sub-Section 2.2.2 and 2.2.3.
2.2.1 Metadata Selection. For a given task, in this case, retrieval
of resolution document, selecting metadata attributes from a given
set of attributes in the Metadata-Based Augmented KB is essential
for effective retrieval. The retrieval of the resolution document
will be based on the match of metadata attribute values, and the
number of such metadata attributes should be kept to a minimum
otherwise the query formulation will be very complex. For a faster
convergence, the system needs to find metadata attributes along
which the system has minimum entropy (impurity or randomness
in attribute values). Entropy[ 29], Information gain[ 10], and Cor-
relation among the metadata attributes are calculated to identify
useful contextual features for resolution retrieval. Let ùëàbe a set of
ùëÅmetadata attributes, ùëà={ùë¢1,ùë¢2,...,ùë¢ùëÅ}, where each metadata
attributeùë¢ùëñfor itsùëöunique values has an associated distribution
={ùë£ùëñ
1:ùëê1,ùë£ùëñ
2:ùëê2,...,ùë£ùëñùëö:ùëêùëö}(ùëêùëñ‚Äôs being the frequency). Then theentropyùëéùëñfor a metadata attribute ùë¢ùëñis calculated as follows:
ùëù(ùëêùëñ
ùëó)=ùëêùëñ
ùëó√çùëö
ùëò=1ùëêùëñ
ùëò
ùê∏(ùëéùëñ)=‚àíùëö‚àëÔ∏Å
ùëó=1ùëù(ùëêùëñ
ùëó)log2ùëù(ùëêùëñ
ùëó)(2)
Based on the application server dataset that we have used for our
experimentation, the entropy of sample metadata attributes Sever-
ity, Category, Sub-Category, ResolutionTitle, and ResolutionUrl are
1.62,4.05,6.75,8.334and7.76, respectively. The range of entropy
values is from 0 to ùëôùëúùëî2ùëö, whereùëöis the number of distinct values
in the metadata attribute distribution; when m=2, for binary class,
the maximum value of entropy is 1. To identify which metadata
attribute is relevant for the task of resolution retrieval, we compute
its correlation with the ResolutionUrl . While Severity reports the
lowest entropy, its low correlation with ResolutionUrl renders it as
an attribute of less importance. Low entropy attributes, such as Cat-
egory andSub-category , report a high correlation with ResolutionUrl
and thus constitute strong candidates for contextual metadata pre-
diction. The following Sub-Sections explain how to build prediction
models for Category andSub-Category metadata attributes.
2.2.2 Category Prediction. Using output of Step 4) of data augmen-
tation algorithm described in Sec. 2.1, we train Stochastic Gradient
Descent (SGD)1based supervised classifiers to predict problem
Category andSub-Category .
While we report a good performance on different sample test
sets as discussed in Section 3.4, we observed a sharp increase of
11.01% in Category prediction accuracy when the three-most prob-
able Category predictions are used as opposed to the most probable
predicted category. This means, that although the most probable
predicted Category may not match the ground truth, however, one
of the top 3 predicted Categories matches the ground truth. This war-
ranted a formulation of a filtering strategy to improve the Category
prediction accuracy, discussed next.
Filtering Strategy .: From the training dataset, a Local Fre-
quency Table ( ùêøùêπùëá) is constructed consisting of MessageCode (ex-
tracted from LogLine ),Category , along with frequency. The ùêøùêπùëá
captures how often a particular combination of MessageCode and
Category were seen in the training corpus. A two-step filtering
process is applied to select a predicted category from the top 3:
(1)For each MessageCode ùëö, letùëÉùëñbe a set of top 3 predicted cate-
gories, andùëÑùëöbe a set of observed categories obtained from
theùêøùêπùëá[ùëö]. The intersection of ùëÉùëñandùëÑùëöretains all those
categories that were also observed in the training data:
ùêπùëö=ùëÉùëñ‚à©ùëÑùëö:ùëö‚ààùêøùêπùëá (3)
where,ùêπùëöis a set of retained categories found in both ùëÉùëñandùëÑùëö;
intuition behind this step is that among the predicted categories
ùëÉùëñ, those that were unobserved in the corpus for a particular
MessageCode ùëöare most likely incorrect predictions.
(2)LetùëÉùëüùëñbe a sorted set of prediction probability scores corre-
sponding to predicted categories in set ùëÉùëñ. The difference in
probability scores of the top two predicted categories below a
1https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.
SGDClassifier.html
1382Metadata-Based Retrieval for Resolution Recommendation in AIOps ESEC/FSE ‚Äô22, November 14‚Äì18, 2022, Singapore, Singapore
certain threshold indicates that Category prediction model is not
confident about the predicted Category with a lower prediction
score; in such a scenario, ùêøùêπùëá guides the Category prediction
model to select the ùê∂ùëéùë°ùëíùëîùëúùëüùë¶‚ààùêπùëöwith the highest frequency
as the predicted category:
ùëëùëñùëìùëñ=|ùëùùëé‚àíùëùùëè|:ùëùùëé,ùëùùëè‚ààùëÉùëüùëñ;ùëè>ùëé;ùëè,ùëé<=ùëôùëíùëõ(ùëÉùëüùëñ)
ùëÜùëÉ=ùëÜùëÇùëÖùëáùê∏ùê∑(ùëëùëñùëìùëñ)
ùëÉùëÜùëñ=ùëÉùëüùëñ‚àóùëÑùëö[ùëê],‚àÄùëê‚ààùëÉùëñ, ùëÜùëÉ[0]>=ùë°
ùëÉùëÜùëñ=ùëÉùëüùëñ, ùëÜùëÉ[0]<ùë°(4)
where,ùëÉùëÜùëñis a new probability score for each ùëÉùëñ, calculated
by taking a dot product of Category probability score and its
frequency count obtained from ùêøùêπùëá. If the difference in ùëëùëñùëìùëñ>=
a pre-defined threshold ùë°then choose the Category with the
highest prediction probability implying that the model is confi-
dent about its prediction. Otherwise, choose the Category with
the highest frequency count. We empirically observed ùë°= 0.2
as a good discriminator to gauge the confidence of Category
prediction model; Values greater than 0.2 is a stricter threshold
which resulted in comparatively more false negatives, and val-
ues less than 0.2 increased the number of false positives thus
degrading the overall performance of category prediction.
2.2.3 Sub-Category Prediction. The metadata attribute Sub-Category
depends on the Category , forming a two-level taxonomy. Figure 4
illustrates the three approaches to predict the Sub-Category for an
input LogLine .
Figure 4: Approaches for Sub-Category prediction
(1)Independent : Given an input LogLine , both Category andSub-
Category classifiers are trained independently to predict their
respective classes.
(2)Conditional : ASub-Category classifier model is trained which
is conditioned upon the input logLine and the predicted Category
obtained from the trained Category classifier.
(3)Hierarchical :LogLine and Predicted Category are input to
predict the Sub-Category classes that are related to Category
based on the two-level taxonomy relationship. This leads to one
Sub-Category model per Category , each equipped to predict a set
ofSub-Category classes within the predicted Category , leading
to a more precise and faster classification. For instance, when
using a conditional approach, there will be only one large Sub-
Category model for all Sub-Category classes. Whereas, whenusing a hierarchical approach, there will be n Sub-Category
models, one for each Category that will predict one of the Sub-
Category classes within its hierarchy. Several extensive grid
search experiments were performed to identify the most optimal
set of hyper-parameters Category andSub-Category prediction.
2.3 Text-Based Retrieval
Text Retrieval is a popular choice[ 9,19,32] to find relevant docu-
ments for a given textual query. The most preferred method is to
index documents‚Äô textual content to create an index. At run-time, a
query is formulated by a human which is run against an index to re-
turn relevant documents. However, for the system proposed in this
paper, query formulation is automatic, based on the log anomaly
and metadata prediction. Hence, avoiding the inefficiency Ad-hoc
Problem Diagnosis and Resolution Application , discussed earlier in
the Section 1. In text retrieval, the average length of a query is two
to three words[ 34]. Whereas, in this case, the query consists of the
whole log anomaly that includes the MessageCode ,MessageDescrip-
tion and/or exception message. We represented each resolution
document as a 512 dimension vector using Glove[ 28] pre-trained
embeddings. These embeddings were then indexed using the annoy
index[ 5]. Annoy allows the capability to index embeddings and
uses approximate nearest neighbor[27] for retrieval.
2.4 Metadata-Based Retrieval
For a stream of anomalous LogLines arriving from an upstream
Anomaly Detection module (refer Figure 1), the proposed Metadata-
Based Retrieval (MBR) predicts the value of metadata attributes,
Category andSub-Category , using pre-trained models. Furthermore,
it masks the LogLine to remove any run-time environment specific
parameter values. If a MessageCode is present in the Log Anomaly
then a query is formulated consisting of MessageCode and predicted
Metadata . Otherwise, masked anomalous LogLine augmented with
predicted Metadata is used to formulate a query. Execute the query
on the Metadata-Based Augmented KB (refer Figure 2) created using
the algorithm described in Section 2.1 to return top k result-set
along with the metadata. Next, The results are re-ranked using
the maximum ResolutionSpecificityScore . Finally, a result set is pre-
pared that consists of predicted metadata, along with ResolutionTi-
tle,ResolutionUrl ,ProductName ,ProductVersion ,Severity , providing
Explainability to the SRE for the retrieved result-set.
3 EXPERIMENTS
This section provide details of the experiments to demonstrate the
effectiveness of the proposed system, including the dataset and its
characteristics, baseline models, and analysis of results.
Table 2: Characteristics of the Application Server datasets
#train #test #category #sub-category
App.
ServerDSet-1 7416 153 44 266
DSet-2 8375 583 50 275
DSet-3 42199 5350 69 499
1383ESEC/FSE ‚Äô22, November 14‚Äì18, 2022, Singapore, Singapore Harshit Kumar, Ruchi Mahindru, and Debanjana Kar
3.1 Dataset
The data for experiments were collected from an in-house deploy-
ment of applications on the cloud that uses a web Application Server.
These applications range from insurance, finance, education, etc.
The duration of log data spans from July 2017 to May 2021. In order
to study the effect of varying dataset sizes on the metadata predic-
tion model training and the downstream resolution retrieval task,
the application server dataset was divided into three sub-datasets -
DSet-1, DSet-2, DSet-3 - of varying sizes from smallest to largest.
Experimenting with datasets of varying sizes allowed us to under-
stand the sensitivity of the learning algorithm to training dataset
size. This is highly critical because when engaging with clients,
the sales team and client representative teams need to clearly ar-
ticulate the training data requirements upfront to the clients. Not
all clients may have large volumes of data available, transparency
pertaining to dataset size and model training accuracy leads to a
clear set of goals and expectations for both the client and the cloud
service provider. Table 2 presents the statistics of the three datasets.
Each record in the dataset contains an original LogLine ,Category ,
Sub-Category , and the ResolutionURL .
3.2 Evaluation Metrics
To evaluate the performance of the metadata prediction algorithms,
accuracy is used as an evaluation metric. Metadata prediction is
a multi-class classification algorithm, where Categories andSub-
Categories are the classes. First, a confusion matrix is computed,
where the classes are listed in the same order in the rows as in the
columns, therefore, the correctly classified elements are located on
the main diagonal from top left to bottom right. The rows repre-
sent the ground truth, i.e. the actual classification, and the columns
represented the predicted classification. Second, the accuracy is cal-
culated from the confusion matrix as, ùëéùëêùëêùë¢ùëüùëéùëêùë¶ =ùëáùëÉ+ùëáùëÅ
ùëáùëÉ+ùëáùëÅ+ùêπùëÉ+ùêπùëÅ,
whereùëáùëÉ,ùëáùëÅ,ùêπùëÉ,ùêπùëÅare the observed True Positives, True Nega-
tives, False Positives, and False Negatives, respectively. To measure
the performance of the resolution retrieval, Precision@k and Ac-
curacy are used as evaluation metrics. Precision@k measures the
number of cases where the relevant ResolutionURL occurs within
top k positions. And, accuracy is calculated, if the top k results
contain the relevant ResolutionURL for a given query.
3.3 Baseline Methods and Proposed Methods
Here we list the baseline methods, including different versions
of them with and without the contextual information, and the
proposed metadata-based retrieval method.
Text(Content)-Based Retrieval Methods : The following base-
line models use the index created from the contents of resolution
documents, refer Section2.3.
(1)CBR+LL - uses the input anomalous LogLine as a query to
search the text-based index to return the resolution documents.
(2)CBR+MC - For a given anomalous LogLine , extract the Mes-
sageCode for query formulation to search the text-based index
to retrieve the resolution documents.
(3)CBR+MC+CAT - For a given anomalous LogLine , extract the
MessageCode and predict the Category . Use the MessageCode and
theCategory for query formulation and search the text-based
index to retrieve the resolution documents.(4)CBR+MC+CAT+SUB-CAT - For a given anomalous LogLine ,
extract the MessageCode , and predict the Category and Sub-
Category . Use the MessageCode , the predicted Category , and the
Sub-Category to formulate a query and search the text-based
index to retrieve the resolution documents.
Metadata-Based Retrieval Methods : The following proposed
models use the Metadata-Based Augmented Knowledge Base (KB)
which was explained in Section 2.1.
(1)MBR+LL - The proposed model uses the input anomalous Log-
Line as a query to search the Metadata-Based Augmented KB .
(2)MBR+MC - The proposed model formulates a query from the
MessageCode extracted from the LogLine to search the Metadata-
Based Augmented KB .
(3)MBR+MC+CAT - The proposed model formulates a query
from the combination of a) MessageCode extracted from the
given anomalous LogLine , b) predicted Category for the given
anomalous LogLine . The query thus formed is used to search
theMetadata-Based Augmented KB to retrieve resolutions.
(4)MBR+MC+CAT+SUB-CAT - The proposed model formulates
a query from the combination of a) MessageCode extracted from
the given anomalous LogLine , b) predicted Category andSub-
Category for the given anomalous LogLine . The query thus
formed is used to search the Metadata-Based Augmented KB to
retrieve resolution documents.
3.4 Results and Discussion
This section presents the results of the experiments, along with a
detailed analysis.
Evaluation - Metadata Prediction: The main objective of the
evaluation is to compare the correctness of metadata prediction
1) across varying dataset sizes and 2) using the three metadata
prediction models explained in Section 2.2.2. Based on the eval-
Table 3: Accuracy of Metadata attributes (Category and Sub-
Category) prediction using the three different models: Inde-
pendent (Ind), Conditional(Cond), and Hierarchical(Hier)
Category PredictionSub-Category Prediction
Ind Cond Hier
DSet-1 72.45% 52.1% 55.68% 56.29%
DSet-2 74.81% 61.17% 64.01% 74.81%
DSet-3 83.13 % 69.75% 72.54% 88.41 %
uation results in Table 3, we share the details of our analysis and
observations below.
(1)Model Accuracy Improves on Larger Dataset : First observa-
tion is that with the availability of more data, DSet-3 vs DSet-1,
the percentage improvement in metadata prediction for Cate-
gory andSub-Category is approximately 15% ((from 72.45% to
83.13% )) and 33-57% - depending on the Sub-Category predic-
tion algorithm, respectively. For DSet-1, and similar for other
datasets, we observed that the long-tail categories (correspond-
ing to <=5 instances) were classified incorrectly. This indicates
that the prediction models performed well on the majority of
data classes where the number of training examples was > 5.
1384Metadata-Based Retrieval for Resolution Recommendation in AIOps ESEC/FSE ‚Äô22, November 14‚Äì18, 2022, Singapore, Singapore
Table 4: Comparing Accuracy, Precision@k, and Average Execution Time per Query (sec) on MBR and CBR for resolution
retrieval on DSet-3
Method Accuracy P@1 P@2 P@3 P@4 P@5 Average Execution Time
MBRMBR+ LL 23.52 0.086 0.111 0.125 0.132 0.138 0.36
MBR+MC 33.68 0.141 0.179 0.195 0.204 0.211 0.34
MBR+MC+CAT 48.32 0.246 0.294 0.313 0.325 0.332 0.37
MBR+MC+CAT+SUB-CAT 60.31 0.396 0.449 0.464 0.471 0.477 0.37
CBRCBR+LL 6.77 0.028 0.038 0.04 0.042 0.043 4.11
CBR+MC 4.45 0.023 0.027 0.029 0.03 0.031 4.55
CBR+MC+CAT 7.34 0.023 0.036 0.04 0.042 0.043 3.8
CBR+MC+CAT+SUB-CAT 16.67 0.047 0.07 0.084 0.089 0.091 3.87
(2)Increase in Categories and Sub-Categories with Dataset
Size: Although the number of Category andSub-Category in-
creased considerably (from 44in DSet-1 to 69in DSet-3, and
from 266in DSet-1 to 499in DSet-3, respectively), the model per-
formance improved on the long-tail categories. This is because,
for the dataset of a larger size, each class had more instances to
train the prediction model.
(3)Hierarchical Classifier is the Winner : For the Sub-Category
prediction task, Hierarchical classifier outperforms Indepen-
dent and Conditional classifier; a percentage improvement in
Independent vs Hierarchical across the three datasets are: 8%
for DSet-1, 22.3% for DSet-2 and 26.8% for DSet-3. The superior
performance of the Hierarchical classifier can be attributed to
the fact that it exploits the taxonomy relationship between meta-
data attributes when training Category specific models. Further,
utilizing taxonomy relationship with predicted Category labels
reduces the search space for the Sub-Category classifier consid-
erably, thereby improving its prediction accuracy.
Next, we discuss the usefulness of the metadata prediction mod-
els for the resolution retrieval task.
Evaluation - Resolution Retrieval: Table 4 compares the reso-
lution retrieval accuracy of the proposed Metadata-based Retrieval
(MBR) and the baseline Text (Content) Based Retrieval (CBR). Re-
sults show that the proposed methods perform much better than
the baseline methods. Especially, note that, MBR with MessageCode
and predicted context (MBR+MC+CAT+SUB-CAT) has an overall
retrieval accuracy of 60.31% . Whereas CBR with MessageCode and
predicted metadata (CBR+MC+CAT+SUB-CAT) has an overall accu-
racy of 16.67% , the percentage improvement is 261% approximately.
This indicates the usefulness of Metadata-Based Augmented KB , that
is the data that otherwise existed in silos, when integrated together
and converted into a structured form, results in a more effective
resolution retrieval. Also, it is to be noted that, the use of contex-
tual information, i.e. MessageCode ,Category , and Sub-Category , for
query formulation improves the retrieval performance for both
MBR and CBR method. When contextual metadata information is
provided for query formulation, the improvement in accuracy for
MBR is more prominent than for CBR. For instance, when MBR
is used without and with context, the retrieval accuracy improves
from 23.52% to60.31% , an absolute improvement of 37% points.
Whereas, when CBR is used, the retrieval accuracy improves from
6.77% to16.67% , respectively, an absolute improvement of 9.9%
points.Precision@k measures if the relevant resolution document oc-
curs in the top k position. The results indicate that when Category
andSub-Category are used along with the MessageCode for query
formulation with MBR, approximately 39% of the queries a rele-
vant resolution document appears at the first rank, and for 45% of
the queries, a relevant resolution document appears in the top 2
positions. Whereas for the CBR when the context is provided, only
4.7% of the queries have a relevant document at the first rank, and
7%of the queries return a relevant document at the top 2 positions.
These results show that the MBR with contextual information ranks
the relevant document at the top position. This is an extremely
critical achievement to address the challenges discussed earlier in
Section 1 about improving SREs‚Äô productivity; this is because, for
39% of the input queries, SREs are confident that the result at the
top rank is the correct resolution. Hence, it increases their confi-
dence in problem-solving and in turn improves their productivity
with a more systematic problem diagnosis and resolution retrieval.
Furthermore, the more systematic problem diagnosis and resolu-
tion retrieval lead to a reduction in MTTR and increased customer
satisfaction, hence, improved SLAs. To summarize, for resolution
retrieval, MBR outperforms CBR by a significant margin, and the
use of contextual information for query formulation helps improve
the overall retrieval accuracy of both the method used.
Next, we compare the retrieval accuracy of the method MBR
with contextual information (MBR+MC+CAT+SUB-CAT) across
the three datasets. We want to study the effect of dataset size on the
quality of retrieved resolutions. Table 5 shows the retrieval accuracy
on three datasets when Independent, Conditional, and Hierarchical
Sub-Category prediction approaches are used for metadata pre-
diction. Although Category andSub-Category prediction models
perform better as they are exposed to larger datasets for training,
the same is not reflected in the retrieval accuracy. For example,
referring to Table 3, the metadata prediction accuracy of Category
class improves from 72.45% to83.13% , and the Sub-Category class
improves from from 50.29% to69.75% for the Independent, 52.69%
to72.54% for Conditional, and 53.89% to75.50% for Hierarchi-
cal. However, when the Independent model is used for metadata
prediction, the resolution retrieval accuracy shows a reasonable im-
provement of (49.01% to 50.53%). Whereas, the resolution retrieval
accuracy drops for the Conditional(64.0% to 58.65%) and Hierar-
chical models (64.0% to 60.31%). This leads to our first observation,
which is, smaller datasets have biases which may lead to incon-
sistent results. Hence, it is recommended to use a larger dataset
for training models to get consistent and reliable results.
1385ESEC/FSE ‚Äô22, November 14‚Äì18, 2022, Singapore, Singapore Harshit Kumar, Ruchi Mahindru, and Debanjana Kar
Irrespective of the size of the dataset, as we move from left to
right, that is, Independent to Conditional or Hierarchical, the res-
olution retrieval accuracy improves. This is because the models
being trained to have seen enough variations of Category andSub-
Category class instances. For example, for DSet-1, the resolution
retrieval accuracy improves from 49% (Independent model) to 64%
(Hierarchical model), percentage improvement of 30%. Whereas,
for DSet-3, the resolution retrieval accuracy improves from 50.5%
(Independent model) to 60.31% (Hierarchical model), a percent-
age improvement of 19.4% . This leads to the second observation
that the Conditional and Hierarchical models are superior
to the Independent model , as they exploit the taxonomy rela-
tionship between Category andSub-Category . Hence, leveraging
relationship between metadata for building metadata predic-
tion model is essential.
Table 5: Comparing Resolution Retrieval Accuracy for
MBR+MC+CAT+SUB-CAT for three metadata prediction
models across three datasets of different sizes
Resolution Retrieval Accuracy
Independent Conditional Hierarchical
DSet-1 49.01 64.0 64.0
DSet-2 50.34 66.6 64.6
DSet-3 50.53 58.65 60.31
Evaluation - Average Execution Time: The last column in
Table 4 shows the average execution time per query in seconds for
the baseline and the proposed methods. The CBR+LL method takes
4.11 seconds on average to return resolution documents, whereas
the MBR+LL method takes only 0.36 seconds . When contextual
information is used for query formulation in MBR, the average
execution time remains more or less the same, in the range of 0.34
to 0.37 seconds. Whereas, when contextual information is provided
for CBR, the average execution time reduces from 4.11 to 3.8 seconds.
This is because the availability of contextual information creates
a view over the whole index, which is a subset, this reduces the
search space to find relevant documents, hence the reduction in
execution time. We also observed that the average execution time
per query for the Hierarchical model is two times faster than
the Conditional model . This is because the Hierarchical model
has one Sub-Category model per category, hence it has a smaller
number of classes to predict from and is thus faster.
Qualitative Evaluation - Metadata Prediction and Reso-
lution Retrieval: In addition to the quantitative evaluations dis-
cussed earlier, we conducted a qualitative evaluation for both Meta-
data Prediction and Metadata-based retrieval. Sixteen unique most
frequently occurring Log anomalies were selected. For result val-
idation, five SREs who manage the Application Server product
were consulted, and majority voting was used to arrive at the final
result. For each anomalous LogLine , a row in Table 6 shows the
obfuscated MessageCode , and the last character ‚ÄôE‚Äô, ‚ÄôW‚Äô, ‚ÄôI‚Äô indicates
whether it is an error, warning or informational (column A), num-
ber of retrieved ResolutionUrl s using baseline method (B), number
of retrieved ResolutionUrl s using MBR (C), number of retrieved Res-
olutionUrl s using MBR that contain steps that can be executed byTable 6: Qualitative Evaluation of Metadata Prediction
(Category) and Resolution Retrieval
(A) (B) (C) (D) (E) (F) (G) (H)
MC1E 12 2 0 - JDBC JDBC Y
MC2E 9 2 0 - Security Security N
MC3E 7 3 3 3 System System Y
MC4W 3 2 2 2 JDBC JDBC Y
MC5E 1 1 0 - Transac Transac N
MC6E 1 1 1 1 Perf JMS N
MC7W 1 1 1 1 System WebServ Y
MC8W 2 2 0 - Classloader HTTP Y
MC9I 1 1 1 1 - JDBC Y
MC10I 1 1 0 - - Security N
MC11E 1 1 0 - - System Y
MC12W 1 1 1 1 - Perf Y
MC13I 1 1 1 1 - JPA Y
MC14W 0 3 1 0 - Security Y
MC15W 0 3 3 1 - Security N
MC16I 0 3 3 0 - Security Y
Total 41 28 17 11 - - -
SEs for problem diagnosis and resolution (D), validation of column
D by SEs (E), actual Category label based on the historical data (F),
predicted Category label (G), SEs validation of F and G (H). For
instance, for a given anomalous LogLine ,MC15W: The res1 could not
be found for element with id attribute res2 , the extracted Message-
Code isMC15W , the metadata prediction model predicted Category
isSystem . The formulated query is MessageCode =‚ÄôMC15W‚Äô and
Category =‚ÄôSystem‚Äô that returns 3 results using MBR. Whereas, for
the same query, the baseline returns 0 results, as the MessageCode
is not present in the dataset. However, the masked LogLine and the
predicted Category help MBR to find the matching results. Note
that among the 3 returned results, all are actionable (i.e. executable
by SEs). However, SEs suggested that only 1 result out of 3 is rel-
evant; a result is relevant if it helps resolve the problem. Overall
qualitative accuracy of the predicted Category is (68.75% ) i.e. 11/16.
For the MessageCode sMC2E andMC5E , SEs indicated that the
ground truth Category labels were incorrect highlighting that the
model is trained on imperfect (subjective) data. We recomputed the
Category prediction accuracy on valid ground truth data only, then
the predicted Category accuracy is ( 78.57% ), i.e. 11/14. The joint
accuracy of the Category andSub-Category prediction is 62%.
For each of the unique anomalous log lines, Category is predicted
using the Conditional Metadata Prediction model. In Table 6, across
16 unique log lines, MBR returned 28 (column C) results as com-
pared to 41 (column B) returned by the baseline, a reduction of
(31%) in the result set; this is because MBR leverages contextual
Metadata during query formulation, resulting in a more targeted
result set. Using rule-based approach for resolution classification
(Step 3 during augmented dataset preparation in Section 2.1), 17/28
(60%) resolutions are actually actionable (i.e. executable). Hence, it
is clear that MBR would derive productivity improvement of SREs
by addressing the inefficiencies discussed in Section 1, as they do
not have to go through non-actionable resolutions (e.g. reference to
another repository or messages like the problem solved or no action
needed or contact support). Finally, per SEs evaluation 11/17 (64.7%)
1386Metadata-Based Retrieval for Resolution Recommendation in AIOps ESEC/FSE ‚Äô22, November 14‚Äì18, 2022, Singapore, Singapore
Figure 5: Log anomalies detected from 45 days of logs obtained from an application deployed on cloud
results were found relevant; and based on observations discussed
above, there is room for improvement. Furthermore, MessageCodes
of type informational and warning are predictive in nature, indi-
cating that an incident may occur in near future. Given that MBR
leverages LogLine for Log Anomaly Detection, the system identifies
anomalous log windows containing such predictive signals; based
on the MessageCode s in Table 6, 62% are informational and warning
that can aid in proactive remediation of incidents.
4 INDUSTRIAL CASE STUDY
To test the usefulness of the proposed MBR based resolution rec-
ommendation, we deployed an insurance application on our orga-
nization cloud Application Server. For a period of 45 days, from
1ùë†ùë°March to 15ùë°‚ÑéApril 2021, a total of 186ùêæsystem log lines were
collected. Each application server log contains a designated Mes-
sageCode orLogLevel , or both. These logs are aggregated into 10
second windows, this process is called as windowed log events,
resulting in 186ùêælog windows. Each log window has a message
field that contains a log message, and there are other fields such as
MessageCode ,StartTimeStamp ,EndTimeStamp ,Severity , and other
information related to logging. A total of 196log anomalies were
detected by the log anomaly detection component of AIOps pipeline
shown in Figure1; out of these only 98contain error MessageCode .
Figure 5 shows five batches of log anomalies detected at differ-
ent time intervals. The first (March 4), second (March 8), and fifth
(April 15) batch contain transitory log anomalies, that are likely
false events and can be ignored. The third batch contains 39log
anomalies, the first one appeared on March 25, and it persisted for
10 minutes. Similarly, the fourth batch contains 55log anomalies,
first of which appeared on March 30, and it persisted for 9 minutes.
For both batches, the most significant message code is MC1E which
requires SRE attention. Now that a significant and persistent log
anomaly event with MessageCode has been identified, the proposed
MBR based resolution is used to retrieve the resolution. Figure 6
shows the user interface of our proposed MBR based resolution
retrieval system. It takes as input the above anomalous log line withmessage code to retrieve up to top 3 resolution documents. It also
predicts the context ( Category andSub-Category ) of the log anom-
aly which is otherwise difficult to comprehend, this addresses the
two challenges mentioned in the introduction about Adhoc Problem
Diagnosis and Resolution Application andincorrect problem routing .
The query is automatically formulated from the message code in
the log anomaly and the predicted contextual information, which
addresses the second challenge, Inadequate Query Formulation for
Resolution Retrieval . Overall, the proposed system empowers the
SRE to quickly isolate the anomalous log events from a large amount
of log data and provide the resolution documents to mitigate the
issue, thereby reducing the MTTD and MTTR. The third and fourth
batches of log anomalies have a lot in common. The first time log
anomaly event with message code MC1E was detected, the SRE
could have used the proposed MBR to retrieve resolutions and fol-
lowed it to resolve the problem. Hence, avoiding recurrence of the
problem. That is, with the availability of the MBR based resolution
recommendation, there will be only one major event as compared to
fivein the 45 days period, and that too would have been resolved
much more efficiently. In a nutshell, through this case study we
have showcased the potential usefulness of the proposed system, in
terms of productivity improvement of SREs, trust and confidence in
problem-solving and reduced MTTR, and improved SLOs, in turn
leading to increased customer satisfaction.
5 THREATS TO VALIDITY
Sampling Bias - Although we have made a best effort to prepare
three different sub-sets of Application Server datasets of varying
sizes so that the trained ML algorithm is not biased. There may be
a possibility that one may get different results if the ML algorithm
is changed or a dataset from a different domain is used.
Subjectivity of Human Evaluation - Typically, there is a sub-
jectivity in human labeling, which is also present in our datasets.
We observed that some of the category labels that our algorithm
predicted matched the ground truth, however, SEs evaluation indi-
cated that the ground truth labels were incorrect.
1387ESEC/FSE ‚Äô22, November 14‚Äì18, 2022, Singapore, Singapore Harshit Kumar, Ruchi Mahindru, and Debanjana Kar
Figure 6: User Interface for Metadata-based Resolution Rec-
ommendation in AIOps
Constrained Query Formulation - While formulating a query
metadata attributes are used. It may be the case that out of nmeta-
data attributes if one could use mmetadata attributes, where m
is a subset of n, then it may return more results, and one of them
may be the relevant one. That is, constraining a metadata-based
query based on number of attributes could have an effect on the
final quality of results, and one needs to strike a balance between
choosing the metadata attributes for query formulation.
6 RELATED WORK
An application or a service deployed on the cloud is as much vul-
nerable to outages as any other service deployed on-premise. When
an outage happens, leading to alerts and anomalies, an SRE comes
into action, whose role is to ensure that the services run uninter-
rupted, i.e. if they fail, they return to normal execution as quickly as
possible without impacting any client business[ 4]. AIOps enables
SREs to respond more quickly and proactively to slowdowns and
outages, with a lot less effort and toil[ 11]. Incident remediation
in AIOps includes finding similar incidents for a given event (log
anomaly or alert or metric anomaly). The most widely used ap-
proach for incident remediation is based on indexing the textual
description of problem statements from historical tickets and using
that for matching a run-time incident description. This is essentially
a text-based retrieval[ 30,31,35]. There are several challenges to
this approach. First, in traditional text retrieval, the queries input
by a user consists of a few keywords[ 34]. Whereas, in Incident
Remediation, the query formulated by an SRE is descriptive[ 23];
this is because the SRE has to define the symptoms of the issue
being observed so it can match with the descriptions of historical
incidents. The second problem stems from how the descriptions
were penned down by the SREs. After an incident is resolved and ifit is a customer-impacting incident, each SRE would analyze the
issue and document it for future reference. However, it has been
observed that the quality of those documents is subpar[ 17,24], that
is, these descriptions are at times incomplete or are unable to cap-
ture the essence of the underlying issue. LiDAR (Linked Incident
identification with DAta-driven Representation)[ 8], a deep learning-
based approach for incident remediation incorporate the textual
description of incidents and structural information extracted from
historically linked incidents to identify possible links among a large
number of incidents. Routing of incidents to SREs is also based on
finding similar incidents[ 7], they also investigated the applicability
of traditional bug triage techniques to incident triage, which aims
to provide useful insights for future study. Another very closely
related problem is incident identification and routing[ 21] which
involves automatic incident detection for cloud systems. The pro-
posed system in this paper does not use historical incidents alone,
it uses both historical incidents and resolution documents for in-
dexing. We propose a novel way of combining different sources of
data, that are otherwise in silos and using them for metadata-based
retrieval of resolution documents.
Retrieving information can be based on full-text or other content-
based indexing or searching for the metadata that describes data,
the latter is known as metadata-based retrieval. Metadata for infor-
mation retrieval has been widely used for both text search[ 6] and
image search[ 14]. Metadata-based retrieval is a natural choice for
image search[ 3,12], because image attributes are easily accessible
that can be modeled as metadata attributes. For textual documents
and queries, it is extremely challenging to extract metadata from
both, this is because textual documents are large and queries are two
to three keywords. To the best of our knowledge, metadata-based
retrieval has not been explored for resolution retrieval in incident
management for AIOps. It appears that the log anomalies have a
natural overlap with support documents and historical incident
tickets. This allows creation of a Metadata-based Augmented KB
(refer Figure 2 and Section 2) index from support documents and
incident tickets. Therefore, at run time, extracting and predicting
metadata attributes from the incoming anomalous LogLine for au-
tomatic query formulation allows searching of the metadata-based
index to return resolution documents with high accuracy.
7 CONCLUSION
This work demonstrates the importance and usefulness of bringing
multiple sources of data together for building a metadata-based in-
dex that can be used for retrieving highly relevant and targeted res-
olution documents for incident remediation with automatic query
formulation from detected log anomalies in an AIOps cloud setup.
The proposed approach, based on metadata based retrieval, utilizes
various contextual metadata to enrich the problematic event (e.g.
anomalous log line) in question for targeted and precise resolution
retrieval in AIOps. On a large dataset of 5k log instances, we show
the usefulness of our approach for both metadata prediction and
resolution retrieval. We are confident that the observations and
recommendations shared are insightful for both researchers and
practitioners in building an effective, production-ready incident
remediation system. These insights can be further applied to other
components in the AIOps pipeline.
1388Metadata-Based Retrieval for Resolution Recommendation in AIOps ESEC/FSE ‚Äô22, November 14‚Äì18, 2022, Singapore, Singapore
REFERENCES
[1]Pooja Aggarwal, Ajay Gupta, Prateeti Mohapatra, Seema Nagar, Atri Mandal,
Qing Wang, and Amit Paradkar. 2020. Localization of Operational Faults in Cloud
Applications by Mining Causal Dependencies in Logs using Golden Signals.
InInternational Conference on Service-Oriented Computing . Springer, 137‚Äì149.
https://doi.org/10.1007/978-3-030-76352-7_17
[2]Pooja Aggarwal, Seema Nagar, Ajay Gupta, Larisa Shwartz, Prateeti Mohapatra,
Qing Wang, Amit Paradkar, and Atri Mandal. 2021. Causal Modeling based
Fault Localization in Cloud Systems using Golden Signals. In 2021 IEEE 14th
International Conference on Cloud Computing (CLOUD) . IEEE, 124‚Äì135. https:
//doi.org/10.1109/CLOUD53861.2021.00026
[3]Ceyhun Burak Akg√ºl, Daniel L Rubin, Sandy Napel, Christopher F Beaulieu, Hayit
Greenspan, and Burak Acar. 2011. Content-based image retrieval in radiology:
current status and future directions. Journal of digital imaging 24, 2 (2011),
208‚Äì222. https://doi.org/10.1007/s10278-010-9290-9
[4]Amar Prakash Azad, Supriyo Ghosh, Ajay Gupta, Harshit Kumar, Prateeti Moha-
patra, Lena Eckstein, Leonard Posner, and Robert Kern. 2022. Picking Pearl From
Seabed: Extracting Artefacts from Noisy Issue Triaging Collaborative Conversa-
tions for Hybrid Cloud Services. In Proceedings of the AAAI Conference on Artificial
Intelligence , Vol. 36. 12440‚Äì12446. https://doi.org/10.1609/aaai.v36i11.21510
[5] Erik Bernhardsson. 2018. Annoy: Approximate Nearest Neighbors in C++/Python .
https://pypi.org/project/annoy/ Python package version 1.13.0.
[6]Shraddha S Bhanuse, Shailesh D Kamble, and Sandeep M Kakde. 2016. Text
mining using metadata for generation of side information. Procedia Computer
Science 78 (2016), 807‚Äì814. https://doi.org/10.1016/j.procs.2016.02.061
[7]Junjie Chen, Xiaoting He, Qingwei Lin, Yong Xu, Hongyu Zhang, Dan Hao, Feng
Gao, Zhangwei Xu, Yingnong Dang, and Dongmei Zhang. 2019. An empirical
investigation of incident triage for online service systems. In ICSE-SEIP 2019 .
IEEE, 111‚Äì120. https://doi.org/10.1109/ICSE-SEIP.2019.00020
[8]Yujun Chen, Xian Yang, Hang Dong, Xiaoting He, Hongyu Zhang, Qingwei Lin,
Junjie Chen, Pu Zhao, Yu Kang, Feng Gao, et al .2020. Identifying linked incidents
in large-scale online service systems. In Proceedings of the 28th ACM Joint Meeting
on European Software Engineering Conference and Symposium on the Foundations
of Software Engineering . 304‚Äì314. https://doi.org/10.1145/3368089.3409768
[9]Eli Collins. 2014. Big data in the public cloud. IEEE Cloud Computing 1, 2 (2014),
13‚Äì15. https://doi.org/10.1109/MCC.2014.29
[10] Thomas M. Cover and Joy A. Thomas. 2006. Elements of Information Theory
(Wiley Series in Telecommunications and Signal Processing) . Wiley-Interscience.
https://doi.org/10.1002/047174882X
[11] Yingnong Dang, Qingwei Lin, and Peng Huang. 2019. AIOps: real-world chal-
lenges and research innovations. In 2019 IEEE/ACM 41st International Conference
on Software Engineering: Companion Proceedings (ICSE-Companion) . IEEE, 4‚Äì5.
https://doi.org/10.1109/ICSE-Companion.2019.00023
[12] Roberto Garcia and Oscar Celma. 2005. Semantic Integration and Retrieval
of Multimedia Metadata. In SemAnnot@ ISWC . http://ceur-ws.org/Vol-185/
semAnnot05-07.pdf
[13] Daniel Gildea and Daniel Jurafsky. 2002. Automatic labeling of semantic
roles. Computational linguistics 28, 3 (2002), 245‚Äì288. https://doi.org/10.1162/
089120102760275983
[14] David Haynes. 2004. Metadata for information management and retrieval . Vol. 1.
Facet publishing. https://doi.org/10.29085/9781783302161
[15] Pinjia He, Jieming Zhu, Zibin Zheng, and Michael R Lyu. 2017. Drain: An online
log parsing approach with fixed depth tree. In 2017 IEEE International Conference
on Web Services (ICWS) . IEEE, 33‚Äì40. https://doi.org/10.1109/ICWS.2017.13
[16] Jinho Hwang, Larisa Shwartz, Qing Wang, Raghav Batta, Harshit Kumar, and
Michael Nidd. 2021. Fixme: Enhance software reliability with hybrid approaches
in cloud. In 2021 IEEE/ACM 43rd International Conference on Software Engineering:
Software Engineering in Practice (ICSE-SEIP) . IEEE, 228‚Äì237. https://doi.org/10.
1109/ICSE-SEIP52600.2021.00032
[17] Jiajun Jiang, Weihai Lu, Junjie Chen, Qingwei Lin, Pu Zhao, Yu Kang, Hongyu
Zhang, Yingfei Xiong, Feng Gao, Zhangwei Xu, et al .2020. How to mitigate
the incident? an effective troubleshooting guide recommendation technique for
online service systems. In Proceedings of the 28th ACM Joint Meeting on European
Software Engineering Conference and Symposium on the Foundations of Software
Engineering . 1410‚Äì1420. https://doi.org/10.1145/3368089.3417054[18] Subhendu Khatuya, Niloy Ganguly, Jayanta Basak, Madhumita Bharde, and Bivas
Mitra. 2018. Adele: Anomaly detection from event log empiricism. In IEEE
INFOCOM 2018-IEEE Conference on Computer Communications . IEEE, 2114‚Äì2122.
https://doi.org/10.1109/INFOCOM.2018.8486257
[19] Mei Kobayashi and Koichi Takeda. 2000. Information retrieval on the web. ACM
Computing Surveys (CSUR) 32, 2 (2000), 144‚Äì173. https://doi.org/10.1145/358923.
358934
[20] Jay Kreps, Neha Narkhede, Jun Rao, et al .2011. Kafka: A distributed messaging
system for log processing. In Proceedings of the NetDB , Vol. 11. 1‚Äì7. http://notes.
stephenholiday.com/Kafka.pdf
[21] Liqun Li, Xu Zhang, Xin Zhao, Hongyu Zhang, Yu Kang, Pu Zhao, Bo Qiao, Shilin
He, Pochian Lee, Jeffrey Sun, et al .2021. Fighting the Fog of War: Automated
Incident Detection for Cloud Systems. In 2021 USENIX Annual Technical Confer-
ence (USENIX ATC 21) . 131‚Äì146. https://www.usenix.org/system/files/atc21-li-
liqun.pdf
[22] Yi Liu, Shujie Han, Cheng He, Jiongzhou Liu, Fan Xu, Tao Huang, and Patrick
P. C. Lee. 2020. An Introduction to PAKDD CUP 2020 Dataset. In Large-Scale
Disk Failure Prediction , Cheng He, Mengling Feng, Patrick P. C. Lee, Pinghui
Wang, Shujie Han, and Yi Liu (Eds.). Springer Singapore, Singapore, 1‚Äì11. https:
//doi.org/10.1007/978-981-15-7749-9_1
[23] Jian-Guang Lou, Qingwei Lin, Rui Ding, Qiang Fu, Dongmei Zhang, and Tao
Xie. 2013. Software analytics for incident management of online services: An
experience report. In 2013 28th IEEE/ACM International Conference on Automated
Software Engineering (ASE) . IEEE, 475‚Äì485. https://doi.org/10.1109/ASE.2013.
6693105
[24] Jian-Guang Lou, Qingwei Lin, Rui Ding, Qiang Fu, Dongmei Zhang, and Tao Xie.
2017. Experience report on applying software analytics in incident management
of online service. Automated Software Engineering 24, 4 (2017), 905‚Äì941. https:
//doi.org/10.1007/s10515-017-0218-1
[25] Theo Lynn, Pierangelo Rosati, and Grace Fox. 2020. Measuring the Business Value
of Cloud Computing: Emerging Paradigms and Future Directions for Research.
Measuring the Business Value of Cloud Computing 107 (2020). https://doi.org/10.
1007/978-3-030-43198-3_7
[26] Ruchi Mahindru, Harshit Kumar, and Sahil Bansal. 2021. Log Anomaly to Reso-
lution: AI Based Proactive Incident Remediation. In 2021 36th IEEE/ACM Inter-
national Conference on Automated Software Engineering (ASE) . IEEE, 1353‚Äì1357.
https://doi.org/10.1109/ASE51524.2021.9678815
[27] Matthew Malensek, Sangmi Pallickara, and Shrideep Pallickara. 2016. Au-
tonomous cloud federation for high-throughput queries over voluminous datasets.
IEEE Cloud Computing 3, 3 (2016), 40‚Äì49. https://doi.org/10.1109/MCC.2016.65
[28] Jeffrey Pennington, Richard Socher, and Christopher D Manning. 2014. Glove:
Global vectors for word representation. In Proceedings of the 2014 conference on
empirical methods in natural language processing (EMNLP) . 1532‚Äì1543. https:
//doi.org/10.3115/v1/D14-1162
[29] Alfr√©d R√©nyi. 1961. On measures of entropy and information. In Proceedings of the
Fourth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1:
Contributions to the Theory of Statistics , Vol. 4. University of California Press, 547‚Äì
562. https://projecteuclid.org/ebook/Download?urlid=bsmsp%2F1200512181&
isFullBook=False
[30] Gerard Salton. 1991. Developments in automatic text retrieval. science 253, 5023
(1991), 974‚Äì980. https://pubmed.ncbi.nlm.nih.gov/17775340/
[31] Gerard Salton and Christopher Buckley. 1988. Term-weighting approaches in
automatic text retrieval. Information processing & management 24, 5 (1988),
513‚Äì523. https://doi.org/10.1016/0306-4573(88)90021-0
[32] Gerard Salton, Anita Wong, and Chung-Shu Yang. 1975. A vector space model
for automatic indexing. Commun. ACM 18, 11 (1975), 613‚Äì620. https://doi.org/
10.1145/361219.361220
[33] Barry Smith. 2008. Ontology (science). Nature Precedings (2008), 1‚Äì1. https:
//doi.org/10.1038/npre.2008.2027.1
[34] Jaime Teevan, Eytan Adar, Rosie Jones, and Michael AS Potts. 2007. Information
re-retrieval: Repeat queries in Yahoo‚Äôs logs. In Proceedings of the 30th annual
international ACM SIGIR conference on Research and development in information
retrieval . 151‚Äì158. https://doi.org/10.1145/1277741.1277770
[35] Howard R Turtle and W Bruce Croft. 1992. A comparison of text retrieval models.
The computer journal 35, 3 (1992), 279‚Äì290. https://doi.org/10.1093/comjnl/35.3.
279
1389