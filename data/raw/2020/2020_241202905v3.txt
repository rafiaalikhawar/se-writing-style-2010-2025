Constrained LTL Specification Learning from
Examples
Changjian Zhang
Carnegie Mellon University
Pittsburgh, PA USA
changjiz@andrew.cmu.eduParv Kapoor
Carnegie Mellon University
Pittsburgh, PA USA
parvk@andrew.cmu.eduIan Dardik
Carnegie Mellon University
Pittsburgh, PA USA
idardik@andrew.cmu.eduLeyi Cui
Columbia University
New York, NY USA
lc3542@columbia.edu
Rˆomulo Meira-G ´oes
The Pennsylvania State University
State College, PA USA
romulo@psu.eduDavid Garlan
Carnegie Mellon University
Pittsburgh, PA USA
dg4d@andrew.cmu.eduEunsuk Kang
Carnegie Mellon University
Pittsburgh, PA USA
eunsukk@andrew.cmu.edu
Abstract —Temporal logic specifications play an important role
in a wide range of software analysis tasks, such as model check-
ing, automated synthesis, program comprehension, and runtime
monitoring. Given a set of positive and negative examples,
specified as traces, LTL learning is the problem of synthesizing a
specification, in linear temporal logic (LTL) , that evaluates to true
over the positive traces and false over the negative ones. In this
paper, we propose a new type of LTL learning problem called
constrained LTL learning , where the user, in addition to positive
and negative examples, is given an option to specify one or more
constraints over the properties of the LTL formula to be learned.
We demonstrate that the ability to specify these additional con-
straints significantly increases the range of applications for LTL
learning, and also allows efficient generation of LTL formulas
that satisfy certain desirable properties (such as minimality). We
propose an approach for solving the constrained LTL learning
problem through an encoding in first-order relational logic and
reduction to an instance of the maximal satisfiability (MaxSAT)
problem. An experimental evaluation demonstrates that ATLAS,
an implementation of our proposed approach, is able to solve
new types of learning problems while performing better than or
competitively with the state-of-the-art tools in LTL learning.
I. I NTRODUCTION
Temporal logic (TL) specifications are a class of specifica-
tion notations that are used to specify how a system behaves
over time. TL specifications, such as linear temporal logic
(LTL) [1], have been used in a wide range of software analysis
tasks, such as model checking [2], reactive synthesis [3], pro-
gram understanding [4], and runtime monitoring [5]. Despite
its utility, formalizing and specifying desired system properties
in temporal logic is a notoriously challenging and error-prone
process [6]–[8].
One active area of research that has the potential to over-
come this challenge is specification learning , where the goal
is to automatically infer formal specifications from example
traces [4], [6], [8]–[10]. These traces may be derived from sys-
tem executions or manually created by developers as examples.
The extracted specification could then be used by developers to
comprehend and debug the behavior of a system, document itsexpected properties, or perform verification through methods
such as model checking and theorem proving [6], [11], [12].
In this work, we specifically focus on the problem of LTL
learning from examples ; that is, given a set of positive and
negative traces, generate an LTL specification that evaluates to
true over the positive traces and false over the negative ones.
Several prior works have investigated this problem [4], [8],
[9], [13]. One of the challenges in these existing approaches
is providing control over the generated LTL formula. Typically,
a given set of (positive and negative) traces are only a partial
specification of the underlying system behavior to be captured
by the resulting LTL specification. A formula that is learned
solely from such traces may fail to precisely capture the system
behavior and need to be further refined.
For example, consider a mobile navigation robot that moves
around three regions, A,B, and R(the last one being a
dangerous area that the robot should avoid). Suppose that
the robot developer wishes to use formal specifications to
precisely document the robot behavior and to leverage them
for verification. An LTL learning tool can be used to extract
such specifications from traces representing sample behaviors
of the robot. Specifically, consider the following two sample
traces collected from an operation log: ⟨A,B,B, . . .⟩(positive;
the robot visiting Aand then B) and⟨B,R,R, . . .⟩(negative;
the robot enters Rand never leaves, indicating a potentially
unsafe behavior). A specification that may be learned from
these traces is: A∧X(GB), i.e., the robot should visit A
initially and then stay in B. Technically, this formula is a
valid solution to the learning problem. However, it also fails
to capture the developer’s intent, i.e., to prohibit the unsafe
scenario. Instead, a more ideal specification would constrain
the robot from being stuck at R, while not requiring it to start
in region A.
Devising an additional set of traces to cover a more diverse
set of system behaviors may be one way to overcome this
issue. However, in general, determining a set of traces that
precisely capture the desired characteristics of a specification
is a challenging task. For example, one may wish to extract a
1arXiv:2412.02905v3  [cs.SE]  30 Dec 2024specification that fits into a certain pattern or a class (e.g., a
safety or liveness property), minimize the number of times that
a certain proposition appears, or learn a formula that is close
to another specification (e.g., in the context of specification
repair). LTL learning approaches that rely solely on examples
lack the expressive power to allow fine-grained control over
the characteristics of the formula to be inferred.
To this end, we propose the constrained LTL learning
problem as a generalization over the original LTL learning
problem. The key idea is to allow the user to specify, besides
the set of positive and negative traces, additional constraints
that must hold over the syntactic structure of the generated
LTL formula. These constraints, based on first-order logic
(FOL), can be used to express a wide range of properties
about LTL expressions, thus giving the user more control
over the solution space being explored. For example, one may
specify a constraint stating that “the resulting LTL formula
must mention region R” or “the formula should follow the
pattern of Gϕ”. In addition, the user can specify optimization
objectives to maximize or minimize the syntactic structure in
certain ways, e.g., minimize the formula size or maximize
the similarity against another LTL formula. Together, these
constraints and objectives can help bias generated solutions
towards more desirable ones.
We present a constrained LTL learning tool, named ATLAS,
that solves this problem by encoding it into AlloyMax[14],
[15], an extension of Alloy, a specification language based on
first-order relational logic. A problem in AlloyMaxis eventually
reduced to an instance of the maximal satisfiability (MaxSAT)
problem [16]. We show that constrained LTL learning is a
simple but powerful generalization of the original LTL learning
problem, enabling a new set of use cases beyond those that
were possible before in the existing state-of-the-art tools. In
addition to its applicability, our experimental evaluation shows
that our approach to solving constrained learning problems
performs significantly better than the existing methods over a
set of benchmark problems, and that it performs competitively
over unconstrained problems.
The primary target users of ATLAS are expert speci-
fiers and tool builders . For experts in formal logic who
currently use LTL learning tools, ATLAS provides them
with a more powerful way to control the learning process
to extract specifications that precisely capture their intent.
Moreover, the generality of FOL means that ATLAS has the
potential to serve as an underlying, general-purpose engine for
other specification-based tools that rely on LTL learning (e.g.,
specification weakening or repair, as described in Section VII).
In addition, a tool built upon ATLAS could automatically
convert domain-specific constraints or requirements in natural
language to FOL, enabling non-expert users to also benefit
from LTL learning.
The contributions of this paper are as follows:
•The formulation of the constrained LTL learning prob-
lem, a generalized learning problem that allows users to
define FOL constraints and optimization objectives over
the structure of the learned formula (Section IV).
Fig. 1: Overview of a constrained LTL learning problem in ATLAS.
•An encoding of the learning problem in AlloyMax, which
is then solved as a MaxSAT problem (Section V and VI),
and a tool implementing the proposed technique, named
ATLAS.
•A set of case studies from different application domains
(Section VII), and a set of benchmark results demonstrat-
ing the performance of our approach on both constrained
and unconstrained learning problems (Section VIII).
II. M OTIVATING EXAMPLE
In this section, we demonstrate the need for more general
and customizable constraints and objectives for LTL learning,
using a case study from specification mining [6], [11], [12],
[17], [18], a major application of LTL learning.
Consider a system analyst working on analyzing a multi-
processing algorithm, developed by other engineers. The an-
alyst plans to employ formal verification but the algorithm is
designed without a formal specification. This lack of specifi-
cation is common in practice; even in safety-critical domains,
many systems do not have formally defined requirements
until a later testing phase, when the need to support rigorous
verification arises [7]. Although the analyst has a background
in formal logic, without an in-depth understanding of the algo-
rithm, it would be challenging to extract a specification that is
not only consistent with the algorithm but also representative
of its behavior. Specification mining is one approach to over-
come this bottleneck—by generating executions (e.g., from an
operation log), one can use LTL learning to infer specifications
that capture the system behavior. These specifications can
then be used for documentation, regression testing, or formal
verification [6], [7].
1:procedure MULTI PROCESSING ALGO(i)
2: while true do
3: a1i:skip // Non-critical section
4: a2i:flag i←true
5: a3i:await (flag 1−i=false )
6: csi:skip // Critical section
7: a4i:flag i←false
Fig. 2: A multi-processing algorithm under analysis.
2Fig. 3: A positive example trace of the algorithm in Figure 2.
We illustrate this workflow using a sample algorithm shown
in Figure 2; here, iis the identifier (ID) for a process, and only
two concurrent processes are considered (ID = 0 or 1). To
generate execution traces, the implementation is instrumented
with labels on instructions. Let each label in Figure 2 (e.g.,
a2ion line 4) be a proposition that is true right before process
iexecutes that line of code, and becomes false after the line
is executed. For instance, a2ibecomes true right before the
instruction flag i←true is executed and becomes false after
this assignment. Then, each trace is a sequence of pairs of
propositions, where each pair describes the current locations
of the concurrent processes. Figure 3 shows an example of
such traces.
a) Limitations of existing methods: The analyst may use
an LTL learning tool to infer a specification from traces. When
an existing learner such as Flie [9] is applied to the trace in
Figure 3, one possible output formula is a10. This formula
is technically valid, as it is consistent with this particular
execution, but is also arguably not descriptive of the overall
algorithm behavior. Providing more traces may not yield a
different solution, as every possible trace starts with a state
where a10is true.
One approach for learning more meaningful formulas is to
allow the user to constrain the space of candidate formulas to
be explored. For instance, suppose that the analyst wants to
learn a safety invariant of form Gϕ(i.e.,ϕalways holds). One
way to achieve this goal is to use a learner that takes a speci-
fication template as an additional input (such as LTLSketcher
[8]). Although templates are a significant improvement, they
also fall short of providing fine-grained control that may be
desired. For example, without further constraining ϕ(e.g.,
ϕshould not contain temporal operators), a template-based
learner may return GF(a10), which is a valid liveness property
but not a safety invariant as intended by the analyst.
b) Proposed approach: We argue that additional con-
straints and objectives are needed to express the analyst’s
preference on what a meaningful safety invariant looks like.
For example, consider the following requirement:
“Learn an LTL formula that is in form Gϕwhere ϕ
does not contain temporal operators, and maximizes
the use of cs0andcs1inϕ”.
It first defines a constraint that the formula needs to be a
safety invariant. Then, it defines an objective to maximize the
use of certain propositions that the analyst is interested in (i.e.,
the critical sections in the code). As explained in Section IV,
it can be expressed as constraints in FOL, and our approach,
ATLAS, can find formula G(¬(cs0∧cs1)), which captures
amutual exclusion property. Such constraints and objectives
cannot be expressed using the existing learning tools.
As another example, consider the trace shown in Figure 4.
This trace is considered negative, as it depicts an undesirable
Fig. 4: A negative example trace generated from the algorithm.
behavior where the execution is stuck at state (a30, a31)(i.e.,
both processes are waiting for the other to reset the flag). In
this case, the analyst wants to learn a liveness property that
would rule out this behavior, in form of G(ϕ→Fψ). Again,
given this pattern as a template, a tool like LTLSketcher [8]
may return G(a30→Fa10). This is a valid liveness property;
however, it is also rather unintuitive as it requires a process to
enter a30before a10, even though a10occurs before a30in
the algorithm’s procedure.
To further improve this formula, the analyst using ATLAS
can specify a constraint capturing the following requirement:
“ψshould be a label after ϕas they appear in the
algorithm procedure”.
This constraint requires that, for example, if ϕ=a30, then
ψshould be either cs0ora40. Given this constraint as an
input, ATLAS generates formula G(a30→Fcs0), which
is arguably more intuitive than the above one. This formula
corresponds to a deadlock-free property.
c) Summary: The algorithm described in Figure 2 is
derived from the well-known Peterson’s Mutual Exclusion
Algorithm [19], with a deadlock defect introduced for illustra-
tion. The learned formulas in the example might look relatively
simple to specify. However, even for a simple algorithm as this
one, existing learning techniques often fail to return solutions
that precisely capture the system behavior. This limitation
cannot be addressed only by adding more traces, and there
is a need for more expressive constraints and objectives.
To our knowledge, ATLAS is the first LTL learning tool
that is expressive enough to encode each of the constraints in
the example above. It offers users the capability to interactively
and gradually add custom constraints and objectives to extract
valuable specifications from examples. Later in (Section VII),
we demonstrate the expressive power and generality of AT-
LAS through additional use cases beside specification mining,
such as specification repair and invariant weakening.
III. P RELIMINARIES
A. Linear Temporal Logic
Linear Temporal Logic (LTL) [1] is an extension of propo-
sitional logic with temporal operators. Its syntax is as follows:
ϕ:=p| ¬ϕ|ϕ∧ψ|ϕ∨ψ|ϕ→ψ|
Gϕ|Fϕ|Xϕ|ϕUψ
where p∈AP is an atomic proposition of a finite set of
propositions AP. An LTL formula is interpreted over an
infinite trace σ∈(2AP)ω. Specifically, the temporal operators
are interpreted as:
•Gϕ(Globally): ϕholds in all future states.
•Fϕ(Finally): ϕholds eventually in some future state.
•Xϕ(Next): ϕholds in the next state.
3•ϕUψ(Until): ϕalways holds until ψbecomes true in
some future state.
B. LTL Learning from Examples
In a typical setting, LTL learning defines the problem of
inferring an LTL formula from positive and negative exam-
ple traces [9]: Given a set of atomic propositions AP, let
P, N⊂(2AP)ωbe two (potentially empty) disjoint sets of
infinite traces, where Parepositive examples andNare
negative examples . We call S= (P, N)asample . Then, the
task of LTL learning is to find a formula ϕsuch that ∀σ∈P:
the trace σsatisfies formula ϕ,σ|=ϕ, and∀¯σ∈N:the trace
σdoes not satisfy formula ϕ,¯σ̸|=ϕ. There exists a trivial
solution to separate PandNin the formW
a∈PV
b∈Nφa,b,
where φa,bseparates each example pair (a, b). However, this
solution is obviously over-fitting and less helpful in practice.
Thus, we are often interested in finding an LTL formula of
minimal size.
C. Alloy and AlloyMax
Alloy [14] is a modeling language based on first-order
relational logic with transitive closure. With its SAT-based
engine, the Alloy Analyzer has been applied to a wide range
of problems, including protocol verification [20], [21], test
generation [22], and bug finding [23], [24].
AlloyMax[15] is an extension of Alloy with a capability
to express and analyze problems with optimal solutions. It
introduces a small addition of language constructs to spec-
ify problems with optimality as an objective and transla-
tion from an AlloyMaxproblem to a maximum satisfiability
(MaxSAT) problem [16], which can be solved by a MaxSAT
solver. Specifically, AlloyMaxcan be used to: (1) maximize or
minimize relations , e.g., maximizing allowed packets while
adhering to network security policies [25]; (2) define soft
constraints , e.g., adding “participants’ time preferences” in
meeting scheduling; and (3) define priorities for various objec-
tives, e.g., prioritizing morning meeting times over afternoon
ones in meeting scheduling.
Interested readers are encouraged to refer to Alloy [14] and
AlloyMax[15] for more details about their capabilities.
IV. P ROBLEM FORMULATION
In this work, we propose a new type of LTL learning
problem called the constrained LTL learning problem .
A. Constrained LTL Learning
Problem 1: A constrained LTL learning problem is defined
as a tuple ⟨AP,S,Φ,Ψ⟩where
•AP is afinite set of atomic propositions,
•S= (P, N)is a sample,
•Φis a first-order predicate that constraints the syntactic
structure of the learned formula, and
•Ψis an optimization objective over the syntactic structure
of the formula.
The goal of the problem is to find an LTL formula ϕsuch
that∀σ∈P:σ|=ϕ,∀¯σ∈N: ¯σ̸|=ϕ,Φ 
syntax (ϕ)
holds,Φ ::= φ|funcDef
funcDef ::= func identifier (var) =expr
φ::= elementary | ¬φ|φ∧φ|φ∨φ|φ→φ|φ↔φ|
∀varDecl :φ| ∃varDecl :φ
elementary ::= expr∈expr|expr⊆expr|expr=expr|
|expr|compOp number
expr::= const|var|comprehension |expr∪expr|
expr∩expr|expr\expr|expr×expr|
expr .expr|∧expr| ∗expr| ∼ expr|func
comprehension ::={var|φ}
func::= identifier (expr)
varDecl ::= var∈expr
compOp ::= = |<|>| ≤ | ≥
const ::= identifier | ∅
var::= identifier |(identifier [,identifier ]∗)
Fig. 5: Abstract syntax of syntactic constraint Φ.
andsyntax (ϕ)optimizes Ψ, where syntax (ϕ)represents the
syntactic structure of ϕ.
For the syntactic constraint Φ, a user could specify it to
learn an invariant Gϕwhere ϕis a propositional formula, a
liveness property G(ϕ→Fψ), or a GR(1) formula, which is
widely used in reactive synthesis [26]. Many of these cannot
be expressed by existing tools. Moreover, for the objective Ψ,
a user could specify it to optimize the syntactic structure in
certain way, e.g., minimizing the size of the formula.
B. Syntactic Constraint Φ
We formally define the constructs for the syntactic constraint
Φ. For an LTL formula ϕ,syntax (ϕ) =⟨L,R, root⟩repre-
sents its syntax tree where L,R ⊆ N×Nare the left child
and right child relations, respectively; Nis the set of nodes
in the syntax tree, and root is the root node. In particular,
N=S
op∈NNopwhere N={G,F,U,X,∧,∨,→,¬, AP}
andNopis the set of nodes for a particular operator type or
atomic propositions.
Then, Φis a FOL constraint over syntax (ϕ). Figure 5 shows
its abstract syntax, which is an extension to FOL and set theory
with the following operations for improved expressiveness:
•s.r={b|a∈s∧(a, b)∈r}, join of set s⊆Nand
relation r⊆N×N. Also, for simplicity, let a.r={a}.r
where a∈N.
•r1.r2={(a, c)|(a, b)∈r1∧(b, c)∈r2}, join of relations.
•∧(r) =r∪r.r∪r.r.r∪. . ., transitive closure of a relation
r⊆N×N.
•∗(r) =∧(r)∪ {(a, a)|a∈N}, reflexive transitive
closure of a relation r⊆N×N.
•∼(r) ={(b, a)|(a, b)∈r}, inverse of a relation.
Moreover, a user can define functions to reuse common
expressions. By default, we introduce the following functions:
4•l(n) =n.L, left child of a node n.
•r(n) =n.R, right child of a node n.
•desc(n) =n.∧(L ∪ R ), all descendent nodes of a node
nby using transitive closure.
•subNodes (n) =n.∗(L ∪ R ), all descendent nodes of a
node nincluding itself.
Example 1 : To learn a liveness property G(ϕ→Fψ)where
ϕandψare propositional formulas, the user can define the
following constraints:
nG∈NG∧n→∈N→∧nF∈NF (1)
root=nG∧l(root) =n→∧r(n→) =nF (2)
subNodes 
l(n→)
∩N{G,F,U,X}=∅ (3)
desc(nF)∩N{G,F,U,X}=∅ (4)
where N{G,F,U,X}=S
op∈{G,F,U,X}Nopand lines are
connected by ∧. Specifically, line (1) declares instances of
nodes, line (2) defines the structure G(ϕ→Fψ), and lines (3)
and (4) define ϕandψshould not contain temporal operators.
C. Optimization Objective Ψ
The syntax for optimization objective Ψis an extension to
the syntax defined in Figure 5:
Ψ := min[k](expr)|max[k](expr)|expr≈[k]∅ |[φ][k]
Specifically, we introduce the following operators:
•min(s), where sis a non-empty set and the number of
elements in sshould be minimized.
•max(s), where sis a non-empty set and the number of
elements in sshould be maximized.
•s≈ ∅, minimizes set sand ideally makes it empty.
•[φ], where φis a constraint and is optional to be true.
An optimization operator can be assigned a superscript k∈
N+(e.g., mink(s)) indicating its priority. An objective with
a higher priority should be optimized before all the other
objectives with lower priorities. When the superscript kis
omitted, the constraint has the lowest priority k= 1.
Example 2: Since there exists an over-fitting solution for any
learning problem, we often prefer to learn a formula that is
minimal in its size. This can be expressed as:
L ∪ R ≈ ∅ (5)
It minimizes the size of the child relations (edges in a syntax
tree), which, in turn, minimizes the size of the formula.
Example 3: In addition, when a user wants to learn a
formula that maximizes the use of a set of critical propositions
critical ⊆AP, they can define:
max2 
subNodes (root)∩Ncritical
(6)
The use of max2specifies that this goal should be optimized
with priority 2, which happens before minimizing the total
size of the solution as shown in the previous example.V. T ECHNICAL APPROACH
We reduce a constrained LTL learning problem to an
instance of relational model finding. In particular, we use
AlloyMax, which allows us to define and solve problems in
first-order relational logic with the support for all the operators
for syntactic constraint Φand optimization objective Ψ.
The idea of our encoding is inspired by the SAT encoding
proposed by Neider and Gavran [9], which is inspired by
bounded model checking [27]. The encoding assumes that
all traces in the sample set are ultimately periodic, known
aslasso traces . Such a trace can be represented as uvωwhere
u∈(2AP)∗andv∈(2AP)+. The observation is that, given a
finite set of AP, the set of states visited by uvω(starting from
any time point t) is finite and can be determined based only on
the finite prefix uv. Therefore, this enables us to check LTL
temporal operators w.r.t. infinite traces [9]. In addition, the
user provides the maximum number of sub-formulas to bound
the search space. Furthermore, we employ several heuristics,
described in later sections, to make our AlloyMaxencoding
more succinct and efficient.
The encoding can be divided into six parts: LTL syntax en-
coding, LTL semantics encoding, problem-specific encoding,
learning objective encoding, custom syntactic constraints, and
optimization objectives.
A. Syntax Encoding
We model the syntax of an LTL formula as a directed acyclic
graph (DAG). Essentially, a syntax DAG is a syntax tree with
shared common sub-formulas. This helps reduce the search
space. The following code snippet shows how this syntax
graph can be modeled in AlloyMax:
1// A "sig" (signature) defines a type of atoms.
2abstract sig DAGNode {
3 // fields of a signature become relations
4 l:set DAGNode, r: set DAGNode
5}
6// "fact" defines a block of constraints.
7fact {all n: DAGNode |nnot in n.ˆ(l + r) }
8// "extends" defines sub-types of a signature.
9sig And, Or, Imply, Until extends DAGNode {} {
10 // "one" means exactly one element.
11 one land one r
12}
13 sig Neg, F, G, X extends DAGNode {} {
14 // "no" means empty set.
15 one land no r
16}
17 abstract sig Literal extends DAGNode {} {
18 noland no r
19}
20 one sig LearnedLTL {Root: DAGNode }
21 fun root: one DAGNode {LearnedLTL.Root }
Line 2 defines the parent signature for all nodes in a DAG,
and line 4 defines the left/right child relations, landr. Line 7
constrains each node to have no paths to itself, i.e., the graph
should be acyclic. Specifically, this is achieved by computing
all the descendent nodes of nthrough transitive closure∧(l+r)
as defined in Section IV-B, where +is the union operator.
Lines 9-19 define the sub-types of nodes including operators
and atomic propositions. Specifically, we add constraints for:
5binary operators to have exactly one left and one right child
(lines 9-12), unary operators to have only left child (line 13-
16), and atomic propositions to have no children (line 17-
19). Finally, lines 20-21 define a helper function for accessing
the root node. Therefore, relation landr, and function root
construct the syntax of the learned formula, syntax (ϕ) =
⟨L,R, root⟩.
B. Semantics Encoding
This section describes the encoding for the semantics of
LTL. We show only the definitions for ∨,X,F,andU.
Encodings for the other operators can be defined in a similar
manner.
1abstract sig SeqIdx {}
2abstract sig Trace {
3 // relation, Trace x SeqIdx x SeqIdx
4 lasso: SeqIdx -> SeqIdx,
5 // relation, Trace x DAGNode x SeqIdx
6 val: DAGNode -> SeqIdx
7}
8fun seqIndices [t: Trace ]:set SeqIdx {..}
9fun futureIdx [t:Trace,i:SeqIdx ]:set SeqIdx {..}
Line 1 defines signature SeqIdx for time points. Lines 2-7
define the signature for lasso traces. Specifically, for any trace
t=uvω, it has a lasso relation (t, i, i′)where i=|uv|−1is
the ending index of its prefix uvandi′=|u|is the starting
index of loop v. It also has a valrelation, where any (t, n, i )∈
valstands for: the trace tsatisfies the sub-formula, represented
by the sub-DAG from node n, starting from time i.
Lines 8-9 define two helper functions seqIndices and
futureIdx . Their functionalities are:
•seqIndices (t)returns all the time points of a trace t, as
the example traces can be in different lengths;
•futureIdx (t, i)returns all the future time points of a trace
tstarting from time i(including i).
They are computed using the lasso relation and a relation
next⊆SeqIdx ×SeqIdx that defines a total order over the
time points, connecting a time iwith its next time point i+1.
For instance, Figure 6 shows an example lasso trace
uvω. The solid black arrows represent relation next =
{(0,1),(1,2)}, and the dashed arrow represents relation
lasso ={(2,1)}of this trace. Based on the next relation,
for time i= 0 andi= 1, the next time points are i′= 1 and
i′= 2, respectively. For time i= 2, the state value at i′= 3
equals to the value at i′= 1 because of the repeating v’s,
andi′= 1 can be retrieved by the lasso relation. Therefore,
{(2,3),(3,4), . . .}are unnecessary tuples (shown in Figure 6),
and we only need to model the finite prefix uvof a lasso trace.
Fig. 6: An example lasso trace with two atomic propositions.For this trace, function seqIndices (t) ={0,1,2}, function
futureIdx (t,0) = {0,1,2}, and function futureIdx (t,2) =
{2,1}. A heuristic is applied that uses transitive closures to
compute them, e.g., i.∗(next+t.lasso )returns all future time
points of iwithout comparing the order of time points.
1)∨-operator: For any node n∈N∨and time ibeing
in the time range of uv(computed by seqIndices ), the tuple
(t, n, i )is invalif and only if, at time i, its left sub-formula
n.lor right sub-formula n.ris in val, i.e., one of the sub-
formulas holds.
1all t: Trace, n: Or, i: seqIndices [t] |
2 n->i int.val iff
3 (n.l->i int.val orn.r->i int.val)
2)X-operator: For any node n∈NXand time i,(t, n, i )∈
valif and only if (t, n.l, i′)∈val, where i′is the next time
point of icomputed by expression i.(next +t.lasso ). For
example in Figure 6, (next+t.lasso ) ={(0,1),(1,2),(2,1)}.
Thus, i.(next +t.lasso )returns the next time point of time i,
considering the loop vint=uvω.
1all t: Trace, n: X, i: seqIndices [t] |
2n->i int.val iff n.l->i.(next+t.lasso) int.val
3)F-operator: For any node n∈NFand time i,(t, n, i )∈
valif and only if ∃i′∈futureIdx (t, i) : (t, n.l, i′)∈val,
where operator some stands for ∃andfutureIdx computes all
the future time points. For example, for the trace in Figure
6, when i= 0,futureIdx (t, i) ={0,1,2}. It means that from
i= 0, all the possible state values can be represented by states
ati′= 0,1,2. Thus, we assert that there exists a time point
in these future indices where pholds.
1all t: Trace, n: F, i: seqIndices [t] |
2 n->i int.val iff
3 some i’: futureIdx [t, i ] | n.l->i’ int.val
4)U-operator: Finally, the following code defines the qUp
operator. Specifically, we leverage the heuristic from the SAT
encoding of the U-operator used in bounded model checking
[27]. It unfolds Uby using the X-operator in the sense that
qUp=p∨(q∧X(qUp)), as defined in lines 4-5. In addition,
on line 3, we constrain that sub-formula p(i.e., n.r) will
eventually be true from time i; otherwise, a trace where p
never becomes true would also satisfy this encoding.
1all t: Trace, n: Until, i: seqIndices [t] |
2 n->i int.val iff {
3 some i’: futureIdx [t, i ] | n.r->i’ int.val
4 n.r->i int.val or(n.l->i int.val and
5 n->i.(next+t.lasso) int.val)
6 }
C. Problem-Specific Encoding
The following code snippet shows the AlloyMaxtemplate
for the problem-specific encoding, particularly the values of
all the positive and negative traces.
1one sig /*p∈AP*/extends Literal {}
2one sig /*i∈[0, max (|t|)), t∈ S*/extends SeqIdx {}
3fact {
4 first = /*i0*/
5 next = /*{(i0, i1),(i1, i2), . . .}*/
6}
67abstract sig PositiveTrace extends Trace {}
8abstract sig NegativeTrace extends Trace {}
9one sig /*t=uvω∈P*/extends PositiveTrace {}{
10 lasso = /*(i|uv|−1, i|u|)*/
11 /*{(t, n, i)|n∈AP∧n∈uv(i)}*/inval
12 // & means set intersection.
13 no/*{(t, n, i)|n∈AP∧n /∈uv(i)}*/& val
14}
15 one sig /*t=uvω∈N*/extends NegativeTrace {}{
16 // same above
17}
In this template, the mathematical expressions in the comments
/*..*/will be replaced by the actual parameters of a specific
learning problem ⟨AP,S,Φ,Ψ⟩. Line 1 defines all the atomic
propositions in APas literal DAG nodes. Lines 2-6 define the
finite set of time points given the maximum length of traces in
the sample Sand explicitly specify the initial time i0and the
next relation. This leverages a heuristic in Alloy to improve
performance through partial instances [28].
Lines 7-8 further divide the Trace signature into two sets,
PositiveTrace andNegativeTrace . Then, lines 9-17 explicitly
specify the value for a trace t=uvωin set PandN.
Specifically, on line 10, its lasso relation maps its last time
index i|uv|−1to the start of the loop i|u|. Lines 11-13 specify
that for any atomic proposition node n∈AP: (1) if n∈uv(i),
where uv(i)is the set of true propositions at time iof prefix
uv, then the tuple (t, n, i )is invalrelation; (2) otherwise, it
is not. E.g., for the trace tin Figure 6, we have:
{(t, x1, i1),(t, x2, i2)} ⊆valand
{(t, x1, i0),(t, x2, i0),(t, x2, i1),(t, x1, i2)} ∩val=∅
D. Learning Objective Encoding
The following code allows AlloyMaxto generate an LTL
formula that satisfies the sample.
1run {
2 all t: PositiveTrace |root->T0 int.val
3 all t: NegativeTrace |root->T0 not in t.val
4}for /*max number of DAG nodes */DAGNode
Line 2 defines that for any positive trace t∈P,(t, root, 0)∈
val, i.e., the learned formula is true on trace tfrom time 0.
In contrast, for any negative trace t∈N,(t, root, 0)is not in
val(line 3). Finally, on line 4, the user provides the maximum
number of DAG nodes allowed for a particular problem.
E. Custom Structural Constraints
AlloyMaxsupports all the constructs for defining the struc-
tural constraint Φ, including FOL, set operations, and the
additional join, transitive closure, and inverse operations1. For
example, to encode the constraints for G(ϕ→Fψ)(Example
1 of Section IV-B), we have:
1fun desc [n: DAGNode ]{n.ˆ(l+r) }
2fun subNodes [n: DAGNode ]{n.*(l+r) }
3one sig G0extends G{}
4one sig Imply0 extends Imply {}
5one sig F0extends F{}
1Due to limited space, the translation from ATLAS constraints and objec-
tives into AlloyMaxis omitted. The translation, however, is straightforward as
Alloy itself is based on FOL and well-suited for encoding the constraints.6fact {
7 root = G0 and root.l = Imply0 and Imply0.r = F0
8 no(G+F+Until+X) & subNodes [Imply0.l ]
9 no(G+F+Until+X) & desc [F0]
10}
Lines 1-2 correspond to the desc andsubNodes functions.
Lines 3-5 declare instances for NG, N→, NF, respectively.
Finally, lines 7-9 correspond to the constraints lines (2)-(4)
in Example 1.
F . Optimization Objective
Similar to the syntactic constraints, AlloyMaxsupports all the
optimization operators for defining objective Ψ. Specifically,
it has the following mappings:
•mink(s):minsome[ k]s
•maxk(s):maxsome[ k]s
•s≈k∅:softno[ k]s
•[f]k:soft[ k] fact
where kis an optional priority. For example, by default, we
include the following optimization goal to minimize the size
of the learned formula (Example 2 in Section IV-C):
1softno l + r
Moreover, to maximize the use of critical propositions (Ex-
ample 3), we have:
1maxsome[ 2]subNodes [root ]& (p + q + r)
where let critical ={p, q, r} ∈AP.
VI. L EARNING BY AlloyMax
A. Solving AlloyMaxwith MaxSAT
We briefly explain how Alloy and AlloyMaxsolve a problem
using a SAT and a MaxSAT solver, respectively; interested
readers should refer to the original papers for more details
[15], [29], [30]. A relation in Alloy is translated into a matrix
of Boolean variables – each of which is true if and only if the
tuple represented by this particular variable is in the relation;
and a relational expression is represented by operations over
one or more Boolean matrices.
For example, consider a relation r:A×Bwhere A=
{A1, A2}andB={B1, B2}. Then, this relation is repre-
sented by a set of Boolean variables {r11, r12, r21, r22}where,
for example, r11is true if and only if tuple (A1, B1)is inr.
Then, in AlloyMax, it encodes optimization goals as weighted
soft clauses such that a MaxSAT solver finds optimal solutions
by maximizing the total sum of weights. For example, the
AlloyMaxoperator softno minimizes the number of tuples in
a relation, the expression softno rwill be converted to:
(¬r11)k∧(¬r12)k∧(¬r21)k∧(¬r22)k
where, e.g., (¬r11)kis a soft clause with weight kthat may
or may not be satisfied. Thus, this formula finds a relation r
with a minimized number of tuples in it, and ideally, r=∅.
In addition, Alloy supports blocking a solution and using an
incremental solver to find a new solution. Thus, we leverage
this feature to enumerate solutions of a learning problem.
7B. Correctness
Our approach is sound but complete only up to the user-
provided bound on the maximum number of DAG nodes. A
correctness proof can be found in the Appendix.
C. Quality of Solutions
Since there can be multiple LTL formulas that satisfy an
LTL learning problem, additional constraints and objectives
are often necessary for finding “useful” solutions w.r.t. a prob-
lem domain. Moreover, enumerating solutions satisfying the
constraints is also a critical functionality. Our approach sup-
ports all of them. Furthermore, other than problem-dependent
constraints, additional sets of constraints are also useful for
avoiding trivial or less-satisfactory solutions. We list a few
constraints that we find useful from our experience.
Disable reusing in DAG: The DAG encoding was designed
to improve performance. When minimizing against a DAG,
it guarantees a minimal number of distinct sub-formulas.
However, this does not always produce a minimal LTL formula
in its syntax tree size where repeating sub-formulas are also
counted. For example, consider Fp∨FGpandFGp∨FGp.
The latter one has a bigger syntax tree size but a smaller DAG
size as the sub-formula FGpis reused [8]. Such behavior
might reduce the usefulness of the tool for certain problems
and can be disabled with the following constraint:
∀n∈N\NAP:|n.∼(L ∪ R )| ≤1∧ L ∩ R =∅
where n.∼(L∪R )returns the parent nodes of n(which could
be more than one in a DAG).
Avoid tautology: Another example is avoiding tautologies
in solutions. This is often necessary when only positive traces
are provided, where the learner may return a tautology ( true )
as a valid solution.
∀n∈N→:l(n)̸=r(n)
Negation normal form (NNF): The use of negation may
result in some equivalent but less readable formulas, e.g.,
¬G(x)versus F(¬x)where the latter may be more readable
and preferable. NNF is also helpful in automated theorem
proving [31]. Thus, we can enforce that negation should only
be applied to atomic propositions.
∀n∈N¬:l(n)∈NAP
This is an inexhaustive list of problem-independent con-
straints that we find helpful. Other examples include requiring
ϕto be in conjunction normal form (CNF) or disjunction
normal form (DNF).
VII. U SECASES
In this section, we present three use cases to demonstrate
the need for syntactic constraints and/or optimization ob-
jectives. These use cases also show how tool builders can
leverage ATLAS as a back-end LTL learner to perform
various specification-based tasks, such as specification repair
and invariant weakening.
enterpassword:selectcandidate:1212vote1conﬁrmFig. 7: A state machine representing the voting machine [33].
A. Specification Mining
This use case demonstrates the usefulness of custom con-
straints and enumeration. This case study is inspired by a
voter fraud incident in Kentucky, USA, where corrupt officials
manipulated a flaw in the system to “flip” votes [32]. Figure 7
shows an abstract model of the system as described in [33]: A
voter enters the booth, enters a password, selects a candidate,
votes, and finally confirms the vote before leaving the booth.
We generate example traces based on this model, manually
check their correctness, and mark them as positive or negative.
Specifically, a negative trace indicating a vulnerability of this
system is: A voter leaves the booth before confirming their
vote; then, a corrupt official enters the booth and uses the back
button to select another candidate and confirms the choice.
We want to learn a safety invariant to ensure election
integrity. Particularly, the invariant should be of the form Gϕ,
where ϕshould not contain any temporal operators. These
constraints can be expressed as:
root∈NG∧l(root)∩NG,F,U,X=∅ (7)
In addition, our technique supports enumerating solutions
that satisfy the given constraints, in the order of the formula
size (or other custom optimization objectives). This is often
helpful in finding variants of formulas. Specifically, in this case
study, the enumeration helps us to find two safety invariants:
1)G(selectCandidate →voterInBooth )
2)G(officialInBooth →enterPwd )
The first formula is in line with the key safety property
defined by formal methods experts in [33]. However, there is
a stronger, implicit requirement defined in [33]: The election
official is restricted from entering the booth after the voter
enters her password. We observe that this requirement is
captured precisely and explicitly by the second invariant.
B. Specification Repair from Demonstrations
In this use case, we demonstrate how custom optimization
objectives can be helpful in learning. The use case is motivated
by the field of autonomous agent interpretability using LTL
specifications [34]. Consider, for example, the setup in Figure
8a where the end effector of a robotic arm has to be actuated
to perform some tasks. The designer provides an initial LTL
specification: F(green )∧G(¬red); i.e., reaching the green
region and avoiding the red region.
However, after a controller has been developed, the designer
decides to refine the LTL specification to better reflect the
system requirements. For example, consider the requirement
that the robot should satisfy the above LTL formula but also
visit the blue region in Figure 8a. The designer can generate
8(a) A 7 DoF Panda Robotic Arm.
 (b) A radiation therapy machine.
Fig. 8: Examples of specification repair and weakening.
a set of demonstrative traces and mark each one as positive or
negative, depending on whether the robot successfully reaches
the blue region in the trace. Moreover, the modification to
the existing LTL should ideally be minimal while taking
this additional requirement into account. We pose this as an
LTL learning problem, where the associated objective is to
minimize the edit distance , i.e., minimizing the removal of
existing sub-formulas as well as the addition of new sub-
formulas. The encoding of this minimal modification problem
is defined as follows:
nG∈NG∧nF∈NF∧n∧∈N∧∧n¬∈N¬ (8)
green, red ∈NAP (9)
oldSpec ={(n∧, nF),(n∧, nG),(nF, green ), (10)
(nG, n¬),(n¬, red)}
max2 
(L ∪ R )∩oldSpec
(11)
Lines (8)-(10) define the original formula. Line (11) minimizes
the edit distance by using the max operator (with priority 2).
The learning process will first retain as many sub-formulas as
possible from the old specification and then minimize the total
size of the final formula. With these constraints, our approach
learns the ideal specification: F(green )∧G(¬red)∧F(blue),
where blue stands for reaching the blue region.
C. Invariant Weakening
In this case study, we show how complex LTL patterns (e.g.,
CNFs and DNFs) can be expressed using our technique. The
idea of invariant weakening, or more generally, specification
weakening, comes from requirements engineering [35], [36].
As the environmental conditions for a software system may
change over time and space, original requirements might
become inadequate or inconsistent with the new environment,
necessitating adaptation or weakening. This concept has been
further explored in self-adaptive systems [37]–[39].
For instance, Figure 8b is a radiation therapy machine
similar to Therac-25 [40] as described in [41]. The machine
has two modes: Electron Beam mode and X-ray mode. A
spreader must be inserted during the X-ray mode to attenuate
the effect of the high-power X-ray beam and limit possible
overdose. This safety requirement can be captured as the
following invariant P:G(XrayMode →SpreaderIn ).
However, a system might become too restrictive to satisfy
this safety property under certain environmental behavior. For
example, when switching from X-ray to Electron beam, itmight be acceptable that the spreader is out before the mode
switching is completed, as long as the beam is not fired.
Otherwise, we may have to disable all mode switching to
ensure safety [41]. One way to mitigate this issue is to weaken
the safety invariant (i.e., finding P′s.t.P→P′) from positive
(acceptable) and negative (definitely unsafe) examples [38].
An ideal weakened formula is: G(XrayMode ∧Fired →
SpreaderIn ).
We consider a safety invariant of the form G(ϕ→ψ),
where ϕandψare Boolean formulas. To achieve weakening,
one can learn an invariant G(ϕ∧ϕ′→ψ∨ψ′)where ϕ∧ϕ′
is a Boolean formula in CNF and ψ∨ψ′is a Boolean formula
in DNF. In other words, an invariant can be weakened by (1)
adding more conditions (as conjunctions) in the assumption, or
(2) adding new acceptable conditions (as disjunctions) in the
guarantee. This weakening objective can be expressed through
the following constraints:
nG∈NG∧n→∈N→∧root=nG∧l(root) =n→(12)
∀n∈desc(n→) :n∈N{∧,∨,¬,AP} (13)
∀n∈desc(n→) :n∈N¬→l(n)∈NAP (14)
∀n∈subNodes 
l(n→)
∩N∨:desc(n)∩N∧=∅(15)
∀n∈subNodes 
r(n→)
∩N∧:desc(n)∩N∨=∅(16)
l(n→) =XrayMode ∨ (17)
l(n→)∈N∧∧l 
l(n→)
=XrayMode
r(n→) =SpreaderIn ∨ (18)
r(n→)∈N∨∧l 
r(n→)
=SpreaderIn
Specifically, line (12) defines the structure G(ϕ→ψ). Line
(13) stipulates that ϕandψcontain only ∧,∨,¬, and AP.
Lines (14)-(16) state that ϕis in CNF and ψis in DNF. Lines
(17)-(18) state that ϕmay add conjuncts to XrayMode , and
ψmay add disjuncts to SpreaderIn . With these constraints,
we can learn the ideal weakened formula as described above.
VIII. E VALUATION
We investigate the following research questions:
1)RQ1 : How does our approach perform compared to the
state-of-the-art tool, Flie [9], over unconstrained LTL
learning problems?
2)RQ2 : For problems with structural constraints and/or
optimization objectives as described in our case studies,
how does our approach perform compared to the state-
of-the-art tools?
For RQ1, the metric we are concerned with is the total time
taken to find the first satisfying formula. For RQ2, we evaluate
performance through two key metrics: (1) the number of
constrained problems solved and (2) the time taken to solve
them. In particular, even though existing tools cannot encode
constraints such as ours, they can be configured to enumerate
all solutions until a solution satisfying the constraints is found;
the goal here is to compare how long it takes for ATLAS and
the baselines to find an ideal solution.
We implemented ATLAS in Java and use OpenWBO [42]
as the MaxSAT solver for AlloyMax. All experiments were
9run on a Linux machine with a 4-core 3.8GHz CPU and 8GB
memory. For each problem, we impose a 180-second time out.
A. Experimental Setup
For fair comparison, we compare ATLAS against the state-
of-the-art tools satisfying the following two criteria: (1) no
restrictions on the type of formula that can be learned and (2)
the guarantee of finding minimal formulas.
1) RQ1: For unconstrained problems, we compare our tool
against the SAT-based algorithm of Flie [9]. We did not use the
decision-tree-based method of Flie as it does not provide the
minimality guarantee. Then, we leverage the same benchmark
problems from Neider [9] which are generated based on com-
mon LTL patterns [43]. Specifically, this benchmark contains
485 problems with a number of examples ranging from 6 to
5000, a number of atomic propositions ranging from 2 to 9,
and a length of traces ranging from 5 to 10.
2) RQ2: For constrained problems, we first compare our
tool against Flie, which is configured to enumerate solutions
until an expected formula is found. We also compare against
LTLSketcher [8] that can learn a formula given a user-defined
template. It considers three types of placeholders in a template:
(1) any LTL sub-formula, (2) any unary operator, and (3) any
binary operator. However, it cannot express all our expected
constraints and does not support enumeration either. Thus, we
test whether it finds an expected formula in one run with the
closest template regarding our required constraints. If it does
not, we count it as a timeout. Also note that LTLSketcher is
not used in RQ1 as it builds on Flie, and without user-provided
templates, it reduces to Flie.
Moreover, other tools are not considered because they do not
meet our criteria. For example, SCARLET [44] is a performant
learning tool but cannot handle Until and nested Eventually
and Globally and also does not guarantee minimality.
Then, we generate a set of constrained problems from our
case studies with the expected solutions provided. Specifically,
we provide a set of solutions satisfying our constraints for each
problem, and a problem is deemed solved when a tool can find
any formula from the set.
Specification Mining. We generate problems from the two use
cases described in Section II and VII. For Peterson’s algorithm,
we randomly generate 30 problems from a model specified
in TLA+ [45], with 12 to 16 example traces, 15 atomic
propositions, and a trace length of 32. We add constraints for
learning the mutual exclusion and the deadlock-free properties.
Then, when comparing against LTLSketcher, we use template
G(?)for mutual exclusion and G(?→F?)for deadlock-free,
where ?stands for any sub-formula.
For the voting example, we generate 10 problems with 8 to
19 example traces, 10 atomic propositions, and a trace length
from 11 to 16. We add the constraint to learn an invariant in
Gϕwhere ϕis a propositional formula. However, the closest
template in LTLSketcher is G(?)where ?can be any formula.
Specification Repair. We generate 20 random problems from
a robot arm simulator developed in [46]. To simulate a
specification repair process, we generate positive traces using
Fig. 9: Comparisons of solving time in (a) unconstrained
and (b) constrained problems. The axes indicate the time in
seconds to solve a problem with a 180s timeout. A marker
(x, y)indicates a problem is solved by Flie in xseconds and by
ATLAS in yseconds. A dot below the diagonal line ( y=x)
indicates our tool is faster than Flie.
the ideal specification and generate negative traces by negating
a sub-formula in it. The problems have example traces ranging
from 4 to 16, 3 atomic propositions, and a length of traces from
33 to 44. When comparing against LTLSketcher, since it has
no way to express our optimization objective, we set an empty
template to learn any formula.
Invariant Weakening. We generate 78 random weakening
problems for two types of weakening: let AP={a, b, c},
(1) weaken G(a→b)toG(a∧c→b), and (2) weaken
G(a→b∧c)toG(a→(b∧c)∨b). The number of examples
of the problems ranges from 20 to 200, and the length of
the examples ranges from 5 to 100. When comparing against
LTLSketcher, the closest it can express is G(?→?).
B. Results
All these tools take a file containing the example traces of a
problem as input (with additional constraints or templates for
RQ2). We checked the consistency of the learned formulas
with our predefined solutions. Then, we report on the compar-
ison results of ATLAS against other tools.
RQ1. Figure 9a shows the evaluation results for unconstrained
problems. A blue marker below the diagonal line indicates
that our approach is faster than Flie for a given problem.
We find that our approach is faster than or equal to Flie in
most of the problems ( 417/485≈86%), including where
both timeout. The average solving time (including the 180s
timeout) is: 96.83s for Flie and 66.76s for ATLAS, where
our tool is about 1.45x faster than Flie.
Even though Flie and our tool both encode as a SAT
problem, Flie guarantees minimality by gradually increasing
the size of the learned formula and invoking a SAT solver for
each bound. However, we guarantee minimality by leveraging
MaxSAT solving, which also involves solving multiple SAT
instances but with the capability of sharing intermediate results
(e.g., conflicting clauses) [16].
RQ2. Figure 9b shows the results for constrained problems,
benchmarked against Flie. We find that our tool is faster than
10TABLE I: Comparisons of the number of solved problems and
the average solving time (including the 180s timeout).
Peterson’s V oting Repair Weakening
#Solved Time #Solved Time #Solved Time #Solved Time
ATLAS 30/30 43.65s 10/10 3.08s 20/20 37.25s 53/78 66.75s
Flie 2/30 179.68s 2/10 144.92s 1/20 178.63s 30/78 142.98s
LTLSketcher 0/30 180s 2/10 144.30s 0/20 180s 11/78 160.73s
or equal to Flie (including where both time out) in most
of the problems, specifically 30/30in Peterson’s algorithm,
10/10in voting machine, 20/20in specification repair, and
71/78≈91%in invariant weakening.
Moreover, Table I shows the number of solved problems
and the average solving time for Flie, LTLSketcher, and
ATLAS. Our tool solves the most number of problems and
also has the lowest average solving time. On average, we solve
about 3.2x as many problems as Flie and 8.7x as many as
LTLSketcher. Also, our tool is about 3xfaster than both Flie
and LTLSketcher.
Although ATLAS also failed to solve some problems due
to timeout, it is better than Flie and LTLSketcher in that: Flie
needs to enumerate a large, unconstrained search space which
leads to timeout more often. LTLSketcher failed due to the lack
of expressiveness (in defining the expected constraints) and
enumeration capability. Thus, we show that strong expressive
power and the enumeration capability are both critical to LTL
learning, and our tool supports both. We can solve all problems
that Flie and LTLSketcher can without the loss of generality
and much performance overhead.
C. Threats to Validity
As shown in RQ2, Flie and LTLSketcher are outperformed
in the constrained LTL problem benchmark. This might be
due to the fact that our benchmark is based on the set of
use cases that we manually constructed to demonstrate the
applicability of constrained LTL learning. However, we believe
that this potential bias is mitigated, as these problems contain
a wide range of FOL constraints and are not specific to our
Alloy-based encoding. We also note that the solutions found
by ATLAS are also in the space of possible solutions that Flie
and LTLSketcher can generate.
IX. R ELATED WORK
Neider and Gavran [9] present Flie, a SAT-based encoding
for LTL learning, which is the first approach of learning any
unrestricted minimal LTL formulas over infinite traces. It also
presents a decision-tree based learning algorithm which is
more efficient but does not guarantee the formula to be mini-
mal. SCARLET [44] was proposed to overcome the scalability
limitations of [9]; however, they deal with a strict fragment of
LTL and also do not provide guarantees on minimality.
Before Neider’s approach, techniques for mining LTL,
such as [4], [12], [13], rely on patterns or templates. For
example, given a template G(x→Fy), Texada [4] infers
specifications by substituting xandywith atomic events from
the given traces (and does not learn from negative traces).Compared to our approach, Texada lies on a different trade-
off point between expressiveness and efficiency: Although
ATLAS gives the user more control over the properties of
LTL expressions to be learned, Texada is able to mine from
much larger traces (e.g., thousands of events). More recently,
Lutz et al. present LTLSketcher [8], where they consider three
types of substitutions (i.e., any formula, unary operator, and
binary operator) and propose a SAT-based method to find valid
substitutions. Although they have improved expressiveness
compared to Texada, they cannot express many patterns (e.g.,
CNF and DNF) as demonstrated in our use cases. In addition,
none of these tools supports custom optimization objectives.
Researchers have also explored different variations of the
learning problem [47]. Gaglione et al. [48] present an approach
using MaxSAT to learn from noisy data. Although AlloyMax
also uses MaxSAT, we cannot solve this type of problem be-
cause AlloyMaxcannot directly control the weights of clauses
in a MaxSAT instance. Roy et al. [49] present an approach
for learning from positive-only examples. While our tool also
supports such a problem, we can only constrain and optimize
the syntactic structure of a solution whereas they can guarantee
semantic minimality (i.e., a minimal set of behavior).
X. C ONCLUSION AND FUTURE WORK
We have proposed the constrained LTL learning problem as
a generalization of LTL learning from examples, and demon-
strated the applicability and performance of ATLAS, our
prototype implementation tool. While our evaluation shows
promise, we plan to investigate further ways to improve the
learning method. First, the scalability of our tool is limited
by the underlying MaxSAT solver, and an interesting future
work is to investigate an approach that uses a different learning
method (based on machine learning, for example). We also
plan to investigate methods or heuristics for further reducing
the space of possible LTL solutions (e.g., an encoding scheme
that eliminates redundant, equivalent LTL expressions). More-
over, we plan to investigate additional use cases for ATLAS
(such as invariant synthesis for distributed systems).
Our approach improves the expressive power of LTL learn-
ing tools. However, crafting constraints in FOL can be chal-
lenging for non-experts in formal logic. As future work, we
plan to improve the usability of LTL learning by building
on ATLAS (e.g., through a DSL front-end or an LLM that
converts natural language to FOL). In addition, ATLAS and
other learning tools require the user to provide examples.
Future work could explore integrating external methods (e.g.,
model checkers or test generation tools) to (semi-)automate
the generation of examples.
ACKNOWLEDGMENT
This work was supported in part by the NSF awards
2144860 and 2319317, and the NSA grant H98230-23-C-0274.
Any views, opinions, findings and conclusions or recommen-
dations expressed in this material are those of the author(s)
and do not necessarily reflect the views of the organizations.
11DATA AVAILABILITY
The source code of our tool and all the experimental results
are available at: https://doi.org/10.5281/zenodo.14578202
REFERENCES
[1] A. Pnueli, “The temporal logic of programs,” in 18th Annual Symposium
on Foundations of Computer Science (sfcs 1977) , 1977, pp. 46–57.
[2] E. M. Clarke, T. A. Henzinger, H. Veith, R. Bloem et al. ,Handbook of
model checking . Springer, 2018, vol. 10.
[3] A. Pnueli and R. Rosner, “On the synthesis of a reactive module,” in
POPL . ACM Press, 1989, pp. 179–190.
[4] C. Lemieux, D. Park, and I. Beschastnikh, “General ltl specification
mining (t),” in 2015 30th IEEE/ACM International Conference on
Automated Software Engineering (ASE) , 2015, pp. 81–92.
[5] A. Bauer, M. Leucker, and C. Schallhart, “Runtime verification for LTL
and TLTL,” ACM Trans. Softw. Eng. Methodol. , vol. 20, no. 4, pp. 14:1–
14:64, 2011.
[6] A. Zeller, “Specifications for free,” in NASA Formal Methods , M. Bo-
baru, K. Havelund, G. J. Holzmann, and R. Joshi, Eds. Berlin,
Heidelberg: Springer Berlin Heidelberg, 2011, pp. 2–12.
[7] K. Y . Rozier, “Specification: The biggest bottleneck in formal methods
and autonomy,” in Verified Software. Theories, Tools, and Experiments ,
S. Blazy and M. Chechik, Eds. Cham: Springer International Publish-
ing, 2016, pp. 8–26.
[8] S. Lutz, D. Neider, and R. Roy, “Specification sketching for linear
temporal logic,” in Automated Technology for Verification and Analysis ,
´E. Andr ´e and J. Sun, Eds. Cham: Springer Nature Switzerland, 2023,
pp. 26–48.
[9] D. Neider and I. Gavran, “Learning linear temporal properties,” in 2018
Formal Methods in Computer Aided Design (FMCAD) , 2018, pp. 1–10.
[10] A. Camacho and S. A. McIlraith, “Learning interpretable models
expressed in linear temporal logic,” in International Conference
on Automated Planning and Scheduling , 2019. [Online]. Available:
https://api.semanticscholar.org/CorpusID:197418408
[11] G. Ammons, R. Bod ´ık, and J. R. Larus, “Mining specifications,”
inProceedings of the 29th ACM SIGPLAN-SIGACT Symposium on
Principles of Programming Languages , ser. POPL ’02. New York, NY ,
USA: Association for Computing Machinery, 2002, p. 4–16. [Online].
Available: https://doi.org/10.1145/503272.503275
[12] M. D. Ernst, J. H. Perkins, P. J. Guo, S. McCamant, C. Pacheco, M. S.
Tschantz, and C. Xiao, “The daikon system for dynamic detection
of likely invariants,” Science of Computer Programming , vol. 69,
no. 1, pp. 35–45, 2007, special issue on Experimental Software and
Toolkits. [Online]. Available: https://www.sciencedirect.com/science/
article/pii/S016764230700161X
[13] W. Li, L. Dworkin, and S. A. Seshia, “Mining assumptions for synthe-
sis,” in Ninth ACM/IEEE International Conference on Formal Methods
and Models for Codesign (MEMPCODE2011) , 2011, pp. 43–50.
[14] D. Jackson, Software Abstractions: Logic, language, and analysis . MIT
Press, 2006.
[15] C. Zhang, R. Wagner, P. Orvalho, D. Garlan, V . Manquinho, R. Martins,
and E. Kang, “Alloymax: bringing maximum satisfaction to relational
specifications,” in Proceedings of the 29th ACM Joint Meeting on
European Software Engineering Conference and Symposium on the
Foundations of Software Engineering , ser. ESEC/FSE 2021. New
York, NY , USA: Association for Computing Machinery, 2021, p.
155–167. [Online]. Available: https://doi.org/10.1145/3468264.3468587
[16] F. Bacchus, M. J ¨arvisalo, and R. Martins, “Maximum Satisfiability,” in
Handbook of Satisfiability , A. Biere, M. Heule, H. van Maaren, and
T. Walsh, Eds. IOS Press, 2021, ch. 24, pp. 929 – 991.
[17] V . Dallmeier, N. Knopp, C. Mallon, S. Hack, and A. Zeller,
“Generating test cases for specification mining,” in Proceedings
of the 19th International Symposium on Software Testing and
Analysis , ser. ISSTA ’10. New York, NY , USA: Association
for Computing Machinery, 2010, p. 85–96. [Online]. Available:
https://doi.org/10.1145/1831708.1831719
[18] B. Peng, P. Liang, T. Han, W. Luo, J. Du, H. Wan, R. Ye, and Y . Zheng,
“Purltl: Mining ltl specification from imperfect traces in testing,” in
2023 38th IEEE/ACM International Conference on Automated Software
Engineering (ASE) , 2023, pp. 1766–1770.[19] G. L. Peterson, “Myths about the mutual exclusion problem,” Inf.
Process. Lett. , vol. 12, no. 3, pp. 115–116, 1981. [Online]. Available:
https://doi.org/10.1016/0020-0190(81)90106-X
[20] P. Zave, “Reasoning about identifier spaces: How to make chord correct,”
IEEE Transactions on Software Engineering , vol. 43, no. 12, pp. 1144–
1156, 2017.
[21] C. Trippel, D. Lustig, and M. Martonosi, “CheckMate: Automated
synthesis of hardware exploits and security litmus tests,” Proceedings
of the Annual International Symposium on Microarchitecture, MICRO ,
vol. 2018-Octob, pp. 947–960, 2018.
[22] S. Khurshid and D. Marinov, “Testera: Specification-based testing of java
programs using SAT,” Autom. Softw. Eng. , vol. 11, no. 4, pp. 403–434,
2004.
[23] G. Dennis, F. S.-H. Chang, and D. Jackson, “Modular verification of
code with sat,” in Proceedings of the 2006 International Symposium on
Software Testing and Analysis , ser. ISSTA ’06. New York, NY , USA:
Association for Computing Machinery, 2006, p. 109–120. [Online].
Available: https://doi.org/10.1145/1146238.1146251
[24] D. Jackson and M. Vaziri, “Finding bugs with a constraint solver,”
inInternational Symposium on Software Testing and Analysis (ISSTA) ,
2000, pp. 14–25.
[25] S. Narain, “Network configuration management via model finding,” in
USENIX Conference on Systems Administration (LISA) , 2005, pp. 155–
168.
[26] N. Piterman, A. Pnueli, and Y . Sa’ar, “Synthesis of reactive(1) designs,”
inVerification, Model Checking, and Abstract Interpretation , E. A.
Emerson and K. S. Namjoshi, Eds. Berlin, Heidelberg: Springer Berlin
Heidelberg, 2006, pp. 364–380.
[27] A. Biere and D. Kr ¨oning, SAT-Based Model Checking . Cham:
Springer International Publishing, 2018, pp. 277–303. [Online].
Available: https://doi.org/10.1007/978-3-319-10575-8 10
[28] E. Torlak and G. Dennis, “Kodkod for alloy users,” in First ACM Alloy
Workshop, Portland, Oregon , 2006, pp. 27–33.
[29] D. Jackson, “Automating first-order relational logic,” in Proceedings
of the 8th ACM SIGSOFT International Symposium on Foundations
of Software Engineering: Twenty-First Century Applications , ser.
SIGSOFT ’00/FSE-8. New York, NY , USA: Association for
Computing Machinery, 2000, p. 130–139. [Online]. Available: https:
//doi.org/10.1145/355045.355063
[30] E. Torlak and D. Jackson, “Kodkod: A relational model finder,” in
Tools and Algorithms for the Construction and Analysis of Systems ,
O. Grumberg and M. Huth, Eds. Berlin, Heidelberg: Springer Berlin
Heidelberg, 2007, pp. 632–647.
[31] L. Wos, R. Overbeek, E. Lusk, and J. Boyle, Automated reasoning
introduction and applications . McGraw-Hill, Inc., 1992.
[32] U.S. Attorney’s Office Eastern District of Kentucky, “Clay county
officials and residents convicted on racketeering and voter fraud
charges,” Mar 2010. [Online]. Available: https://archives.fbi.gov/
archives/louisville/press-releases/2010/lo032510.htm
[33] R. Meira-G ´oes, I. Dardik, E. Kang, S. Lafortune, and S. Tripakis,
“Safe environmental envelopes of discrete systems,” in Computer Aided
Verification , C. Enea and A. Lal, Eds. Cham: Springer Nature
Switzerland, 2023, pp. 326–350.
[34] A. J. Shah, P. Kamath, J. A. Shah, and S. Li, “Bayesian
inference of temporal task specifications from demonstrations,” in
Neural Information Processing Systems , 2018. [Online]. Available:
https://api.semanticscholar.org/CorpusID:53625998
[35] A. van Lamsweerde, R. Darimont, and E. Letier, “Managing conflicts in
goal-driven requirements engineering,” IEEE Transactions on Software
Engineering , vol. 24, no. 11, pp. 908–926, 1998.
[36] D. Alrajeh, A. Cailliau, and A. van Lamsweerde, “Adapting require-
ments models to varying environments,” in International Conference on
Software Engineering (ICSE) . ACM, 2020, pp. 50–61.
[37] J. Whittle, P. Sawyer, N. Bencomo, B. H. Cheng, and J.-M. Bruel,
“Relax: Incorporating uncertainty into the specification of self-adaptive
systems,” in 2009 17th IEEE International Requirements Engineering
Conference , 2009, pp. 79–88.
[38] T. Buckworth, D. Alrajeh, J. Kramer, and S. Uchitel, “Adapting specifi-
cations for reactive controllers,” in 2023 IEEE/ACM 18th Symposium
on Software Engineering for Adaptive and Self-Managing Systems
(SEAMS) , 2023, pp. 1–12.
[39] S. Chu, E. Shedden, C. Zhang, R. Meira-G ´oes, G. A. Moreno, D. Gar-
lan, and E. Kang, “Runtime resolution of feature interactions through
adaptive requirement weakening,” in Proceedings of the 18th Symposium
12on Software Engineering for Adaptive and Self-Managing Systems , ser.
SEAMS ’23, 2023.
[40] N. G. Leveson and C. S. Turner, “An investigation of the therac-25
accidents,” Computer , vol. 26, no. 7, pp. 18–41, 1993.
[41] C. Zhang, T. Saluja, R. Meira-G ´oes, M. Bolton, D. Garlan, and E. Kang,
“Robustification of behavioral designs against environmental devia-
tions,” in 2023 IEEE/ACM 45th International Conference on Software
Engineering (ICSE) , 2023, pp. 423–434.
[42] R. Martins, V . Manquinho, and I. Lynce, “Open-wbo: A modular maxsat
solver,” in Theory and Applications of Satisfiability Testing – SAT 2014 ,
C. Sinz and U. Egly, Eds. Cham: Springer International Publishing,
2014, pp. 438–445.
[43] M. B. Dwyer, G. S. Avrunin, and J. C. Corbett, “Property specification
patterns for finite-state verification,” in Proceedings of the Second
Workshop on Formal Methods in Software Practice , ser. FMSP ’98.
New York, NY , USA: Association for Computing Machinery, 1998, p.
7–15. [Online]. Available: https://doi.org/10.1145/298595.298598
[44] R. Raha, R. Roy, N. Fijalkow, and D. Neider, “Scalable anytime
algorithms for learning fragments of linear temporal logic,” in Tools
and Algorithms for the Construction and Analysis of Systems , D. Fisman
and G. Rosu, Eds. Cham: Springer International Publishing, 2022, pp.
263–280.
[45] L. Lamport, Specifying Systems: The TLA+ Language and Tools for
Hardware and Software Engineers . Addison-Wesley, June 2002.
[46] V . Kurtz and H. Lin, “Temporal logic motion planning with convex
optimization via graphs of convex sets,” IEEE Transactions on Robotics ,
2023.
[47] D. Neider and R. Roy, “Expanding the Horizon of Linear Temporal
Logic Inference for Explainability,” 2022 IEEE 30th International
Requirements Engineering Conference Workshops (REW) , pp. 103–107,
Aug. 2022. [Online]. Available: https://ieeexplore.ieee.org/document/
9920141/
[48] J.-R. Gaglione, D. Neider, R. Roy, U. Topcu, and Z. Xu, “MaxSAT-
based temporal logic inference from noisy data,” Innovations in Systems
and Software Engineering , vol. 18, no. 3, pp. 427–442, Sep. 2022.
[Online]. Available: https://doi.org/10.1007/s11334-022-00444-8
[49] R. Roy, J.-R. Gaglione, N. Baharisangari, D. Neider, Z. Xu, and
U. Topcu, “Learning interpretable temporal properties from positive
examples only,” in Proceedings of the AAAI Conference on Artificial
Intelligence , vol. 37, no. 5, 2023, pp. 6507–6515.
13APPENDIX
A. Correctness Proof
Our approach is sound but complete only up to the bound
of the user-provided max number of DAG nodes.
Theorem 10.1 (Soundness): Given a constrained learning
problem ⟨AP,S,Φ,Ψ⟩and an upper bound of nodes n, a
solution to the translated AlloyMaxproblem is an LTL formula
that is consistent with S, satisfies Φ, and optimizes against Ψ.
Theorem 10.2 (Completeness): If there is a valid solution to
a constrained learning problem within a bound n, our approach
is guaranteed to find it.
Proof. For soundness, recall that input traces are in the lasso
form (i.e., uvω). As demonstrated in Figure 6, although a lasso
is infinite, the set of all states that are reachable from any time t
is finite and can be computed from the finite prefix uv. Thus,
the valuation of an LTL formula on a lasso can be decided
based only on uv[9]. Our semantic encoding is inspired by
the established encoding of SAT-based LTL model checking
[9], [27], and the correctness of the AlloyMaxto MaxSAT
translation is established in [15]. For completeness, the syntax
encoding in Section V-A guarantees that it will search for all
possible formulas given the bound. Moreover, the objective Ψ
does not change the amount of valid solutions w.r.t. sample S
and constraint Φ[15]. For instance, with objective L∪R ≈ ∅ ,
the solver first returns a formula of minimal size and can
enumerate all valid solutions within the bound in ascending
order of formula size. □
Specifically, the correctness of the above proof relies on the
following theorems.
Theorem 10.3: For any LTL formula ϕ, its valuation on a
lasso-shaped trace uvωcan be decided purely on the finite
prefix uv.
Proof. In this work, we consider only future-time operators
(i.e., X, U, F, G ). For example, consider the next operator X,
given an LTL formula Xϕand a lasso trace uvω, the valuation
ofuvω, i|=Xϕdepends on the valuation of uvω, i+ 1|=ϕ.
In the case where i+ 1>|uv|, the trace cycles within v, and
thus the valuation can be reduced to uvω,|u|+ 
(i+ 1− |u|)
mod|v|
|=ϕ. The same reduction can be derived for other
temporal operators [9]. □
Therefore, for any valuation uvω, i|=ϕ, we only need to
compute the finite set of future states from the time i. We then
show that our Alloy encoding can compute the future states
of any lasso trace and any time point.
Theorem 10.4: For a lasso trace uvωand a time point i,
our Alloy encoding correctly computes the finite set of future
states of uvω[i,∞].
Proof. The computation of future states is based on the re-
lations next andlasso . For example, for the trace tdescribed
in Figure 6, we have next ={(0,1),(1,2)}andt.lasso =
{(2,1)}. Thus, next +t.lasso ={(0,1),(1,2),(2,1)}, and
the expression i.(next+t.lasso )computes the next time point
(state) of time iwith the consideration of the cycle (e.g., when
i= 2, the expression evaluates to {1}). Moreover, for the
F,G,andUoperators, we use the futureIdx (t, i)function tocompute the set of all future time points (states) of a trace t
starting from time i. It is defined as follows:
1fun futureIdx [t: Trace, i: SeqIdx ]:set SeqIdx {
2 i.ˆ(next + t.lasso) + i
3}
The∧operator computes the transitive closure of a relation.
Thus, in our example,∧(next +t.lasso ) ={(0,1),(0,2),
(1,2),(1,1),(2,1),(2,2)}, and the expression i.∧(next +
t.lasso )returns the set of future states from time i(e.g., when
i= 0, it evaluates to {1,2}; and when i= 2, it evaluates to
{1,2}where both 1and2are returned because of the cycle).
In addition, we append the current time point ito the set based
on the LTL semantics. Finally, this set of future states are used
to evaluate an LTL expression. □
Finally, we show our Alloy model encodes the LTL seman-
tics.
Theorem 10.5: The Alloy encoding has the same semantics
as the semantics of LTL.
Proof. It is straightforward to see that our Alloy encoding
models the semantics of LTL as both of them are based on
first-order logic expressions. For example, the interpretation
ofuvω, i|=Fϕis defined as ∃j:i≤j∧uvω, j|=ϕ. This is
represented in our Alloy encoding as:
1some j: futureIdx [t, i ] | n.l->j int.val
where some corresponds to ∃,tis the trace, futureIdx com-
putes the set of future states from i,nis the expression Fϕ,
andn.lis the sub-expression ϕ. One exception is the encoding
of the U-operator, where we leverage the heuristics from
bounded model checking to unfold it using the X-operator,
i.e.,qUp=p∨(q∧X(qUp)). This heuristic can produce a
more succinct encoding and thus improve the performance. □
14