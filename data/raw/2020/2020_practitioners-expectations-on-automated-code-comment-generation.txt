Practitioners‚Äô Expectations on Automated Code Comment
Generation
Xing Hu
School of Software Technology,
Zhejiang University
Ningbo, China
xinghu@zju.edu.cnXin Xia‚àó
Zhejiang University
Hangzhou, China
xin.xia@acm.orgDavid Lo
Singapore Management University
Singapore
davidlo@smu.edu.sg
Zhiyuan Wan
Zhejiang University
Hangzhou, China
wanzhiyuan@zju.edu.cnQiuyuan Chen
Zhejiang University
Hangzhou, China
chenqiuyuan@zju.edu.cnThomas Zimmermann
Microsoft Research
Seattle, USA
tzimmer@microsoft.com
ABSTRACT
Good comments are invaluable assets to software projects, as they
helpdevelopersunderstandandmaintain projects.H owever, due
tosomepoorcommentingpractices,commentsareoftenmissing
or inconsistentwith the sourcecode. Softwareengineering practi-
tioners often spend a significant amount of time and effort reading
andunderstandingprogramswithoutorwithpoorcomments.To
counter this,researchers have proposedvarious techniques toau-
tomatically generate code comments in recent years, which can
not only save developers time writing comments but also help
thembetterunderstandexistingsoftwareprojects.However,itis
unclear whether these techniques can alleviate comment issuesand whether practitioners appreciate this line of research. To fillthis gap, we performed an empirical study by interviewing and
surveyingpractitionersabouttheirexpectationsofresearchincode
commentgeneration.Wethencomparedwhatpractitioners need
and the current state-of-the-art research by performing a literature
review of papers on code comment generation techniques pub-
lishedinthepremierpublicationvenuesfrom2010to2020.From
thiscomparison,wehighlightedthedirectionswhereresearchers
need to put effort to develop comment generation techniques that
matter to practitioners.
KEYWORDS
Code Comment Generation, Empirical Study, Practitioners‚Äô Expec-
tations
ACM Reference Format:
XingHu,XinXia,DavidLo,ZhiyuanWan,QiuyuanChen,andThomasZim-
mermann. 2022. Practitioners‚Äô Expectations on Automated Code Comment
Generation.In The44thInternationalConferenceonSoftwareEngineering,
‚àóCorresponding Author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ICSE 2022, May 21‚Äì29, 2022, Pittsburgh, PA, USA
¬© 2022 Association for Computing Machinery.
ACM ISBN 978-1-4503-9221-1/22/05...$15.00
https://doi.org/10.1145/3510003.3510152May 21‚Äì29, 2022, Pittsburgh, PA, USA. ACM, New York, NY, USA, 13 pages.
https://doi.org/10.1145/3510003.3510152
1 INTRODUCTION
Codecommentsareessentialpartsofsoftwareprojectsandprovide
descriptive information about the functionality, design rationale,
and usage of a code snippet [ 4]. They help practitioners use, un-
derstand, and maintain software projects [ 45]. Well-commented
source code improves project readability and developerproductiv-
ity.Despitetheintrinsicvalueofcodecommentsduringsoftware
developmentandevolutionactivities,thecreationandmaintenance
of comments are often neglected. To address these issues, different
approachesandtoolshavebeenproposedtogeneratecomments
from source code automatically [13, 17, 19, 21, 22, 49, 51, 52].
These techniques traditionally rely on manually crafted tem-
platesandinformationretrieval(IR)techniquestogeneratecom-
ments.Template-basedapproachesmainlyrelyonelaborateheuris-
ticsandtemplatesfordifferenttypesofprogramstogeneratede-
scriptive comments [ 32,42]. However, defining a template requires
substantialhumaneffortandextensivedomainknowledge.IR-based
approachesmainly extracttermsfromsource codeandthenorga-
nizethesetermsforgeneratingcomments[ 13,17].Besides,some
studies generate comments by retrieving similar code snippetsand using their corresponding comments for comment genera-
tion[51,52].Inrecentyears,manyresearchershavetakenadvan-
tageofdeeplearningtechniquestogeneratecommentsbylearningfromlarge,publiclyavailablecoderepositories[
19,21,22,49].These
techniques apply neural machine translation models to learn to
translate source code to comments [16].
Despitenumerousstudiesoncodecommentgeneration,unfor-
tunately,fewstudieshaveinvestigatedtheexpectationsofpracti-
tionersonresearchincommentgeneration.Itisunclearwhether
practitionersappreciatethislineofresearch.Eveniftheydo,itis
unclear whether they would adopt code comment generation tools,
what factors affect their decisions to adopt, and their minimum
thresholdsforadoption.Thepractitioners‚Äôperspectiveisimportant
to help guide software engineering researchers to create solutions
that satisfy developers. In addition, some gaps between practition-
ers‚Äô expectations and research have not yet been investigated.
To gain insights into practitioners‚Äô expectations on code com-
ment generation, we first conducted semi-structured interviews
16932022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:32:16 UTC from IEEE Xplore.  Restrictions apply. ICSE 2022, May 21‚Äì29, 2022, Pittsburgh, PA, USA Xing Hu, Xin Xia, David Lo, Zhiyuan Wan, Qiuyuan Chen, and Thomas Zimmermann
with16 professionalsfromvarious companies.Throughthe inter-
views, we qualitatively investigated the commenting practices and
issues that our interviewees experienced in software development,
andtheirexpectationsoncodecommentgeneration.Then,wevali-
dated our findings through a survey answered by 720 professional
developersorotherITprofessionalsfrom26countriesacrosssix
continents.Afterthesurvey,weperformedaliteraturereviewofthe
state-of-the-art papers. We then compared techniques proposed in
the papers against the criteria that practitioners have for adoption.
Inparticular,weinvestigatedthefollowingfourresearchques-
tions:RQ1: What is the state of code commenting practices and
what are the issues?
Thisresearchquestionstudiescodecommentingpracticesand
issues that practitioners experienced during software development.
82% and 81% of the survey respondents often write commentsand are often confused when reading code without comments,
respectively. Meanwhile, 69% and 62% respondents considered lack
of comments andgeneric comments as the main issues, respectively.
RQ2: Are automated code comment generation tools usefulfor practitioners?
This research question investigates practitioners‚Äô willingness
toadoptcodecommentgenerationtechniques.80%ofthesurvey
respondents think code comment generation tools are worthwhile
and essential for them. 78% of them agree that these tools can help
themunderstandthesourcecode,especiallyforexistingprojects
with fewer comments and improve code readability.
RQ3:Whatarepractitioners‚Äôexpectationsoncodecommentgeneration tools?
Thisresearchquestionfocusesoninvestigatingwhattocomment
and where to comment for different granularity level comments
thatpractitionersexpect,andwhatfactorscanaffecttheiradoption
of a comment generation technique. Most participants (about 85%)
expecttoolstogeneratemethod-levelcomments.Thecommentsshould include information about 1) what the method does (i.e.,
functionality);2)howtousethemethod;and3)whythemethod
exists (i.e., design rationale). The most important locations to be
commentedonincludecomplex,tricky,andnonself-explanatory
methods.Theoptimallengthofageneratedcommentis2-3lines.
Before adopting a code comment generation tool, the generatedcomments should satisfy the amount of additional information
(i.e., amount of information beyond what can be easily gleaned
from scanning the source code), content adequacy (the amount of
contentcarriedoverfromtheinputcodetothegeneratedcomments,
ignoring fluency of the text), and conciseness.RQ4: How close are the current state-of-the-art studies tosatisfy practitioner needs and demands before adoption?
Thisresearchquestioninvestigatesthecurrentstate-of-the-art
researchandcomparesthegapbetweenitandpractitioners‚Äôexpec-tations.Weidentified25papersthatproposedcodecommentgener-ationtechniquesand17ofthemgeneratedmethod-levelcomments.
Mostpapersgeneratedcommentstodescribemethods‚Äôfunction-
ality.However, fewpapersgenerated commentswith‚Äúhowto use ‚Äù
and ‚Äúwhy a method exists ‚Äù information. In addition, most papers
focus on measuring the overlapped N-grams between generated
comments and human-written comments, while it is not preferred
by a large majority of our respondents. Also, no papers evaluate  	   
	 	
	





	






 


 
 




		
		



# 
	$ 	!
	% 	

	
		! " 	
	 
Figure 1: Research Methodology Overview
theamountofadditionalinformation inthegeneratedcomments,
which most practitioners expect.
Ourresearchismeanttohelpresearcherstoconsidertheneedsof
practitioners to continue the development of better code comment
generationtechniquesthatcaneventuallyresultinhighadoption
and satisfaction rate.
This paper makes the following contributions:
‚Ä¢We interviewed 16 professionals and surveyed 720 practitioners
frommorethan26countriestoshedlightonpractitioners‚Äôex-
pectations, including their views on the importance of comment
generation and their thresholds and reasons for adopting or not
adopting such techniques.
‚Ä¢We performed a literature review of papers published in the pre-
mier publication venues in software engineering and artificialintelligence communities in the last ten years. Then, we com-
paredthecurrentstate-of-researchwithwhatpractitionerswant
and highlighted what can be done next to meet practitioners‚Äô
needs and demands.
PaperStructure :Section2describesthemethodologyofourstudy.
Section3showstheresultsofourstudy.WediscusstheimplicationsofourresultsinSection4.Section5discussesrelatedwork.Section
6 draws conclusions and outlines avenues for future work.
2 RESEARCH METHODOLOGY
TheoverviewofthemethodologyinourstudyisshowninFigure1
and consists of three stages. Stage 1: Interviews with professionals
on their practices on commenting, issues they face related to code
comments, and their expectations on code comment generation
techniques. Stage 2:Anonlinesurveyforconfirmingandextending
theconclusionsaboutcodecommentsbasedontheinterview. Stage
3:Performaliteraturereviewtoanalyzewhetherandtowhatextent
current state-of-the-art research has satisfied practitioners‚Äô needs
and demands. The interviews and survey were approved by the
relevant institutional review board (IRB).
2.1 Stage 1: Interview
Theinterviewaimstounderstandcommentingpracticesandissues
that professionals experience during software development and
practitioners‚Äôexpectationsoncodecommentgenerationtools.This
section presents the interview process.
1694
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:32:16 UTC from IEEE Xplore.  Restrictions apply. Practitioners‚Äô Expectations on Automated Code Comment Generation ICSE 2022, May 21‚Äì29, 2022, Pittsburgh, PA, USA
2.1.1 Protocol. The first author conducted a series of face-to-face
semi-structured, in-depthinterviews basedon aninterview guide
toenableadetailedexplorationoftheparticipants‚Äôviewsandexpe-
riences.Wedevelopedtheinterviewguidethroughabrainstorming
process.Weinvited16softwarepractitionerstoparticipateinthe
interviews from 10 IT companies worldwide. Each interview took
30-40 minutes. In the remainder of the paper, we denoted these 16
interviewees as I1 to I16.
Each interview had three parts. In the first part, we asked some
demographicquestionsabouttheinterviewee‚Äôsbackground(e.g.,
jobrole,lengthofworkexperience,andteamsize).Inthesecond
part,weaskedopen-endedquestionsaboutwhattheyconsidertobegood/badcodecomments.Thispartaimedtoallowtheinterviewees
to speak freely about their opinions and experience without theinterviewer biasing their responses. In the third part, we askedthe interviewees to discuss the commenting practices and issuesthat they faced related to code comments. We also asked about
theimportanceofautomatedcommentgenerationtoolsandtheir
expectations on these tools.
Attheendofeachinterview,wethankedintervieweesandbriefly
informed them of our next plan.
2.1.2 Interviewees. We invited professionals from our networks in
thesoftwareindustrywhowereworkingfulltimeindifferentroles
(e.g.,developersandarchitects)toparticipateintheinterviews.We
sent 20formal invitationsto invitepotential interviewees,and 16
interviewees agreed to participate in the interviews from ten IT
companiesworldwide.These 16interviewees hadanaverage of4.2
years of professional experience in software development (min: 1,
max: 11, median: 4.2, sd: 2.5).
2.1.3 Data Analysis. Thefirstauthoranalyzedtheinterviewsby
transcribing them and then performed open coding to generatecodesoftheinterviewcontentsusingNVivoqualitativeanalysissoftware [
1]. Then, the second author verified the initial codes
createdbythefirstauthorandprovidedsuggestionsforimprove-
ment.Afterincorporatingthesesuggestions,twoauthorsseparately
analyzed the codes and sorted the generated cards into potential
statements. The overallCohen‚Äôs Kappa value between thetwo au-
thors was 0.78, which indicated substantial agreement between the
them. The two authors discussed their disagreements to reach a
common decision. To reduce bias from the two authors sorting the
cards to form initial statements, they both reviewed and agreedon the final set of statements. Eventually, based on the results of
the interviews, we derived 6 commenting practices, 6 commenting
issues, 5 conclusions for tool importance, 12/17/14 conclusions for
expectations on class/method/statement comment generation, and
11 factors that affect the adoption of code comment generation
tools.
2.2 Stage 2: Online Survey
To confirm the statements made by the interviewees (i.e., Stage 1),
weconductedananonymousonlinesurveywithmoreparticipants.
Thesurveyaimedtovalidateandquantifytheobservationsfrom
our interviews.
2.2.1 Design. The survey included different types of questions,
e.g., multiple-choice questions, short answer questions, and ratingquestions (in 5-point Likert scale: Strongly Disagree to Strongly
Agree). We included the category ‚ÄúI don‚Äôt understand‚Äù to filter
respondents who do not understand our brief descriptions.
The survey consists of six sections:
‚Ä¢Demographics: Thesurveyfirstaskedfordemographicinfor-
mation about the participants, including country/area of resi-
dence, primary job role, experience in years, and team size.
‚Ä¢Commenting Practices: This section investigated practition-
ers‚Äô commenting practices during software development, specif-
ically, their practices on writing and reading comments, thecommenting distributions in different projects, as well as the
commenting review practices in practitioners‚Äô teams.
‚Ä¢Commenting Issues: Thissectionfocusedoncommentingis-
sues that practitioners faced during software development, in-
cluding outdated comments, too long comments, and redundant
comments in projects.
‚Ä¢Tool Importance: This section provided respondents with a
brief description of code comment generation tools and asked
themhowtheyperceivetheimportanceofsuchlineoftoolswith
thefollowingstatements:(i) Essential:Iwillusethistoolevery
day to help software development or code comprehension; (ii)
Worthwhile : I will use this tool to help software development or
codecomprehension;(iii) Unimportant :Iwillnotusethistool;
(iv)Unwise: This tool will harm my or my team‚Äôs productivity.
Then, we asked practitioners about the importance aspects (e.g.,
improving development efficiency and code readability).
‚Ä¢Practitioners‚ÄôExpectations: Thissectioninvestigatedpracti-
tioners‚Äôexpectationsonthesetools,includingpreferredgranular-itylevels(i.e.,generatingclass-level,method-level,andstatement-
level comments). Then, we asked what information should be
included in generated comments, the locations to be commented
and preferred lengths for different level comments.
‚Ä¢Tool Adoption: This section asked respondents factors that
affect their likelihood to adopt a code comment generation tech-
nique. Specifically, we asked the minimum Turing Test rate ( the
percentage of generated comments that are indistinguishablefrom human-written comments by a human evaluator), maxi-
mumrevisedrate (thepercentageofthecontentinagenerated
comment that is needed to be revised before adoption), and min-
imum efficiency (the time of a tool to give a recommendation).
Attheendofthesurvey,weallowedrespondentstoprovidefree-
text comments, suggestions, and opinions about code commenting
and our survey. A respondent may or may not provide any final
comments.
We piloted the preliminary survey with a small set of practition-
ers who were different from our interviewees and survey takers.
We obtained feedback on (1) whether the length of the survey was
appropriate, and (2) the clarity and understandability of the terms.
We made minor modifications to the preliminary survey based on
thereceivedfeedbackandproducedafinalversion.Notethatthe
collectedresponsesfromthepilotsurveywereexcludedfromthe
presented results in this paper.
TosupportrespondentsfromChina,wetranslatedoursurvey
to Chinese before distributing it to them. We chose to make our
survey available both in English on Google Forms, and in Chinese
on a popular survey website in China [ 3]. We chose to make our
1695
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:32:16 UTC from IEEE Xplore.  Restrictions apply. ICSE 2022, May 21‚Äì29, 2022, Pittsburgh, PA, USA Xing Hu, Xin Xia, David Lo, Zhiyuan Wan, Qiuyuan Chen, and Thomas Zimmermann
Table 1: Participants roles & programming experience
Role Population <1 y 1-3 y 3-5 y 5-10 y >10 y
Development 534 32 110 162 173 57
Testing 59 71 31 81 6 5
Algorithm/ML Model Design 55 91 61 51 0 5
Project manager 14 0 013 1 0
Architect 23 0 039 1 1
Others 35 41 11 05 5
720 52 150 209 216 93
surveyavailableinChineseandEnglishastheearlieristhemost
spoken language and the latter is an international lingua franca.
2.2.2 Participant Recruitment. We followed two steps to invite
participants:
‚Ä¢WecontactedprofessionalswithinoursocialnetworkfromIT
companiesandaskedtheirhelptodisseminateoursurvey.Specif-
ically,wesent invitationstoourcontacts inTencent,Microsoft,
Alibaba, Google, Huawei, and other companies, encouraging
themtodisseminateoursurveytosomeoftheircolleagues.By
following this strategy, we received 598 responses.
‚Ä¢We mined GitHub repositories to extract their contributors‚Äô pub-
lic email addresses. Specifically, we sought repositories with the
toppopularopensourceprojects(basedontheirnumberofstars).
We sent emails to 2000 potential developers with a link to our
survey. We aimed to recruit open-source practitioners who have
software development experience in addition to professionals
workingin theindustry.Out oftheseemails,wereceivedeight
automaticrepliesnotifyingusoftheabsenceofthereceiver;two
receivers replied that they would not answer any survey. Finally,
we received 137 responses.
In total, we received 735 survey responses. We discarded two
incompletesurveysand13responseswithlessthantwominutes
ofsurveycompletiontime.Thedatareportedhereinwerefromthe
remaining720validresponses.The720respondentsresidedin26
countriesacrosssixcontinents.Thetoptwocountrieswherethe
respondentscamefromwereChinaandUnitedStates.Anoverview
ofthe surveyedparticipants andtheirexperience wasdepictedin
Table 1. Most participants were engaged in software development
and had 3-5 years of professional experience.
2.2.3 Data Analysis. We analyzed the survey results based on the
question types. For multiple-choice questions, we reported the
percentage of each option is selected. In terms of open-ended ques-
tions, we analyzed the survey results qualitatively by inspecting
responses.TounderstandtrendsintheLikert-scalequestions,we
createdbarcharts(manyofwhichareshownintheremainderof
thispaper).Wedropped‚ÄúIdon‚Äôtknow‚Äùratingsthatformasmall
minority (about 1%) of all ratings.ReplicationPackage.
Theinterviewguideandquestionnaireused
to run our study are available in our replication package [2].
2.3 Stage 3: Literature Review
Research papers about code comment generation techniques are
usuallypublishedinsoftwareengineeringandartificialintelligence
fields.Therefore,wewentthroughfullresearchpaperspublished
inICSE,ESEC/FSE,ASE,ICPC,SANER,MSR,ICSME,TSE,TOSEM,
EMSE,ACL,IJCAI,ICLR,NIPS,andAAAIfrom2010to2020.We
selectedpapersfromtheaboveconferencesandjournalsastheyare
premierpublicationvenuesinsoftwareengineeringandartificial
intelligenceresearchcommunities,andstate-of-the-artfindingsare
published in these conferences and journals.Figure 2: Comment practices and comment issues
Table 2: The agreement rate of statement [P1] and [P2] in
terms of practitioners‚Äô experiences.
StatementsExperiences<1 y 1-3 y 3-5 y 5-10 y >10 y
[P1]10.82 0.80 0.83 0.82 0.80
[P2]20.9 0.88 0.83 0.77 0.71
1[P1] I often write comments during software development
2[P2] I‚Äôm often confused when reading code without comments
Wereadthetitlesandabstractsofallpapersandjudgedwhether
each of the papers proposes a new code comment generation tech-
niquethatcanhelppractitionersgeneratecommentsduringsoft-
ware development. We included papers on IR-based code com-
ment generation (e.g., [ 17]), template-based code comment genera-
tion(e.g.,[ 42]),anddeep-learning-basedcodecommentgeneration
(e.g., [22]). We excluded papers on other types of software docu-
mentationgeneration(e.g.,commitmessagegeneration[ 23][28]),
and empirical study on comment generation (e.g., [4]).
Foreachcodecommentgenerationpaper,twoauthorsreadits
content and analyzed the capabilities of the proposed technique in
terms of the following factors: granularity level, what-to-comment,
where-to-comment, and evaluation criteria, respectively. For ex-
ample, Wei et al. [ 50] declared that they took the first sentence
orlineinJavaDocastheoutputoftheirproposedapproach,thus
we classified its length as one line. If a paper did not declare the
capabilities explicitly, the two authors checked the contents and
discussed its capabilities. For example, Moreno et al. [ 32] proposed
theFactory stereotype to generate comments for factory class; thus,
we inferred that it satisfied the statement [C9], i.e., commenting at
Classes with design patterns. Two authors discussed the differences
in the capability analysis and confirmed the final result throughfurther paper reading. Among the selected venues, we found no
commentgenerationpaperinMSRandICSME.Wewilldiscussthe
literature review results in Section 3.4.
3 RESULTS
Weexplaintheresultsofresearchquestionsthatinvestigatecom-
ment generation techniques from the perspective of practitioners.
3.1 RQ1: Commenting Practices and Issues
InRQ1,weexploredcommentingpractices,includingpractition-
ers‚Äôpracticesonwriting/readingcommentsduringdevelopment,
quantity and quality of comments in their projects, and the com-
mentingreviewpracticesintheirteam.Besides,wealsoreported
the main commenting issues that participants frequently face. Fig-
ure 2 illustrates respondents‚Äô rating of some statements related to
commenting practices and issues.
3.1.1 Commenting Practices. For developers ,wefindthatmore
than82% participantsoften writecode commentsduring software
1696
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:32:16 UTC from IEEE Xplore.  Restrictions apply. Practitioners‚Äô Expectations on Automated Code Comment Generation ICSE 2022, May 21‚Äì29, 2022, Pittsburgh, PA, USA
development.Interestingly,almostthesameproportionofpartic-
ipants(81%)areoftenconfusedwhenreadingcodewithoutcom-
ments.Althoughmostparticipantsoftenwritecomments,thequan-
tityofcommentsisstillnotenoughfordeveloperstoreadsource
code.Participants‚Äôopinionsonwritingandreadingcodecomments
arecontradictory.Asoneparticipantinoursurveystated:‚ÄúEvery-
one wants others to write as many comments as possible, but they
don‚Äôt want to write comments ‚Äù. Table 2 illustrates the agreement
rate(percentageofAgreeorStronglyAgree)ofstatements[P1]and
[P2] interms ofpractitioners‚Äô experiences.We can findthat there
are no clear differences in writing comments for practitioners with
different years of experience. H owever,junior practitioners are sta-
tisticallysignificantlymoreconfusedwhenreadingcodewithout
comments (with Mann-Whitney Wilcoxon Test p-value <0.001).
Consideringsoftwareprojects ,only37%participantsindicate
thatthere aremany high-qualitycode commentsin theirprojects.
Ononehand,thequantityofcodecommentswaslimited;onthe
other hand, lots of code comments had various issues making it
difficultforparticipantstoinferusefulinformationfromcomments.
In addition, 52% of participants agreed that larger projects usually
containedmuchhigherqualitycomments.Theseprojectsusually
neededteamcooperationandhigh-qualitycommentscouldhelp
toimprovecollaborativedevelopment.Intermsofprojects,high-
quality code comments were essential as participants stated in our
survey:(1)‚ÄúCommentsinprojectsareveryusefultounderstandthe
code logic, especially indispensable for facilitating project handover.‚Äù
(2) ‚ÄúComments can facilitate project maintenance and fault location ‚Äù.
Few teams (30%) conducted comment reviews during the code
review,eventhoughcommentqualitywasimportantfordevelopers
and software projects. Without comment review, issues in code
comments cannot be captured in time. In addition, one participant
pointedouttheimportanceofcommentsoncodereview,as‚ÄúDuring
the development process, it is important but not urgent, but it is
necessary for code review.‚Äù
For commenting practices, participants mainly have two atti-
tudes:
‚Ä¢/thumbs_up_altCommentsare necessary .Mostdevelopersthoughtthatcom-
ments were essential and should be provided along with the
sourcecode.Arespondentsharedher/hisexperienceonworking
with a legacy system to support the effectiveness of the code
comments. ‚ÄúThe system has a lot of comments in each program
inwhichhundredsoflinesofcommentsaccompanyseveralcode
lines.ThissystemwasintroducedtoHongKonginthe1980sand
then moved to Guangzhou and Beijing. Thanks to the abundant
(evenredundant)comments,thelegacysystemisstillmaintainable
being running for almost 40 years, and it is still the indispensable
coresystemofacompany.‚Äù Therespondentexpressedthattheir
experiencemadethemrealizedthebenefitofwritingpropercode
comments in the long term and made them optimistic about the
future of the comment generation tools.
‚Ä¢/thumbs_down_altCommentsare unnecessary .Afractionofdevelopersthought
code comments were unnecessary and writing self-explanatory
code was much more important. As a participant stated: ‚ÄúSource
codeisthebestcomments.Itismoreimportanttowritecodethat
iseasiertounderstand.Maintainingthesourceandcommentsat
the same time is time-consuming and reduces efficiency.‚ÄùFigure 3: Tool importance and the importance factors
/light_bulbFinding 1. Junior practitioners find it harder to read source
codewithout comments. Thequantity andquality ofcom-
mentsinsoftwareprojectsarelimitedandfewteamsconduct
comment reviews.
3.1.2 Commenting Issues. Figure2showedrespondents‚Äôratingsof
comment-relatedissuestheyfacedduringsoftwaredevelopment.
69% and 62% respondents considered lack of comments andgeneric
comments asthemainissues,respectively.Withoutcodecomments,
practitioners tend to read the source code and resorted to exter-
nal sources of information to understand the source code [ 5]. One
participant stressed the issue by using her/his personal experience:
‚ÄúWithoutcodecomments,thesourcecodeisnotonlyunreadablebyoth-
ers, but also may not be understood by myself after a period of time ‚Äù.
Genericcomment wasanotherissue duringsoftwaredevelopment.
Participantscannotgetusefulinformationfromthecodecomments
withoutmoredetails. Outdatedcomments wereperceivedasa fre-
quent issue by almost half (i.e., 47%) of the surveyed practitioners.
Thisissueoftenoccursduringsoftwaredevelopment.Developers
may forget or ignore the updates of comments when changing
sourcecode[ 29].Inconsistency betweencodeandcommentwere
alsoperceivedasafrequentissuebypractitioners(31%).27%ofthe
participants thought that redundant comment was a frequent issue.
Asone participantstated:‚ÄúThemore noise,theharder itisto notice
valuableinformationincomments....Redundantcommentsarefar
lessintuitivethanlookingatthecode...‚ÄùIntermsofthelengthofcode
comments,only16%ofparticipantsregardedtoolongcommentsasanissue.Thisissuemayincreasethetimetounderstandthesourcecode,asoneparticipantstressed:‚ÄúToolongcommentsmayaffectthe
efficiency, and I prefer precise and concise comments.‚Äù
/light_bulbFinding 2. Lack of comments and generic comments that
do not provide much information are the most frequently
encountered issues.
3.2 RQ2: Tool Importance
Figure 3 illustrated the percentages of ratings of various categories
(i.e., Essential, Worthwhile, Unimportant, Unwise) and importance
factors. We could notice that most respondents (i.e., 80%) gave
‚ÄúEssential ‚Äù and ‚ÄúWorthwhile ‚Äù ratings. Around 18.5% of respondents
ratedcommentgenerationtoolasan‚ÄúEssential ‚Äùtoolandwoulduse
it every day during software development.
We further investigated the factors that affected the importance
of the code comment generation tools. All factors received simi-
lar agreement from participants. As shown in Figure 3, improving
1697
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:32:16 UTC from IEEE Xplore.  Restrictions apply. ICSE 2022, May 21‚Äì29, 2022, Pittsburgh, PA, USA Xing Hu, Xin Xia, David Lo, Zhiyuan Wan, Qiuyuan Chen, and Thomas Zimmermann
code readability (78% AgreeorStrongly Agree ) was the most im-
portant factor among all importance factors. Comment generation
toolscouldhelptoimprovedevelopmentefficiency,understandthe
sourcecode,andimprovecodereadability.Asparticipantsstated:
(1) ‚ÄúAutomated comment generation tool can improve efficiency and
productivity ‚Äù; (2) ‚ÄúIf the tool can automatically extract the meaning
of the program, it will greatly improve the efficiency of code com-
prehension and to a certain extent can assist in determining whether
the program is correct; ‚Äù (3) ‚Äú... It improves code readability and at
the same time improve developers‚Äô coding ability, which can help
developers write more logically clear code.‚Äù
In addition, a good comment generation tool could also help
to check the consistency between code and comments (supported
by75%ofrespondents)andcheckwhetheracodesnippetisself-
explanatory (supported by 75% of respondents). Inconsistency be-
tweenthesourcecodeanditscommentwasacriticalissue.Agood
comment generation tool indicated that it could understand the
meaning of the source code. Participants could check the consis-tency by comparing the generated comments and existing com-
ments.Ontheotherhand,awell-generatedcommentalsoindicatedthatthegivensourcecodecouldbewellunderstoodbythemachine,
thus it was very self-explanatory.
We also analyzed the reasons why participants thought the tool
wasunwiseorunimportant(140participants).Thereasonsgiven
by them could be grouped into the following categories:
‚Ä¢Useless. Some participants (40) thought this tool was not mean-
ingful.Asoneparticipantstated:‚ÄúCommentsofthissort,which
just restate *what* the code does, in ‚Äònatural language‚Äô, are not
useful. They are redundant with the code itself, which a program-
mer should be able to understand at this level on its own, and once
created,theyriskbecomingoutofdateandinconsistentwiththe
actual code. Comments are useful when they include the human
insight that is *not* embodied in the code itself.‚Äù
‚Ä¢Not trustworthy. Some participants (32) doubt the accuracy of
thetool.Asoneparticipantstated:‚ÄúThegeneratedcodecomments
are probably incorrect and developers who do not write comments
will not revise the generated comments. It will further affect the
readability of the code ‚Äù
/light_bulbFinding 3. 80%ofthesurveyrespondentsthinkcodecom-
ment generation tools have the potential to be useful for
them. While this finding does not show much these tools
would actually help, it shows that most developers do not,
outofhand,dismisstheideaofcodegenerationasunneeded.
Althoughmostparticipantsthoughtsuchacommentgeneration
toolwasuseful,fewofthemhadusedsuchatool.Accordingtothe
16interviewees,only3ofthemhaveusedsuchtoolstogenerate
commentsordocumentationforsourcecode.Thesetoolshelpthem
to generate comment templates and they fill the comment content.
Other interviewees have never heard of such comment generation
toolsortechniques:(1) ‚Äú...IusedatoolnamedDoxygentogenerate
documentation according to the comments and I never heard of a tool
that can generate comments. -I7‚Äù (2)‚ÄúI just used the tool built-in the
IntelliJ to manage my comments. When I typed /**, it can generate a
template and I write the comment in the template. -I11‚ÄùFigure4:Thenumberofrespondentsspecifyingvariouspre-ferred granularity levels
Figure 5: Expectations on class-level comments
3.3 RQ3: Practitioners‚Äô Expectations
Different comment generation techniques generate comments for
different granularity levels, e.g., class, method, and statements.Figure 4 illustrated participants‚Äô preferred granularity levels ongenerated comments. Among all participants, 62%, 85%, and 28%participants preferred generating class-level, method-level, and
statement-level comments, respectively. Note that the percentages
did not add up to 100% since a respondent could indicate more
than one preferred granularity level. Among the three granularity
levels, method-level comments were the most needed comments to
begeneratedandasmallnumberofparticipantsneedstatement-
levelcomments.Inthefollowingpartofthissection,wewillreport
practitioners‚Äôexpectationsonthesethreelevelsofgranularityof
commentsfromdifferentaspects,e.g.,‚Äúwhattocomment ‚Äù, ‚Äúwhereto
comment‚Äù,andthe preferredlength.‚Äú Whattocomment ‚Äùcorresponds
to the information that generated comments should include before
participants adopt this tool. ‚ÄúWhere to comment ‚Äù corresponds to
thelocationthatparticipantsexpectthetooltogeneratecomments.Preferredlength aimstoinvestigatepractitionerspreferencesonthe
lengths of generated comments.
/light_bulbFinding4. Method-levelcommentsisthemostneededtype
of comments. A small part of participants (28%) expect tools
to generate statement-level comments.
3.3.1 RQ 3.1: Expectations on class-level comments. Figure 5 illus-
tratesparticipants‚Äôexpectationsonclasslevelcomments,including
‚ÄúWhat to comment ‚Äù and ‚ÄúWhere to comment ‚Äù.
What to Comment. Wenoticedthatthetop-3mostinformation
needed to be commented was: functionality, how to use a class,
andtechnical debt. 94% of them expected the functionality was
includedinthegeneratedcomments.Functionalitydescriptionwasimportantfordevelopers,asoneparticipantstated:‚ÄúThecommentis
the functionality description of the source code. It can help developers
to understand what the code does...‚Äù. The second top information
washow to use a class which usually described the expected set-up
of using the class. The Technical Debt such as TODO comments
1698
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:32:16 UTC from IEEE Xplore.  Restrictions apply. Practitioners‚Äô Expectations on Automated Code Comment Generation ICSE 2022, May 21‚Äì29, 2022, Pittsburgh, PA, USA
Figure 6: Expectations on method-level comments
could be used to track problems developers saw and ideas in the
class. To comment on a class, the workflow description was also
important for developers and 62% participants expected tools to
generateworkflowdiagramsforthem.Aclearworkflowdiagram
could help developers organize and understand the business logicjustlikeonerespondentstressed: ‚ÄúForabusinessproject,itismore
importanttodescribetheworkflowdiagramandtheversionupdates.‚Äù
Theimplementation details received the least agreement among all
statements.Asoneparticipantstated:‚Äú...Ifthetoolisjusttranslating
the code implementation logic, there is no different from reading thesource code...‚Äù.Where to Comment.
Commentingatsuitablelocationswasimpor-
tantforcodereadabilityandcodecomprehension.Commentingforclasseswithcomplexlogic receivedthemostagreements(morethan
91%respondents).Accordingtointerviewees,complexclasseswerechallengingtounderstandastheyusually(1)havelongcodelength;
(2)havemanyloopsandconditionalstatements(e.g.,if/switchstate-
ments); (3) have many API invocations. It is time-consuming fordevelopers to read these classes and comments are essential forunderstanding. The other three types of classes received similaragreements, i.e., 86%, 85%, and 82% respondents agree that com-
mentsareneededfor classeswithdesignpatterns, utilityclasses,and
user-defined exceptions, respectively. Classes with design patterns
usually had special solutions and algorithms. Utility classes pro-
videdmanymethodsformultipleotherclasses(sharedcode)and
could be reused many times in a codebase. They should be well-
commentedforeaseofcodereuse. User-definedexceptions should
be commented the trigger conditions in exceptions.
/light_bulbFinding 5. For class-level comments, functionality and how
touseaclassarethemostimportantinformationthatpartic-
ipants expect automated comment generation tool to gener-ate. Classes with complex logics and design patterns should
be well-commented.
3.3.2 RQ 3.2: Expectations on method-level comments. Figure 6
illustrated participants‚Äô expectations on method-level comments.What to Comment.
Similar to expectations on class-level com-
ments,functionality andhow to use a method were the top-2 pre-
ferred information that should be included in method-level com-ments. Participants also provided the least support to comments
documenting Implementation details. Compared to class-level com-
ments, fewer participants agreed to generate comments that in-
cluded aworkflow diagram and highlight technical debt. 86% partic-
ipantsagreedtogeneratecommentswith InputandOutput infor-
mation.ParametersandreturntypesweretwoimportantpartsofFigure 7: Expectations on statement-level comments
methods.Generatingthe InputandOutput informationwashelpful
for developers to call methods correctly. 66% participants expected
a code comment generation tool to generate comments with thedesign rationale that included authors‚Äô intent and why a method
exists.Asoneparticipantstated:‚ÄúCommentshavetobeinsightful
and not just describing what the code is doing. Comments are meant
to provide background to what the code is doing and why. ‚Äù 62% of
allrespondentssupportedcommentsthatincluded examplecases.
Examplecases providedconcretedetailsonhowamethodshould
be used.Where to Comment.
Similar to class-level comments, almost all
respondents (92%) supported commenting complex methods. The
next important methods requiring comments were those that were
non self-explanatory (supported by 91% respondents). The next im-
portant types of methods requiring comments were tricky method,
key logic or algorithm method, and interfaces. There was no clear
winneramongthesethreetypesofmethods. Trickymethods (e.g.,
check numbers are equal or not using bitwise XOR operators in-
stead of comparison operators) usually had special algorithms and
othersmightbeconfusedbyauthors‚Äôintentbehindthesourcecode.
Key logic or algorithm methods were mainly for processing busi-
ness logic and good comments were helpful. Commenting methods
in interfaces was essential as they were often invoked by others.
Commentingdeprecatedmethodswasalsoconsideredhelpful(as
supported by 71% of the respondents).
/light_bulbFinding 6. For method-level comments, information about
functionality,howtouse,inputandoutput,anddesignratio-
nale are considered important. A high proportion of respon-
dentsexpectautomatedcommentgenerationtooltogeneratesuchpiecesofinformation.Inotherwords,commentsshould
explain code from ‚Äúwhat ‚Äù, ‚Äúhow‚Äù, and ‚Äúwhy ‚Äù aspects. All the
differentkindsof methods exceptthedeprecatedmethods
received a similar level of support from respondents.
3.3.3 RQ 3.3: Expectations on statement-level comments. Figure7
illustratedpractitioners‚Äôexpectationsonstatement-levelcomments.
What to Comment. Similar to class-level comments and method-
levelcomments,themostinformationshouldbeincludedwas func-
tionalityanddesignrationale.Theimplementationdetailswerealso
theleastimportantamongallstatements. Techniquedebt andwarn-
ing(e.g.,‚ÄúDon‚Äôtinputint-typevalues‚Äù)receivedsimilaragreements.
Where to Comment. 93% of participants agreed to add comments
oncomplex code statements. 89% participants expected this tool
generatecommentsfor specialstatements.Thesestatementsusually
processedspecialbusinesslogic,suchas,astatementonlyaccepted
1699
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:32:16 UTC from IEEE Xplore.  Restrictions apply. ICSE 2022, May 21‚Äì29, 2022, Pittsburgh, PA, USA Xing Hu, Xin Xia, David Lo, Zhiyuan Wan, Qiuyuan Chen, and Thomas Zimmermann
Figure 8: Participants‚Äô expectations on lengths for different
granularity comments
(a) Evaluation criterion
(b) Effectiveness
(c) Minimum efficiency
Figure 9: Factors that affect practitioners‚Äô likelihood toadopt a code comment generation technique.
strings with a special format. Hard coding andtricky statement
received88%and89%agreements,respectively.81%and73%par-
ticipants rated the regular expressions andlambda expressions that
should be commented.
/light_bulbFinding7. Forstatement-levelcomments,mostrespondents
requiresuchcommentstoinclude functionality anddesign
rationale information. All the types of statements, except
theLambdaexpressions statement,receivedsimilarlevelof
support from respondents.
3.3.4 RQ 3.4: Preferred Length. Figure8demonstratedpractition-
ers‚Äôexpectationsoncommentlengthofcommentsforcodeunits
of different levels of granularity (classes, methods, and statements).
Wecouldobservethatmostrespondentssupport2-3linestobethe
most suitable length. For class-level comments, many participants
also agreed to generate comments with 4-5 lines.
/light_bulbFinding8. Expecttoolstogeneratecommentswith2-3lines
for the three levels of granularity (class, method, statement).
3.3.5 RQ 3.5: Adoption Factors. Figure 9 illustrated factors that
affectpractitioners‚Äôlikelihoodtoadoptacodecommentgeneration
tool, including evaluation criterion, effectiveness, and efficiency.
Evaluation Criteria. We asked participants‚Äô opinions on evaluat-
ing code comment generation tools. We observed that the top-3preferredevaluationcriteriawere: amountofadditionalinformation
(i.e., amount of information beyond what can be easily gleaned
from scanning the source code), content adequacy (i.e., the amount
of contentcarried over fromthe input codeto the generatedcom-
ments), and conciseness. More than 88% participants rated agree or
stronglyagreeforthesethreecriteria.82%participantscaredabout
the fluency and grammaticality of the generated comments. 76%participants thought the similarity between machine-generated
commentsandhuman-writtencommentswasimportant,whilethe
overlapped N-grams between them received the least support (63%).
Effectiveness. Figure 9(b) showed the percentages of respondents
who were satisfied with different rates. The satisfaction rate would
be80%ifatleast60%generatedcommentscouldpasstheTuring
Test.Ifthegeneratedcommentscontained60%contentofthesource
code,thesatisfactionratewouldbe80%.Iftherevisedcontentin
the generated comments was no more than 40%, the satisfaction
ratewouldbe82%.Comparedtowritingcomments,ifaparticipant
couldsave 60%of timeusing thetools, thesatisfaction ratewouldbe 89%.Efficiency.
Figure 9(c) showed the maximum amount of time prac-
titioners were willing to wait for a comment generation technique
to provide a recommendation. Few respondents were willing to
wait more than one minute for a comment generation technique to
doitsjob(lessthan6%).Mostparticipantsexpectedthistoolcan
finish its computation in less than 5 seconds.
3.4 RQ4: Current state-of-the-art research
At the end of our literature review process, we totally identified
25 papers from the premier publication venues in software engi-
neeringandartificialintelligencecommunities.Table3showedthe
capabilitiesofthestate-of-the-artcodecommenttechniques.The
Likertscorewastheaveragescoreofdifferentagreements:Strongly
Disagree (1 score), Disagree (2 scores), Neutral (3 scores), Agree (4
scores), Strongly Agree (5 scores).Granularity Level
: From Table 3 we could observe that only one
paper (i.e., [ 32]) worked at class-level, which was the second most
preferredoption.Mostpapersworkedatthemethod-levelgranu-
laritythatwasthemostpreferredoption.Severalpapersworkedat
the statement-level. We provided more detailed information below:
‚Ä¢Class-level comments : Only Moreno et al. [ 32] proposed a
class-level comment generation technique. This work generated
functionalitydescriptionsforcomplexclasses(e.g.,classthatcon-sistsof accessorsandmutators)and classeswithdesign patterns.
‚Ä¢Method-level comments : 17 papers proposed approaches to
generate comments for methods. Most of the proposed tools
mainly generated functionality comments that described what a
methoddoes.Twopapersgeneratedcommentstodescribehowtouseamethod.Inaddition,threepaperscouldgeneratecomments
to explain the design rationale and answer why a method exists.
Althoughimplementationdetailswerenotpreferredbyalarge
majorityofourrespondents,fourpapersproposedtechniquestogeneratecommentswithimplementationdetails.Onlyonepaper
aimed to generate comments for complex methods, i.e., methods
with many API invocations.
‚Ä¢Statement-level comments :Therewerefourpapersgenerat-
ing comments for statements. These tools generated comments
thatdescribedthefunctionalityofstatements.Amongthem,two
1700
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:32:16 UTC from IEEE Xplore.  Restrictions apply. Practitioners‚Äô Expectations on Automated Code Comment Generation ICSE 2022, May 21‚Äì29, 2022, Pittsburgh, PA, USA
Table 3: Capabilities of Current State-of-Research.
StatementLikert
scorePapers
Whatto Comment
Functionality [C1]4.35[32]
How to use this class [C2]4.28-
Implementation details [C3]3.43-
Business background [C4]3.79-
Workflow diagram [C5]3.69-
Technical Debt [C6]3.88-
Where to Comment
Complex Class [C7]4.34[32]
User-define d Exception [C8]4.09-
Classwith design patterns [C9]4.25[32]Class-level comments
Utilityclasses [C10] 4.17-
Whatto Comment
Functionality [M1] 4.36[6,7, 14, 19, 20, 22, 25, 26, 29, 37, 38, 42, 49, 50]
How to use this method [M2] 4.24[30][31]
Implementation Details [M3] 3.44[38][29][30][31]
Example cases[M4] 3.76[31]
Input&Output [M5] 4.20[44][34]
DesignRationale [M6] 3.81[42][30][31]
Workflow diagram [M7] 3.52-
Technical debt [M8] 3.79-
Where to Comment
Complex Method [M9] 4.36[21]
Tricky Method [M10] 4.18-
Deprecated Method [M11] 3.93-
Key logic and algorithm method [M12] 4.24-
Methods in interfaces [M13] 4.22-
NonSelf-explanatory methods [M14] 4.30-Method-level comments
Other - -[6,7, 14, 19, 20, 22, 25, 26, 34, 37, 38, 42, 44, 48‚Äì50, 53]
Whatto Comment
Functionality [S1] 4.17[52][43][11][22]
Implementation details [S2] 3.86-
DesignRationale [S3] 4.17-
Technical debt [S4] 3.91-
Warning [S5] 4.04-
Where to Comment
Complex Statement [S6] 4.39[52][43]
Harding Coding [S7] 4.21-
Tricky Statement [S8] 4.28-
Special Statement [S9] 4.28-
Lambda Expression [S10] 3.93-
RegularExpression [S11] 4.12-Statement-le vel comments
Other - [11][22]
1line - -[7,11, 14, 19‚Äì22, 25, 26, 29, 42‚Äì44, 48‚Äì50, 52, 53]
2-3lines - -[32]
4-5lines - -[30][31]
>5lines - --Length
Other - -[37,38]
Fluency and Grammaticality [A1]4.06[32][50][22]
ContentAdequacy [A2]4.21[32][50][42][52][30][31][22]
Conciseness [A3]4.22[32][42][52][30][31]
Similarity [A4]4.03[50][20][53]
Amountof additional information [A5]4.27-Evaluation
Overlapped N-grams [A6]3.74[6,7, 11, 14, 19‚Äì22, 25, 26, 29, 34, 48‚Äì50, 53]
papersaimedtogeneratecommentsforcomplexstatements,e.g.,
API invocation statements.
/light_bulbFinding9. Mostpapersgeneratecommentstodescribewhat
a code snippet does (e.g., functionality and implementation
details), while a few papers describe how to use and whyit exists. Considering the types of code units that need to
becommentedon,moststudiesgeneratecommentsforall
types of codeunits. However, commenting atthe right place
is far better than commenting anywhere.
PreferredLengths: AsTable3showed,mostproposedtoolsaimed
to generate one line code comments. Only 5 papers proposed tools
togeneratedcommentswithmorethanoneline.However,2-3lines
comments were supported by most participants.
/light_bulbFinding 10. There isa greatdiscrepancybetweenthe cur-
rent tools (1 line) and most practitioners expect (2-3 lines)
on the length of comments.
Evaluation: Wecouldfindthatmostpapersevaluatethequality
of generated comments by computing the overlapped N-grams be-
tweengeneratedcommentsandhuman-writtencomments,suchas
BLEU [35], METEOR [ 10], and ROUGE [ 27]. These criteria usually
involvedautomatedevaluationofgeneratedcomments.Unfortu-
nately,evaluatingoverlappedN-gramswasnotpreferredbyalarge
majority of our respondents. No paper evaluated the amount ofadditional information beyond what can be easily gleaned fromscanning the source code, which most respondents expected to be
used to evaluate the generated comments. There are 6, 5, 3, and
3papersthatevaluatedtheeffectivenessoftheproposedtoolsin
terms of content adequacy, conciseness, similarity, and fluency and
grammaticality, respectively.
/light_bulbFinding11. Mostpapersfocusonmeasuringtheoverlapped
N-grams between generated comments and human-written
comments that is not preferred by a large majority of ourrespondents. The criterion amount of additional informa-
tion(i.e.,amountofinformationbeyondwhatcanbeeasily
gleaned from scanning the source code) that practitioners
valued most is ignored by all studies.
4 DISCUSSION
4.1 Implications
Our results highlight a number of points to be further discussed
and several implications for the research community:
4.1.1 Comment completion tools. Inadditiontogeneratingcom-
mentsfromsourcecode,manydevelopersalsoexpectatoolthat
cancompletecommentswhiletheyarewritingcomments.Onecon-
cernof practitionersaboutcomment generationtoolsis thatthey
have to spend additional effort to check if the generated comments
can express the source code. In fact, our participants mentioned
this concern, e.g., ‚ÄúI don‚Äôt believe this tool can generate correct com-
ments,thusIhavetodouble-checkthegeneratedcomments.Compared
with writing comments myself, the checking process is more time-
consuming.-I2‚Äù Acommentcompletiontoolcanalleviatethisissue,
and developers can choose comment recommendations (e.g., the
next token, phrase and even sentence) while writing comments. It
can not only speed upthe commenting process, but also allow the
developer to choose the content of the comments. As one practi-
tionerstated: ‚ÄúInsteadofacommentgenerationtool,Iexpectatool
that can complete comments during the development, just like the
code completion tools in IDE. In this way, I can write comments more
efficiently. - I2‚Äù
4.1.2 Identifying where to write comments. According to the re-
plyofourintervieweesandrespondentsofoursurvey,toomany
comments are also harmful to code readability and understand-
ing.Fromtheliteraturereview,wecanobservethatmostpapersgeneratecommentsforanycodesnippetsexceptconstructorsor
testcases[ 19,26].However,respondentsexpecttoolstogenerate
comments for complex and non self-explanatory code instead ofany pieces of code. They point out that it is unnecessary to gen-erate comments for source code that is easy to understand. It is
challenging for existing techniques to generate accurate comments
for a complex piece of code with long lengths, many API invoca-
tions,andmanyconditionalstatements.Thus,commentgeneration
techniques should by improved to generate accurate comments for
particular locations that practitioners expect.
4.1.3 Describing why a code snippet exists. Inadditiontodescribing
whata codesnippet doesand how touse it,codecomments should
describewhyacodesnippetexists,i.e.,thedesignrationaleandtheintentofadeveloper.However,fewstudiescangeneratecomments
withthisinformation.Thisisalsoanimportantfactorasonepartic-
ipantstated:‚Äú Agoodcommentexplains"why"not"how."Acomputer
1701
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:32:16 UTC from IEEE Xplore.  Restrictions apply. ICSE 2022, May 21‚Äì29, 2022, Pittsburgh, PA, USA Xing Hu, Xin Xia, David Lo, Zhiyuan Wan, Qiuyuan Chen, and Thomas Zimmermann
is not able to explain "why." Only a human can do that. To generate a
comment automatically means that a program must understand the
author‚Äôsintent.Thiswouldrequireartificialintelligence.‚ÄùThus,to
improve the trustworthiness of comment generation techniques,
these techniques should have to mine the intent behind the source
code.
4.1.4 Evaluation Criterion. Evaluation criterion is another impor-
tant factor that should satisfy practitioners‚Äô expectations. Existing
studiesusuallyevaluatethegeneratedcommentsbycomparingthe
generated comments with human-written comments in terms of
overlapped N-grams (such as BLEU scores and ROUGE). However,
theoverlappedN-gramsistheleastimportantamongallevaluationcriteria.Practitionersexpecttoevaluatetheamountofadditionalin-formation,whereasnoneofthecollectedpapershasmentionedthis
metric. In addition, other metrics, such as Turing Test passing rate,
revisedrate,andtime-savingrate,arealsomissinginpublications.
4.1.5 Detecting inconsistencies between comments and source code.
Among all commenting issues we highlighted in our survey, in-
consistency between comments and source code is not the most
frequentlyencounteredissues,butisthemostseriousissue.Accord-ingtoTanetal.[
46],manysoftwarebugsarecausedbyamismatch
between programmers‚Äô intention and code‚Äôs implementation. From
our survey, 74% respondents agree that a good comment genera-
tion tool can help to check the consistency between comments and
code. A tool that can detect inconsistency and recommend a good
comment simultaneously is needed by practitioners.
4.1.6 Checking if the source code is self-explanatory. Writingself-
explanatory code is a common practice for developers. During the
developmentprocess,developersusuallycheckifthecodeisself-
explanatory.I3stressedthatagoodcommentgenerationtoolcan
also help her/him to check the code automatically: ‚ÄúFor me, a com-
mentgenerationtoolcouldnotonlyhelpmetowritecommentsand
understandprograms,butalsocancheckifmycodeisself-explanatory.
If the generated comments can express my code, it means that my
code can be comprehended by machines, thus indicates that the code
is self-explanatory.-I3 ‚Äù
4.2 Threats to Validity
Itispossiblethatsomeofoursurveyrespondentsdonotunderstand
code comment generation techniques or our questions well, and
thustheirresponsesmayintroducenoisetothedatathatwecol-
lect. To reduce this threat, we drop responses submitted by people
whoareneitherprofessionalsoftwareengineersnorparticipantsof
open source projects. We also drop responses by respondents who
completethesurveyinlessthantwominutes.Still,wecannotfully
ascertain whether participant responses are accurate reflectionsof their beliefs. This is a common and tolerable threat to validity
in many past studies about practitioners‚Äô perceptions and expecta-
tions, e.g., [ 24], which assume that the majority of responses truly
reflectwhatrespondentstrulybelieve.Anotherthreatisthatour
participantsmaynotberepresentationsoftypicalsoftwareengi-
neersandthatasresultourfindingsmaynotapplytoothers.Since
we surveyed employees of many software companies as well as
open source, we believe this is a minor threat for our study.5 RELATED WORK
The two major lines of research related to our work are (i) develop-
ingtoolsandapproachestoautomaticallygeneratecodecommentsand(ii)empiricallyinvestigatingsoftwaredocumentationpractices.
5.1 Automated Code Comment Generation
There has been much work proposing techniques to support the
automatedgenerationofcodecomments.Thesetechniquesvary
frommanually-craftedtemplates[ 31,32,42],IRtechniques[ 13,51]
to deep-learning-based models [ 19,22]. Sridhara et al. [ 42] and
Moreno et al. [ 32] define heuristics and stereotypes to select the
information and create summariesthrough manually-crafted tem-
plates. IR-based approaches [ 17] usually leverage IR techniques,
suchasLSIandVSM,tochoosetoptermsfromgivencodesnippets.
Some researchers [ 51,52] retrieve a similar code snippet from a
codebase and use its comment to generate comments. Many neural
networkshavebeenproposedtogeneratecommentsbytraining
on large-scale code corpora in recent years. Iyer et al. [ 22] propose
anencoder-decoderframework togeneratecommentsfor C#and
SQL statements. Inspired by the neural machine translation, Hu et
al.[19]proposetheDeepComtogeneratecommentsforJavameth-
odsbytheseq2seqmodel.Tointegratethestructure-informationofthesourcecode,Huetal.[
19,20]andLeclairetal.[ 26]proposecom-
biningthesequentialASTinformationandsemanticinformation
togethertogeneratecomments.Chenetal.[ 12]exploitedcomment
categories to boost code summarization. In addition, some stud-
ies[53][50]combinethesethreetechniques,includes,templates,
IR, and neural networks.
5.2 Studies on documentation practices
Studiesondocumentationpracticesarehighlyrelatedtothiswork[ 4,
5,8,15,18,40,41,45,47]. Some studies focused on empirical re-
search of general software documentation aspects, including tuto-
rials, logs, and code comments [ 4,5]. Table 4 shows an overview
ofempiricalstudiesonsoftwaredocumentationpractices.Forex-
ample,Aghajanietal. [ 5]analyzedtheissuesindifferenttypesof
software documentation by mining open source software reposito-
ries and artifacts related to software documentation. They [ 4] also
presentedpractitioners‚Äô perspectivesonsoftware documentation
bysurveyingsoftwarepractitioners.Somestudiesinvestigateda
specifictypeofdocumentation.Forexample,Headetal.[ 18]investi-
gatedtheinformationthatmaybemissingfromAPIdocumentation
and provided an understanding of trade-offs of improving miss-ingdocumentationinheaderfiles.Sohanetal.[
40]andUddinet
al[47]alsoinvestigatetheAPIdocumentation.Alsuhaibanietal.[ 8]
conductaquestionnairewithsoftwaredeveloperstoanalyzethemethod names.Safwan and Servant [
39] investigatedhowdevel-
opersdecomposetherationaleofcodecommits.Alsorelatedare
studies that investigated comment types [ 36]. Pascarella et al. [ 36]
focus on analyzing the comment types that developers write in
sourcecodefilesandautomatingclassifyingcodecomments.Thesestudiesmainlyinvestigatedthedocumentationpracticesandissues.
In addition, they are limited in analyzing ‚Äúwhat ‚Äù and ‚Äúwhere ‚Äùt o
commentthatdevelopersexpectfordifferenttypesofcomments.
Different from the afor ementioned prior works, we not only reveal
the issues with code comments, but also provide detailed expec-
tationsthatdevelopershavetoimprovethecommentgeneration
1702
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:32:16 UTC from IEEE Xplore.  Restrictions apply. Practitioners‚Äô Expectations on Automated Code Comment Generation ICSE 2022, May 21‚Äì29, 2022, Pittsburgh, PA, USA
Table 4: Summary of previous works on software documentation practices
Study Artifacts Methodology Summary of findings
Fluri et al. [15] Code Comments Investigationwiththreeopensourcesys-
temsWhen code and comments coevolve, both are changed in the
same revision: 97% of comment changes are done in the samerevision as the associated source code change. But code and
comments rarely co-evolve
Uddinet al. [47] API documentation Questionnaire with 230 software profes-
sionalsRespondentsprioritizedaddressingfivecontent-relatedproblems,
including incompleteness, ambiguity, unexplained examples, ob-
soleteness, and inconsistency
Pascarella et al. [36] Code comments Exploratory investigation on six major
Java OSS systemsClassify comments into 16 inner categories and 6 top categories
and themost prominent category ofcomments summarizes the
purpose of the code
Sohanet al. [40] Usage Examples in API
documentationStudy with 26 developers REST API client developers face productivity problems with
usingcorrectdatatypes,dataformats,requiredHTTPheaders
and request body when documentation lacks usage examples.
Headet al. [18] API Documentation for
C++Interviews with 18 developers and 8 API
maintainersUpdating documentation may provide only limited value fordevelopers, while requiring effort maintainers don‚Äôt want to
invest.
Safwan and Ser-
vant [39]Code Commits Interviewswith20softwaredevelopers
and questionnaire with 24 developersSoftwaredevelopersdecomposetherationaleofcodecommits
into 15 separate components and the most frequent components
are committer, modifications, and location.
Aghajani et al. [5] SoftwareDocumentation Qualitativelyanalyze878artifactsfrom
open source software repositoriesBuilt163typesofdocumentationissuesandfrequentissuesre-
lated to the correctness, up-to-dateness and completeness of the
information reported in the documentation.
Stapleton et al. [45] Code Comments Humanstudyinvolving45bothuniver-
sitystudentsandprofessionaldevelopersparticipants performed significantly better using human-written
summaries versus machine-generated summaries.
Aghajani et al. [4] SoftwareDocumentation Questionnairewith146professionalsoft-
ware practitionersCodeCommentandContributionGuidelinewerethetwodoc-
umentation types considered as more useful for the different
tasks.
Alsuhaibani et al. [ 8]Method Names Questionnaire with 1,604 software devel-
opersDevelopersaresupportiveofclearlyarticulatingmethodnamingstandardsandfeelithasapositiveimpacttocodecomprehension.
Sondhiet al. [41] Javadoc comments Studymethoddocumentationandcom-
mits logs of 11 open-source projects62% of the studied Javadoc comments being dependent on other
entities
Arafat and Riehle [ 9]Code Comments Investigation on density of comments in
open source software codeSuccessfulopensourceprojectsfollowaconsistentpracticeof
documenting their source code and the comment density is inde-
pendent of team and project size.
Nielebock et al. [33] Code Comments Questionnaire with 277 developers Comments seem to be considered more important in previous
studiesandbytheirparticipantsthantheyareforsmallprogram-
ming tasks.
tools. Moreover, we identify and present the gap between practi-
tioners‚Äô expectations and capabilities of existing tools proposed by
variousstudies.Ourfindingsshowthecodecommentgeneration
tools have the potential to be useful for developers.
6 CONCLUSION AND FUTURE WORK
Codecommentgenerationisapopularareaofresearchinrecent
years. In this work, we interviewed 16 professionals and surveyed
720 practitioners on commenting practices and issues they face
and their expectations on code comment generation tools. Prac-
titioners are enthusiastic about research in comment generationtechniques and expect tools to generate comments for different
granularitylevels(especiallyclassandmethodlevels).Practitionersexpectacommentgenerationtosatisfyfactorsintermsofcomment
content, comment locations, evaluation criteria, effectiveness, and
efficiency.Wealsocomparecapabilitiesofcurrentstate-of-researchin comment generation with practitioners‚Äô expectation for adop-
tiontoidentifydiscrepancies.Wepointoutthelimitationsofthe
currentstate-of-researchandavenuesforfutureworktomakecode
comment generation techniques well-adopted by practitioners. Fu-
ture studies could put more effort into generating comments at the
rightlocationsinsteadofgeneratingcommentsforalltypesofcode
units.Besides, studiescouldputmoreeffort intoinvestigatingtheevaluation criteria that practitioners valued most.
ACKNOWLEDGMENTS
ThisresearchwassupportedbytheNationalScienceFoundation
ofChina(No.62141222andNo.U20A20173)andtheNationalRe-
search Foundation, Singapore under its Industry Alignment Fund ‚Äì
Prepositioning (IAF-PP) Funding Initiative. Any opinions, findings
and conclusions or recommendations expressed in this material
are thoseof theauthor(s) anddo not reflectthe viewsof National
Research Foundation, Singapore.
1703
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:32:16 UTC from IEEE Xplore.  Restrictions apply. ICSE 2022, May 21‚Äì29, 2022, Pittsburgh, PA, USA Xing Hu, Xin Xia, David Lo, Zhiyuan Wan, Qiuyuan Chen, and Thomas Zimmermann
REFERENCES
[1] 2021. Nvivo qualitative data analysis software.
[2]https://github.com/xing-hu/Practitioners-Expectations-on-Automated-Code-
Comment-Generation.
[3] https://www.wjx.cn.[4]
Emad Aghajani, Csaba Nagy, Mario Linares-V√°squez, Laura Moreno, Gabriele
Bavota,MicheleLanza,andDavidCShepherd.2020. Softwaredocumentation:thepractitioners‚Äôperspective.In 2020IEEE/ACM42ndInternationalConference
on Software Engineering (ICSE). IEEE, 590‚Äì601.
[5]EmadAghajani,CsabaNagy,OlgaLuceroVega-M√°rquez,MarioLinares-V√°squez,
Laura Moreno, Gabriele Bavota, and Michele Lanza. 2019. Software documenta-
tion issues unveiled. In 2019 IEEE/ACM 41st International Conference on Software
Engineering (ICSE). IEEE, 1199‚Äì1210.
[6]WasiAhmad,SaikatChakraborty,BaishakhiRay,andKai-WeiChang.2020. A
Transformer-based Approach for Source Code Summarization. In Proceedings of
the58thAnnualMeetingoftheAssociationforComputationalLinguistics.4998‚Äì
5007.
[7]Uri Alon, Shaked Brody, Omer Levy, and Eran Yahav. 2018. code2seq: Gen-erating sequences from structured representations of code. arXiv preprint
arXiv:1808.01400 (2018).
[8]Reem S Alsuhaibani, Christian D Newman, Michael J Decker, Michael L Collard,
andJonathanIMaletic.2021. OntheNamingofMethods:ASurveyofProfes-
sionalDevelopers.In 2021IEEE/ACM43rdInternationalConferenceonSoftware
Engineering (ICSE). IEEE, 587‚Äì599.
[9]OliverArafatandDirkRiehle.2009. TheCommentingPracticeofOpenSource.In
Proceedings of the 24th ACM SIGPLAN Conference Companion on Object Oriented
Programming Systems Languages and Applications (Orlando, Florida, USA) (OOP-
SLA‚Äô09).AssociationforComputingMachinery,NewYork,NY,USA,857‚Äì864.
https://doi.org/10.1145/1639950.1640047
[10]Satanjeev Banerjee and Alon Lavie. 2005. METEOR: An automatic metric for
MT evaluation withimproved correlation with humanjudgments. In Proceedings
of the acl workshop on intrinsic and extrinsic evaluation measures for machine
translation and/or summarization. 65‚Äì72.
[11]RuichuCai,ZhihaoLiang,BoyanXu,YuexingHao,YaoChen,etal .2020. TAG:
Type Auxiliary Guiding for Code Comment Generation. In Proceedings of the
58th Annual Meeting of the Association for Computational Linguistics. 291‚Äì301.
[12]Qiuyuan Chen, Xin Xia, Han Hu, David Lo, and Shanping Li. 2021. Why mycodesummarizationmodeldoesnotwork:Codecommentimprovementwith
category prediction. ACM Transactions on Software Engineering and Methodology
(TOSEM) 30, 2 (2021), 1‚Äì29.
[13]BrianPEddy,JeffreyARobinson,NicholasAKraft,andJeffreyCCarver.2013.
Evaluatingsourcecodesummarizationtechniques:Replicationandexpansion.
In2013 21st International Conference on Program Comprehension (ICPC). IEEE,
13‚Äì22.
[14]PatrickFernandes,MiltiadisAllamanis,andMarcBrockschmidt.2018. Structured
neural summarization. arXiv preprint arXiv:1811.01824 (2018).
[15]Beat Fluri, Michael Wursch, and Harald C Gall. 2007. Do code and comments
co-evolve?ontherelationbetweensourcecodeandcommentchanges.In 14th
Working Conference on Reverse Engineering (WCRE 2007). IEEE, 70‚Äì79.
[16]David Gros, Hariharan Sezhiyan, Prem Devanbu, and Zhou Yu. 2020. Code toComment ‚ÄúTranslation‚Äù: Data, Metrics, Baselining & Evaluation. In 2020 35th
IEEE/ACM International Conference on Automated Software Engineering (ASE).
IEEE, 746‚Äì757.
[17]SoniaHaiduc,JairoAponte,LauraMoreno,andAndrianMarcus.2010. Onthe
useofautomatedtextsummarizationtechniquesforsummarizingsourcecode.
In2010 17th Working Conference on Reverse Engineering. IEEE, 35‚Äì44.
[18]Andrew Head, Caitlin Sadowski, Emerson Murphy-Hill, and Andrea Knight.2018. Whennottocomment:questionsandtradeoffswithapidocumentation
forc++projects.In Proceedingsofthe40thInternationalConferenceonSoftware
Engineering. 643‚Äì653.
[19]Xing Hu, Ge Li, Xin Xia, David Lo, and Zhi Jin. 2018. Deep code comment gener-ation.In2018IEEE/ACM26thInternationalConferenceonProgramComprehension
(ICPC). IEEE, 200‚Äì20010.
[20]Xing Hu, Ge Li, Xin Xia, David Lo, and Zhi Jin. 2020. Deep code comment
generationwithhybridlexicalandsyntacticalinformation. EmpiricalSoftware
Engineering 25, 3 (2020), 2179‚Äì2217.
[21]Xing Hu, Ge Li, Xin Xia, David Lo, Shuai Lu, and Zhi Jin. 2018. Summariz-ing source code with transferred api knowledge.(2018). In Proceedings of the
Twenty-Seventh International Joint Conference on Artificial Intelli-gence (IJCAI
2018), Stockholm, Sweden, 2018 July 13, Vol. 19. 2269‚Äì2275.
[22]Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, and Luke Zettlemoyer. 2016.
Summarizingsourcecodeusinganeuralattentionmodel.In Proceedingsofthe
54thAnnualMeetingoftheAssociationforComputationalLinguistics(Volume1:
Long Papers). 2073‚Äì2083.
[23]Siyuan Jiang, Ameer Armaly, and Collin McMillan. 2017. Automatically generat-
ing commit messages from diffs using neural machine translation. In 2017 32nd
IEEE/ACM International Conference on Automated Software Engineering (ASE).IEEE, 135‚Äì146.
[24]Miryung Kim, Thomas Zimmermann, and Nachiappan Nagappan. 2014. An em-
piricalstudyofrefactoringchallengesandbenefitsatmicrosoft. IEEETransactions
on Software Engineering 40, 7 (2014), 633‚Äì649.
[25]Alexander LeClair, Sakib Haque, Lingfei Wu, and Collin McMillan. 2020. Im-proved code summarization via a graph neural network. In Proceedings of the
28th International Conference on Program Comprehension. 184‚Äì195.
[26]Alexander LeClair, Siyuan Jiang, and Collin McMillan. 2019. A neural modelfor generating natural language summaries of program subroutines. In 2019
IEEE/ACM 41st International Conference on Software Engineering (ICSE). IEEE,
795‚Äì806.
[27]Chin-YewLin.2004. Rouge:Apackageforautomaticevaluationofsummaries.
InText summarization branches out. 74‚Äì81.
[28]Zhongxin Liu, Xin Xia, Ahmed E Hassan, David Lo, Zhenchang Xing, and Xinyu
Wang. 2018. Neural-machine-translation-based commit message generation:
how far are we?. In Proceedings of the 33rd ACM/IEEE International Conference on
Automated Software Engineering. 373‚Äì384.
[29]ZhongxinLiu,XinXia,MengYan,andShanpingLi.2020. AutomatingJust-In-
Time Comment Updating. In 2020 35th IEEE/ACM International Conference on
Automated Software Engineering (ASE). IEEE, 585‚Äì597.
[30]PaulWMcBurneyandCollinMcMillan.2014. Automaticdocumentationgen-
erationvia sourcecodesummarizationof methodcontext.In Proceedingsof the
22nd International Conference on Program Comprehension. 279‚Äì290.
[31]PaulWMcBurneyandCollinMcMillan.2015. Automaticsourcecodesumma-
rization of contextfor java methods. IEEE Transactionson Software Engineering
42, 2 (2015), 103‚Äì119.
[32]Laura Moreno, Jairo Aponte, Giriprasad Sridhara, Andrian Marcus, Lori Pollock,
andKVijay-Shanker.2013. Automaticgenerationofnaturallanguagesummaries
for java classes. In 2013 21st International Conference on Program Comprehension
(ICPC). IEEE, 23‚Äì32.
[33]SebastianNielebock,DariuszKrolikowski,JacobKr√ºger,ThomasLeich,andFrankOrtmeier.2018. CommentingSourceCode:IsItWorthItForSmallProgramming
Tasks?SpringerEmpiricalSoftwareEngineering(EMSE) 24,3(2018),1418‚Äì1457.
https://doi.org/10.1007/s10664-018-9664-z
[34]Sheena Panthaplackel, Pengyu Nie, Milos Gligoric, Junyi Jessy Li, and Raymond
Mooney. 2020. Learning to Update Natural Language Comments Based on
CodeChanges.In Proceedingsofthe58thAnnualMeetingoftheAssociationfor
Computational Linguistics. 1853‚Äì1868.
[35]Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: amethod for automatic evaluation of machine translation. In Proceedings of the
40th annual meeting of the Association for Computational Linguistics. 311‚Äì318.
[36]Luca Pascarella and Alberto Bacchelli. 2017. Classifying code comments in Java
open-sourcesoftwaresystems.In 2017IEEE/ACM14thInternationalConference
on Mining Software Repositories (MSR). IEEE, 227‚Äì237.
[37]P. Rodeghero, C. Liu, P. W. McBurney, and C. McMillan. 2015. An Eye-Tracking
Study of Java Programmers and Application to Source Code Summarization.IEEE Transactions on Software Engineering 41, 11 (2015), 1038‚Äì1054. https:
//doi.org/10.1109/TSE.2015.2442238
[38]PaigeRodeghero,CollinMcMillan,PaulWMcBurney,NigelBosch,andSidney
D‚ÄôMello. 2014. Improving automated source code summarization via an eye-
trackingstudyofprogrammers.In Proceedingsofthe36thinternationalconference
on Software engineering. 390‚Äì401.
[39]Khadijah Al Safwan and Francisco Servant. 2019. Decomposing the rationaleof code commits: the software developer‚Äôs perspective. In Proceedings of the
201927thACMJointMeetingonEuropeanSoftwareEngineeringConferenceand
Symposium on the Foundations of Software Engineering. 397‚Äì408.
[40]SMSohan,FrankMaurer,CraigAnslow,andMartinPRobillard.2017. Astudy
of the effectiveness of usage examples in REST API documentation. In 2017 IEEE
Symposium on Visual Languages and Human-Centric Computing (VL/HCC). IEEE,
53‚Äì61.
[41]Devika Sondhi, Avyakt Gupta, Salil Purandare, Ankit Rana, Deepanshu Kaushal,
andRahulPurandare.2021. OnIndirectlyDependentDocumentationintheCon-
text of Code Evolution: A Study. In 2021 IEEE/ACM 43rd International Conference
on Software Engineering (ICSE). IEEE, 1498‚Äì1509.
[42]Giriprasad Sridhara, Emily Hill, Divya Muppaneni, Lori Pollock, and K Vijay-
Shanker.2010. Towardsautomaticallygeneratingsummarycommentsforjava
methods. In Proceedings of the IEEE/ACM international conference on Automated
software engineering. 43‚Äì52.
[43]Giriprasad Sridhara, Lori Pollock, and K Vijay-Shanker. 2011. Automatically
detecting and describing high level actions within methods. In 2011 33rd Interna-
tional Conference on Software Engineering (ICSE). IEEE, 101‚Äì110.
[44]Giriprasad Sridhara, Lori Pollock, and K Vijay-Shanker. 2011. Generating pa-
rametercommentsandintegratingwithmethodsummaries.In 2011IEEE19th
International Conference on Program Comprehension. IEEE, 71‚Äì80.
[45]SeanStapleton,YashmeetGambhir,AlexanderLeClair,ZacharyEberhart,Westley
Weimer, Kevin Leach, and Yu Huang. 2020. A Human Study of Comprehension
andCodeSummarization.In Proceedingsofthe28thInternationalConferenceon
Program Comprehension. 2‚Äì13.
1704
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:32:16 UTC from IEEE Xplore.  Restrictions apply. Practitioners‚Äô Expectations on Automated Code Comment Generation ICSE 2022, May 21‚Äì29, 2022, Pittsburgh, PA, USA
[46]Lin Tan, Ding Yuan, Gopal Krishna, and Yuanyuan Zhou. 2007. /* iComment:
Bugs or bad comments?*. In Proceedings of twenty-first ACM SIGOPS symposium
on Operating systems principles. 145‚Äì158.
[47]Gias Uddin and Martin P Robillard. 2015. How API documentation fails. Ieee
software32, 4 (2015), 68‚Äì75.
[48]Yao Wan, Zhou Zhao, Min Yang, Guandong Xu, Haochao Ying, Jian Wu, and
PhilipSYu.2018. Improvingautomaticsourcecodesummarizationviadeeprein-
forcementlearning.In Proceedingsofthe33rdACM/IEEEInternationalConference
on Automated Software Engineering. 397‚Äì407.
[49]Bolin Wei, Ge Li, Xin Xia, Zhiyi Fu, and Zhi Jin. 2019. Code generation as a
dualtaskofcodesummarization.In AdvancesinNeuralInformationProcessing
Systems 2019. Neural Information Processing Systems (NIPS).
[50]Bolin Wei, Yongmin Li, Ge Li, Xin Xia, and Zhi Jin. 2020. Retrieve and refine:
exemplar-basedneuralcommentgeneration.In 202035thIEEE/ACMInternationalConference on Automated Software Engineering (ASE). IEEE, 349‚Äì360.
[51]E. Wong, Taiyue Liu, and L. Tan. 2015. CloCom: Mining existing source code
forautomaticcommentgeneration.In 2015IEEE22ndInternationalConference
on Software Analysis, Evolution, and Reengineering (SANER) . 380‚Äì389. https:
//doi.org/10.1109/SANER.2015.7081848
[52]Edmund Wong, Jinqiu Yang, and Lin Tan. 2013. Autocomment: Mining question
and answer sites for automatic comment generation. In 2013 28th IEEE/ACM
International Conference on Automated Software Engineering (ASE). IEEE, 562‚Äì
567.
[53]Jian Zhang, Xu Wang, Hongyu Zhang, Hailong Sun, and Xudong Liu. 2020.
Retrieval-based neural source code summarization. In 2020 IEEE/ACM 42nd Inter-
national Conference on Software Engineering (ICSE). IEEE, 1385‚Äì1397.
1705
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:32:16 UTC from IEEE Xplore.  Restrictions apply. 