Extracting Rationale for Open Source Software
Development Decisions — A Study of Python
Email Archives
Pankajeshwara Nand Sharma∗, Bastin Tony Roy Savarimuthu†, Nigel Stanger‡
Department of Information Science, University of Otago
Dunedin, New Zealand
∗pankaj.sharma@postgrad.otago.ac.nz,†tony.savarimuthu@otago.ac.nz,‡nigel.stanger@otago.ac.nz
Abstract —A sound Decision-Making (DM) process is key to the
successful governance of software projects. In many Open Source
Software Development (OSSD) communities, DM processes lie
buried amongst vast amounts of publicly available data. Hidden
within this data lie the rationale for decisions that led to the
evolution and maintenance of software products. While therehave been some efforts to extract DM processes from publicly
available data, the rationale behind ‘how’ the decisions are
made have seldom been explored. Extracting the rationale for
these decisions can facilitate transparency (by making themknown), and also promote accountability on the part of decision-
makers. This work bridges this gap by means of a large-scale
study that unearths the rationale behind decisions from Python
development email archives comprising about 1.5 million emails.This paper makes two main contributions. First, it makes a
knowledge contribution by unearthing and presenting the ratio-
nale behind decisions made. Second, it makes a methodological
contribution by presenting a heuristics-based rationale extractionsystem called Rationale Miner that employs multiple heuristics,
and follows a data-driven, bottom-up approach to infer the
rationale behind speciﬁc decisions (e.g., whether a new module
is implemented based on core developer consensus or benevolent
dictator’s pronouncement). Our approach can be applied toextract rationale in other OSSD communities that have similar
governance structures.
Index T erms—Open Source Software Development (OSSD),
decision-making, Python, rationale, causal extraction, heuristics,Rationale Miner
I. I NTRODUCTION
One of the key factors of a successful Open Source Soft-
ware (OSS) project is its underlying governance mechanism.
Decision-making processes are important governance artefacts
that articulate how decisions are or should be made within
an organization. These decision-making (DM) processes often
lie hidden (i.e., implicit) within large amounts of data andhence may not be known to everyone in a transparent fashion
[1]. While there have been efforts to unearth these decision-
making processes ([2]–[4]), the rationale depicting how certaindecisions were made are not made explicit in the DM processmodels.
The Merriam-Webster deﬁnes rationale as the “the expla-
nation of controlling principles of opinion, belief, practice, orphenomena, or an underlying reason.” However, the literature
on rationale identiﬁcation and extraction in OSS design ([5],[6]), has highlighted that the focus has mainly been on thedecisions themselves [7] (i.e., ‘what’ these decisions are), not
on ‘how’ they are made. Thus, the focus of this work isextracting the rationale behind how actually these decisions aremade (i.e. decision-making constructs such as consensus and
BDFL decree). We chose Python as a case study as this OSSDcommunity is known to follow good governance practices [8].
The Python language is modiﬁed and evolved by means of
formal Python Enhancement Proposals (PEPs) . There might
be different rationale for accepting or rejecting a PEP . For ex-ample, the rationale behind PEP 289’s acceptance was: “Basedon the favorable feedback, Guido has accepted the PEP forPy2.4” [9]; whereas for PEP 285, the project leader (referred
to as the Benevolent Dictator F or Life orBDFL ) responded:
“Despite the negative feedback, I’ve decided to accept the
PEP” [10]. These rationale-containing sentences are hiddenin email discussions inside email repositories, particularly the
Python-Dev repository of core developer discussions.
This work aims to bridge the gap by extracting rationale for
decisions made during the evolution of Python. We propose an
approach called Rationale Miner, which is a heuristics-based
rationale extraction system, and use this approach to extract
rationale. Thus, this paper makes two key contributions: (i)
a methodological contribution in the form of an approach orframework that can extract rationale that lie hidden in Python
repositories, and (ii) a knowledge contribution in the form of
the rationale behind decisions that were made.
This paper is organized as follows. Section II provides a
background of relevant work and also presents the research
questions. Section III presents the methodology used to extractrationale. Section IV presents the results, followed by a
discussion of contributions in Section V. Section VI presentsour conclusions.
II. B
ACKGROUND AND RESEARCH QUESTIONS
Only recently have researchers explored the ‘actual’
decision-making processes that lie hidden in OSS repositories.The ﬁrst focus had been the extraction of high-level decision-
making processes in the form of a process diagram. Prior stud-
ies ([1] and [2]) extracted the decision-making process model
using structured ﬁelds within messages from the Python-
checkins mailing list. The process extracted by study in [2]
showed 13 main states that a Python Enhancement Proposal
10082021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)
1558-1225/21/$31.00 ©2021 IEEE
DOI 10.1109/ICSE43902.2021.00095
(PEP) goes through. PEPs are documents that capture all
the major proposed changes to the language, and also the
processes that Python developers should adhere to. WheneverPython community members want to enhance the languagewith a new idea, feature, or patch, they propose it via aPEP . These proposals remain in a particular state (e.g., draft )
until a decision is made to move it to another state (e.g.,accepted ). The ofﬁcial Python documentation showed eight
decision making states for the PEP process, presented in PEP1, as shown in Figure 1. Based on mining Python repositories,prior work obtained ﬁve more decision-making states [1]in the Python DM process. Subsequently, some researchersrecently extended this study by extracting sub-states between
the 13 main states [4]. Their work revealed a richer and
more complex decision-making process that encompassed sub-structures such as voting and consensus formation phases.However, a limitation of these prior works is that they did not
capture the rationale behind state transitions. In other words,
they did not answer the question what is the rationale for a
transition between states? For example, how did a PEP move
from draft toaccepted state while another moved from draft
torejected? Was it through consensus orBDFL decree?
Fig. 1. Decision-making process used in Python Enhancement Proposals [2].
As previously noted, the rationale behind state changes in
OSSD communities are often hidden inside email repositories.
Identifying and extracting rationale from email messages is
a challenging task for two reasons. First, mailing lists are
informal communication channels and the rationale for state
changes are thus often discussed in an informal way. Thereare no prescriptions or structure around how decisions shouldbe communicated. Thus, rationale must be extracted from
ambiguous and incomplete messages, which is a challengingcomputational task. Even a researcher armed with human
intuition would need to manually analyze all the messagesfor a given PEP , and read the important messages severaltimes, in order to understand the underlying rationale for a
decision. Second, the underlying rationale for how decisionsare made can be spread across many different email messages.
These may need to be identiﬁed and linked in order to extractrationale.
This paper aims to overcome these challenges. Toward this
goal, this work poses three research questions (RQs).
RQ 1 What are the different rationales for PEP deci-
sions and their prevalence, as evident in Pythonemail archives?
RQ 2 How can we design and develop an automated
approach that extracts the rationale for PEP
decisions?
RQ 3 How effective is our approach at extracting the
rationales behind PEP decisions?
III. M
ETHODOLOGY
With regards to RQs 1-3, Figure 2 depicts the approach that
we used to extract and present the rationale for decisions made
during Python’s evolution. This is embodied in a heuristics-based rationale extraction system called Rationale Miner. Our
approach comprises nine steps as outlined below.
7.Rankingmodule
Rankscandidates based onSBSandMBS
Rationale Identification andRanking
5.Extracting GroundTruth
(Actualrationalesentences)
Rationale 
MinerGUI
9.Rankedcandidate rationale
sentences andmessages
6.Candidate Rationale Sentence 
extraction using Patterns &Heuristics
4. Extract emails exchanged during 
Decision-making stage
Data ExtractionMySQLDatabase
Proposals
3. Email 
messages
fromDMforums
1. PEPs
Github
2. PEP 
statesStates
Mailinglists
(e.g.pythonͲdev)
Emails
8.Evaluaterankedresults
(bycomparing againstgroundtruth)
Fig. 2. Methodology used to extract rationale behind PEP decisions.
Step 1: The ﬁrst step was to download all the 248 PEPs
which were accepted orrejected. Among other details, the
PEP includes its author, and BDFL Delegates (if any) whomade the ﬁnal decision on the PEP . We obtained the PEPsfrom Python’s Github repository
1and stored it in a database.
Step 2: Next, we retrieved all the 13 main states that each
PEP transitioned through [2]. This information was extracted
for all PEPs from Python’s GitHub repository, which includes
all versions of every PEP document. These documents containtwo key details: i) the next transition state of a PEP from itscurrent state (e.g., from draft toaccepted ), and ii) the date of
the change. We extracted Github data for Python state commitsfrom its inception (March 1995) through to 12th July 2018.This end date was chosen because that was the date when theBDFL resigned, marking the end of benevolent dictatorship
governance model.
Step 3: We then extracted all individual email messages
from the Python email archives, and stored them in a MySQL
database. We used the following email archives: Python-Dev,
Python-Ideas, Python-Commits, Python-Checkins, Python-
List, and Python-Patches. These six mailing lists were chosen
as they are the leading forums for Python developer discus-sions, with Python-Dev being acknowledged as the main forum
1e.g., PEP 8: https://github.com/python/peps/blob/master/pep-0008.txt
1009to discuss PEP development. The resulting dataset contained
a total of 1,553,564 email messages. During this step, we also
assigned a PEP number to email messages where possible.This was achieved by running a procedure that identiﬁedmentions of the PEP number(s) or title(s) within a message,and stored this as a ﬁeld in the database alongside other detailsof a message (author, date, etc.).
Step 4: From all the email messages stored in the database,
we selected only those that related to PEP decision-making,i.e., emails that had successfully been assigned a PEP number.
Step 5: Next, we extracted the ground truth, i.e. the actual
rationale behind PEP decisions, from the email messages of
each PEP . This ground truth will be used to answer RQ1,
and also to identify patterns of how rationale are stated whiledesigning the automated rationale extraction approach. Wealso use this result to evaluate against the results of the
Rationale Miner tool. Our approach in compiling the ground
truth is explained in Section III-A.
Step 6: In this step, we identiﬁed a set of heuristics
that could be used to separate rationale-containing sentences
from non rationale-containing sentences. Scores were assigned
to individual heuristics, and each sentence was assigned anaggregate heuristic score based on how well it matches the
with relevant heuristics. These heuristics and the relevant
operational details to extract candidate rationale-containingsentences are described in detail in Section III-B.
Step 7: The goal of this step was to rank candidate rationale-
containing sentences using two schemes: a Sentence BasedScheme (SBS) and a Message Based Scheme (MBS). In SBS,candidate rationale-containing sentences from the previousstep were ranked based on their heuristic score. In MBS,
candidate sentences were aggregated at the message level
and the ranks of the messages were computed. The ranksindicate the position of a sentence or a message respectivelyin the rank-ordered output, with the top ranks having thehighest heuristic score for containing rationale. Sections III-B1
and III-B2 explain these two approaches respectively.
Step 8: Next, we evaluated the performance of the SBS and
MBS by comparing their rank-ordered results with the ground
truth (step 5). This is discussed further in Section III-D.
Step 9: The ﬁnal step was to present the rank-ordered results
for both SBS and MBS in a graphical user interface (GUI).
The GUI can be used to browse the ranked results to examine
and understand the rationale behind a particular decision.This is discussed further in Section IV-B. Subsequently we
also obtained feedback from a former Python steering councilmember who was closely involved in decisions made in Pythonwhich are presented in Section IV.
A. Extracting Ground Truth
To achieve our goal of automatically extracting rationale
sentences we had to create a ground truth dataset comprising
rationale for decisions that were made. To obtain the ground
truth, we conducted an in-depth manual exploratory analysis of
email messages (spanning multiple mailing lists) relating to all
PEPs that reached either the accepted (152 PEPs) or rejected(96 PEPs) states. The ﬁrst author read the correspondingmessages and identiﬁed the rationale behind why each PEPwas accepted or rejected. A custom-built GUI tool
2was used
for this purpose, which retrieved all messages for a PEP in date
order. We examined messages for each PEP , paying particular
attention to their decision date, in order to understand howthe discussions unfolded and how the ﬁnal decisions weremade. When rationale for decisions were found (e.g., decision
made based on consensus amongst developers) the rationale-containing sentences and the messages containing them weremarked as ground truth data.
Of the 152 accepted PEPs, 107 had an explicitly stated
rationale for acceptance. We manually extracted 179 rationalesentences from 162 unique messages relating to these PEPs.For some PEPs we found multiple rationale sentences. Of the96rejected PEPs, 86 had an explicitly stated rationale for
rejection. We manually extracted 121 rationale sentences from97 unique messages relating to these PEPs. This gave us a
ground truth dataset of 300 rationale sentences relating to 193
PEPs. All rationale sentences in the dataset were veriﬁed by
the second author (i.e., 100% consensus).
The next section describes how we automated the process
of rationale extraction, as manually extracting rationale from
large datasets is laborious and time-consuming. The ﬁrstauthor spent three months full-time on the exploratory analysis
described in this section. This required reading most messages
relating to the 248 PEPs, with some messages requiringmultiple readings to fully understand the nuances.
B. Heuristics-Based Approach to Extract Rationale
We used the heuristics-based approach to address the com-
plexities of identifying rationale containing sentences. In the
literature on software design decisions rationale extraction
([11]–[15]), a number of heuristics have been proposed tobe used in different contexts. For example, the work in [15]
identiﬁes users’ rationale for writing app reviews. The work ofWilliams et al. [11] have employed heuristics to extract argu-ments in software engineering practitioners’ blogs. However,
these works do not identify and extract the rationale behind
‘how’ these decisions are made in the OSS development
context using a data-driven approach.
Our approach, developed as the Rationale Miner tool, uses
13 heuristics that were indicative of rationale on how PEP de-cisions are made, grouped into ﬁve categories. These heuristicswere identiﬁed mainly from the literature and supplementedby our personal experience with manual rationale extraction
from PEP messages. These heuristics were used to create ascoring function that is used in both the SBS and MBS.
1) Sentence-Based Scheme (SBS): SBS considers ﬁve cat-
egories of heuristics to compute the heuristic score of a
sentence.
Category 1: Term patterns. This category, comprising
three heuristics, considers whether a sentence contains certain
2A screenshot of the tool used to analyze messages can be viewed at
https://doi.org/10.6084/m9.ﬁgshare.12363014.
1010patterns of terms3that indicate the presence of a rationale
behind a PEP decision [16]: “Accordingly, the PEP [Pro-
posal Identiﬁer] was rejected [State] due to the lack of an
overwhelming majority [Reason] for change.” Here, the term
pattern is made up of three term types (in brackets) and the
rationale for the decision (lack of majority) can be clearlyinferred. These term patterns can appear in:
•the sentence currently being considered, represented bythe heuristic Term Pattern in Current Sentence (TPCS);
•the remainder of the paragraph following the current
sentence, represented by the heuristic Term Pattern in
Rest of Paragraph (TPROP); and
•the subject line of the message containing the current
sentence, represented by the heuristic Term Pattern in
Message Subject (TPMS).
These three heuristics play an important role in determiningwhether a sentence may contain rationale. The scores assigned
to the different term patterns range between 0 and 0.9.
3Three
of the six terms listed in the link in the footnote above were
inspired from the literature on rationale identiﬁcation. Theseare Reason Identiﬁer, Entity, and Decision Terms from the
works of ([7][17][15]).
Category 2: Proximity-based heuristics. We have also
identiﬁed heuristics that are based on proximity. These includethe location of the email message in relation to the PEP’s
evolution and the location of a sentence within a message.
This category also comprises three heuristics.
Days From State Commit (DFSC): Based on our manual
analysis we found that messages containing rationale tended
to appear closer to the dates of making decisions. When adecision is made (e.g., a PEP going from draft toaccepted ),
these state changes are reﬂected in the PEP document commit-
ted to the version control system. Messages for a PEP that arecloser (number of days) to the date of the commit recording
the PEP’s acceptance or rejection are assigned a higher score.
Sentence Location In Message (SLIM): Research has shown
that the ﬁrst sentence in a paragraph always introduces the
main topics of the paragraph, while the last sentence inmany instances summarizes what the paragraph discusses [13],
[18]–[22]. We found evidence of this in our manual analysisof emails, where sentences located in the ﬁrst or second
paragraph conveyed the main idea of the message while thelast paragraph placed emphasis on what had already been said.Therefore, in our heuristics scheme, if a sentence is in the ﬁrst
or last paragraph of a message, that sentence is assigned ascore of 0.9 for this heuristic, otherwise 0.
Negation Terms (NT): As PEP generally undergoes several
rounds discussion, negation terms such as “may”, “not”, and
“should not” are generally used in earlier stages of the PEP ,
not the ﬁnal PEP decision. They change the meaning of a
sentence. Therefore, if a sentence contains such terms, it is
assigned a −0.8 negation penalty that reduces its total score.
3The full list of rationale term types, their patterns and scores, see
https://doi.org/10.6084/m9.ﬁgshare.12385862.Category 3: Role-based heuristics. A number of ﬁelds in
an email message can play a role in identifying a rationale
sentence. We group them into three types, each representedby a corresponding heuristic.
Message Type (MT): From our ﬁndings there are three
types of email messages related to a PEP: the ofﬁcial PEPsummaries, PEP state commit messages, and all other mes-
sages pertaining to the PEP . The PEP summaries are ofﬁcial
summaries that reﬂect on the PEP , written after a decision has
been made and placed on the Python website.
4State commit
messages reﬂect state changes (e.g., draft toaccepted ), as
previously mentioned. If a sentence belongs to one of these
two message types, it has a higher chance of containing arationale, and is therefore assigned a score of 0.9; otherwise
it scores 0.
Author Role (AR): During the different stages of a PEP’s
evolution, various members of the Python community writedifferent types of email messages for a PEP . However, mes-sages containing decisions and their rationale are usuallywritten by certain roles. If the message is from the BDFL or
BDFL Delegate (who may differ for each PEP), the sentences
in the message are assigned a score of 0.9 for this heuristic.If the message is from a PEP Author then this heuristic is
assigned a score of 0.6. If the message is from a PEP Editor
(who are mainly consulted in the earlier stages of the PEP
evolution) the score assigned is 0.5, while messages fromaCore Developer score 0.4. A score of 0 is assigned to
this heuristic if the message is written by anyone else (i.e.developers or users). This heuristic is inspired based on prior
works ([14][18][22][23]) that have considered the roles playedby individuals (e.g. author of a message).
Speciﬁc Author Messages Containing Explicit Rationale
(SAMCER): This heuristic identiﬁes messages that contain
speciﬁc hints about rationale.
1)PEP author’s message containing rationale: When a
PEP author feels the PEP is nearing completion, they
write a message formally requesting a review and pro-nouncement on the PEP . The community’s consensus
on the PEP is sometimes mentioned in this message,for example: “As you said, consensus is reached, so
just Guido’s BDFL stamp of approval is all I can
think of” [24]. Here, consensus has been reached in thecommunity and the PEP is waiting for a pronouncement
from the BDFL. The rationale for the PEP’s eventual
approval is the indicated community consensus.
2)BDFL or BDFL Delegate PEP Review: In messages
preceding formal acceptance of the PEP , the BDFL ordelegate may mention their rationale for future accep-tance. For example, “Assuming no material objection
[sic] appear to the new syntax and semantics, I can
approve the PEP later this week” [25]. This PEP wasaccepted few days later, the rationale being that the com-munity had no further objections (i.e., lazy consensus).
4e.g., for PEP 308: https://www.python.org/dev/peps/pep-0308.
10113)BDFL or BDFL Delegate PEP Acceptance or Rejection:
The BDFL or delegate formally accepts or rejects the
PEP , but the rationale for acceptance is not explicitlymentioned. For example: “Given the feedback so far, Iam happy to pronounce PEP 393 as accepted” [26]. Inthis case, the PEP was accepted because of communityconsensus, which is implicit in the sentence.
4)Community members reﬂecting on decisions: Sometimes
a core developer would mention how a PEP was receivedby the community, either while summarizing the PEP ordiscussing the decision later on. For example: “Raymondsuggested updating PEP 284 (‘Integer for-loops’), butseveral people spoke up against it, including Guido, so
the PEP was rejected” [27].
If a sentence belongs to a message from one of these four
types, it is assigned a score of 0.9, otherwise 0.
Category 4: Response to certain speciﬁc messages. This
category comprises two heuristics related to speciﬁc messages.
Response Messages to the Same State Change Message
(RMSSCM): If the PEP author requests pronouncement based
on feedback received from the community, for example by
stating “there were no outstanding issues”, it is likely that the
reply message will contain the rationale for the subsequentdecision. Therefore, we assign a higher score to messages withthe same subject line. This heuristic was inspired by a similar
heuristic used by AbdelRahman et al. [28].
Rationale F ound Using Triple Extraction (RFUTE): In our
previous research work ([4]), we used Subject, V erb, Object
(S,V ,O) triples to identify decision-making sub-states thatoccur between the main states shown in Figure 1. In our
manual analysis, we observed that we could automatically
identify some sentences as rationale-containing sentences via
the S,V ,O triples they contained. For example, the S,V ,O tripleextracted from the rationale sentence “As you said, consensusis reached, so just Guido’s BDFL stamp of approval is all I can
think of” [24] is [“consensus”, “is”, “reached”] which impliesconsensus. We therefore adopted this approach to identify
and match S,V ,O triples, where certain decision-speciﬁc terms,such as “consensus”, were included in the triples. Sentenceswhere such S,V ,O triples were extracted and matched were
assigned a score of 0.9, otherwise 0.
Category 5: Special Identiﬁers. Based on our analysis of
PEP email messages, we included two additional heuristics for
special identiﬁers that exhibited rationale behind state changes.These heuristics have not been previously reported in the
literature on rationale identiﬁcation.
Decision Terms In Message (DTIM): On some occasions,
members inserted a heading before the paragraph that stated
the rationale for PEP acceptance or rejection. Examples in-clude “BDFL Pronouncement”, “PEP Acceptance”, and “PEP
Rejection”. We consider these as terms that convey decisions
and therefore any sentence containing such terms is assigneda score of 0.9 for this heuristic, otherwise, 0.
Decision Terms as Header of current Paragraph (DTHP):
If the decision terms identiﬁed above exist as the heading
of the paragraph that contains the sentence currently beingconsidered, we assign a score of 0.9 for this heuristic to all
sentences in that paragraph.
The Final Scoring function. The Final Score (FS ) for each
sentence is the sum of its scores for all 13 heuristics:
FS=TPCS +TPROP +TPMS +DFSC
+SLIM +NT+MT+AR+SAMCER
+RMSSCM +RFUTE +DTIM +DTHP (1)
The sentence scores of all sentences belonging to a PEP are
compared in order to produce a descending rank-ordered list
of candidate rationale containing sentences.
2) Message-Based Scheme (MBS): In the sentence-based
scheme, candidate rationale sentences from the same emailmessage may appear in different rank-ordered positions, asthe rationale may be present in multiple sentences. However,a user may prefer to see results from the perspective of theentire message containing these rationale sentences. MBS isa message-level aggregation of the SBS. This approach has
two advantages. First, it prevents multiple rationale sentencesfrom the same message being shown in different rank-ordered
positions, so that users can view related rationale sentences inthe context of the same message. This will reduce the effort
required for the user to scroll through the list of rationalesentences. Second, and more importantly, it shows the entire
message which may provide a richer context around the
rationale for the candidate rationale sentence. The evaluationof these two approaches is presented in Section IV-C.
C. Heuristic optimization based on ground truth
After identifying the 13 heuristics described above, we un-
dertook two-pronged optimization: 1) identifying the heuristics
(variables) that strongly inﬂuence the identiﬁcation of rationale
and 2) using parameter sweeping to ﬁnd the best values for
these variables. We describe these two aspects next.
Having set values for the 13 heuristics to initial values as
described in the previous section, we computed the scores foreach sentence in all the emails. Then, we computed the total
number of sentences that were correctly identiﬁed in the top-5results in the SBS scheme (by checking whether a rationale
containing sentence (from the ground truth set) appeared inthese results. Having computed this result (which we call thebaseline result for optimization purposes), we systematicallyremoved one variable at a time and compared how thatimpacted the overall results. The goal of this approach was
to identify variables that strongly inﬂuence our results.
Identifying inﬂuential heuristics - Table I shows the
number of fewer or additional rationale sentences captured at
top-5
ranks for Accepted and Rejected PEPs in both the SBS
and the MBS after removing each heuristic from the FS. The
negative values indicate the removal of the associated heuristic
decreases the number of rationale sentences captured: thus it
has a positive inﬂuence. The inﬂuence of the variables aredivided into ﬁve groups as shown in Table I.
The positive inﬂuential heuristics were RFUTE and TPCS
(both strong). When these variables were removed, the results
1012TABLE I
RELA TIVE CONTRIBUTION OF HEURISTICS IN TOP 5RANKINGS
SBS MBSInﬂuence
Heuristics Acc. Rej. Acc. Rej.
RFUTE -12 -5 -14 -9 Positive
(strong) TPCS -5 -3 -4 -2
DFSC -3 -1 -6 -6 Positive
(medium) DTIM -1 0 -1 -2
SAMCER 4 2 -1 0Mixed
(strong)M T 5 - 2- 2- 1
TPMS 7 - 2- 8- 1
DTHP 1 0 -1 -1Mixed
(weak)NTP 1 0 0 -1
TPROP 2 - 1- 1- 3
SLIM 0 -2 0 -1
None AR 0 -1 0 0
RMSSCM 0 0 0 -1
were negatively impacted (e.g., up to 12 results not appearing
in the top-5 results). DFSC and DTIM variable had a medium
(positive) inﬂuence on the results. The heuristics that hadmixed but strong inﬂuence were SAMCER, MT and TPMS.
Their inﬂuences on both types of PEPs and in both schemes
were strong, but varied (i.e., values are positive at times
and negative at other times), and thus were of particular
interest during optimisation (see next paragraph) Heuristicswith weak mixed inﬂuence or those with almost noeffect the
top 5 rankings were DTHP , NTP , TPROP , SLIM, AR, and
RMSSCM.
Parameter Sweeping: For the seven variables that either
had positive inﬂuence or mixed inﬂuence, we performed
parameter sweeping, a technique widely used in simulation
systems [29] to identify the best values for the variables by
changing the values in increments of 0.3. Five values wereconsidered for each heuristic (-0.3, 0, +0.3, +0.6, +0.9). We
varied one heuristic at a time by keeping all the values of
all the other heuristics the same. This approach enabled us to
ﬁnd the best conﬁguration of values for the chosen heuristics,
by comparing the results obtained by a conﬁguration withthe ground truth results. Adopting this approach, we foundthat for both SBS and MBS, generally, our current DFSC
and TPMS heuristics values needed to be incremented by
0.6. Changing the values for the other heuristics made nosigniﬁcant difference. Hence, the results reported in SectionIV are based on the best conﬁguration for these 13 heuristics.
D. Evaluating the Heuristics-Based Approach
We compared the results obtained using the heuristics-based
approach against the ground truth using two methods. First,
we compared the rank-ordering of sentences and messages.If a sentence was identiﬁed in the ground truth dataset as a
rationale-containing sentence for a particular PEP , we checked
the rank of the same sentence (and its corresponding message)
in the heuristics-based results. If there was only one rationale
sentence for a PEP in the ground truth dataset, then the idealresult would be that the heuristics-based approach assignedthe highest score (i.e., highest rank) to that sentence and itscorresponding message. We, therefore, quantiﬁed the numberof sentences and messages that matched at various ranks.
Second, we used the normalized discounted cumulative gain
(NDCG) metric, a metric commonly used in the information
retrieval domain to evaluate the ranking results for a query
in relation to the “perfect” ranking for the same query [30].It has, for example, been used to evaluate an email ranking
system based on search query results [28]. In the context ofour work, most PEPs have one or two rationale sentences. Iffor instance these are not captured in the top two ranks, the
ranking quality for these two positions will be penalized by
this approach. NDCG is calculated using this formula [30]:
NDCG
k=DCG k
IDCG k(2)
where IDCG kis the ideal DCG value (based on its deﬁnition
in [30]) of the ranking at position k, that is, the DCG value
of the ground truth. NDCG is normalized to the interval [0,1],with 1 indicating a perfect estimation of the ground truth.
IV . R
ESULTS
This section presents the results for the research questions.
A. RQ1: Rationales for PEP Decisions
Figure 3 shows 11 different decision rationales for accepted
and rejected PEPs that have been unearthed in our qualitative
analysis. These are based on the 300 ground truth rationalesentences we manually extracted.
5Table II gives examples of
rationale sentences corresponding to each of these rationale.
0102030405060
Consensus Lazy
ConsensusInept PEPs BDFL
DecreeBDFL P.
after No
ConsensusLittle
SupportRough
ConsensusNo
ConsensusMajority No
MajorityBDFL P.
over
MajorityAccepted Rejected
Fig. 3. Rationale for accepted and rejected PEPs. The horizontal axis shows
the rationale and the vertical axis the number of PEPs.
The top 5 rationale for decisions were consensus (57), lazy
consensus (43), inept PEPs (42), BDFL decree (17) and BDFL
pronouncement after no consensus amongst developers (15).
Inept PEPs is an aggregate of eight rationale that represent
a problem with a PEP , such as “PEP beneﬁts marginal”,“requires signiﬁcant changes”, etc. BDFL decree refers to
instances where the BDFL makes a decision regardless of the
5A spreadsheet containing the raw data for these sentences can be viewed
at https://doi.org/10.6084/m9.ﬁgshare.12732260.
1013TABLE II
SAMPLE SENTENCES CONTAINING RA TIONALE BEHIND DECISIONS ON Accepted AND Rejected PEP S
Rationale Rationale sentence PEP
Consensus “The user community unanimously rejected this so I won’t pursue this idea any further” [31] 259
No Consensus “Although a number of people favored the proposal there were also some objections ” [32] 3128
Lazy Consensus “If anyone has objections to Michael Hudson’s PEP 264: raise them now.” [33] 264
Rough Consensus “Several people agreed, and no one disagreed, so the PEP is now rejcted. [sic]” [27] 265
Little Support “It has failed to generate sufﬁcient community support in the six years since its proposal.” [34] 268
Majority “Comments from the Community: The response has been mostly favorable”. [35] 279
No Majority “Accordingly, the PEP was rejected due to the lack of an overwhelming majority for change.”[16] 308
BDFL Decree “After a long discussion, I’ve decided to add a shortcut conditional expression to Python 2.5.” [36] 308
BDFL P . after No Consensus “There’s no clear preference either way here so I’ll break the tie by pronouncing false and true.” [37] 285
BDFL P . over Majority “Python is not a democracy.” [38] 326
Most of these statements were made by the BDFL directly or are references to the BDFL’s views.
community’s views. The descriptions of each of the rationale
is provided in this link6.
The work in [39] outlines the commonly used rationale be-
hind decisions (i.e. ‘how’ decisions are made) by consideringthe Apache OSS project. The work identiﬁes ﬁve rationalesspeciﬁc to this project. However, no prior work has beenundertaken for Python to understand the rationale in decision-making in the context of PEPs, and in particular conducting adata-driven qualitative study to unearth the ‘actual’ rationale
from email discussions and the prevalence of the usage ofeach rationale as we have undertaken here. We have also
unearthed several additional rationales (e.g., rough consensus
and the ones involving BDFL) whose prevalence has not beenpreviously quantiﬁed in the literature. To our understanding,rough consensus is used to consider some form of community
majority when full consensus is not attainable. Some PEPshave intense discussions where it is not possible to achievefull consensus, and rough consensus may be a way to avoid a
situation where the community’s preference is based only on
the opinions of a vocal minority or inﬂuential individuals [40].
There are rationale whose occurrences indicate a clear
decision (e.g., accepted orrejected, but not both). For example,
little support, no consensus, no majority, and lack of champion
always lead to a PEP being rejected. There are other rationale,
however, where the ﬁnal decision is not so clear cut. Forexample, even after lazy consensus orrough consensus, a PEP
could be still rejected (possibly due to BDFL decree). We
also observed one PEP (326) where the BDFL overrode themajority’s opinion. The majority of the community preferredthe PEP , but the BDFL rejected it, emphasizing that “Pythonis not a democracy” [38]. The substantial number of PEPs
where the BDFL has exercised his own preference (BDFL
decree, BDFL pronouncement after no consensus, and DFL
pronouncement after majority) implies that in the Pythoncommunity, the BDFL is free to exercise his choices when
necessary. However, most of the decisions taken by the BDFL,
are based entirely on a collective community view, such
asconsensus, lazy consensus, rough consensus, majority, no
majority, and little support. The Python project leader allowsthe community to come to a collective view on proposal
6https://doi.org/10.6084/m9.ﬁgshare.12887885outcomes, using any of these rationales, and then he (orsometimes his delegates) appear to mostly concur with the
collective view.
B. RQ2: An Approach for Rationale Extraction
To answer RQ2, we ﬁrst identiﬁed relevant heuristics both
from the literature and from our efforts during the manual
extraction of rationale-containing sentences. We identiﬁed 13such heuristics. Using these heuristics we then constructed a
scoring mechanism that was used to rank candidate rationale-containing sentences in the SBS. At a higher level of ag-
gregation, messages containing these rationale sentences were
ranked using the MBS.
Figure 4 shows the Graphical User Interface (GUI) of the
Rationale Miner. This is designed to help users understand
the rationale behind how decisions made, by enabling them
to explore the results of both sentence-based and message-
based rationale extraction for a particular PEP . Panel 1 (greennumbering) is for entering search parameters such as the
desired PEP number. Panel 2 shows a timeline of states
traversed by the selected PEP (e.g., draft and accepted ). To
obtain all the rationale sentences (or messages), the user canselect in Panel 4 the appropriate approach (sentence-basedor message-based) and also whether they are interested inPEPs that were accepted orrejected. Clicking the Extract
Reasons button causes the results to be shown in Panel 5.
Clicking on a result row in Panel 5 shows the correspondingsentence or message in Panel 3. When a message is shown inPanel 3, all rationale-containing sentences are underlined. A
video demonstrating the features of the GUI can be viewed
at https://youtu.be/nrB9Jk1OFXo. For simplicity, in the video,
the Rationale Miner is referred to as the Reasons Miner.
C. RQ3: Effectiveness of the Approach
In this section, we demonstrate the effectiveness of the
Rationale Miner in identifying rationale using two approaches.
1) Evaluation Approach 1—Comparing Rank-Ordered Re-
sults: Table III shows the number and percentage of ground
truth rationale-containing sentences captured by SBS and MBSat a particular rank k, for PEPs that reached the ﬁnal states
accepted orrejected. We can see that 15.7% (accepted ) and
29.8% (rejected ) of the ground truth sentences appeared as the
1014Fig. 4. The Rationale Miner GUI. (A larger version may be viewed at https://doi.org/10.6084/m9.ﬁgshare.12377633)
top result (k =1 ) in the heuristics-based system using SBS.
MBS performed even better: 20.2% and 47.1%, respectively.
Furthermore, 39.7% (accepted ) and 48% (rejected ) of ground
truth sentences appeared within the top 5 results using SBS(61.5% and 74.4% respectively for MBS, and highlighted inbold in Table III). The number of ground truth sentences
appearing within the top kSBS and MBS results increases
with k, as to be expected, but it is heartening to see that a
relatively large fraction of ground truth sentences are ranked
within the top 5, especially for MBS. Most of the rationalesentences for both states are captured within the top 100.
TABLE III
HEURISTICS -BASED APPROACH VS .GROUND TRUTH
SBS MBS
Accepted Rejected Accepted RejectedRanking
(Top k) CC*%C C %C C %C C %
Top 1 28 15.7 36 29.8 36 20.2 57 47.1
Top 2 30 16.7 42 34.7 67 37.4 68 56.2
Top 3 45 25.1 49 40.5 85 47.5 79 65.3
Top 4 52 29.1 56 46.3 103 57.6 85 70.2Top 5 71 39.7 58 48.0 110 61.5 90 74.4Top 10 94 52.5 72 59.5 133 74.3 104 86.0Top 15 110 61.4 82 67.8 147 82.1 110 91.0Top 30 131 73.2 94 77.7 161 90.0 111 91.8Top 50 139 77.7 98 81.0 170 95.0 111 91.8Top 100 158 88.3 99 81.8 175 97.8 112 92.6
Top 100+ 0 0 0 0 0 0 0 0
No match 21 11.7 22 18.2 4 2.2 9 7.4
Total 179 121 179 121
*CC = cumulative count of rationale sentences
Comparing the SBS and MBS results, two aspects can
be noted. First, MBS captures a larger number of rationale
sentences than SBS at each rank k. This is because a rankedmessage in MBS can have more than one rationale-containing
sentence. For example, suppose that there are two sentencesfrom the same message ranked at 3 and 8 in the SBS ranking.
Under MBS, the rank for this message will be 3, and both
sentences will be considered part of this message. So if weconsider the 9th ranked sentence under SBS, it will be ranked
8th under MBS. MBS thus has an inherent advantage over
SBS. Second, the results show that there are more unmatched
sentences under SBS than MBS. Unmatched sentences are
those which were identiﬁed as rationale sentences in theground truth dataset, but did not appear in results of theheuristics-based system. This is because these sentences did
not have patterns matching the heuristics. MBS has fewer
unmatched sentences because sentences not matched by SBSmay appear in the same message as sentences that are matched.
We observe that many rationale are captured at lower ranks
(say k> 15). This mainly arises when rationale are stated
long before or long after the date a PEP’s accepted orrejected
state was committed to the Python repository. For example, the
rationale for a PEP’s acceptance or rejection is conveyed ina message, but the PEP is only formally accepted orrejected
much later (sometimes six months or in the extreme case upto two years later). Alternatively, the community member in
charge of committing the decisive state of the PEP may forsome reason postpone doing so and commit the state changes
for several outstanding PEPs as a batch. Since our approachprefers rationale sentences that are closer to the dates at which
decisions were made, sentences written much earlier or muchlater are given a lower score in the DFSC heuristic, resultingin a lower rank.
2) Evaluation Approach 2—Using NDCG: We used the
NDCG metric to formally evaluate our heuristics-based ap-proach, as discussed in Section III-D. We computed the
1015average NDCG for each rank k(equation 2), for accepted
and rejected PEPs under both SBS and MBS retrieval-based
ranking approaches are summarized in Figure 5. We used
different thresholds for the minimal size of the search results,
where the ranges over the values top 5; top 10; top 15; top
30; top 50; top 100.
00.10.20.30.40.50.60.70.80.91
0 1 02 03 04 05 0Average NDCG
Ranking (k)SBS Accepted PEPs SBS Rejected PEPs
MBS Accepted PEPs MBS Rejected PEPs
Fig. 5. Average NDCG values of 152 Accepted and 96 Rejected PEPs for
both MBS and SBS.
The chart shows that MBS produces better results than SBS
for both accepted and rejected PEPs at almost all ranks. This
aligns with the results of the rank-ordering comparison in
Section IV-C1. For example, the MBS scores for rejected are
higher than the SBS scores for all ranks k. Speciﬁcally, MBS
for rejected outperforms SBS by 10.3% at k=5, 12.4% at
k=10, 14.7% at k=25, and 11.2% at k=50.
V. D ISCUSSION
In this section we revisit our research questions and discuss
the main contributions.
A. RQ1: Rationale behind PEP decisions
We can infer that while the Python OSS community em-
ploys a strict hierarchical and authoritative DM structure, the
DM structure is not totally authoritarian. There is a largeadherence to the community’s view, acquired and represented
via different mechanisms. For most PEPs, the project leadertransfers the burden of coming to a decision to the communitythrough some form of consensus (including lazy consensus
and rough consensus). This helps avoid the situation of the
dictator’s decision continually suppressing the views of thecommunity. The BDFL uses this mixture of two principles,which seem to work well together, for the success of decision-
making and the Python project overall.
To evaluate the correctness of our results (i.e., the identiﬁed
rationale are correct), we presented our ﬁndings to a prominent
Python core developer (name withheld) who had been leadauthor or co-author of 22 PEPs and has been BDFL Delegate14 times, and is a former Python Steering Council member.
He replied “I think your list of reasons looks good”. This
demonstrates that the extracted rationale are accurate.B. RQ2: An Approach for Rationale Extraction
We have operationalized a heuristic-based Rationale Miner
tool to extract rationales. In doing so we automated the
extraction of features in a sentence (e.g., presence of PEPnumber), the assignment of scores for a feature, and the ﬁnalcomputation of overall score for a sentence that representswhether or not a sentence contains rationale or not. The twoschemes for rationale identiﬁcation the SBS and MBS offerdistinct advantages. SBS offers a more ﬁne-grained sentence-level rationale, while MBS offers coarse-grained message-levelrationale. MBS can be argued to provide a richer context
and thus a deeper understanding of the rationale behind
decisions that were discussed on the mailing lists. However,SBS presents a more direct and explicit rationale-containingsentence that may be quicker and easier to understand. MBS
presents entire messages instead of individual sentences, which
will take more effort for users to read and understand. We
have reduced this cognitive load in the Rationale Miner GUI
(Figure 4) by highlighting the rationale-containing sentences
within a message.
We asked the same Python core developer mentioned in the
previous sub-section, whether the idea of a tool which extracts
how PEP decisions are made, is useful. He emphasized the
importance of such a tool in his response: “Yes, I think the
idea is valuable, as it should be possible for at least Steering
Council members to compare their subjective impressions ofoutcomes and rationales with the output of the tool, andpotentially use that comparison to help assess how well the
PEP process is actually working. ”
C. RQ3: Effectiveness of the Approach
The MBS is the best performing of the two schemes
described in this work. It accurately (i.e., top-ranked result)
captures 20% of ground truth rationale sentences for accepted
PEPs and 47% of sentences for rejected PEPs (see Table III). If
we consider the top 10 ranked results, MBS captures 74% and
86% of rationale sentences, respectively; and top 15 increases
this further to 82% and 91%, respectively. Thus, we believe,
the results are good enough for the intended purposes.
Having said the above, there are three main reasons why
not all rationale-containing sentences are captured at the ﬁrstrank. First, in some sentences, there may be little or nothing to
indicate the presence of a rationale. For example, consider the
sentence “Augmented assignment is scheduled to go in soon(well, before 2.0b1 at least) and if you don’t spot the loonynow, we’ll have to live with it forever :)”[41]. The implied
rationale here is that there is lazy consensus on the PEP . This
might be clear to a human, but there are no obvious patterns
that can be identiﬁed here from the viewpoint of heuristics.
A second reason is that some sentences do not include
term patterns that commonly appear in rationale-containingsentences. For example, in PEP 3131, the sentence which
comes closest to a rationale-containing sentence is: “After 175
replies and counting the only thing that is clear is the contro-versy [Reason] around this PEP [Proposal Identiﬁer]”[42].
There are identiﬁable two term types (in brackets) in this
1016sentence, but these do not conform to the common patterns of
how rationale are stated. These two term types are common
in sentences, but not every sentence containing these termtypes will be a rationale sentence. Including the kinds of termpatterns exhibited by the sentence above would therefore resultin an unmanageable number of candidate rationale sentences.Since this sentence does not contain any of the term patternswe had coded, it does not appear in the results.
The third and most inﬂuential reason is that some messages
containing actual rationale appear a long time before or afterthe PEP’s decisive state change is committed, as discussed
in Section IV-C1. As our approach includes a heuristic thatconsiders proximity to the commit state, rationale sentences
that are temporally more distant from the state change are
ranked lower. This is particularly challenging when there areother similar candidate rationale sentences that are closer in
time to the state change, as they are likely to have higher FS
and thus be ranked higher than the actual rationale sentence.
Evaluating our MBS results using the NDCG metric (as
discussed in Section IV-C2) produced an average NDCGvalue greater than 0.5 for all ranks beyond the top 5 (see
Figure 5). For example, for k=15 (i.e., top 15 results) the
average NDCG value was 0.6 for accepted PEPs and 0.73
forrejected PEPs. Intuitively, this means that MBS correctly
ranked rationale sentences 60% of the time for accepted PEPs
and 73% of the time for rejected PEPs. If we disregard the
exact order of results within the top 15, the match is muchhigher: 82% and 92%, respectively (see Table III).
Also, when compared to the prior work of Mr ´owka [43]
which has identiﬁed ﬁve rationales in Apache (which they call
‘approval types’), our work has unearthed six additional ones(a total of 11 rationales). Their work describes the process
model for decision-making qualitatively and our work focuses
on rationale for decisions quantitatively – e.g., 57 out of 248
were ‘consensus’ decision. In other words, Mr ´owka’s work
identiﬁes ‘consensus’ exists, but does not quantify how often
it is used during decision making. In addition, no practical tool
was developed by Mr ´owka as we have pursued in this work.
D. Demonstrating the Practical Utility of our Approach
We demonstrate the use of our approach to visualize the
results from rationale extraction using two examples, both
of which are also described in the video mentioned in Sec-tion IV-B. First, we consider the rationale for the acceptance
of PEP 572 — a PEP that was so contentious that the BDFL
resigned shortly afterwards. We identiﬁed three rationale sen-
tences, of which the most insightful was: “It’s really hard to
choose between alternatives, but all things considered I have
decided in favor of ‘NAME := EXPR’ instead”[44], which is
an example of BDFL decree. SBS ranked this sentence 10th,
whereas MBS ranked the corresponding message 8th.
The second example is for the highly contentious PEP 308.
The PEP went through several decision-making phases, in-cluding a poll,avote, and a complementary vote, and was
subsequently rejected. It was eventually accepted by the BDFL
two years later. Due to the many decision-making phases thePEP went through, the rationale behind its eventual acceptancewere stated in a single message: the PEP 308 summarymessage ([45]). SBS ranked two of these rationale-containingsentences 8th and 9th, whereas MBS ranked the correspondingmessage 2nd.
We also found some surprising results in our evaluation.
There were four instances where the rationale sentence cap-tured by Rationale Miner was better than what we had capturedmanually. For example, the following sentence was manually
ﬂagged as a rationale-containing sentence for PEP 465, and
was ranked 26th by SBS: “Because this way is compatible withthe existing consensus, and because it gives us a consistentrule that all the built in numeric operators also apply in
an elementwise manner to arrays; the reverse conventionwould lead to more special cases.” However, a more insightful
sentence, which provided more details of the “consensus”was ranked 7th by SBS: “the result is a strong consensus
among both numpy developers and developers of downstream
packages that numpy.matrix should essentially never be usedbecause of the problems caused by having conﬂicting duck
types for arrays.” Both sentences were from the same message[46], which MBS ranked 5th. While these surprises were
observed in four instances, one could argue these four caseswere due to human error (i.e., the human coder failed to labela rationale sentence). This highlights that our system indeed
has found those sentences correctly. We believe this also showsthe effectiveness of our approach to unearthing rationale.
E. Usage of Rationale extraction tool
The intended users for the heuristic-based rationale extrac-
tion tool are both practitioners and researchers. Practitioners
(developers and decision-makers in Python) can use the tool
to unearth rationale (e.g., 11 types of rationale such as lazyconsensus, with some of them unknown to stakeholders such
as ‘rough consensus’), and quantify their uptake (e.g., how of-
ten is rough consensus used?) Also, they can use the system tounderstand when, why, and how decisions were made throughretrospective analysis (since the details of these discussionsare not available in the PEP documents themselves). The toolcan be used for comparative studies across communities.
Researchers can use the tool to examine the nature of the
rationale for decisions (similar to what we have presented in
Figure 3). Also, several research questions can be answeredsubsequently. To name a few: a) what are the nature of the
arguments for and against acceptance (e.g. strong vs. weak,or evidence-driven or anecdotal rationale) b) what are the
‘signatures’ of success (what facilitates the PEP acceptance?),
and c) how can bad PEPs (e.g. inept PEPs) be avoided at theoutset. Thus, our work will spur further investigations.
Extending beyond the Python community, our ﬁndings also
has implications regarding decision making processes in other
open source projects. These include: a) reuse of our method-
ological
approach (i.e, 13 heuristics) as a template towards
rationale extraction in other OSS communities, b) knowledge
of the existence of more rationale (11 in our work compared
to ﬁve in Mr ´owka) c) learning from why PEPs fail (e.g., inept
1017PEPs), and then use that to avoid failures in other communities
(e.g., OpenJDK).
F . Threats to V alidity
In this section, we consider threats to construct validity,
internal validity, and external validity. Threats to construct va-
lidity refer to the appropriateness of our evaluation measures.
In our scoring construct we used 13 different heuristics based
on prior work and our experience with manual analysis of
emails. It is possible that we may have missed other heuristicsthat may be inﬂuential in identifying rationale sentences. Forformal evaluation of rationale sentences we considered the
NDCG metric which has been previously used to evaluateranking of emails. Thus, the threats to the use of this construct
are minimal.
Athreat to the internal validity of the study is that the
labelling process (i.e., labelling a sentence as a rationale-
containing sentence or not), is a subjective one and there mightbe errors. To overcome this threat, the second author of the
paper double-checked the labels of the 300 rationale sentences,and any discrepancy was resolved by discussion. Another
threat to the internal validity is that we may have missed some
rationale containing sentences where the human languageis ambiguous. However, we believe this threat is somewhat
mitigated because almost all the rationale we have identiﬁed
have been identiﬁed in different literature on decision-making,
except for rough consensus.
Athreat to external validity is the generalization of our
approach to extract rationale. We concede that our approachis applicable only to software development communities that
have decision-making processes similar to Python. For exam-
ple the rationale for decisions in Java Community that follows
Java Enhancement Proposals (JEPs) that were inspired byPEPs. However, we believe the approach employed in theRationale Miner can be extended to extract rationale fromother communities such as the Linux and Perl projects.
VI. C
ONCLUSION
There has been relatively little prior research in software
engineering investigating automated extraction of rationalebehind how decisions are made. The current work bridgesthis gap by proposing a heuristics-based approach that isoperationalized in the Rationale Miner tool. Two approaches torationale extraction (sentence-based and message-based) wereproposed and evaluated, using the Python OSSD project as acase study.
Our results identiﬁed 11 different ways of reaching a
decision outcome. Rationale Miner was able to correctly
rank rationale-containing sentences for PEP decisions into thetop 10 results nearly two-thirds of the time for both accepted
and rejected PEPs. Our approach can be extended and used in
other OSSD communities that have decision-making structures
similar to that of Python, such as the Java Community Process
with its JEPs. The heuristics may need to be remodelled toaccommodate any additional factors in these communities.A
CKNOWLEDGMENT
The ﬁrst author thanks Russell Education Trust for their
ﬁnancial support to pursue a part of his PhD study.
REFERENCES
[1] B. T. R. Savarimuthu, H. K. Dam, S. Licorish, S. Keertipati, D. Av-
ery, and A. K. Ghose, “Process compliance in open source software
development—A study of Python Enhancement Proposals (PEPs),” in
Proceedings of the 24th European Conference on Information Systems.
AIS, 2016, research paper 48.
[2] S. Keertipati, S. A. Licorish, and B. T. R. Savarimuthu, “Exploring
decision-making processes in Python,” in Proceedings of the 20th
International Conference on Evaluation and Assessment in SoftwareEngineering. ACM, 2016, article no. 43.
[3] P . Sharma, B. T. R. Savarimuthu, N. Stanger, S. A. Licorish, and
A. Rainer, “Investigating developers’ email discussions during decision-
making in python language evolution,” in Proceedings of the 21st
International Conference on Evaluation and Assessment in Software
Engineering. ACM, 2017, pp. 286–291.
[4] P . Sharma, B. T. R. Savarimuthu, and N. Stanger, “Mining decision-
making processes in open source software development: A study ofPython Enhancement Proposals (PEPs) using email repositories,” inProceedings of the 24th International Conference on Evaluation andAssessment in Software Engineering, 2020, pp. 200–209.
[5] M. Razavian, B. Paech, and A. Tang, “Empirical research for software
architecture decision making: An analysis,” Journal of Systems and
Software, vol. 149, pp. 360–381, 2019.
[6] M. Bhat, K. Shumaiev, U. Hohenstein, A. Biesdorf, and F. Matthes,
“The evolution of architectural decision making as a key focus area
of software architecture research: a semi-systematic literature study,” in
2020 IEEE International Conference on Software Architecture (ICSA).
IEEE, 2020, pp. 69–80.
[7] X. Li, P . Liang, and Z. Li, “Automatic identiﬁcation of decisions from
the hibernate developer mailing list,” in Proceedings of the Evaluation
and Assessment in Software Engineering, 2020, pp. 51–60.
[8] J. Wang, P . C. Shih, Y . Wu, and J. M. Carroll, “Comparative case
studies of open source software peer review practices,” Information and
Software Technology, vol. 67, pp. 1–12, 2015.
[9] The Coding Forums Mailing List Discussions. (2003)
PEP 289: Generator Expressions (ACCEPTED). [On-line]. Available: https://www.thecodingforums.com/threads/pep-289-
generator-expressions-accepted.324160/
[10] Python Mailing List Discussions. (2002) ACCEPTED: PEP 285.
[Online]. Available: https://mail.python.org/pipermail/python-announce-
list/2002-April/001350.html
[11] A. Williams, “Using reasoning markers to select the more rigorous
software practitioners’ online content when searching for grey literature,”
inProceedings of the 22nd International Conference on Evaluation and
Assessment in Software Engineering 2018, 2018, pp. 46–56.
[12] S. Teufel, “Sentence extraction as a classiﬁcation task,” in Intelligent
Scalable Text Summarization, 1997.
[13] H. P . Edmundson, “New methods in automatic extracting,” Journal of
the ACM (JACM), vol. 16, no. 2, pp. 264–285, 1969.
[14] M.-G. J. Okurowski, C. Aone, and I. Larsen, “A trainable summarizer
with knowledge acquired from robust NLP techniques,” Mani, and MT
Maybury. Advances in automatic text summarization, pp. 4–5, 1999.
[15] Z. Kurtanovi ´c and W. Maalej, “Mining user rationale from software
reviews,” in 2017 IEEE 25th International Requirements Engineering
Conference (RE). IEEE, 2017, pp. 61–70.
[16] Python Mailing List Discussions. (2003) PEP 308 Rejec-
tion. [Online]. Available: https://mail.python.org/pipermail/python-checkins/2003-August/037477.html
[17] A. Williams, “Finding high-quality grey literature for use as evidence
in software engineering research.” 2019.
[18] D. McDonald and H. Chen, “Using sentence-selection heuristics to rank
text segments in TXTRACTOR,” in Proceedings of the 2nd ACM/IEEE-
CS Joint Conference on Digital Libraries. ACM, 2002, pp. 28–35.
[19] J. Kupiec, J. Pedersen, and F. Chen, “A trainable document summarizer,”
Advances in Automatic Summarization, pp. 55–60, 1999.
1018[20] J. Goldstein, M. Kantrowitz, V . Mittal, and J. Carbonell, “Summarizing
text documents: Sentence selection and evaluation metrics,” in Pro-
ceedings of the 22nd Annual International ACM SIGIR Conference on
Research and Development in Information Retrieval. ACM, 1999, pp.
121–128.
[21] J.-Y . Yeh, H.-R. Ke, W.-P . Yang, and I.-H. Meng, “Text summarization
using a trainable summarizer and latent semantic analysis,” Information
Processing & Management, vol. 41, no. 1, pp. 75–95, 2005.
[22] Y .-H. Hu, Y .-L. Chen, and H.-L. Chou, “Opinion mining from online
hotel reviews–a text summarization approach,” Information Processing
& Management, vol. 53, no. 2, pp. 436–449, 2017.
[23] Y . Ye and K. Kishida, “Toward an understanding of the motivation of
open source software developers (pp. 419-429),” IEEE. doi, vol. 10,
2003.
[24] Python Mailing List Discussions. (2010) PEP 386 and PEP 345.
[Online]. Available: https://mail.python.org/pipermail/python-dev/2010-
January/097045.html
[25] ——. (2015) What’s going on with PEP 448 -
Additional Unpacking Generalizations? [Online]. Available:https://mail.python.org/pipermail/python-list/2000-August/051942.html
[26] ——. (2011) PEP 393 close to pronouncement. [On-
line]. Available: https://mail.python.org/pipermail/python-dev/2011-September/113701.html
[27] ——. (2005) PEP 265 & 284 Rejection — python-dev Summary
for 2005-06-16 through 2005-06-30 [draft]. [Online]. Available:https://mail.python.org/pipermail/python-dev/2005-July/054624.html
[28] S. AbdelRahman, B. Hassan, and R. Bahgat, “A new email retrieval
ranking approach,” International Journal of Computer Science & Infor-
mation Technology, vol. 2, no. 5, pp. 44–63, October 2010.
[29] R. Buyya, M. Murshed, D. Abramson, and S. V enugopal, “Scheduling
parameter sweep applications on global grids: a deadline and budgetconstrained cost–time optimization algorithm,” Software: Practice and
Experience, vol. 35, no. 5, pp. 491–512, 2005.
[30] W. B. Croft, D. Metzler, and T. Strohman, Search Engines:
Information Retrieval in Practice, 2015. [Online]. Available:https://ciir.cs.umass.edu/downloads/SEIRiP .pdf
[31] Python Mailing List Discussions. (2001) PEP 259 Rejection —
PEP 259 – Omit printing newline after newline. [Online]. Available:https://www.python.org/dev/peps/pep-0259/
[32] ——. (2007) PEP 3128 Rejection — PEP 3128 – BList: A Faster List-
like Type. [Online]. Available: https://www.python.org/dev/peps/pep-3128
[33] ——. (2001) PEP 264 Acceptance — Objections to PEP 264.
[Online]. Available: https://mail.python.org/pipermail/python-dev/2001-August/017091.html
[34] ——. (2001) PEP 268 Rejection — PEP 268 - Ex-
tended HTTP functionality and WebDA V . [Online]. Available:
https://www.python.org/dev/peps/pep-0268/
[35] ——. (2002) PEP 279 Acceptance. [Online].
Available: https://mail.python.org/pipermail/python-checkins/2002-April/025640.html
[36] ——. (2005) PEP 308 Acceptance — Conditional Expression Res-
olution. [Online]. Available: https://mail.python.org/pipermail/python-dev/2005-September/056846.html
[37] ——. (2004) PEP 285 Acceptance. [Online].
Available: https://mail.python.org/pipermail/python-checkins/2002-
April/025716.html
[38] ——. (2004) PEP 326 Rejection — PEP 326 (quick location possibility).
[Online]. Available: https://mail.python.org/pipermail/python-dev/2004-January/042306.html
[39] R. Mr ´owka, “Decision-making in the process of implementation of open
source projects.” Business Systems & Economics, vol. 2, no. 2, pp. 39–
49, 2012.
[40] The Mail Archive. (2009) PEP 3003 Acceptance — PEP 3003 -
Python Language Moratorium. [Online]. Available: https://www.mail-archive.com/python-dev@python.org/msg43214.html
[41] Python Mailing List Discussions. (2000) PEP 203 Acceptance
— PEP 203 Augmented Assignment. [Online]. Available:https://mail.python.org/pipermail/python-list/2000-August/051942.html
[42] ——. (2007) PEP 3131 Acceptance — PEP 3131:
Supporting Non-ASCII Identiﬁers. [Online]. Available:https://mail.python.org/pipermail/python-list/2007-May/449001.html[43] R. Mr ´owka, “Decision-making in the process of implementation of open
source projects.” Business Systems & Economics, vol. 2, no. 2, pp. 39–
49, 2015.
[44] Python Mailing List Discussions. (2018) PEP 572 Acceptance — How
about integrating “as” semantics and postpone PEP 572 to Python 4.0.[Online]. Available: https://mail.python.org/pipermail/python-dev/2018-July/154400.html
[45] ——. (2005) PEP 308 Acceptance — python-dev Summary
for 2005-09-16 through 2005-09-30. [Online]. Available:https://mail.python.org/pipermail/python-dev/2005-July/054624.html
[46] ——. (2014) PEP 465 Acceptance — Fwd: [RFC] draft PEP:
Dedicated inﬁx operators for matrix multiplication and matrix
power. [Online]. Available: https://mail.python.org/pipermail/python-
ideas/2014-March/027053.html
1019