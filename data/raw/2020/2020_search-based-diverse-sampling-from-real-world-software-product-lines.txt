Search-based Diverse Sampling from Real-world Software
Product Lines
Yi Xiang
xiangyi@scut.edu.cn
South China University of
Technology
Guangzhou, ChinaHan Huang∗
hhan@scut.edu.cn
South China University of
Technology
Guangzhou, ChinaYuren Zhou
School of Computer Science and
Engineering, Sun Yat-Sen
University
Guangzhou, China
Sizhe Li
South China University of
Technology
Guangzhou, ChinaChuan Luo
Microsoft Research
Beijing, ChinaQingwei Lin
Microsoft Research
Beijing, China
Miqing Li
University of Birmingham
Birmingham, UKXiaowei Yang∗
xwyang@scut.edu.cn
South China University of
Technology
Guangzhou, China
ABSTRACT
Real-world software product lines (SPLs) often encompass
enormous valid conﬁgurations that are impossible to enu-merate. To understand properties of the space formed byall valid conﬁgurations, a feasible way is to select a smal-
l and valid sample set. Even though a number of sampling
strategies have been proposed, they either fail to producediverse samples with respect to the number of selected fea-tures (an important property to characterize behaviors ofconﬁgurations), or achieve diverse sampling but with lim-ited scalability (the handleable conﬁguration space size islimited to 10
13). To resolve this dilemma, we propose a scal-
able diverse sampling strategy, which uses a distance metricin combination with the novelty search algorithm to produce
diverse samples in an incremental way. The distance metric
is carefully designed to measure similarities between conﬁg-urations, and further diversity of a sample set. The noveltysearch incrementally improves diversity of samples throughthe search for novel conﬁgurations. We evaluate our sam-pling algorithm on 39 real-world SPLs. It is able to generatethe required number of samples for all the SPLs, includingthose which cannot be counted by sharpSAT, a state-of-the-art model counting solver. Moreover, it performs better than
∗Corresponding authors.
Permission to make digital or hard copies of all or part of this work
for personal or classroom use is granted without fee provided thatcopies are not made or distributed for proﬁt or commercial advan-tage and that copies bear this notice and the full citation on the ﬁrstpage. Copyrights for components of this work owned by others thanACM must be honored. Abstracting with credit is permitted. To copyotherwise, or republish, to post on servers or to redistribute to lists,requires prior speciﬁc permission and/or a fee. Request permissionsfrom permissions@acm.org.
ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA©2022 Association for Computing Machinery.
ACM ISBN 978-1-4503-9221-1/22/05... $15.00
https://doi.org/10.1145/3510003.3510053or at least competitively to state-of-the-art samplers regard-
ing diversity of the sample set. Experimental results suggestthat only the proposed sampler (among all the tested ones)achieves scalable diverse sampling.
CCS CONCEPTS
•Software and its engineering →Search-based soft-
ware engineering ;•Mathematics of computing →
Optimization with randomized search heuristics .
KEYWORDS
Software product lines, diverse sampling, novelty search, dis-tance metric
ACM Reference Format:
Yi Xiang, Han Huang, Yuren Zhou, Sizhe Li, Chuan Luo, Qing-
wei Lin, Miqing Li, and Xiaowei Yang. 2022. Search-based Diverse
Sampling from Real-world Software Product Lines. In 44th Inter-
national Conference on Software Engineering (ICSE ’22), May21–29, 2022, Pittsburgh, PA, USA. ACM, New York, NY, USA,
13 pages. https://doi.org/10.1145/3510003.3510053
1 INTRODUCTION
Softwareproductlines(SPLs)[11],beinghighlyconﬁgurable,
allow users to derive products by selecting and deselectingfeatures, which are increments of product functionality. That
is, a set of features deﬁnes a unique product (or conﬁgura-
tion) of an SPL. Clearly, as the number of features increases,
the number of all possible conﬁgurations grows exponential-
ly [41]. A common tool for representing all valid conﬁgura-
tions is a tree-like structure, called a feature model (FM)
[32], in which features and constraints among them are ex-plicitly speciﬁed. The space formed by all valid conﬁgura-tionsiscalleda conﬁguration space ,denotedasΨhenceforth.
In practice, because large real-world SPLs often encompass(hundreds of) thousands of features, the size of Ψ, i.e., |Ψ|,
*&&&"$.UI*OUFSOBUJPOBM$POGFSFODFPO4PGUXBSF&OHJOFFSJOH	*$4&
ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Xiang, et al.
could be astronomically large ( /greatermuch1010) [43]. Therefore, it
is rarely possible to enumerate every valid conﬁguration. To
achieve a certain goal, e.g., learning a performance predic-tion model [31], testing SPLs [45], we need to sample from
the conﬁguration space a small set of valid conﬁgurations,
called asample set, where each valid conﬁguration is known
as asample.
Quite often, sample sets must be well-chosen based on
domain knowledge. For instance, a sample set should cov-er allt-wise feature combinations in the context of t-wise
sampling [2, 19, 30]. If no domain knowledge is available,however, sample sets are expected to cover the conﬁgurationspace as widely and uniformly as possible [31, 43]. There
have been several sampling strategies in the literature, e.g.,
random sampling [20, 22, 37–39], solver-based sampling [10,
18, 24, 26], coverage-oriented sampling [ 2 ,1 9 ,3 0 ]a n d u-
niform sampling [1, 9, 40, 42, 43, 49, 51]. These sampling
strategies focus on diﬀerent aspects of sampling from SPLs,and come with diﬀerent strengths and weaknesses (detaileddiscussions are available in Section 6).
Inthispaper,wefocusonanotherkindofsampling,known
asdiverse sampling, which seems to be largely ignored. Di-
verse sampling brings lots of beneﬁts. For example, it couldreduce the risk of missing important conﬁgurations with dis-tinct performance behavior when deriving a performanceprediction model (see [31]), and it forms a scalable and ﬂex-ible alternative to t-wise sampling (see [25, 54]). Recently,
Kaltenecker et al. [31] proposed a diverse sampling strate-gy, called diversiﬁed distance-based sampling (DDbS), which
pursues to derive diverse samples regarding the number of s-
elected features. In fact, the number of selected features for a
conﬁguration c∈Ψ,denotedas T(c),isimportanttocharac-
terize the behavior of this conﬁguration. Pursuing diversity
in terms of this number can directly improve the accuracyof performance prediction, which has been shown in [31].Moreover, the number of selected features is directly treatedas an optimization goal in multi-objective SPL conﬁguration[24, 28, 50, 57]. In such scenarios, a common and importantissue is how to improve the samples’ diversity regarding thisnumber.
Though important, achieving diverse sampling regarding
the number of selected features poses great challenges tostate-of-the-art samplers. Figs. 1 (a) and (b) show the dis-tribution of the number of selected features for samples gen-erated by two recent uniform samplers (i.e., Smarch [43] andUnigen3 [51]) on the HiPAcc feature model [31]. As seen,compared with DDbS [31] [see Fig. 1 (c)], both of them areunable to produce diverse samples concerning the numberof selected features. Notice that even though DDbS couldsample more diverse conﬁgurations on this model, it faces
the scalability issue. In fact, DDbS failed to handle conﬁg-
uration space larger than 10
13[43]. This is also conﬁrmed
by our experiments performed in Section 5.3, and explainedlater in Section 5.5. In summary, these samplers either fail toproduce diverse conﬁgurations, or achieve diverse samplingbut with limited scalability.5 1 01 52 02 53 0Smarch
(a)5 1 01 52 02 53 0Unigen3
(b)
5 1 01 52 02 53 0DDbS
(c)5 1 01 52 02 53 0NSbS
(d)
Figure 1: Distribution of the number of selected fea-tures for samples generated by four samplers onHiPAcc [31]. In this ﬁgure, the x-axis is the num-
ber of selected features in a conﬁguration; ⋆denotes
the estimated boundaries of the above number (seeSection 2.2). Note that these boundaries may notbe reachable. We pursue to cover the range betweenthe two boundaries as diversely as possible.
To enable scalable diverse sampling, this paper provides
an alternative perspective, i.e., search-based sampling. Thekey idea is to generate initial samples using eﬃcient oﬀ-the-
shelf SAT solvers, and then incrementally improve the di-
versity of the sample set using a speciﬁc search algorithm.This sampling strategy relies on a special distance metricand a search technique, called novelty search (NS) [34, 35].We name this sampling algorithm NS-based sampling (NS-
bS for short). To demonstrate merits of NSbS, we compareit with several state-of-the-art sampling algorithms using 39real-world SPLs adopted by Oh et al. [43]. Experimental re-sults reveal that NSbS indeed enables a scalable diverse sam-
pling from SPLs. In particular, it successfully generates the
requested number of conﬁgurations (i.e., 100 conﬁgurationsin our setting) for all 39 SPLs, including the largest ones onwhich most state-of-the-art samplers fail to generate evenone conﬁguration within an hour.
Main contributions of the paper are summarized as fol-
lows.
•A tailored distance metric. By using the number of s-elected features, the conﬁguration space Ψ is mappedto a small behavior space B={T(c)|c∈Ψ}
1.Ad i s -
tance metric is designed to measure similarities be-tween conﬁgurations in both Band Ψ. We show, both
theoretically and experimentally, that using this dis-
tance metric not only improves the coverage in the
behavior space, but also promotes diversity in the o-riginal conﬁguration space. Considering diversity inboth spaces could improve the representativeness ofthe sample sets.
•A beﬁtting search technique. We choose NS as thesearch engine because of its good theoretical proper-ties [16, 17] that well ﬁt the goal of diverse sampling.
1The behavior space is a concept introduced in NS algorithms [34, 35]
Search-based Diverse Sampling from Real-world Software Product Lines ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
Precisely, NS has been shown to tend towards a di-
verse/uniform sampling of the behavior space [16, 17].The above property could help to improve diversityof the sample set in the behavior space. As shown in
Fig.1(d),samplesgeneratedbyNSbSareasdiverseas
those of DDbS, which, as mentioned early, is a tailoreddiverse sampler.
•Flexibility in the sampling process. Since diversity isimproved in an incremental way, it is easy for user-s to achieve a desired trade-oﬀ between diversity andeﬃciency. If a higher-quality sample set is required,then more execution time can be speciﬁed. The ﬂex-ibility in the sampling process is one of the main ad-
vantages of NSbS over other state-of-the-art samplers,
most of which are not controllable regarding the exe-cution time.
2 PRELIMINARIES
In this section, we provide necessary preliminaries on sam-pling from conﬁguration spaces, and the space mapping s-trategy. Moreover, a brief introduction to NS is also present-ed.
2.1 Sampling from conﬁguration spaces
Formally, an FM can be seen as a tuple /angbracketleftF,C/angbracketright,w h e r eF=
{f1,...,f n}is the set of nfeatures, and Cis the set of al-
l constraints among features. A conﬁguration c, represented
by{±f1,...,±fn}, is deﬁned as a set of selected or deselect-
ed features. Precisely, +f iand−fiindicate that the feature
fiis selected and deselected, respectively. In programming,
ccan be represented by a binary string, with 1 indicating a
selected feature, and 0 a deselected one. Due to constraintsinC, not all conﬁgurations are valid. The conﬁguration that
satisﬁes all the constraints is called a valid conﬁguration,and all valid conﬁgurations form the conﬁguration space Ψ.
Many software engineering tasks require to derive a smal-
ls a m p l es e tf r o mΨ .I nt h i sc o n t e x t ,asample set ,S=
{s
1,...,s N}(whereNdenotes the sample size), is a subset
of Ψ, i.e., S⊆Ψ. Manually deriving samples is error-prone
and time-consuming even for tiny FMs. Therefore, automat-ed solvers, like SAT solvers, have been widely adopted togenerate samples from Ψ [25, 36, 57]. It is well-known thatan FM can be easily converted into a propositional formulaφ[6]. The derived φis then used as the input of automated
solvers, which are internally run to ﬁnd solutions to φ.
2.2 Mapping to behavior spaces
As mentioned previously, by characterizing the behavior ofa conﬁguration using the number of selected features, c∈
Ψ is mapped to an integer. Accordingly, the conﬁgurationspace Ψ is mapped into the behavior space B.L e tΦ
bbe
the space formed by all conﬁgurations with exactly b∈B
selectedfeatures,thenΨ = ∪b∈BΦb.Thatistosay,thewhole
conﬁguration space Ψ is decomposed into |B|subspaces. We
can then sample conﬁgurations that are diversely distributedamong these subspaces.Understanding Bis much easier than Ψ due to that |B|
is signiﬁcantly smaller than |Ψ|. In fact, the lower and up-
per bounds for Bcan be approximated by using the num-
ber of core features (denoted by |core|) and the number of
dead features (denoted by |dead|), respectively. Notice that
core features must be selected in every valid conﬁguration,while dead features must not be selected. To be more specif-ic, min(B )≥|core|,a n dm a x ( B)≤n−|dead|,w h e r e nis the
total number of features. Therefore, the size of Bis at most
n−(|core|+|dead|)+1. In contrast, |Ψ|grows exponential-
ly with respect to n. Hence, Ψ can be astronomically large,
especially for large real-world SPLs. For example, |Ψ|is as
large as 7.78 ×10
417for the uClinux-conﬁg model [43]. We
mustmentionthat,intheory,knowingexactly Bisashardas
knowing Ψ because every conﬁguration should be investigat-ed in the worst case. However, Bcan be well approximated
by the following set, B
/prime={|core|,|core|+1,...,n−|dead|},
which contains all possible integers from |core|ton−|dead|.
It is possible that there exist some integers to which no con-ﬁgurations are mapped. Therefore, Bis a subset of B
/prime.I n
Section 4.3, B/primewill be used to calculate performance indica-
tors.
2.3 Novelty search
As mentioned in Section 1, NS [34, 35] is adopted in oursearch-based diverse sampling. Therefore, it is necessary togive a brief introduction to this search technique. NS is oneof the main divergent search algorithms [34], and its promi-nent feature is to abandon objectives [34]: it replaces theconventional goal-oriented objective by a criterion measur-ingnoveltyof individuals. This criterion is referred to as
novelty score, deﬁned as the average distance of an individu-al to itsknearest neighbors, where kis a constant. Formally,
ρ(x), the novelty score of x, is given as follows [16, 34, 35].
ρ(x)=1
kk/summationdisplay
j=1d(x,xj)( 1)
wherexjis thej-th nearest neighbor of xamong an archive
of previously explored individuals and the current popula-tion in the behavior space; d(x,x
j) is any distance metric.
ρ(x) estimates the sparseness of xin the behavior space. If
this score is large, then xis in a sparse area; in contrast, it
is in a dense area in case that the novelty score is small. Ingeneral, individuals in sparse regions are preferred to thosein dense regions as the exploitation around sparse regionsis helpful to perform a diverse exploration of the behaviorspace [16].
Following the practice in [54], the calculation of the nov-
elty score can be extended from a single conﬁguration to asample set S={s
1,...,s N}. Speciﬁcally,
ρ(S)=N/summationdisplay
i=1ρ(si)( 2)
whereρ(si) is the novelty score of a single conﬁguration, as
given by Eq. (1). Clearly, the higher the novelty score, themore diverse the sample set.
ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Xiang, et al.
Finally, it is worth mentioning that there is an interesting
search behavior of NS. That is, the sampling produced by NS
covers the whole reachable behavior space [16]. This suggests
that NS explores the behavior space diversely. It is a good
property, which well matches the goal of diverse sampling
from SPLs. Therefore, we choose NS as the search engine.
3 NS-BASED DIVERSE SAMPLING
The NSbS procedure is outlined in Algorithm 1. The keyidea is to continuously improve diversity of the initial sam-
ple set through the search for novelindividuals (i.e., conﬁg-
urations). The algorithm takes the propositional formula φ
(derived from a given FM) and the sample size Nas input,
and outputs a set of samples stored in an archive A.
Algorithm 1: NSbS algorithm
Input:φ(propositional formula), N(sample size)
Output: A(archived samples)
1Initialize the archive Aby generating Nsolutions to φ
using the randomized SAT4J solver [25];
2Initialize the distance matrix D=(dij)(N+1)× (N+1),
wheredij(i,j=1,...,N), as given in Eq. (3), is the
distance between xi∈Aandxj∈A;
3For each x∈A, calculate its novelty score ρ(x)b a s e d
on Eq. (1);
4whilethe termination condition is not met do
5{p1,p2}←matingSelection (A);
6{c1,c2}←crossover (p1,p2);
7fori∈{1,2}do
8 ci←mutation( ci);
9 ifciis invalid then
10 Repairciusing the probSAT solver [5];
11 end
12 A←updateAchive( A,ci);
13end
14end
15returnA
3.1 Initialization
As shown in Line 1 of Algorithm 1, Ais initialized with N
conﬁgurations generated by the randomized SAT4J solver
[7], in which the order how the logical clauses and the lit-erals are parsed is randomized [24]. According to the im-plementation in [24, 26], there exist three parsing strate-gies, i.e.,NegativeLiteralSelectionStrategy, PositiveLiteralSe-
lectionStrategy andRandomLiteralSelectionStrategy.E a c hs -
trategy has an equal chance of being chosen when generatinginitial conﬁgurations. In particular, the ﬁrst strategy prefersnegative assignments to literals, and thus emphasizes con-ﬁgurations with less selected features. Therefore, the lowerbound of Bcan be approximated by using this strategy. Sim-
ilarly, the second strategy helps to approximate the upperbound of B. The third strategy randomly assigning trueorfalseto literals is able to improve randomness of the generat-
edconﬁgurations.Usingsimultaneouslythreestrategiesaimsat improving diversity of the initial sample set. In particular,bounds of Bcould be well approximated. We should mention
that this SAT-based seeding, instead of random seeding, isused here because the former always generates valid conﬁgu-rations while the latter is highly likely to generate unwantedinvalid ones due to the constraints.
3.2 Distance metric
To measure similarities between two conﬁgurations, we de-ﬁne the following distance
2:
dij=d(xi,xj)=1
2·/parenleftbiggabs(T(xi)−T(xj))
n/parenrightbigg
+1
2·/parenleftbigg
1−|xi∩xj|
n/parenrightbigg
·δ(3)
wherexi,xj∈A(xi/negationslash=xj) are two diﬀerent conﬁgurations;
T(xi) denotes the number of selected features in xi;abs(·)
returns the absolute value of a number; and |·|returns the
cardinality of a set. δis a constant, as given below.
δ=/braceleftBigg1
max{T(xi),T(xj)}T(xi)+T(xj)≤n,
1
n−min{T (xi),T(xj)}otherwise.(4)
Asseen,thisdistancemetricconsistsoftwoweightedpart-
s. The ﬁrst part measures the similarity between conﬁgura-tions in the behavior space, while the second part in the
original conﬁguration space. In fact, 1 −|xi∩xj|
nis the Ham-
ming distance [3] between xiandxj. Note that using the
above two parts is intended to sample conﬁgurations cov-
ering diversely in the behavior space, and also keeping asdissimilar as possible in the conﬁguration space. In Section
5.1, we will experimentally verify this distance metric.
It is also worth noting that δis set based on our theoret-
ical analysis, which shows that δis needed to mitigate bias-
es towards sampling speciﬁc conﬁgurations. In other words,
Eq.(3) without using δcan introduce biases in the behav-
ior space, and thus can hamper diversity of the sample set.Detailed analysis can be found in Section S-1 of the supple-ment
3. In Section 5.2, we will experimentally investigate δ’s
eﬀects. Therein, one will ﬁnd that using δindeed improves
diversity of the sample set in the behavior space.
According to Line 2 in Algorithm 1, the distance matrix
D(N+1)× (N+1)is initialized by working out the distance be-
tween each pair of conﬁgurations in A. Note that, since D
is symmetric, we only need to calculate distances for half ofthese pairs. We would like to mention that the size of Dis
(N+1)×(N+1), rather than N×N, because we reserve
spaces for storing distances when evaluating a new conﬁg-uration (see Algorithm 2). After obtaining D,a ss h o w ni n
Line 3 of Algorithm 1, the novelty score for each x∈Ais
calculated based on Eq. (1).
2Ifxi=xj,dijis forcibly set to 0.
3The online supplement is available at https://doi.org/10.5281/
zenodo.5828178
Search-based Diverse Sampling from Real-world Software Product Lines ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
3.3 Genetic operations
Like in genetic algorithms, we perform in order the mating
selection, crossover and mutation to generate new individu-als. As shown in Line 5 of Algorithm 1, the matingSelection
procedure chooses from Atwo parents p
1andp2each time.
The basic idea of choosing a parent is to select the one withlarger novelty score from two diﬀerent random members inA. In case of a tie, a random selection is performed betweenthe two members. Clearly, the above mating selection em-phasizes individuals located in sparse regions. Explorationaround sparse regions could potentially improve diversity ofthe samples.
Algorithm 2: A←updateAchive (A,c)
Input:A,c
Output: A
1ifAcontains cthen
2returnA;
3end
4fori=1,...,Ndo
5di,(N+1)←d(xi,c);
6d(N+1),i←di,(N+1);
7end
8d(N+1),(N+1)←0;
9For each x∈A∪c, calculate its novelty score ρ(x)
based on Eq. (1);
10xworst←argmin
x∈Aρ(x) // Find the worst member in A;
11ifρ(c)>ρ(xworst)then
12xworst←c;
// Update D
13forj=1,...,Ndo
14 dj,worst←dj,(N+1);
15 dworst,j←d(N+1),j;
16end
17dworst,worst ←0;
18end
19returnA
Once two parents p1andp2have been selected, the uni-
form crossover is applied to generate two children, c1andc2
(Line 6 in Algorithm 1). To be speciﬁc, for each index j∈
{1,...,n}, we generate a random number rand.I frand <
0.5, then c1(j)a n dc 2(j) are set to p1(j)a n dp2(j), respec-
tively. Otherwise, they are set to p2(j)a n dp1(j), respec-
tively. Notice that c1(j) denotes the value taken in the j-th
position of c1. The newly generated individuals are then sub-
jected to bit-wise mutation (Line 8 in Algorithm 1). Specif-
ically, for each bit, the value is changed from 1 (true) to 0
(false), or vice versa. Often, the ratio of bits to be changedis controlled by a parameter P
μ, called mutation probability.
In this work, we set Pμto 0.1, following the common practice
in [55].
Itisnotuncommonthattheresultingconﬁgurations(after
crossover and mutation) are invalid. In this case, as shownin Line 10 of Algorithm 1, the probSAT solver [5], one of thehigh-performing stochastic local search (SLS) SAT solvers, isadopted to repair invalid conﬁgurations. The variables to beﬂipped by the solver are chosen based on probabilities such
that more promising variables are given more chances to be
selected. In fact, probSAT [5] has been adopted to repairinfeasible conﬁgurations in prior work [56, 57] in the con-text of optimal products selection from SPLs. In particular,the empirical study in [56] suggested that probSAT is moreeﬀective than WalkSAT [8], another popular SLS solver, inimproving diversity of a conﬁguration set. For more detailson probSAT, we direct readers to the original study [5]. No-tice that internal parameters of this solver are set following
the practice in [5] and [56]. Therefore, a tuning phase is not
required in this work.
Conﬁgurations operated by probSAT could still be invalid
(even though they are valid most of the time)
4,i np a r t i c u l a r
for large-scale FMs. In case of invalidity, we simply requestto the randomized SAT solver, as described in Section 3.1,to return a valid conﬁguration.
3.4 Updating archive
The archive Astores novel conﬁgurations discovered during
the search process. Its update procedure is presented in Al-gorithm 2. To improve diversity, as shown in Lines 1-3, theproducer rejects the entrance of any conﬁguration that is i-dentical to already archived ones. When a totally diﬀerentconﬁguration cis available, we need to ﬁll the distance ma-
trixDby working out distances between cand each x
i∈A.
Thesedistancesarestoredin thelastrowand thelastcolum-n. In what follows, as indicated in Line 9 of Algorithm 2, the
novelty score for each member x∈A∪cis calculated based
on Eq. (1). We should note here that the novelty scores are
computed taking into account not only members in Abut
also the new conﬁguration c. This enables an evaluation of
the novelty with respect to both previously explored individ-uals and the current one that represents the most recentlyvisited point [34].
In Line 10 of Algorithm 2, we ﬁnd the worst member from
A, and this member is denoted by x
worst, where the index
worstis its position in the archive. In case that the novel-
ty score of cis higher than that of xworst, we will replace
xworstbyc. Subsequently, the distance matrix should be
updated. This is achieved by simply copying the last row(column) to the worst-th row (column) (see Lines 13-16).
At last,d
worst,worst should be set to 0.
According to the above update procedure, the algorithm
consistently looks for novel individuals, pushing individualsto constantly move in the behavior space: in new and un-
explored areas ﬁrst, but also then in already explored areas
as their density of individuals is never exactly homogeneous
[17]. This way, diversity of the samples can be persistentlyimproved.
4Diﬀerent from conﬂict-driven clause learning solvers [14], such as
SAT4J, SLS-type SAT solvers oﬀer no guarantees on ﬁnding valid
assignments.
ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Xiang, et al.
3.5 Termination conditions
Termination of NSbS can be ﬂexibly speciﬁed by users. We
oﬀer the following two termination strategies.
Strategy 1:Terminationcontrolledbythemaximumrun-
ning time (max t). This is a common way of stopping a
search algorithm, and the setting of maxtdepends largely
on the demands of users.
Strategy 2: Automatic termination when the algorithm
gets relatively steady. This is achieved by adding the follow-ing piece of codes after Line 13 in Algorithm 1.
If
|ρ(/tildewideA)−ρ(A)|
ρ(/tildewideA)<0.1%
counter++
Else
counter ←0
End
where /tildewideAis the old archive, while Ais the newly updated
one. If the change ratio of novelty scores for the two archives
is below 0.1%, then counter is increased by one; otherwise, it
is reset to 0. The algorithm will terminate once counter ex-
ceedsR,at h r e s h o l ds p e c i ﬁ e db yu s e r s .I no u re x p e r i m e n t s ,
we setRto 10. With this setting, it is found that NSbS
automatically terminates on almost all of the tested FMs.
We would like to mention that we give users freedom to
specify the termination of the sampling process. Most of the
state-of-the-art samplers are not controllable with respectto the execution time. Indeed, it may take excessively long
before a set of samples is returned [43, 47]. Instead, the pro-
posed NSbS allows users to make a desired trade-oﬀ betweenquality (primarily diversity) and eﬃciency. If users want ahigher-quality sample set, he/she can set Rormax
tto a
relatively larger value. The ﬂexibility regarding terminationsis one of the main advantages of NSbS over other state-of-the-art samplers.
4 EXPERIMENT SETUP
Inthissection,westartbyintroducingourresearchquestion-s (RQs). Then, we give information about FMs used in our
empirical study. Subsequently, we describe how the perfor-
mance of diﬀerent samplers can be measured using special-ized indicators. Finally, detailed implementations are given.
4.1 Research Questions
The distance metric is expected to play an important rolein sampling products that are diverse not only in the be-havior space, but also in the original conﬁguration space. Itis necessary to investigate the eﬀect of components in Eq.(3). With this regard, we aim at answering the following twoRQs.
RQ1:What are the beneﬁts brought by using the two weight-
ed parts in the distance metric?
RQ2:Does the factor δmatter in the distance metric of
NSbS?
To address RQ1, we perform an ablation study where the
distancemetricdeﬁnedinEq.(3)iscomparedagainstamod-iﬁed one in which the second part is removed. Our primarygoal is to sample diverse conﬁgurations in the behavior spaceB. On top of this, we also expect that they are as diverse as
possible in the conﬁguration space Ψ. The ﬁrst part in thedistance metric is designed for the primary goal, and elimi-nating it will lead to failure of this goal (because the second
part only measures similarity in Ψ). Hence, we only remove
the second part in the ablation study. According to our theo-retical analysis, the goal of δin Eq. (3) is to alleviate biases
towards speciﬁc conﬁgurations in the behavior space. Thesecond research question amounts to experimentally verify-ing this.
Moreover, we intend to answer two more research ques-
tions regarding the eﬀectiveness of NSbS in comparison withseveral state-of-the-art samplers, and impacts of the param-
eterk.
•RQ3:How eﬀective is NSbS concerning both scalabil-
ity and diversity in comparisons with state-of-the-art
samplers?
•RQ4:How is the performance of NSbS aﬀected by its
key parameter k?
To address RQ3, we compare NSbS with SAT-based sam-
pling [24], DDbS [31], UniGen3 [51] and Smarch [43]. Weexpect that NSbS performs better than or at least competi-tively to them with respect to both scalability and diversity.Finally, the fourth research question seeks to provide useful
guidelines for tuning NS in the context of diverse sampling
from SPLs.
4.2 Subject Feature Models
In our experiments, we consider 39 FMs that have been care-fully selected by Oh et al. [43] in their evaluation of Smarch.Table 1 gives an overview of the subject FMs, including thenumber of features (|F|), the number of CNF constraints(|C|), the size of the conﬁguration space ( |Ψ|), the num-
ber of core, dead and unconstrained
5features (i.e., |core|,
|dead|and|uc|). Note that |Ψ|is counted by sharpSAT [53],
which fails on the last ﬁve largest FMs. All FMs are publiclyavailable in DIMACS format
6, the standard format for SAT
solvers.
4.3 Performance indicators
Performance indicators are required to evaluate the quali-ty of a sample set S={s
1,...,s N}. To measure whether
Swidely covers the behavior space B={b1,...,b |B|},m o t i -
vated by the deﬁnition of inverted generational distance [12],the following indicator, which we call Spread, is deﬁned.
Spread(S,B)=1
|B||B|/summationdisplay
i=1dmin(bi,S), (5)
wheredmin(bi,S) denotes the minimum distance from bito
S. Mathematically, dmin(bi,S) is in the following form
dmin(bi,S)=N
min
j=1abs(bi−T(sj)). (6)
5Unconstrained features here are those that are not involved in the
CNF constraints.
6All FMs are downloaded from https://github.com/jeho-oh/Smarch
Search-based Diverse Sampling from Real-world Software Product Lines ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
Table 1: Overview of the subject feature models
FM |F| |C| |Ψ || core||dead|| uc|
lrzip 20 63 1.44E+ 02 2 0 0
LLVM 11 1 1.02E+ 03 1 0 10
X264 16 11 1.15E+ 03 3 0 7
Dune 17 16 2.34E+ 03 2 0 0
BerkeleyDBC 18 19 2.56E+ 03 2 0 7
HiPAcc 31 104 1.35E+ 04 1 0 0
JHipster 45 104 2.63E+ 04 7 0 0Polly 40 100 4.00E+ 04 9 0 0
7z 44 210 6.86E+ 04 5 0 0
JavaGC 39 105 1.93E+ 05 7 0 0
VP9 42 104 2.16E+ 05 9 0 0
ﬁasco
1710 234 1178 1.00E+ 10 7 6 7
axTLS214 94 190 2.00E+ 12 4 0 2
ﬁasco 1638 5228 3.58E+ 14 49 964 6toybox 544 1020 1.45E+ 17 4 365 0axtls 684 2155 4.29E+ 20 3 381 0uClibc-ng
1029 269 1403 8.00E+ 26 14 0 37
toybox075 316 106 1.40E+ 81 8 15 203
uClinux 1850 2468 1.63E+ 91 7 1237 0
ref4955 1218 3099 8.20E+ 123 0 50 0
adderII 1276 3206 3.57E+ 125 0 37 0
ecos-icse11 1244 3146 4.97E+ 125 0 35 0m5272c3 1323 3297 2.37E+ 125 0 43 0pati 1248 3266 7.90E+ 126 0 47 0
olpce2294 1274 3881 8.19E+ 126 0 42 0integrator
arm9 1267 50606 4.06E+ 129 0 44 0
at91sam7sek 1319 3963 9.45E+ 131 0 74 0
se77x9 1319 49937 1.20E+ 135 0 58 0
phycore229x 1360 4026 1.77E+ 136 0 89 0
busybox-1.18.0 6796 17836 8.50E+ 216 12 3939 0busybox
1280 998 962 1.30E+ 248 12 0 177
embtoolkit 23516 180511 2.10E+ 252 839 6561 1freebsd-icse11 1396 62163 8.39E+ 313 3 38 50uClinux-conﬁg 11254 31637 7.78E+ 417 15 6012 0buildroot 14910 45603 / 100 6895 12freetz 31012 102705 / 117 14445 02.6.28.6-icse11 6888 343944 / 58 102 41
2.6.32-2var 60072 268223 / 1100 31960 12
2.6.33.3-2var 62482 273799 / 1200 33233 12
Regarding B, as mentioned in Section 2.1, it is not exactly
known,butcanbeeasilyapproximatedby B/prime.Inpractice,w e
therefore calculate Spread(S,B/prime), instead of Spread(S,B).
It is clear that a smaller value of Spreadindicates a more
diverse distribution in the behavior space. In addition toSpread, the novelty score of a sample set, ρ(S), as given in
Eq. (2), also serves as a performance indicator. It measuresthe diversity of Sin the original conﬁguration space.
4.4 Detailed implementations
For each FM, we sample 100 conﬁgurations and compute theaverage sampling time per conﬁguration (measured in mil-liseconds) to compare eﬃciency. All samplers except NSbS
terminate once 100 conﬁgurations are sampled, or the sam-
pling time takes more than 3600,000 milliseconds (i.e., onehour). Since NSbS is able to quickly sample 100 conﬁgura-tions, it terminates either automatically based on Strategy
2as described in Section 3.5, or forcibly when the sampling
time reaches a timeout of one hour. Note that, to mitigaterandom bias, all samplers are independently run 30 times,and we present and analyze experimental results regardingmean values of the performance indicators.
All experiments are performed on a Quad Core@2.20 GHz
with 8 GB of RAM running Ubuntu 20.04.2. Source codes
of SAT-based sampling [24], DDbS [31], UniGen3 [51] and
Smarch [43] are downloaded from their authors’ repositories,and they are all executed on a single thread (i.e., withoutparallelization), following the practice in [27]. The codes ofNSbS can be found in our repository
7.
5R E S U L T S
In this section, we provide a series of experimental results re-garding the research questions. Due to limited space, raw re-sultsaregiveninTablesS-1toS-3intheonlinesupplement
8.
To determine whether the diﬀerence between diﬀerent algo-rithms (over all the 30 runs) is signiﬁcant or not, followingguidelines suggested by Arcuri and Briand [4], the Mann-
Whitney U test with a 0.05 signiﬁcance level is performed
for each FM. In these tables, test results are represented bythree symbols: •,‡and◦, indicating that the algorithm in
the ﬁrst column performs better than, equivalently to andworse than the algorithm in other columns, respectively. Inthe following subsections, the performance comparisons arebased on these results.
5.1 RQ1: Beneﬁts brought by using the
two weighted parts in the distance
metric
To investigate beneﬁts brought by using two weighted parts
in Eq.(3), we consider two diﬀerent distance metrics. Theﬁrst one, as given in Eq.(3), uses two weighted parts. Here-after, we call it weighted distance. The second one retains
only the ﬁrst part, and therefore measures only the similar-ity in the behavior space. This metric is called unweighted
distance. Both distance metrics are tested within the same
NS framework in which k= 15. This setting of khas been
widelyemployedin NS-related literature [21]. Ourtuning ex-
perimentspresentedinSection5.4suggestthat k=1 5i sa l s o
a good setting in our context. When the weighted distance is
used, the sampling algorithm automatically terminates ac-cording to Strategy 2.I nt h ec a s eo funweighted distance,
the termination is controlled by Strategy 1,i nw h i c hmax
t
is set to the running time consumed by the correspondingalgorithm using the weighted distance. This setting allows
us to investigate the beneﬁts while eliminating potential im-pacts brought by using diﬀerent running time.
Regarding Spread,t h eweighted distance performs signif-
icantly better than its counterpart on 3 out of all the 39FMs, but worse on only one FM, i.e., the simplest LLVM.For all the remaining 35 FMs, the two distance metrics havesimilar performance. The above results suggest that usingalone the ﬁrst part of Eq. (3) (which measures similarities inthe behavior space) is enough to obtain good spread in the
behavior space in the majority of the cases.
7https://github.com/YiXiangScut/NSbS
8https://doi.org/10.5281/zenodo.5828178
ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Xiang, et al.
Regarding the novelty score, the weighted distance shows
signiﬁcant improvements over the unweighted one on 26 out
of39FMs(67%),anddegenerationsononlylrzipand2.6.33.3-
2var. Clearly, the second part of Eq. (3) is necessary in pro-
moting diversity in the original conﬁguration space.
Therefore,theanswertoRQ1isclear. Using the two weight-
ed parts in Eq. (3) indeed brings beneﬁts: it improves cover-
age in the behavior space; at the same time, it also promotesdiversity in the original conﬁguration space. Boosting diver-sity in both spaces is beneﬁcial for enhancing representative-n e s so ft h es a m p l es e t .
5.2 RQ2: δmatters in the distance metric
According to Section 3.1, δin Eq. (3) is used to mitigate
potential biases towards speciﬁc conﬁgurations. In this sec-tion, we are going to experimentally examine the eﬀects ofthis factor. To this end, we compare NSbS (described in Al-gorithm 1) against its variant, i.e., NSbS- δin which δis
omitted in the distance metric. The only diﬀerence betweenthe two algorithms is the presence or absence of δ.
0 200 400 600 800 1000NSbS
1000 2000 3000 4000 5000 6000NSbS
0 200 400 600 800 1000NSbS- δ
(a)1000 2000 3000 4000 5000 6000NSbS- δ
(b)
Figure 2: Conﬁgurations sampled by NSbS widelycover the behavior space, while those sampled byNSbS-δ fail. (a) ref4955, (b) 2.6.28.6-icse11
As shown by the Spreadresults, NSbS performs better
than or at least comparably to NSbS-δ on all the 39 FMs. In
particular,NSbSsigniﬁcantlyoutperformsitscounterparton25/39 = 64% of the FMs. Moreover, the improvements are
mostly observed on large FMs. Taking ref4955 and 2.6.28.6-icse11 as example, Fig. 2 graphically shows the distributionof the sampled conﬁgurations in the behavior space. As seen,conﬁgurations sampled by NSbS are distributed more wide-ly than those sampled by NSbS- δon the two FMs. More
speciﬁcally, conﬁgurations of NSbS-δ cover intensively in the
middle part, but sparsely at the boundaries.
The above experimental results bring out the following.
Theδindeed matters: when δis omitted, diversity of the
sampled conﬁgurations is signiﬁcantly aﬀected in the behav-ior space. In particular, boundaries of the behavior space tendnot to be suﬃciently covered. The above experimental result-s are in line with our theoretical ﬁndings, stating that theadoption of δis able to mitigate bias towards sampling spe-
ciﬁc conﬁgurations.Table 2: Time taken to sample a conﬁguration (inmilliseconds). timeout = one hour
FM NSbS SAT-based DDbS Unigen3 Smarch
lrzip 2 1 18 <1 185
LLVM 2 <15 <1 110
X264 87 <11 0 <1 151
Dune 2 <11 4 <1 163
BerkeleyDBC 148 <11 4 <1 165
HiPAcc 2 <1 99 5 329
JHipster 10 <1 161 1 388
Polly 92 <1 400 1 373
7z 120 <1 1299 3 467
JavaGC 9 <1 780 1 381
VP9 6 <1 2412 2 396
ﬁasco1710 12 <1 timeout 15 3260
axTLS2146 <1 timeout 12 895
ﬁasco 93 1 timeout 20 58003
toybox 13 <1 timeout 7 7123
axtls 14 1 timeout 34 13515
uClibc-ng 1029 7 <1 timeout 4681 4239
toybox0757 <1 timeout 231 3492
uClinux 61 2 timeout 258 39713
ref4955 46 1 timeout timeout 37299
adderII 49 1 timeout timeout 48508
ecos-icse11 40 1 timeout timeout timeout
m5272c3 45 1 timeout timeout 43946
pati 46 1 timeout timeout 38404
olpce2294 51 1 timeout timeout 53946
integrator arm9 65 2 timeout timeout 377666
at91sam7sek 49 1 timeout timeout 45776
se77x9 70 2 timeout timeout timeout
phycore229x 49 1 timeout timeout 56323
busybox-1.18.0 202 3 timeout timeout timeoutbusybox
12803 7 <1 timeout timeout 18087
embtoolkit 2306 35 timeout timeout timeoutfreebsd-icse11 201 7 timeout timeout timeoutuClinux-conﬁg 296 7 timeout timeout timeoutbuildroot 6916 21 timeout timeout timeout
freetz 16540 35 timeout timeout timeout
2.6.28.6-icse11 558 29 timeout timeout timeout
2.6.32-2var 36000 256 timeout timeout timeout2.6.33.3-2var 36000 289 timeout timeout timeout
5.3 RQ3: Eﬀectiveness of NSbS in
comparison with state-of-the-art
samplers
Table 2 gives the average time (measured in milliseconds)
to sample a single conﬁguration for all FMs. If the samplingcan not ﬁnish within one hour, then we declare a timeout.
AccordingtoTable2,SAT-basedsimplerscalesverywell,be-ing able to sample one conﬁguration within 300 millisecondseven for the largest FM, i.e., 2.6.33.3-2var. Quite often, thesampling takes no more than 1 millisecond. For DDbS, it canonlyhandle11smallFMswith |Ψ|≤2.16×10
5.ForUnigen3,
it succeeds in dealing with 19 FMs with |Ψ|≤1.63×1091.
Regarding Smarch, it scales better than DDbS and Unigen3,but still fails on 11 FMs. For our NSbS, it dose not en-counter a timeout for all FMs. We would like to mention
that even though NSbS runs out of one hour on 2.6.32-2varand 2.6.33.3-2var, it successfully samples 100 conﬁgurationsas requested. Therefore, we do not declare a timeout.I nf a c t ,
this is totally diﬀerent from the timeout of other samplers,
Search-based Diverse Sampling from Real-world Software Product Lines ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
0 50 1000102030Selected features(#)NSbS
0 50 1000102030Selected features(#)SAT-based
0 50 1000102030Selected features(#)DDbS
0 50 1000102030Selected features(#)Unigen3
0 50 1000102030Selected features(#)Smarch
0 50 100012Difference
0 50 100012Difference
0 50 100012Difference
0 50 100012Difference
0 50 100012Difference
Figure 3: For conﬁgurations generated by each sampler on JHipster, the number of selected features and the
diﬀerence of this number between two successive conﬁgurations are shown in histograms.
which are unable to sample 100 conﬁgurations within one
hour. Regarding the sampling speed, as shown in Table 2,
NSbS is slower than the SAT-based sampler, but much faster
than Smarch.
Table 3 summarizes Wilcoxon’s test results for each pair-
wise comparison between NSbS and each sampler regardingSpread. In this table, available cases refer to those withoutatimeout for both samplers. As can be found, NS performs
better than or at least competitively to other samplers in al-most all the available cases. The only exception is observedon the pairwise comparison between NSbS and DDbS on
the simplest LLVM. In this case, NSbS is signiﬁcantly worse
than DDbS. This exceptional case accounts for 9% of all theavailable 11 cases for the pair NSbS v.s. DDbS. In summa-ry, NSbS is more eﬀective than SAT-based sampler, Unigen3and Smarch in generating diverse conﬁgurations; NSbS andDDbS are able to sample conﬁgurations covering similarly inthe behavior space. However, as discussed previously, DDbSsuﬀers from the scalability issue, being only able to handlevery small FMs.
Table 3: Summary of Wilcoxon’s test results (regard-
ingSpread) for pairwise comparisons between NSbS
and each sampler
NSbS v.s. SAT-based DDbS Unigen3 Smarch
Available cases (#) 39 11 19 28
• 77% 0% 68% 82%
‡ 23% 91% 32% 18%
◦ 0% 9% 0% 0%
For conﬁgurations generated by the ﬁve samplers on JHip-
ster (chosen as an example), we plot in Fig. 3 the number ofselected features, and the diﬀerence of this number betweentwo successive conﬁgurations. Notice that conﬁgurations inthese sample sets are sorted in increasing order based on thenumber of selected features. It can be found in Fig. 3 thatthe number of selected features for NSbS increases more reg-ularly than that for other samplers. To be more speciﬁc, theincrement of this number for NSbS is steady being alwaysone, while it is either one or two for DDbS and Smarch. In
addition,conﬁgurationssampledbyNSbScanbepartitioned
into nearly equal-sized subsets based on the number of se-lected features. For other samplers, however, this partition isless balanced. This can be observed from histograms for the‘diﬀerence’, indicating that some groups have more conﬁgu-rations than others. The above graphical results suggest thatNSbS is capable of sampling conﬁgurations that are widelyand nearly-uniformly distributed in the behavior space.
Experiments performed in this section emphasize the fol-
lowing.First, NSbS and SAT-based sampling are the two best
samplers regarding scalability, and both of them can handleall FMs under study. Second, NSbS and DDbS perform bestconcerning diversity of the samples in the behavior space.Therefore, only NSbS (among all samplers tested in this sec-tion) achieves scalable diverse sampling.
5.4 RQ4: Parameter study on k
In NSbS, kis an important parameter which determines how
many conﬁgurations in the archive are used to calculate thenovelty score. To investigate the impact of this parameter,we consider six values for k, i.e., 2, 15, 25, 50, 75 and 100.
Notice that 2 is the minimum possible value for k.W h e n
k= 2, the novelty score of a conﬁguration is evaluated based
on its two closest neighbors (including itself). The value 15has been widely employed in NS-related literature [21], whilevalues 25, 50, 75 and 100 are 1/4, 1/2, 3/4 and 4/4 of thesample size (i.e., 100), respectively. Testing multiple valuesofkallows us to observe the trend of the performance as
kincreases. Note that, to eliminate the impacts of initial
population, the same set of conﬁgurations is initialized forall values of kin each of the 30 independent run.
Fig. 4 presents, in the form of boxplots, Spreadvalues
over all runs on four representative FMs. It can be foundthatk∈{50,75,100}performs signiﬁcantly worse than k∈
{2,15,25}on all FMs. According to these results, kshould
be set to relatively small values, e.g., k<50. Furthermore,
it can be found that k= 15 yields the best performance on
most of the feature models. Hence, k= 15 is advisable.
ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Xiang, et al.
2 1 52 55 07 5 1 0 0
k020406080100SpreadadderII
2 1 52 55 07 5 1 0 0
k20406080Spreadpati
2 1 52 55 07 5 1 0 0
k20406080100Spreadbusybox_1_28_0
2 1 52 55 07 5 1 0 0
k200400600800Spread2.6.28.6-icse11
Figure 4: Parameter study on kin NSbS. Based on these results, k=1 5is recommended.
Finally, the following conclusions could be drawn based on
the above parameter study. First, the performance of NSbS
is indeed aﬀected by its parameter k. In general, small values
forkare preferred to large ones. Second, the value 15 is rec-
ommended for this parameter. That is to say, in the context
of search-based diverse sampling, we can directly set kto the
value that has been widely used in NS-related studies [21].
5.5 Discussions
It is not surprising that NSbS performs better than SAT-based sampler regarding diversity. In fact, initial populationin NSbS is the outcome of the SAT-based sampler. This ini-tial population is sequently improved by NS in an incremen-tal way. As shown in Fig. 5, novelty scores of the samplesets are persistently improved during the sampling processof NSbS, naturally leading to more and more diverse sam-ples.
0 0.1 0.2 0.3 0.4
Time (s)2.12.22.32.42.5 Novelty scoreDune
02 0 4 0
Time (s)00.511.52 Novelty score2.6.28.6-icse11
Figure 5: Novelty scores of the sample sets are per-
sistently improved during the sampling process ofNSbS
It is also easy to explain why DDbS is computationally
much more expensive than NSbS. In fact, NSbS uses geneticoperations to generate temporary conﬁgurations, and then
adopts probSAT [5] to repair them if necessary. This is an
eﬃcient way of creating new conﬁgurations. Instead, eachtime DDbS requests to the Z3 constraint solver [15] to ﬁnd aconﬁguration with exactly dselected features, where dis uni-
formly drawn from the set of all possible distances. However,it is not always easy to ﬁnd such conﬁgurations because theymay not exist. Sometimes the constraint solver takes long toﬁnd a feasible conﬁguration, or fails to return any one evenafter a long time of running. Hence, DDbS suﬀers from loweﬃciency.
The following is the reason why the two uniform sampler-
s (Unigen3 and Smarch) can not generate diverse samplesin the behavior space. In fact, Unigen3 and Smarch aim atderiving uniform samples in the conﬁguration space. Theuniformity in this space cannot guarantee diversity in thebehavior space. Recall in Section 2.2 that Ψ = ∪
b∈BΦb.I fa
subspace Φ bis larger, then more conﬁgurations will be sam-
pled from this subspace. All these conﬁgurations collapse toa single point in the behavior space. Clearly, this mechanism
could hamper diversity in the behavior space.
5.6 Threats to Validity
In this section, we brieﬂy discuss threats to internal validity
and external validity, as well as how they could be mitigated.
Internal validity. This type of threats can be caused
by potential errors in our implementation of NSbS and thesamplers used for comparisons. To rule out errors in the im-plementation, we have thoroughly tested our codes by ana-lyzing the outcomes step by step on small FMs. For samplers
used in performance comparisons, they were implemented by
codes provided by their authors.
Due to stochastic nature of the samplers under study, out-
comes of diﬀerent runs could be diﬀerent. To diminish ran-dom biases, we independently run the samplers 30 times,and compare them based on mean values of performance in-dicators. In addition, statistical tests are utilized to makereliable comparisons.
External validity. This threat is related to the degree to
which we can generalize from the experiments. To increase
external validity, we select 39 real-world FMs from diﬀerent
domains, and most of them have been widely used by otherstoevaluatetheirsamplingalgorithms[31,43,47].TheseFM-s are representative with respect to the conﬁguration size,which ranges from 10
2to more than 10417. Therefore, we
are conﬁdent that our results could generalize to many moreFMs.
Search-based Diverse Sampling from Real-world Software Product Lines ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
6 RELATED WORK
There are diﬀerent strategies for sampling conﬁgurations
fromSPLs:randomsampling,solver-basedsampling,coverage-oriented sampling and uniform sampling.
Random sampling : The simplest way to create a sam-
ple set is to randomly assign trueorfalseto each feature
for each conﬁguration [22, 37–39]. Due to constraints amongfeatures, however, this method is very likely to generate in-valid conﬁgurations. Instead of randomly selecting features,there exist sampling approaches randomly selecting conﬁg-urations either from all the enumerated conﬁguration space[49], or by using the Monte-Carlo method without exhaustedenumeration [20]. Nevertheless, these approaches also select
invalid conﬁgurations, or suﬀer from low eﬃciency because
of the time-consuming or even impractical enumeration.
Solver-based sampling : Oﬀ-the-shelf SAT or satisﬁabil-
ity modulo theories constraint solvers have been widely used
to derive samples. These solvers include SAT4J [24, 25, 36],PicoSAT [10, 48], Z3 solver [18, 23, 31, 44]) and stochasticlocal search SAT solvers [54, 56, 57]. This kind of samplinggenerally scales well to large real-world SPLs, but oﬀers noguarantees about randomness or coverage [31, 47]. In partic-
ular, to improve the diversity of conﬁgurations, Henard et
al. [24] randomized the order how the logical clauses and theliterals are parsed. The resulting randomized SAT4J solver,which has been extensively adopted in diﬀerent contexts[25, 26, 54], is selected as a baseline in this paper. Accordingto our results, this solver cannot give any guarantees aboutcoverage in the behavior space, though.
Coverage-oriented sampling : It creates a sample set
according to a speciﬁc coverage criterion. One of the promi-
nent example is t-wisesampling in which all possible tfea-
ture combinations must be covered [13]. Nowadays, various
t-wise sampling approaches are available, e.g., Chvatal [29],ICPL [30], IncLing [2], YASA [33] and CASA [19]. Based onthe evaluations in [38], however, most of the t-wise sampling
techniques can only deal with small FMs considering oftent=1o rt= 2. For large real-world SPLs and/or high tin-
teraction strengths, they often run out of memory, do notterminate, or take too much running time [46].
Uniform sampling : Achieving uniform sampling is im-
portant to understand properties of the whole conﬁgurationspace [43]. Recently, uniform sampling has caught increasingattention from both SAT and SPL communities [1, 27, 47].UniGen2 [9] partitions the conﬁguration space as evenly aspossible using hashing functions. Subsequently, sampling isdone by choosing a partition at random, and then generatinga valid conﬁguration in that partition using an SAT solver.Unigen2 also supports parallelism on sampling, and its im-
proved version, i.e., UniGen3 [51], is now available. Several
strategies perform counting-based uniform sampling. Typi-cally, they subsequently partition the conﬁguration space onvariable assignments, and then count the number of conﬁg-urations of the resulting parts. In [40], the number of validconﬁgurations can be easily counted since an FM is encodedas a binary decision diagram. Both Spur[1] andSmarch[43]rely on sharpSAT [53] to count the number of valid conﬁg-urations. The above samplers guarantee uniform sampling,but may encounter a bottleneck in some cases. According toSundermann et al. [52], none of their evaluated model count-
ing solvers, including sharpSAT, can count the number of
valid conﬁgurations for some large industrial SPLs. Alter-natively, QuickSampler [18] performs an eﬃcient samplingof conﬁgurations using only a small number of MAX-SATsolver calls. This sampler, however, oﬀers no guarantees onuniformity or even validity of the samples [27, 47].
7 CONCLUSIONS
This paper focuses on diverse sampling from SPLs. In prac-tice, the number of selected features for a conﬁguration isimportant to characterize its behaviors. By using this num-ber, the conﬁguration space is mapped to a small behaviorspace. Deriving a small set of valid conﬁgurations that hasa good coverage in the behavior space is required in manysoftware engineering tasks. However, most existing samplingstrategies fail to achieve this goal. In this paper, we proposea search-based sampling strategy which adopts an eﬃcien-
t oﬀ-the-shelf SAT solver to generate an initial sample set,
and then improves its diversity in an incremental way. Thisis achieved by using a special distance metric in combinationwith the novelty search algorithm. Experimental results on39 real-world SPLs demonstrate that our sampling algorith-m can not only improve coverage in the behavior space, butalso promote diversity in the original conﬁguration space.Moreover, we show, both theoretically and experimentally,that the designed distance metric is able to mitigate bias to-
wards covering speciﬁc parts in the behavior space. Finally,
our results show that only the proposed sampling algorithmachieves scalable diverse sampling among all the ﬁve evalu-ated samplers.
Focusing on sampling diverse conﬁgurations from behav-
ior spaces, this paper provides a search-based sampler, whichis a general tool. Other than the number of selected features,other metrics can also be applicable. In addition, it will bevery useful in the future to design dedicated genetic oper-ators in the search algorithm. Currently, we focus on the
sampling mechanism itself. As one of the subsequent stud-
ies, we will apply the tool to some real-world problems, e.g.,t-wise testing [54] and performance prediction [31].
ACKNOWLEDGMENTS
This work was supported by National Natural Science Foun-dation of China (61906069, 61876207), Science and Technol-ogy Program of Guangzhou (202002030355, 201802010007),
Guangdong Basic and Applied Basic Research Foundation
(2019A1515011411,2019A1515011700),GuangdongProvinceKey Area R&D Program (2018B010109003), Science andTechnology Innovation 2030–“New Generation Artiﬁcial In-telligence” Major Project (2020AAA0108404), FundamentalResearchFundsfortheCentralUniversities(2020ZYGXZR014),and Microsoft Research Asia.
ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Xiang, et al.
REFERENCES
[1] Dimitris Achlioptas, Zayd S. Hammoudeh, and Panos Theodor-
opoulos. 2018. Fast Sampling of Perfectly Uniform Satisfying As-
signments. In Theory and Applications of Satisﬁability Testing
– SAT 2018, Olaf Beyersdorﬀ and Christoph M. Wintersteiger(Eds.). Springer International Publishing, Cham, 135–147.
[2] Mustafa Al-Hajjaji, Sebastian Krieter, Thomas Th¨ um, Malte
Lochau, and Gunter Saake. 2016. IncLing: Eﬃcient Product-LineTesting Using Incremental Pairwise Sampling. In Proceedings of
the 2016 ACM SIGPLAN International Conference on Gen-erative Programming: Concepts and Experiences (Amsterdam,
Netherlands) (GPCE 2016). Association for Computing Machin-
ery, New York, NY, USA, 144–155.
[3] Mustafa Al-Hajjaji, Thomas Th¨ um, Malte Lochau, Jens Meinick-
e, and Gunter Saake. 2019. Eﬀective product-line testing us-ing similarity-based product prioritization. Software & Systems
Modeling 18 (2019), 499–521.
[4] Andrea Arcuri and Lionel Briand. 2011. A Practical Guide for
Using Statistical Tests to Assess Randomized Algorithms in Soft-ware Engineering. In Proceedings of the 33rd International Con-
ference on Software Engineering (Waikiki, Honolulu, HI, US-
A)(ICSE’11) . Association for Computing Machinery, New York,
NY, USA, 1–10.
[5] Adrian Balint and Uwe Sch¨ oning. 2012. Choosing Probability
Distributions for Stochastic Local Search and the Role of Makeversus Break. International Conference on Theory and Applica-tions of Satisﬁability Testing, Berlin, Heidelberg, 16–29.
[6] Don Batory. 2005. Feature Models, Grammars, and Propositional
Formulas. In Proceedings of the 9th International Conference
Software Product Lines, SPLC 2005 , Henk Obbink and Klaus
Pohl (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg, 7–20.
[7] Daniel Le Berre and Anne Parrain. 2010. The Sat4j library, re-
lease 2.2, system description. Journal on Satisﬁability, Boolean
Modeling and Computation 7 (2010), 59–64.
[8] Shaowei Cai, Chuan Luo, and Kaile Su. 2014. Improving Walk-
SAT By Eﬀective Tie-Breaking and Eﬃcient Implementation.Comput. J. 58, 11 (11 2014), 2864–2875.
[9] Supratik Chakraborty, Daniel J. Fremont, Kuldeep S. Meel, San-
jit A. Seshia, and Moshe Y. Vardi. 2015. On Parallel ScalableUniform SAT Witness Generation. In Tools and Algorithms for
the Construction and Analysis of Systems , Christel Baier and
Cesare Tinelli (Eds.). Springer Berlin Heidelberg, Berlin, Heidel-berg, 304–319.
[10] Jianfeng Chen, Vivek Nair, Rahul Krishna, and Tim Menzies.
2019. ‘Sampling’ as a Baseline Optimizer for Search-based Soft-ware Engineering. IEEE Transactions on Software Engineering
45, 6 (2019), 597–614.
[11] Paul Clements and Linda Northrop. 2001. Software product
lines: practices and patterns . Addison-Wesley Longman Pub-
lishing Co., Inc. 467 pages.
[12] Carlos A. Coello Coello and Margarita Reyes Sierra. 2004. A
Study of the Parallelization of a Coevolutionary Multi-objectiveEvolutionary Algorithm. In Mexican International Conference
on Artiﬁcial Intelligence (MICAI). Springer Berlin Heidelberg,688–697.
[13] Myra B. Cohen, Matthew B. Dwyer, and Jiangfan Shi. 2007. In-
teraction Testing of Highly-Conﬁgurable Systems in the Presence
of Constraints. In Proceedings of the 2007 International Sympo-
sium on Software Testing and Analysis (London, United King-
dom) (ISSTA’07). Association for Computing Machinery, New
York, NY, USA, 129–139.
[14] Martin Davis, George Logemann, and Donald Loveland. 1962. A
Machine Program for Theorem-proving. Communications of the
ACM5, 5 (1962), 394–397.
[15] Leonardo de Moura and Nikolaj Bjørner. 2008. Z3: An Eﬃcien-
tS M TS o l v e r .I n Proceedings of the International Conference
on Tools and Algorithms for the Construction and Analysis of
Systems , C. R. Ramakrishnan and Jakob Rehof (Eds.). Springer
Berlin Heidelberg, Berlin, Heidelberg, 337–340.
[16] Stephane Doncieux, Alban Laﬂaqui` ere, and Alexandre Coninx.
2019. Novelty Search: A Theoretical Perspective. In Proceed-
ings of the Genetic and Evolutionary Computation Conference(Prague, Czech Republic) (GECCO’19) . Association for Com-
puting Machinery, New York, NY, USA, 99–106.[17] Stephane Doncieux, Giuseppe Paolo, Alban Laﬂaqui` ere,and
Alexandre Coninx. 2020. No
velty Search makes Evolvability In-
evitable. In Proceedings of the Genetic and Evolutionary Com-
putation Conference (Canc˜Aˇzn, Mexico) (GECCO’20) . Associ-
ation for Computing Machinery, New York, NY, USA, 85–93.
[18] Rafael Dutra, Kevin Laeufer, Jonathan Bachrach, and Koushik
Sen. 2018. Eﬃcient Sampling of SAT Solutions for Testing. In2018 IEEE/ACM 40th International Conference on SoftwareEngineering (ICSE) . IEEE Computer Society, Los Alamitos, CA,
USA, 549–559.
[19] Brady J. Garvin, Myra B. Cohen, and Matthew B. Dwyer. 2011.
Evaluating improvements to a meta-heuristic search for con-strained interaction testing. Empirical Software Engineering 16,
1 (2011), 61–102.
[20] Vibhav Gogate and Rina Dechter. 2006. A New Algorithm for
Sampling CSP Solutions Uniformly at Random. In Principles
and Practice of Constraint Programming - CP 2006 ,F r ´ed´eric
Benhamou (Ed.). Springer Berlin Heidelberg, Berlin, Heidelberg,711–715.
[21] Jorge Gomes, Pedro Mariano, and Anders Lyhne Christensen.
2015. Devising Eﬀective Novelty Search Algorithms: A Com-prehensive Empirical Study. In Proceedings of the 2015 An-
nual Conference on Genetic and Evolutionary Computation(Madrid, Spain) (GECCO’15) . Association for Computing Ma-
chinery, New York, NY, USA, 943–950.
[22] Jianmei Guo, Krzysztof Czarnecki, Sven Apel, Norbert Sieg-
mund, and Andrzej Wasowski. 2013. Variability-aware per-formance prediction: A statistical learning approach. In 28th
IEEE/ACM International Conference on Automated SoftwareEngineering (ASE). 301–311.
[23] Jianmei Guo, Jia Hui Liang, Kai Shi, Dingyu Yang, Jingsong
Zhang, Krzysztof Czarnecki, Vijay Ganesh, and Huiqun Yu. 2019.SMTIBEA: a hybrid multi-objective optimization algorithm forconﬁguring large constrained software product lines. Software &
Systems Modeling 18 (2019), 1447–1466.
[24] Christopher Henard, Mike Papadakis, Mark Harman, and
Yves Le Traon. 2015. Combining Multi-Objective Search andConstraint Solving for Conﬁguring Large Software Product Lines.InThe 37th International Conference on Software Engineering ,
Vol. 1. 517–528.
[25] Christopher Henard, Mike Papadakis, Gilles Perrouin, Jacques K-
lein, Patrick Heymans, and Yves Le Traon. 2014. Bypassing theCombinatorial Explosion: Using Similarity to Generate and Pri-oritize T-Wise Test Conﬁgurations for Software Product Lines.IEEE Transactions on Software Engineering 40, 7 (July 2014),
650–670.
[26] Christopher Henard, Mike Papadakis, Gilles Perrouin, Jacques
Klein, and Yves Le Traon. 2013. PLEDGE: A Product Line Edi-tor and Test Generation Tool. In Proceedings of the 17th Inter-
national Software Product Line Conference Co-Located Work-shops(Tokyo, Japan) (SPLC’13 Workshops) . Association for
Computing Machinery, New York, NY, USA, 126–129.
[27] Ruben Heradio, David Fernandez-Amoros, Jos´ e A. Galindo, and
David Benavides. 2020. Uniform and Scalable SAT-Sampling forConﬁgurable Systems. In Proceedings of the 24th ACM Con-
ference on Systems and Software Product Line: Volume A -Volume A (Montreal, Quebec, Canada) (SPLC ’20). Associa-
tion for Computing Machinery, New York, NY, USA, Article 17,11 pages.
[28] Robert M. Hierons, Miqing Li, Xiaohui Liu, Sergio Segura, and
Wei Zheng. 2016. SIP: Optimal Product Selection from FeatureModels Using Many-Objective Evolutionary Optimization. ACM
Transactions on Software Engineering and Methodology 25, 2,
Article 17 (April 2016), 39 pages.
[29] Martin Fagereng Johansen, Øystein Haugen, and Franck Fleurey.
2011. Properties of Realistic Feature Models Make Combinatori-al Testing of Product Lines Feasible. In Proceedings of the 14th
International Conference on Model Driven Engineering Lan-guages and Systems (Wellington, New Zealand) (MODELS’11) .
Springer-Verlag, Berlin, Heidelberg, 638–652.
[30] Martin Fagereng Johansen, Øystein Haugen, and Franck Fleurey.
2012. An Algorithm for Generating T-Wise Covering Arrays fromLarge Feature Models. In Proceedings of the 16th Internation-
al Software Product Line Conference - Volume 1 (Salvador,
Brazil) (SPLC’12). Association for Computing Machinery, New
York, NY, USA, 46–55.
Search-based Diverse Sampling from Real-world Software Product Lines ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
[31] Christian Kaltenecker, Alexander Grebhahn, Norbert Siegmund,
Jianmei Guo, and Sven Apel. 2019. Distance-Based Sampling of
Software Conﬁguration Spaces. In Proceedings of the 41st Inter-
national Conference on Software Engineering (Montreal, Que-
bec, Canada) (ICSE’19). IEEE Press, 1084–1094.
[32] Kyo C. Kang, Sholom G. Cohen, James A. Hess, William E.
Novak, and A. Spencer Peterson. 1990. Feature-oriented do-
main analysis (FODA ) feasibility study. Technical Report.CMU/SEI-90-TR-21. SEI. Georgetown University.
[33] Sebastian Krieter, Thomas Th¨ um, Sandro Schulze, Gunter Saake,
and Thomas Leich. 2020. YASA: yet another sampling algorith-m. In VaMoS 20: 14th International Working Conference on
Variability Modelling of Software-Intensive Systems, Magde-burg Germany, February 5-7, 2020 , Maxime Cordy, Mathieu
Acher, Danilo Beuche, and Gunter Saake (Eds.). ACM, 4:1–4:10.
[34] Joel Lehman and O. Stanley Kenneth. 2011. Abandoning Objec-
tives: Evolution Through the Search for Novelty Alone. Evolu-
tionary Computation 19, 2 (2011), 189–223.
[35] Joel Lehman and Kenneth O. Stanley. 2008. Exploiting open-
endedness to solve problems through the search for novelty. InProceedings of the E leventh International Conference on Arti-
ﬁcial Life (ALIFE XI). 329–336.
[36] Jia Hui Liang, Vijay Ganesh, Krzysztof Czarnecki, and Venkatesh
Raman. 2015. SAT-based Analysis of Large Real-world FeatureModels is Easy. In Proceedings of the 19th International Con-
ference on Software Product Line (Nashville, Tennessee) (SPLC
’15). ACM, New York, NY, USA, 91–100.
[37] J¨org Liebig, Alexander von Rhein, Christian K¨ astner, Sven Apel,
Jens D¨ orre, and Christian Lengauer. 2013. Scalable Analysis ofVariable Software. In Proceedings of the 2013 9th Joint Meet-
ing on Foundations of Software Engineering (Saint Petersburg,
Russia) (ESEC/FSE 2013). Association for Computing Machin-
ery, New York, NY, USA, 81–91.
[38] Fl´avio Medeiros, Christian K¨ astner, M´ arcio Ribeiro, Rohit Ghey-
i, and Sven Apel. 2016. A Comparison of 10 Sampling Algorithmsfor Conﬁgurable Systems. In 2016 IEEE/ACM 38th Interna-
tional Conference on Software Engineering (ICSE) . 643–654.
[39] Jean Melo, Elvis Flesborg, Claus Brabrand, and Andrzej Wa-
sowski. 2016. A Quantitative Analysis of Variability Warnings inLinux. In Proceedings of the Tenth International Workshop on
Variability Modelling of Software-Intensive Systems (Salvador,
Brazil) (VaMoS’16). ACM, New York, NY, USA, 3–8.
[40] Jeho Oh, Don Batory, Margaret Myers, and Norbert Siegmund.
2017. Finding Near-Optimal Conﬁgurations in Product Linesby Random Sampling. In Proceedings of the 2017 11th Joint
Meeting on Foundations of Software Engineering (Paderborn,
Germany) (ESEC/FSE 2017). ACM, New York, NY, USA, 61–
71.
[41] Jeho Oh, Paul Gazzillo, and Don Batory. 2019. T-Wise Coverage
by Uniform Sampling. In Proceedings of the 23rd Internation-
al Systems and Software Product Line Conference - Volume A(Paris, France) (SPLC’19). Association for Computing Machin-
ery, New York, NY, USA, 84–87.
[42] Jeho Oh, Paul Gazzillo, Don Batory, Marijn Heule, and Margaret
Myers. 2019. Uniform Sampling from Kconﬁg Feature Models .
Technical Report TR-19-02. The University of Texas at Austin.
[43] Jeho Oh, Paul Gazzillo, Don Batory, Marijn Heule, and Margaret
Myers. 2020. Scalable Uniform Sampling for Real-World Soft-
ware Product Lines . Technical Report TR-20-01. The University
of Texas at Austin.
[44] Rafael Olaechea, Derek Rayside, Jianmei Guo, and Krzysztof
Czarnecki. 2014. Comparison of exact and approximate multi-objective optimization for software product lines. In The Inter-
national Software Product Line Conference . 92–101.
[45]Tobias P ett,
Sebastian Krieter, Thomas Th¨ um, Malte Lochau,
and Ina Schaefer. 2021. AutoSMP: An Evaluation Platform for
Sampling Algorithms . Association for Computing Machinery,
New York, NY, USA, 41–44.
[46] Tobias Pett, Thomas Th¨ um, Tobias Runge, Sebastian Krieter,
Malte Lochau, and Ina Schaefer. 2019. Product Sampling forProduct Lines: The Scalability Challenge. In Proceedings of the
23rd International Systems and Software Product Line Con-f e r e n c e-V o l u m eA (Paris, France) (SPLC’19). Association for
Computing Machinery, New York, NY, USA, 78–83.
[47] Quentin Plazar, Mathieu Acher, Gilles Perrouin, Xavier Devroey,
and Maxime Cordy. 2019. Uniform Sampling of SAT Solutionsfor Conﬁgurable Systems: Are We There Yet?. In 12th IEEE
Conference on Software Testing, Validation and Veriﬁcation,ICST 2019, Xi’an, China, April 22-27, 2019 . IEEE, 240–251.
[48] Richard Pohl, Kim Lauenroth, and Klaus Pohl. 2011. A perfor-
mance comparison of contemporary algorithmic approaches forautomated analysis operations on feature models. In IEEE/ACM
International Conference on Automated Software Engineering .
313–322.
[49] Atri Sarkar, Jianmei Guo, Norbert Siegmund, Sven Apel, and
Krzysztof Czarnecki. 2015. Cost-Eﬃcient Sampling for Perfor-mance Prediction of Conﬁgurable Systems. In Proceedings of the
30th IEEE/ACM International Conference on Automated Soft-ware Engineering (Lincoln, Nebraska) (ASE’15). IEEE Press,
342–352.
[50] Abdel Salam Sayyad, Joseph Ingram, Tim Menzies, and Hany
Ammar. 2013. Scalable product line conﬁguration: A straw tobreak the camel’s back. In 2013 28th IEEE/ACM International
Conference on Automated Software Engineering (ASE) . 465–
474.
[51] Mate Soos, Stephan Gocht, and Kuldeep S. Meel. 2020. Tinted,
Detached, and Lazy CNF-XOR solving and its Applications toCounting and Sampling. In Proceedings of International Con-
ference on Computer-Aided Veriﬁcation (CAV) .
[52] Chico Sundermann, Thomas Th¨ um, and Ina Schaefer. 2020. Eval-
uating #SAT Solvers on Industrial Feature Models. In Proceed-
ings of the 14th International Working Conference on Vari-ability Modelling of Software-Intensive Systems (Magdeburg,
Germany) (VAMOS’20). Association for Computing Machinery,
New York, NY, USA, Article 3, 9 pages.
[53] Marc Thurley. 2006. sharpSAT – Counting Models with Ad-
vanced Component Caching and Implicit BCP. In Theory and
Applications of Satisﬁability Testing - SAT 2006, Armin Biereand Carla P. Gomes (Eds.). Springer Berlin Heidelberg, Berlin,Heidelberg, 424–429.
[54] Yi Xiang, Han Huang, Miqing Li, Sizhe Li, and Xiaowei Yang.
2021. Looking For Novelty in Search-based Software ProductLine Testing. IEEE Transactions on Software Engineering 1, 1
(2021), 1–1.
[55] Yi Xiang, Xiaowei Yang, Yuren Zhou, and Han Huang. 2020. En-
hancing Decomposition-based Algorithms by Estimation of Dis-tribution for Constrained Optimal Software Product Selection.IEEE Transactions on Evolutionary Computation 24, 2 (2020),
245–259.
[56] Yi Xiang, Xiaowei Yang, Yuren Zhou, Zibin Zheng, Miqing Li,
and Han Huang. 2020. Going deeper with optimal software prod-ucts selection using many-objective optimization and satisﬁabili-ty solvers. Empirical Software Engineering 25 (2020), 591–626.
[57] Yi Xiang, Yuren Zhou, Zibin Zheng, and Miqing Li. 2018. Con-
ﬁguring Software Product Lines by Combining Many-ObjectiveOptimization and SAT Solvers. ACM Transactions on Soft-
ware Engineering and Methodology 26, 4, Article 14 (Feb. 2018),
46 pages.
