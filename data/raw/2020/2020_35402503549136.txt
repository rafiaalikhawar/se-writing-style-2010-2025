AgileCtrl : A Self-Adaptive Framework for Configuration Tuning
Shu Wang
LinkedIn
Sunnyvale, California, USA
shuwang@uchicago.eduHenry Hoffmann
University of Chicago
Chicago, Illinois, USA
hankhoffmann@cs.uchicago.eduShan Lu
University of Chicago
Chicago, Illinois, USA
shanlu@uchicago.edu
ABSTRACT
Software systems increasingly expose performance-sensitive con-
figuration parameters, or PerfConfs, to users. Unfortunately, the
right settings of these PerfConfs are difficult to decide and often
change at run time. To address this problem, prior research has
proposed self-adaptive frameworks that automatically monitor the
softwareâ€™s behavior and dynamically tune configurations to provide
the desired performance despite dynamic changes. However, these
frameworks often require configuration themselves; sometimes ex-
plicitly in the form of additional parameters, sometimes implicitly
in the form of training.
This paper proposes a new framework, AgileCtrl , that eliminates
the need of configuration for a large family of control-based self-
adaptive frameworks. AgileCtrl â€™s key insight is to not just monitor
the original software, but additionally to monitor its adaptations
and reconfigure itself when its internal adaptation mechanisms are
not meeting software requirements. We evaluate AgileCtrl by com-
paring against recent control-based approaches to self-adaptation
that require user configuration. Across a number of case studies,
we find AgileCtrl withstands model errors up to 106Ã—, saves the
system from performance oscillation and crashes, and improves the
performance up to 53%. It also auto-adjusts improper performance
goals while improving the performance by 50%.
CCS CONCEPTS
â€¢Software and its engineering â†’Software configuration
management and version control systems ;Software perfor-
mance ;Software reliability ;â€¢Computer systems organization
â†’Cloud computing.
KEYWORDS
Software Configuration, Performance, Distributed Systems, Self-
Adaptive Control
ACM Reference Format:
Shu Wang, Henry Hoffmann, and Shan Lu. 2022. AgileCtrl : A Self-Adaptive
Framework for Configuration Tuning. In Proceedings of the 30th ACM Joint
European Software Engineering Conference and Symposium on the Founda-
tions of Software Engineering (ESEC/FSE â€™22), November 14â€“18, 2022, Singa-
pore, Singapore. ACM, New York, NY, USA, 13 pages. https://doi.org/10.1145/
3540250.3549136
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore
Â©2022 Association for Computing Machinery.
ACM ISBN 978-1-4503-9413-0/22/11. . . $15.00
https://doi.org/10.1145/3540250.35491361 INTRODUCTION
Modern software systems provide great flexibility to users by al-
lowing them to customize (or tune) the softwareâ€™s configuration
parameters. These configuration parameters determine the size of
critical data structures, the thresholds to trigger time-consuming
operations, the parallelism of the process, and many other aspects of
system operation [ 38,67,68,71]. Many of these configurations can
greatly affect system performance metrics, such as request latency,
job throughput, memory and disk consumption, and others. Un-
fortunately, these performance-sensitive configurations, PerfConfs
for short, are typically numerical variables, whose optimal settings
are difficult to determine and vary based on run-time situations.
Their mis-configuration easily leads to performance degradation
or even crashes [ 20,67]. Indeed, a recent study finds that 65% of
configuration-related issues in 4 distributed systems (Cassandra,
HBase, HDFS, MapReduce) involve performance concerns [67].
To ensure that software is configured optimally despite dynamic
changes in operating environment, prior works have proposed self-
adaptive frameworks, including, but not limited to SmartConf [67],
DAC [ 69], OtterTune [ 66], POET [ 27] , SimCA [ 60,62], CAPES [ 39],
AENEAS [ 7], JouleGuard [ 23], and CALOREE [ 46]. Such frame-
works monitor software performance and automatically adjust Per-
fConfs to ensure optimal operation despite unpredictable external
changes. For example, AENEAS dynamically adjusts Androidâ€™s GPS
accuracy ( gpsPrio ) and update interval gpsUpdate to meet per-
formance requirements ( e.g.20% per hour battery drain rate). By
dynamically configuring the PerfConfs, such self-adaptive frame-
works make software substantially more robust than approaches
that must stick with a single PerfConf setting for their lifetime
[7, 17, 26, 39, 42, 60, 62, 66, 67, 69].
However, these approaches do not eliminate all the burden of
managing PerfConfs, as self-adaptive frameworks themselves ex-
pose configuration parameters that need to be set by users. We call
these AdapConfs to distinguish the parameters of a self-adaptive
framework from the PerfConfs of the systems it should control.
For example, to use a self-adaptive framework based on control
theory, users must set an explicit AdapConfâ€”called the poleâ€”that
determines the tradeoff between adaptationâ€™s reaction time and
noise sensitivity [ 17,42]. If the pole is too small, the self-adaptive
framework is more sensitive to disturbances and it may crash the
software; if the pole is too large, the framework is slow to change
the PerfConf, which leads to sub-optimal performance and negates
the benefits of using the self-adaptive framework in the first place.
In addition to these explicit AdapConfs, there are implicit Adap-
Confs which are not directly set by users but are computed based
on the training or profiling data that is provided by users. For exam-
ple, in a machine-learning-based self-adaptive framework, training
data determine implicit AdapConfs ( e.g. weights used in neural net-
works) [ 7,66,69]. When the training inputs and environment do
459
ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore Shu Wang, Henry Hoffmann, and Shan Lu
not match that at deployment, the self-adaptive frameworks will
not react appropriately and can crash the system under control or
fail to deliver the required performance [ 11]. For example, if the
training inputs for a web server consist of only small requests, the
system could crash when processing larger requests [67].
In summary, self-adaptive frameworks have the potential to au-
tomatically configure software systems, but they do not completely
solve the configuration management problem because they typi-
cally have their own explicit and implicit configuration parameters.
In other words, prior works proposing self-adaptive frameworks
replace PerfConfs with AdapConfs, which must still be set by users.
And, much like PerfConfs, the optimal settings for these Adap-
Confs depend on the target software, the hardware platform, the
run-time workload and environment. Like PerfConfs, these Adap-
Confs become a new source of bugs, either from setting the explicit
AdapConf incorrectly, or through providing insufficient or unrep-
resentative training data for the implicit AdapConf. Unsuitable
AdapConfs lead to sub-optimal performance, system instability, or
even system crashes. Thus, a configuration-free (both PerfConfs
and AdapConf free) self-adaptive framework for general software
systems is highly desired.
In this work, we propose a novel self-adaptive control frame-
work, AgileCtrl , which extends general control-based self-adaptive
systems [ 16,17,21,26,27,41,49,56,60â€“62,67,72] by automati-
cally adjusting its internal AdapConfs so that explicit AdapConfs
can be completely eliminated and much larger errors in implicit
AdapConfsâ€™ training can be tolerated.
To better motivate AgileCtrl , we first experimentally show how
a state of the art self-adaptive framework, SmartConf [67], can han-
dle some training-deployment mismatches and yet greatly suffers
from performance degradation, performance oscillation, and even
crashes when mismatch becomes large; i.e., when the error in any
explicit or implicit AdapConf settings becomes high (Section 3).
To help self-adaptive frameworks, AgileCtrl â€™s design leverages
two insights:
â€¢First, AgileCtrl adjusts its own AdapConfs based on how
well its own internal adaptations are performing, measured
by how accurately it predicts future performance. This is
in contrast to prior work that adjusts only PerfConfs based
on how closely the system meets its pre-defined goal. Ag-
ileCtrl adjusts both the PerfConfsâ€”like prior work using the
difference between the performance goal and the measured
performanceâ€”and its internal AdapConfsâ€”using the differ-
ence between the predicted and measured performance.
â€¢Second, AgileCtrl leverages a simplified MIT rule1[2] to
adjust AdapConfs, so that the predicted software perfor-
mance stays close to the observed software performance, to
ensure that AgileCtrl â€™s AdapConf adjustments always drive
the software system to its overall performance goal.
Putting these two insights together, AgileCtrl allows a large
family of self-adaptation frameworksâ€”specifically those based on
control theoryâ€”to dynamically adapt their own adaptation logic,
accommodating different run time dynamics and a wide range of
1The MIT rule was developed at the Instrumentation Laboratory (now Draper Labora-
tory) at the Massachusetts Institute of Technology.training or profiling deficiencies without any extra configuration
requirements for users. The details are in Section 4.
Finally, we apply the AgileCtrl to 3 widely-used open-source
distributed systems (Cassandra, HBase, and HDFS) in Section
5. Without introducing any additional AdapConf, AgileCtrl
greatly enhances the system through the model and robustness
self-adjustment. For model self-adjustment, AgileCtrl withstands
errors up to a factor of 106Ã—and saves the system from
performance oscillation and crashes. For uncrashed systems,
AgileCtrl can further improve the performance up to 53%. For
robustness self-adjustment, AgileCtrl can automatically reset the
goal requirement while improving the performance by 50%.
To summarize, AgileCtrl makes the following contributions:
â€¢Exposing AdapConfs used in self-adaptive frameworks as a
potential source of bugs and demonstrate the importance of
properly setting AdapConfs.
â€¢Proposing that self-adaptive frameworks can be designed to
reduce these potential bugs by constructing them to observe
their own behavior and automatically modify their own
internal AdapConfs.
â€¢Proposing AgileCtrl to show how to use self-monitoring prin-
ciple in self-adaptive frameworks based on control theory.
â€¢Evaluating AgileCtrl against multiple advanced self-adaptive
frameworks and demonstrate that AgileCtrl greatly enhance
the system robustness with performance improvement.
2 BACKGROUND
We first discuss the common properties of self-adaptive frameworks
in general. We then describe a large class of such frameworks
distinguished by their use of control theory.
2.1 The Benefits of Self-Adaptive Frameworks
Modern software must deliver non-functional requirements such
as performance, energy consumption, and others [ 6], while facing
unexpected changes at run time, such as resource contention and
workload fluctuations [ 70,74]. Self-Adaptive frameworks help de-
velopers meet these requirements by automatically adjusting the
softwareâ€™s PerfConfs, based on observed run time behavior.
Self-Adaptive frameworks can be generally classified as either
control theory-based [ 2,16,27,67] or machine learning-based ap-
proaches [ 7,19,66,69], with some representative ones listed in
Table 1. As the table shows, all these systems contain two or more
AdapConfs that users must set, either explicitly or implicitly. Note
that, SmartConf ,ADSS , and POET all use multiple AdapConfs to
automate a single PerfConf, thus the total number of AdapConfs is
actually larger than that of PerfConfs [16, 27, 67].
As indicated by the last column of Table 1, these parameters
can affect the frameworkâ€™s internal model or its robustness to error .
Intuitively, the accuracy of the internal model affects the average
performance achieved while the robustness to error affects the abil-
ity to tolerate variance in the underlying system. All frameworks
have internal models that are used to predict how a change in a
PerfConf will affect the observed performance. For example, both
SmartConf â€™sğ›¼andOtterTune â€™s neural network weights ğ‘Šare es-
sential for each framework to predict the performance that could be
achieved with a specific PerfConf setting. Other parameters affect
460AgileCtrl : A Self-Adaptive Framework for Configuration Tuning ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore
Table 1: Partial AdapConfs used in self-adaptive frameworks
(E: explicit AdapConf and I: implicit AdapConf)
SystemCate-
goryAdap-
ConfTypeHow to
set ?Role
SmartConf
[67]
Controlğ‘ğ‘œğ‘™ğ‘’ I Profiling Robustness
ğ›¼ I Profiling Model
ğ‘£ğ‘” I Profiling Robustness
ADSS
[16]ğ‘ğ‘œğ‘™ğ‘’ E Expert Robustness
ğ›¼ I Profiling Model
POET
[27]ğ‘ğ‘œğ‘™ğ‘’ E Expert Robustness
ğ›¼ I Profiling Model
ğ‘ğ‘ E Expert Model
ğ‘šğ‘£ E Expert Model
SimCA
[60, 62]ğ‘ğ‘œğ‘™ğ‘’ E Expert Robustness
ğ›¼ I Profiling Model
Brownout
[34]ğ‘ğ‘œğ‘™ğ‘’ I Profiling Robustness
ğ›¼ I Profiling Model
AENEAS
[7]
Machine Learningğ›¿ E Expert Model
ğœ E Expert Model
ğœ– E Expert Model
OtterTune
[66]ğ‘Š I Profiling Model
ğ‘‘ğ‘  E Expert Model
ğ‘™ğ‘Ÿ E Expert Robustness
ğ‘‘ğ‘œ E Expert Robustness
DAC
[69]ğ‘›ğ‘¡ I Expert Model
ğ‘¡ğ‘ I Expert Model
ğ‘™ğ‘Ÿ I Expert Robustness
ACTGAN
[4]ğ‘Š I Profiling Model
ğ‘˜â„
ğ‘‘E Expert Model
ğ‘™ğ‘Ÿ E Expert Robustness
RFHOC
[5]ğ‘ğ‘  E Expert Model
ğ‘šğ‘ E Expert Robustness
ğ‘ğ‘ E Expert Robustness
the frameworkâ€™s robustness to tolerate some error or uncertainty in
terms of the unexpected workloads, environments, or constraints.
For instance, in control based approaches setting the pole ğ‘prop-
erly avoids aggressive adaptation and makes the software stable
during transient disturbances; in learning-based approaches setting
a suitable learning rate (lr) avoids model over-fitting so the
framework better generalizes to unseen data.
Overall, AdapConfs are common, important, and complicated.
The importance of setting suitable AdapConfs is underestimated,
and the consequence of improper AdapConfs have not been thor-
oughly examinedâ€”this paper illustrates some problems with Adap-
Confs in the SmartConf framework in Section 3.
2.2 Control-Based Self-Adaptive Frameworks
Control theory is an increasingly popular set of techniques for im-
plementing self-adaptive frameworks. The benefit of using control
theory is that it supports formal analysis of the self-adaptive frame-
work [ 18]: implementers can reason about the conditions under
which the software system will or will not meet its goals. The draw-
back is that control-based approaches often require some expert
knowledge to deploy effectively. In other words, many such ap-
proaches expose explicit AdapConfsâ€”e.g., ADSS, POET, and SimCA
from Table 1â€”that must be set by users.To alleviate this burden (and reduce the total number of parame-
ters exposed to users, including both PerfConfs and AdapConfs),
some approaches have eliminated explicit AdapConfs from their
interface, leaving only implicit ones that are set through profiling.
SmartConf [ 67], Brownout [ 34], and DAC [ 69] are all examples of
this idea (see Table 1). While eliminating the explicit AdapConfs
makes it easier for non-experts to deploy these systems, the im-
plicit AdapConfs must still be properly set to avoid bugs (as we
demonstrate in the next section).
To further understand the challenges with implicit AdapConfs
we focus on those from a state-of-the-art self-adaptive framework
SmartConf [67] that applies proportional-integral-derivative (PID)
control techniques to automatically adjust PerfConfs in distributed
systems. SmartConf represents a large family of self-adaptive frame-
works that combine a linear model with traditional PID controller
[59]. Other examples of this approach include POET [ 27], ADSS [ 16],
ACMA [ 42], Sthira [ 52], Tangram[ 53], SAMA [ 43], ControlVAE[ 58],
Brownout [ 34], SimCA [ 60,62], CALOREE [ 46], JouleGuard [ 23],
and others.
SmartConf uses 3 AdapConfs for each PerfConf: model coeffi-
cient (ğ›¼), pole (ğ‘) and virtual goal ratio ( ğ‘£ğ‘”). The former two are
also used in many other control-based self-adaptive frameworks,
as shown in Table 1.
Coefficient ( ğ›¼)is a key parameter for the underlying linear
model. It approximates how the current performance ğ‘ ğ‘˜at timeğ‘˜
reacts to the PerfConf valueğ‘ğ‘˜âˆ’1(e.g., queue size, cpu frequency)
at timeğ‘˜âˆ’1. This value is typically set through offline profiling,
where a linear regression model is built to quantify the effects as
following:
ğ‘ ğ‘˜=ğ›¼Â·ğ‘ğ‘˜âˆ’1+ğ‘. (1)
A positiveğ›¼means increasing configuration increases the per-
formance metric; a negative ğ›¼means the opposite. The larger ğ›¼â€™s
absolute value is, the more sensitive the system performance is to
any configuration changes.
Because this coefficient is a key parameter of many control sys-
tems, the recent MoD2 framework automatically detects when
the workload has drifted outside of a valid model and adapts this
coefficient dynamically [ 65]. This approach uses a Kalman filter
to perform this dynamic adjustment, which provides greater ro-
bustness. Unfortunately, the Kalman filter itself requires additional
AdapConfs and Kalman filter-based solutions can still lead to cata-
strophic failures when the model error is sufficiently high (see our
evaluation in Section 5).
Pole (ğ‘)is a key parameter for a PID controller as the pole
determines how aggressively the controller reacts to the current
performance error ğ‘’ğ‘˜, whereğ‘ğ‘˜is the PerfConf at time ğ‘˜:
ğ‘ğ‘˜+1=ğ‘ğ‘˜+1âˆ’ğ‘
ğ›¼ğ‘’ğ‘˜. (2)
InSmartConf ,ğ‘is set based on a profiling measurement of
how (un)stable the software under control isâ€”the more stable, the
smallerğ‘is and hence the controller would react more aggressively.
Specifically, SmartConf computes an (un)statbility metric Î”=1+
1
ğ‘Ãğ‘
13ğœğ‘–
ğ‘šğ‘–â€², whereğœğ‘–andğ‘šğ‘–â€²are the standard deviation and mean
of the performance measured w.r.t minimum performance under the
ğ‘–-th sampled configuration value. SmartConf setsğ‘to beğ‘šğ‘ğ‘¥(0,1âˆ’
2/Î”).
461ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore Shu Wang, Henry Hoffmann, and Shan Lu
 0 50 100 150
 0 2 4 6 8 10 12 14 16 18 20Tail Latency(s)
Request Index100%CPU
50%CPU20%CPU
10%CPU
Figure 1: HD4995 under different CPU resources
Virtual Goal Ratio ( ğ‘£ğ‘”)is brought in when there is a hard
constraint of performance, like never overshooting memory limits.
Theğ‘£ğ‘”is a real number between 0 to 1. It reserves some potential
performance gain as cushion space to trade for robustness to sys-
tem instability (like environment or workload changes). The more
unstable the system is, the larger the cushion space needs to be.
Specifically, the virtual goal ratio ğ‘£ğ‘”:=1âˆ’1
ğ‘Ãğ‘
1ğœğ‘–
ğ‘šğ‘–, whereğœğ‘–and
ğ‘šğ‘–are the standard deviation and mean of the performance mea-
sured under the ğ‘–-th sampled configuration value based on offline
profiling. Then, Virtual Goal can be calculated by ğ‘£ğ‘”âˆ—Ëœğ‘ , where Ëœğ‘ is
the desired performance goal.
InSmartConf , like other systems that use implicit AdapConfs,
these parameters are set through profiling runs. Users provide rep-
resentative workloads and the framework collects statistics from
those workloads to set the AdapConfs. The next section demon-
strates some problems that can arise from this approach.
3 MOTIVATING EXAMPLE
To better motivate AgileCtrl , we investigate how implicit Adap-
Confs are used in SmartConf [67], which sets its AdapConfs during
training then uses these fixed values throughout run-time. We show
these fixed values can lead to system performance degradation or
crashes when the deployment environment differs significantly
from the training environment. We take two benchmarks from
SmartConf (HD4995 and HB3813) as examples. While this specific
example uses SmartConf to illustrate the points, the general prob-
lems and behaviors are shared by all self-adaptive frameworks that
use offline profiling data to set implicit AdapConfs.
3.1 Run-Time Resource Mismatch
Our first example HD4995 reveals that, although SmartConf can
tolerate some training-deployment mismatch in terms of run-time
resources, it severely malfunctions when the mismatch increases.
Here, the target system HDFS has a PerfConf
content-summary.limit that limits the number of files
traversed before du, a HDFS command for estimating file space
usage, has to release a highly contested lock. If this PerfConf value
is too large, write requests would be blocked for long; if too small,
dulatency hurts.
 0 200 400
 0  20  40  60  80  100Request Size:Used Memory(MB)
Completed Workload(%)1MB
2MB
5MB
10MBFigure 2: HB3813 under different workloads.
We use the same training workload used in SmartConf with
100% CPU resources, which is based on the distributed file system
benchmark TestDFSIO [ 25]. Through training, SmartConf computes
AdapConfs < ğ›¼,ğ‘,ğ‘£ğ‘”> as <0.00005s, 0.53, 1.00>, with ğ›¼indicating
the average latency to traverse a single file to be 0.00005s. In the
deployment runs, we gradually decrease the CPU allocated to HDFS
from 100% to 10%.
As shown in Figure 1, SmartConf provides some robustness
when the environment is a little bit different from training: under
both 100% CPU resources (green curve) and 50% CPU resources
(blue curve), SmartConf gradually reduces the tail latency to the
required goal (20s).
However, when the CPU resource drops to 20%, the SmartConf
acts too aggressively, with the tail latency oscillating around the
goal (pink curve). Even worse, with 10% CPU allocated to HDFS,
the system fails to converge, with the tail latency jumping between
1s and 90s (orange curve).
The rationale is that the HDFS file/directory processing speed
slows down when the CPU resources drop, causing the ideal setting
of the AdapConf ğ›¼to increase. Without adjusting the controllerâ€™s
ğ›¼setting at run time, the whole systemâ€™s performance oscillates.
3.2 Run-Time Workload Mismatch
Our second example HB3813 shows, when the run-time workloads
differ from the training workloads, the SmartConf may overshoot
the hard constraint and result in crashes.
The PerfConf max.queue.size determines the largest size for
an RPC queue used in Hbase. A large queue can lead to an out-of-
memory (OOM) when under memory pressure, while a small queue
reduces RPC throughput.
We use YCSB [ 12] workload-A with 1MB request size and 50-50
read-write ratio as the training workload, under which SmartConf
computes three AdapConfs < ğ›¼,ğ‘,ğ‘£ğ‘”> as <1.25MB, 0.45, 0.91>.
Specifically, ğ›¼characterizes the average request size inside the
queue. At runtime, we gradually increase the request size from
1MB to 10MB.
As shown in Figure 2, for 1MB workload (green curve), SmartConf
works as expected, keeping the memory consumption under the
specified constraint (the red horizontal line). For a slightly larger
request size 2MB (blue curve), SmartConf can still efficiently utilize
462AgileCtrl : A Self-Adaptive Framework for Configuration Tuning ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore
the memory as SmartConf has some ability to accommodate for
training-deployment workload mismatch.
However, when the request size increases to 5ğ‘€ğµ, the system
exceeds the memory limits after finishing around 10% of the total
workload and then crashed. Unsurprisingly, Hbase also crashed
with 10ğ‘€ğµrequest size with only 5% workload finished.
The rationale is that the ideal setting of the AdapConf ğ›¼increases
with the Hbase request size. Without adjusting its ğ›¼setting at run
time, SmartConf underestimates the memory impact of the RPC
queue, causing out of memory failures.
Our two motivational experiments reveal that fixed AdapConfs
are sources of system under-performance or crashes. While exist-
ing self-adaptive frameworks like SmartConf eliminates explicit
AdapConfs to avoid direct human misconfiguration, it still has im-
plicit AdapConfs set based on user-designed training data. As our
experiments show, when the training data does not match with the
run-time characteristics (resources or workloads), the AdapConfs
settings become problematic. Therefore, eliminating any explicit
AdapConf and self-adjusting any implicit AdapConf are highly
desirable for a robust self-adaptive system.
4AGILECTRL DESIGN
The previous section shows how self-adaptive frameworks may
fail to meet software requirements if their operating environment
diverges significantly from the profiling environment. Specifically,
if the environment does diverge, implict AdapConfs representing
either the frameworkâ€™s internal model or robustness to error might
be set incorrectly, leading to performance oscillation (i.e., failure
to meet the requirements) or even system crashes. The key insight
of this paper is to augment such self-adaptive frameworks with an
ability to observe themselves and adjust their AdapConfs to prevent
this bad behavior.
We note that one approach could be to monitor different aspects
of the environment (e.g., resource availability or workload prop-
erties). The problem with this approach is that there could be any
number of environmental factors to observe and it is not clear ahead
of time which of these factors matter or even which can be easily
monitored. Thus, we propose that self-adaptive frameworks should
be modified to observe both (1) how well they are meeting the
performance requirements and (2) the same metrics that were used
to set any implicit AdapConfs during profiling. This modification
can be done internally to the framework with no change required
from users. It is also robust to any environmental factor that affects
the frameworkâ€™s ability to meet goals, and it does not require col-
lecting any new information beyond what the framework already
collects during profiling. Specifically, as AdapConfs affect either the
frameworkâ€™s internal model or its robustness to errors, we propose
to monitor (1) how well the self-adaptive framework predicts future
performance on average and (2) how close the framework comes to
its goal (by both mean and standard deviation). The first of these
allows our approach to make dynamic adjustments to the model
while the second allows adaptive adjustments to the AdapConfs
that affect robustness.
-
Controllerperformance 
goalmeasured 
performance
SystemAgileCtrl
PerfConf
adjustment-
PerfConfcalibrated 
performanceModel 
Adjustment
disturbance
AdapConfÎ± vgRobustness
AdjustmentPerformance
ModelPerformance
Calibrationpredicted 
performanceFigure 3: The overall AgileCtrl which extends a generic
control-based self-adaptive framework.
4.1 Overview
We apply the above insights to SmartConf , a state-of-the-art and
general self-adaptive framework. Specifically, shown in Figure 3,
AgileCtrl collects both the measured performance from the target
system and the predicted performance based on current controller
status for model adjustment ( ğ›¼). Moreover, AgileCtrl leverages the
stability of measured performance w.r.t to the goal for robustness
adjustment ( ğ‘£ğ‘”andğ‘ğ‘œğ‘™ğ‘’). Together, AgileCtrl enhances the system
with model and robustness self-adjustment during the run-time.
Our proposal is to make online adjustments to AdapConfs within
a self-adaptive framework. In other words, we want to estimate the
best setting for these AdapConfs based on the softwareâ€™s current
operating conditions. In deciding how to estimate these values, we
face a design choice: they can be estimated directly or indirectly
based on the properties of each AdapConf [ 2]. For direct estimation,
AdapConfs use design equations to reparameterize the model. This
approach has a shorter response time [ 65], but it assumes that
there is low noise in the samples and that inaccurate estimation
will not lead to catastrophic failure. Indirect estimation, recursively
estimates (i.e., slowly approaches the best value) for each AdapConf
as it collects feedback. This approach is much more resistant to
transient noise because a single erroneous (or outlier) observation
will not change the overall trajectory in which the AdapConf setting
is moving [2, 64].
The underlying ideas of AgileCtrl can be applied to other self-
adaptive frameworks besides SmartConf .AgileCtrl can be applied
with almost no changes to the increasingly large number of control
based self-adaptive frameworks (e.g., [ 16,27,34,60,62]), which
all have one or more parameters that capture the model relating
PerfConf settings to performance (analogous to ğ›¼in this paper).
Similarly, while not all control methods use a virtual goal, all have
some parameter relating to robustness to error and that parameter
can be tuned following the same methodology shown below. For
Multiple-Input Multiple-Output (MIMO) systems, the correlation
between configuration parameters and performance metrics can
be captured as a matrix instead of a scalar. AgileCtrl can leverage a
vector of performance metrics to update the model matrix based
on the difference between measured and predicted performance
metrics. In other words, the principle of updating the model based
on observed behavior still applies.
Interesting future work could investigate applying the same prin-
ciples to tune machine learning based models, as well, although
463ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore Shu Wang, Henry Hoffmann, and Shan Lu
the application of the proposed methods to such models is not
straightforward. Learning methods train an internal model relat-
ing PerfConfs to performance. Updating that model online would
require retraining as the learning-based framework evaluates its
dynamic behavior, so it is not clear that retraining cost would be
worthwhile. It is possible a learning-based system would also bene-
fit from observing the dynamic volatility in the environment and
adjusting its own robustness-related AdapConfs (e.g., the learning
rate) to tailor online behavior to the actual environment rather
than assuming the run time will be the same as the profiling, but
applying this approach would require a careful understanding of
the relationship between ML hyperparameters and the desired per-
formance.
4.2 Tuning AdapConfs Related to the Model
An accurate performance model is important for self-adaptive
frameworks to provide theoretical guarantees [ 16]; for instance, that
the software will converge to the desired performance. As shown
in Sec. 3, model deviation threatens both these formal guarantees
and even system availability.
For control-based self-adaptive frameworks, coefficient ğ›¼(or
analogous parameter) is the most important AdapConf for charac-
terizing the system model. It has the following properties:
(1)Its sign is the primary determinant of whether the software
converges to the goal, since the sign determines whether to
increase/decrease the underlying PerfConf, while its magni-
tude determines how aggressively the adjustment moves in
the direction indicated by the sign.
(2)Its magnitude usually has a wide range, as designers want
meaningful parameters and prior studies show that 90% of
the configuration are either integer or floating point values
[67].
(3)Its performance is sensitive to ğ›¼(Changingğ›¼from 0.01 to
0.001 could result in PerfConf changed by 10 times based on
Equation 2).
For all these reasons, we use the most conservative self-adaptive
strategy for ğ›¼tuning. Furthermore, we make the design choice
that it is preferable to reduce convergence speed while reducing
the chance for divergence. We therefore split the process of model
adjustment into two parts: determining the sign (or direction) of ğ›¼
and then determining the magnitude once the sign is established.
Coefficient ğ›¼sign , as mentioned above, is the key for perfor-
mance convergence or divergence. Moreover, it is the only Adap-
Conf that captures the trendâ€”positive or negative correlation of
performance-configurationâ€”and thus determines whether the un-
derlying PerfConf should be bigger or smaller (Equation 1). It is also
important to note that none of other AdapConfs ( ğ›¼â€™s magnitude,
poleğ‘norğ‘£ğ‘”) in Sec 2.2 have the property that incorrect setting
would result in tuning in the wrong direction. In other words, the
trend remains the same even all other AdapConfs are wrong. Thus,
we can indirectly detect the wrong ğ›¼sign based on tracking the
trend of how well the software system is meeting its goal.
Specifically, we can calculate the performance error ğ‘’ğ‘˜as the cur-
rent performance w.r.t the performance goal (Note that all control-
based approaches already track this value). Ideally, the traditionalcontroller is asymptotically stable, which means |ğ‘’ğ‘˜|should de-
crease while gradually reducing to zero [ 51]. Therefore, we check
the trend of ğ‘’ğ‘˜by comparing consecutive errorsâ€”whether the last
ğ‘–2errors are decreasing or not. The noise could occasionally affect
the temporary trend, but the long-term trend remains the same.
Specifically, we flip the sign when the last ğ‘–errors are in ascending
order (Algorithm 1); i.e., the performance is diverging further and
further away from the goal.
Algorithm 1: Wrongğ›¼sign detection
Input : Gâ€“ Performance Goal
ğ¶ğ‘˜â€“ Current performance measured at time ğ‘˜
ğ‘–â€“ Lastğ‘–samples
Output:ğ›¼â€“ Updated alpha sign
1Calculate current error ğ‘’ğ‘˜=|Gâˆ’ğ¶ğ‘˜|
2ifğ‘’ğ‘˜>ğ‘’ğ‘˜âˆ’1>Â·Â·Â·>ğ‘’ğ‘˜âˆ’ğ‘–+1then
/* incorrect ğ‘’ğ‘˜trend, flip the sign */
3ğ›¼ğ‘˜+1=âˆ’ğ›¼ğ‘˜
4end
Coefficient ğ›¼magnitude determines how the magnitude in
change for the underlying PerfConf. For example, if the PerfConf
controls the maximum size of a software data structure, then ğ›¼â€²ğ‘ 
magnitude determines how much that size might be changed at one
time. Specifically, if ğ›¼is too big, the controller might not be able to
react to the system changes fast enough, resulting in performance
degradation. Conversely, if ğ›¼is too small then the system becomes
unstable, causing performance oscillation or even crashes. AgileCtrl
approaches the ideal ğ›¼gradually without introducing extra Adap-
Confs through indirect estimation. In fact, it is much easier and more
robust to determine to enlarge or reduce ğ›¼magnitude iteratively
than acquiring optimal ğ›¼magnitude directly [ 1,2,29]. Specifically,
we leverage Model Reference Adaptive Control [ 2,13,37,50] used
in control theory to build another feedback loop to evaluate the
controllerâ€™s performance and propose a simple adaptation rule to
estimateğ›¼â€™s magnitude.
Specifically, we make ğ›¼a time varying quantity: ğ›¼ğ‘˜. We then
determine a ratio ğœƒ, where 0<ğœƒ<1, so that we can write ğ›¼ğ‘˜+1=
ğœƒğ›¼ğ‘˜. In control theory, the MIT Rule proposes to adjust ğœƒsuch that
the quadratic loss function [ 44]:ğ½=1
2(ğ‘ƒâˆ’ğ¶)2=1
2(ğœƒğ›¼ğ‘˜âˆ’ğ›¼ğ‘¡ğ‘Ÿğ‘¢ğ‘’)2ğ‘2
is minimized. Here ğ‘ƒandğ¶are the predicted and current perfor-
mance,ğ‘is current configuration, and ğ›¼ğ‘¡ğ‘Ÿğ‘¢ğ‘’ represents the actual
coefficient of the system (which cannot be measured). Essentially,
the loss function ğ½represents the error between the predicted and
current performanceâ€”we expect the predicted performance to be
the same as the actual measurement if ğ›¼ğ‘˜is accurate. Thus, we can
approximate ğ›¼ğ‘¡ğ‘Ÿğ‘¢ğ‘’ by noting that if the predicted performance is
far from the current performance, then the current ğ›¼ğ‘˜must also
be far fromğ›¼ğ‘¡ğ‘Ÿğ‘¢ğ‘’ as well. Specifically, the true value for ğœƒisğ›¼ğ‘¡ğ‘Ÿğ‘¢ğ‘’
ğ›¼ğ‘˜,
but since we cannot measure ğ›¼ğ‘¡ğ‘Ÿğ‘¢ğ‘’, we approximate the ratio of
the true to current ğ›¼ğ‘˜asğ›¼ğ‘¡ğ‘Ÿğ‘¢ğ‘’
ğ›¼ğ‘˜=(ğ›¼ğ‘¡ğ‘Ÿğ‘¢ğ‘’âˆ—ğ‘ğ‘˜+ğ‘)âˆ’(ğ›¼ğ‘¡ğ‘Ÿğ‘¢ğ‘’âˆ—ğ‘ğ‘˜âˆ’1+ğ‘)
(ğ›¼ğ‘˜âˆ—ğ‘ğ‘˜+ğ‘)âˆ’(ğ›¼ğ‘˜âˆ—ğ‘ğ‘˜âˆ’1+ğ‘)=
ğ¶ğ‘˜âˆ’ğ¶ğ‘˜âˆ’1
ğ‘ƒğ‘˜âˆ’(ğ›¼ğ‘˜âˆ—ğ‘ğ‘˜âˆ’1+ğ‘)â‰ˆğ¶ğ‘˜âˆ’ğ¶ğ‘˜âˆ’1
ğ‘ƒğ‘˜âˆ’ğ¶ğ‘˜âˆ’1. Of course, we assume the system is
subject to noise so we regularize this approximation using |Gâˆ’ğ¶ğ‘˜
G|
2ForAgileCtrl , we set i = 4. See Sec. 5.4 for more discussions.
464AgileCtrl : A Self-Adaptive Framework for Configuration Tuning ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore
as an exponent on this ratio. When the current performance already
meets the goal, then the exponent is close to 0 and ğ›¼remains the
same. When the current performance is far away from the goal,
the exponent is close to 1 which allows maximum changes on ğ›¼.
Putting this all together, we indirectly estimate ğ›¼ğ‘˜as:
ğ›¼ğ‘˜+1=ğ›¼ğ‘˜Â·{|ğ¶ğ‘˜âˆ’ğ¶ğ‘˜âˆ’1
ğ‘ƒğ‘˜âˆ’ğ¶ğ‘˜âˆ’1|}|Gâˆ’ğ¶ğ‘˜
G|, (3)
whereğ¶ğ‘˜âˆ’1andğ¶ğ‘˜are the previous and current performance,
ğ‘ƒğ‘˜is the predicted performance and Gis the performance goal.
Specifically, we update ğ›¼based on Algorithm 2. As long as the ratio
ğ¶ğ‘˜âˆ’ğ¶ğ‘˜âˆ’1
ğ‘ƒğ‘˜âˆ’ğ¶ğ‘˜âˆ’1is closeğ›¼ğ‘¡ğ‘Ÿğ‘¢ğ‘’
ğ›¼ğ‘˜, then we prove that ğ‘0<Â·Â·Â·<ğ›¼ğ‘˜âˆ’1<ğ›¼ğ‘˜<
Â·Â·Â·<ğ›¼ğ‘¡ğ‘Ÿğ‘¢ğ‘’ by induction, which means ğ›¼ğ‘˜will converge to ğ›¼ğ‘¡ğ‘Ÿğ‘¢ğ‘’.
Algorithm 2: Dynamicğ›¼Adjustment
Input : Gâ€“ Performance Goal
ğ¶ğ‘˜â€“ Current performance measured at time ğ‘˜
Output:ğ›¼â€“ Updated alpha magnitude
1Predict further performance ğ‘ƒğ‘˜at timeğ‘˜based onğ¶ğ‘˜âˆ’1
using Equation 1
2Updateğ›¼ğ‘˜+1=ğ›¼ğ‘˜Â·{|ğ¶ğ‘˜âˆ’ğ¶ğ‘˜âˆ’1
ğ‘ƒğ‘˜âˆ’ğ¶ğ‘˜âˆ’1|}|Gâˆ’ğ¶ğ‘˜
G|
SmartConf assumes a linear model (Equation 1) with bounded
errors for PerfConf, and the linearity assumption can cause failures
shown in Section 3. AgileCtrl relaxes such assumption through
dynamically updating the approximation (Algorithm 2).
4.3 Tuning AdapConfs Related to Robustness
Besides model accuracy, robustness is another important property
of any self-adaptive system. The robustness means the system can
accommodate unexpected changes in workload or environment.
For control-based self-adaptive framework, robustness is cap-
tured by both the pole ğ‘and the virtual goal, ğ‘£ğ‘”. For AgileCtrl , the
poleğ‘does not need to be adjusted dynamically, since (1) it is set
to tolerate erros in ğ›¼which are already addressed in Sec. 4.2 and (2)
ğ›¼andğ‘are correlated and together constitute a coefficient that de-
termines how aggressively the controller reacts to the performance
error. Therefore, ğ‘=0is used in AgileCtrl .
Recent works [ 63,67] introduce a virtual goal ( ğ‘£ğ‘”) that is smaller
than actual goal to avoid overshooting, and it can be calculated
based on inherent system noise (Sec. 2). Unlike ğ›¼,ğ‘£ğ‘”is in the range
[0,1]. Also,ğ‘£ğ‘”itself characterizes the system noise, which can be
statistically estimated. Therefore, ğ‘£ğ‘”can be self-adjusted through
direct estimation at run time.
To re-calculate ğ‘£ğ‘”, one needs to compensate for performance
variation caused by different configurations, since PerfConfs are
continuously changed by self-adaptive framework. To solve it, we
leverage the system configuration-performance model. Specifically,
wecalibrate the performance by compensating the measured per-
formance difference with the configuration differences, as shown
in Algorithm 3. We take ğ‘3pairs of <performance, configuration>
for virtual goal adjustment. We calibrate performance ğ‘ƒas if it is
measured with configuration ğ¶ğ‘˜based on the system model (i.e.,
3ForAgileCtrl , we set N = 40 suggested by sample-size rule-of-thumb [ 24]. See Sec. 5.4
for more discussions.based onğ›¼ğ‘˜as computed above) and obtain calibrated performance
ğ‘ƒâ€²(line 2-5). Then, we can simply recalculate the ğœğ‘˜andğ‘šğ‘˜based
on calibrated performance and recalculate the virtual goal as usual.
Algorithm 3: Virtual Goal Self-Adjustment
Input : P â€“ Current Performance
C â€“ Current Configuration
ğ‘â€“ Lastğ‘samples
Output:ğ‘£ğ‘”ğ‘˜â€“ Updated virtual goal
1s = 0
2while s < N do
3 Calibrateğ‘ƒğ‘˜âˆ’ğ‘ toğ‘ƒâ€²
ğ‘˜âˆ’ğ‘ =ğ‘ƒğ‘˜âˆ’ğ‘ âˆ’ğ›¼ğ‘˜(ğ¶ğ‘˜âˆ’ğ‘ âˆ’ğ¶ğ‘˜)
4 s++
5end
6Calculate standard deviation ğœğ‘˜and meanğ‘šğ‘˜ofğ‘ƒâ€²
7Updateğ‘£ğ‘”ğ‘˜=1âˆ’1
ğ‘Ãğ‘
1ğœğ‘˜
ğ‘šğ‘˜
4.4 Putting It All Together
All above-mentioned components are integrated into AgileCtrl and
can function seamlessly. In fact, ğ›¼sign correction is independent
of others since it does not require ğ›¼value orğ‘£ğ‘”to be accurate. The
ğ›¼magnitude adjustment will continuously update the performance
model to match the run-time, and it does not depend on either the ğ›¼
sign orğ‘£ğ‘”adjustment. The ğ‘£ğ‘”adjustment only relies on an accurate
performance model. There is no circular dependency among all
those components. As result, all components in AgileCtrl operate
together to achieve a self-adaptive system.
5 EVALUATION
5.1 Evaluation Methodology
Machines We used the Chameleon Cloud [ 33] for our experiments.
Each server has 2 12-core Intel Xeon E5-2670v3 CPU with 128GB
RAM. Ubuntu 16.04, JVM 1.7, and JVM 1.8 (compatible with CA6059)
are installed.
Baseline and Benchmarks We compare AgileCtrl with SmartConf
from three aspects: ğ›¼sign,ğ›¼magnitude and ğ‘£ğ‘”. We evaluate all
benchmarks used in SmartConf except for MR28204, as shown in
Table 2. Among those benchmarks, HD4995 and HB2419 have a
constraint on latency, and the other three benchmarks have hard-
limit constraints on memory usage to avoid out-of-memory failures.
Workload For database-related benchmarks Hbase and Cassandra
(HB3813, HB6728, HB2149, and CA6059), standard performance
testing framework YCSB [ 12] is used, while we use TestDFSIO [ 25]
for file system related benchmark HDFS (HD4995).
Run-time As shown in Table 2, we consider a separated run-time
settings for evaluating model self-adjustment ( ğ›¼sign and magnitude
adjustment) and robustness self-adjustment ( ğ‘£ğ‘”adjustment).
4For MR2820, the main goal is to restrict the maximum OOD exceptions within one
job smaller than the threshold to avoid job failure, and the exception is limited by the
number of machines the job tried. AgileCtrl is expected to work well for a large cluster.
However, given the small cluster size in our experiment, AgileCtrl failed to correct the
improper AdapConfs fast enough. Further discussions on AgileCtrl limitation are in
Section 5.4.
465ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore Shu Wang, Henry Hoffmann, and Shan Lu
Table 2: Benchmark suite and run-time setting for evaluation.
IDIssue Description Metrics Run-time Setting
(the primary constraint is put earlier; the trade-off constraint is later) Primary Secondary ğ›¼signğ›¼magnitude ğ‘£ğ‘”
HD
4995content-summary.limit limits #files traversed before dureleases locks. Write du
Man-Limit CPU
ReduceToo big, write blocked for long; Too small, dulatency hurts. Latency Latency
uallyusage to
ğ‘£ğ‘”toHB
2149global.memstore.lowerLimit decides how much memstore is flushed. Tail # Violated
flip100%/50%/
20%/40%/Too big, write blocked for too long; Too small, write blocked too often. Latency Latency 20%/10%
60%/80%HB
3813ipc.server.max.queue.size limits RPC-call queue size.MemoryThrough-
ğ›¼signToo big, OOM; Too small, read/write throughput hurts. put Increase
HB
6728ipc.server.response.queue.maxsize limits RPC-response queue size.MemoryThrough- size to
Too big, OOM; Too small, read/write throughput hurts. put 1/2/5/10
CA
6059memtable_total_space_in_mb limits the memtable size.Memory LatencyMB
Too big, OOM; Too small, write latency hurts.
Table 3:ğ›¼Sign Evaluation (Primary: the normalized primary
performance w.r.t the goal; the closes to 1 the better. Sec-
ondary: the secondary trade-off performance speedup w.r.t
SmartConf ; the larger, the better.)
BenchmarkSmartConf AgileCtrl
Primary Secondary Primary Secondary
HD4995 0.13
1.001.08 1.12
HB2149 0.15 0.99 1.42
HB3813 0.62 0.86 1.16
HB6728 0.53 0.70 2.67
CA6059 0.08 0.81 1.28
Forğ›¼sign: The wrong sign mostly comes from insufficient pro-
filing or human mistakes, which we simulate by flipping the sign of
the initialğ›¼, rather than workload or run-time resources changes.
Forğ›¼magnitude: ğ›¼magnitude are usually affected by different
types of runtime settings. For benchmarks (HB2149 and HD4995),
their primary performance metric is about latency which is directly
affected by CPU resources. Therefore, we limit CPU resources by
a factor ofÃ—1,Ã—2,Ã—5, andÃ—10 (namely, limit CPU usage to 100%,
50%, 20%, and 10%) with Linux CPULimit Tool. For benchmarks
(HB3813, HB6728 and CA6059), their primary metric is memory
usage, which is affected by workload. Therefore, we increase every
request size by the same factor (from 1MB up to 10MB).
Forğ‘£ğ‘”: Sinceğ‘£ğ‘”reflects the chaos of the runtime environment
and an improper ğ‘£ğ‘”means a mismatch between offline and online
virtual goal setting, we reduce the initial virtual goal by 20%, 40%,
60%, and 80%, and compare SmartConf andAgileCtrl .
5.2 AgileCtrl Evaluation
5.2.1 Model ( ğ›¼) Self-Adjustment: Our experiment with the wrong
ğ›¼sign shows that AgileCtrl performs much better than the baseline
SmartConf . As shown in Table 3, SmartConf can achieve only 13â€“
62% of the primary performance goal. On the contrary, AgileCtrl
keeps tracking of the moving direction of the primary performance,
and hence can auto-correct the sign of ğ›¼and achieves mostly more
than 80% of the primary performance goal even with an incorrectly
initializedğ›¼sign. Moreover, AgileCtrl also improves the secondary
performance compared with SmartConf .Table 4:ğ›¼Magnitude Evaluation. (C: the system crashes. O:
primary performance oscillates around the goal. Neither C
nor O: the normalized secondary performance speedup with
AgileCtrl being 1; the higher, the better.)
Bench Change Level SC OLR KF AgileCtrl
HD4995
ResourceÃ—1 0.93 0.91 1.00 1.00
Ã—2 0.93 0.91 0.87 1.00
Ã—5 O 0.97 0.91 1.00
Ã—10 O 0.92 0.83 1.00
HB2419Ã—1 0.86 O 0.87 1.00
Ã—2 0.80 O 0.88 1.00
Ã—5 O O 0.81 1.00
Ã—10 O O O 1.00
HB3813
WorkloadÃ—1 1.00 C 0.91 1.00
Ã—2 0.96 C 0.86 1.00
Ã—5 C C 0.81 1.00
Ã—10 C C C 1.00
HB6728Ã—1 0.98 C 1.01 1.00
Ã—2 0.65 C 1.02 1.00
Ã—5 C C 1.00 1.00
Ã—10 C C C C
CA6059Ã—1 0.97 C 0.95 1.00
Ã—2 0.95 C 1.01 1.00
Ã—5 C C 0.89 1.00
Ã—10 C C 0.99 1.00
Our experiment with the wrong ğ›¼magnitude compares AgileC-
trlwith not only SmartConf but also two prior techniques that
adjustğ›¼through Online Linear Regression (OLR) [16] or Kalman
Filter (KF) [27,65]. As shown in Table 4, online linear regression
(OLR) performed the worst, causing system crashes (mainly due to
out-of-memory problems) or severe performance oscillation in all
but one benchmark. This result shows that directly re-setting the
value ofğ›¼using the same offline linear regression algorithm used
during profiling, as in OLR, does not work. SmartConf (SC) is just
slightly better than OLR. Kalman Filter (KF) can eliminate most of
the crashes and oscillations encountered by OLR and SC, but still
performs significantly worse than AgileCtrl . It also introduces extra
configuration tuning, which we explain below. In contrast, AgileCtrl
466AgileCtrl : A Self-Adaptive Framework for Configuration Tuning ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore
only failed in one extreme case of HB6728, where other strategies
also failed. AgileCtrl performs the best for meeting primary perfor-
mance goals without oscillations or crashes, and enabling better
secondary performance without introducing any new AdapConfs.
Kalman Filter is a recursive filter that indirectly estimates the
internal parameters of a system given noisy measurements [ 32]. In
general, it suffers from two limitations compared with AgileCtrl .
(1) It assumes Gaussian noise, but software performanceâ€™s noise
often does not follow a normal distribution [ 45]. (2) It contains two
additional parameters, process noise and observation noise, that
are hard to be set correctly. In our experiment, we actually tuned
these two additional parameters by exhaustively search.
Finally, we quantify the model robustness of AgileCtrl against
other alternative solutions by calculating their error tolerance .
Specifically, we first calculate the ideal alpha ğ›¼ğ‘ ğ‘¦ğ‘ based on the of-
fline profiling. Then, we vary the ğ›¼ğ‘ğ‘¡ğ‘Ÿğ‘™magnitude and find the low-
est and highest boundary alpha ( ğ›¼ğ‘™ğ‘œğ‘¤ğ‘’ğ‘ ğ‘¡ _ğ‘ğ‘œğ‘¢ğ‘›ğ‘‘ andğ›¼â„ğ‘–ğ‘”â„ğ‘’ğ‘ ğ‘¡ _ğ‘ğ‘œğ‘¢ğ‘›ğ‘‘ )
under the same workload that system is about to crash or oscillate.
Therefore, the error tolerance (ğ¸ğ‘‡ğ‘™andğ¸ğ‘‡â„) for the particular
benchmark and strategy can be defined as:
ğ¸ğ‘‡ğ‘™=ğ›¼ğ‘ ğ‘¦ğ‘ 
ğ›¼ğ‘™ğ‘œğ‘¤ğ‘’ğ‘ ğ‘¡ _ğ‘ğ‘œğ‘¢ğ‘›ğ‘‘, ğ¸ğ‘‡â„=ğ›¼â„ğ‘–ğ‘”â„ğ‘’ğ‘ ğ‘¡ _ğ‘ğ‘œğ‘¢ğ‘›ğ‘‘
ğ›¼ğ‘ ğ‘¦ğ‘ (4)
By definition, both ğ¸ğ‘‡ğ‘™andğ¸ğ‘‡â„are greater than 1. The larger ğ¸ğ‘‡ğ‘™
orğ¸ğ‘‡â„is, the better ability to tolerate the errors in ğ›¼the system has,
thus the better system robustness is. In other words, the system is
stable ifğ›¼ğ‘ğ‘¡ğ‘Ÿğ‘™is within[ğ›¼ğ‘ ğ‘¦ğ‘ 
ğ¸ğ‘‡ğ‘™,ğ›¼ğ‘ ğ‘¦ğ‘ ğ¸ğ‘‡â„]. If none ofğ›¼can save the
system from crash or oscillation, we set ğ¸ğ‘‡=0to indicate such a
solution can not be used for adjusting the alpha magnitude.
Table 5: Overall Error Tolerance for AgileCtrl compared with
alternative approaches ( ğ¸ğ‘‡ğ‘™/ğ¸ğ‘‡â„: the lowest/highest alpha that
corresponding approach can correct without causing perfor-
mance oscillations or system crashes. 0: No such alpha with-
out causing performance oscillations or crashes)
BenchmarkSC OLR KF AgileCtrl
ğ¸ğ‘‡ğ‘™ğ¸ğ‘‡â„ğ¸ğ‘‡ğ‘™ğ¸ğ‘‡â„ğ¸ğ‘‡ğ‘™ğ¸ğ‘‡â„ğ¸ğ‘‡ğ‘™ğ¸ğ‘‡â„
HD4995 2 4 1061065âˆ—105104106106
HB2419 21030 0 10 2 106106
HB3813 31050 0 10630 106106
HB6728 21050 0 1.5 40 106106
CA6059 51032400 2 106106106
Table 5 shows AgileCtrl can greatly extend both the lowest bound
and highest bound compared with all alternative approaches, which
means it can tolerate a larger range of wrong ğ›¼ğ‘ğ‘¡ğ‘Ÿğ‘™used by the con-
troller. Well-tuned Kalman filter approach achieves slightly worse
performance, and online linear regression failed to provide any
robustness in 3 out of all 5 cases. The baseline solution SmartConf
can only provide only limited tolerance but it is more stable than
online linear regression.
5.2.2 Robustness (virtual goal) Self-Adjustment: Specifically, we
investigate how much secondary performance improved if the ini-
tial virtual goal is only 20%, 40%, 60%, and 80% of the ideal virtual
goal obtained from the profiling. Our experiment shows, across all
benchmarks, SmartConf fails to correct the wrong initial ğ‘£ğ‘”, whichTable 6: Virtual Goal ( ğ‘£ğ‘”) Evaluation: the speedup on the sec-
ondary performance metric w.r.t SmartConf under different
initial virtual goal ratios.
BenchmarkInitial Virtual Goal Ratio
20% 40% 60% 80%
HD4995 1.16 1.20 1.05 1.00
HB2149 1.65 1.42 1.38 1.19
HB3813 1.58 1.38 1.34 1.27
HB6728 2.10 2.39 2.26 2.13
CA6059 1.86 1.46 1.09 1.04
leads to poor secondary performance as well. AgileCtrl resets the
wrong initial goal requirement so that the primary performance
meets the ideal goal, while improving secondary performance by
50% on average, as shown in Table 6.
5.3 Case Study
 0 200 400Used
 Memory(MB)
Virtual Goal
Acutal Usage
-10 0 10
 0  2  4  6  8  10  12  14  16  18alpha
 (MB/items)
Time (s)Tolerable Alpha
Ideal Alpha
Actual Alpha
Figure 4: Both Initial ğ›¼â€™s magnitude and initial virtual goal
are 10x different from the ideal setting, and the initial ğ›¼â€™s
sign is also flipped. All modules of AgileCtrl are enabled and
able to fix wrong ğ›¼and virtual goal for HB3813
We take a close look at how AgileCtrl handles one representative
case HB3813. We considers an extreme buggy scenario. None of ğ›¼
sign,ğ›¼magnitude, and ğ‘£ğ‘”are right, and it required all components
to work together. Then, we analyze how each component functions
in this representative case.
Again, in HB3813, the PerfConf max.queue.size limits the
largest size for an Hbase RPC queue. Out-of-memory (OOM) is
more likely to happen with a large queue, while RPC throughput is
reduced with a small queue. The SmartConf alleviated the HB3813
issues to accommodate different workloads, maintain the memory
consumption without OOM, and improve the system throughput.
However, SmartConf introduces two representative AdapConfs
(<ğ›¼,ğ‘£ğ‘”>) to the system, where ğ›¼represents the size of the average
request, and ğ‘£ğ‘”reserved a portion of memory for safety. In fact,
467ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore Shu Wang, Henry Hoffmann, and Shan Lu
HB3813 contains the following challenges that are unique to self-
adaptive for software configuration tuning: (1) it requires online ğ›¼
tuning since online request size could be much larger or smaller
than offline. (2) it has a hard constraint on the performance, e.g.
the memory limit cannot be violated, (3) the performance (memory
usage) has large variations due to JAVA GC.
Ideally, a full combination of different ğ›¼â€™s magnitude, ğ›¼â€™s sign,
and virtual goal variations should be tested thoroughly. However,
the target system is more likely to suffer from performance degra-
dation or crash when attributes ğ›¼or virtual goal deviate from the
ideal setting. Therefore, we consider the following situation, where
both initial ğ›¼â€™s magnitude and initial virtual goal are 10Ã—differ-
ent from ideal, and ğ›¼â€™s sign is also flipped compared to ideal sign
(Specifically, ğ›¼ğ‘–ğ‘›ğ‘–ğ‘¡ğ‘–ğ‘ğ‘™ =âˆ’0.125andğ‘£ğ‘”ğ‘–ğ‘›ğ‘–ğ‘¡ğ‘–ğ‘ğ‘™ =0.091). As shown in
Fig. 4, though the initial ğ›¼andğ‘£ğ‘”are both wrong from the begin-
ning, AgileCtrl can quickly adjust the virtual goal back to the ideal
setting (90% of max memory), and ğ›¼sign is flipped to the positive
and quickly converge to ideal alpha magnitude. This demonstrates
that AgileCtrl â€™s feasibility of fixing multiple errors at the same time.
5.4 Limitations of AgileCtrl
AgileCtrl has its limitations. First, ğ›¼magnitude adjustment depends
on MIT rule, where itself is not globally convergent nor stable [ 44].
Compared with SmartConf ,AgileCtrl sacrifices statistical guaran-
tees provided by the traditional controller in return for system
robustness. Though the statistical guarantees we gave up, as shown
previously, the AgileCtrl outperforms SmartConf empirically.
Second, ideally, AgileCtrl can fix the both ğ›¼andğ‘£ğ‘”problem
no matter its initial magnitude. For example, in our evaluation,
AgileCtrl can tolerate improper ğ›¼by106Ã—due to human error. This
error tolerance could vary in different scenarios that affect the
system-performance model. For example, in HB3813, if the request
size is enlarged from 1ğ‘€ğµto106ğ‘€ğµâ‰ˆ1ğ‘‡ğµ, and any HBase with
less than 1ğ‘‡ğµheap memory resources will crash directly. This is due
toAgileCtrl is an asymptotic approach to bridge the gap between the
system model and control model. It does require a certain response
time to react to unexpected changes in the environment or workload.
Yet, in the previous example, the memory was already used up
before receiving the first full request, so there is no time for AgileCtrl
to realize the workload changes and take any precautions. Besides
response time, the computational precision should also take into
consideration when we deal with the extreme AdapConfs values.
Third, we introduce two parameters: ğ‘–(Algorithm 1) and ğ‘(Al-
gorithm 3). Unlike other AdapConfs, these two parameters provide
statistical guarantees. For example, in HB3813, when the setting
ofğ‘–is smaller than the default setting 4, we observe that a large
percentage of executions fail due to frequent sign flipping (90% for
ğ‘–=2and 60% for ğ‘–=3). Whenğ‘–is not smaller than the default
setting, none of the executions fail. With a larger ğ‘–, Algorithm 1 is
less sensitive to the system noise but takes a longer time to detect
the incorrect ğ›¼sign. Similarly, for sample size ğ‘that is less than
the default setting 40, like when ğ‘is10or20, all executions would
fail due to inaccurate ğ‘£ğ‘”estimation. In general, selecting a suitable
sample size is covered by best practices in statistics [ 24,30,31,48]
and is out of the scope of this paper.Fourth, AgileCtrl is designed to automate AdapConfs ( ğ›¼and
ğ‘£ğ‘”) used in control-based self-adaptive framework. For machine
learning-based self-adaptive system, they introduce a different set
of AdapConfs (learning rate, weight, etc) which are not solved by
existing AgileCtrl .
6 RELATED WORK
Automatic Configuration Tuning Large modern software con-
tains hundreds to thousands of configurations and those configura-
tions are usually badly documented and are hard for both developer
and user to set [ 67]. Great efforts have been made towards auto-
matic configuration tuning in recent years. Specifically, existing
approaches can be classified as, model-based tuning, search-based
tuning, and learning-based tuning. Model-based tuning [ 3,22] re-
lies on the accurate performance model of the system. Such model
synthesis usually requires domain-specific knowledge to abstract
software with a mathematical model. The model is highly abstracted
and very specific to the analyzed software. Search-based tuning
[47,73] treats the software as a black-box and uses a searching algo-
rithm to find the optimal settings. However, those approaches suffer
from exploration and exploitation problems and are not suitable
for dynamic adjustment during the runtime. Learning-based tuning
[10,57,67,69] usually builds a performance model based on the
profiling, and finds the best configuration during the runtime. The
performance models could be regression model [ 57,67] or machine
learning model [10, 69].
However, all those works mainly focus on improving the sys-
tem performance for the similar workload or environment. In
fact, both workload and environment have important impacts on
software performance, and they are unusually hard to model and
learn. SmartConf [67], a control theory-based solution, provides
a formal guarantee that systems can achieve desired performance
when the environments changes are within a small and pre-defined
boundary.
AgileCtrl is designed specifically for extending the system ro-
bustness without sacrificing the performance gain. For previous
works, the parameters are statically determined by the offline
profiling workload and environment. However, AgileCtrl automati-
cally adjusts those parameters during the runtime to accommodate
the workload and environment changes. Consequently, the system
error tolerance is greatly extended and system performance is im-
proved. In fact, AgileCtrl is designed to eliminate the offline process;
every parameter obtained from offline profiling should be adjusted
as well. Though AgileCtrl has only been applied to SmartConf in
this paper, the idea of AgileCtrl should be applied to any automatic
configuration tuning framework based on either static performance
model, static searching algorithm or offline profiling.
Machine Learning Machine learning has been widely used to
learn the system performance model as the foundation for search-
ing the optimal performance [ 10,14,15,57,66,69]. In general, those
approaches require a huge amount of effort on data collection, e.g.
tens of hours for one workload [ 54,69], let alone infinitely many
disturbances, workloads, and environment. A limited amount of
training data is not enough for the machine learning technique to
work in dynamics. The ability to adjust the machine model itself
468AgileCtrl : A Self-Adaptive Framework for Configuration Tuning ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore
based on dynamics during the runtime is needed. In contrast, con-
trol theory is designed for system dynamics with formal guarantee
[21]. Empirical studies comparing control and learning solutions
have observed that control techniques approach the goal with less
error [ 40]. Moreover, the machine learning model, such as neural
networks and deep learning, usually are hard to interpret as the
target system is treated as a black-box [ 36]. Therefore, machine
learning is not suitable for dealing with dynamics.
Adaptive Control Traditional control framework can still maintain
its properties if the applied system is slightly different from its
model synthesis or suffers from environment changes. To further
advance the controller for unexpected dynamic disturbances, the
adaptive control aims at adapting its underlying model during the
runtime to compensate for the environment or workload changes.
Though various adaptive control techniques have been proposed,
most of them are designed for specific systems. For example, it has
been successfully applied to Aerial Vehicles [ 55], Engine Control [ 9],
Distillation Column [ 35] and so on. However, the adaptive control
is hard to be generalized to different applications because of dif-
ferent underlying system models. AgileCtrl is designed specifically
to enhance general control frameworks [ 16], which approximates
the system model as a linear model without taking the high-order
correlations into consideration. AgileCtrl does not require addi-
tional assumptions other than the control framework. Moreover,
AdapConf is adjusted based on its internal performance instead of
analyzing the external system and environment. As demonstrated
in the evaluation section, with different benchmarks, disturbances,
and performance goals, AgileCtrl is robust enough across different
deployment scenarios and different environmental settings that
cause errors in AdapConfs. Thus, AgileCtrl itself is general with
respect to different applications as well as different types of system
disturbances.
Most importantly, adaptive controllers are inherently nonlinear
and complex [ 8] and prior researches focus on establishing stability
analysis of the adaptive control. However, most adaptive control
system introduces additional parameters, which require the control
expert to set. For non-expert, those parameters are hard to set and
error-prone. Previous work, CoPPer ,POET , and MoD2 [27,28,65],
took the first step for adjusting controller key parameters using
Kalman filter. However, it requires setting two additional parame-
ters, namely, process and observation noise with the assumption of
Gaussian distribution. AgileCtrl aims at allowing non-expert to use
without setting additional parameters.
7 CONCLUSIONS
Self-Adaptive frameworks have been successfully applied to auto-
mate configuration tuning with better performance. Those self-
adaptive frameworks explicitly or implicitly introduce a set of
AdapConfs to the system, and the proper AdapConfs setting de-
pends not only on the understanding of AdapConfs but also compli-
cated environment or workloads during the runtime. We argue that
self-adaptive frameworks should automate not only PerfConfs but
also AdapConfs. We proposed AgileCtrl to automatically modify
AdapConfs based on how well self-adaptive is performing. Our
evaluation demonstrates that, compared with other well-tuned ap-
proaches, AgileCtrl can tolerate larger workload or environmentchanges while achieving a similar performance without introducing
AdapConfs.
ACKNOWLEDGMENTS
We would like to thank the anonymous reviewers for their
insightful feedback and comments. This research is supported
by NSF (grants CCF-2119184, CCF-2028427, CNS-1956180,
CNS-1952050, CCF-1837120, CCF-1823032, CNS-1764039), ARO
(grant W911NF1920321), DOE (grant DESC0014195 0003), DARPA
(grant FA8750-16-2-0004), the CERES Center for Unstoppable
Computing, the Marian and Stuart Rice Research Award, gifts
from Microsoft and Facebook, and computation resources from
Chameleon.
REFERENCES
[1]Karl J Ã…strÃ¶m. 1984. LQG SELF-TUNERS. In Adaptive Systems in Control and
Signal Processing 1983 . Elsevier, Amsterdam, Netherlands, 137â€“146.
[2]Karl J Ã…strÃ¶m and BjÃ¶rn Wittenmark. 2013. Adaptive control . Courier Corporation,
Chelmsford, MA, USA.
[3]Simonetta Balsamo, Antinisca Di Marco, Paola Inverardi, and Marta Simeoni.
2004. Model-based performance prediction in software development: A survey.
IEEE Transactions on Software Engineering 30, 5 (2004), 295â€“310.
[4]Liang Bao, Xin Liu, Fangzheng Wang, and Baoyin Fang. 2019. Actgan: Auto-
matic configuration tuning for software systems with generative adversarial
networks. In 2019 34th IEEE/ACM International Conference on Automated Software
Engineering (ASE) . IEEE, Piscataway, NJ, USA, 465â€“476.
[5]Zhendong Bei, Zhibin Yu, Huiling Zhang, Wen Xiong, Chengzhong Xu, Lieven
Eeckhout, and Shengzhong Feng. 2015. RFHOC: A random-forest approach to
auto-tuning hadoopâ€™s configuration. IEEE Transactions on Parallel and Distributed
Systems (TPDS) 27, 5 (2015), 1470â€“1483.
[6]AndrÃ© B Bondi. 2015. Foundations of software and system performance engineer-
ing: process, performance modeling, requirements, testing, scalability, and practice .
Pearson Education, London, United Kingdom.
[7]Anthony Canino, Yu David Liu, and Hidehiko Masuhara. 2018. Stochastic energy
optimization for mobile GPS applications. In Proceedings of the 2018 26th ACM
Joint Meeting on European Software Engineering Conference and Symposium on
the Foundations of Software Engineering (ESEC/FSE) . ACM, New York, NY, USA,
703â€“713.
[8]Rajeev Chandramohan and Anthony J Calise. 2013. Output Feedback Adaptive
Control in the Presence of Unmodeled Dynamics. In AIAA Guidance, Navigation,
and Control (GNC) Conference . AIAA, Reston, VA, USA, 4517.
[9]Anthony Siming Chen, Jing Na, Guido Herrmann, Richard Burke, and Chris
Brace. 2017. Adaptive air-fuel ratio control for spark ignition engines with time-
varying parameter estimation. In 2017 9th International Conference on Modelling,
Identification and Control (ICMIC) . IEEE, Piscataway, NJ, USA, 1074â€“1079.
[10] Haifeng Chen, Wenxuan Zhang, and Guofei Jiang. 2010. Experience transfer for
the configuration tuning in large-scale computing systems. IEEE Transactions on
Knowledge and Data Engineering 23, 3 (2010), 388â€“401.
[11] Yeounoh Chung, Peter J. Haas, Eli Upfal, and Tim Kraska. 2019. Unknown
Examples & Machine Learning Model Generalization. arXiv:1808.08294 [cs.LG]
[12] Brian F Cooper, Adam Silberstein, Erwin Tam, Raghu Ramakrishnan, and Russell
Sears. 2010. Benchmarking cloud serving systems with YCSB. In Proceedings of
the ACM Symposium on Cloud Computing (SoCC) . ACM, New York, NY, USA,
143â€“154.
[13] Aniruddha Datta and Petros A Ioannou. 1994. Performance analysis and improve-
ment in model reference adaptive control. IEEE Trans. Automat. Control 39, 12
(1994), 2370â€“2387.
[14] Yi Ding, Nikita Mishra, and Henry Hoffmann. 2019. Generative and multi-
phase learning for computer systems optimization. In Proceedings of the 46th
International Symposium on Computer Architecture (ISCA) . ACM, New York, NY,
USA, 39â€“52.
[15] Yi Ding, Ahsan Pervaiz, Michael Carbin, and Henry Hoffmann. 2021. Generaliz-
able and Interpretable Learning for Configuration Extrapolation. In Proceedings
of the 29th ACM Joint Meeting on European Software Engineering Conference and
Symposium on the Foundations of Software Engineering (ESEC/FSE) . ACM, New
York, NY, USA, 728â€“740.
[16] Antonio Filieri, Henry Hoffmann, and Martina Maggio. 2014. Automated design of
self-adaptive software with control-theoretical formal guarantees. In Proceedings
of the 36th International Conference on Software Engineering (ICSE) . ACM, New
York, NY, USA, 299â€“310.
[17] Antonio Filieri, Henry Hoffmann, and Martina Maggio. 2015. Automated multi-
objective control for self-adaptive software design. In Proceedings of the 2015
469ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore Shu Wang, Henry Hoffmann, and Shan Lu
10th Joint Meeting on Foundations of Software Engineering (ESEC/FSE) . ACM, New
York, NY, USA, 13â€“24.
[18] Antonio Filieri, Martina Maggio, Konstantinos Angelopoulos, NicolÃ¡s Dâ€™ippolito,
Ilias Gerostathopoulos, Andreas Berndt Hempel, Henry Hoffmann, Pooyan
Jamshidi, Evangelia Kalyvianaki, Cristian Klein, et al .2017. Control strategies for
self-adaptive software systems. ACM Transactions on Autonomous and Adaptive
Systems (TAAS) 11, 4 (2017), 1â€“31.
[19] Omid Gheibi, Danny Weyns, and Federico Quin. 2021. Applying Ma-
chine Learning in Self-Adaptive Systems: A Systematic Literature Review.
arXiv:2103.04112 [cs.NE]
[20] Haryadi S Gunawi, Mingzhe Hao, Riza O Suminto, Agung Laksono, Anang D
Satria, Jeffry Adityatama, and Kurnia J Eliazar. 2016. Why does the cloud stop
computing? lessons from hundreds of service outages. In Proceedings of the
Seventh ACM Symposium on Cloud Computing (SoCC) . ACM, New York, NY, USA,
1â€“16.
[21] Joseph L. Hellerstein, Yixin Diao, Sujay Parekh, and Dawn M. Tilbury. 2004.
Feedback Control of Computing Systems . John Wiley & Sons, Hoboken, NJ, USA.
[22] Herodotos Herodotou, Harold Lim, Gang Luo, Nedyalko Borisov, Liang Dong,
Fatma Bilgen Cetin, and Shivnath Babu. 2011. Starfish: A Self-tuning System for
Big Data Analytics. In Conference on Innovative Data Systems Research (CIDR) .
CIDR, USA, 261â€“272.
[23] Henry Hoffmann. 2015. Jouleguard: Energy guarantees for approximate appli-
cations. In Proceedings of the 25th Symposium on Operating Systems Principles
(SOSP) . ACM, New York, NY, USA, 198â€“214.
[24] Robert Vincent Hogg and Elliot A Tanis. 2009. Probability and statistical inference .
Pearson Education, London, United Kingdom.
[25] Shengsheng Huang, Jie Huang, Jinquan Dai, Tao Xie, and Bo Huang. 2010. The
HiBench benchmark suite: Characterization of the MapReduce-based data anal-
ysis. In 2010 IEEE 26th International conference on data engineering workshops
(ICDEW) . IEEE, Piscataway, NJ, USA, 41â€“51.
[26] Connor Imes and Henry Hoffmann. 2016. Bard: A unified framework for man-
aging soft timing and power constraints. In 2016 International Conference on
Embedded Computer Systems: Architectures, Modeling and Simulation (SAMOS) .
IEEE, Piscataway, NJ, USA, 31â€“38.
[27] Connor Imes, David HK Kim, Martina Maggio, and Henry Hoffmann. 2015. POET:
a portable approach to minimizing energy under soft real-time constraints. In 21st
IEEE Real-Time and Embedded Technology and Applications Symposium (RTAS) .
IEEE, Piscataway, NJ, USA, 75â€“86.
[28] Connor Imes, Huazhe Zhang, Kevin Zhao, and Henry Hoffmann. 2019. Copper:
Soft real-time application performance using hardware power capping. In 2019
IEEE International Conference on Autonomic Computing (ICAC) . IEEE, Piscataway,
NJ, USA, 31â€“41.
[29] Rolf Isermann. 1982. Parameter adaptive control algorithms - A tutorial. Auto-
matica 18, 5 (1982), 513â€“528.
[30] Glenn D Israel. 1992. Determining sample size.
[31] Prashant Kadam and Supriya Bhalerao. 2010. Sample size calculation. Interna-
tional journal of Ayurveda research 1, 1 (2010), 55.
[32] Rudolph Emil Kalman. 1960. A new approach to linear filtering and prediction
problems. Journal of basic Engineering 82, 1 (1960), 35â€“45.
[33] Kate Keahey, Jason Anderson, Zhuo Zhen, Pierre Riteau, Paul Ruth, Dan Stanzione,
Mert Cevik, Jacob Colleran, Haryadi S. Gunawi, Cody Hammock, Joe Mambretti,
Alexander Barnes, FranÃ§ois Halbach, Alex Rocha, and Joe Stubbs. 2020. Lessons
Learned from the Chameleon Testbed. In Proceedings of the 2020 USENIX Annual
Technical Conference (ATC) . USENIX, Berkeley, CA, USA.
[34] Cristian Klein, Martina Maggio, Karl-Erik Ã…rzÃ©n, and Francisco HernÃ¡ndez-
Rodriguez. 2014. Brownout: Building more robust cloud applications. In Proceed-
ings of the 36th International Conference on Software Engineering (ICSE) . ACM,
New York, NY, USA, 700â€“711.
[35] Petia Koprinkova-Hristova, Yancho Todorov, Nicolae Paraschiv, Marius Olteanu,
and Margarita Terziyska. 2017. Adaptive control of distillation column using
adaptive critic design. In 2017 21st International Conference on Process Control
(PC). IEEE, Piscataway, NJ, USA, 434â€“439.
[36] Josua Krause, Adam Perer, and Enrico Bertini. 2016. Using visual analytics to
interpret predictive machine learning models.
[37] Gerhard Kreisselmeier and Brian Anderson. 1986. Robust model reference adap-
tive control. IEEE Trans. Automat. Control 31, 2 (1986), 127â€“133.
[38] Chi Li, Shu Wang, Henry Hoffmann, and Shan Lu. 2020. Statically inferring
performance properties of software configurations. In Proceedings of the Fifteenth
European Conference on Computer Systems (EuroSys) . ACM, New York, NY, USA,
1â€“16.
[39] Yan Li, Kenneth Chang, Oceane Bel, Ethan L Miller, and Darrell DE Long. 2017.
CAPES: Unsupervised storage performance tuning using neural network-based
deep reinforcement learning. In Proceedings of the international conference for
high performance computing, networking, storage and analysis (SC) . ACM, New
York, NY, USA, 1â€“14.
[40] Martina Maggio, Henry Hoffmann, Alessandro V Papadopoulos, Jacopo Panerati,
Marco D Santambrogio, Anant Agarwal, and Alberto Leva. 2012. Comparisonof decision-making strategies for self-optimization in autonomic computing
systems. ACM Transactions on Autonomous and Adaptive Systems (TAAS) 7, 4
(2012), 1â€“32.
[41] Martina Maggio, Henry Hoffmann, Marco D Santambrogio, Anant Agarwal, and
Alberto Leva. 2010. Controlling software applications via resource allocation
within the heartbeats framework. In 49th IEEE Conference on Decision and Control
(CDC) . IEEE, Piscataway, NJ, USA, 3736â€“3741.
[42] Martina Maggio, Alessandro Vittorio Papadopoulos, Antonio Filieri, and Henry
Hoffmann. 2017. Automated control of multiple software goals using multiple
actuators. In Proceedings of the 2017 11th joint meeting on foundations of software
engineering (ESEC/FSE) . ACM, New York, NY, USA, 373â€“384.
[43] Biswadip Maity, Majid Shoushtari, Amir M Rahmani, and Nikil Dutt. 2019. Self-
adaptive memory approximation: A formal control theory approach. IEEE Em-
bedded Systems Letters 12, 2 (2019), 33â€“36.
[44] Iven MY Mareels, Brian DO Anderson, Robert R Bitmead, Marc Bodson, and
Shankar S Sastry. 1987. Revisiting the MIT rule for adaptive control. In Adaptive
Systems in Control and Signal Processing 1986 . Elsevier, Amsterdam, Netherlands,
161â€“166.
[45] Aleksander Maricq, Dmitry Duplyakin, Ivo Jimenez, Carlos Maltzahn, Ryan
Stutsman, and Robert Ricci. 2018. Taming performance variability. In 13th USENIX
Symposium on Operating Systems Design and Implementation (OSDI) . USENIX,
Berkeley, CA, USA, 409â€“425.
[46] Nikita Mishra, Connor Imes, John D Lafferty, and Henry Hoffmann. 2018.
CALOREE: Learning Control for Predictable Latency and Low Energy. In Pro-
ceedings of the Twenty-Third International Conference on Architectural Support for
Programming Languages and Operating Systems (ASPLOS) . ACM, New York, NY,
USA, 184â€“198.
[47] Vivek Nair, Tim Menzies, Norbert Siegmund, and Sven Apel. 2017. Using bad
learners to find good configurations. In Proceedings of the 2017 11th Joint Meeting
on Foundations of Software Engineering (ESEC/FSE) . ACM, New York, NY, USA,
257â€“267.
[48] Marlies Noordzij, Giovanni Tripepi, Friedo W Dekker, Carmine Zoccali,
Michael W Tanck, and Kitty J Jager. 2010. Sample size calculations: basic prin-
ciples and common pitfalls. Nephrology dialysis transplantation 25, 5 (2010),
1388â€“1393.
[49] Pradeep Padala, Kang G Shin, Xiaoyun Zhu, Mustafa Uysal, Zhikui Wang, Sharad
Singhal, Arif Merchant, and Kenneth Salem. 2007. Adaptive control of virtualized
resources in utility computing environments. In Proceedings of the 2nd ACM
SIGOPS/EuroSys European Conference on Computer Systems (EuroSys) . ACM, New
York, NY, USA, 289â€“302.
[50] Patric Parks. 1966. Liapunov redesign of model reference adaptive control systems.
IEEE Trans. Automat. Control 11, 3 (1966), 362â€“367.
[51] Alexey Pavlov, Nathan Van De Wouw, and Henk Nijmeijer. 2005. Convergent
systems: analysis and synthesis. In Control and observer design for nonlinear finite
and infinite dimensional systems . Springer, New York, NY, USA, 131â€“146.
[52] Raghavendra Pradyumna Pothukuchi, Amin Ansari, Bhargava Gopireddy, and
Josep Torrellas. 2017. Sthira: A formal approach to minimize voltage guardbands
under variation in networks-on-chip for energy efficiency. In 2017 26th Interna-
tional Conference on Parallel Architectures and Compilation Techniques (PACT) .
IEEE, Piscataway, NJ, USA, 260â€“272.
[53] Raghavendra Pradyumna Pothukuchi, Joseph L Greathouse, Karthik Rao, Christo-
pher Erb, Leonardo Piga, Petros G Voulgaris, and Josep Torrellas. 2019. Tangram:
Integrated control of heterogeneous computers. In Proceedings of the 52nd Annual
IEEE/ACM International Symposium on Microarchitecture (MICRO) . ACM, New
York, NY, USA, 384â€“398.
[54] Raghavendra Pradyumna Pothukuchi, Sweta Yamini Pothukuchi, Petros G Voul-
garis, and Josep Torrellas. 2020. Control Systems for Computing Systems: Making
computers efficient with modular, coordinated, and robust control. IEEE Control
Systems Magazine 40, 2 (2020), 30â€“55.
[55] Nirmit Prabhakar, Andrew Painter, Richard Prazenica, and Mark Balas. 2018.
Trajectory-Driven Adaptive Control of Autonomous Unmanned Aerial Vehicles
with Disturbance Accommodation. Journal of Guidance, Control, and Dynamics
41, 9 (2018), 1976â€“1989.
[56] Muhammad Husni Santriaji and Henry Hoffmann. 2016. Grape: Minimizing
energy for gpu applications with performance requirements. In 2016 49th An-
nual IEEE/ACM International Symposium on Microarchitecture (MICRO) . IEEE,
Piscataway, NJ, USA, 1â€“13.
[57] Atri Sarkar, Jianmei Guo, Norbert Siegmund, Sven Apel, and Krzysztof Czarnecki.
2015. Cost-efficient sampling for performance prediction of configurable sys-
tems (t). In 2015 30th IEEE/ACM International Conference on Automated Software
Engineering (ASE) . IEEE, Piscataway, NJ, USA, 342â€“352.
[58] Huajie Shao, Shuochao Yao, Dachun Sun, Aston Zhang, Shengzhong Liu, Dongxin
Liu, Jun Wang, and Tarek Abdelzaher. 2020. Controlvae: Controllable variational
autoencoder. In International Conference on Machine Learning (ICML) . PMLR,
USA, 8655â€“8664.
[59] Stepan Shevtsov, Mihaly Berekmeri, Danny Weyns, and Martina Maggio. 2017.
Control-theoretical software adaptation: A systematic literature review. IEEE
Transactions on Software Engineering 44, 8 (2017), 784â€“810.
470AgileCtrl : A Self-Adaptive Framework for Configuration Tuning ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore
[60] Stepan Shevtsov, Danny Weyns, and Martina Maggio. 2017. Handling new and
changing requirements with guarantees in self-adaptive systems using SimCA.
In2017 IEEE/ACM 12th International Symposium on Software Engineering for
Adaptive and Self-Managing Systems (SEAMS) . IEEE, Piscataway, NJ, USA, 12â€“23.
[61] Stepan Shevtsov, Danny Weyns, and Martina Maggio. 2019. Self-adaptation of
software using automatically generated control-theoretical solutions. In Engi-
neering Adaptive Software Systems . Springer, New York, NY, USA, 35â€“55.
[62] Stepan Shevtsov, Danny Weyns, and Martina Maggio. 2019. SimCA* A Control-
theoretic Approach to Handle Uncertainty in Self-adaptive Systems with Guar-
antees. ACM Transactions on Autonomous and Adaptive Systems (TAAS) 13, 4
(2019), 1â€“34.
[63] Filippo Sironi, Martina Maggio, Riccardo Cattaneo, Giovanni F Del Nero, Do-
natella Sciuto, and Marco D Santambrogio. 2013. ThermOS: System support for
dynamic thermal management of chip multi-processors. In Proceedings of the 22nd
International Conference on Parallel Architectures and Compilation Techniques
(PACT) . IEEE, Piscataway, NJ, USA, 41â€“50.
[64] Torsten SÃ¶derstrÃ¶m, Lennart Ljung, and Ivar Gustavsson. 1974. A comparative
study of recursive identification methods.
[65] Yanxiang Tong, Yi Qin, Yanyan Jiang, Chang Xu, Chun Cao, and Xiaoxing Ma.
2021. Timely and accurate detection of model deviation in self-adaptive software-
intensive systems. In Proceedings of the 29th ACM Joint Meeting on European
Software Engineering Conference and Symposium on the Foundations of Software
Engineering (ESEC/FSE) . ACM, New York, NY, USA, 168â€“180.
[66] Dana Van Aken, Andrew Pavlo, Geoffrey J Gordon, and Bohan Zhang. 2017.
Automatic database management system tuning through large-scale machine
learning. In Proceedings of the 2017 ACM International Conference on Management
of Data (SIGMOD) . ACM, New York, NY, USA, 1009â€“1024.
[67] Shu Wang, Chi Li, Henry Hoffmann, Shan Lu, William Sentosa, and Achmad Imam
Kistijantoro. 2018. Understanding and Auto-Adjusting Performance-Sensitive
Configurations. In Proceedings of the Twenty-Third International Conference on Ar-
chitectural Support for Programming Languages and Operating Systems (ASPLOS) .ACM, New York, NY, USA, 154â€“168.
[68] Tao Ye and Shivkumar Kalyanaraman. 2003. A recursive random search algorithm
for large-scale network parameter configuration. In Proceedings of the 2003 ACM
SIGMETRICS International conference on Measurement and modeling of computer
systems (SIGMETRICS) . ACM, New York, NY, USA, 196â€“205.
[69] Zhibin Yu, Zhendong Bei, and Xuehai Qian. 2018. Datasize-aware high dimen-
sional configurations auto-tuning of in-memory cluster computing. In Proceedings
of the Twenty-Third International Conference on Architectural Support for Program-
ming Languages and Operating Systems (ASPLOS) . ACM, New York, NY, USA,
564â€“577.
[70] Gina Yuan, Shoumik Palkar, Deepak Narayanan, and Matei Zaharia. 2020. Offload
annotations: Bringing heterogeneous computing to existing libraries and work-
loads. In 2020 USENIX Annual Technical Conference (ATC) . USENIX, Berkeley, CA,
USA, 293â€“306.
[71] Yuanliang Zhang, Haochen He, Owolabi Legunsen, Shanshan Li, Wei Dong, and
Tianyin Xu. 2021. An Evolutionary Study of Configuration Design and Imple-
mentation in Cloud Systems. In 2021 IEEE/ACM 43rd International Conference on
Software Engineering (ICSE) . IEEE, Piscataway, NJ, USA, 188â€“200.
[72] Yanqi Zhou, Henry Hoffmann, and David Wentzlaff. 2016. CASH: Supporting
IaaS Customers with a Sub-Core Configurable Architecture. SIGARCH Comput.
Archit. News 44, 3 (jun 2016), 682â€“694. https://doi.org/10.1145/3007787.3001209
[73] Yuqing Zhu, Jianxun Liu, Mengying Guo, Yungang Bao, Wenlong Ma, Zhuoyue
Liu, Kunpeng Song, and Yingchun Yang. 2017. BestConfig: tapping the perfor-
mance potential of systems via automatic configuration tuning. In Proceedings
of the 2017 Symposium on Cloud Computing (SoCC) . ACM, New York, NY, USA,
338â€“350.
[74] Sergey Zhuravlev, Sergey Blagodurov, and Alexandra Fedorova. 2010. Addressing
shared resource contention in multicore processors via scheduling. ACM Sigplan
Notices 45, 3 (2010), 129â€“142.
471