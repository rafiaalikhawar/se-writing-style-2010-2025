Grace: Language Models MeetCodeEdits
Priyanshu Gupta∗
priyansgupta@microsoft.com
Microsoft
IndiaAvishree Khare∗†
akhare@seas.upenn.edu
Universityof Pennsylvania
USAYasharthBajpai
ybajpai@microsoft.com
Microsoft
India
SaikatChakraborty
saikatc@microsoft.com
Microsoft Research
USASumit Gulwani
sumitg@microsoft.com
Microsoft
USAAdityaKanade
kanadeaditya@microsoft.com
Microsoft Research
India
ArjunRadhakrishna
arradha@microsoft.com
Microsoft
USAGustavoSoares
gsoares@microsoft.com
Microsoft
USAAshish Tiwari
astiwar@microsoft.com
Microsoft
USA
ABSTRACT
Developers spend a signi/f_icant amount of time in editing code for
a variety of reasons such as bug /f_ixing or adding new features. De-
signingeﬀective methodsto predictcodeeditshas been anactive
yetchallengingareaofresearchduetothediversityofcodeedits
andthediﬃcultyofcapturingthedeveloperintent.Inthiswork,we
addressthese challengesbyendowing pre-trained large language
models (LLMs) with the knowledge of relevant prior associated ed-
its,whichwecallthe Grace(GenerationconditionedonAssociated
CodeEdits)method.ThegenerativecapabilityoftheLLMshelps
address the diversity in code changes and conditioning code gener-
ationonprioreditshelpscapturethelatentdeveloperintent.We
evaluatetwowell-knownLLMs, codexandCodeT5,inzero-shot
and /f_ine-tuning settings respectively. In our experiments with two
datasets,Gracebooststheperformance of theLLMssigni/f_icantly,
enabling them to generate 29% and 54% more correctly-edited code
intop-1suggestionsrelativetothecurrentstate-of-the-artsymbolic
andneuralapproaches,respectively.
CCS CONCEPTS
•Softwareanditsengineering →Softwareevolution ;Auto-
matic programming ;•Computing methodologies →Arti/f_icial
intelligence .
KEYWORDS
Codeediting,Associatededits,Largelanguagemodels,Pre-trained
model,Programminglanguageprocessing
∗Bothauthorscontributed equally to thiswork.
†Workdonewhile at Microsoft
Permissionto make digitalor hard copies of allorpart ofthis work for personalor
classroom use is granted without fee provided that copies are not made or distributed
forpro/f_itorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthe/f_irstpage.Copyrights forcomponentsofthisworkownedbyothersthanthe
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or
republish,topostonserversortoredistributetolists,requirespriorspeci/f_icpermission
and/or a fee. Request permissions from permissions@acm.org.
ESEC/FSE ’23, December 3–9, 2023, San Francisco, CA,USA
©2023 Copyright heldby the owner/author(s). Publicationrightslicensed to ACM.
ACM ISBN 979-8-4007-0327-0/23/12...$15.00
https://doi.org/10.1145/3611643.3616253ACMReference Format:
Priyanshu Gupta, Avishree Khare, Yasharth Bajpai, Saikat Chakraborty,
Sumit Gulwani, Aditya Kanade, Arjun Radhakrishna, Gustavo Soares,
and Ashish Tiwari. 2023. Grace: Language Models Meet Code Edits. In
Proceedings of the 31st ACM Joint European Software Engineering Conference
andSymposiumontheFoundationsofSoftwareEngineering(ESEC/FSE’23),
December 3–9, 2023, San Francisco, CA, USA. ACM, New York, NY, USA,
13pages.https://doi.org/10.1145/3611643.3616253
1 INTRODUCTION
Maintainingandmodifyingexistingcodetakesupaconsiderable
portionofadeveloper’stimecomparedtowritingnewcode[ 9,40].
Duetothehighcostofsoftwaremaintenance[ 32,35],popularInte-
grated Development Environments (IDEs) have tooling to support
developersastheyrefactorcode[ 25,26,45],/f_ixdefects,adaptcode
to changes in the environment, or add support for new or changed
requirements [ 34,45]. One desirable feature is code edit suggestions
whereinthetoolsusethelocationwherethedeveloperisediting
code,andthesurroundingcodecontext,togeneratecandidateedits
to recommend[ 44,68].
Toautomatecodeeditsuggestions,researchershaveproposed
several approaches to learn edit patterns from edits in source code
repositories[ 7,19,36,56].However,theseapproachessuﬀerfrom
two key limitations: (1) They focus on individual edits and learn
program transformation rules for them. We note that edits are not
performedinisolation.Developersmakechangesatonelocation,
then jump to another, and then maybe back to the /f_irst location to
makefurtherchanges[ 37].Theeditsthatdevelopersmaketothe
code at diﬀerent locations may not be identical, but they are often
interrelated.Infact,thenexteditoftendependsonthepreviously
performed edits [ 68]. Learning one-step edit patterns limits the
ability of these approaches to accurately predict the most likely
next edit. (2) The symbolic program transformation rules can only
slice and dice the existing code and compose its pieces to create
code – they cannot generate new code whose pieces do not already
occurintheexistingversion.Thislimitstheexpressivenessofthese
approachesinterms ofthe types of editsthat they can predict.
Unlike symbolic program transformation rules, neural language
models have the capability to generate new code that does not
1483
ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA P. Gupta, A.Khare, Y. Bajpai, S.Chakraborty, S.Gulwani, A.Kanade, A.Radhakrishna, G.Soares, andA.Tiwari
necessarily occur in the surrounding code context. The pre-trained
large language models (LLMs) like codex[16] andCodeT5[63]
have been shown to be highly pro/f_icient at generating code. In
fact,theyarealreadyimpactingsoftwareengineeringinsigni/f_icant
ways, e.g., through popular code completion tools like GitHub
Copilot [28]. However, when it comes to editing code, without the
knowledgeofpreviousedits,thesemodelsareunabletoinferthe
developers’ intentand failto generate codethat should be used to
replaceexistingcodeinthenextedit.Inthiswork,weexploreways
topredictcodeeditsusing LLMs byconditioningcodegeneration
on prior, relevant edits. We call such prior edits associated edits
and this methodology as Generation conditioned on Associated Code
Edits(Grace).
In recent times, there have been a few attempts to leverage
past history of code evolution to learn to edit code [ 10,55,68].
overwatch [68] is a symbolic technique that mines "edit sequence
patterns".Suchapatternisessentiallyaprogramtransformation
rulewhoseapplicationisconditionedonthepriorapplicationof
someotherprogramtransformationrules.Beingapattern-based
technique, overwatch suﬀersfromtheinabilitytogeneratenew
code, and it also requires signi/f_icant engineering eﬀort to build
the underlying symbolic pattern-learning engine. c3po[10] is a
neuralmodeltopredictthenexteditatalocation,giventheedits
only in the spatial vicinity of that location. While reliance on such
spatially related edits shows initial promise towards automation in
code editing, the hypothesis may not always hold true—developers
may edit two locations simultaneously that are far away from each
other spatially [ 37]. In this work, we attempt to relax this reliance,
and do not restrict associated edits to be the ones that occur in
thespatialvicinityofthelocationunderconsideration.Weshow
that associated edits obtained from temporal history can also be
useful.Further,the c3pomodelisacustommodelthatgenerates
the edited code by copy-pasting existing code fragments and is
therefore unable to generate new code (similar to the symbolic
techniques including overwatch ).
EditPro [55] is a recent neural model that aims to learn the edit
process for natural language documents and code /f_iles. It proposes
aspecialmulti-stepprocedurewherethemodel/f_irstpredictstoken-
wise editactions(insert, delete, etc.), whichare thensubsequently
applied to the code. The edit actions requiring code generation,
suchasinsertandreplace,requireaseparatedecodingstep.Edit-
Proexperimentswithsingle-lineedits,whereasourdatasetscon-
tain multi-line edits. Instead of training a new type of model from
scratch, which can be expensive and requires a signi/f_icant amount
ofdata,Graceallows ustorepurposethealready powerfulLLMs
to generateeditedcode.
We demonstrate the bene/f_its of our approach in two settings:
(1)zero-shotsetting inwhichtheLLMisusedout-of-the-boxwithout
additionaltrainingbutwithaninformativepromptaboutassociated
edits and (2) /f_ine-tuning setting in which the LLM is /f_ine-tuned on
dataannotatedwithassociatededits.Inbothcases,ourresultsshow
signi/f_icant bene/f_its of conditioning existing LLMs on associated
edits without having to pay the price of designing and training
specializedmodels from scratch.
Inourexperiments,weusethecode-editingbenchmarksfrom
overwatch andc3po. As the baseline LLMs, we use the codex-
davincimodel in the zero-shot setting and the CodeT5model(220M params)in the /f_ine-tuning setting. We show thatthe use of
associatededitshelpsboosttheabilityofthesemodelstopredict
the next edit compared to the pre-trained models used without
associated edits. In the case of codex-davinci , we get improve-
mentsof17%and30%(inabsoluteterms)fortheOverwatchand
C3PO datasets, and improvement of 7.45% and 9.64% in the case
ofCodeT5.Wealso compare codex-davinci withassociated-edit
prompting and the /f_ine-tuned CodeT5model with the overwatch
andc3pomethodsontherespectivedatasets.Allourmodelssub-
stantially outperform these methods on their own datasets by a
signi/f_icant margin. Our best models outperform overwatch on its
dataset by 10.92% and c3poon its dataset by 28.63% (absolute): this
is 28.61% and 53.82% relative improvement respectively. EditPro
datasetandmodelhavenotbeenreleasedbytheauthorsyet,there-
fore,wewereunabletocompareagainstit.Both overwatch and
c3poconstruct edited code from existingor past code, whereas we
useLLMsthatarecapableofgenerating newcode.Weshowthat
this makes our approach more general, and we can predict code
editsthat are often out-of-scope for theseapproaches.
In summary,we make the following contributions:
(1)We consider a practically important software-engineering
problemofpredictingcodeeditsandpropose Grace,anovel
methodofleveragingpowerfulLLMstopredictcodeedits
byconditioningthemonprior edits.
(2)Through experimentation on two datasets, we show that
usingGracewecansubstantiallyimproveperformanceof
LLMsinzero-shotor/f_ine-tuningsettings.
(3)Graceis superior to the state-of-the-art symbolic or neural
methodsdesignedspeci/f_ically to handle code edits.
(4)We conduct experiments to thoroughly evaluate Graceand
report insightsgleanedfrom them.
2 MOTIVATING EXAMPLE
In this section, we motivate Graceby using a concrete code
developmentscenario.Wefurtherdiscusshowthisapproachdiﬀers
from existing approaches.
Illustrative Example : Consider a developer refactoring code
showninFigure 1aasVersion /u1D4631.Thegoalofthedeveloperistouse
SerializationException provided by the System.Runtime.Serialization
namespace to get to Version /u1D4633shown in Figure 1c. Let us say that
the developer /f_irst replaces Exception on line 250 in Version /u1D4631with
SerializationException to create Version /u1D4632shown in Figure 1b. This
edit required to go from Version /u1D4631to Version /u1D4632is denoted as /u1D6FF1,2.
The developer’s cursor then moves to Line 3 of Version /u1D4632and our
goal is to predict the next edit the developer will perform to reach
Version/u1D4633,namely the edit /u1D6FF2,3.
Conditioning on Prior Edits : The task of predicting the edit
/u1D6FF2,3is non-trivial. The code in Version /u1D4632has some useful informa-
tion; for example, the code indicates that SerializationException is
de/f_ined on Line 250 of Version /u1D4632but the required System.Runtime
.Serialization namespace hasn’t been imported anywhere. This
signal, however, is faintly present within 250 lines of additional
spatialcontextandtherelationshipbetweentheaddedException
andtherequiredimportislost.Thisrelationshipisanimportant
pieceofinformationthatisrequiredtoinsertthe usingstatement
1484Grace: LanguageModelsMeet Code Edits ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
1usingSystem;
2usingSystem.Linq;
3usingSystem.Text; ...
250catch(Exception )
251 ...
(a)Version /u1D46311usingSystem;
2usingSystem.Linq;
3usingSystem.Text; ...
250- catch (Exception)
250+ catch (SerializationException)
(b) Version /u1D4632withassociatededit /u1D6FF1,21usingSystem;
2usingSystem.Linq;
3+ using System.Runtime.Serialization;
4usingSystem.Text; ...
251 catch(SerializationException )
(c) Version /u1D4633withtargetedit /u1D6FF2,3
Figure1:Thedeveloperperformsedit /u1D6FF1,2togofromVersion /u1D4631oftheircodetoVersion /u1D4632.Thiseditservesasanassociatededit
that helpswith predictingtheedit /u1D6FF2,3needed to gofromVersion /u1D4632to/u1D4633.
Table 1:Comparisonofdiﬀerentapproacheson theexample fromFigure 1
Technique Prediction Correct?
c3po NoResponse (alieninsertion) ✗
overwatch NoResponse (nomatching pattern) ✗
code-davinci-edit-1 EmptyResponse ✗
codex-davinci withoutassociated edits usingSystem.Net.Http; ✗
CodeT5withoutassociated edits usingSystem.Threading ; ✗
codex-davinci withassociated edits(Ourapproach) usingSystem.Runtime.Serialization ; ✓
CodeT5withassociated edits(Ourapproach) usingSystem.Runtime.Serialization ; ✓
on Line 3 of Version /u1D4633.Our /f_irst key observation for improving pre-
dictionofcodeupdatesisthatitshouldbeconditionedonrelatededits
from the past. In the above scenario, we want to predict the update
to Version /u1D4632by also looking at the how Version /u1D4632was created
from Version /u1D4631. The edit /u1D6FF1,2is anassociated edit . In this example,
thereisjustoneassociatededit,butingeneraltherecanbemultiple
previous editspickedas associatededits.
Therehasbeensomerecentworkonpredictingcodechanges
conditioned on previous changes [ 10,68]. We now discuss how
theseapproachesworkontheillustrativeexample.Table 1shows
the predictions ofvarioustechniques onthe target.
c3po:c3poisapath-basededitpredictionmethodthatgenerates
an edit script to predict subsequent edits. It uses a pointer network
to pick valid target edits at /u1D4632by attending to /u1D6FF1,2, represented
asaneditpathintheAST.Asthesetargeteditscanonlyreferto
nodesintheASTsat /u1D4632and/u1D6FF1,2,thepointernetworkdoesnothave
access to the Serialization token needed to be inserted on Line 3.
Therefore, c3powould/f_ilteroutabove-mentionedexampleinits
training and testing pipelines categorizing it as an ‘alien insertion’.
Whenc3po/f_inetunedonthe overwatch trainsetisusedtopredict
/u1D6FF2,3,itincorrectly suggestspickingan existing usingstatement.
overwatch :overwatch is a symbolic procedure that learns
(abstract syntax) tree transformation rules from example edit se-
quences in the training data, and then makes predictions by apply-
ing those rewrite rules. The above-mentioned example does not
match any of the ∼50patterns that the authors released in [ 68].
Thus, out of the box, overwatch would not be able to provide any
suggestion because of unavailability of a matching pattern for the
target edit in the example. Ifwe provide enough edit sequences
similar to “ /u1D6FF1,2followed by /u1D6FF2,3” as training data to overwatch ,
then it might learn a few edit patterns depending on the examples
itgetsandtheorderinwhichtheyaregeneralized.Theonlytwo
usefulpatternsthatcouldbelearnedwouldbeeither(1)“thesubsti-
tutionof ExceptionbySerializedException isfollowedbyimporting
theSystem.Runtime.Serialization namespace”,or(2)“thesubstitutionofException by aplaceholder Type is followed by importing a place-
holdernamespace .”Whilepattern(1)wouldreturnthecorrectre-
sponse,itisan“over/f_itpattern”thatdoesnotgeneralizetoother
changesinthesubstitutedtype.Pattern(2)istoogeneralandcannot
generateaconcrete suggestiondueto the unbound placeholder.
Using LLMs : The approaches discussed above cannot gener-
ate the right predictions either when the target requires a new
token(c3po)orwhenitcannotmatchanexistinglearnedpattern
(overwatch ). LLMs of Code have emerged as competitive code
completion tools that oﬀer generative capabilities. This leads to
our second key observation: LLMs can handle diverse editing sce-
nariosincludingthosethatinvolvegenerationofnewtokens. Wenow
discuss howthesemodels work onthe illustrative example.
LLMs without Associated Edits : First, let us consider how
a modern code completion tool (based on powerful LLMs) will
attempt to predict the new code at Line 3 of Version /u1D4633. Code
completion tools, like codex-davinci , look at the current snapshot
ofthe codetomakepredictions. In other words, thetool will look
at Version /u1D4632to predict Version /u1D4633. When we provide code from
version/u1D4632tocodex-davinci ,itcorrectlypredictsthatsomething
shouldbeimported,butitpredictsanincorrectnamespace.Ifwe
usecode-davinci-edit-1 , the editing variant of codex-davinci
thatallowsyoutoprovideinstructionsforediting,theprediction
continues to remainincorrect.
LLMs with Grace: Following our two key observations, we
presenttheedit /u1D6FF1,2tocodex-davinci ,alongwithLine3ofVersion
/u1D4632thatneeds tobeupdated.Now,themodel successfullypredicts
that the updated code would be Line 3 of Version /u1D4633. We discuss
the prompt designindetailinSection 4.2.
We foundthat this utility of associated edits for edit prediction
also extends to other models: a base CodeT5model /f_ine-tuned
to predict /u1D6FF2,3using/u1D4632incorrectly predicts System.Threadingwhile
the same model /f_ine-tuned to additionally use /u1D6FF1,2to make the
prediction getsthe import right.
Bybuildingacodechangepredictionmodeloveracodegener-
ation model, we are able to extend the scope of edit predictions.
Moreover,weareabletoalsoperformbetterthantheexistingworks
1485ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA P. Gupta, A.Khare, Y. Bajpai, S.Chakraborty, S.Gulwani, A.Kanade, A.Radhakrishna, G.Soares, andA.Tiwari
on the subset of the benchmarks that are in their scope. We dis-
cuss our quantitative performance on these benchmarks compared
toc3poandoverwatch in Sections 5.4 and 5.5 respectively. We
further present aqualitative analysisofthe results inSection 5.6.
3 ASSOCIATED CODE UPDATES
We de/f_ine the associated code update task in this section. The
associated code update task is inspired from the EditCompletion
task[10]andthe editlikelihoodprediction task[ 55].
Let/u1D4630,...,/u1D463/u1D45Bbe a sequence of versions of a source code /f_ile. An
edit/u1D6FF/u1D456,/u1D457is the diﬀerence between two versions, /u1D463/u1D456and/u1D463/u1D457. We view
/u1D6FF/u1D456,/u1D457as a function that returns /u1D463/u1D457on the input /u1D463/u1D456, i.e.,/u1D6FF/u1D456,/u1D457(/u1D463/u1D456)=/u1D463/u1D457.
Furthermore,an associatededit Δ/u1D456is/u1D6FF/u1D457,/u1D458,forsome 0≤/u1D457</u1D458</u1D45B.
Giventhe /u1D45Aassociatededits Δ1,Δ2,...,Δ/u1D45Aandtheversion /u1D463/u1D45B−1
along with locations /u1D43Fin/u1D463/u1D45B−1, theassociated code update task is
to predict version /u1D463/u1D45Bassuming only the locations /u1D43Fin/u1D463/u1D45B−1are
updated.We thus want to modelthe probability
/u1D443(/u1D463/u1D45B|/u1D43F,/u1D463/u1D45B−1,Δ1,Δ2,...,Δ/u1D45A)
We nextmakeafewremarks aboutthe problem formulationabove.
First, the/u1D45B−1versions/u1D4630,/u1D4631,...,/u1D463/u1D45B−2need not necessarily match
the history of the underlying source code /f_ile. The actual historical
versions can be diﬀerent, and in fact, in the formulation above, it is
notthecompleteversionsthemselves,buttheedits Δ/u1D456thatareused
in the prediction task. The only version that is important here is
the current version /u1D463/u1D45B−1. Furthermore, the set of /u1D45Apast edits need
not even be theexhaustive set of alltemporally consecutive edits;
they could be a subset of the edits that have been performed so far.
Hence,Δ/u1D456doesn’tnecessarily have to be /u1D6FF/u1D456−1,/u1D456.
Second, the edits are allowed to be spatially far away from each
otherandfromthetargetlocations /u1D43FinVersion /u1D463/u1D45B−1.Whileanedit
Δ/u1D456that modi/f_ies locations close to the targetlocations /u1D43Fis likely to
be useful to include in the set /u1D45Aof edits, edits farther away from /u1D43F
may also be relevant.We makesnoassumption onspatial locality
ofeditsincontrastto the EditCompletion taskin[ 10].
3.1 Assumptions aboutSub-Problems
Our problem formulation above abstracts away three important
andchallengingrelatedsub-problemsthatarecrucialtobuildan
end-to-end tool. These three sub-problems are: (1) edit localization,
(2)editgranularity,and(3)associatededitsidenti/f_ication.Theas-
sociatedcodeupdateproblemformulationassumesthatwehave
somesolution for thesethree relatedproblems.
EditLocalization :Theeditlocalizationproblemseeksto/f_ind
the locations /u1D43Fwhere the developer should make edits. How we
get these locations is dependent on the application. For example,
inan IDE, cursor locationisagoodindicator of where the devel-
oper wants to make changes. Another option is to build a model
that predictsthenext edit locationgivenpriorassociated edits. In
overwatch [68], locations werepicked based on whethercertain
learned patterns matched the code at those locations. The patterns
thatwerematchedagainstwereselectedconditionedonthepast
applicationsofassociatededitpatterns.
Edit Granularity : The edit granularity problem refers to the
issueofde/f_iningwhatconstitutesan“edit”.Weassumethatwehave
heuristicstode/f_inewhenalocalcodechangequali/f_iesasasingleedit. All changes between two versions that successfully parse can
beusedasade/f_initionofasingleedit,asinthework[ 46].Another
heuristic could be to combine all changes that occur within a small
spatialvicinityofeachother(inacommit)as asingleedit[ 10].
Associated Edits : The associated edits problem seeks to /f_ind
edits from the past history that would be most useful in predicting
changes at the given locations /u1D43Fin the current version /u1D463/u1D45Bof the
source code /f_ile. Edits that are spatially close to the target loca-
tions/u1D43Fare likely relevant [ 10]. Similarly, edits that are temporally
close – that is, edits that happened in the recent past – are also
likely candidates for being relevant. We can use some combina-
tion of temporal and spatial proximity to obtain a candidate set
ofrelevantedits[ 68].Forpredictingupdatesonatargetlocation,
the temporally-proximal edits can indicate the developer’s editing
intentandthespatially-proximaleditscanassistinprovidingmean-
ing to the target snippet. We can even further selectively choose
fromtheeditsinthespatio-temporalvicinityofthetargetlocations
usingtheapproachinarecentworkthatminesrelevanteditsbased
on their syntactic structure and their likelihood of occurring to-
gether [68]. We can use any or all of these approaches to construct
the set of relevant edits. Our goal is to show that even when the
relevanteditsare heuristically generated,usingthemforassociated
code updatepredictions can be very bene/f_icial.
3.2 Related ProblemFormulations
Existing auto-regressive LLMs, such as, gpt3andcodex, predict
completions for a given prompt. If the prompt contains the current
version/u1D463/u1D45B−1of the artifact, then these LLMs predict text that is
meant to be appended to /u1D463/u1D45B−1to generate the new version /u1D463/u1D45B.
These models rely on the text in the spatial vicinity of the change-
locations /u1D43Fto makepredictions. In our terminology,these models
aremodelingtheprobability /u1D443(/u1D463/u1D45B|/u1D463/u1D45B−1).This isclearlydiﬀerent
from the problem we are considering. We demonstrate that the
associated code update formulation yields a simple yet eﬀective
wayofimprovingLLMperformanceonsoftwaredevelopmenttasks.
The EditCompletion task in [ 10] is formalized as a study of
/u1D443(/u1D6FF2,3|/u1D43F,/u1D4632,/u1D6FF0,1,/u1D6FF1,2)where the two given edits are edits per-
formed in the spatial vicinity of the current location, one before
andoneafterthecurrentlocation.TheEditCompletiontaskdoes
not consider relevant edits that may be spatially distant. Our prob-
lem formulation is a generalization of EditCompletion problem,
and in fact, we use the benchmarks from [ 10] for evaluation. As
discussedinthe introduction, our approachesare diﬀerenttoo.
The edit likelihood prediction problem [ 55] explicitly consid-
ers the study of /u1D443(/u1D463/u1D45B|/u1D4630,/u1D4631,...,/u1D463/u1D45B−1), but it uses /u1D443(/u1D6FF/u1D45B−1,/u1D45B|
/u1D4630,/u1D4631,...,/u1D463/u1D45B−1)asa waytoestimate the former. This problemdif-
fers from the associated code update problem in two ways: /f_irst, it
includes the sub-problem of /f_inding the locations /u1D43Fthat need to be
edited as part of the larger problem, and second, it considers the
entire edit history as an ordered sequence (in an auto-regressive
way) whereas we focusonasmall setof associatededits.
4 EXPLOITING ASSOCIATED EDITS
Wepropose Grace,atechniquetousepre-trainedlanguagemodels
for solving the associated code update problem. There are two
possible ways of using these models to perform the associated
1486Grace: LanguageModelsMeet Code Edits ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
codeupdatetask.One approachisbasedonusing themodels asa
black-box,butwithcarefullydesignedprompts(Section 4.2).This
promptingstrategyworksforbigLLMs,suchas gpt3andcodex.
Thesecondapproachisbasedon/f_ine-tuningapretrainedlanguage
model,CodeT5in our case, for our speci/f_ic associated code update
task(Section 4.3).
4.1 Pre-trainedLanguage Models
There is now a large collection of pre-trained language models.
These models are pre-trained on data collected from millions of
webpages, and treat all data as a sequence of tokens, which is
the natural choice for representing natural language text [ 50,52,
53]. The reason for the popularity of this class of models is that
they exhibit ability to perform multiple diﬀerent tasks with just
some instructions and zero examples (zero-shot task transfer) even
though they are not explicitly trainedfor thesetasks.
It was observed that pre-trained LLMs are not as eﬀective when
workingwithcodebecausecodehasstrictsyntacticandsemantic
correctnessrequirements.Diﬀerentrepresentationsforcodeand
codeeditshavebeendevelopedandmodelshavebeentrainedto
work with those representations [ 5,10]. However, as the size of
pretrainedlanguagemodelshasgrown,theirzero-shotperformance
acrosstaskshasimproved.Moreover,thesemodelshavealsoshown
theabilitytoperformanewtaskgivenjustafewdemonstrations
intheprompt(few-shotlearning)[ 11].Usingtheirzero-shotand
few-shot learning capabilities, these models are now being used
successfully on tasks that involve understanding, manipulating, or
generating code [ 16,28,63] while still viewing code just as text
(andnot as an abstract syntax tree,for example).
4.2 Prompting LLMs
We experimented with a few diﬀerent prompt designs and then
/f_ixedoneforourexperiments.(Theresultswerenotsigni/f_icantly
diﬀerent for other reasonable prompt designs.) Before we describe
theGraceprompt, we /f_irst describe the completion, insertion, and
editing variants ofthe codexfamily ofmodels [ 8,16].
Thecodexfamily of models is available in the “completion”,
“insertion” and “editing” variants. The completion model takes a
prompt,whichusually contains codebefore acursorlocation, and
predicts the code that will follow that prompt. Apart from the
prompt, the insertion model also takes a suﬃxprompt, which usu-
allycontainsthepartofcodethatshouldcome afterthecodethe
model predicts. Thus, the insertion models perform the in/f_illing
task-predictthecodethatshouldcomeafterthepromptbutbefore
the suﬃx. Finally, the editing variant of the codex models has two
diﬀerent input prompts: an inputthat is the string that needs to be
edited, and an instruction that tells the model how to edit the input.
We treat the associated code update task as an in/f_illing prob-
lem and hence use the codex insert family of models for our
experiments. The reasons for this choiceare as follows:
(1)Theinsertionmodelallowsustoincludecodethatisspatially
after the target location inthe suﬃx.
(2)The editing variant ( code-davinci-edit-1 ) requires instruction
onhowtoeditthegivenpieceofcode.Ourexperimentswith
providing the associated edits in this instruction prompt failed
to generate good results. This is possible because the editing1<CurrentEdit >
2 <Prefix> . . . </ Prefix>
3 <Before> . . . </ Before>
4 <After> . . . </ After>
5 <Suffix> . . . </ Suffix>
6</CurrentEdit >
7<CtxEdits >
8 <Edit>
9 <Prefix> . . . </ Prefix>
10 <Before> . . . </ Before>
11 <After> . . . </ After>
12 <Suffix> . . . </ Suffix>
13 </Edit>
14 <Edit>...</Edit>
15 . . .
16</CtxEdits >
Figure 2: GracePrompt for the associated code update task.
model is better suited only for instructions given in natural
language1.
Figure2showsthe Gracepromptweprovided codexmodels
fortheassociatedcodeupdatetask.Let /u1D463/u1D45B−1bethecurrentversion
of the/f_ile, /u1D43Fbe thelocations where code needs to be updated, and
/u1D6FF0,1,/u1D6FF1,2,...,/u1D6FF/u1D45B−2,/u1D45B−1bethe/u1D45B−1associatededits.Weassumethat
eachedit /u1D6FF/u1D456−1,/u1D456canbepartitionedinfourparts:(1) <Prefix>,which
contains the fragment of code in version /u1D463/u1D456−1that is untouched
bytheedit,butoccursbeforetheeditedcode,(2) <Before>,which
contains the fragment of code in version /u1D463/u1D456−1at locations /u1D43Fthat
is replaced by the edit, (3) <After>, which contains the fragment
of code in version /u1D463/u1D456at locations /u1D43Fin place of beforein/u1D463/u1D456−1, (4)
<Suffix>, which contains the fragment of code in version /u1D463/u1D4561that is
untouched by the edit, but occurs after the edited code. These four
parts are included in the prompt for each edit as shown in Figure 2.
The associated edits are all included within the <CtxEdits >tag. The
editto be predictedisincludedinside the <CurrentEdit >tag.
In this prompt format, the current edit is written out /f_irst fol-
lowed by the associated edits. This style ensures that if the prompt
gets bigger than what can /f_it in the input to the model, the to-
kensfromtheassociatededitsarepruned.Wealsoexperimented
with variants where certain associated edits were placed before
the current edit and some after depending on where they occurred
spatially.Mostsuchchangesdidnotcauseanysigni/f_icantchange
inour experimental observations.
Theinsertionmodelisexpectedtopredictthestringthatshould
occur between <After>and</After>that occurs under <CurrentEdit >.
The pre/f_ix of the prompt string up until <After>goes in the prompt,
andthesuﬃxofthepromptstringstartingfrom </After>isincluded
inthe suﬃxprompt ofthe insertionmodel.
The prompt design above is reminiscent of few-shot learning
prompts where the prompt contains afewexamplesof the taskto
beperformed.Technicallyspeaking,theabovepromptisnotafew-
shotpromptsincewearenotprovidingoneormoreexamplesofthe
“associatedcodeupdate task”.However,ifwe viewtheassociated
code update problem as a means of providing few-shot examples for
the“codeupdatetask” ,thenanaturalquestioniswhetherassociated
edit update task can just be viewed as a few-shot prompting for
code updatetask.We answer this questioninSection 5.
One of the central goals of the paper is to /f_ind how using associ-
atededitscompareswithnotusingitwhenpredictingcodeupdates.
To enable this comparison, we need a prompt for the case when
1Wedo not include code-davinci-edit-1 in ourexperiments
1487ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA P. Gupta, A.Khare, Y. Bajpai, S.Chakraborty, S.Gulwani, A.Kanade, A.Radhakrishna, G.Soares, andA.Tiwari
1<CurrentEdit >
2 <Prefix> . . . </ Prefix>
3 <Before> . . . </ Before>
4 <After> . . . </ After>
5 <Suffix> . . . </ Suffix>
6</CurrentEdit >
Figure 3:Promptwhenassociated edits are notused.
Table 2:The models used inour experiments.
Name BaseModel Fine-tuned on
codex-davinci code-davinci-002 -
codeT5-u CodeT5-base un/f_iltered c3potrain
codeT5-uf codeT5-u /f_ilteredc3potrain
codeT5-uo codeT5-u overwatch train
associatededitsareunavailable.Here,weusethepromptshownin
Figure3. Speci/f_ically, we remove the <CtxEdits >section in Figure 2.
Note that the current code context is still available to the model in
the<Prefix>and<Suffix>tags within <CurrentEdit >.
4.3 Fine-tuningLLMs
Wenowdescribehowwecreate/f_ine-tunedmodelsforpredicting
codeupdates withandwithout associatededits.Westartedwiththe
CodeT5-basemodel [39,63], a pre-trained encoder-decoder Trans-
formermodel.ThisbasemodelwastrainedonCodeSearchNet[ 33]
thatcontainssourcecodein6commonprogramminglanguages,
extended with two additional C/C# datasets from BigQuery [ 29].
We further /f_ine-tuned several variants of this model on the task of
predictingcodeedits(seeTable 2).There aretwoversions ofeach
variant–onethatis/f_ine-tunedusingthegivenassociatededitsand
onethatonlyusesthecurrentversionofthecode.Thetwotypes
of /f_ine-tuning use the same dataset and base model weights, the
only diﬀerence being how the data was prepared. The variants are
discussedindetailinSection 5.1.
We prepare data for /f_ine-tuning by turning each train-
ing example into the Graceprompt, as shown in Fig-
ure2. We adapt the CodeT5 tokenizer by adding spe-
cialtokens: <Prefix>, </Prefix>, <Suffix>, </Suffix>, <CurrentEdit >,
</CurrentEdit >, <CtxEdit>, </CtxEdit>, <Edit>
</Edit>, <After>, </After>, <Before>, </Before>. We formulate the
training as a masked span prediction task where we replace the
contents between <After>and</After>under<CurrentEdit >with a
sentineltoken andask the modelto predict the maskedspan.
When /f_ine-tuning CodeT5to predict code update without using
associatededits ,weusethepromptshowninFigure 3.Again,we
formulatethetrainingasamaskedspanpredictiontaskreplacing
the contents between <After>and</After>under<CurrentEdit >with
a sentinel token and asking the model to predict the masked span.
4.4 Deployment
We now discuss how the sub-problems discussed in Section 3.1can
potentially be solved and integrated with our approach to create
an IDE-basededitprediction tool:
Setup:As discussed in Section 3.1, the editing target could be
thelinecorrespondingtotheuser’scursorlocation. overwatch
can be used to extract temporal edits from patterns that match the
target location andtheseeditscan serve as our associatededits.Table 3:The datasetsused for/f_ine-tuningand testing.
Dataset #training #eval#test
c3po/f_iltered 39.5K 4.4K5.9K
c3poun/f_iltered 1.67M 180K210K
overwatch 9K1k1K
Worklow: Consider a user editing code in an IDE. The tool will
get triggered on the line where the user’s cursor resides and the
associated edits would be retrieved using overwatch . Our edit
predictionpromptwillbegeneratedasdiscussedinSection 4.2.The
promptwillthenbesentasaninputtoanLLM(say, codex-davinci )
andthepredictededit(ortop-kpredictededits)willbesuggestedto
the user. We have designed an interactive tutorial to walk readers
through this work/f_low using the various examples discussed in
Section2andSection 5.6(see Section 9for instructions).
5 EXPERIMENTS & RESULTS
5.1 ExperimentalSetup
Weusetwodatasetsfrompriorworkforourexperiments,the c3po
dataset [10]andthe overwatch dataset [68];see Table 3.
c3poDataset: Thec3podataset [10] was created by scraping
allcommitsin53mostpopularC#GitHubrepositories.Eachedit
in a commit would create a single example, and the edits, if any,
onthe10linesaboveand10linesbelowtheeditwouldmakeup
the associatededits. The taskis to predict the code after an editis
performed,giventhecodebefore theeditand theassociatededits.
Thus, the c3podataset is an instance of the associated code update
task,where spatiallocality isusedtode/f_ineassociationsbetween
edits.Notethatthe c3popaperreferstotheseeditsas contextual
editswhichtranslate to edits withspatial associations inour work.
Thec3podataset was further /f_iltered by its creators into a /f_il-
teredc3podatasetby removing “simple” benchmarks (e.g. those
containingonlydeletionorrenaming).Further,theyremovedall
benchmarkswherethetargeteditinvolvedinsertionof newcode
as their approach cannot handle those. The /f_iltered set was further
partitioned into train, validation, and test benchmarks, containing
respectively39.5K,4.4K,and5.9Kbenchmarks;seeTable 3.Weused
the same partitionsinour evaluation.
overwatch Dataset: The dataset describedin [ 68]was gath-
ered from versions of source code /f_iles taken as they were being
edited in an IDE session over two separate periods. In the /f_irst
period, 134.5K versions were collected over 682 sessions. In the
second period, 201.1K versions were collected over 399 sessions.
Theversionsinthe/f_irstperiodwereminedin[ 68]togetasetof
9.9Kedit sequences which are further used to learn a collection of
symbolic rules representing commonly occurring Edit Sequence
Patterns.Theselearnedrulesareusedtogeneratecodesuggestions
inthesecondperiod,andtheyarefoundtobecapableofproducing
suggestions at 1048/f_ileversions.For the purposeof thiswork,we
areconsidering90%ofthe 9.9Keditsequencesfromthe/f_irstperiod
astheoverwatch trainingset,keepingother10%asthe overwatch
evaluation set;andthepointsofapplicationsasthe overwatch test
set.We discuss thesedatasets further inSection 5.5.
Models: We used two models as starting points. The /f_irst is
code-davinci-002 (referred to as codex-davinci in this text), a
1488Grace: LanguageModelsMeet Code Edits ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
decoder-onlytransformermodelwhichisapartofthe OpenAIgpt-
3.5series[8,16].Thismodelispresentedwiththepromptsbased
on either Figure 2or Figure 3depending if we want to use use
associatededitsforeditprediction.Thesecondmodelis CodeT5
[39,63], an encoder-decoder model introduced by Salesforce in the
baseandlargeVariants. We use the CodeT5-base variant which
has220Mparameterswith12transformerblocksintheencoderand
decodereach.Thismodelis/f_ine-tunedontheun/f_iltered c3potrain-
ing datasetto create the model codeT5-u .Themodel codeT5-u is
further /f_ine-tuned on the c3po/f_iltered train set and overwatch
train set to create codeT5-uf andcodeT5-uo , respectively; see
Table2. We used this two step /f_ine-tuning process since the over-
watchtraining data was limited. The /f_ine-tuning and inference
setupsfor thesemodels are describedbelow.
Setupfor codex-davinci Experiments :Weusedthe OpenAI
publicAPItoperformtheinferenceexperimentswiththe codex-
davincimodel.The insertmodeofthemodelwasusedandthe
input was divided into promptandsuﬃxfollowing our prompting
strategydiscussedinSection 4.2.Temperaturesamplingwasused
to generate n=5 predictions, and the temperature was set to 0.1
afterevaluatingmultiplecandidatevalues.Themaximumlength
(maximumnumberoftokenstogenerate)wassetto256,stoptoken
to</After>anddefaultvalueswere usedfor allotherparameters.
Setup for CodeT5 Experiments : For our /f_ine-tuning experi-
ments,weuseavirtualmachine with16AMDMI200GPUs(each
with64GiBofvRAM),92CPUcoresand1594GBofRAM.Wesetthe
inputtokenlengthto1024tokensandtruncateanylongerinputs
fromtheend.There aretwosteps inour/f_ine-tuningprocess:/f_ine-
tuning on the un/f_iltered c3podataset followed by dataset-speci/f_ic
/f_ine-tuningonthe overwatch training and c3po/f_iltereddatasets.
Fortheinitial /f_ine-tuningwiththeun/f_iltered c3podataset,weini-
tialize the model with the publicly released CodeT5-baseweights
and train it for 8 epochs with a batch size of 8 per device. The
optimization is done using the Adafactor[ 59] optimizer with learn-
ingrateinitiallysetto 3/u1D452−4andgraduallyupdatedusingalinear
scheduler after a warmup of 500 steps. The best model weights are
determinedusingtheperplexityscorebyevaluatingonthe c3po
validationdatasetatevery1000steps.Forfurther/f_ine-tuningonthe
overwatch trainingand c3po/f_iltereddatasets,wesettheinitial
learning rate to 1/u1D452−4, the number of warmup steps to 50 and train
the model for 10 epochs while evaluating it every 50 steps. During
inference,we use beam searchwithabeam widthof5.
Metric: In order to stay consistent with the metrics used by
papers that curated the target datasets (namely the c3poandover-
watchdatasets),wede/f_ineametriccalledthe exactmatch .Inthe
experiments with the c3podataset, a prediction is said to be an
exact match if it syntactically matches the ground truth modulo
whitespaces. We use ExactMatch to alsodenotethe percentage of
caseswhereapredictionwasanexactmatch.Moredetailsonthe
overwatch datasetevaluationcanbefoundinSection 5.5.Inall
our results, we report ExactMatch for Top-1predictions.
5.2GraceImprovesPrediction
A key question we set out to answer was whether associated edits
helppredict future code changes.In otherwords:
RQ1. Does availability of associated edits improve code update
predictions?Doestheanswerdependonthepredictionapproach?Table 4:Associated edits improve codeprediction.
c3potestset overwatch testset
ModelWithout
assoc.editsWith
assoc.edits
(Grace)Without
assoc.editsWith
assoc.edits
(Grace)
codex-davinci 37.09 67.92 31.81 49.09
codeT5-u 64.52 74.16 22.25 34.00
codeT5-uf 73.46 81.83 40.78 48.23
Toanswerthisquestion,wetestedboth codex-davinci andCodeT5
onboththe c3poandoverwatch testsets,oncewithassociated
editsinthe prompt andoncewithoutthem.
Results:Table4showstheExactMatch obtained when we use
the diﬀerent models on the diﬀerent datasets with and without
associated edits. We see that codex-davinci shows a 30% absolute
increaseinExactMatchwhenprovidedassociatededitsthanwhen
not on the c3podataset, and about 17% absolute increase on the
overwatch dataset. The /f_ine-tuned CodeT5models showed about
a 10% absolute increase in Exact Match on both datasets. Finally,
althoughTable 4reports thetrendfor2 modelsand oneprompting
style, we tried other models (including other OpenAImodels from
gpt3andgpt-3.5series)anddiﬀerentstylingoftheprompts(for
example, using C# comments, rather than tags, to delineate the
“before” and “after”versions),andin every case,there was atleast
a 10% absolute increase in Exact Match – often it was much higher.
Result1:Conditioningcodepredictiononassociatededitshelps,
acrossmodelsand test datasets.
5.3 RelevanceofEditsMatters
The associated code update problem conditions code prediction
onsomeassociated edits.Wehaveinformallymentionedthatthe
associatededitsshouldbepickedbasedontheirrelevancetothe
codethatisbeingupdated.Ournextresearchquestionisconcerned
withhowrelevanceimpacts prediction.
Tomotivatethisresearchquestion,we/f_irstmaketheconnection
to“few-shotprompting”.Considerjustthe codeupdatetask –predict
the new version of the code given its old version. The diﬀerence
betweenthe “codeupdatetask”and “associatedcodeupdatetask”
aretheassociatededits.Now,apromptcontaininganinstanceof
the“associatedcodeupdate”taskbeginstolookalotsimilartoa
few-shot prompt for a code update task where the associated edits
serve the purpose offew-shotexamples of code update.
It may be tempting to say that the “associated code update” task
just combines some few-shot examples with a code update task.
However,thisviewisnotbene/f_icialsinceassociatededitsaremore
thanjust anyexamplesofcodeupdates .AsdiscussedinSection 2,
the associated edits contain crucial information for performing the
given code update. To validate that associated edits are more than
justcode updateexamples, we turnto our nextresearch question:
RQ2.Areassociatededitsimportantforcodeupdateprediction,
or simply serveasfew-shot examples for thecodeupdatetask?
Inotherwords,istheresomethingtobegainedbyusingasso-
ciated edits beyond what we gain by just adding some few-shot
examples ofcode updates(that are not necessarily associated)?
Results:Table5showsthe ExactMatch wegetusingthe codex-
davincimodelusingdiﬀerentsetsofeditsasthe“associatededits”.
1489ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA P. Gupta, A.Khare, Y. Bajpai, S.Chakraborty, S.Gulwani, A.Kanade, A.Radhakrishna, G.Soares, andA.Tiwari
Table 5: Less relevant edits degrade prediction: codex-
davinci on/f_iltered c3potestsetfordiﬀerentassociatededits.
ChoiceofAssociated Edits Exact Match
Association Dataset Repository
Spatial Filtered Same 67.92
Random Filtered Same 64.90
Random Filtered Other 55.82
Random Un/f_iltered Same 43.23
Random Un/f_iltered Other 43.64
NoAssociated Edits 37.09
Weusethe c3po/f_ilteredtestsetagainforevaluation.Wesawbefore
thatwegeta 67.92%ExactMatchonthistestset(Table 4).Thiscase
corresponds to when the prompt includes spatially close /f_iltered
editsfromthesame/f_ile(thisisapropertyofthe c3pobenchmarks).
Let us now randomly sample edits to include in the prompt. There
are twodimensions andtwobuckets ineachdimension touse for
sampling:the/f_iltereddatasetversustheun/f_iltereddataset,andedits
fromthesamerepositoryversuseditsfromdiﬀerentrepositories.
Randomlypicking/f_ilterededitsfromthesamerepodropsperfor-
manceonlyslightly.However,randomlypicking/f_ilterededitsfrom
other repos drops performance more signi/f_icantly to 55.82%. When
samplingfromun/f_ilterededits-irrespectiveofwhethereditsare
from the same or diﬀerent repos - the Exact Match remains consis-
tentlyaround 43%.Werecallthatwhenweprovidenoassociated
editsinthe prompt,we had 37.09%ExactMatch (Table 4).
The results show that going from /f_iltered to un/f_iltered edits
reduces relevance of edits to the target /f_iltered edit . This is because
the /f_iltering stepin [ 10] actually removes certain kinds of edits; for
example, edits that are pure insertions or deletions, or edits that
result in unparseable code. Hence, a randomly picked un/f_iltered
editis morelikelytobe structurallydiﬀerent fromourtarget edit
(whichwaspickedfrom the /f_ilteredtest set.)
The results also show that pickingedits from repositories other
than the repositoryof the target edit reduces relevance of the edit
to the target edit. This is because edits from the same repository
could potentially be using common concepts, classes, methods,
programmingpractices,andeven contain similar changes.
Finally, we note that using un/f_iltered edits from other reposi-
tories(43.64%)isstillbetterthannotusingthem( 37.09%).Thisis
possiblyduetotheLLMleveragingits few-shotlearningcapabilities
in that case. The gain from around 43%to around 68%can thus be
attributed to the associated edits. We can, therefore, conclude that:
Result2:Associatededitsplayacrucialroleinpredictingatarget
edit,andtheExactMatchmetricdropsastherelevanceoftheedits
to thetargeteditdrops.
5.4 Pre-trainedOutperforms Custom
When working with code and code edits, LLMs (such as codex
andgpt3)andotherpre-trainedmodels(suchas CodeT5)usebyte-
pairencodings(BPE)totokenizecodeandthenrepresentcodeas
a sequence of tokens – in the same way as Natural Language is
represented. In contrast, some works have argued for the use of
custom representations for code and code edits that partly capture
theparsestructureand/ortheprogramminglanguagesemantics.
Thepaperthatintroducedthe c3podataset[10]alsousedthespatialTable 6:Comparisonwith c3po.
Exact Match on
Model c3pooverwatch
c3po 53.20 10.50
codex-davinci 67.92 49.09
codeT5-u 74.16 34.00
codeT5-uf /codeT5-uo 81.83 48.23
editsusedbyourpre-trainedLLMsbuttheylearnedacustommodel
employing code-centric representations for code edits. Our next
research question concerns comparing our approach based on pre-
trainedmodelswithpriorworkoncustomneuralapproaches.While
both the approaches have access to the associated spatial edits, we
wantto understandhowpre-trained modelswiththeir text-based
promptscompareagainstmodelswithcustomcoderepresentations.
RQ3. How does our LLM-based approach compare with the c3po
approach based on a custom neural model on the associated code
updatetask?
Let us compare how the c3pocustom neural model performs
in comparison to codex-davinci and /f_ine-tuned CodeT5. We /f_irst
compare these models on the /f_iltered c3potest set and the over-
watchtestset.Table 6showsthatboth codex-davinci and/f_ine-
tunedCodeT5signi/f_icantly outperform the custom c3pomodel on
both test datasets. The c3pomodel was reported to give a 53.2%
accuracy [ 10] on thec3potest set, whereas both codex-davinci
and/f_ine-tuned CodeT5give betterresults.The codeT5-uf model
gives81.83%Exact Match, which is signi/f_icantly higher than 53.2%
achieved by the c3pomodel. Similarly, on the overwatch dataset,
the best possible con/f_iguration of c3powas reported to give 10.5%
ExactMatch[ 68],whereasallof codex-davinci (49.09%),codeT5-u
(34%), andcodeT5-uo (48.23%) perform signi/f_icantly better.
Comparison on Un/f_iltered c3poTest Set: Thec3pomodel
doesnotreportresultsontheun/f_iltered c3podataset.Thisispartly
because it contains benchmarks that are out of scope for their
technique. Two such notable benchmarks are: (a) benchmarks that
containalieninsertions wheretheinsertedcodecontainstokensthat
do not occur in either the associated edits or the current version
ofthetargetcodesnippet,and(b)benchmarksthatcontaincode
snippetsthatcannotbeparsedbyanunderlyingparser(thisstep
isimportant for c3poto generate theAbstract Syntax Tree (AST)).
Gracecan handle both these classes of benchmarks. We evaluated
codex-davinci on a 5.9K random sample from this test set and
obtaineda43.47%ExactMatch.These5.9Ksamplesdidnotcontain
anybenchmarksfromthe/f_ilteredset.(Weusedasamplebecause
ofthecostofdoinginferencesusinganLLM.)Onthe fullun/f_iltered
c3potestset,codeT5-u has57.3%ExactMatchusing Graceand
45.30%without.Thesenumbersarelowerthanthoseforthe/f_iltered
c3potest set. This indicates that the un/f_iltered benchmarks are
more challenging than the /f_iltered benchmarks, which is at odds
withthe informal assertions to the contrary in[ 10].
AlienInsertionBenchmarks :Weextractedthesamplesfrom
un/f_iltered c3potestset thatinvolved alieninsertions.Onthatset,
codeT5-u withGraceachieved17.6%exactmatch,butonly10.28%
without it.The codex-davinci model achieved17.37%exact match
withGraceand 10.67% without it. This indicates that conditioning
onassociatededitscan helpwithhardbenchmarks.
1490Grace: LanguageModelsMeet Code Edits ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
Table 7:Comparisonwith overwatch .
Technique overwatchCodex-
DavincicodeT5-u codeT5-uo
Exact Match 38.17 49.09 34.00 48.23
Admittedly, the c3pomodel is much smaller (750K parameters)
comparedtoboth codex-davinci (175B)and CodeT5(220M).How-
ever, these large models are pre-trained and hence they can be
quickly /f_ine-tuned or prompt engineered for downstream tasks
without need for excessive training data. Furthermore, the pre-
trainedmodelsarenotlimitedinscope,aswehavediscussedabove.
Result3:Pre-trainedlanguagemodelscanbetunedtoyieldhigher
Exact Match compared to the custom c3pomodel for associated
code updateprediction.
5.5 TemporalEditPrediction
The temporal edit prediction problem is an application that is well-
suited for using Grace. The state of the art in this application
domain is overwatch [68]. Fundamentally, overwatch is solving
adiﬀerentproblemfromtheassociatededitspredictionproblem:
the input to overwatch are/f_ine-grained IDE version histories of
the form /u1D4630,...,/u1D463/u1D45Bwhere each /u1D463/u1D456is a version of the source code
/f_ile. The edit histories are extremely /f_ine-grained, at the keystroke
unlike source control histories. For example, if a developer types a
variablename predicate ,eachintermediate/f_ileversioncontaining
the pre/f_ixes p,pr,...ispresent inthe edithistory.
Theoverwatch technique takes the set of such IDE version
historiesas atraining set,andproduces arankedsequenceofedit
sequence patterns (ESPs). At inference or run-time in an IDE, each
ESPexaminesthecurrentversionhistory /u1D4630,...,/u1D463/u1D45Band(a)identi/f_ies
asequenceoftransitivecoarse-grainededits /u1D6FF/u1D4560,/u1D4561,/u1D6FF/u1D4561,/u1D4562,...,/u1D6FF/u1D456/u1D458−1,/u1D456/u1D458
(i.e., each /u1D6FF/u1D4560,/u1D456/u1D458is the edit between the potentially non-consecutive
versions/u1D463/u1D456/u1D457and/u1D463/u1D456/u1D457+1),and(b)usestheseeditstopredictthenext
edit to/u1D463/u1D456/u1D458. In short, the ESPs are doing two tasks: (a) identifying
“associated edits” from /f_ine-grained version histories, and (b) using
theseassociatededitsto predict the nextedit.
RQ4.CanourLLMbasedapproachbeusedinconjunctionwith
overwatch ’stemporalassociatededitidenti/f_ication?Howdoesit
comparewith overwatch ’ssymboliceditpredictioncomponent?
The second task above is exactly the prediction from associated
editsproblemwearetacklinginthispaper.Hence,werun over-
watchonitstestdataof 399versionhistorieswithover 200,000
versions,andgathertheassociatededitswherevertheESPsareable
toidentifythem.Thisresultsinadatasetof1048casesasmentioned
in Section 5.1. At training time, overwatch identi/f_ies a set of 9.9K
editsequencesfromtheolderdataof 682versionhistories,however
usingdiﬀerenttechniques.Theeditsequencesaresuchthateach
ofthembelongtosomecommonlyoccurringeditsequencepattern
acrossversionhistories–theyarethesupportsforESPs–andthus
each of them canbe treatedas aset of associatededits (alledits in
the sequence but the last), and expected edit prediction (last edit in
thesequence).Weusethissetof9.9Kinstancestofurther/f_ine-tune
codeT5-u to obtain codeT5-uo ; see Table 2.
Table7summarizes the diﬀerent models’ performance on the
1048test cases, along with overwatch ’s predictionsasa baseline.1catch(Exception ex )
2{
3- info.ReportClientError( 'Scheme is missing ');
4+ info.ReportClientError( 'Scheme is missing ',System.Net.
HttpStatusCode.BadRequest);
5}
6default :
7- info.ReportClientError( 'No such action ');
8+ info.ReportClientError( 'No such action ',System.Net.
HttpStatusCode.NotFound);
Figure4:Useradds BadRequesterrorcodeonLine3andmoves
to Line5 where we should predictinserting NotFound.
ExceptcodeT5-u , all of our models beat the prediction component
ofoverwatch byaconsiderablemarginofroughly10%.
Result4:OurLLM-basedtechniques,inconjunctionwithsystems
likeoverwatch createsneuro-symbolicsolutionsthatarebetter
at predicting next editcompared to purely symbolictechniques.
5.6 QualitativeAnalysis
Our experiments support two major observations: (a) LLMs can
predicteditsthatexistingtechniquesfundamentallycannotsupport,
and(b)theadditionofassociatededitsimprovestheperformanceof
LLMsonthetaskofpredictingcodeedits.Next,weprovideinsights
intowhy theseobservations holdtrue.
5.6.1Comparison with existing techniques. In the following
few paragraphs, we discuss the salient features of LLMs and the
Gracepromptdesignthathelpourapproachoutperformexisting
techniques,i.e., c3poandoverwatch oncertainkindsof edits.
GenerativeCapabilitiesofLLMsareUsefulinPredicting
AlienInsertions :Asdiscussed in Section 2, theLLMswe discuss
in this paper can support most forms of insertions as they have
accesstoawidenumberoftokensthroughtheirpre-trainingand
ourpromptingsetupdoesn’trestrictthetokensthatthemodelscan
generate.Existingtechniquesarerestrictedinthisaspectbydesign:
c3pocannot insert tokens other than those found in the contextual
editsandOverwatchmaylearnpatternswherethepredictiontemplate
is incomplete due to unavailable mappings for holes in the Temporal
EditPattern. Forinstance,considerthescenarioinFigure 4wherea
developeristryingtoaddHTTPerrorcodestoerrorreportingcalls.
Here, the developer /f_irst edits Line 3 by adding a BadRequest error
code to the reporting call. They then move to Line 5 to make a
similaredit.NotethattheexpectederrorcodeonLine5isdiﬀerent
fromtheoneonLine3asitcorrespondstoa“Nosuchaction”error
message.Moreover,theexpectederrorcodehasatoken‘NotFound’
whichisnotpresentanywhereintheexistingcontext.AsC3PO’s
pointer network can only pick paths to/from existing nodes, it
cannotgeneratethisnewtoken. codex-davinci withGracecan
correctlypredict this edit.
Access to Local Spatial Context in the Prompt is Useful :
overwatch learnspatternsandtemplatesfromobservededitse-
quencesandstrictlyreliesonthesepatternstomakepredictions.
There are cases, however, where the pattern learnt by overwatch
istoogeneralandisapplicableirrespectiveofwhatisinthespatial
vicinity of the target edit. To better understand this limitation, con-
sider the scenario in Figure 5from an active IDE editing session.
Theuser/f_irstreplaces exonLine5with ex.Outputandthenmoves
toLine3tomakethenextedit.OverwatchgetstriggeredonLine3
1491ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA P. Gupta, A.Khare, Y. Bajpai, S.Chakraborty, S.Gulwani, A.Kanade, A.Radhakrishna, G.Soares, andA.Tiwari
1foreach (varexincurrentExamples )
2{
3- Console.WriteLine(GetText(ex, diff.BeforeFile));
4+ Console.WriteLine(GetText(ex.Input, diff.BeforeFile ));
5- Console.WriteLine(GetText(ex, diff.AfterFile));
6+ Console.WriteLine(GetText(ex.Output, diff.AfterFile ));
7}
8varoutput =Run(currentExamples .First().Input);
9AssertEqual (currentExamples .First().Output,output);
Figure5:Userreplaces exonLine5by ex.Output,movestoLine3
where we should predictreplacing exbyex.Input.
andpredictsthat exshouldbereplacedby ex.Outputsinceitlearns
the pattern “repeat the same replacement”, which is an instance of
a common pattern. However, this is incorrect since exshould be
replaced by ex.Inputhere.codex-davinci , withGrace, correctly
predictsthiseditbecause exonLine3isfollowedby diff.BeforeFile
andLine8hasadditionalinformationabouttheproperty Inputthat
is associated with each entry in ‘currentExamples’. Our prompt
design allows /f_lexible addition of this additional spatial context
throughthe <Prefix>and<Suffix>tags.overwatch ,ontheother
hand,cannotaccessspatialcontextthatisnotalreadypresentin
the learnedtemplate.
Language Based Pre-training is Useful in Identifying Se-
manticEditing Pa/t_terns :Scenarios inFigures 4and5alsohigh-
light the ability of LLMs to predict patterns based on semantics
ofidenti/f_iersinthecontext.InFigure 5,codex-davinci seemsto
understand that the relationship between diff.AfterFileanddiff.
BeforeFile wouldalsore/f_lectintheprecedingargument( ex.Output
andex.Input, respectively). In Figure 4,codex-davinci uses the
signalfrom the 'No such action 'errormessageto correctlypredict
thattheerrorcodeshouldbe System.Net.HttpStatusCode .NotFound.Ex-
istingtechniquessuchas c3poandoverwatch relyoneditpath
analogies and symbolic editing patterns respectively to understand
theeditingintent.Withouttheuseofalanguage-basedpre-training
component,itmaybediﬃculttoobtainthesemanticunderstanding
neededto perform the editsinFigures 4and5.
5.6.2Benefits of using associated edits. We observed three key
bene/f_itsofprovidingassociatededitsto LLMs:
AssociatedEditsHelpinClarifyingtheEditingIntentofthe
Developer : The illustrative example in Section 2(Figure1) showed
that associated edits provide strong signals about the next edit
thatthedeveloperintendstoperform.Infact,withoutassociated
edits,codex-davinci doesn’tpredicttherightediteveninthetop-5
results. With associated edits, the correct prediction is ranked at
the top suggesting that associated edits help improve the top-1
performance ofthe model.
AssociatedEditsEmphasizeRelevantCodeContext :While
LLMs like codex-davinci can support a large number of tokens in
their prompts ( 4K in codex-davinci ’s case), it has been observed
thatirrelevantinformationinthepromptaﬀectsthemodel’sability
to attend to the right set of tokens [ 60]. In the illustrative example
in Figure 1, the target edit is 247 lines away from the required
spatialcontext. codex-davinci canpredicttherightimportwith
only4-5linesinthespatialcontextandaccesstotheassociatededit.
The scenario without associated edits, on the other hand, requires
providing250linesofmostlyirrelevantcodetothemodeltoinclude
theExceptionthattherequiredimportprovides. codex-davinci
fails to generate the right prediction in the top-5 results even withall of this spatial context. On a simpler version of this example
where the relevantcodecontextis movedcloser to thetargetedit
(fromLine250toLine15), codex-davinci withoutassociatededits
predictstherightimportintop-10,butitisnotthetop-1prediction.
Associated Edits Contain Information about Edited Code
Elements : There may be key variables that are deleted or replaced
by previous edits but referenced by the target codelocation. With-
outaccesstotheseassociatededits,themodelhasnocontextabout
thesevariables, methodsorothercode elements.Forexample, ifa
variable var1isreplacedby var2inapreviouseditandthedeveloper
nowmovestoline var1=var1/ 2,themodelisexpectedtoreplace
thislinewith var2=var2/ 2.Withoutaccesstothepreviousedit,
themodeldoesn’tknowtherelationshipbetween var1andvar2and
mayconsiderthemto be twodistinct variables.
5.7 AdditionalResults & Discussion
Weconductedadditionalexperimentstounderstandhow Grace
aﬀectsrobustness andentropyduring prediction. We also evaluated
otherpromptingstylesandmodelcon/f_igurations.Seethetechnical
report for details andfurther discussion.
6 RELATED WORK
6.1 AutomaticCodeEditing
In recent years, there has been a signi/f_icant boom in academic and
industrial researchfor automating developers’ code editing activi-
ties.MostmodernIDEs[ 25,45]supportautomatedcodechanges
like the addition of boilerplate code, developer-assisted refactoring,
etc. While these developer-assisted approaches tremendously help
boostproductivity[ 47],asigni/f_icantamountoffurtherresearchex-
ists in automated code editing aimed at learning code edit patterns
fromdeveloper’spreviousedits[ 6,10,13,17,27,48,49,54,55,61,
67,68].Wedividetheseapproachesintotwoorthogonaldirections:
Symbolic Approaches : Symbolic approaches learn the code
transformation patterns by representing the example edits with
symbolicabstractions.Givenasetofsuchsymbolicallyrepresented
abstract edits, these approaches generalize the edit patterns as a
sequenceofeditoperations.Forinstance,Refazer[ 56]represents
syntactic changes with Domain Speci/f_ic language and uses a de-
ductive inference algorithm to generalize and synthesize common
editpatterns.Morerecently,Overwatch[ 68]learnstogeneralize
developercode editing behavior from asequence of code versions.
Eacheditisrepresentedas preandpostprogramstates,andgeneral-
ized edit sequences are derived from an edit graph from these state
pairs.Whiletheearlierworksinsymbolicediting[ 24,34,42,43,56]
primarilyfocusedonsyntacticediting,i.e.,refactoring,similarto
overwatch [68], we also focus on semantic changes in code. Simi-
lartooverwatch ,we emphasizeonconditioningfuture edit w.r.t.
associatededits.However,unlike overwatch ,Gracedoesnotnec-
essarily need demonstrations of the speci/f_ic edit sequence pattern
to learn to apply that pattern.
Neural Network Based Approaches : Recent advancements
in machine learning and neural networks have catapulted the
/f_ieldofcodeeditingwithNeuralNetworksrelyingontheirnoise
tolerance and generalization capabilities. As such, several ap-
proaches [ 10,13,17,21,62,67] have been proposed over the years
usingdiﬀerenttypesofNeuralNetworksforautomaticallygener-
ating edits. Notable among these are Sequence to Sequence Neural
1492Grace: LanguageModelsMeet Code Edits ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
Machine Translation based approaches [ 15,17,62], Tree to Tree
translationsapproach[ 13],andGraphNeuralNetworkbasedap-
proach[21,65].Whilemostoftheseapproacheslearntogeneralize
code edit patterns from seemingly unrelated example edits, this
workshowstheimportanceofrelatedassociatededits.Neverthe-
less,themostnotablefeatureofNeuralCodeEditingapproaches
is how the approach generates the edited code. While some ap-
proaches[ 10,21,67]generateascriptofeditoperations( i.e.,insert,
delete,update),others[ 13,17,62]generatetheeditedcodeapplying
theeditpatternintheprocessoftranslation.Similartothelatter
approach, we generate the edited code given the code before the
edit.
6.2 DeepLearning forSourceCode
RecentadvancementinDeepNeuralNetworks(DNN)hasdrawn
focusontheapplicationofsuchindiﬀerentsourcecodeunderstand-
ing and generation tasks, including bug detection [ 14,22], code
comprehension [ 1], code search [ 12], code generation [ 63], code
translation[ 3,38],programrepair[ 17,62],etc.Thevastplethoraof
DNNmodelsinSEtasksrangesfromgeneral-purposemodels[ 2]
inspiredbyNaturalLanguageProcessingtocustom-builtmodelsfor
source code modeling [ 21,30,65]. These models, however, require
a large quantity of labeled data to optimize millions of parameters.
To overcomethisproblem, researchershave proposedto pre-train
modelswithalargequantityofunlabelleddata andsubsequently
re-usesuchapre-trainedmodelacrossdiﬀerenttasks[ 20,51].There
are a wide variety of pre-trained models for source code proposed
over the years [ 2,16,23,63], some containing hundreds of billions
ofparameters[ 16],colloquiallyknownaslargelanguagemodels
or LLMs. LLMs showexcellent promise in autonomously learning
programminglanguagepropertiesandadditionally,haveshownthe
abilityto learn deductive reasoninginherentinprogramming and
naturallanguages[ 41,57,64,66].Assuch,theseLLMsareleveraged
in many industrial developer assistance tools such as GitHub Copi-
lot[28],AmazonCodeWhisperer[ 58],IntellicodeCompose[ 18,44],
etc. In this work, we show an in-depth investigation of harnessing
the power oftheseLLMsfor automatedcode editing.
7 LIMITATIONS& THREATS TO VALIDITY
Limitations : There are certain limitations of our approach that
wewouldliketoaddressinfuturework.Firstly,asourapproach
depends on other edit mining techniques, it is restricted by the
quality of the collected edits. On rare occasions, associated edits in
the prompt can also mislead the model with some irrelevant infor-
mation which in turn leads to incorrect predictions. Moreover, our
approach canalso failwhen thegroundtruthrequires knowledge
ofcertaincontext(methodsignatures,forexample)thatdoesnot
appearintheassociatededits.Secondly,theLLMsusedareprone
toknownissuessuchashallucinations,generationofuncompilable
code, etc. Despite being generative, these models can still fail to
predict editsthat involve generatingentirelynewcode.
Threats to Validity : When using a pre-trained model, there is
alwaysathreatoftestdataleakingtothetrainset[ 4].Itispossible
that the data used for pre-training codex-davinci contained some
or all of the data in the c3potest set since the c3podataset was
created from GitHub repositories. One wayto mitigate this threat
istoperformevaluationonmultipletestsets.Therefore,wealsoperformed our evaluation on the overwatch dataset. The over-
watchtestsetwasnotpubliclyavailableandweobtaineditdirectly
from the authors. Hence, we believe our results are not in/f_lated
because ofthe possibility of codex-davinci having seenthe c3po
test set. We mitigated the threat further by performing the same
experimentson/f_ine-tuned CodeT5.Allconclusionswemakeinthis
workareinformedbyresultsfrombothmodelsonbothdatasets.
Finally, this potential data leak would aﬀect all our experiment
settings with the codex-davinci model equally and any bene/f_it
would also have been available to the model without associated
edits.Ourresultssuggestthatthemodelclearlybene/f_itsfromthe
additionofassociatededitsthus entailingafair comparison.
Thetestsetsareanothersourceofpossiblegapbetweenwhatwe
observeinourexperimentsandwhatwemayseeiftheapproach
were deployed in real world. The c3podataset was created from
commits. It de/f_ined an edit at a certain level of granularity. This
de/f_initionmaynotmatchthenotionofeditsusedinsometarget
application(ofourcodepredictionmodels).Again,wemitigatethis
threatbyalsotestingon overwatch datasetthatusesadiﬀerent
level of granularity for de/f_ining an edit. Our results appear to hold
acrossthediﬀerentpossiblenotionsofan“edit”.Infact,bypresent-
ing the associated edits to the model (in the prompt and during
/f_ine-tuning),weareabletoteachthenotionofanedittoit.Even
withthenotionofeditconveyed,thedistributionofassociatededits
in our test sets may not re/f_lect what we observe in practice. The
approach based on codex-davinci is not immune to this threat,
but the /f_ine-tuning approach can adapt if we have /f_ine-tuning data.
8 CONCLUSIONS& FUTUREWORK
Predictingcodeeditsisanimportantsoftware-engineeringproblem.
In thispaper, we leveragethe generative capability of LLMstoad-
dressthisproblem.Withouttheknowledgeofprioredits,theLLMs
fail topredict the requirededits, butwhenwe combine themwith
associatededits,theirperformanceimprovesgreatly.Thissimple
strategy is quite eﬀective, and as shown in the experiments, Grace
outperformsthecurrentstate-of-the-artspecializedsymbolicand
neuralmethodsontheirrespective datasets.
ThegenerativecapabilityofLLMshasopenedupmanyoppor-
tunities for addressing software-engineering problems that have
beenhardtodealwith.WebelievethatcombiningtheLLMswith
domain-speci/f_ic insights, such as our use of associated edits, holds
promise for hithertochallengingproblems.In thefuture, we shall
seektoexploitthisstrategyforothersoftwareengineeringprob-
lems.Ontheproblemofpredictingcodeedits,weplantoexplore
the problem of discovering associated edits, and the application to
large-scale migrations,refactorings, andmaintenanceactivities.
9 DATA-AVAILABILITYSTATEMENT
Thec3podataset is made publicly available by the authors of [ 10].
Wesharethescripts,prompts,andinstructionstoaccessthe/f_ine-
tunedmodelson c3poathttps://aka.ms/GrACE-Code [31].Sincethe
overwatch datasetisprivate,wedonotholdtheauthoritytoredis-
tributethedatasetoranymodelslearnedfromthatdataset.Readers
with access to overwatch data can reproduce the experiments us-
ing the shared scripts. An interactive tutorial notebook discussing
deployment of our approach in an IDE-based edit suggestions tool
isalsoavailable at the same webpage.
1493ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA P. Gupta, A.Khare, Y. Bajpai, S.Chakraborty, S.Gulwani, A.Kanade, A.Radhakrishna, G.Soares, andA.Tiwari
REFERENCES
[1]WasiAhmad,SaikatChakraborty,BaishakhiRay,andKai-WeiChang.2020. A
Transformer-based Approach for Source Code Summarization. Proceedings of
the58thAnnualMeetingoftheAssociationforComputationalLinguistics (2020),
4998–5007.
[2]Wasi Ahmad, Saikat Chakraborty, Baishakhi Ray, and Kai-Wei Chang. 2021. Uni-
/f_ied Pre-training for Program Understanding and Generation. Proceedings of the
2021ConferenceoftheNorthAmericanChapteroftheAssociationforComputa-
tional Linguistics: Human Language Technologies (2021), 2655–2668.
[3]Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, and Kai-Wei Chang.
2023. SummarizeandGeneratetoBack-translate:UnsupervisedTranslationof
Programming Languages. The 17th Conference of the European Chapter of the
Associationfor ComputationalLinguistics (EACL2023) (2023).
[4]Miltiadis Allamanis. 2019. TheAdverse Eﬀectsof Code Duplicationin Machine
Learning Models of Code. In Proceedings of the 2019 ACM SIGPLAN International
SymposiumonNewIdeas,NewParadigms,andRe/f_lectionsonProgrammingand
Software(Athens,Greece) (Onward!2019) .AssociationforComputingMachinery,
NewYork, NY, USA,143–153. https://doi.org/10.1145/3359591.3359735
[5]UriAlon,MeitalZilberstein,OmerLevy,andEranYahav.2019.code2vec:learning
distributedrepresentationsofcode. Proc.ACMProgram.Lang. 3,POPL(2019),
40:1–40:29. https://doi.org/10.1145/3290353
[6]Jesper Andersen, Anh Cuong Nguyen, David Lo, Julia L Lawall, and Siau-Cheng
Khoo. 2012. Semantic patch inference. In Automated Software Engineering (ASE),
2012Proceedingsofthe27thIEEE/ACMInternationalConferenceon .IEEE,382–385.
[7]JohannesBader,AndrewScott,MichaelPradel,andSatishChandra.2019. Geta/f_ix:
LearningtoFixBugsAutomatically. Proc.ACMProgram.Lang. 3,OOPSLA,Article
159(Oct.2019),27pages. https://doi.org/10.1145/3360585
[8]Mohammad Bavarian, Angela Jiang, Heewoo Jun, and Henrique Pondé. 2022.
New GPT-3 Capabilities: Edit & Insert. (2022). At https://openai.com/blog/gpt-3-
edit-insert .
[9] B.W. Boehm. 1976. SoftwareEngineering. IEEE Trans. Computers 25,12(1976).
[10]ShakedBrody,UriAlon,andEranYahav.2020. Astructuralmodelforcontextual
codechanges. 4,OOPSLA(Nov.2020). https://doi.org/10.1145/3428283 Publisher
Copyright: ©2020 Owner/Author..
[11]Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,
PrafullaDhariwal,ArvindNeelakantan, Pranav Shyam, GirishSastry,Amanda
Askell,SandhiniAgarwal,ArielHerbert-Voss,GretchenKrueger,TomHenighan,
Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeﬀrey Wu, Clemens Winter,
ChristopherHesse,MarkChen,EricSigler,MateuszLitwin,ScottGray,Benjamin
Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya
Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners.
CoRRabs/2005.14165 (2020). arXiv: 2005.14165 https://arxiv.org/abs/2005.14165
[12]JoseCambronero,HongyuLi,SeohyunKim,KoushikSen,andSatishChandra.
2019. When deep learning met code search. In Proceedings of the 2019 27th ACM
JointMeetingonEuropeanSoftwareEngineeringConferenceandSymposiumon
the FoundationsofSoftwareEngineering . 964–974.
[13]Saikat Chakraborty, Yangruibo Ding, Miltiadis Allamanis, and Baishakhi Ray.
2020. Codit:Codeeditingwithtree-basedneuralmodels. IEEETransactionson
SoftwareEngineering 48,4 (2020), 1385–1399.
[14]Saikat Chakraborty, Rahul Krishna, Yangruibo Ding, and Baishakhi Ray. 2021.
Deep learning based vulnerability detection: Are we there yet. IEEE Transactions
onSoftwareEngineering (2021).
[15]SaikatChakrabortyandBaishakhiRay.2021. Onmulti-modallearningofedit-
ingsourcecode.In 202136thIEEE/ACMInternationalConferenceonAutomated
SoftwareEngineering (ASE) . IEEE,443–455.
[16]MarkChen,JerryTworek,HeewooJun,QimingYuan,HenriquePondedeOliveira
Pinto,JaredKaplan,HarriEdwards,YuriBurda,NicholasJoseph,GregBrockman,
Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish
Sastry,PamelaMishkin,BrookeChan,ScottGray,NickRyder,MikhailPavlov,
Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe
Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis,
ElizabethBarnes,ArielHerbert-Voss,WilliamHebgenGuss,AlexNichol,Alex
Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain,
WilliamSaunders,ChristopherHesse,AndrewN.Carr,JanLeike,JoshAchiam,
VedantMisra,EvanMorikawa, AlecRadford,MatthewKnight,MilesBrundage,
Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam
McCandlish, Ilya Sutskever, and Wojciech Zaremba. 2021. Evaluating Large
Language Models Trained on Code. https://doi.org/10.48550/ARXIV.2107.03374
[17]Z.Chen,S.Kommrusch,M.Tufano,L.Pouchet,D.Poshyvanyk,andM.Monperrus.
2021. SequenceR: Sequence-to-Sequence Learning for End-to-End Program
Repair.IEEETransactionsonSoftwareEngineering 47,09(sep2021),1943–1959.
https://doi.org/10.1109/TSE.2019.2940179
[18]MicrosoftCorp.2022. OverviewofIntelliCode .https://learn.microsoft.com/en-
us/visualstudio/intellicode/overview
[19]Reudismam Rolim de Sousa, Gustavo Soares, Rohit Gheyi, Titus Barik, and Loris
D’Antoni. 2021. Learning Quick Fixes from Code Repositories. In SBES ’21: 35th
BrazilianSymposiumonSoftwareEngineering,Joinville,SantaCatarina,Brazil,
27 September 2021 - 1 October 2021 , Cristiano D. Vasconcellos, Karina GirardiRoggia, Vanessa Collere, and Paulo Bous/f_ield (Eds.). ACM, 74–83. https://doi.
org/10.1145/3474624.3474650
[20]Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert:
Pre-trainingofdeepbidirectionaltransformersforlanguageunderstanding. arXiv
preprint arXiv:1810.04805 (2018).
[21]ElizabethDinella,HanjunDai,ZiyangLi,MayurNaik,LeSong,andKeWang.
2020.Hoppity:Learninggraphtransformationstodetectand/f_ixbugsinprograms.
InInternationalConference onLearning Representations (ICLR) .
[22]Yangruibo Ding, Luca Buratti, Saurabh Pujar, Alessandro Morari, Baishakhi Ray,
andSaikatChakraborty.2022. TowardsLearning(Dis)-SimilarityofSourceCode
from Program Contrasts. In Annual Meeting of the Association for Computational
Linguistics .
[23]Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong,
LinjunShou,BingQin,TingLiu,DaxinJiang,etal .2020. Codebert:Apre-trained
modelfor programmingand natural languages. arXiv preprint arXiv:2002.08155
(2020).
[24]StephenR.Foster,WilliamG.Griswold,andSorinLerner.2012. WitchDoctor:IDE
support for real-time auto-completion of refactorings. In 2012 34th International
Conference on Software Engineering (ICSE) . 222–232. https://doi.org/10.1109/
ICSE.2012.6227191
[25]EclipseFoundation.2018. EclipseIDE( https://www.eclipse.org ).https://www.
eclipse.org
[26] Martin Fowler. 2018. Refactoring . Addison-WesleyProfessional.
[27]Xi Ge, Quinton L DuBose, and Emerson Murphy-Hill. 2012. Reconciling manual
and automatic refactoring. In Proceedings of the 34th International Conference on
SoftwareEngineering . IEEE Press,211–221.
[28]github.com. 2022. GitHub Copilot: YourAI pair programmer . github.com. https:
//github.com/features/copilot
[29]google.com. 2022. GitHub Acitvity Data . google.com. https://console.cloud.
google.com/marketplace/details/github/github-repos
[30]Daya Guo, Shuo Ren, Shuai Lu, Zhangyin Feng, Duyu Tang, Shujie Liu, Long
Zhou, Nan Duan, Alexey Svyatkovskiy, Shengyu Fu, et al .2020. Graphcodebert:
Pre-training code representations with data /f_low. arXiv preprint arXiv:2009.08366
(2020).
[31]PriyanshuGupta,AvishreeKhare,YasharthBajpai,SaikatChakraborty,Sumit
Gulwani,AdityaKanade,ArjunRadhakrishna,GustavoSoares,andAshishTiwari.
2023. Reproduction Package for Grace: Language Models Meet Code Edits.
https://doi.org/10.1145/3580411
[32]Anandi Hira and Barry Boehm. 2016. Function Point Analysis for Software
Maintenance.In Proceedingsofthe10thACM/IEEEInternationalSymposiumon
EmpiricalSoftwareEngineeringandMeasurement (CiudadReal,Spain) (ESEM’16) .
AssociationforComputingMachinery,NewYork,NY,USA,Article48,6pages.
https://doi.org/10.1145/2961111.2962613
[33]Hamel Husain, Ho-Hsiang Wu, Tiferet Gazit, Miltiadis Allamanis, and Marc
Brockschmidt.2019. CodeSearchNetChallenge:EvaluatingtheStateofSemantic
CodeSearch. https://doi.org/10.48550/ARXIV.1909.09436
[34] JetBrains. 2021. ReSharper.(2021). At https://www.jetbrains.com/resharper/ .
[35] CapersJones. 1998. EstimatingSoftwareCosts . McGraw-Hill.
[36]M.Kim,D.Notkin,D.Grossman,andG.Wilson.2013. IdentifyingandSummariz-
ingSystematicCode ChangesviaRuleInference. IEEETransactionsonSoftware
Engineering 39,1 (2013), 45–62. https://doi.org/10.1109/TSE.2012.16
[37]Amy J. Ko, Brad A. Myers, Michael J. Coblenz, and Htet Htet Aung. 2006. An
Exploratory Study of How Developers Seek, Relate, and Collect Relevant In-
formationduringSoftwareMaintenanceTasks. IEEETransactionsonSoftware
Engineering 32,12(2006), 971–987. https://doi.org/10.1109/TSE.2006.116
[38]Marie-AnneLachaux,BaptisteRoziere,LowikChanussot,andGuillaumeLample.
2020. Unsupervised translation of programming languages. arXiv preprint
arXiv:2006.03511 (2020).
[39]HungLe,YueWang,AkhileshDeepakGotmare,SilvioSavarese,andStevenC.H.
Hoi. 2022. CodeRL: Mastering Code Generation through Pretrained Models and
DeepReinforcementLearning. arXiv preprint arXiv:2207.01780 (2022).
[40]M. M. Lehman and L. Belady. 1985. Software Evolution–Processes of Software
Change. Academic.
[41]Christopher D Manning. 2022. Human language understanding & reasoning.
Daedalus 151, 2 (2022), 127–138.
[42]Na Meng, Miryung Kim, and Kathryn S McKinley. 2011. Sydit: Creating and
applyingaprogramtransformationfromanexample.In Proceedingsofthe19th
ACM SIGSOFT symposium and the 13th European conference on Foundations of
softwareengineering . 440–443.
[43]Na Meng, Miryung Kim, and Kathryn S McKinley. 2013. LASE: locating and
applying systematic edits by learning from examples. In 2013 35th International
Conference onSoftwareEngineering (ICSE) . IEEE,502–511.
[44]Microsoft.2021. IntelliCodesuggestions.(2021). At https://devblogs.microsoft.
com/visualstudio/intellicode-suggestion-apply-all/ .
[45] Microsoft.2021. Visual Studio. (2021). At https://www.visualstudio.com .
[46]AndersMiltner,SumitGulwani,VuLe,AlanLeung,ArjunRadhakrishna,Gustavo
Soares,Ashish Tiwari, and Abhishek Udupa.2019. On the FlySynthesis of Edit
Suggestions. 3, OOPSLA, Article 143 (oct 2019), 29 pages. https://doi.org/10.
1494Grace: LanguageModelsMeet Code Edits ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
1145/3360569
[47]RaimundMoser,PekkaAbrahamsson,WitoldPedrycz,AlbertoSillitti,andGi-
ancarlo Succi. 2008. A case study on the impact of refactoring on quality and
productivity in an agile team. In Balancing Agility and Formalism in Software
Engineering: Second IFIP TC 2 Central and East European Conference on Software
EngineeringTechniques,CEE-SET2007,Poznan,Poland,October10-12,2007,Revised
SelectedPapers . Springer, 252–266.
[48]AnhTuanNguyen,MichaelHilton,MihaiCodoban,HoanAnhNguyen,LilyMast,
EliRademacher,TienNNguyen,andDannyDig.2016. APIcoderecommendation
usingstatisticallearningfrom/f_ine-grainedchanges.In Proceedingsofthe201624th
ACM SIGSOFT International Symposium on Foundationsof Software Engineering .
ACM,511–522.
[49]AnhTuanNguyen,HoanAnhNguyen,TungThanhNguyen,andTienNNguyen.
2014.StatisticallearningapproachforminingAPIusagemappingsforcodemigra-
tion. InProceedings of the 29th ACM/IEEE international conference on Automated
softwareengineering . ACM,457–468.
[50]AlecRadfordandKarthikNarasimhan.2018. ImprovingLanguageUnderstanding
by GenerativePre-Training.
[51]Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al .2018.
Improvinglanguageunderstandingby generativepre-training. (2018).
[52]Alec Radford, Jeﬀ Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
Sutskever. 2019. Language Models areUnsupervised MultitaskLearners.
[53]Colin Raﬀel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang,
Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the
LimitsofTransferLearningwithaUni/f_iedText-to-TextTransformer. J.Mach.
Learn. Res. 21(2020), 140:1–140:67. http://jmlr.org/papers/v21/20-074.html
[54]Veselin Raychev, Max Schäfer, Manu Sridharan, and Martin Vechev. 2013. Refac-
toring with synthesis.In ACMSIGPLAN Notices , Vol. 48.ACM,339–354.
[55]Machel Reid and Graham Neubig. 2022. Learning to Model Editing Processes.
https://doi.org/10.48550/ARXIV.2205.12374
[56]ReudismamRolim,GustavoSoares,LorisD’Antoni,OleksandrPolozov,Sumit
Gulwani,RohitGheyi,RyoSuzuki,andBjörnHartmann.2017. Learningsyntactic
programtransformationsfromexamples.In 2017IEEE/ACM39thInternational
Conference onSoftwareEngineering (ICSE) . IEEE,404–415.
[57]Christopher Rytting and David Wingate. 2021. Leveraging the inductive bias
of large language models for abstract textual reasoning. Advances in Neural
InformationProcessingSystems 34(2021), 17111–17122.
[58]AmazonWebServices.2022. ML-poweredcodingcompanion-AmazonCodeWhis-
perer.AmazonWeb Services. https://aws.amazon.com/codewhisperer/
[59]Noam Shazeer and Mitchell Stern. 2018. Adafactor: Adaptive learning rates with
sublinear memory cost. In International Conference on Machine Learning . PMLR,4596–4604.
[60]Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, Ed Huai
hsinChi,NathanaelScharli,andDennyZhou.2023. LargeLanguageModelsCan
Be EasilyDistracted by Irrelevant Context. ArXivabs/2302.00093 (2023).
[61]Wesley Tansey and Eli Tilevich. 2008. Annotation refactoring: inferring upgrade
transformationsforlegacyapplications.In ACMSigplanNotices ,Vol.43.ACM,
295–312.
[62]Michele Tufano, Jevgenija Pantiuchina, Cody Watson, Gabriele Bavota, and
Denys Poshyvanyk. 2019. On learning meaningful code changes via neural
machine translation. In 2019 IEEE/ACM 41st International Conference on Software
Engineering (ICSE) . IEEE,25–36.
[63]Yue Wang, Weishi Wang, Sha/f_iq R. Joty, and Steven C. H. Hoi. 2021. CodeT5:
Identi/f_ier-awareUni/f_iedPre-trainedEncoder-DecoderModelsforCodeUnder-
standing and Generation. In Proceedings of the 2021 Conference on Empirical
MethodsinNaturalLanguageProcessing,EMNLP2021,VirtualEvent/PuntaCana,
Dominican Republic, 7-11 November, 2021 . Association for Computational Lin-
guistics,8696–8708. https://doi.org/10.18653/v1/2021.emnlp-main.685 Seealso
https://arxiv.org/abs/2109.00859 .
[64]JasonWei,XuezhiWang,DaleSchuurmans,MaartenBosma,EdChi,QuocLe,
andDennyZhou.2022. Chainofthoughtpromptingelicitsreasoninginlarge
languagemodels. arXiv preprint arXiv:2201.11903 (2022).
[65]Pengcheng Yin, Graham Neubig, Miltiadis Allamanis, Marc Brockschmidt,
and Alexander Gaunt. 2019. Learning to Represent Edits. In ICLR
2019.https://www.microsoft.com/en-us/research/publication/learning-to-
represent-edits/ arXiv:1810.13337 [cs.LG].
[66]Eric Zelikman, Yuhuai Wu, and Noah D Goodman. 2022. Star: Bootstrapping
reasoning with reasoning. arXiv preprint arXiv:2203.14465 (2022).
[67]Jiyang Zhang, Sheena Panthaplackel, Pengyu Nie, Junyi Jessy Li, and Mi-
los Gligoric. 2023. CoditT5: Pretraining for Source Code and Natural Lan-
guage Editing. In Proceedings of the 37th IEEE/ACM International Conference
on Automated Software Engineering (Rochester, MI, USA) (ASE ’22) . Associ-
ation for Computing Machinery, New York, NY, USA, Article 22, 12 pages.
https://doi.org/10.1145/3551349.3556955
[68]Yuhao Zhang, Yasharth Bajpai, Priyanshu Gupta, Ameya Ketkar, Miltiadis Al-
lamanis, Titus Barik, Sumit Gulwani, Arjun Radhakrishna, Mohammad Raza,
Gustavo Soares, and Ashish Tiwari. 2022. Overwatch: Learning patterns in
code edit sequences. Proc. ACM Program. Lang. 6, OOPSLA2 (2022), 395–423.
https://doi.org/10.1145/3563302
Received 2023-02-02; accepted 2023-07-27
1495