Demystifying the Dependency Challenge in Kernel FuzzingYu HaoUC RiversideRiverside, USAyhao016@ucr.eduHang ZhangGeorgia Institute of TechnologyAtlanta, USAhzhan033@ucr.eduGuoren LiUC RiversideRiverside, USAgli076@ucr.eduXingyun DuUC RiversideRiverside, USAdxing003@ucr.eduZhiyun QianUC RiversideRiverside, USAzhiyunq@cs.ucr.eduArdalan Amiri SaniUC IrvineIrvine, USAardalan@uci.eduABSTRACTFuzz testing operating system kernels remains a daunting task todate. One known challenge is that much of the kernel code is lockedunder speci/f_ic kernel states and current kernel fuzzers are not ef-fective in exploring such an enormous state space. We refer to thisproblem as the dependency challenge. Though there are some ef-forts trying to address the dependency challenge, the prevalenceand categorization of dependencies have never been studied. Mostprior work simply attempted to recover dependencies opportunisti-cally whenever they are relatively easy to recognize. In this paper,we undertake a substantial measurement study to systematicallyunderstand the real challenge behind dependencies. To our surprise,we show that even for well-fuzzed kernel modules, unresolved de-pendencies still account for 59% - 88% of the uncovered branches.Furthermore, we show that the dependency challenge is only asymptom rather than the root cause of failing to achieve more cov-erage. By distilling and summarizing our/f_indings, we believe theresearch provides valuable guidance to future research in kernelfuzzing. Finally, we propose a number of novel research directionsdirectly based on the insights gained from the measurement study.ACM Reference Format:Yu Hao, Hang Zhang, Guoren Li, Xingyun Du, Zhiyun Qian, and ArdalanAmiri Sani. 2022. Demystifying the Dependency Challenge in Kernel Fuzzing.In44th International Conference on Software Engineering (ICSE ‚Äô22), May21‚Äì29, 2022, Pittsburgh, PA, USA.ACM, New York, NY, USA, 13 pages.https://doi.org/10.1145/3510003.35101261 INTRODUCTIONFuzzing has become one of the most popular and essential methodsfor uncovering bugs and vulnerabilities due to its practicability ande"ectiveness. Both academia and industry have devoted a largeamount of resources to researching and deploying fuzzing systems.For example, Google allocated more than 25,000 servers to deployits ClusterFuzz infrastructure and has found tens of thousands ofvulnerabilities so far [13].This work is licensed under a Creative Commons Attribution International 4.0 License.ICSE ‚Äô22, May 21‚Äì29, 2022, Pittsburgh, PA, USA¬© 2022 Copyright held by the owner/author(s).ACM ISBN 978-1-4503-9221-1/22/05.https://doi.org/10.1145/3510003.3510126However, despite the continuous research e"orts and improve-ments on fuzzing techniques, fuzzing sophisticated stateful software(e.g.,OS kernels) remains a big challenge. Even with the state-of-the-art kernel fuzzer Syzkaller [15], the achievable code coverageof various kernel modules is generally low from our measurements(from 21% to 46%) after extensive fuzzing sessions.One common belief of the major obstacle is that a large portionof code can only be covered under speci/f_ic kernel states (e.g.,someglobal variables need to be set to speci/f_ic values). It is known to bedi#cult for a fuzzer to search the enormous state space and enterthe desired ones. This problem cannot be easily solved by simplyadopting advanced mutation strategies that operate solely on localinputs (e.g.,function arguments), since many conditions in the codeare controlled by global memory (which may need to be set by acompletely di"erent function/syscall invocation). In this paper, werefer to this challenge as thedependency challengein fuzzing OSkernels.In recent years, there have been a few related works that madesome progress in tackling this challenge. MoonShine [25] aimsto recognize dependencies from manually curated test cases (e.g.,Linux testing project [10]), and distill them into more concise seedsfor fuzzing. However, its goalis not to discover and analyze newdependencies. HFL [19] applies static analysis and symbolic execu-tion to solve a subset of dependency issues. Although it manages toachieve improvements on code coverage compared to the baseline,according to our measurement, its result is still far from satisfactory(e.g.,only 10.5% of Linux kernel code can be covered during a 50-hour fuzzing session). Furthermore, it still remains unknown whattypes of dependencies are resolved and how large of a fraction theyrepresent. In general, due to the lack of a deep and quantitativeunderstanding of the dependency challenge, we argue that currentresearch has only explored the surface of this challenge.In this paper, we take a data-driven approach to systematicallyunderstand the dependency challenge in kernel fuzzing, with anin-depth measurement study on a subset of Linux kernel modules.Speci/f_ically, we aim to answer the following questions:(1) How well does the state-of-the-art fuzzer perform (e.g.,re-garding code coverage) against the complex and stateful kernel?How many uncovered branches are related to dependencies? Wespeci/f_ically focus on well-fuzzed kernel modules as the results willrepresent the di#cult cases that are worth solving in the future.(2) What are the root causes behind unresolved dependenciesand how important are they? Though the community has been
6592022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)
ICSE ‚Äô22, May 21‚Äì29, 2022, Pi/t_tsburgh, PA, USAYu Hao, Hang Zhang, Guoren Li, Xingyun Du, Zhiyun Qian, and Ardalan Amiri Saniaware of the dependency for years, it is still unclear what the rootcauses are for fuzzers‚Äô failure to resolve the dependency.(3) What can we do to address unresolved dependencies? Withthe understanding of root causes, we hope to shed light on potentialsolutions and draw attention to blind spots in current researchdirections.To answer these questions, we develop a pipeline of measurementinfrastructure, including a combination of automated components(fuzzing and static analysis) and meticulous manual investigationswhenever necessary to get to the root causes that are otherwisedi#cult to obtain. Through our measurement study, we not onlydiscover that the dependency challenge is ubiquitous, but also/f_inda diverse set of root causes, which need focused e"orts movingforward. For example, as will be discussed in ¬ß7, we suggest thatmulti-syscall analysis and multi-interface fuzzing are two promisingdirections. Furthermore, we show that much of the kernel codeis simply impossible to be covered (dead code) without a properenvironment. We believe the curated dataset from our study isvaluable in guiding future research in kernel fuzzing.We summarize our main contributions as below:‚Ä¢To the best of our knowledge, we are the/f_irst to perform an in-depth measurement and systematic analysis on the dependencychallenge in kernel fuzzing.‚Ä¢We develop a measurement pipeline including automated com-ponents that can quantify the magnitude of the dependencychallenge. We will open source the measurement pipeline anddata to facilitate future research.‚Ä¢Based on our measurement results and deep understanding of thedependency challenge, we reveal many unexpected observationsand point to new research directions that will improve kernelfuzzing.2 BACKGROUND2.1 De/f_initionThis section gives some de/f_initions to help explain the challengesof resolving dependencies and the root causes of uncovered code.Unresolved condition (UC).We de/f_ine an unresolved conditionto be a condition that has been evaluated during fuzzing, but it hasnever been evaluated to the desired value that allows an uncoveredbranch to be taken.Global memory.We de/f_ine global memory to include global vari-ables and any heap memory reachable from global variables (e.g.,aglobal pointer may point to a heap object). Either way, global mem-ory persists across system call invocations,i.e.,system calls canchange the global memory, which becomes observable to another.Kernel state.We de/f_ine the kernel state as all the content in globalmemory. If a function reads the global memory in a condition, thecorresponding kernel state could in/f_luence which branch is taken.This means that an execution path of a system call depends on notonly arguments but also the kernel state.Unresolved dependency (UD).We de/f_ine an unresolved depen-dency to be an UC where some global memory is read,i.e.,thiscondition can only be satis/f_ied if the kernel has a desired state.Write statement (WS).We de/f_ine a statement as awrite statementas long as it writes to some global memory.1static intcdrom_read_cdda(...) {2if(cdi->cdda_method==CDDA_BPC_FULL&& nframes >1){3// uncoveredcode4... } }5intregister_cdrom(...) {6cdi->cdda_method = CDDA_BPC_FULL;}Figure 1: An example case of unresolved dependencyEÔ¨Äective write statement (EWS).We de/f_ine an e"ective writestatement to be a WS that has the potential to change the globalmemory to an expected value by an UD.Dependency.We de/f_ine a dependency to be a relationship betweenan UD and its EWS. Conceptually it is similar to def-use, exceptdependency is speci/f_ic to global memory and the use has to be acondition check. Furthermore, we further categorize dependenciesintoexplicit dependenciesandimplicit dependencies. Theformer represents the cases where the value written to the globalmemory (e.g.,a/f_ile descriptor) is propagated back to userspace,which is then subsequently passed as an argument that is checkedagainst the global memory (a read). As an example, when a syscallgenerates a kernel/f_ile object (throughopen()), it will be stored in aglobal array and its/f_ile descriptor returned to userspace. The samedescriptor value will be passed in a subsequent syscall (read())which causes the stored object in the array to be read. The latterrepresents the cases where there is no overlap between one syscall‚Äôsoutput and another syscall‚Äôs input arguments. The example we willshow next is an implicit dependency.2.2 An Example CaseWe use a simple example from thecdromkernel module to illus-trate how to/f_ind the root cause of an UD. As shown in Figure 1,conditioncdi->cdda_method == CDDA_BPC_FULL(line 2, wherecdiis a global structure) always evaluates to false when a fuzzingtest case reaches it, causing the true branch to be uncovered.A common way to resolve such a condition is to/f_ind and executeits EWS [35]. In this example, line 6, which is reachable throughanother functionregister_cdrom(), is an EWS for the UD at line2 since it writes the expected value tocdi->cdda_method. The nextstep is to assemble a test case reaching (and thus executing) theEWS before the UD. If the EWS is again guarded behind anotherUD, we need to resolve it at/f_irst - this can be a recursive process.3M O T I V A T I O NLinux Kernel Fuzzing Tackling Dependencies.The typical in-terface exposed by OS kernels is syscalls. Therefore, before onecan start fuzzing the kernel, it is necessary to generate a test caseconsisting of a sequence of syscalls (with corresponding argumentsprepared). In the case of the state-of-the-art kernel fuzzer Syzkaller,it requires a description or speci/f_ication of the syscall interfaces.Typically the speci/f_ications (also calledtemplates) are manuallycurated, which includes the information about the syscalls, theirexplicit dependency relationship, and the possible range of valuesof syscall arguments. Since manually curating templates for variouskernel modules is not scalable especially a long tail of device drivers,there has been some recent work,e.g.,DIFUZE [7] and SyzGen [4],that aims to automate the generation of syscalltemplates, which660Demystifying the Dependency Challenge in Kernel FuzzingICSE ‚Äô22, May 21‚Äì29, 2022, Pi/t_tsburgh, PA, USAincludes some limited hardcoded knowledge about explicit depen-dencies as well. Another direction considered is to simply takesyscall traces generated by existing applications (that exercise aspeci/f_ic target module) and mutate the trace [16]. This bypasses theneed to generate syscall templates and instead pushes the problemto being able to generate high quality syscall traces. In practice, itoften falls short in coverage because existing applications typicallyexercise only a small portion of the kernel module.Furthermore, Syzkaller templates by design are unable to en-code implicit dependencies where no explicit return and argumentrelationship exists,e.g.,the example in Figure 1 is such a case. Itis possible to analyze existing syscall traces generated by applica-tions [16,25]. This line of work can capture dependencies (bothexplicit and implicit) that are naturally exercised by existing appli-cations, but will not be able to resolve new dependencies. Anotherdirection (e.g.,explored by HFL [19]) is to conduct more sophisti-cated program analyses and look for read/write relationships ofthe same global memory. However, it focuses on resolving mostlyexplicit dependencies which are typically encoded in well-writtentemplates already, i.e., the templates correctly describe most of thesystem calls and their relationships. Indeed, as we/f_ind out frommeasuring the dependency challenge in popular kernel modules,the majority of UDs are implicit instead of explicit.Motivation.To summarize, we believe the state-of-the-art kernelfuzzing research has only explored the surface of the dependencychallenge.In particular, we/f_ind that most of the existing workfocuses on the low-hanging fruits of improving fuzzing cov-erage against the kernel modules with largely incomplete (ormissing) syscall templates.For example, DIFUZE [7] generatestemplates (considering some explicit dependencies) for kernel mod-ules where no prior templates exist. HFL [19] focused on discov-ering explicit dependencies in less tested modules.However, inthis paper, we aim to understand what the remaining chal-lenges are when syscall templates are already comprehensivewith the obvious dependencies recognized and encoded, andwhen fuzzing time is suÔ¨Éciently long. In particular, we areinterested in whether the dependency challenge is still theprominent hurdle and why?Consider the example case in Fig-ure 1. Surprisingly, even such a seemingly trivial dependency canbe extremely challenging for the state-of-the-art kernel fuzzer toresolve and cannot be solved by prior work (because it is an implicitdependency). Interestingly, as will be shown in ¬ß6.3, it turns outthe root cause is that the EWS is inside the initialization functionsof the kernel module, and a kernel fuzzer implicitly assumes suchfunctions are out of the fuzzing scope and never considers fuzzingsuch functions.Following this direction, in this project, we select a set of kernelmodules whose templates are well-written so that we can observeand analyze their coverage de/f_iciencies. From this study, the ob-vious question we hope to answer is whether dependencies arestill a major hurdle. If so, what future research directions should beconsidered to overcome the challenge? To achieve this goal, we relyon the state-of-the-art kernel fuzzer, Syzkaller, which has provede"ective in/f_inding thousands of kernel bugs [14] and continuouslyimproved. In particular, we allow Syzkaller to fuzz speci/f_ic kernelmodules su#ciently long to realize the ‚Äúfull‚Äù potential of the corre-sponding templates. This allows us to have an objective view of theremaining UCs, which represent the hard cases we want to furtherinvestigate.4 MEASUREMENT PIPELINETo conduct a proper analysis of the dependency challenge in kernelfuzzing, we build a measurement pipeline that has a combinationof automatic and manual analysis components. Roughly speaking,the automatic analysis aims to measure the scale of the dependencyproblem, whereas the manual analysis attempts to distill the rootcauses of UDs. The latter is often much more in-depth and requiresmore than just mechanical analysis.The high-level work/f_low of the measurement pipeline is shownin Figure 2. First, after long fuzzing sessions of speci/f_ic kernel mod-ules, we collect the coverage and test cases from a fuzzer and obtainthe UCs based on the coverage. Then we use static analysis to de-termine what UCs are actually UDs, which can quantify the degreeof the dependency challenge (answering the/f_irst question in ¬ß1). Inaddition, we leverage static analysis to recognize the correspond-ing WSs that can in/f_luence a condition, which is a necessary steptoward analyzing the root causes of UDs (in part to answer thesecond question in ¬ß1). From here on, we manually inspect each WSof a dependency and/f_igure out EWS. If so, we then investigate thereason Syzkaller fails to resolve the dependency. If none of the WSscan resolve the dependency, we will also investigate the underlyingreasons.Step 1: Collecting Coverage.This step is relatively straightfor-ward. In addition to allocating su#cient fuzzing time for kernelmodules, we log all the test cases and their corresponding coveragesuch that we can later use them for automated and manual analysis.Step 2: Determining Unresolved Dependencies.The next stepis to determine what UCs are UDs. This can be achieved through astatic taint analysis where the taint source is any global memory.In addition, we also consider local variables whose values are indi-rectly decided by global memory as taint sources (more detail in¬ß6.1). Basically, whenever any source/f_lows into any sink, the sinkstatement is e"ectively an UD. The result of this step allows us toquantify how often the dependency challenge impedes the fuzzerto make further progress.Since accuracy is critical for ensuring that our measurement isnot too far o"from the ground truth, we have made changes and im-provements to a state-of-the-art static analysis engine Dr.Checker [23]to adapt it to our use case and demonstrate decent accuracy. In ad-dition, it is worth noting that the static taint analysis is based onthe toolchain of LLVM [21]. Therefore, it is necessary to map anUC address to the LLVM instruction. The details of the above aredescribed in ¬ß5.Step 3: Recognizing Write Statements of Dependencies.Givenan UD, next step is to identify WSs throughout a kernel module1that can in/f_luence the value of the global memory, thereforehaving a chance to resolve the dependency. In addition, we aim topinpoint any EWS. To identify WSs, we rely on static alias analysisby searching for WSs that change the same global variable(s) asused in an UD.1The EWSs are possible outside the kernel module. Due the scalability issue, we do notextend the scope of static analysis to the whole kernel, but we will manually searchthe whole kernel in later manual analysis.661ICSE ‚Äô22, May 21‚Äì29, 2022, Pi/t_tsburgh, PA, USAYu Hao, Hang Zhang, Guoren Li, Xingyun Du, Zhiyun Qian, and Ardalan Amiri Sani
	
		
	
	
	
	
		

	
	
	
	
	
	
	 		Figure 2: Measurement pipeline including the data collected from dynamic, static, and manual analysisOnce static analysis results provide a set of WSs, we then man-ually inspect each WS and determine which one(s) are in fact ‚Äúef-fective‚Äù. Unfortunately, this goal is extremely challenging to ful/f_illautomatically because many WSs write values that are dynamicallydetermined, and it can be hard to construct a test case to reach suchstatements as well. In fact, according to our analysis, the majority ofthe WSs are simply never even covered in our long fuzzing sessions.Nevertheless, when the write values are statically determined,i.e.,constants, our static analysis can determine their e"ectiveness andprune any WSs that are obviously not e"ective. For the remainingWSs, we have to resort to a manual analysis to identify EWSs.Step 4: Distilling Root Causes.Finally, to drill down to the rootcause of an UD, we need to prove or disprove whether it can beresolved. Speci/f_ically, if we manage to/f_ind any EWS from the pre-vious step, we will attempt to construct an actual test case that canexercise the EWS, which will eventually resolve the dependency.We can then analyze why the fuzzer failed to generate such a testcase (i.e.,root causes) by inspecting its runtime logs recorded pre-viously. However,i np r a c t i c e ,w e/f_ind it extremely challenging toconstruct such test cases, even for experienced researchers.First of all, most EWSs were never even exercised during thefuzzing session. It can be challenging to construct a test case thatcan reach the statement. For example, the EWS may be guardedagain by some UCs (and even UDs). Even if we can reach the EWS,it can often be tricky to precisely control the value (which mayin turn depend on global memory). This can lead to a recursiveanalysis starting all the way from the second step (more details in¬ß6.2). Even though our static analysis can help with this process ofdetermining UDs and narrowing down the search space of EWSs,it is still a substantial undertaking.Second, it turns out that it is challenging to ‚Äúmechanically‚Äù followthe procedure of looking for EWSs and how to reach them. Forexample, there are often complications such as test cases not beingable to reproduce the same consistent behaviors (as some kernelstates are modi/f_ied by the test cases). Therefore, in the end, weend up/f_irstly making sense of the overall architecture of eachkernel module,i.e.,understanding the semantics of most criticalfunctions and data structures, before jumping into the details ofeach dependency. This includes manual auditing of the source codeas well as dynamic testing,e.g.,setting breakpoints and observingbehaviors of certain functions. As more details will be discussedin ¬ß6.3, on average, each case takes about 0.5 hour to 4 hours toanalyze. We believe this is a valuable dataset that will bene/f_it anyfuture research on kernel fuzzing.5 IMPLEMENTATIONIn total, there are 10.9k (C++), 4.7k (Go) and 0.5k (Protobuf) linesof code for the whole pipeline, including the mapping between bi-nary and LLVM bitcode (¬ß5.1), static taint analysis (4k C++ lines ofchanges to Dr.Checker in ¬ß5.2), data sharing (serialization and dese-rialization) between all components, collecting statistics, organizinginformation to support manual analysis, and the experimental so-lution (¬ß7). Below we describe in more detail about the two maincomponents in the measurement pipeline, Mapping (¬ß5.1) and StaticAnalysis (¬ß5.2). We will open source all of the components and datato facilitate the reproduction of results and future research.5.1Mapping Between Binary and LLVM BitcodeThe coverage information collected during fuzzing is about bi-nary instructions, speci/f_ically through the instrumentation pro-vided by kcov [18]. In contrast, our static analysis operates on theLLVM bitcode. For example, when determining whether an UCis an UD, it takes a branch instruction in LLVM as input,i.e.,brcond, true_branch, false_branch. Therefore, we need to mapthe binary level coverage back to the LLVM bitcode level. This turnsout to be a non-trivial process. Speci/f_ically, by default, the Linuxkernels are compiled with a high optimization levelO2(this is alsonecessary for an e#cient fuzzing process), the bitcode/f_iles gener-ated at an early stage (unoptimized) in the compilation pipelineare very di"erent from the kernel binary in terms of the control/f_lows and boundaries of basic blocks, making it challenging to mapbetween them.Our solution is to use optimized bitcode/f_iles produced at a muchlater stagein Clang (through an undocumented feature), whichshare the same control/f_low graph and basic block structure as thosein binary. This allows us to obtain an accurate mapping betweenthe binary and IR instructions. Due to the space limit, we do notgo into details here. We will however include the solution in theopen sourced version of our measurement infrastructure, whichmay help other projects that need such mappings.5.2 Static Taint AnalysisOur static analysis engine is built on top of the state-of-the-art Dr.Checker [23], which is designed to be/f_low-, context-, and/f_ield-sensitive to analyze kernel source (translated into LLVM IR). How-ever, since Dr. Checker‚Äôs built-in alias and taint analyses are notsuitable and precise enough for our purposes, we made two cate-gories of changes: (1) adapting it to work in our use cases, and (2)improving its accuracy.(1) First, since the LLVM bitcode we analyze is compiled withtheO2optimization level as described above, exotic forms of IRinstructions will be generated by Clang, which are not handled662Demystifying the Dependency Challenge in Kernel FuzzingICSE ‚Äô22, May 21‚Äì29, 2022, Pi/t_tsburgh, PA, USAby Dr. Checker (as it compiles the kernel usingO0). One such in-struction is the multi-index GEP that aggregates multiple layersof pointer o"set calculations in a single instruction. For example,getelementptr %struct.foo* @chunky, i64 1, i32 2, i323, i32 4is equivalent to&chunky[1].f2.f3.f4(the last three in-dices 2, 3, 4 represent the/f_ield indexes). Second, instead of treatinguser-controlled syscall arguments as taint sources (as in the case ofDr. Checker), we need to taint any global memory, which, accordingto its de/f_inition in ¬ß2.1, can be either (a) explicitly declared globalvariables or (b) heap memory reachable from global variables. Theformer is straightforward. The latter can be tricky because some-times the reachability relationship is established during some setupor initialization phase, which can often be outside of the scope ofa kernel module. An example is thefileordevicestructure thatfrequently appear as the/f_irst argument of a driver‚Äôsioctl()han-dler. Such structures may belong to heap memory and are reachablefrom some global data structures, but such reachability relationshipis set up in the generic kernel as opposed to a speci/f_ic kernel module.Therefore, we simply apply domain knowledge to such functionarguments and label them as taint sources accordingly.(2) One signi/f_icant improvement we made over Dr. Checker isthe pointer arithmetic resolution. Partly due to theO2optimizationlevel, we/f_ind many more pointer arithmetic operations such as*(int*)((char*)p + byte_offset), which is basically equivalenttop->f, wherepis originally a pointer to a structure type whichcontains an integer/f_ieldfat the o"setbyte_offset. Therefore,we analyze the de/f_inition of structures and map a byte o"set to aparticular/f_ield in the structure. With this improvement, we willnot lose track of such points-to relationships. We also handle thewidespread container_of() cases in kernel, where the pointer toa container structure is obtained by subtracting an o"set from apointer to an embedded structure within it. These cases can causedi#culties for a static analysis due to the pointer arithmetic andthe unawareness of the container structure type. We address thisproblem by inferring the container type from the context of thecontainer_of() pointer calculation (e.g.,the resultingchar*pointercan be converted to the actualstruct*type by a later ‚Äúcast‚Äù IR),and then creating the correct container object hosting the originalembedded structure. This way, we can precisely maintain the point-to records.6 EVALUATIONIn this section, we/f_irst describe the experiment setup and vali-dation of the static analysis results in ¬ß6.1. We then present themeasurement results about the prevalence of UDs and the complex-ity involved in analyzing them in ¬ß6.2. Finally, we report the resultsof our root cause analysis to ¬ß6.3.6.1 Experiment Setup and Validation ofMethodologyFuzzing Setup.We pick four Linux kernel driver modules fortesting (from kernel version 4.16) as listed in Table 1. They areall available and compiled based on thedefconfig(default kernelcon/f_iguration), which represents commonly used drivers. There arethree reasons we pick them:Table 1: Description and fuzzing time for each moduleNameSLoC Template size (#lines) Time (hour)cdrom 4.6k 34448snd_seq 14k 27848ptmx 39k 32448kvm 60k 806120FGURPVQGBVHTSWP[NYPFigure 3: Coverage over timeTable 2: Categories of unresolved dependencies and samplecases for manual analysis#DomI#UC #DomI/u1D448/u1D436#SampleA #UD #DomI/u1D448/u1D437#SampleR<112182 10,014 74 1415 7,176 3511 - 100 577 23,553 32 428 17,565 37101 - 190 124 16,885 10 80 11,073 13>190 94 62,448 17 65 39,378 30Sum2977 112,900 135 1988 75,192 115‚Ä¢Compared to the core Linux kernel, driver modules account forthe majority of the kernel code and therefore the attack surfaceas well. There are about 22.7M SLoC for the whole Linux kernelbut 16.4M SLoC (71.9%) of them are device drivers.‚Ä¢As mentioned in ¬ß3, compared to the less tested and less populardrivers, we choose more popular ones that are relatively welltested and have relatively comprehensive Syzkallertemplates. Atthe start of our analysis, there were only 32 drivers with Syzkallertemplates, and 15 of which had well-written templates, whichlimits our choices signi/f_icantly.‚Ä¢We aim to cover di"erent types of Linux device drivers ‚Äî onecharacter device driver:ptmx, one block device driver:cdrom, andone main sub-category of character device driver (miscellaneous):kvm, and one other character device driver that is outside of the/drivers folder:snd_seq.As shown in Table 1, we test each module individually foratleast48 hours, repeated three times. The machine we use to conductfuzzing has an Intel(R) Xeon(R) Gold 6248 CPU and 512GB of RAM,and runs Ubuntu 18.04 LTS. We use 32 CPU cores (in 32 di"erentVMs) when fuzzing a module. We collect the union of coverageachieved in all three fuzzing runs. The fuzzing time is determinedexperimentally based on how long it took for coverage to converge,as will be shown in Figure 3. For example, the coverage ofptmx,snd_seq, andcdromstill improves after 24 hours and we allocate48 hours for them. On the other hand, the coverage ofkvmstillimproves even after the 72-hour mark, which prompts us to allocate120 hours for it. This way, we ensure all the remaining UCs at theend of the fuzzing session will likely represent the limitations ofSyzkaller and its templates.663ICSE ‚Äô22, May 21‚Äì29, 2022, Pi/t_tsburgh, PA, USAYu Hao, Hang Zhang, Guoren Li, Xingyun Du, Zhiyun Qian, and Ardalan Amiri SaniTable 3: Accuracy of static analysisName#UCManual AnalysisStatic Analysis#UD#WS #EWS #UD #FP #FN #WS #FP #FNcdrom 16 11 3.00 1.00 11 9.09% 20.00% 3.00 0.00% 0.00%snd_seq 16 13 3.00 1.00 8 0.00% 60.00% 3.00 5.56% 5.56%ptmx 25 17 7.88 1.75 16 0.00% 20.00% 7.50 0.00% 4.76%kvm 78 45 3.00 1.33 40 0.00% 19.23% 2.94 1.85% 3.70%Sum/Avg 135/- 86/- -/4.08 -/1.33 75/- 1.33% 24.39% -/3.97 1.36% 4.08%Sampled Cases for Manual Analysis.We sample two datasetsfor manual analysis, summarized in Table 2. The/f_irst dataset isto validate the accuracy of our static analysis results. The secondis for the root cause analysis. For the/f_irst dataset, we start fromUCs and manually determine which are in fact UDs. Then we alsoconduct an exhaustive manual search for their corresponding WSs,with the understanding of the semantics of each kernel module (asdiscussed in ¬ß4). Such UDs and their WSs serve as ground truth.To cover a representative set of samples, we categorize the UCsby the number of instructions behind them,i.e.,the instructions(denoted as #DomI) that are dominated by the condition in thesame function (and that there are no other ways to reach themwithout satisfying the condition). A smaller #DomI indicates thatthe condition is likely related to simple error handling, whereas alarger #DomI is related to the functional part of the kernel module.As shown in Table 2, we partition the UCs into four ranges basedon #DomI, from which we then randomly sample #SampleA ofcases. Note that although the/f_irst category (<11) happens the most(#UC), but the aggregated #DomI is the lowest, whereas the lastcategory has fewer UCs but more aggregated #DomI. As a result, weslightly favor the last category as they represent more functionalcode and are generally more worthwhile to test. For the seconddataset, we start directly with UDs (as opposed to UCs), so we caninvestigate their root causes. In total, we randomly sampled 115UDs over di"erent categories as shown under the #SampleR columnin Table 2, favoring the last category even more because resolvingsuch dependencies will unlock more functional code.Accuracy Validation of Static Analysis.From the/f_irst sampleddataset that serves as ground truth, we show the static analysisresults in Table 3. As we can see, since we try our best to optimizeour analysis to avoid exaggerating the UD problem in kernel fuzzing,the overall accuracy is very good. There are a 1.33% false-positiverate and 24.39% false-negative rate with regards to determining ifan UC is an UD. That means that there is likely an underestimateof the dependency issue by our static analysis (as there are morefalse negatives). There are a 1.36% false-positive rate and at leasta 4.08% false-negative rate regarding the WS analysis; note thatthe false-negative rate is a lower bound because we do not claimto have found the complete set of WSs manually for each UD. Inother words, the #WS result overall is also an underestimate.Unreachable Functions Elimination.Our initial observation ofthe fuzzing results indicate that most kernel modules have muchmore code than what we can cover with Syzkaller because of ob-viously unreachable functions. As a result, we prune unreachablefunctions as described later in ¬ß8 because otherwise the percentageof code coverage in the end will look unrealistically small, whichTable 4: Classi/f_ication of unresolved conditionsName#UC#UD#unknown #non-UD#Global#Controlcdrom 16 7 4 2 3snd_seq 16 10 3 2 1ptmx 25 12 5 3 5kvm 78 29 16 24 9Sum135 58 28 31 18Table 5: Prevalence of unresolved dependenciesName #UncoveredE/#E #UD/#UC #DomE/u1D448/u1D437/#DomE/u1D448/u1D436cdrom 615/915 (67%) 37/54 (69%) 80/122 (99%)snd_seq 7355/9255 (79%) 162/274 (59%) 204/356 (57%)ptmx 3541/5105 (69%) 254/289 (88%) 763/830 (92%)kvm 15471/28516(54%) 1554/2050(76%) 4073/5677(72%)Sum 26982/43791(62%) 2007/2667(75%) 5106/8037(73%)may leave us with the wrong impression about the kernel fuzzingperformance.Classi/f_ication of Unresolved Conditions.We now give an overviewof the 135 UCs from the SampleA dataset. Based on our manualcharacterization of these cases, as shown in Table 4, we can dividethem into 86 (58+28) UDs, 18 non-UDs, and 31 unknown cases. Wecan further break down the UD cases into 58 cases where the UD isdirectly a"ected by a global memory and 28 cases where the UDis indirectly a"ected by global memory. The latter cases representUDs where their conditions check the value of a (local) variablewhose value is indirectly decided by global memory through controldependence (as opposed to data dependence). For example,‚Äúif(UD)var=true; if(var)//Uncovered code‚Äù.if(var)is classi/f_ied asUD because the local variablevaris indirectly a"ected byif(UD).For the non-UD cases, they always correspond to conditions whosevalues are in/f_luenced purely by syscall arguments. Finally, for theunknown cases, they represent cases that are di#cult to analyzebecause they require analysis of either the assembly code or codeexternal to the driver module itself. We exclude these unknowncases from our subsequent analysis. Overall, the UD cases repre-sent 86/104 = 83% of the UC cases, indicating that the dependencychallenge is indeed a major hurdle for kernel fuzzing.6.2 Measurement ResultsIn this section, we report (1) static analysis results at scale, and(2) quantitative metrics that show the di#culty of analyzing theseUDs.Prevalence of Unresolved DependenciesThe results are shownin Table 5. The number of total edges (#E) represents the total pos-sible coverage (from one basic block to another) for each module.After taking the union of coverage obtained from three fuzzingruns, we report the remaining uncovered edges (#UncoveredE). Aswe can see, even with all the pruning of unreachable code, there arestill many uncovered edges even after 3√ó48 hours or 3√ó120 hours offuzzing for each module, ranging from 54% to 79% percentage-wise.Out of edges that are never covered, we further look at those withcorresponding conditions that are exercised but never evaluatedto the desired value (i.e.,either true or false). These correspond664Demystifying the Dependency Challenge in Kernel FuzzingICSE ‚Äô22, May 21‚Äì29, 2022, Pi/t_tsburgh, PA, USATable 6: Write statements stats from static analysisName#UDStatic Analysis#WS#WSC #WSE #WSE/#WScdrom 37 1.90 1.45 0.46 24.21%snd_seq 162 3.56 1.03 2.53 71.07%ptmx 254 18.05 5.50 12.54 69.47%kvm 1554 13.51 4.53 8.99 66.54%Sum/Avg 2007/- -/13.25 -/4.36 -/8.90 67.15%to UCs (#UC), which are much smaller than the total number ofuncovered edges, but each of them acts as a guard that preventsmany more subsequent edges from being covered. Out of theseUCs, our static analysis reports on average 75% as UDs (#UD). Eventhough dependency is a known problem, this prevalence of it isstill surprising (keep in mind that the number is likely an underes-timate). According to the breakdown by modules,ptmxandkvmhave the higher #UD. This is expected because the more complex amodule is, the more global states are likely introduced and hencemore dependencies. #DomE/u1D448/u1D436describes the sum of the numberof uncovered edges that are intra-procedurally dominated by theguard conditions (reachable only from the UCs), and #DomE/u1D448/u1D437isthe sum over all the UDs. We choose intra-procedural dominationbecause we do not want to overestimated it. It shows that UDsroughly lock away three quarters of the code.Write Statements.From our static analysis results, we/f_ind thatthe average number of WSs for each UD is about 13, as shownin the #WS column in Table 6. If we look at the number for eachmodule,kvmandptmxexhibit many more WSs. In addition, we/f_ind that sometimes an UD may involve more than one piece ofglobal memory (e.g.,in/f_luenced by multiple global variables), andeach of them may have multiple WSs.The next step in the measurement pipeline is to determine whichWSs are e"ective. As discussed in ¬ß4, this step is very challengingeven with manual analysis. One of the reasons is that these WSsare often writing values determined at runtime (in the form ofexpressions). As Table 6 shows, 67.15% of the written values areexpressions (#WSE) instead of constants (WSC). In the end, asshown in our later manual analysis results in Table 3, we/f_ind thatthe number of EWSs (#EWS) is far smaller than #WS (often only asingle one).The results show that it would be likely an expensive search toexhaustively test every single WS automatically, given that we mayneed to determine the possible values that can be written (whichcan be challenging by itself). This problem is exacerbated when weconsider the recursive nature of dependencies, as will be shownnext.Recursive Dependencies.Whenever a WS cannot be reached byany of the existing test cases attempted by Syzkaller, it is likely thatit may be blocked o"due to additional UDs, leading us to recur-sively analyze more WSs and dependencies. When this happens,the search space can blow up quickly depending on (1) the numberof WSs we have to attempt at each depth level which we know is13 on average and (2) the depth of recursion (di#cult to measure).We measure two approximate metrics to quantify the recursivedependency challenge. First, we/f_ind that on average 35.91% of #WSare uncovered after the fuzzing sessions are done across all fourTable 7: Root causes of unresolved dependenciesName #UD#DeadCode #Environment #Unobserved #Template #Search unknown¬ß6.3.1 ¬ß6.3.2 ¬ß6.3.3 ¬ß6.3.4 ¬ß6.3.5cdrom 7 0 6 1 0 0 0snd_seq 32 16 2 9 2 3 0ptmx 33 12 5 1 5 5 5kvm 43 7 14 0 15 1 6Sum115 35 27 11 22 9 11drivers. This indicates that it requires work to construct a test casebefore we can even verify whether these WSs are feasible. Second,when the WSs are not covered, we/f_ind surprisingly 93.72% of themare due to recursive dependencies based on our static analysis of thedominating conditions.In other words, if a fuzzer has not managedto reach the EWSs after a long fuzzing session, it is almost alwaysnever due to barely missing the opportunity, indicating some morefundamental roadblocks as we will investigate later in ¬ß6.3.Non-self-contained (Unstable) Test Cases.During the processof our manual investigation of root causes, we/f_ind another commonhurdle. That is, the test cases generated by Syzkaller are not self-contained. Speci/f_ically, Syzkaller (or fuzzers based on it) generatesa stream of test cases and executes them, accumulating signi/f_icantkernel state changes as it progresses (until a reboot occurs). Thismeans that the ‚Äúsuccess‚Äù of a test case can be dependent on theprevious ones that may have accidentally set up the kernel state,e"ectively making these test cases non-self-contained or ‚Äúunstable‚Äù.This is important for our manual investigation because we rely onthe test cases generated by Syzkaller to reproduce the results,e.g.,if a test case is reported to reach some UD, we will re-execute thetest case and hope that it will still be able to, otherwise we have toput more e"ort in the steps mentioned in ¬ß4. Unfortunately, a largefraction of test cases that were previously able to reach UDs andWSs become unstable when tested later in isolation (average 97%and 46% respectively). This is another reason why manual analysiscan be expensive, as we need to reconstruct the state which canhelp us understand the root cause of the unresolved dependency.6.3 Analysis of Root CausesOverall, it took about 300 person-hours, with the help of all the re-sults produced by automated analysis in the measurement pipeline,in order for us to be con/f_ident about the correctness of our results.Even then, there are a few cases where we cannot determine theroot causes even after hours of investigation. This means that wecannot either construct a test case that can resolve the dependencyor prove that it is impossible. Given the level of di#culty in con-ducting such an analysis, we will publicly share the datasets, whichwe believe is valuable to researchers who aim to improve kernelfuzzing.Overall, we distill and summarize the root causes into six cat-egories (and an unknown category). The results are presented inTable 7. We next describe them one by one.6.3.1 Dead Code.The amount of dead code in a large complexpiece of software such as Linux is a mystery. From our results, weare surprised to see a substantial portion of the UDs (35/115) turnout to lead to dead code, representing almost 30% of UDs. In other665ICSE ‚Äô22, May 21‚Äì29, 2022, Pi/t_tsburgh, PA, USAYu Hao, Hang Zhang, Guoren Li, Xingyun Du, Zhiyun Qian, and Ardalan Amiri Sani1static struct snd_seq_queue *queue_list[SNDRV_SEQ_MAX_QUEUES];2static intseq_free_client1(...) {3snd_seq_queue_client_leave(client->number);4snd_seq_queue_client_termination(client->number);5}6voidsnd_seq_queue_client_leave(intclient) {7for(i = 0; i < SNDRV_SEQ_MAX_QUEUES; i++) {8if((q = queue_list_remove(i, client)) != NULL)9queue_delete(q);10}11}12voidsnd_seq_queue_client_termination(intclient) {13for(i = 0; i < SNDRV_SEQ_MAX_QUEUES; i++) {14if((q = queueptr(i)) == NULL)15continue;16spin_lock_irqsave(&q->owner_lock, flags);17if(q->owner == client)18// Uncovered branch19q->klocked = 1;20spin_unlock_irqrestore(&q->owner_lock, flags);21if(q->owner == client){22// Uncovered branch23if(q->timer->running)24snd_seq_timer_stop(q->timer);25snd_seq_timer_reset(q->timer);26}27queuefree(q);28}29}Figure 4: Case of dead codewords, it is simply impossible to reach these uncovered branchesbehind UDs no matter how hard we try. The best thing fuzzerscan do it to recognize them and avoid wasting time trying to coverthem.Dead code is a well known issue and compilers routinely per-form dead code elimination [5,9]. We suspect that the reason whycompilers fail to identify them is due to the nature of UDs requiringthe analysis of global memory (beyond a local context). For exam-ple, we/f_ind a function may double check the existence of certainelements in a global queue right after its caller removes them (theexample is available in the uploaded dataset, among other exam-ples). To get further con/f_irmation, we reported the case to Linuxkernel developers and they have agreed with our assessment andeliminated the dead code subsequently. Even though we have notreported all the cases to Linux, we exercise the same rigor acrossall the dead code cases.Interestingly, exceptcdrom, all other kernel modules have asubstantial fraction of dead code cases out of their UDs. Forsnd_seq,half of its UDs are surprisingly dead code (16 cases out of 32). Inaddition, we are curious to see whether the dead code cases onlyrepresent small pieces of code (e.g.,redundant error checks). Ingeneral, the data are indeed in line with the hypothesis, especiallygiven the way these cases are sampled (shown in Table 2). However,there is still a substantial fraction of counterexamples. Followingthe categorization in Table 2, we/f_ind 18 out of the 35 dead codecases have only a small number of dominated instructions in thesame function (<11). However, the remaining 17 cases are spreadout: 10 cases with11-100dominated instructions, 4 cases with101-190dominated instructions, and 3 cases with>190dominatedinstructions.We give a fairly complex dead code example that we manually de-termined in Figure 4. There are two unresolved dependencies (line17 with 23 uncovered instructions and line 21 with 61 uncovered1static intcdrom_read_cdda(...) {2if(cdi->cdda_method == CDDA_OLD)3// Uncovered branch4... }5intregister_cdrom(structcdrom_device_info *cdi) {6if(cdi->disk)c d i - > c d d a _ m e t h o d=C D D A _ B P C _ F U L L ;7elsecdi->cdda_method = CDDA_OLD;// Uncovered branch8... }9static intide_cd_probe(...) {10if(drive->media != ide_cdrom)gotofailed;11devinfo ->disk = info->disk;12register_cdrom(devinfo); ... }13static intprobe_gdrom(...) {14if(gdrom_execute_diagnostic()!=1)return-ENODEV;15register_cdrom(gd.cd_info); ... }Figure 5: Case of environment dependencyinstructions). Based on the control/f_low graph and data/f_low graph,it does not seem like the uncovered branches of line 18-19 and line22-25 are dead code. However, if we look at the call graph, we can/f_ind that the only caller of the functionsnd_seq_queue_client_termination()is the functionseq_free_client1()that callsthe functionsnd_seq_queue_client_leave()before the func-tionsnd_seq_queue_client_termination(). What the functionsnd_seq_queue_client_leave()does is to remove all the ele-ments in global queues if their client IDs are equal toclient->number(see line 3). Interestingly, functionsnd_seq_queue_client_termination()goes through the same global queues to look forelements that have a speci/f_ic client ID (againclient->numberasshown in line 4). This will obviously lead both conditions at 17and 21 to always evaluating to false. To get further con/f_irmation,we reported this case to Linux kernel developers and they haveagreed with our assessment and eliminated the dead code subse-quently. Even though we have not reported all the cases to Linux,we exercise the same rigor across all the dead code cases.6.3.2 Environment Dependency.We/f_ind that oftentimes an UDmay depend on the con/f_iguration of and values from the executionenvironment (e.g.,hardware). If the underlying execution environ-ment is not the expected type or returns the expected result, adependency will not be resolved. Note that we do attempt to prunecode that obvious cannot be reached because of environment de-pendency (see ¬ß8). Nevertheless, our heuristics only focused onfunction pointers which point to di"erent targets depending onthe underlying execution environment. Other than those, we/f_indthere are still many other cases (most are much smaller) that arenot excluded earlier. An analysis that could automatically recognizethem would be helpful so users of fuzzer can tune the con/f_iguration.We show an example in Figure 5, where the UD iscdi ->cdda_method == CDDA_OLD(line 2). We/f_ind the EWScdi ->cdda_method = CDDA_OLD(line 7), which is not covered because ofyet another UDif (cdi->disk)(line 6). The value ofcdi->diskis decided by the caller ofregister_cdrom(), which can be eitheride_cd_probe()(line 9) orprobe_gdrom()(line 13). These twofunctions check the type of the hardware device, and either writestodevinfo->disk(line 11) or does not. We omit a few other devicetypes and the exact hardware read functions for brevity. Only if wehave the correct hardware device present (in this case a GDROM,not CDROM), will we reach line 7 and in turn line 3.666Demystifying the Dependency Challenge in Kernel FuzzingICSE ‚Äô22, May 21‚Äì29, 2022, Pi/t_tsburgh, PA, USA1static structsnd_seq_client*clienttab[SNDRV_SEQ_MAX_CLIENTS];2static intopen(*file) {3clienttab[client->number] =client;4client->type = USER_CLIENT;5file->private_data =client;}6static longioctl(*file, cmd, arg) {7*client=f i l e - > p r i v a t e _ d a t a ;8snd_seq_ioctl_create_port(client);... }9static intsnd_seq_ioctl_create_port(...) {10if(client->type == KERNEL_CLIENT)11// Uncovered branch12... }13intsnd_seq_create_kernel_client(...) {14client->type = KERNEL_CLIENT;15returnclient ->number; }16int__initsnd_seq_system_client_init()){17sysclient=s n d _ s e q _ c r e a t e _ k e r n e l _ c l i e n t ( N U L L , 0 ,!System!);18snd_seq_ioctl_create_port(sysclient);... }19module_init(alsa_seq_init)Figure 6: Case of unobserved dependency (moduleinit)In total, we identify 27 such cases as shown in Table 7, whichrepresent almost a quarter of all UDs. Among them, we/f_ind that 18are about reading the hardware type or property (nine in moduleinitfunctions, and nine in syscalls, a special situation here isnested guests inkvm, which counts six cases). Six of them attemptto read something that can change at runtime. The remaining threeare undetermined.6.3.3 (Partially) Unobserved Dependency.This is an interestingcategory (although rare in our investigation) related to the designof Syzkaller where certain functions are simply not in the scope ofthe fuzzer. For example, any code that occurs in the moduleinitorexitfunctions, or the bottom-half processing [27] are not trackedby Syzkaller. This means that any code that is reachable from eithercategory of functions will never be covered (even if they do getexecuted). This is because such coverage cannot be attributed to aspeci/f_ic test case. This leads to a variety of problems.First, this can lead to incorrect accounting of UDs. Speci/f_ically,some functions can be reachable from both syscall entry points andthe above categories. We/f_ind that it is possible that such functionshave UDs during syscall fuzzing, but in reality the dependency is infact resolved during these other unobserved execution paths (frominit/exitor bottom-half). For example,snd_seq_create_kernel_client()in Figure 6 contains the only EWS (line 14) for theUD (line 10), and is only called by themodule initfunction, (i.e.,__init alsa_seq_initat line 19). When the UD is reached fromsyscalls,i.e.,ioctl(), the kernel stateclient->typealways takesthe value ofUSER_CLIENT, which is set by the WS at line 4 inopen(). Obviously, this will lead the Syzkaller to think that it isunresolved. There are two cases in total that can be essentiallyconsidered resolved dependencies.Second, because Syzkaller was not aware of functions relatedto theinit/exitand bottom half, it also does not have the abilityto schedule them during fuzzing. This leads to EWSs that are in-voked only sporadically (in the case of the bottom half) or onlyat the module load time or unload time. For example, the mod-ule init may initialize some kernel state to an expected value (byan EWS). However, Syzkaller may/f_irst schedule test cases thataccidentally overwrite the expected value before the UD is evenseen. We/f_ind nine such cases where the only EWSs are located in
	
	 !"#!$%!#&%! !' ( !)*'+,	

		
-. !"#!/&0 &+
12332	24		5	6
,7


8-8

23
	9:,;<1<.0-8
=>?
2
<	@38<=>?<,=>?
2
<	@38$	A?5	4?	9=>?:8.-0=>	B4628
1<3
	5=>C+1.D&
	E
	D%2	DD*
		D@	/	D/D/D%
6,7<=>	F1!&G'H!/ '#1.CC=>C+1.DD=>C&
	E
	,6
	8;-&
			-	242	
	
	<3
I
	
	<3
I
Figure 7: Case of unresolved dependency because of incom-plete templatesinit/exitfunctions or the bottom half. There are two cases underthis category where the dependencies are not triggerable.As we can see, this is highly dependent on the kernel mod-ules. Even though rare overall, they do constitute a non-negligibleportion of the cases incdrom(14.29%) andsnd_seq(28.13%). Weanticipate seeing many more cases of bottom-half processing inmodules with frequent external interactions,e.g.,audio, camera,and network drivers.6.3.4 Incomplete Templates.The root causes introduced thus farare outside of the control of a fuzzer (e.g.,dead code and envi-ronment dependencies). Now we move on to the root causes thattechnically fall under the scope of Syzkaller. Speci/f_ically, we men-tioned that Syzkaller relies on templates that encode the knowledgeabout the syscall interface for each kernel module. The qualityof templates has a direct impact on the fuzzing performance, asthe test cases are generated based on the templates. Even thoughthe templates are already comprehensive, as suggested by theirsizes shown in Table 1, from our analysis, we discover a variety ofde/f_iciencies. This can include missing knowledge about syscall rela-tionships, argument types and ranges, etc., which result in failuresto reach otherwise reachable EWSs. Basically, if an UD can be re-solved clearly with an amended template, it belongs to this category.Overall, our manual investigation reports 22 cases under this cate-gory (#Template) as shown in Table 7. This represents the largestcategory of root causes that will allow coverage improvement byresolving more dependencies.Most cases belong tokvm, which is the most complex piece ofkernel module out of the four we analyze. An example is shown inFigure 7. The UD is at line 17, and we locate the EWSs at line 15.As we can see, the value of thectxt->dis determined by anothervariableopcode.flags, which is in turn determined by the WSopcode = twobyte_table[ctxt->b]at line 13. Finally, we knowthat the data (an instruction bu"er) referenced byuserspace_addr(which is a pointer/f_ield in an argument of the syscall at line 3) candecide the value ofctxt->b. However, the template in Syzkallerdoes not correctly describe what the bu"er should look like. Inorder to resolve the dependency, a test case would need a speci/f_icsequence of instructions in the bu"er as described in lines 8 and 9.Unfortunately, Syzkaller is simply not aware of the desirable bytesequences. In total, we/f_ind about 11 cases that are similar to thisexample inkvmmodules.667ICSE ‚Äô22, May 21‚Äì29, 2022, Pi/t_tsburgh, PA, USAYu Hao, Hang Zhang, Guoren Li, Xingyun Du, Zhiyun Qian, and Ardalan Amiri SaniThere are also similar but simpler examples where a single ar-gument needs to take a magic number, much like what commonlyoccurs in userspace programs. In the kernel modules we analyzed,we observe eight such cases.In addition, we observe that the templates can also miss explicitdependencies. Across the four drivers though, there is only a singlecase we/f_ind inkvm. This con/f_irms our assertion that the templateswritten for these four drivers are already relatively comprehensive.6.3.5 Specialized Search Requirement.Finally, there are a few casesthat need a more specialized search algorithm that is beyond thecapability of a general-purpose fuzzer. Our manual analysis/f_inds 9cases related to the search algorithm (#Search) out of 115 in Table 7.‚Ä¢Interleaving of Multiple Threads:In order for the UD to readthe expected value, sometimes a race condition is required. Inother words, a speci/f_ic thread interleaving has to occur in orderfor the value written by the EWS to be exposed. If the windowof opportunity is small, it is highly unlikely that Syzkaller willbe able to resolve the dependency. In total, we/f_ind six cases.‚Ä¢Speci/f_ic Sequence of syscalls:Some EWSs need multiple itera-tions to successfully change the kernel state to the desired value(e.g.,++i). This means that one needs to repeatedly invoke one ormore syscalls that contain the EWSs to resolve the dependency.In total, we/f_ind three cases related to the sequence of syscalls.7 FUTURE RESEARCH DIRECTIONSFrom the previous results, we have shown that UDs are a prominentreason for uncovered code in kernel fuzzing. We also show theyare challenging to resolve due to a diverse set of root causes. In thissection, based on the insights we gained from our measurement,we summarize two main future research directions that have topromise to overcome these challenges.Open Problem: Cross-Syscall Input Propagation Analysis.As reported in ¬ß6.3.4, 19% of the UDs are actually the result ofimperfect templates (missing certain syscall argument knowledge).This means that once the templates are amended, the dependenciescan be potentially resolved (and we verify that it is indeed the casewith experiments). In this section, we propose a new analysis thattracks the propagation of a syscall input argument across syscallinvocations.We wish to point out this is a unique type of dependency becausethe WS always writes a value speci/f_ied in a syscall argument. If weblindly target any dependency without understanding its uniquepattern, it is unclear what we should do to resolve them. For exam-ple, one can attempt a whitebox approach similar to HFL [19] tolocate the write and read pairs regarding the same global memory.However, as we showed in our measurement (see ¬ß6.2), there aretypically several possible WSs and it is unclear which one is theEWS. This is likely why HFL has focused on only explicit depen-dencies where typically there is only one WS. To understand howthis general direction will work in practice, we actually developeda failed solution (prior to having the full insight from our measure-ment study) that attempts to collect all the write syscalls duringfuzzing, and then pair them up with the read syscalls. The resultsshow that whatever implicit dependencies that we are able to re-solve in this solution, Syzkaller can also resolve them, in most caseseven quicker. This is a good indication that Syzkaller is actuallyalready sophisticated enough in terms of its algorithmics. As long asthe templates have encoded su#cient knowledge regarding syscallsand argument types and possible values, given su#cient fuzzingtime, Syzkaller will be able to resolve the implicit dependencies thatare ‚Äúcovered‚Äù by the templates. Unfortunately, it does not resolvethe hard dependencies such as those that are reported in our re-sults. This is because we simply do not have the knowledge of whatcorrect syscall arguments to supply (not given in syscall templates)in order for the WS to write the expected value. Thanks to ourmeasurement insight as shown in ¬ß6.3.4, we know that 19 cases outof 22 are due to incomplete descriptions of syscall arguments.Secondly, we observe that more than half of such inputs (11cases) are not processed immediately in a single syscall invocation.Instead, they are stored in some global memory in one syscall, andthen used in another syscall invocation. If we analyze the syscallwhere the use happens, oftentimes they look just like a magicnumber check (if(g_array[0] == MAGIC_NUM), which should betheoretically easy to resolve (e.g.,through symbolic execution). Nev-ertheless, these magic number checks are performed against theglobal memory (to make which symbolic directly is meaningless)rather than syscall inputs. Those cases would become solvable ifthere is a cross-syscall input propagation analysis (in the form ofeither static or symbolic) which could/f_ind the related inputs. Wehave leveraged our static taint analysis developed for the measure-ment and found that indeed such cross-syscall propagations canbe identi/f_ied. They have resulted in us identifying four missingdescriptions in the templates (two of which have been/f_ixed in alater version of Syzkaller). Therefore, we believe a cross-syscallinput propagation analysis is an e"ective method to resolve suchcomplex dependencies.Open Problem: Multi-Interface Fuzzing.As we discussed in¬ß6.3.3, we show that many dependencies can be resolved only whenwe consider the interfaces that are not out of the scope of Syzkaller(i.e.,unobserved). We have given two speci/f_ic categories of inter-faces including hardware-side input and the moduleinit/exitfunctions. We have mentioned that the latter should be included aspart of the syscall fuzzing interface. On the other hand, hardware-side input has been considered in recent works [26, 28, 33].We wish to point out that this is a very di"erent problem from thecurrent hardware-side fuzzers such as USBFuzz [26] and Franken-stein (Bluetooth fuzzing) [28], which focus primarily on the attacksurface from the hardware side only. This is understandable becausethese drivers do process complex inputs from the hardware (in ad-dition to those from syscalls). Nevertheless, from the insight gainedfrom our measurement, we show syscall fuzzing and hardware-side fuzzing can be intertwined. That is, in order to make furtherprogress in syscall fuzzing (i.e.,covering certain branches), we ac-tually need proper hardware-side input to arrive at the right timeto write to the global memory with the expected value. To general-ize this observation, conversely, when performing hardware-sidefuzzing, we might encounter dependencies that can be resolved bysyscall inputs only (e.g.,putting the device into certain states bysyscalls).We frame the goal as multi-interface fuzzing as it needs to coor-dinate the inputs from multiple di"erent types of interfaces (e.g.,inputs from syscall and hardware side can be interleaved). We be-lieve this is a worthwhile research direction as the bugs that are668Demystifying the Dependency Challenge in Kernel FuzzingICSE ‚Äô22, May 21‚Äì29, 2022, Pi/t_tsburgh, PA, USAuncovered this way are likely hidden deeply in some di#cult-to-reach driver states.8 DISCUSSION AND LIMITATIONLimited Data Set Scale.In this paper, we delve into four spe-ci/f_ic Linux kernel modules to investigate the dependency challenge.Even though we believe they are representative of kernel modulesof varying type and size, their functionalities may not be diverseenough to cover other modules such as GPU drivers, network mod-ules,/f_ile systems, etc.. Nevertheless, based on our observation, thedistilled dependency challenges do appear general enough for otherdrivers. In the future, we plan to pick more modules and charac-terize their di"erences in terms of their respective dependencychallenges. In addition, much of the analysis is conducted manuallywhich is hard to scale. Nevertheless, we plan to expand the analysise"ort as future work to improve kernel fuzzing.Unreachable Functions Elimination.As we mentioned in ¬ß6.1,we prune as much unreachable functions as we can. Speci/f_ically, weprune two types of unreachable functions: (1) interrupt handlingrelated functions that can not be reached from userspace, and (2)functions that are reachable only when certain hardware environ-ment is present. For the/f_irst case, based on the call graph generatedduring static analysis, we prune all the functions that cannot bereached from syscall entry points,e.g.,ioctl(). To account forpotential inaccuracies in call graphs (due to indirect calls), we applya known type-based method [6] to conservatively generate callgraphs,i.e.,as long as the signature of the function pointer is com-patible with that of a target function, we will consider it a validtarget. This method guarantees that all potential targets will bediscovered and no functions will be incorrectly pruned (this methodis commonly used to enforce control-/f_low integrity [6]). The secondcase turns out to be much more challenging as hardware-dependentcode can be scattered throughout a module. As a/f_irst order approx-imation, we inspect all function pointers and their potential targetsand look for cases where the target is dependent on the underlyinghardware environment. A major example is thesvmpart of thekvmmodule, which is dedicated to AMD CPUs, containing 2,889 basicblocks. In total, the two methods can prune about 33% of edgesacross modules on average.Accuracy and Bene/f_it of Manual Analysis.Our measurementstudies heavily relied on the manual analysis to identify the rootcauses of dependencies. This is a non-trivial task because everydependency may look di"erent and unique in certain aspects. Toensure that we do a good job, we not only look at the UDs them-selves. Instead, we read the overall structure of the whole kernelmodule to understand its design in a big picture, which allows us tomake an accurate assessment of the root causes. Unfortunately, it isvery much di#cult to replace our manual analysis with automatedprogram analysis, which means fuzzer can not resolve those hardproblems automatically like humans. However, fuzzers have theirown ways that conduct a ‚Äúrandom‚Äù search for test cases in a givenscope. And the root causes from manual analysis can help eitherset up the fuzzing scope or o"er better search.Generalization to general software fuzzingWe aim not to over-claim our/f_indings beyond kernel fuzzing, as the OS kernel is animportant class of software that deserves attention by itself. Never-theless, we believe that fuzzing stateful and multi-entry programs,especially device drivers, will likely encounter similar challenges,although the distribution of the root causes might di"er.9 RELATED WORKLinux Kernel Fuzzing.In recent years, there is a plethora ofresearch on improving kernel fuzzing with the goal of achievingmore coverage and/f_inding more bugs. kAFL [30] supports x86based kernels and speeds up fuzzing by hardware-assisted feedback.Razzer [17] leverages static and dynamic analysis techniques to/f_ind race bugs through fuzzing. There are also tools built on fuzzingspeci/f_ic Linux kernel subsystems, including/f_ile systems [20], devicedrivers (by mutating hardware inputs) [33], and hypervisors [29].The work [31] deploys fuzzing to the enterprise-level Linux kernel.Nevertheless, few address the dependency challenge directly.Stateful Fuzzers.There are some stateful fuzzers which try toconsider states during fuzzing, for user space programs, particularlynetwork protocols. RESTler [1] uses a lightweight static analysisto explore service states of REST API. And the work [12] tries toinvestigate how to extend stateful REST API fuzzing (e.g.,RESTler)in general. SPFuzz [32] uses the knowledge from the RFC to help thefuzzing. SNOOZE [2] needs humans to de/f_ine the states of protocolsto assist fuzzing. Steelix [22] uses program-state, which includescoverage information and comparison progress information, toguide fuzzing. The work [8] improves fuzzing of TLS by analyzingits state machine, which again requires signi/f_icant manual e"ort.The work [34] generates test cases for a compiler when there arewell-de/f_ined syntax and non-trivial semantics.Static Taint Analysis on Linux kernels.There are several statictaint (or data/f_low) analysis tools against Linux kernel source. Dr.Checker [23], UBITect [36] and K-miner [11] are based on theLLVM framework [21] and are all open source. PacketGuardian [3]is another one based on CIL [24]. Dr. Checker best suits our needand our static analyzer is built on top of it.10 CONCLUSIONIn conclusion, we have conducted an in-depth investigation ofthe dependency challenge in kernel fuzzing, using a combinationof static and manual analysis. With a comprehensive set of data,we demonstrate the challenges when analyzing the unresolveddependencies in Linux kernel. In addition, we distill the root causesof unresolved dependencies. Finally, we reveal many unexpectedobservations and point to new research directions that will improvekernel fuzzing.ACKNOWLEDGMENTSThis work was supported in part by the US National Science Foun-dation (NSF) grants CNS-1953933 and CNS-1953932.DATA AVAILABILITYSource code and datasets related to this article can be found athttps://www.doi.org/10.5281/zenodo.5348989 and https://www.doi.org/10.5281/zenodo.5441138.669ICSE ‚Äô22, May 21‚Äì29, 2022, Pi/t_tsburgh, PA, USAYu Hao, Hang Zhang, Guoren Li, Xingyun Du, Zhiyun Qian, and Ardalan Amiri SaniREFERENCES[1]Vaggelis Atlidakis, Patrice Godefroid, and Marina Polishchuk. 2019. RESTler:stateful REST API fuzzing. InProceedings of the 41st International Conference onSoftware Engineering, ICSE 2019, Montreal, QC, Canada, May 25-31, 2019, Joanne M.Atlee, Tev/f_ik Bultan, and Jon Whittle (Eds.). IEEE / ACM, 748‚Äì758. https://doi.org/10.1109/ICSE.2019.00083[2]Greg Banks, Marco Cova, Viktoria Felmetsger, Kevin C. Almeroth, Richard A.Kemmerer, and Giovanni Vigna. 2006. SNOOZE: Toward a Stateful NetwOrkprOtocol fuzZEr. InInformation Security, 9th International Conference, ISC 2006,Samos Island, Greece, August 30 - September 2, 2006, Proceedings (Lecture Notes inComputer Science, Vol. 4176), Sokratis K. Katsikas, Javier L√≥pez, Michael Backes,Stefanos Gritzalis, and Bart Preneel (Eds.). Springer, 343‚Äì358. https://doi.org/10.1007/11836810_25[3]Qi Alfred Chen, Zhiyun Qian, Yunhan Jack Jia, Yuru Shao, and Zhuoqing Mor-ley Mao. 2015. Static Detection of Packet Injection Vulnerabilities: A Case forIdentifying Attacker-controlled Implicit Information Leaks. InProceedings of the22nd ACM SIGSAC Conference on Computer and Communications Security, Denver,CO, USA, October 12-16, 2015, Indrajit Ray, Ninghui Li, and Christopher Kruegel(Eds.). ACM, 388‚Äì400. https://doi.org/10.1145/2810103.2813643[4]Weiteng Chen, Yu Wang, Zheng Zhang, and Zhiyun Qian. 2021. SyzGen: Au-tomated Generation of Syscall Speci/f_ication of Closed-Source macOS Drivers.InProceedings of ACM SIGSAC Conference on Computer and CommunicationsSecurity CCS.[5]Yih-Farn Chen, Emden R. Gansner, and Eleftherios Koutso/f_ios. 1997. A C++ DataModel Supporting Reachability Analysis and Dead Code Detection. InSoftwareEngineering - ESEC/FSE ‚Äô97, 6th European Software Engineering Conference HeldJointly with the 5th ACM SIGSOFT Symposium on Foundations of Software Engi-neering, Zurich, Switzerland, September 22-25, 1997, Proceedings (Lecture Notes inComputer Science, Vol. 1301), Mehdi Jazayeri and Helmut Schauer (Eds.). Springer,414‚Äì431. https://doi.org/10.1007/3-540-63531-9_28[6]Clang. 2021.Control Flow Integrity Design Documentation. https://clang.llvm.org/docs/ControlFlowIntegrityDesign.html[7]Jake Corina, Aravind Machiry, Christopher Salls, Yan Shoshitaishvili, ShuangHao, Christopher Kruegel, and Giovanni Vigna. 2017. DIFUZE: Interface AwareFuzzing for Kernel Drivers. InProceedings of the 2017 ACM SIGSAC Conferenceon Computer and Communications Security, CCS 2017, Dallas, TX, USA, October 30- November 03, 2017, Bhavani M. Thuraisingham, David Evans, Tal Malkin, andDongyan Xu (Eds.). ACM, 2123‚Äì2138. https://doi.org/10.1145/3133956.3134069[8]Joeri de Ruiter and Erik Poll. 2015. Protocol State Fuzzing of TLS Implementations.In24th USENIX Security Symposium, USENIX Security 15, Washington, D.C., USA,August 12-14, 2015, Jaeyeon Jung and Thorsten Holz (Eds.). USENIX Associa-tion, 193‚Äì206. https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/de-ruiter[9]Saumya K. Debray, William S. Evans, Robert Muth, and Bjorn De Sutter. 2000.Compiler techniques for code compaction.ACM Trans. Program. Lang. Syst.22, 2(2000), 378‚Äì415. https://doi.org/10.1145/349214.349233[10]LTP developers. [n.d.].Linux Testing Project. https://linux-test-project.github.io[11]David Gens, Simon Schmitt, Lucas Davi, and Ahmad-Reza Sadeghi. 2018. K-Miner: Uncovering Memory Corruption in Linux. In25th Annual Network andDistributed System Security Symposium, NDSS 2018, San Diego, California, USA,February 18-21, 2018. The Internet Society. http://wp.internetsociety.org/ndss/wp-content/uploads/sites/25/2018/02/ndss2018_05A-1_Gens_paper.pdf[12]Patrice Godefroid, Bo-Yuan Huang, and Marina Polishchuk. 2020. Intelligent RESTAPI data fuzzing. InESEC/FSE ‚Äô20: 28th ACM Joint European Software EngineeringConference and Symposium on the Foundations of Software Engineering, VirtualEvent, USA, November 8-13, 2020, Prem Devanbu, Myra B. Cohen, and ThomasZimmermann (Eds.). ACM, 725‚Äì736. https://doi.org/10.1145/3368089.3409719[13] google. 2021.ClusterFuzz. https://github.com/google/clusterfuzz[14] google. 2021.syzbot. https://syzkaller.appspot.com/upstream[15] google. 2021.syzkaller. https://github.com/google/syzkaller[16]HyungSeok Han and Sang Kil Cha. 2017. IMF: Inferred Model-based Fuzzer. InProceedings of the 2017 ACM SIGSAC Conference on Computer and CommunicationsSecurity, CCS 2017, Dallas, TX, USA, October 30 - November 03, 2017, Bhavani M.Thuraisingham, David Evans, Tal Malkin, and Dongyan Xu (Eds.). ACM, 2345‚Äì2358. https://doi.org/10.1145/3133956.3134103[17]Dae R. Jeong, Kyungtae Kim, Basavesh Shivakumar, Byoungyoung Lee, and InsikShin. 2019. Razzer: Finding Kernel Race Bugs through Fuzzing. In2019 IEEESymposium on Security and Privacy, SP 2019, San Francisco, CA, USA, May 19-23,2019. IEEE, 754‚Äì768. https://doi.org/10.1109/SP.2019.00017[18] kernel. 2020.kcov.[19]Kyungtae Kim, Dae R. Jeong, Chung Hwan Kim, Yeongjin Jang, Insik Shin, andByoungyoung Lee. 2020. HFL: Hybrid Fuzzing on the Linux Kernel. InProceedings2020 Network and Distributed System Security Symposium. Internet Society, SanDiego, CA. https://doi.org/10.14722/ndss.2020.24018[20]Seulbae Kim, Meng Xu, Sanidhya Kashyap, Jungyeon Yoon, Wen Xu, and TaesooKim. 2019. Finding semantic bugs in/f_ile systems with an extensible fuzzingframework. InProceedings of the 27th ACM Symposium on Operating SystemsPrinciples, SOSP 2019, Huntsville, ON, Canada, October 27-30, 2019, Tim Brecht andCarey Williamson (Eds.). ACM, 147‚Äì161. https://doi.org/10.1145/3341301.3359662[21]Chris Lattner and Vikram S. Adve. 2004. LLVM: A Compilation Framework forLifelong Program Analysis & Transformation. In2nd IEEE / ACM InternationalSymposium on Code Generation and Optimization (CGO 2004), 20-24 March 2004,San Jose, CA, USA. IEEE Computer Society, 75‚Äì88. https://doi.org/10.1109/CGO.2004.1281665[22]Yuekang Li, Bihuan Chen, Mahinthan Chandramohan, Shang-Wei Lin, Yang Liu,and Alwen Tiu. 2017. Steelix: program-state based binary fuzzing. InProceedingsof the 2017 11th Joint Meeting on Foundations of Software Engineering, ESEC/FSE2017, Paderborn, Germany, September 4-8, 2017, Eric Bodden, Wilhelm Sch√§fer,Arie van Deursen, and Andrea Zisman (Eds.). ACM, 627‚Äì637. https://doi.org/10.1145/3106237.3106295[23]Aravind Machiry, Chad Spensky, Jake Corina, Nick Stephens, ChristopherKruegel, and Giovanni Vigna. 2017. DR. CHECKER: A Soundy Analysis forLinux Kernel Drivers. In26th USENIX Security Symposium, USENIX Security 2017,Vancouver, BC, Canada, August 16-18, 2017, Engin Kirda and Thomas Ristenpart(Eds.). USENIX Association, 1007‚Äì1024. https://www.usenix.org/conference/usenixsecurity17/technical-sessions/presentation/machiry[24]George C. Necula, Scott McPeak, Shree Prakash Rahul, and Westley Weimer. 2002.CIL: Intermediate Language and Tools for Analysis and Transformation of CPrograms. InCompiler Construction, 11th International Conference, CC 2002, Heldas Part of the Joint European Conferences on Theory and Practice of Software, ETAPS2002, Grenoble, France, April 8-12, 2002, Proceedings (Lecture Notes in ComputerScience, Vol. 2304), R. Nigel Horspool (Ed.). Springer, 213‚Äì228. https://doi.org/10.1007/3-540-45937-5_16[25]Shankara Pailoor, Andrew Aday, and Suman Jana. 2018. MoonShine: Opti-mizing OS Fuzzer Seed Selection with Trace Distillation. In27th USENIX Se-curity Symposium, USENIX Security 2018, Baltimore, MD, USA, August 15-17, 2018,William Enck and Adrienne Porter Felt (Eds.). USENIX Association, 729‚Äì743.https://www.usenix.org/conference/usenixsecurity18/presentation/pailoor[26]Hui Peng and Mathias Payer. 2020. USBFuzz: A Framework for Fuzzing USB Dri-vers by Device Emulation. In29th USENIX Security Symposium, USENIX Security2020, August 12-14, 2020, Srdjan Capkun and Franziska Roesner (Eds.). USENIXAssociation, 2559‚Äì2575. https://www.usenix.org/conference/usenixsecurity20/presentation/peng[27]Alessandro Rubini and Jonathan Corbet. 2001.Linux device drivers. " O‚ÄôReillyMedia, Inc.".[28]Jan Ruge, Jiska Classen, Francesco Gringoli, and Matthias Hollick. 2020. Franken-stein: Advanced Wireless Fuzzing to Exploit New Bluetooth Escalation Tar-gets. In29th USENIX Security Symposium, USENIX Security 2020, August 12-14,2020, Srdjan Capkun and Franziska Roesner (Eds.). USENIX Association, 19‚Äì36.https://www.usenix.org/conference/usenixsecurity20/presentation/ruge[29]Sergej Schumilo, Cornelius Aschermann, Ali Abbasi, Simon W√∂rner, andThorsten Holz. 2020. HYPER-CUBE: High-Dimensional Hypervisor Fuzzing.In27th Annual Network and Distributed System Security Symposium, NDSS2020, San Diego, California, USA, February 23-26, 2020. The InternetSociety. https://www.ndss-symposium.org/ndss-paper/hyper-cube-high-dimensional-hypervisor-fuzzing/[30]Sergej Schumilo, Cornelius Aschermann, Robert Gawlik, Sebastian Schinzel,and Thorsten Holz. 2017. kAFL: Hardware-Assisted Feedback Fuzzing for OSKernels. In26th USENIX Security Symposium, USENIX Security 2017, Vancouver, BC,Canada, August 16-18, 2017, Engin Kirda and Thomas Ristenpart (Eds.). USENIXAssociation, 167‚Äì182. https://www.usenix.org/conference/usenixsecurity17/technical-sessions/presentation/schumilo[31]Heyuan Shi, Runzhe Wang, Ying Fu, Mingzhe Wang, Xiaohai Shi, Xun Jiao,Houbing Song, Yu Jiang, and Jiaguang Sun. 2019. Industry practice of coverage-guided enterprise Linux kernel fuzzing. InProceedings of the ACM Joint Meetingon European Software Engineering Conference and Symposium on the Foundationsof Software Engineering, ESEC/SIGSOFT FSE 2019, Tallinn, Estonia, August 26-30,2019, Marlon Dumas, Dietmar Pfahl, Sven Apel, and Alessandra Russo (Eds.).ACM, 986‚Äì995. https://doi.org/10.1145/3338906.3340460[32]Congxi Song, Bo Yu, Xu Zhou, and Qiang Yang. 2019. SPFuzz: A HierarchicalScheduling Framework for Stateful Network Protocol Fuzzing.IEEE Access7(2019), 18490‚Äì18499. https://doi.org/10.1109/ACCESS.2019.2895025[33]Dokyung Song, Felicitas Hetzelt, Dipanjan Das, Chad Spensky, Yeoul Na, StijnVolckaert, Giovanni Vigna, Christopher Kruegel, Jean-Pierre Seifert, and MichaelFranz. 2019. PeriScope: An E"ective Probing and Fuzzing Framework for theHardware-OS Boundary. In26th Annual Network and Distributed System SecuritySymposium, NDSS 2019, San Diego, California, USA, February 24-27, 2019. TheInternet Society.[34]Vasudev Vikram, Rohan Padhye, and Koushik Sen. 2021. Growing A Test Corpuswith Bonsai Fuzzing. In43rd IEEE/ACM International Conference on SoftwareEngineering, ICSE 2021, Madrid, Spain, 22-30 May 2021. IEEE, 723‚Äì735. https://doi.org/10.1109/ICSE43902.2021.00072[35]Guangliang Yang, Je"Huang, and Guofei Gu. 2018. Automated Generation ofEvent-Oriented Exploits in Android Hybrid Apps. In25th Annual Network andDistributed System Security Symposium, NDSS 2018, San Diego, California, USA,670Demystifying the Dependency Challenge in Kernel FuzzingICSE ‚Äô22, May 21‚Äì29, 2022, Pi/t_tsburgh, PA, USAFebruary 18-21, 2018. The Internet Society. http://wp.internetsociety.org/ndss/wp-content/uploads/sites/25/2018/02/ndss2018_04B-3_Yang_paper.pdf[36]Yizhuo Zhai, Yu Hao, Hang Zhang, Daimeng Wang, Chengyu Song, ZhiyunQian, Mohsen Lesani, Srikanth V. Krishnamurthy, and Paul Yu. 2020. UBITect:a precise and scalable method to detect use-before-initialization bugs in Linuxkernel. InESEC/FSE ‚Äô20: 28th ACM Joint European Software Engineering Conferenceand Symposium on the Foundations of Software Engineering, Virtual Event, USA,November 8-13, 2020, Prem Devanbu, Myra B. Cohen, and Thomas Zimmermann(Eds.). ACM, 221‚Äì232. https://doi.org/10.1145/3368089.3409686
671