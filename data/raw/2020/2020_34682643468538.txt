Cross-LanguageCodeSearchusingStaticandDynamicAnalyses
George Mathew
North Carolina StateUniversity
USA
george2@ncsu.eduKathrynT.Stolee
North Carolina StateUniversity
USA
ktstolee@ncsu.edu
ABSTRACT
As code search permeates most activities in software development,
code-to-code search has emerged to support using code as a query
andretrievingsimilarcodeinthesearchresults.Applicationsin-
clude duplicate code detection for refactoring, patch identification
forprogramrepair,andlanguagetranslation.Existingcode-to-code
searchtoolsrelyonstaticsimilarityapproachessuchasthecom-
parisonoftokensandabstractsyntaxtrees(AST)toapproximate
dynamic behavior, leading to low precision. Most tools do not sup-
portcross-languagecode-to-codesearch,andthosethatdo,relyon
machine learningmodels that require labeledtraining data.
We present Code-to-Code Search Across Languages (COSAL), a
cross-language technique that uses both static and dynamic analy-
sestoidentifysimilarcodeanddoesnotrequireamachinelearning
model. Code snippets are ranked using non-dominated sorting
basedoncodetokensimilarity,structuralsimilarity,andbehavioral
similarity.WeempiricallyevaluateCOSALontwodatasetsof43,146
Java and Python files and 55,499 Java files and find that 1) code
search based on non-dominated ranking of static and dynamic sim-
ilaritymeasuresismoreeffectivecomparedtosingleorweighted
measures; and 2) COSAL has better precision and recall compared
to state-of-the-art within-language and cross-language code-to-
code search tools. We explore the potential for using COSAL on
largeopen-sourcerepositoriesanddiscussscalabilitytomorelan-
guages and similarity metrics, providing a gateway for practical,
multi-language code-to-code search.
CCS CONCEPTS
Â·Softwareanditsengineering â†’Softwaremaintenancetools ;
Â·Informationsystems â†’Similaritymeasures .
KEYWORDS
code-to-codesearch,cross-languagecodesearch,non-dominated
sorting,staticanalysis,dynamicanalysis
ACMReference Format:
George Mathew and Kathryn T. Stolee. 2021. Cross-Language Code Search
usingStaticandDynamicAnalyses.In Proceedingsofthe29thACMJointEu-
ropean Software Engineering Conference and Symposium on the Foundations
ofSoftwareEngineering(ESEC/FSEâ€™21),August23Å›28,2021,Athens,Greece.
ACM,NewYork,NY,USA, 13pages.https://doi.org/10.1145/3468264.3468538
Permissionto make digitalor hard copies of allorpart ofthis work for personalor
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACM
mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,
topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ESEC/FSE â€™21, August 23Å›28,2021, Athens,Greece
Â©2021 Associationfor Computing Machinery.
ACM ISBN 978-1-4503-8562-6/21/08...$15.00
https://doi.org/10.1145/3468264.34685381 INTRODUCTION
Code-to-code search describes the task of using a code query to
search for similar code in a repository. This task is particularly
challenging when the query and results belong to different lan-
guages dueto syntactic andsemantic differences between the lan-
guages[20]. Considerthecase ofcodemigration,where it is com-
mon for applications in a specific language to be re-written to
another language [ 52]. For example, while porting the video game
Fezfrom Microsoft XBox to Sony PlayStation, the developers faced
theirbiggestchallengeinconvertingtheoriginalC#codetoC++
asthePlayStationdidnotsupporttheC#compiler[ 85].Code-to-
code search is also involved in identifying code clones [ 63,66],
findingtranslationsofcodeinadifferentlanguage[ 58],program
repair[10,68],andsupportingstudentsinlearninganewprogram-
minglanguage[ 3].Thegrowingprominenceoflargeonlinecode
repositoriesandtherepetitivenatureofsourcecode[ 48,70]leadto
thepresenceoflargequantitiesofpotentiallysimilarcodeacross
languages,providingaviable platform for code-to-code search.
We propose the first cross-language code-to-code search ap-
proachwithdynamicandstaticsimilaritymeasures.Thenoveltyis
intheapplicationofnon-dominatedsorting[ 19]tocode-to-code
search, allowing static and dynamic information (without aggre-
gation) to identify search results. COSAL leverages prior art in
clone detection using input-output (IO) behavior [ 51]. As dynamic
clone detection requires executable code, individually it cannot
achieve the recall required for practical search applications. This is
wherethepriorartinstaticanalysisshines;weusetoken-basedand
AST-based measures to complement the dynamic analysis. COSAL
reaps the benefits of dynamic analysis in finding code that behaves
similarly,whendynamicinformationisavailable,andthebenefits
of static information when dynamic information is infeasible. It
provides results that balance how code looks withhow it behaves , in
the spiritofreturningcode that looks more naturalto the user.
We evaluate COSAL using 43,146 Java and Python files from
AtCoder,aprogrammingcontestdataset,and55,499Javafilesfrom
BigCloneBench[ 79],aJavabasedclonedetectionbenchmark.We
show that combiningstatic and dynamic analyses yields better pre-
cision and success rate compared to code search with individual
or weighted analyses. COSAL performs better in cross-language
and within-language contexts compared to the state-of-the-art
code search tool FaCoY and the industrial benchmark, GitHub.
COSAL can also detect more cross-language code clones compared
toSLACCandCLCDSA,thestate-of-the-artcodeclonedetection
techniques.The contributionsof this work are:
â€¢thefirstcode-to-codesearchapproachusingnon-dominated
sortingover staticanddynamic similaritymeasures,
â€¢an evaluation of COSAL with state-of-the-practice cross-
languagecode search inGitHubandElasticSearch (RQ2),
205
ESEC/FSE â€™21, August 23â€“28, 2021,Athens,Greece GeorgeMathewandKathryn T. Stolee
1List<Integer> getEvens( intmax) {
2 List<Integer> evens = newArrayList<>();
3 for(inti =0; i < max; i++)
4 if(i %2==0)
5 evens.add(i);
6 returnevens;
7}
(a)Java:forloop to populate an array of even numbers
1defall_odds(n):
2 odds = []
3 n = range(n)
4 foriinn:
5 ifi %2==0:continue
6 odds.append(i)
7 returnodds
(b)Python:forloop to populate an array of odd numbers
1Integer[] func( intx) {
2 int[] n = IntStream. range(0, x).toArray();
3 List<Integer> e = newArrayList<>();
4 for(inti=0; i<n.length(); i++)
5 if(n.get(i) %2==0)
6 e.add(n.get(i));
7 returne.toArray();
8}
(c)Java:Listof even numbersusingversion specificlibraries
1defeven_nums(max_val):
2 nums = xrange(max_val)
3 return[iforiinnumsifi %2==0]
(d)Python:listof even numbersusing list-comprehension
Figure 1: Different functions to return a filtered array of
numbersimplementedin JavaandPython.Thecodein(a),(c),
and(d)arefunctionallyidentical.Thecodein(b)isdifferent.
â€¢anevaluationofCOSALwithstate-of-the-artsingle-language
code searchtechniqueFaCoY(RQ3),
â€¢an evaluation of COSAL against cross-language clone detec-
tiontechniques CLCDSAandSLACC(RQ4),and
â€¢anopen-sourcetoolthatperformscross-languagecodesearch
onJavaandPythonandcanbeextendedtootherlanguages[ 2].
2 MOTIVATION
Effective code-to-code search requires code similarity measures
that cover a variety of developer concerns. Code-to-code search
shouldpreservecodebehavior,andthusIOsimilarityfromdynamic
analysis is an important consideration. Prior work has shown that
identifiers impact source code comprehension, especially for be-
ginners [14], and as developers must understand the code returned
by search, tokens are an important consideration. Prior work in
code-to-codesearchthatreliesonASTshaveseenhighprecision
and recall [ 43,63] suggesting that is an important consideration as
well. Individually, each measure has shortcomings. Taken together,
however,we showthe wholeisgreater thanthe sum ofits parts.
ConsiderthecodesnippetsinFigure 1.Threeofthefunctions
are behaviorally identical, taking an input integer and returning
anarrayofevenintegers: 1(a)isaJavafunctionwhichusesafor
loop;1(c)uses the stream library from Java v8; 1(d)is a Python
function which uses a filtered list-comprehension .1(b)is different:
it is a Python function that takes an integer ğ‘šğ‘ğ‘¥and returns a listFig.AST Tokens
ğ½1(a)
getevens, get, evens,
max, list, integer, ar-
raylist, array, add
ğ‘ƒ1(b)
allodds, all, odds,
range, append
ğ½1(c)
func, intstream,
stream, range, toarray,
array, list, integer,
arraylist, length,get,
add
ğ‘ƒ1(d)
evennums, even,
nums, maxval, max,
val, xrange
Figure2:GenericASTsandTokensforJava( ğ½)andPython( ğ‘ƒ)
functions fromFigure 1
ofoddnumbersbetween [0,ğ‘šğ‘ğ‘¥).Figure2containsASTandtoken
information for the code snippets,discussedextensivelyinÄŸ 3.
To identify behaviorally identical Python code for Figure 1(a), a
code-to-code search engine should support both the programming
languagesJavaandPython.Inthiscase,usingapurelytoken-based
approach forcross-languagesearchwillnotbe veryhelpful.First,
the syntactic features of each language will skew the search. For
example, since Java is static typed, variables are declared with
a datatype, while variables in Python lack these tokens due to
dynamic typing in Python. Second, even if the language-specific
keywordsareignored,thereisanoverrelianceonthenamesofvari-
ablesandlibrariestoinferbehavioralcontextwhichmaynotalways
succeed.Forexample, 1(a)usesevenstodenoteaJavalist,while 1(d)
usesnumstorepresentthesamePythonarray.Still,identifiernames
canbe informative in describing thebehavior of code [ 86,87]and
are thereby useful as ametric.
Using an AST-based approach to identify similar code across
languages is useful but not consistently viable due to the language-
specific constructs. For example, 1(a)uses a standard forloop to
populate the list while 1(d)useslist-comprehension which is a
pythonic construct for the same task. The nearest structural match
would be 1(b)since it also uses a forloop. However, the func-
tions1(a)and1(b)are behaviorally different. In such cases, a dy-
namicapproachbasedonIOsimilaritywouldrevealthedifferences.
Behavioral approaches also havetheirlimitations.For example,
IntStream from1(c)isspecifictoJavav8andabove.Similarly xrange
from1(d)is specific to Python v2.x. Hence, the right version of the
206Cross-LanguageCode SearchusingStatic andDynamic Analyses ESEC/FSE â€™21, August 23â€“28, 2021,Athens,Greece
languageandlibrariesisaprerequisiteandinmanycasesa major
bottleneckfor dynamicsimilarity.
There is no single best similarity measure for cross-language
code-to-code search. It depends on multiple varying criteria which
cannot be generalized for all cases. Hence, we need a code-to-code
searchtechniquethatenablessearchbasedonmultiplesimilarity
measures. This can be handled by aggregating the multiple mea-
sures into a single measure or by using all the measures in tandem.
When aggregating into a single measure, it is easier to compare
but there are limitations. Search methods [ 38,41] and evolution-
aryalgorithms[ 25]convertmultiplesearchobjectivestoasingle-
objective search problem [ 53]. Using such methods is not very
optimal [92] as ranking the results would be very subjective if the
objectives are independent or weakly correlated to each other. An
aggregated approach can also lead to bias in comparison [ 17]. This
motivates the use of an approach to ranking that preserves each of
the similarity measures, using them in tandem. In this section, we
haveshownthatcodethatmatchesononemeasure(e.g.,ASTsimi-
laritywouldmatch 1(a)with1(b))maydifferonanothermeasure
(e.g., behavioral similarity shows 1(a)and1(b)are different). When
aggregating intoasinglemeasure,such nuances are often lost.
Non-dominated ranking orders search results across multiple
independent search objectives without aggregating them. We se-
lect three similarity measures to represent the context, structure
andbehavioracrossprogramminglanguages.Thesemeasuresare
weakly and moderatelycorrelated to each other,presenting non-
overlapping perspectives when used to compare code. Further,
non-dominated ranking could provide information sufficient to
explain why one result is ranked above another in a meaningful
way, an ability that is lacking in aggregated approaches (e.g., "1(a)
and1(b)have more structural similarity" ). While we do not investi-
gate the value of the explanations in this work, we conjecture that
such explanations may be useful when developers discern between
searchresults andleave that for future exploration.
3 CODE-TO-CODE SEARCHACROSS
LANGUAGES
Figure3depictsthe generalworkflowofCOSAL:
(1)Offline, a Repository is crawled to extract Code Snippets (e.g.,
GitHub,alocal File System.)
(2) Offline,Indices are createdfor eachofthe following:
(a) ATokenIndex for code names andlibraries ( ÄŸ 3.1).
(b)Alanguage-agnostic ASTIndex forcodestructures(ÄŸ 3.2).
(c)Ifthecodecanbeexecuted,the IOIndexisrecorded(ÄŸ 3.3).
(3)Duringsearch,a CodeQuery isprocessedinthesamemanner
as Steps2(a)-(c), to gather Tokens,AST,andIOinformation.
(4)Non-DominatedSorting identifies SearchResults ,whichare
rankedandreturnedto the user( ÄŸ 3.4)
We illustrate COSAL using the code examples from Figure 1.
3.1 Token-BasedSearch
Fragments of code that are contextually similar often use simi-
lar variable names [ 69], though the naming conventions vary by
language. For example, Java primarily uses camelCase conventions
whilePythonuses snake_case .Librariesacrosslanguagestendto
share similar function names or contexts [ 4]; for example List
Figure 3:Overview ofCOSAL
classfrom java.utillibraryand listfromthePython __builtin__
library are both commonly used to represent an array. Develop-
erstendtodescribethecodeincommentsbasedonthefunction-
ality [33]. We infer context by extracting non-language-specific
tokens from sourcecode andcomments as follows:
(1)Remove language-specific keywords based on the documen-
tation [18,60]. For example, Java tokens publicandstatic,
andPythontokens defandassert,are allremoved.
(2)Remove frequently-used words used in a language based on
common coding conventions. For example, in Python, the
tokenselfisoften usedto denotethe class object.1
(3)RemovecommonstopwordsfromtheEnglishvocabulary[ 15],
such asdoesandfrom.
(4)Splittokenstoaddresslanguage-specificnomenclature.Vari-
ables typically use camelCase in Java and snake_case in
Python.Thesearesplitinto{Å‚camelÅ¾andÅ‚caseÅ¾}and{Å‚snakeÅ¾
andÅ‚caseÅ¾},respectively.
(5) Remove tokens oflength less than MIN_TOK_LEN .
(6) Convertallthe tokens to lower case.
A repository of code is tokenized using the above approach and
storedinanElasticSearch[ 29]index.Forauserâ€™scodequery,the
tokens generated from the indexing approach are looked up in the
searchindexandthebestmatchedresultsarereturnedusingthe
tokensimilaritydistance (ğ‘‘ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›).Thisdistanceisthesameasthe
JaccardCoefficient [ 59]andisdefinedas follows:
ğ‘‘ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›=|ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›ğ‘ ğ‘ğ‘¢ğ‘’ğ‘Ÿğ‘¦âˆ©ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›ğ‘ ğ‘Ÿğ‘’ğ‘ ğ‘¢ğ‘™ğ‘¡|
|ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›ğ‘ ğ‘ğ‘¢ğ‘’ğ‘Ÿğ‘¦âˆªğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›ğ‘ ğ‘Ÿğ‘’ğ‘ ğ‘¢ğ‘™ğ‘¡|
ğ‘‘ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›will range from [0.0,1.0]. Larger values of ğ‘‘ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›indicate
higher similaritybetween the query andresult.
For the functions in Figure 1, the generated tokens using this
approachareshowninFigure 2andthetokensimilaritydistancefor
each pair of functions is shown in Table 1(ğ‘‘ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›). If the Java func-
tion1(a)isthe query, the bestPython result would be 1(d)(ğ‘‘ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›
= 0.067). The common token maxextracted from these functions
help in identifyingthissimilarity.Note that none of the functions
in Figure 1have code comments, while in our implementation the
comments are analyzed.
Inmanycasesthetoken-basedanalysiscannotyieldidealresults.
Itreliesonself-describingsnippets;thechoiceofvariablenames,
functionnames,librariesused,andcommentsallimpacttheresults.
1Complete listsof the removed tokens areavailable [ 2].
207ESEC/FSE â€™21, August 23â€“28, 2021,Athens,Greece GeorgeMathewandKathryn T. Stolee
Table1:SimilaritymeasuresforJava( ğ½)andPython( ğ‘ƒ)func-
tions from Figure 1. High similarity implies high values ( â†‘)
ofğ‘‘ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›,low values( â†“) ofğ‘‘ğ´ğ‘†ğ‘‡,andhigh values( â†‘) ofğ‘‘ğ¼ğ‘‚.
Snip1 Snip2 ğ’…ğ’•ğ’ğ’Œğ’†ğ’(â†‘)ğ’…ğ‘¨ğ‘ºğ‘»(â†“)ğ’…ğ‘°ğ‘¶(â†‘)
(s1,s2) (s2,s1)
ğ½-1(a)ğ‘ƒ-1(b)0.0 1 0.0 0.0
ğ½-1(a)ğ½-1(c)0.333 16 1.0 1.0
ğ½-1(a)ğ‘ƒ-1(d)0.067 7 1.0 1.0
ğ‘ƒ-1(b)ğ½-1(c)0.0 17 0.5 0.3
ğ‘ƒ-1(b)ğ‘ƒ-1(d)0.0 8 0.5 0.5
ğ½-1(c)ğ‘ƒ-1(d)0.059 21 1.0 1.0
Notallcodesnippetsadheretointuitivenaming conventions.For
example,in 1(c),theprogrammerchoseverygenericnames.Still,
we show in ÄŸ 6.1that our approach for tokenization yields more
precise results comparedto full textsearch.
3.2 AST-BasedSearch
A tree-based representation for comparison across languages is
challengingsincethereisnogenericASTrepresentationthaten-
compasses syntactic features of different languages. Traditional
AST parsers like ANTLR[61],JavaParser [83],python-ast [65] mod-
ulesusedifferentgrammarstodenotesimilarfeatures.Forexample,
a function node in JavaParser is represented as MethodDeclaration
whilethe python-ast parserrepresentsthenodeas FunctionDef .As
aresult,tocompareASTsofdifferentlanguagesrequiresamapping
scheme between eachpair ofprogramming languages.
For better scalabilitytoadditional programminglanguages, we
built a parser for a generic AST. By mapping the ASTs for Java
and for Python onto the generic AST, we can compare across these
languages(seeÄŸ 7.3.2foradiscussiononscalability).Thegeneric
ASTisbasedonourintuitionandchosenlanguages,andtheremay
bemoreeffectiveorefficientrepresentations.Itcontainsasuperset
ofthe languagefeatures, as follows:
â€¢Commoncontrolstructures :Controlstructuresaresim-
plified and clustered. For example, the loopnode is used for
the Java constructs: for,forEach,whileanddo-while; and
Pythonconstructs: for,while,andlist-comprehension .
â€¢NormalizingVariable :Variablesaredenotedas varnodes.
â€¢Normalizing Literals : Literalsare denotedas litnodes.
â€¢NormalizingOperators :Operatorsaredenotedas opnodes.
â€¢Languagespecificfeatures :Ifafeatureisimplementedin
onlyonelanguage,acustomnodeiscreated.Forexample,
switchis specific to Java and not supported in Python. As a
result, acustomnode switchiscreatedfor this statement.
Similarity between ASTs is computed using the Zhang-Sasha
algorithm[ 90](ğ‘‘ğ´ğ‘†ğ‘‡).Thealgorithmcomputestheminimumnum-
berofeditsrequiredtotransformanorderedlabeledtreetoanother
orderedlabeledtreeinquadratic time. ğ‘‘ğ´ğ‘†ğ‘‡will rangefrom [0,âˆ).
Lower valuesof ğ‘‘ğ´ğ‘†ğ‘‡are associatedwithhigher similarity.
For the functions in Figure 1, the generated ASTs are shown
in Figure 2and the AST edit distance for each pair of functions
is shown in Table 1(ğ‘‘ğ´ğ‘†ğ‘‡). Based on ğ‘‘ğ´ğ‘†ğ‘‡, a query with Pythonfunction 1(d)yields1(a)as the best Java result ( ğ‘‘ğ´ğ‘†ğ‘‡= 7). No-
tably, the syntactic constructs of the two functions are also dif-
ferent. The Python search query 1(d)uses alist-comprehension
which is a Python feature and the Java search result 1(a)uses a
forloop.Identifyingthematchingsearchresultispossible,since
list-comprehension and theforloop are denoted as loopnodes in
the grammarfor the genericAST.
There are cases where a generic AST-based approach is non-
ideal.Forexample,iftheJavafunction 1(a)isqueriedusing ğ‘‘ğ´ğ‘†ğ‘‡,
thebestPythonresultwouldbe 1(b).Thisisbecausebothfunctions
use traditional forloops and updates the return array sequentially,
andyet,thesearchresultisbehaviorallydifferentfromthe query.
Suchscenarios can be handledusing dynamic similarity.
3.3 Input-OutputBasedSearch
DynamicsearchinCOSAL, isperformedbyclusteringcode based
onthetheirIOrelationship.TodeterminetheIOrelationshipbe-
tween two pieces of code, we use SLACC [ 51], a publicly-available
IO-based cross-language code clone detection tool. SLACC seg-
ments code into executable snippets of size greater than MIN_STMTS
andexecutedon ARGS_MAX argumentsgeneratedusingagrey-box
strategy. The executed functions are then clustered using a similar-
ity measure ( ğ‘ ğ‘–ğ‘š) based on the inputs and outputs of the functions.
Consideraquery ğ‘andapotentialsearchresult ğ‘ .Letğ‘„andğ‘†be
setsofsegmentsidentifiedbySLACCfrom ğ‘andğ‘ respectively.We
definethe IO similarityas:
ğ‘‘ğ¼ğ‘‚(ğ‘,ğ‘ )=1
|ğ‘„|/summationdisplay.1
ğ‘ğ‘–âˆˆğ‘„ğ‘šğ‘ğ‘¥ğ‘–ğ‘šğ‘–ğ‘§ğ‘’
ğ‘ ğ‘˜âˆˆğ‘†ğ‘ ğ‘–ğ‘š(ğ‘ğ‘–,ğ‘ ğ‘˜)
The value ğ‘‘ğ¼ğ‘‚range from [0.0,1.0]. Higher similarity corresponds
to higher valuesof ğ‘‘ğ¼ğ‘‚.
The IO similarity between any ğ‘andğ‘ is not commutative.
This is because it is often preferred for a search result to con-
tain extra behavior as compared to the query [ 76]. Also, there
may be a many-to-one mapping where multiple query segments
matchwithasinglesegmentintheresult.Consideranexample:let
ğ‘„={ğ‘1,ğ‘2,ğ‘3,ğ‘4,ğ‘5}be set of five segments and ğ‘†={ğ‘ 1,ğ‘ 2,ğ‘ 3}
be set of three segments identified by SLACC. Segments ğ‘1,ğ‘2and
ğ‘3findsegments ğ‘ 1,ğ‘ 2andğ‘ 1tobethemostsimilar,respectively,
withsimilarityscores( ğ‘ ğ‘–ğ‘š)ofğ‘ ğ‘–ğ‘š(ğ‘1,ğ‘ 1)=0.8,ğ‘ ğ‘–ğ‘š(ğ‘2,ğ‘ 2)=0.95
andğ‘ ğ‘–ğ‘š(ğ‘3,ğ‘ 1)=0.7. Notice how ğ‘ 1is identified as the closest
match for both ğ‘1andğ‘3. Segments ğ‘4andğ‘5did not find seg-
ments inğ‘†with similarity greater than 0 .0. In this case, ğ‘‘ğ¼ğ‘‚(ğ‘,ğ‘ )=
0.8+0.95+0.7+0.0+0.0
5=0.49.
As a practical example, say a developer is looking for a Java API
forQuickSelect2,whichfindsthe ğ‘˜ğ‘¡â„smallestnumberfromanarray
of integers. It has a method that identifies a random pivot in the
array and a method that swaps values. However, these methods do
notcalleachother.Thus,tocharacterizethebehaviorofthisfile,
we characterize and aggregate the behavior of segments of the file.
Then, when comparing to a custom Python QuickSort3API that
has a function to recursively find a random pivot and perform a
swapoperation,amatchisidentifiedeventhoughthenumberof
methodsandhowthey accomplishthe same taskare different.
2fromorg.apache.datasketches
3stackabuse.com/quicksort-in-python
208Cross-LanguageCode SearchusingStatic andDynamic Analyses ESEC/FSE â€™21, August 23â€“28, 2021,Athens,Greece
Thedynamic similaritybetweenallthefunctionsinFigure 1is
showninTable 1.WenoticedinÄŸ 3.2that1(a)and1(b)werevery
similar based on ğ‘‘ğ´ğ‘†ğ‘‡, but functionally different. Using behavioral
analysis,weseethattheyareindeedfunctionallydifferentas ğ‘‘ğ¼ğ‘‚=
0.5forbothmeasuresof ğ‘‘ğ¼ğ‘‚.Incontrast, 1(a)and1(c)aresimilar
based on behavior ( ğ‘‘ğ¼ğ‘‚=1.0), even though structural similarity
(ğ‘‘ğ´ğ‘†ğ‘‡) islow.
3.4 Non-dominatedRanking
WeuseNon-dominatedSorting,whichisacomponentofNSGA-
II[19],andordersresultswithmultipleobjectiveswithoutaggre-
gation. COSAL uses this algorithm to rank search results based on
ğ‘‘ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›,ğ‘‘ğ´ğ‘†ğ‘‡,andğ‘‘ğ¼ğ‘‚.Wenotethatthesimilaritymeasuresconsid-
eredinthisworkareweaklycorrelated,asdescribedinÄŸ 7.2,making
this an appropriate algorithmic choice. We usethe algorithmin a
novelcontext;thisisthefirstworkthatusesnon-dominatedsorting
for code-to-code search.
Inourcontext,eachsimilaritymeasureisanobjective.COSAL
incorporatesnon-dominatedrankingas follows:
(1)Individual Search : For a query, top TOP_Nsearch results
are fetched using each similarity measure ( ğ‘‘ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›,ğ‘‘ğ´ğ‘†ğ‘‡and
ğ‘‘ğ¼ğ‘‚) independently.
(2)Merge:Theindividualsearchresultsaremergedsuchthat
duplicateinstancesofsearchresults are removed.
(3)Sort:ThemergedresultsaresortedbyNSGA-II[ 19]bymea-
suring the dominance ofone result over the other.
A search result ğ‘ is said to dominate a search result ğ‘¡, ifğ‘ is no
worse than ğ‘¡in any objective and is better than ğ‘¡in at least one
objective. Otherwise, there is a tie. In case of a tie, we select the
result that has the dominant objective closest to the optimal value.
Forexample,considerthefollowingscenariosoftherelationship
betweenğ‘ andğ‘¡andthreehypotheticalsimilaritymeasures, ğ‘‘ğ´,ğ‘‘ğµ,
andğ‘‘ğ¶,where higher valuesmean higher similarity:
scenario ğ’…ğ‘¨ğ’…ğ‘©ğ’…ğ‘ªwinner
1s>ğ‘¡s>ğ‘¡s>ğ‘¡ ğ‘ 
2ğ‘ =ğ‘¡ ğ‘ =ğ‘¡s>ğ‘¡ ğ‘ 
3ğ‘ =ğ‘¡ ğ‘ <t s>ğ‘¡tie
4ğ‘ <tğ‘ <t s>ğ‘¡tie
Forscenario1, ğ‘ isbetterthan ğ‘¡onallmeasures,making ğ‘ thewinner.
In scenario 2, since ğ‘ isbetter than ğ‘¡onone measure,andisnever
worse than ğ‘¡,ğ‘ is thewinner. In the third scenario, ğ‘ is better than
ğ‘¡ononemeasure( ğ‘‘ğ¶),andworseonanother( ğ‘‘ğµ).Therefore,there
is a tie. Similarly on scenario 4, ğ‘ is worse than ğ‘¡on two measures
andbetteronone,soitisalsoatie.Tiesarebrokenbylookingat
thesearchresultsthatarebetterforeachsimilaritymeasureand
thencomparingtooptimalvalues(typically1or0,dependingon
whether high orlowvaluesrepresent bettersimilarity).
Using the examples from ÄŸ 2, consider the Python functions 1(d)
and1(b)inFigure 1asqueries.Thepotentialcross-languageresults
are1(a)and1(c).We show the relationships between the potential
results using three similarity measures; see Table 1for specific
values.The winnerfor eachcomparison isboldedfor clarity.
query ğ’…ğ’•ğ’ğ’Œğ’†ğ’ğ’”(â†‘)ğ’…ğ‘¨ğ‘ºğ‘»(â†“)ğ’…ğ‘°ğ‘¶(â†‘)winner
1(d)1(a)>1(c)1(a)<1(c) 1(a) =1(c) 1(a)
1(b) 1(a) =1(c)1(a)<1(c) 1(a) <1(c)tieWhen the query is 1(d),1(a)is better than 1(c)on two of the
measures, and equal on the third, thus making 1(a)the winner.
Whenthequeryis 1(b),1(a)isthewinnerfor ğ‘‘ğ´ğ‘†ğ‘‡and1(c)isthe
winnerfor ğ‘‘ğ¼ğ‘‚,meaningwe needto breakthe tie.
To break ties, we compute distances between each search result
andtheoptimalvalueforeachsimilaritymeasure(omittingsimilar-
itymeasuresonwhichtheresultsaretied).Theoptimalvaluefor
ğ‘‘ğ´ğ‘†ğ‘‡is0,asthatrepresentsisomorphicASTs.Theoptimalvaluefor
ğ‘‘ğ¼ğ‘‚is1,asthatrepresentsaperfectmatchincodebehavior(i.e.,the
search result and query return the sameoutput for allthe provided
inputs). The optimal value for ğ‘‘ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›is also 1, as this represents
highly similar syntax. We use a normalized distance because the
similarity measures have different rangesof values. Thus, normal-
izing ensures a uniform comparison scale between the different
similarity measures and subsequently avoid the precedence of one
similarity measure over other similarity measures. The normalized
distance of a similarity measure ( ğ‘‹) on a snippet ğ‘ is computed
asğ‘‘ğ‘‹(ğ‘ )âˆ’ğ‘šğ‘–ğ‘›(ğ‘‘ğ‘‹)
ğ‘šğ‘ğ‘¥(ğ‘‘ğ‘‹)âˆ’ğ‘šğ‘–ğ‘›(ğ‘‘ğ‘‹).Forğ‘‘ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›andğ‘‘ğ¼ğ‘‚,theğ‘šğ‘ğ‘¥andğ‘šğ‘–ğ‘›values
are 0.0 and 1.0 respectively. In the case of ğ‘‘ğ´ğ‘†ğ‘‡, theğ‘šğ‘–ğ‘›value is 0
and the max value is set to the largest value of ğ‘‘ğ´ğ‘†ğ‘‡from all the
individualsearchresults.Thisisbecause ğ‘‘ğ´ğ‘†ğ‘‡,cantheoreticallybe
infinitelylargesoweusethelargestobservedvalue.Forexample,
ğ‘šğ‘ğ‘¥(ğ‘‘ğ´ğ‘†ğ‘‡)for the query 1(d)is21 from Table 1.
Continuingwiththeexample,thenormalizeddistancefor 1(a)to
the optimal ğ‘‘ğ´ğ‘†ğ‘‡is 0.048. We do not need to consider the distance
for1(c)since1(a)wasthewinnerfor ğ‘‘ğ´ğ‘†ğ‘‡. Thenormalizeddistance
between ğ‘‘ğ¼ğ‘‚of1(c)is 0.5. Since the normalized ğ‘‘ğ´ğ‘†ğ‘‡of1(a)is
closer to the optimal value compared to the normalized ğ‘‘ğ¼ğ‘‚of1(c),
COSAL ranks 1(a)as the winnerfor the query 1(b).
Wenotethatsimilaritymeasurescharacterizingothercodere-
lationships,suchassoftwaremetrics[ 9,62],couldbeaddedwith
relativeease.Non-dominationrankingpreserveseachobjectiveâ€™sin-
dependenceandtherearenoweightsthatrequiretuning;seeÄŸ 7.3.3.
4 RESEARCH QUESTIONS
Theredoesnotexistacross-languagecode-to-codesearchtoolto
compare against directly (see ÄŸ 8). Thus, our evaluation assesses
each part of COSAL: the ranking algorithm, within-language code-
to-codesearchcomparedtostate-of-the-practiceandstate-of-the-
art tools, and cross-language clone detection. The first research
question(RQ) examines the similaritymeasures andranking:
RQ 1
Doesnon-dominatedrankingusingtokens,ASTandIOyield
better results for cross-language code-to-code search as com-
pared to any subset or aggregation of those search similarity
measures?
After validating the choice of using multiple code similarity
measures and non-domination ranking, COSAL is compared to the
state-of-the-practice search in GitHub Search and ElasticSearch
whichare basedonfull textsearch. We ask:
RQ 2
HoweffectiveisCOSALincross-languagecode-to-codesearch
comparedto state-of-the-practice publiccode search tools?
209ESEC/FSE â€™21, August 23â€“28, 2021,Athens,Greece GeorgeMathewandKathryn T. Stolee
Table2:SummaryofRQswiththeapplication(code-to-codesearch,clonedetection),baselines,benchmarks(AtCoderorBig-
CloneBench) andthelanguage(s).COSAL <ğ‘ ğ‘–ğ‘›ğ‘”ğ‘™ğ‘’>representsCOSAL usingasinglesimilarity measure.
RQ Purpose Application Baselines Language(s) Benchmarks
1 Merit ofusingmultiplesimilaritymeasures Code-to-CodeSearch COSAL <ğ‘ ğ‘–ğ‘›ğ‘”ğ‘™ğ‘’> Javaâ†”Python AtCoder
2 Vsstate-of-the-practice cross-language tools Code-to-CodeSearch ElasticSearch,GitHub Java â†”Python AtCoder
3 Vsstate ofthe art within-language tools Code-to-CodeSearch FaCoY Java AtCoder, BigCloneBench
4 Using COSAL to identifysimilar code CloneDetection CLCDSA, ASTLearner Java â†”Python AtCoder
FaCoY[40],thestate-of-the-artincode-to-codesearchiswithin-
language, but COSAL is a multi-language tool. We limit our tool to
within-languagecode-to-codesearchandevaluateitagainstFaCoY.
RQ 3
How effective is COSAL in within-language code-to-code
searchas comparedto the state-of-the-art?
Code-to-codesearchisoftenusedinclonedetection[ 66,68].Us-
ingCOSALforclonedetection,wecompareagainstASTLearner[ 63],
CLCDSA[ 56], andSLACC[ 51]:
RQ 4
Can COSAL effectivelydetectcross-language code clones?
5 STUDY
The setup for each RQ is different. In all evaluations we make a
bestefforttobefairinthecomparison.TheRQsaresummarizedin
Table2,whichliststheapplication(eithercode-to-codesearchor
clonedetection),baselineapproaches,language(s),andbenchmarks.
5.1 Data
The data usedinthis study are available online[ 2].
5.1.1 AtCoder(AtC). We require a labeled setof similar code snip-
pets in multiple programming languages for queries and search
results.Hence,likepriorstudies[ 56,63],weuseAtCoder[ 5]tocre-
ateadatasetofsimilarcodesnippetsacrossdifferentprogramming
languages. Competitive programming contests like AtCoder [ 5]
haveopenproblemswhereuserscansubmittheirsolutionsinmost
commonprogramminglanguages.Solutionswhicharesyntactically
incorrectordonotpasstheextensivetestsuiteare filteredoutby
AtCoder.Alltheacceptedsolutionsforasingleproblemimplement
thesamefunctionalityandarebehavioralcodeclones.Ifasearch
query and a result belong to the same problem, we consider the
result to be valid and the query-result pair as valid code clones;
the problem solutions are the ground truth in our experiments. We
limitourstudytothemostrecent398problemswhichhadsolutions
inJavaorPython.Fortheseproblems,wecrawled43,146filesfrom
alltheacceptedJavaandPythonsolutions.Table 3listsanoverview
ofthedatasetusedforthestudy;307ofthe398problemshaveboth
aJava andPythonsolutions.
5.1.2 BigCloneBench (BCB). BigCloneBench [ 79] is one of the
largestpubliclyavailablecodeclonebenchmarksforJavawithover
55,000sourcecodefilesharnessedfromapproximately25,000open-
source repositories. Table 3lists a summary of BigCloneBench. We
consider query-result snippets belonging to the same functionality
as a valid search result. Fragments of code with less than 6 lines or50tokensarenotconsideredwhichisastandardminimumclone
size for benchmarking[ 12,40,79].
5.2 Baselines
WecompareCOSALtoeachoftheothertoolsbysearchingover
thesamedatasets.ForRQ3andRQ4,weusedthesourcecodein
the GitHubrepositoriesof the toolsfor experimentation.
5.2.1 RQ2â€“TextSearch. Google searchis commonlyusedby de-
velopers for code search [ 75]. Textual queries can take the form of
keywords,expectedcode,orexceptionsraised.Inourstudy,Google
failedtoindexourcoderepositoryafterasixweekwait.Asaresult,
we turned to a custom full text search using ElasticSearch [ 29]
which takes in a code snippet, tokenizes the code and identifies
results based on Luceneâ€™s Practical Scoring Engine [ 6]. For this
study, each Java and Python file is added to an ElasticSearch index
andsearchedusing the ElasticSearch programmatic search API.
5.2.2 RQ2â€“ GitHubSearch. GitHubsearch engineisanIR-based
search model over code repositories, including issues, pull request,
documentation, and code data [ 81]. Using the built-in code search
onGitHub,codecanbesearchedgloballyacrossallofGitHub,or
searchedwithinaparticularrepositoryororganization.Weaddthe
JavaandPythonfilesfromthedatasettoasingleGitHubrepository
andsearchwithintherepositoryusingtheGitHubSearchAPI[ 80].
5.2.3 RQ3â€“FaCoY. FaCoY[40]isaJava-basedcode-to-codesearch
toolthatusesaqueryalternationapproachusingrelevantkeywords
from StackOverflow Q&A posts. FaCoY can be modified to change
itssearch databasefrom Q&Aposts tocustomdatasets. Inour ex-
periments,weredirectedthesearchtotherepositoriesofcodefrom
the AtCoder and BigCloneBench datasets. Similar to the experi-
mentsintheFaCoYevaluationwhencomparingagainstresearch
tools,FaCoYdoes not use StackOverflowinour baseline.
5.2.4 RQ4 â€“ ASTLearner. Perez and Chiba developed a semi-
supervisedcross-languagesyntacticclonedetectionmethodthat
wecallASTLearner[ 63].Itusesaskip-grammodelandanLSTM
based encoder. The encodings train a feed forward neural network
classifierusingnegativesamplingtoidentifyclones.ASTLearner
consideredcode as clones if the classifier score isgreater than0 .5.
5.2.5 RQ4â€“CLCDSA. CrossLanguageCodeCloneDetection[ 56]
(CLCDSA),usessyntacticfeaturesandAPIdocumentationtodetect
cross-language clones in Java, Python and C#. Nine features are
extracted from the AST; API call similarity is learned using API
documentationandaWord2Vec[ 54]model.Thevectorizedfeatures
train a reconfigured Siamese architecture [ 8] using a large amount
210Cross-LanguageCode SearchusingStatic andDynamic Analyses ESEC/FSE â€™21, August 23â€“28, 2021,Athens,Greece
Table3:SummariesofAtCoderandBigCloneBenchdatasets
AtCoder (AtC) BigCloneBench (BCB)
Metric Java Python Metric Java
#Problems 364 333 #Features 43
#Files 20,828 22,318 #Files 55,499
Avg. Files /Problem 57 67 Avg. Files /Feature 1291
#Methods 81,896 10,020 #Methods 765,331
Avg. Lines/File 51 14 Avg. Lines/File 278
oflabeleddata.CLCDSAusescosinesimilaritytodetectclones;the
bestF1 scores were when the similaritythreshold was0 .5.
5.2.6 RQ4 â€“ SLACC. Simion-based Language-Agnostic Code
Clones [51] (SLACC), uses IO behavior to identify clones. It is
alsousedinCOSALfordynamicsimilarity.Here,weuseSLACC
as a baseline in its original context, clone detection. We use the
samevaluesforthehyper-parameterssetbytheauthorsofSLACC:
MIN_STMTS issetto 1; ARGS_MAX issetto 256; SIM_Tissetto 1 .0.
5.3 Metrics
5.3.1 Code Search. For code search applications (RQ1, RQ2, RQ3),
we usePrecision@k ,SuccessRate@k ,andMRR.
Precision@k orP@kistheaveragepercentageofrelevantresults
in the top-k search results for a query [ 31,40].SuccessRate@k or
SR@kisthepercentageof queriesforwhich oneormorerelevant
result exists among the top-k search results [ 31,49].MRRis the
MeanReciprocalRankoftherelevantresultsforaquery[ 31,40,49].
Consider a query ğ‘in a set of queries ğ‘„.ğ‘…ğ‘˜ğ‘is set of all relevant
resultsinthetopkresultsfor ğ‘.ğµğ‘…(ğ‘)istherankofthefirstrelevant
searchresultfor ğ‘.ğ›¿ğ‘˜isanindicatorfunctionwhichreturns1ifthe
inputisless thanorequal to ğ‘˜and0otherwise.Mathematically,
ğ‘ƒ@ğ‘˜=/summationtext.1
ğ‘âˆˆğ‘„|ğ‘…ğ‘˜ğ‘|
ğ‘˜
|ğ‘„|ğ‘†ğ‘…@ğ‘˜=/summationtext.1
ğ‘âˆˆğ‘„ğ›¿ğ‘˜(ğµğ‘…(ğ‘))
|ğ‘„|ğ‘€ğ‘…ğ‘…=/summationtext.1
ğ‘âˆˆğ‘„1
ğµğ‘…(ğ‘)
|ğ‘„|
Precision@k ,SuccessRate@k andMRRrange[0.0,1.0]. For better
readability, in the rest of study, we report these metrics as per-
centages ranging between [0,100]. Forğ‘˜=1,Precision@k and
SuccessRate@k are the same. For higher values of ğ‘˜,SuccessRate@k
indicateswhether there is something relevant in the results, Preci-
sion@kmeasures how relevant the ğ‘˜results are on average. We set
ğ‘˜={1,3,5,10}. Higher values of MRRimply relevant results are
rankedhigher inthe results.
5.3.2 Clone Detection. For clone detection [ 56,63] (RQ4), we use
Precision,RecallandF1score.Precision (P) is the ratio of valid
clonestothenumberofretrievedclones. Recall(R)istheratioof
the number of accurately detected clones to the number of total
actualclones. F1orF-Measure ,istheharmonicmeanofprecision
and recall.We define |ğ¶+|as thenumber ofvalid clones identified,
|ğ¶âˆ’|as the number of valid clones not identified, and |ğ‘ğ¶+|as the
number ofinvalidclones identified:
ğ‘ƒ=|ğ¶+|
|ğ¶+| + |ğ‘ğ¶+|ğ‘…=|ğ¶+|
|ğ¶+| + |ğ¶âˆ’|ğ¹1=2âˆ—ğ‘ƒâˆ—ğ‘…
ğ‘ƒ+ğ‘…
Precision,RecallandF1rangefrom [0.0,1.0].Likethecodesearch
metrics, we report Precision,RecallandF1as percentages between[0,100]forbetterreadability.Highervaluesof precision meanthe
detected clonescontain fewerfalse positives andhighervalues of
recall mean more clones were identified with fewer false negatives.
5.4 ExperimentalSetup
Our experiments were run on a Ubuntu 18.04 LTS Virtual Machine
with 32 CPUs and 64GB memory using a Dell PowerEdge R640
server with Intel Xeon Silver 4210 CPU @ 2.2 GHz and VMware
ESXi6.7.0hypervisior.Theexperimentshavefourhyper-parameters:
5.4.1 Minimum Token Size. (MIN_TOK_SIZE in ÄŸ3.1) This is set to
three. IR based techniques [ 33,86] on source code find that tokens
less thanthree characters are irrelevant.
5.4.2 Minimum Segment Size. (MIN_STMTS in ÄŸ3.3) A small value
ofMIN_STMTS results in more granular snippets. We set it to 1 for
maximum number ofbehavioralsnippetsof code.
5.4.3 Maximum Number of Arguments. (ARGS_MAX in ÄŸ3.3) Prior
workfinds ARGS_MAX=256wassufficientforcross-languageclones
inGoogle Code Jam[ 27],sowe use the same.
5.4.4 NumberofIndividualSearchResults. (TOP_NinÄŸ3.4)This is
setto100.WeexperimentedonCOSALwith10%oftheAtCoder
datasetvarying TOP_Nin{10,20,50,100,200,500}.ForTOP_Ngreater
than100,weseeaminimalchangeinthecodesearchmetrics.Hence,
for eachindividualsearch, we fetch the top100search results.
6 RESULTS
We present the results ofeachRQinturn.
6.1 RQ1: Single vsMultipleSearch Similarity
Measures
In a cross-language search context, we compare the results of
COSALwithmultiplesearchsimilaritymeasurestoCOSALwith
subsetsofthesimilarity(e.g.,COSAL ğ´ğ‘†ğ‘‡isCOSALwithonlythe
ASTsimilarity).Thevalidation ofthisstudywasperformedusing
â€˜leave-one-outâ€™cross-validation[ 72]whereeach code fragmentis
usedasaqueryagainstallotherfragmentsintherepository.We
use this approach over the traditional k-fold cross validation since
â€˜leave-one-outâ€™ is approximately unbiased and more thorough [ 50].
Eachofthe43,146codefragmentsisusedasaquery.Theresults
are detailed in Table 4. Overall, COSAL outperforms the other
formulations that use subsets of the similarity measures. It also
outperforms an alternate ranking approach based on weighted
measures (KDTree [ 13]).
We observe that token-based search (COSAL ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›ğ‘ ) and AST-
basedsearch(COSAL ğ´ğ‘†ğ‘‡)arelesspreciseindividuallycompared
todynamicsearch(COSAL ğ‘†ğ¿ğ´ğ¶ğ¶),buthavehighersuccessratefor
ğ‘˜={5,10}.Whenboththestaticsimilaritymeasuresareusedas
parts of a bi-similarity search (COSAL ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘–ğ‘), we see better metrics
comparedtoeachsimilarityindividually,andbettermetricsthan
thedynamicapproachCOSAL ğ‘†ğ¿ğ´ğ¶ğ¶inP@kandSR@kwhenğ‘˜>1.
Thepowerofthetechniquecomesfromusingstaticanddynamic
informationwithoutconvertingthemintoasinglesearchmetric.
Rather than non-dominated ranking, an alternate avenue would be
a weighted approach. For example, KD ğ¼ğ‘‚+ğ´ğ‘†ğ‘‡+ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›usesğ‘‘ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›,
ğ‘‘ğ´ğ‘†ğ‘‡andğ‘‘ğ¼ğ‘‚to build a KDTree [ 13], a common approach used
211ESEC/FSE â€™21, August 23â€“28, 2021,Athens,Greece GeorgeMathewandKathryn T. Stolee
Table 4: RQ1 & RQ2: Cross-language code search re-
sults on AtCoder dataset comparing COSAL against the
state-of-the-practice ( SotP) GitHub, and ElasticSearch.
COSAL ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›, COSAL ğ´ğ‘†ğ‘‡, COSAL ğ‘†ğ¿ğ´ğ¶ğ¶use single search
similarities ( Single Sim. )ğ‘‘ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›,ğ‘‘ğ´ğ‘†ğ‘‡andğ‘‘ğ¼ğ‘‚respectively.
COSAL ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘–ğ‘usesğ‘‘ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›andğ‘‘ğ´ğ‘†ğ‘‡with non-domination.
KDğ¼ğ‘‚+ğ´ğ‘†ğ‘‡+ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›performs code search with KDTree using
ğ‘‘ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›,ğ‘‘ğ´ğ‘†ğ‘‡andğ‘‘ğ¼ğ‘‚.Codesearchtechniquesusingmultiple
similarity measuresare represented with Multi Sim.
Search MRR P@1/3/5/10 SR@1/3/5/10
SotPElasticSearch 29 27/25/23/24 27/44/57/75
GitHub 37 32/36/38/39 32/49/60/73
Single
Sim.COSAL ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘› 31 27/31/40/42 27/48/58/72
COSAL ğ´ğ‘†ğ‘‡ 34 34/41/45/44 34/41/58/82
COSAL ğ‘†ğ¿ğ´ğ¶ğ¶ 45 42/42/35/27 42/45/47/47
Multi
Sim.COSAL ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘–ğ‘ 43 40/45/44/48 40/72/85/86
KDğ¼ğ‘‚+ğ´ğ‘†ğ‘‡+ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›39 39/41/40/37 39/56/71/89
COSAL 64 58 /64/65/61 58/88/91/94
forinformationretrieval[ 21,30].AlthoughKD ğ¼ğ‘‚+ğ´ğ‘†ğ‘‡+ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›and
COSALusethesamesimilaritymeasuresforcodesearch,theformer
under-performsonallmetricscomparedtothelatter.Thissuggests
that aggregation of similarity measures into a single measure does
not helpcode searchas thesemeasures complementeachother.
Usingnon-dominatedrankingwithstaticanddynamicsimilarity
measures improves the quality of results for code-to-code search
comparedto subsetsoraweightedaggregation ofmeasures.
6.2 RQ2: State-of-the-Practice Cross-Language
Code-to-CodeSearch
We compare COSAL against GitHub Search ( ÄŸ 5.2.2) and a custom
full text search based on ElasticSearch ( ÄŸ 5.2.1). We use â€˜leave-one-
outâ€™cross-validationwitheachofthe43,146codefragmentsasa
query.Results are showninTable 4.
We observethatbetweenthetextual codesearch tools,GitHub
Search has better MRR,Precision@k andSuccessRate@k compared
to ElasticSearch except for SuccessRate@10 . Yet, GitHub Search and
ElasticSearchare worse off comparedto COSAL inallmetrics.
COSALobtainsbetter Precision@k ,SuccessRate@k andMRRcom-
paredto GitHubSearchandElasticSearch.
6.3 RQ3: State-of-the-Art Code-to-CodeSearch
FaCoY[40]isastate-of-the-artcode-to-codesearchtoolforJava.
Hence,wecompareCOSALagainstFaCoYusingJavacodesnippets
only.ThisreducestheAtCoderdatasetto351problemswith20,673
Java files. To ensure that the dataset is not skewed due to outlier
projects with limited submissions, we use Java projects with 10
or more submissions. Like RQ1 and RQ2, we use â€˜leave-one-outâ€™
cross-validation with each of the 20,673 code fragments as a query
andthe remaining problems as the searchindex.Table 5: RQ3: Single-language Java code search comparing
COSAL to the state-of-the-art ( SotA) FaCoY on AtCoder and
BigCloneBench.
Search MRR P@1/3/5/10 SR@1/3/5/10AtCoderSotAFaCoY 51 37/35/33/32 37/40/49/63
Single
Sim.COSAL ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›ğ‘  46 36/32/31/29 36/40/45/58
COSAL ğ´ğ‘†ğ‘‡ 40 38/33/31/28 38/42/51/69
COSAL ğ‘†ğ¿ğ´ğ¶ğ¶ 40 39/39/38/32 39/48/52/59
Multi
Sim.COSAL ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘–ğ‘ 53 43/45/44/41 43/58/65/77
COSAL 57 50 /53/54/48 50/63/75/88BigCloneBenchSotAFaCoY 76 70/68/68/65 70/72/74/81
Single
Sim.COSAL ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›ğ‘  75 69/65/61/59 69/72/74/81
COSAL ğ´ğ‘†ğ‘‡ 72 68/61/55/51 68/74/76/83
COSAL ğ‘†ğ¿ğ´ğ¶ğ¶ 07 06/02/01/01 06/07/07/09
Multi
Sim.COSAL ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘–ğ‘ 8176/73/72/67 76/ 81/89/94
COSAL 81 77 /73/72/68 77/81/89/94
The results for MRR,Precision@k andSuccessRate@k are tabu-
latedinTable 5.COSALhasbetterscoresonallmetricscomparedto
FaCoY. Even if COSAL is used with only static similarity measures
(COSAL ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘–ğ‘), itconsistently performs betterthanFaCoY.
Since, FaCoY supports only Java, we also compare FaCoY to
COSALusingBigCloneBench.Thisexperimentmovesustoward
evaluating the feasibility of COSAL with open-source projects. We
again use â€˜leave-one-outâ€˜ cross-validation where each file from
BigCloneBench is used as a query and the other files are used as
search results. A search result is considered valid if it has the same
functionalitygroup as the search query.
Compared to AtCoder, theBigCloneBenchdatasetyields better
resultsforalltechniques.Thisisbecausethe43functionalitiesin
BigCloneBench have minimal overlap. This can be corroborated by
thebetterscoresfortoken-basedsearchcomparedtotheAST-based
search on BigCloneBench dataset. In contrast, on AtCoder, AST-
basedsearchout-performstoken-basedsearch.LiketheAtCoder
dataset, search based on a combination of measures (COSAL ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘–ğ‘,
COSAL)yieldbetterresults comparedto FaCoY.
Only4,984 (9%)ofthefilesfromBigCloneBenchareexecutable
bySLACC;theremainingfilesdependonexternallibraries.Thus,
dynamic similarity (COSAL ğ‘†ğ¿ğ´ğ¶ğ¶) has much lower scores in Ta-
ble5. Subsequently, the inclusion of dynamic similarity hardly
contributes to the results of COSAL as highlighted by their similar
valuesforCOSAL ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘–ğ‘andCOSAL.Wedivedeeperintotherole
ofdynamic similarityinÄŸ 7.1.
Compared to state-of-the-art Java code-to-code search FaCoY,
usingdynamicinformationhelpsCOSALobtainsbettersearch
resultswhenexecutablecodesnippetsarepresent.Intheabsence
of dynamic information, a combination of AST and token-based
similaritymeasures stillyieldsbetterresults thanFaCoY.
6.4 RQ4:Cross-LanguageCodeCloneDetection
As there is no existing tool for cross-language code-to-code search,
weinsteadcomparetocross-languagecodeclonedetectiontech-
niques: ASTLearner, CLCDSA and SLACC. While code-to-code
212Cross-LanguageCode SearchusingStatic andDynamic Analyses ESEC/FSE â€™21, August 23â€“28, 2021,Athens,Greece
Table 6: RQ4: Cross-language performance of COSAL in
clone detection compared to ASTLearner, CLCDSA, and
SLACC on AtCoder.
Clone Detector Precision Recall F1
Single Sim.ASTLearner 25 80 38
CLCDSA 49 83 62
SLACC 66 19 30
Multi Sim.COSAL ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘–ğ‘ 48 85 61
COSAL 55 89 68
searchcanbepartofclonedetection,theyaredifferent.Foragiven
codesnippet,codeclonedetectionreturnsanidenticalcodesnip-
pet and code-to-code search returns a set of potentially relevant
snippets. Hence, to use COSAL as a clone detection tool, we select
the top-1 ranked search result returned by non-dominated ranking.
ASTLearner and CLCDSA build deep learning models and re-
quire a training, validation and testing set. Hence we randomly
divide our dataset into these three sets using the same approach
adoptedinCLCDSA[ 56].Weonlyconsiderprojectswithatleast
20 Java and 20 Python submissions, reducing the dataset to 302
different problems. For each problem, we select ten submissions
eachfromJavaandPythonaspartofthetrainingset,fiveforthe
validationsetandfiveforthetestset.Weusedthedefaulthyper-
parametersfromASTLearnerandCLCDSAtobuildtheirmodels.
Since COSAL and SLACC do not use machine learning models, we
add all the submissions from the training set to the search data-
base and use the test set for evaluation. We do not include the
validation set in the search database to ensure a fair comparison to
ASTLearner and CLCDSA. To account for variance, we repeat this
step 10 times andreport the mean precision,recallandF1scores.
Results are shown in Table 6, separating the techniques that
use a single similarity measure ( Single Sim. ) from those that use
multiplesimilaritymeasures( MultiSim. ).SLACCisthemostprecise
technique onthis dataset but hasextremely low recallcomparedto
othertechniques,andhencethelowestF1.Thelow recallonSLACC
is because itrequires executable codesnippets.COSALhas better
precision andrecallcompared to the static similarity approaches
ASTLearner and CLCDSA. If COSAL is used only with the static
similaritymeasures(COSAL ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘–ğ‘),theprecision andrecallisstill
betterthanASTLearnerandcomparable to CLCDSA.
Forcodeclonedetection,COSALobtainsbetter precision,recall
andF1scorescomparedtoASTLearnerandCLCDSA,without
theneedtobuild models.COSAL haslower precision toSLACC
but muchbetter recallandF1score.
7 DISCUSSION
We have evaluated COSAL extensively against prior work in code-
to-code search and clone detection. In all cases, it outperforms the
competitionwithouttheneedtobuild,train,orupdatemodels.In
this section, we discuss the cost/benefit of dynamic analysis, the
potentialfor scalability,andthreatsto the validity.Table 7: Performance based on 4,984 executable code snip-
pets fromBigCloneBench.
Search MRR P@1/3/5/10 SR@1/3/5/10
SotP GitHub 68 64/58/54/46 64/68/72/75
SotA FaCoY 79 74/70/68/57 74/76/81/84
Single
Sim.COSAL ğ‘†ğ¿ğ´ğ¶ğ¶ 8281/78/74/67 81/83/89/94
Multi
Sim.COSAL ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘–ğ‘ 80 78/75/72/66 79/83/87/91
COSAL 83 81 /79/74/68 81/86/91/96
Table 8: Pearsonâ€™s correlation ( ğ‘Ÿ) between ğ‘‘ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›,ğ‘‘ğ´ğ‘†ğ‘‡and
ğ‘‘ğ¼ğ‘‚for cross-language snippets on AtCoder (AtC) and
within-language Java snippets on AtCoder and on 4,984 ex-
ecutable BigCloneBench(BCB) datasets.
Dataset LanguageCorrelations (ğ‘Ÿ)
ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›,ğ´ğ‘†ğ‘‡ ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›,ğ¼ğ‘‚ ğ´ğ‘†ğ‘‡,ğ¼ğ‘‚
AtC Java â†”Python -0.38 0.33 -0.41
AtC Java â†”Java -0.49 0.51 -0.68
BCB Java â†”Java -0.46 0.53 -0.71
7.1 On theCost/BenefitofDynamicAnalysis
In ÄŸ6.3and Table 5, we observe a low scores for code search using
IO-basedsimilarity(COSAL ğ‘†ğ¿ğ´ğ¶ğ¶)comparedtoothertechniques
due to the small sample of files in BigCloneBench (9%) with exe-
cutablecode.Tostudytherelativecontributionofdynamicanalysis
toCOSALresults,werepeatthevalidationstudyonBigCloneBench
but restrictedto the filesthat can be executed(4,984).
Resultsonthe executable dataset are slightlybetterforallthe
techniquescomparedtothecompleteBigCloneBenchdataset(Ta-
ble7). Although COSAL ğ‘†ğ¿ğ´ğ¶ğ¶is slightly better than COSAL ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘–ğ‘,
executing snippets takes more time and memory, making code
search slow and impractical if the runtime data are not cached.
Sincethe gains are not veryhigh with the BigCloneBenchdataset,
itmightbe sufficient to relyonstaticsimilarityinthis case.
However, this cannot be generalized across datasets as Big-
CloneBench is built on Java code from open-source projects. For
cross-languagesearch(Table 4),usingdynamicandstaticsimilarity
measuresvastlyimprovestheresults.Thisisduetothesyntacticdif-
ferences between languages which can be overcome in many cases
with dynamic information [ 35]. Hence, the benefit of including
dynamic similaritymustbe balancedagainst the costandcontext.
7.2 On Non-dominatedSorting
For cross-language code search, combining the similarity measures
using an aggregated weighted approach (KD ğ¼ğ‘‚+ğ´ğ‘†ğ‘‡+ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›) results
in lower MRR, P@kandSR@kcompared to the non-dominated
sortingapproach(Table 4).Asonepotentialexplanation,thispoorer
performance for the aggregation approach could be a result of bias
due to the independence or weak correlation between the three
similarity measures [ 17] . In this section, we explore the impact of
the correlations between the similaritymeasures.
213ESEC/FSE â€™21, August 23â€“28, 2021,Athens,Greece GeorgeMathewandKathryn T. Stolee
1classHashMultiSet<E> ... {
2...
3public int count(Object element) {
4 Count frequency = Maps. safeGet(backingMap, element);
5 return(frequency == null) ?0: frequency. get();
6}
7...
8}
(a)Methodthat returnscountof a MultiSetfrom google-guava
1classCounter(dict):
2"""
3... count ...
4"""
5...
6def__getitem__(key):
7 returnself.get(key, 0)
8...
(b) Function to get countof a key froma Counter from
collections library.
Figure 4: Open Source code; the query in (a) yields (b) based
on cross-language static anddynamic information
Table8showsthePearsonâ€™scorrelation( ğ‘Ÿ)betweenthethreesim-
ilarity measures for cross-language and within-language snippets
on20repeatsof1000randompairsofsnippets.Overall,forthecross-
language analysis, we observe lower correlations compared to the
within-languageanalyses.Thecross-languagecorrelationsareweak
(0.20â‰¤ |ğ‘Ÿ| â‰¤0.39) [55] to moderate (0 .40â‰¤ |ğ‘Ÿ| â‰¤0.59). The single-
languagecorrelations are moderateto strong(0 .60â‰¤ |ğ‘Ÿ| â‰¤0.79).
Connectingthistoourresults,theweaktomoderatecorrelations
inthecross-languagecontextmayhavecontributedtorelatively
betterperformanceofnon-dominatedsorting.Sincenon-dominated
sortingiseffectiveforsearchobjectiveswithlowcorrelation[ 82,
92],itseemsappropriateforcross-languagecode-to-codesearch.
Studieshavealsoshownthatnon-dominatedsortingworksbestfor
fewerobjectives[ 23,91].AsCOSALisextendedwithmoremetrics
inthe future,we willwant to revisitthis analysis.
However, as correlation impacts the performance of the ranking
algorithm, non-dominated sorting is not a panacea. When the simi-
laritymeasuresaremorestronglycorrelated,whichouranalysis
shows is true for single-language code search, a different approach
maybe needed,such as aggregation orevolutionary algorithms.
7.3 ScalabilityExploration
Weexplorethreescalabilityconcerns:indexingandsearchingopen-
sourcecode,addingnewlanguages,andaddingsimilaritymeasures.
7.3.1 Open-Source Repositories. We used the AtCoder and Big-
CloneBench datasets to benchmark our experiments, similar to
prior art in code search and clone detection [ 40,71,77,78]. Yet,
neither dataset is particularly realistic. AtCoder is composed of
programming contest submissions and is not a true representation
ofopen-sourcecode.BigCloneBenchcontainsexamplecodeclones,
making clone detection and code search relatively easier. To some
extent,thesedatasets setus(andthe baselines)upfor success.
WewanttoexplorehowCOSALcouldworkwithanarbitrary
open-source project. To do this, we consider three popular open-
source libraries for Java and Python: GuavaJava library by Google,
commons-collections Java library by Apache Software Foundation,
andcollections Python2.7 systemlibrary.
ConsiderthecodesnippetsinFigure 4.Forthisexample,COSAL
uses4(a)as the query, which counts the number of occurrencesof an object in the MultiSet. Across languages, COSAL identifies a
similarcodesnippetfromthe collections libraryinPython: 4(b)
returns the count of an element from a Counter. ACounteris a
Python collection, like a bag, that takes elements and maintains
a count of their occurrences. For this pair, we can see that they
sharefewcommontokens( count, get ),donothavesimilarASTs,
butare behaviorallysimilar.Hence,the token-basedandIO-based
similarity in COSAL influence the ranking of search results and
returns4(b)as avalid search result for the query 4(a).
In our experiments, we see low scores for COSAL ğ‘†ğ¿ğ´ğ¶ğ¶since
only around 9% of the files in BigCloneBench had executable code.
In this open-source exploration, around 68% of the Java and all the
Python classes had executable code. The presence of dependent
codeinthelibrariescomparedtotheisolatedfilesinBigCloneBench
actually facilitatedmore widely applicable behavioralanalysis.
Thus,weconcludethatCOSALcanbescaledtosupportopen-
source projects in the current implementation. The token-based
and AST-based similarity measures for COSAL can be used on
any project or file(s) in its current version. Since the behavioral
similaritymeasureusedbyCOSALisheavilydependentonSLACC,
scaling to support new projects would require the projects have all
its dependencies satisfiedandexecutable.
7.3.2 Support for New Languages. COSAL currently supports Java
and Python. While we have not demonstrated scalability to new
languages,we comment onthe effortrequired.
For dynamic behavior, COSAL is dependent on SLACC [ 51], so
addinganewlanguagetoCOSALrequiressupportinSLACC.How-
ever,COSAL ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘–ğ‘canbeextendedtonewlanguagesbyadapting
the token and AST analyses. A language-specific tokenizer like
c-tokenizer [ 32] or a generic tokenizer like ANTLR [ 61] can be
used to parse code and convert it into tokens as detailed in ÄŸ 3.1.
FortheAST,COSALusesagenericASTtorepresentsourcecode
acrossdifferentlanguages.Usingalanguage-specificASTParser
likeclangforC[ 45]orroslynfor.NET[ 22],codecouldbeparsed
and converted to the generic AST-based on the grammar available
intheGitHubcoderepositoryforCOSAL[ 2].Ifafeaturespecific
to a language is not supported by the grammar, a new node should
be createdbasedonthe featureâ€™ssyntactic structure.
7.3.3 AddingNewSearchSimilarityMeasures. COSALusesthree
searchsimilaritymeasuresforcode-to-codesearch,whichprovides
a start for this line of research. New search similarity measures
can be added or existing similarity measures can be replaced in
COSAL.First,asimilaritymeasuretocomparecodesnippetshas
tobedefined.Thesimilaritymeasurehastobeanumericalvalue
tosupportnon-dominatedrankingofthesearchresults.Next,an
indexmustbecreatedcharacterizingthesimilaritymeasure.Lastly,
the similaritymeasure has to be updatedinthe configurationfile.
7.4 Threatsto Validity
LanguageBias .COSALwasimplementedforJavaandPython
andmaynot generalize to otherlanguages.
BaselineBias .TheElasticSearchbaselineforcross-languagecode-
to-code search (in RQ2) is not an exact representation of a code-to-
code searchtoolusedbydevelopers [ 70].
214Cross-LanguageCode SearchusingStatic andDynamic Analyses ESEC/FSE â€™21, August 23â€“28, 2021,Athens,Greece
DataBias .Thedatasetsarefromaprogrammingcontestanda
codeclonebenchmark,whicharenotrepresentativeofindustrial
or open-source coding practices. However, our initial investiga-
tionintoopen-sourcecode(ÄŸ 7.3.1)revealedthatCOSALcanbe
successfulinthat context,but more explorationisneeded.
Similarity Bias . COSAL uses three similarity measures based on
syntacticandsemanticfeaturesforcodesearchbasedonthecontext,
structure and IO behavior. Other similarity measures [ 9,62] are
not explored in this study. But, COSAL can be extended to support
thesesimilaritymeasures as describedinSection ÄŸ 7.3.3.
8 RELATED WORK
We present work incode similarity,search, andclone detection.
8.1 CodeSimilarity
Sourcecodesimilarityisusedtocharacterizetherelationshipbe-
tween pieces of code in software engineeringapplicationssuch as
program repair [ 28,37,57,74,75], code search [ 40,49,66], soft-
waresecurity[ 67,84,89]andidentifyingplagiarizedcode[ 7].Code
similaritycan be measuredthroughstaticordynamic analyses.
Techniques that use static code attributes to compute similar-
ityoftenparsecodeintoan intermediaterepresentationbasedon
text[7,36,47],AST[11,34]orgraph-based[ 26,46]andcompute
a measure for syntactic similarity. For cross-language syntactic
similarity, most techniques are text-based [ 43,56,58]. Tree- and
graph-basedapproacheshavenotbeenexploredforcross-language
similarity due to language specific grammar. We tackle this chal-
lenge by creating a language-agnostic grammar by abstracting out
common features acrosslanguagesto buildagenericAST ( ÄŸ 3.2)
Techniques that execute code to determine similarity are classi-
fied as dynamic. For some techniques, functions are adjudged to
be similar if they have similar inputs, outputs, and side-effects [ 24,
35,51,78]. Other techniques use abstract program states after exe-
cutions to analyze the behaviors of the code fragments [ 39,64,77].
Dynamic measures are particularly successful in detecting code
clones across languages since it does not rely on syntactic prop-
erties [35,51]. Limitations to this approach include the need to
executethe code whichdictatesthe granularity [ 20]andruntime.
8.2 CodeSearch
Incodesearch,thegoalistofindcodethatissimilartoagivenquery.
Historically,developershavepreferredgeneralsearchenginessuch
asGoogleandBingwhen searching for code to reuse [ 73,75,76].
Somecodesearchtools[ 1,44]usecodesnippetsasthequery,aprob-
lemcalledcode-to-codesearch.Solutionstocode-to-codesearch
vary in several dimensions, we list three: within [ 31,40] vs. across
languages[ 49,56,63],static[1,34,36]vs.dynamicanalysis[ 51,68],
andindex-based[ 40,49,81]vs. modelbased[ 31,56,63].
In cross-language code-to-code search, the query is a code snip-
petinonesourcelanguageandtheresultsarefromadifferenttarget
language(s).AROMA[ 49],supportscross-languagecode-to-code
search across Java, Hack, JavaScript, and Python using static analy-
sis based on the parse tree. Since AROMA is not publicly available,
it is not used as a baseline in this study. InferCode [ 16] is a self su-
pervised cross-language (Java, C, C++ and C#) code representation
approach using Tree-based Convolutional Neural Networks basedon syntax subtrees. Since this work was performed in parallel to
our study, we have not benchmarked COSAL against InferCode
and leave that for future work. FaCoY [ 40] is a within-language
code-to-code search tool on JAVA that uses query alteration to find
semantically similar code snippetsusing Q&A posts.
8.3 CloneDetection
Clone detection is a special case of code-to-code search; results are
identified as clones if they meet a specified similarity threshold.
Clonesareoftencategorizedintofourtypes:typesI-IIIarebased
onsyntax andtype IVisbasedonbehavior.
Mostcodeclonedetectiontools[ 11,26,34Å›36,46,47,78]have
been proposed for single language clone detection and on static
typed languages like Java [ 34,42] and C [ 11,34,36,88]. A small
numberoftoolssupportcross-languagecodeclonedetection[ 51,
56,58,63]. API2Vec [ 58] detects clones between two syntacti-
cally similar languages by embedding source code into a vectors
and subsequently comparing the similarity between the vectors.
CLCDSA[ 56]identifiesninefeaturesfromthesourcecodeASTand
usesadeepneuralnetworktolearnthefeaturesanddetectcross
language clones. Perez and Chiba [ 63] propose an LSTM-based
deep learning architecture using ASTs to detect clones in Java and
Pythoncode.Thesethreetoolsbuildmachinelearningmodelsto
detect code clones. As a result, these techniques require a large
numberofannotatedtrainingdatatobuildthemodelandthehyper-
parametersneedto be carefullyoptimizedto avoid over-fitting.
SLACC [51] is a cross-language code clone detection tool that
uses IO profiles. It succeeds in detecting code clones with high
precisionbetweenprogramminglanguageswithdifferenttyping
schemes. However, SLACC requires the code snippets to be exe-
cutableandas aresult has lowrecallandalarge runtime.
In a clone detection context, we use CLCDSA, the Perez and
Chiba approach, andSLACC as baselinesfor comparison (ÄŸ 6.4).
9 CONCLUSION
We present COSAL, a cross-language code-to-code search tool that
uses static and dynamic analyses. It uses two static similarity mea-
suresbasedonextractedtokensfromsourcecodeandatreeeditdis-
tance based on a generic AST, and one dynamic similarity measure
tocomputeIOsimilarity.Foragivencodesearchquery,thesethree
similarity measures find results using non-dominated sorting. Our
experimentalevaluationon98,645JavaandPythonfilesfromAt-
Coder and BigCloneBench datasets show that COSAL outperforms
state-of-the-art code search tools FaCoY and industrial benchmark
of GitHub code search. We also compare COSAL to state-of-the-
art clone detection techniques using the AtCoderdataset and find
that COSAL has better RecallandF1. Cross-language code-to-code
search appears to have a bright future, but more work is needed to
evaluate itfor more languagesandinrelevantapplications.
ACKNOWLEDGMENTS
We thank the anonymous reviewers for their valuable feedback.
This work is supported in part by the National Science Foundation
underNSF SHF# 1645136,#1749936,and#2006947.
215ESEC/FSE â€™21, August 23â€“28, 2021,Athens,Greece GeorgeMathewandKathryn T. Stolee
REFERENCES
[1] [n.d.]. SearchCode. searchcode.com . [Online;accessed 06-February-2020].
[2]2021.COSAL. Mathew, George and Stolee, Kathryn T. Stolee. https://doi.org/10.
5281/zenodo.4968705
[3]Yasemin Acar,MichaelBackes,Sascha Fahl, Doowon Kim,Michelle LMazurek,
andChristianStransky.2016. Yougetwhereyouâ€™relookingfor:Theimpactof
informationsourcesoncodesecurity.In 2016IEEESymposiumonSecurityand
Privacy (SP) . IEEE,289Å›305. https://doi.org/10.1109/SP.2016.25
[4]Miltiadis Allamanis, Earl T Barr, Christian Bird, and Charles Sutton. 2014.
Learning natural coding conventions. In Proceedings of the 22nd ACM SIG-
SOFT InternationalSymposiumonFoundationsofSoftwareEngineering .281Å›293.
https://doi.org/10.1145/2635868.2635883
[5] AtCoderInc. [n.d.]. AtCoder. atcoder.jp . Accessed:2020-08-12.
[6]LeifAzzopardi,YasharMoshfeghi,MartinHalvey,RamiSAlkhawaldeh,Krisztian
Balog,EmanueleDiBuccio,DiegoCeccarelli,JuanMFernÃ¡ndez-Luna,Charlie
Hull, Jake Mannix, et al .2017. Lucene4IR: Developing information retrieval
evaluationresourcesusingLucene.In ACMSIGIRForum ,Vol.50.ACMNewYork,
NY, USA,58Å›75. https://doi.org/10.1145/3053408.3053421
[7]Brenda S Baker. 1995. On finding duplication and near-duplication in large
softwaresystems.In Proceedingsof2ndWorkingConferenceonReverseEngineering .
IEEE,86Å›95. https://doi.org/10.1109/WCRE.1995.514697
[8]PierreBaldiandYvesChauvin.1993. Neuralnetworksforfingerprintrecognition.
neuralcomputation 5,3(1993),402Å›418. https://doi.org/10.1162/neco.1993.5.3.402
[9]Geetika Bansal and Rajkumar Tekchandani. 2014. Selecting a set of appropriate
metrics for detecting code clones. In 2014 Seventh International Conference on
Contemporary Computing (IC3) . IEEE, 484Å›488. https://doi.org/10.1109/IC3.2014.
6897221
[10]EarlTBarr,YuriyBrun,PremkumarDevanbu,MarkHarman,andFedericaSarro.
2014. Theplasticsurgeryhypothesis.In Proceedingsofthe22ndACMSIGSOFT
International Symposium on Foundations of Software Engineering . ACM, 306Å›317.
https://doi.org/10.1145/2635868.2635898
[11]Ira D Baxter, Andrew Yahin, Leonardo Moura, Marcelo Santâ€™Anna, and Lorraine
Bier. 1998. Clone detection using abstract syntax trees. In Software Maintenance,
1998. Proceedings., International Conference on . IEEE, 368Å›377. https://doi.org/10.
1109/ICSM.1998.738528
[12]StefanBellon,RainerKoschke,GiulioAntoniol,JensKrinke,andEttoreMerlo.
2007. Comparison and evaluation of clone detection tools. IEEE Transactions on
softwareengineering 33,9(2007),577Å›591. https://doi.org/10.1109/TSE.2007.70725
[13]JonLouisBentley.1975. Multidimensionalbinarysearchtreesusedforassociative
searching. Commun. ACM 18, 9 (1975), 509Å›517. https://doi.org/10.1145/361002.
361007
[14]Dave Binkley, Marcia Davis, Dawn Lawrie, Jonathan I Maletic, Christopher
Morrell, and Bonita Sharif. 2013. The impact of identifier style on effort and
comprehension. Empirical Software Engineering 18, 2 (2013), 219Å›276. https:
//doi.org/10.1007/s10664-012-9201-4
[15]S Bird,E Klein,and E Loper. 2009. Accessing text corpora and lexical resources.
Natural Language Processingwith Python (2009).https://doi.org/10.5555/1717171
[16]Nghi DQ Bui, Yijun Yu, and Lingxiao Jiang. 2021. InferCode: Self-Supervised
Learning of Code Representations by Predicting Subtrees. In 2021 IEEE/ACM
43rdInternationalConferenceonSoftwareEngineering(ICSE) .IEEE,1186Å›1197.
https://doi.org/10.1109/ICSE43902.2021.00109
[17]WilliamAVClarkandKarenLAvery.1976. Theeffectsofdataaggregationin
statisticalanalysis. GeographicalAnalysis 8,4(1976),428Å›438. https://doi.org/
10.1111/j.1538-4632.1976.tb00549.x
[18]PythonCommunity.[n.d.]. Python Keywords. tiny.cc/q7jqsz . Accessed:2020-08-
12.
[19]Kalyanmoy Deb, Amrit Pratap, Sameer Agarwal, and TAMT Meyarivan. 2002.
Afastandelitistmultiobjectivegeneticalgorithm:NSGA-II. IEEEtransactions
onevolutionarycomputation 6,2(2002),182Å›197. https://doi.org/10.1109/4235.
996017
[20]Florian Deissenboeck, Lars Heinemann, Benjamin Hummel, and Stefan Wagner.
2012. Challengesofthedynamicdetectionoffunctionallysimilarcodefragments.
InSoftwareMaintenanceandReengineering(CSMR),201216thEuropeanConference
on. IEEE,299Å›308. https://doi.org/10.1109/CSMR.2012.38
[21]Kan Deng. 1998. Omega: On-line memory-based general purpose system classifier .
Ph.D.Dissertation.Carnegie MellonUniversity. https://doi.org/10.5555/929042
[22]DotNet. [n.d.]. Roslyn. https://github.com/dotnet/roslyn . Accessed: 2020-08-12.
[23]MahaElarbi,SlimBechikh,AbhishekGupta,LamjedBenSaid,andYew-SoonOng.
2017. A new decomposition-based NSGA-II for many-objective optimization.
IEEEtransactionsonsystems,man,andcybernetics:systems 48,7(2017),1191Å›1210.
https://doi.org/10.1109/TSMC.2017.2654301
[24]RochelleElvaandGaryTLeavens.2012. Semanticclonedetectionusingmethod
ioe-behavior.In 20126thInternationalWorkshoponSoftwareClones(IWSC) .IEEE,
80Å›81.https://doi.org/10.1109/IWSC.2012.6227874
[25]Carlos M Fonseca,Peter JFleming,etal .1993. Genetic AlgorithmsforMultiob-
jectiveOptimization:FormulationDiscussionandGeneralization..In Icga,Vol.93.
Citeseer, 416Å›423. https://doi.org/10.5555/645513.657757[26]Mark Gabel, Lingxiao Jiang, and Zhendong Su. 2008. Scalable detection of
semanticclones.In Proceedingsofthe30thinternationalconferenceonSoftware
engineering . ACM,321Å›330. https://doi.org/10.1145/1368088.1368132
[27]Google. [n.d.]. Google Code Jam. code.google.com/codejam . Accessed: 2018-09-
25.
[28]Divya Gopinath, Muhammad Zubair Malik, and Sarfraz Khurshid. 2011.
Specification-basedprogramrepairusingSAT.In InternationalConferenceonTools
andAlgorithmsfortheConstructionandAnalysisofSystems .Springer,173Å›188.
https://doi.org/10.1007/978-3-642-19835-9_15
[29]ClintonGormleyandZacharyTong.2015. Elasticsearch:thedefinitiveguide:a
distributedreal-time search and analyticsengine . " Oâ€™ReillyMedia,Inc.".
[30] MichaelGreenspanandMikeYurick.2003. Approximatekd treesearchforeffi-
cientICP.In FourthInternationalConferenceon3-DDigitalImagingandModeling,
2003. 3DIM 2003. Proceedings. IEEE, 442Å›448. https://doi.org/10.1109/IM.2003.
1240280
[31]Xiaodong Gu, Hongyu Zhang, and Sunghun Kim. 2018. Deep code search. In
Proceedingsofthe40thInternationalConferenceonSoftwareEngineering .ACM,
933Å›944. https://doi.org/10.1145/3180155.3180167
[32]James Halliday. [n.d.]. c-tokenzier. https://github.com/substack/c-tokenizer .
Accessed:2020-08-12.
[33]AbramHindle,EarlTBarr,ZhendongSu,MarkGabel,andPremkumarDevanbu.
2012. On the naturalness of software. In 2012 34th International Conference on
Software Engineering (ICSE) . IEEE, 837Å›847. https://doi.org/10.5555/2337223.
2337322
[34]LingxiaoJiang,GhassanMisherghi,ZhendongSu,andStephaneGlondu.2007.
Deckard:Scalableandaccuratetree-baseddetectionofcodeclones.In Proceedings
of the 29th international conference on Software Engineering . IEEE Computer
Society, 96Å›105. https://doi.org/10.1109/ICSE.2007.30
[35]Lingxiao Jiang and Zhendong Su. 2009. Automatic mining of functionally equiv-
alent code fragments via random testing. In Proceedings of the eighteenth in-
ternational symposium on Software testing and analysis . ACM, 81Å›92. https:
//doi.org/10.1145/1572272.1572283
[36]Toshihiro Kamiya, Shinji Kusumoto, and Katsuro Inoue. 2002. CCFinder: a
multilinguistictoken-basedcodeclonedetectionsystemforlargescalesource
code.IEEE Transactions on Software Engineering 28, 7 (2002), 654Å›670. https:
//doi.org/10.1109/TSE.2002.1019480
[37]Yalin Ke, Kathryn T Stolee, Claire Le Goues, and Yuriy Brun. 2015. Repairing
programs with semantic code search. In Automated Software Engineering(ASE),
2015 30th IEEE/ACM International Conference on . IEEE, 295Å›306. https://doi.org/
10.1109/ASE.2015.60
[38]James Kennedy and Russell Eberhart. 1995. Particle swarm optimization. In
Proceedings of ICNNâ€™95-International Conference on Neural Networks , Vol. 4. IEEE,
1942Å›1948. https://doi.org/10.1109/ICNN.1995.488968
[39]Heejung Kim, Yungbum Jung, Sunghun Kim, and Kwankeun Yi. 2011. MeCC:
memorycomparison-basedclonedetector.In Proceedingsofthe33rdInternational
Conference on Software Engineering . ACM, 301Å›310. https://doi.org/10.1145/
1985793.1985835
[40]Kisub Kim, Dongsun Kim, TegawendÃ© F BissyandÃ©, Eunjong Choi, Li Li, Jacques
Klein, and Yves Le Traon. 2018. FaCoY: a code-to-code search engine. In Pro-
ceedings of the 40th International Conference on Software Engineering . 946Å›957.
https://doi.org/10.1145/3180155.3180187
[41]ScottKirkpatrick,CDanielGelatt,andMarioPVecchi.1983. Optimizationby
simulated annealing. science220, 4598 (1983), 671Å›680. https://doi.org/10.1126/
science.220.4598.671
[42]RainerKoschke,RaimarFalke,andPierreFrenzel.2006. Clonedetectionusingab-
stractsyntaxsuffixtrees.In 200613thWorkingConferenceonReverseEngineering .
IEEE,253Å›262. https://doi.org/10.1109/WCRE.2006.18
[43]Nicholas A Kraft, Brandon W Bonds, and Randy K Smith. 2008. Cross-language
Clone Detection..In SEKE. 54Å›59.https://doi.org/10.1.1.725.26
[44]KenKrugler.2013. Kruglecodesearcharchitecture. In FindingSourceCodeon
theWebforRemixandReuse .Springer,103Å›120. https://doi.org/10.1007/978-1-
4614-6596-6
[45]ChrisLattneretal .[n.d.]. clang:aClanguagefamilyfrontendforLLVM. http:
//clang.llvm.org . Accessed:2020-08-12.
[46]Jingyue Li and Michael D Ernst. 2012. CBCD: Cloned buggy code detector. In
Proceedings of the 34th International Conference on Software Engineering . IEEE
Press,310Å›320. https://doi.org/10.1109/ICSE.2012.6227183
[47]Zhenmin Li, Shan Lu, Suvda Myagmar, and Yuanyuan Zhou. 2004. CP-Miner:
ATool for Finding Copy-paste and Related Bugs in Operating SystemCode.. In
OSdi, Vol. 4.289Å›302. https://doi.org/10.1109/TSE.2006.28
[48]CristinaVLopes, Petr Maj,PedroMartins, Vaibhav Saini,Di Yang, JakubZitny,
HiteshSajnani,andJanVitek.2017. DÃ©jÃ Vu:amapofcodeduplicatesonGitHub.
Proceedings of the ACM on Programming Languages 1, OOPSLA (2017), 1Å›28.
https://doi.org/10.1145/3133908
[49]Sifei Luan, Di Yang, Celeste Barnaby, Koushik Sen, and Satish Chandra. 2019.
Aroma:Coderecommendationviastructuralcodesearch. ProceedingsoftheACM
on Programming Languages 3, OOPSLA (2019), 1Å›28. https://doi.org/10.1145/
3360578
216Cross-LanguageCode SearchusingStatic andDynamic Analyses ESEC/FSE â€™21, August 23â€“28, 2021,Athens,Greece
[50]Aleksandr Luntz. 1969. On estimation of characters obtained in statistical proce-
dureof recognition. TechnicheskayaKibernetica 3 (1969).
[51]GeorgeMathew,ChristopherParnin,andKathrynT.Stolee.2020.SLACC:Simion-
based Language Agnostic Code Clones. International Conference on Software
Engineering (ICSE) (Jul2020). https://doi.org/10.1145/3377811.3380407
[52]PhilipMayer,MichaelKirsch,andMinhAnhLe.2017. Onmulti-languagesoft-
ware development, cross-language links and accompanying tools: a survey of
professionalsoftwaredevelopers. JournalofSoftwareEngineeringResearchand
Development 5,1 (2017), 1. https://doi.org/10.1186/s40411-017-0035-z
[53]KaisaMiettinen.2012. Nonlinearmultiobjectiveoptimization .Vol.12. Springer
Science & BusinessMedia.
[54]Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient
estimationofwordrepresentationsinvectorspace. arXivpreprintarXiv:1301.3781
(2013).
[55]DavidSMooreandStephaneKirkland.2007. Thebasicpracticeofstatistics .Vol.2.
WH FreemanNewYork.
[56]KawserWazedNafi,TonnyShekhaKar,BananiRoy,ChanchalKRoy,andKevinA
Schneider. 2019. CLCDSA: cross language code clone detection using syntactical
featuresandAPIdocumentation.In 201934thIEEE/ACMInternationalConference
onAutomatedSoftwareEngineering(ASE) .IEEE,1026Å›1037. https://doi.org/10.
1109/ASE.2019.00099
[57]Hoang Duong Thien Nguyen, Dawei Qi, Abhik Roychoudhury, and Satish Chan-
dra. 2013. Semfix: Program repair via semantic analysis. In Software Engi-
neering (ICSE), 2013 35th International Conference on . IEEE, 772Å›781. https:
//doi.org/10.1109/ICSE.2013.6606623
[58]TrongDucNguyen,AnhTuanNguyen,HungDangPhan,andTienNNguyen.
2017. Exploring API embedding for API usages and applications. In Software
Engineering (ICSE), 2017 IEEE/ACM 39th InternationalConference on . IEEE, 438Å›
449.https://doi.org/10.1109/ICSE.2017.47
[59]Suphakit Niwattanakul, Jatsada Singthongchai, Ekkachai Naenudorn, and Su-
pachanun Wanapu. 2013. Using of Jaccard coefficient for keywords similarity.
InProceedings of the international multiconference of engineers and computer
scientists, Vol. 1.380Å›384.
[60] Oracle. [n.d.]. JavaLanguage Keywords. tiny.cc/s7jqsz . Accessed:2020-08-12.
[61] TerenceParr. 2013. The definitiveANTLR4 reference . Pragmatic Bookshelf.
[62]J-FPatenaude,EttoreMerlo,MichelDagenais,andBrunoLaguÃ«.1999. Extending
softwarequalityassessmenttechniquestojavasystems.In ProceedingsSeventh
International Workshop on Program Comprehension . IEEE, 49Å›56. https://doi.org/
10.1109/WPC.1999.777743
[63]DanielPerezandShigeruChiba.2019.Cross-languageclonedetectionbylearning
over abstract syntax trees. In 2019 IEEE/ACM 16th International Conference on
Mining Software Repositories (MSR) . IEEE, 518Å›528. https://doi.org/10.1109/MSR.
2019.00078
[64]David M Perry, Dohyeong Kim, Roopsha Samanta, and Xiangyu Zhang. 2019.
SemCluster: clustering of imperative programming assignments based on quan-
titative semantic features. In Proceedings of the 40th ACM SIGPLAN Confer-
ence on Programming Language Design and Implementation . 860Å›873. https:
//doi.org/10.1145/3314221.3314629
[65]Python Community. [n.d.]. Python AST. docs.python.org/3/library/ast.html .
[Online;accessed 23-August-2019].
[66]ChaiyongRagkhitwetsagulandJensKrinke.2019. Siamese:scalableandincre-
mental code clone search via multiple code representations. Empirical Software
Engineering 24, 4 (2019), 2236Å›2284. https://doi.org/10.1007/s10664-019-09697-7
[67]Baishakhi Ray, Miryung Kim, Suzette Person, and Neha Rungta. 2013. Detecting
andCharacterizingSemanticInconsistenciesinPortedCode.In Proceedingsof
the28thIEEE/ACMInternationalConference onAutomated SoftwareEngineering
(Silicon Valley, CA, USA) (ASEâ€™13). IEEE Press, Piscataway, NJ, USA, 367Å›377.
https://doi.org/10.1109/ASE.2013.6693095
[68]StevenPReiss.2009. Semantics-basedcodesearch.In 2009IEEE31stInternational
Conference on Software Engineering . IEEE, 243Å›253. https://doi.org/10.1109/ICSE.
2009.5070525
[69]PA Relf.2004. Achievingsoftware quality through identifiernames. In Qualcon
2004. 33Å›34.
[70]CaitlinSadowski,KathrynTStolee,andSebastianElbaum.2015. Howdevelopers
search for code: a case study. In Proceedings of the 2015 10th Joint Meeting on
FoundationsofSoftwareEngineering . 191Å›201.
[71]Hitesh Sajnani, Vaibhav Saini, Jeffrey Svajlenko, Chanchal K Roy, and Cristina V
Lopes.2016.SourcererCC:Scalingcodeclonedetectiontobig-code.In Proceedings
ofthe38thInternationalConferenceonSoftwareEngineering .1157Å›1168. https:
//doi.org/10.1145/2884781.2884877[72]Claude Sammut and Geoffrey I Webb. 2010. Leave-one-out cross-validation.
Encyclopediaofmachinelearning (2010), 600Å›601.
[73]Susan Elliott Sim, Medha Umarji, Sukanya Ratanotayanon, and Cristina V Lopes.
2011. How well do search engines support code retrieval on the web? ACM
TransactionsonSoftwareEngineeringandMethodology(TOSEM) 21,1(2011),1Å›25.
https://doi.org/10.1145/2063239.2063243
[74]Kathryn T Stolee and Sebastian Elbaum. 2012. Toward semantic search via SMT
solver.In ProceedingsoftheACMSIGSOFT20thInternationalSymposiumonthe
FoundationsofSoftwareEngineering .ACM,25. https://doi.org/10.1145/2393596.
2393625
[75]Kathryn T Stolee, Sebastian Elbaum, and Daniel Dobos. 2014. Solving the search
for source code. ACM Transactions on Software Engineering and Methodology
(TOSEM) 23,3 (2014), 26. https://doi.org/10.1145/2581377
[76]KathrynT Stolee,SebastianElbaum, andMatthewB Dwyer.2016. Code search
with input/output queries: Generalizing, ranking, and assessment. Journal of
Systems and Software 116 (2016), 35Å›48. https://doi.org/10.1016/j.jss.2015.04.081
[77]Fang-Hsiang Su, Jonathan Bell, Kenneth Harvey, Simha Sethumadhavan, Gail
Kaiser, and Tony Jebara. 2016. Code relatives: detecting similarly behaving
software. In Proceedings of the 2016 24th ACM SIGSOFT International Symposium
onFoundationsofSoftwareEngineering . ACM,702Å›714.
[78]Fang-Hsiang Su, Jonathan Bell, Gail Kaiser, and Simha Sethumadhavan. 2016.
Identifying functionally similar code in complex codebases. In Program Compre-
hension (ICPC), 2016 IEEE 24th International Conference on . IEEE, 1Å›10. https:
//doi.org/10.1109/ICPC.2016.7503720
[79]Jeffrey Svajlenko and Chanchal K Roy. 2015. Evaluating clone detection tools
withBigCloneBench.In 2015IEEEInternationalConferenceonSoftwareMainte-
nance and Evolution (ICSME) . IEEE, 131Å›140. https://doi.org/10.1109/ICSM.2015.
7332459
[80]Team Github. [n.d.]. Github REST API. docs.github.com/en/rest . Accessed:
2020-08-12.
[81] TeamGithub.[n.d.]. GithubSearch. tiny.cc/ig5nsz . Accessed:2020-08-12.
[82]Ye Tian, Handing Wang, Xingyi Zhang, and Yaochu Jin. 2017. Effectiveness and
efficiency of non-dominated sorting for evolutionary multi-and many-objective
optimization. Complex&IntelligentSystems 3,4(2017),247Å›263. https://doi.org/
10.1007/s40747-017-0057-5
[83]DannyvanBruggen.2015. Javaparser-ForprocessingJavacode. github.com/
javaparser/javaparser . [Online;accessed 23-August-2019].
[84]Andrew Walenstein and Arun Lakhotia. 2007. The software similarity problem
in malware analysis. In Dagstuhl Seminar Proceedings . Schloss Dagstuhl-Leibniz-
ZentrumfÃ¼r Informatik.
[85]Alex Wawro. [n.d.]. What exactly goes into porting a video game? BlitWorks
explains. http://tiny.cc/r5jqsz . Accessed:2020-08-12.
[86]QiXin and Steven P Reiss. 2017. Leveragingsyntax-relatedcode forautomated
programrepair.In 201732ndIEEE/ACMInternationalConferenceonAutomated
Software Engineering (ASE) . IEEE, 660Å›670. https://doi.org/10.1109/ASE.2017.
8115676
[87]QiXinandStevenPReiss.2019. RevisitingssFixforBetterProgramRepair. arXiv
preprint arXiv:1903.04583 (2019).
[88]Wuu Yang. 1991. Identifying syntactic differences between two programs. Soft-
ware:PracticeandExperience 21,7(1991),739Å›755. https://doi.org/10.1002/spe.
4380210706
[89]R.Yue,Z.Gao,N.Meng,Y.Xiong,X.Wang,andJ.D.Morgenthaler.2018. Au-
tomaticCloneRecommendationforRefactoringBasedonthePresentandthe
Past.In2018IEEEInternationalConferenceonSoftwareMaintenanceandEvolution
(ICSME). 115Å›126. https://doi.org/10.1109/ICSME.2018.00021
[90]KaizhongZhangandDennisShasha.1989. Simplefastalgorithmsfortheediting
distancebetweentreesandrelatedproblems. SIAMjournaloncomputing 18,6
(1989), 1245Å›1262. https://doi.org/10.1137/0218082
[91]QingfuZhangandHuiLi.2007. MOEA/D:Amultiobjectiveevolutionaryalgo-
rithmbasedondecomposition. IEEETransactionsonevolutionarycomputation
11,6 (2007), 712Å›731. https://doi.org/10.1109/TEVC.2007.892759
[92]Eckart Zitzler and Lothar Thiele. 1998. An evolutionary algorithm for mul-
tiobjective optimization: The strength pareto approach. TIK-report 43 (1998).
https://doi.org/10.1.1.40.7696
217