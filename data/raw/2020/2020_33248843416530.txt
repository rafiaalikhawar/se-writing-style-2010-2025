OCoR: An Overlapping-Aware Code Retriever
Qihao Zhu
Key Lab of High Confidence Software
Technologies, Ministry of Education
Department of Computer Science and
Technology, EECS, Peking University
Zhuqh@pku.edu.cnZeyu Sun
Key Lab of High Confidence Software
Technologies, Ministry of Education
Department of Computer Science and
Technology, EECS, Peking University
szy_@pku.edu.cnXiran Liang
Key Lab of High Confidence Software
Technologies, Ministry of Education
Department of Computer Science and
Technology, EECS, Peking University
liangxiran11@163.com
Yingfei Xiongâˆ—
Key Lab of High Confidence Software
Technologies, Ministry of Education
Department of Computer Science and
Technology, EECS, Peking University
xiongyf@pku.edu.cnLu Zhang
Key Lab of High Confidence Software
Technologies, Ministry of Education
Department of Computer Science and
Technology, EECS, Peking University
zhanglucs@pku.edu.cn
ABSTRACT
Code retrieval helps developers reuse code snippets in the open-
sourceprojects.Givenanaturallanguagedescription,coderetrieval
aimstosearchforthemostrelevantcoderelevantamongasetof
code snippets. Existing state-of-the-art approaches apply neural
networks to code retrieval. H owever, these approaches still fail
to capture an important feature: overlaps. The overlaps betweendifferent names used by different people indicate that two differ-
entnamesmaybepotentiallyrelated(e.g.,â€œmessageâ€andâ€œmsgâ€),
and the overlaps between identifiers in code and words in natu-ral language descriptions indicate that the code snippet and the
description may potentially be related.
To address this problem, we propose a novel neural architecture
named OCoR1, where we introduce two specifically-designed com-
ponents to capture overlaps: the first embeds names by characters
to capture the overlaps between names, and the second introduces
anoveloverlapmatrixtorepresentthedegreesofoverlapsbetween
each natural language word and each identifier.
The evaluation was conducted on two established datasets. The
experimentalresultsshowthatOCoRsignificantlyoutperformsthe
existing state-of-the-art approaches and achieves 13 .1% to 22.3%
improvements.Moreover,wealsoconductedseveralin-depthex-
periments to help understand the performance of the different
components in OCoR.
âˆ—Corresponding author
1OCoR, is short for An O verlapping-Aware Co de Retriever.
Permission to make digital or hard copies of all or part of this work for personal or 
classroom use is granted without fee provided that copies are not made or distributed 
for profit or commercial advantage and that copies bear this notice and the full citation 
on the first page. Copyrights for components of this work owned by others than ACM 
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, 
to post on servers or to redistribute to lists, requires prior specific permission and/or a 
fee.
 Request permissions from permissions@acm.org.
ASE '20, September 21â€“25, 2020, Virtual Event, Australia
Â© 2020 Association for Computing Machinery.
ACM ISBN 978-1-4503-6768-4/20/09â€¦$15.00
https://doi.org/10.1145/3324884.3416530CCS CONCEPTS
â€¢Information systems â†’Novelty in information retrieval ;
â€¢Software and its engineering ;â€¢Computing methodologies
â†’Information extraction ;Neural networks ;
KEYWORDS
Code Retrieval; Neural Network; Overlap
ACM Reference Format:
Qihao Zhu, Zeyu Sun, Xiran Liang, Yingfei Xiong, and Lu Zhang. 2020. 
OCoR: An Overlapping-Aware Code Retriever. In 35th IEEE/ACM Interna-
tional Conference on Automated Software Engineering (ASEâ€™20), September 
21â€“25, 2020, Melbourne, Australia. ACM, New York, NY, USA, 12 pages. 
https://doi.org/10.1145/3324884.3416530
1 INTRODUCTION
Coderetrievalisanimportantsoftwareengineeringproblem,which
aims to retrieve the most related code snippet among a set of code
snippetsbyagivennaturallanguagedescription.Aneffectivecode
retrieverhelpsdevelopersreusethecodesnippetsfromtheinternet.
For example, if a SQL programmer gives an instruction â€œget all the
dataintableAâ€,acoderetrieverwillhelptheprogrammertosearchfromthelargescaleofcodeontheinternetandfindthetargetcode
â€œselect * from Aâ€.
Withthedevelopmentofdeeplearningandthecollectionoflarge
scale labeled datasets, neural networks have been widely used for
variousareas[ 11,18,28,35,38].Forthetaskofretrieval,various
approaches have been proposed [ 8,11,18,19,40,42], by using
neuralnetworks.Theseapproachesmostlyembedthequestionandtheanswerintoahigh-dimensionalvectorspaceandtrytofindthe
most similar one between the vectors of questions and the vectors
ofanswers(e.g.,usingcosinesimilarity).Whenitisappliedtocode
retrieval, it takes the natural language description as the question
and the target code as the answer [11, 42].
However, these retrieval approaches fail to effectively handle
overlaps,whichareimportantincoderetrieval.Ononehand,differ-entpeoplemayusedifferentnamestodescribethesimilarmeanings,
either in codeor in natural languages, andsuch names often have
overlapped substrings. For example, â€œSortâ€ and â€œQuickSortâ€ has
theoverlappedsubstringâ€œSortâ€.Ontheotherhand,identifiersin
8832020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE)

!$
 !


	
+%  && '"(%"
+" &&  %
1%1-#
,% %"%&
!
%1%#
-% %"'%(
'%1%(!%#

'
(*%0/
*%-,*%-.


Figure 1: An Example from the StaQC dataset. The code re-
trieval in our approach ranks candidate code snippets withthe scores given by the model.
code are often related to words in the natural language description.
Though they may not be fully equal, overlapped sub-strings often
exist. For example, in Figure 1 the identifier â€œjoint_table_bâ€ is re-lated to the words â€œjointâ€ and â€œtableâ€. As far as we are aware, noexisting neural architecture is specifically designed for handling
overlaps.
To address these problems, we propose a novel neural architec-
ture,OCoR,acoderetrieverbasedontheoverlapfeatures.Werepre-
sent each word by combining the representations of the characters
withinit,namelyusingthecharacter-levelembeddingtocapture
the overlap between the names used by different programmers.
Furthermore, we introduce a novel overlap matrix to represent the
degrees of overlaps between each word in the natural language de-
scription and each identifier in code. Finally, we combine different
code retrieval approaches by ensemble to enhance our model.
Theexperimentwasconductedonseveralestablisheddatasets
forSQLandC#coderetrieval,followingIyeretal .,Yaoetal .[22,
42]. The experimental results show that our model significantly
outperforms existing approaches by 13 .1% to 22.3% improvements
and achieve the best performance on all the datasets. To better
understandourmodel,wealsoconductedtheexperimentsfocusing
ontheeffectivenessofthecomponents,andtheresultsshowthat
each component contributes to the overall performance.
To summarize, this paper makes the following contributions:
â€¢Weproposeanovelneuralarchitecture,OCoR,forcodere-
trieval. OCoR uses two novel techniques, namely character-
levelembeddingandtheoverlapmatrix,tocapturetheover-
laps between identifiers in code and words in natural lan-
guage descriptions.
â€¢Weconductedextensiveexperimentstoevaluatetheeffec-
tiveness of our approach and the components in our ap-proach. The results show that our approach significantly
outperforms existing approaches by 13.1% to 22.3% improve-
ments and all components in our approach are effective.
2 MOTIVATION
Asmentionedintheintroduction,therearetwotypesofoverlapsin
thecoderetrievaltask.Thefirsttypeofoverlapisthatdifferentpeo-
ple may use different names to describe the similar meanings (e.g.,
thewords innaturallanguageand theidentifiersincode).For ex-
ample, â€œjoint_table_aâ€ and â€œjoint_table_bâ€ in the first SQL query in
Figure1couldalsobenamedasâ€œjoint_table_1â€andâ€œjoint_table_2â€.
	











 
  	  	
   	 

  
   
     



 	
  
 
 	
 
Figure2:Examplesofthecomputationofthecharacter-level
embedding and the overlap matrix.
IfaneuralnetworkistrainedoverthecodeinFigure1,itisdifficultforittoknowthattheidentifiersâ€œjoint_table_1â€andâ€œjoint_table_2â€
are also related to the same query. To address this challenge, exist-
ingapproaches[ 42]forcoderetrievalreplacingvariablenamesand
raw strings with the variable types and numbers (e.g., rename the
first table variable â€œjoint_table_bâ€ in a SQL with â€œTable_1â€). In this
way,theneuralnetworkisforcedtoignoretheidentifiernamesbut
usesthestructureofthecodeandtheidentifiertypes.However,thename of the identifier potentially carries useful information for thecoderetrieval,andignoringthemislikelytolowertheperformance.
Tosolvethisproblem,weproposecharacter-levelembeddingtoen-
code the names. The character-level embedding first encodes each
character within each name via one-hot encoding and combine
theserelativevectorsbyaconvolutionallayer.Figure2(a)shows
the computation of character-level embedding of â€œjoint_table_bâ€
and â€œjoint_table_câ€.As shown,the combinedvectors ofthese two
identifiersarealmostcomputedfromthesamevectorsexceptthe
vector of the last character. Thus, the final embedding of these
identifiers is closed to each other in the high-dimensional space.
Thesecondtypeofoverlapisthatidentifiersincodeareoften
related to some words in natural language description. In a general
perspective, this type of overlap is the overlap between questionand answer, and is often considered in existing information re-
trievalapproaches.Theseapproachesmeasurethenumberofthe
exactly matched tokens between the questions and the answers.
However,inthecoderetrievaltask,identifiersincodeandwords
innaturallanguagedescriptionsareoftennotfullyequal.Forex-
ample, as shown in Figure 1, the identifier â€œjoint_table_bâ€ is not
fullyequaltoanywordinthenaturallanguagedescription,butit
is related to two words â€œjointâ€ and â€œtableâ€. To address this problem,
we not only consider exactly matched words but also measure the
degree ofoverlaps between partially matchedwords. We design a
representation,namedoverlapmatrix,torepresentthedegreeof
overlap between each word in natural language description and
each identifier in code. In this matrix, each row represents a word
in the natural language description, while each column represents
an identifier in code. Each cell is the degree of overlap between the
word and the identifier. The degree of overlap can be measured by
differentmetrics,andinthispaperweusethelongestcommonsub-
string, theproportion ofthe longest consecutivesub-string ğ‘that
appears in both the natural languages word and the code identifier.
Figure2(b)showsapartialoverlapmatrixofthequestion-codepair
in Figure 1. We can see that though identifiers â€œjoint_table_bâ€ and
884
	
	




Figure 3: An Example of the computation convolutional
layer.
word â€œjointâ€ are not exact match, their degree of overlap is still
higher than most other pairs. Finally, our model takes the over-
lapmatrixasinput,utilizingthedetailedoverlapinformationfor
identifying the most related code snippet.
3 BACKGROUND
3.1 Convolutional Layer
The Convolutional layer, which is the main building layer of a con-
volutional neural network (CNN) [ 26], has been widely used in
variousareas[ 8,18,24,26].Thislayercanberegardedasaregular-
izedversionofafully-connectedlayer.Thefully-connectedlayer
usuallyconsistsofseveralneurons,andeachneuroninonelayer
is connected to all neurons in the next layer. Different from such a
fully-connected layer, the connection in the convolutional layer is
connected from each neuron in one layer to several corresponding
neurons in the next layer. Such connections depend on pre-defined
convolutional kernels.
Innaturallanguageprocessing,theconvolutionallayerisused
toextractthefeaturesinthecontents.Givenaninputvector,which
represents the words in natural language,the convolutional layer
uses kernels to extract the features in each vector and its neighbor-
ingvectorsandoutputsanewvector.ForexampleinFigure3,foran
inputvectorofasentenceâ€œthisisacoderetrieverâ€withkernelsize
3, the layer outputs a new vector of â€œisâ€ by a weighted summation
ofthevectorsofâ€œisâ€withitsneighborsâ€œthisâ€andâ€œaâ€.Thishelps
capturethefeaturesofthecontentsintheinputnaturallanguage
descriptionandcodeofOCoR.Thus,weapplyitinourapproach.
The details of using this layer will be introduced in Section 4.
3.2 Attention
Inthebasicencoder-decoderframework[ 37]2,themodelalways
suffers from the the long-dependency problem [ 5] with long se-
quences.Toalleviatethisproblem,Bahdanauetal .[4]proposedthe
attentionmechanism,whichaimstolettheneuralmodelinspect
the relevance between each pair of tokens in two long sequences.
Recently,tobetteralleviatethelong-dependencyproblem,Vaswani
etal.[38]proposedawidelyusedattentionmechanismcalledMulti-
Head Attention. The overview of such mechanism is shown in
2The encoder-decoder framework, which is also known as sequence-to-sequence
framework,isawidelyusedapproachinneuralmachinetranslation.Inthisframework,
the neural network is divided into two parts: encoder, decoder. The encoder encodes
the sequence into a vector and the decoder decodes the vector to a sequence in target
language.





   	

     	 
Figure 4: The detail of Multi-Head Attention.
Figure 4(a). This mechanism takes three vectors (mostly the repre-
sentation of the words in the input sequence) as inputs and maps a
query vector and a set of key-value vector pairs to the output. The
main computation of this attention is called Dot-Product Attention
layers, where the input of each layer consists of query vectors ( ğ‘„),
key vectors ( ğ¾) and value vectors ( ğ‘‰) as shown in Figure 4(b). The
weightsofthevaluevectorsarecalculatedbythequeryvectorsand
thecorrespondingkeyvectors.Finally,theoutputiscomputedasaweightedsumofthevalues,wherethequerydetermineswhich
values to focus on.
Self-attentionisanattentionmechanismforasinglesequence
to extract the complex comprehension of itself (formally, ğ‘„=ğ¾=
ğ‘‰). This technique is often used to capture the long dependency
information in sequences and has good performance in various
tasks[20,38,41].Thedetailedcomputationoftheattentionmecha-
nism will be introduced in the following section.
4 PROPOSED MODEL
4.1 Problem Definition
We follow the existing studies [ 11,42] and use the same definition
forcoderetrieval.Givennaturallanguagedescription ğ‘„andaset
of candidate code snippets ğ¶, our task is to retrieve a relevant code
snippetğ¶ğ‘Ÿâˆˆğ¶that specified by ğ‘„.
AsshowninFigure1,toretrieveacodesnippet,wefirstcompute
the relevance score between each code snippet ğ‘âˆˆğ¶and the input
naturallanguagedescription ğ‘„.Then,werankthecodesnippets
in the set of candidate code snippets ğ¶. Finally, the code ğ¶ğ‘Ÿwith
the highestscore is selectedas theoutput of ourapproach, which
is computed as
ğ¶ğ‘Ÿ=argmax
ğ‘âˆˆğ¶ğ‘…(ğ‘„,ğ‘) (1)
whereğ‘…denotes the computation of the relevance score. In our
approach, the relevance score is a real number between 0 and 1.
4.2 Overview
Figure 5 shows the overview of OCoR. We adopt the traditional
overallarchitectureusedininformationretrievalFuetal .[8],where
we encode the question (the natural language description) and the
885&$
' &
$'!

#
!  #(

%!!	"

#
!  #(
%!!	"

  

# #
 	"
	 !	"
  
  
 #  #
Figure 5: The overview of the OCoR. The ğ´(ğ¶ğ‘‚ğ·ğ¸,ğ‘ğ¿ )andğ´(ğ‘ğ¿,ğ¶ğ‘‚ğ·ğ¸ )are the Overlap Matrices.
answer (the code snippet) respectively and combine the outputs
via attention layers for further predicting the target relevant score.
Based on this architecture, we design two encoders with the same
structureforthequestionandtheanswer.Eachencodertakesthe
overlap matrix and the question / answer as input and turns this
input into a set of vectors.
Furthermore, as the evaluation will show later, our model com-
plements existing approaches on code retrieval. To achieve even
better performance, we use an an additional ensemble component
to combine previous code retrieval models with OCoR.
In the rest of this section, we will describe the components of
our architecture one by one. Besides,
4.3 Input of Model
The inputs of OCoR are divided into three parts: 1) the natural
language description; 2) the code snippet; 3) the overlaps between
the natural language description and the candidate code snippet,
where the last one is computed from the first two.
4.3.1 Preprocessing. For the first two parts, we first process these
inputstomakethemsuitabletobefedtotheneuralnetwork.For
the input natural language description, we first tokenize this input
by the tool in the NLTK toolkit [ 27] and convert its characters
withinthetokenstolowercase.Asfortheinputcodesnippet,we
keeptheoriginalvariablenamesandtherawstrings,tokeepthe
semanticinformationinthenames.Then,wetokenizethecodeand
alsoconvertthecharacterswithinthenamestolowercase.Thus,
we get the preprocessed inputs for the neural network.
4.3.2 OverlapMatrix. Asmentionedbefore,weusetheoverlapma-
trix to represent the degrees of overlaps between natural language
words and code identifiers. The overlap matrix is a real-valued
matrixğ´(ğ‘‡1,ğ‘‡2)âˆˆRğ¿(ğ‘‡1)Ã—ğ¿(ğ‘‡2),which containstheoverlapscores
between a token sequence ğ‘‡1and another token sequence ğ‘‡2. Each
cellğ´ğ‘–ğ‘—(ğ‘‡1,ğ‘‡2)in this matrix denotes the overlap score between
theğ‘–-th token ğ‘‡1(ğ‘–)in theğ‘‡1sequence and the ğ‘—-th token ğ‘‡2(ğ‘—)intheğ‘‡2. Such score in OCoR is computed by
ğ´ğ‘–ğ‘—(ğ‘‡1,ğ‘‡2)=len(ğ‘†(ğ‘‡1(ğ‘–),ğ‘‡2(ğ‘—))/len(ğ‘‡2(ğ‘—)) (2)
wherelen(ğ‘‡2(ğ‘–))denotesthelengthoftheword ğ‘‡1(ğ‘–),ğ‘†(ğ‘‡1(ğ‘–),ğ‘‡2(ğ‘—)
denotes the longest common sub-string of ğ‘‡1,ğ‘‡2. In particular,
thecomputationoftheoverlapmatrix ğ´isnotcommutative,i.e.,
ğ´(ğ‘‡1,ğ‘‡2)â‰ ğ´(ğ‘‡2,ğ‘‡1).Inourapproach,weconsiderboththeoverlap
scorebetweenthenaturallanguagedescription ğ‘ğ¿andthecode
ğ¶ğ‘‚ğ·ğ¸aswellastheoverlapscorebetweenthecodeandthenatural
languagedescription,namelyboth ğ´(ğ’,ğ’„)andğ´(ğ’„,ğ’)respectively.
These two metrics are further fed to the encoder layer to extract
features for code retrieval.
4.4 Encoder
In OCoR, there are two encoders for both the natural language
description and the code. Each encoder takes the overlap matrix
andthe naturallanguagedescription/ codeasinputs. Theseinputs
are encoded into vectors in a high-dimensional space for further
similarity computations.
To better encode the input information, inspired by Vaswani
et al.[38], we design the encoder with a stack of ğ‘mechanisms.
Eachmechanismcontainsthreesub-layers:1)aselfattentionlayer;
2)agatinglayer;3)aconvolutionallayer.Aftereachmechanism,
the ResNet [ 13]3and the layer normalization [ 3]4are used. For the
firstmechanism,ittakestheoverlapmatrix,namely ğ´(ğ‘ğ¿,ğ¶ğ‘‚ğ·ğ¸ )
/ğ´(ğ¶ğ‘‚ğ·ğ¸,ğ‘ğ¿ ),asinputandfurthercombinesthenaturallanguage
description / the code. For the rest of ğ‘âˆ’1 mechanisms, they take
theoutputofthepreviousmechanismasinputandalsocombine
thefeaturesofhiddenlayersinthenaturallanguagedescription/
the code. Wewill first describe how we feedthe overlap matrix to
the first mechanism.
3ResNet is residual learning framework to ease the training of networks.
4Layer normalization normalizes the values of the neurons into a suitable distribution,
which eases the training.
886Input Overlap Matrix. The Overlap Matrix5for our approach
is a real-valued matrix, where each cell denotes the overlap scores
between the natural language words and the identifiers in code. To
take this matrix as input, we first reduce the matrix ğ´(ğ‘ğ¿,ğ¶ğ‘‚ğ·ğ¸ )
into an overlap vector ğ’‚(ğ‘ğ¿), where the ğ‘–-th element ğ’‚ğ‘–(ğ‘ğ¿)in
thisvectordenotesanewoverlapscorecomputedfromthe ğ‘–-throw
in theğ´(ğ‘ğ¿,ğ¶ğ‘‚ğ·ğ¸ )(the cells representing the ğ‘–-th token in the
naturallanguageandeachidentifierinthecode)viamax-pooling.
Max-pooling [ 24] has been shown to be an effective way to reduce
the matrix into a vector in various areas [ 10,42,44]. Following
Max-pooling, we select the maximum value for each column as the
element of ğ’‚(ğ‘ğ¿), which is computed by
ğ’‚ğ‘–(ğ’)=len(ğ’„)max
ğ‘—=1ğ´ğ‘–ğ‘—(ğ’,ğ’„) (3)
This vector contains the maximum overlap scores. For exam-
ple, the fixed-size vector of the overlap matrix in Figure 2(b) is
[0.3,0.75,0.4,0.3]. To ease neural processing of the overlap scores,
we further embed the scores with one-hot encoding. Please note
that the scores are the real-values between 0 and 1. We partition
the scores with the interval 0.01 and use a one-hot vector of length
100 to encode the scores.
4.4.1 SelfAttentionLayer. Thefirstsub-layerintheencodermech-
anismistheselfattentionlayer.Asweknow,sequentialinformation
is important in both the natural language description and the code.
To handle such information effectively, we apply the self attention
mechanism,whichisproposedbyVaswanietal .[38]andhasshown
to be an effective way to encode this information [ 38,41], as the
first sub-layer in the encoder.
Theselfattentionlayertakesthepreviousoutputvectors ğ’1,ğ’2,Â·Â·Â·,ğ’ğ¿
as input, where ğ¿denotes the length of the input natural language
description / code. This layer consists of two parts: 1) the position
embedding layer; 2) multi-head attention layer.
Position Embedding Layer. A position embedding layer is a
standard layer in transformer architecture [ 38] to provide the in-
dexesofthewordsintheinputmatrix.Forexample,thelayershould
know the word â€œjointâ€ is the 5-th token in the natural language
description in Figure 1. If we directly use an attention layer for the
input vectors, the position information will not be considered, and
this is why we need the position embedding layer.
In this layer, the vector of the ğ‘–-th position is represented as a
real-valued vector, which is computed by
ğ‘(ğ‘–,2ğ‘—)=sin(ğ‘ğ‘œğ‘ /(100002ğ‘—/ğ‘‘))
ğ‘(ğ‘–,2ğ‘—+1)=cos(ğ‘ğ‘œğ‘ /(100002ğ‘—/ğ‘‘))(4)
whereğ‘ğ‘œğ‘ =ğ‘–+ğ‘ ğ‘¡ğ‘’ğ‘,ğ‘—denotestheelementoftheinputvectorand
ğ‘ ğ‘¡ğ‘’ğ‘denotestheembeddingsize.Afterwegetthevectorofeach
position, we directly add this vector to the corresponding input
vector, where ğ’†ğ‘–=ğ’ğ‘–+ğ’‘ğ‘–.
Multi-head Attention Layer. The second part of the self at-
tentionlayeristhemulti-head6attentionlayer.Asintroducedin
thebackgroundsection,anattentionmechanismmapsaquery,a
5We takeğ´(ğ‘ğ¿,ğ¶ğ‘‚ğ·ğ¸ )as example in this section.
6Themulti-headmechanismconsistsofseveralheads,eachofwhichisanattention
layer, separately. The outputs of these heads are further jointed together by a fully-
connected layer.keyandavaluetoanoutput.Inthislayer,thequery,thekey,the
value, and output are all vectors.
Following the definition of Vaswani et al .[38], we divide the
multi-head mechanism into ğ»heads. Each head is an attention
layer, which maps the query ğ‘„, the key ğ¾and the value ğ‘‰to an
output, namely the output of each head â„ğ‘’ğ‘ğ‘‘. The computation of
theğ‘ -th head is represented as
â„ğ‘’ğ‘ğ‘‘ğ‘ =softmax(ğ‘„ğ¾ğ‘‡
/radicalbig
ğ‘‘ğ‘˜)ğ‘‰ (5)
whereğ‘‘ğ‘˜=ğ‘‘/ğ»denotesthelengthofeachextractedfeaturevector
andğ‘„,ğ¾andğ‘‰arecomputedbyafully-connectedlayerfrom ğ‘„,ğ¾,
ğ‘‰. In the encoder, the vectors ğ‘„,ğ¾andğ‘‰are all the outputs of the
positionembeddinglayer ğ’†1,ğ’†2,Â·Â·Â·,ğ’†ğ¿.Theoutputsoftheseheads
are furtherjointed togetherwith afully-connected layer,which is
computed by
ğ´ğ‘¡ğ‘¡=[â„ğ‘’ğ‘ğ‘‘1;Â·Â·Â·;â„ğ‘’ğ‘ğ‘‘ğ»]Â·ğ‘Šâ„ (6)
whereğ‘Šâ„denotestheweightsinfully-connectedlayerandtheout-
putvectors ğ´ğ‘¡ğ‘¡=[ğ’‚1,ğ’‚2,Â·Â·Â·,ğ’‚ğ¿]arethehigh-levelvectors,which
combinethesequentialinformationandtheoriginalinformation
together. However, these vectorsstill fail to encode the semantic
informationofeachwordeffectivelyatleastinthefirstmechanism
in the encoder. Thus, we will then describe how we address this
issue via a gating layer .
4.4.2 GatingLayer. Thesecondsub-layerintheencodermecha-
nism is a gating layer. This layer takes the outputs of the previous
layer and the input natural language description / code as input.
existing state-of-the-art approaches [ 42] use the word2vec [ 30]
mechanismtoutilizethesemanticinformationoftheinput.How-
ever, it may be not suitable for code retrieval, where the similar
identifierscanbenameddifferentlybydifferentprogrammersbut
withoverlappedcharacters(e.g.,itmayhaveaverysimilarmeaning
fortwowordsâ€œdataIdâ€andâ€œdata_idâ€),whichmayleadtoalargenumber of vocabulary for neural networks to learn. To address
this issue, we propose to use the character-level semantics to catch
the overlaps between identifiers in code retrieval. We combine the
outputsofthepreviouslayerwiththecharacter-levelembedding
approach for each word.
Character Embedding .To implement the character embed-
ding,wefirstpadeachtoken(boththewordinthenaturallanguage
descriptionandtheidentifierincode)toafixedlength ğ¶ğ¿witha
special character. In particular, if the length of the token is more
thanğ¶ğ¿,wetruncatetheendofthistokenandmakeita ğ¶ğ¿-length
token. Then, we represent each character in the token as a real-
valuevector,namely ğ‘’ğ‘šğ‘ğ‘’ğ‘‘ğ‘‘ğ‘–ğ‘›ğ‘” .Asweknow,atokenconsistsof
severalcharacters.Tocatchthesemanticinformationofeachtoken,
we adopt a set of convolutional layers to integrate the vectors of
the characters within the token. The extracted semantic vector for
theğ‘–-th token ğ’•ğ‘–is computed by
ğ’•(ğ‘–,ğ‘›)=ğ‘Š(ğ‘,ğ‘›)[ğ’•(1,ğ‘›âˆ’1);ğ’•(2,ğ‘›âˆ’1);Â·Â·Â·;ğ‘¡(ğ¶ğ¿,ğ‘›âˆ’1)](7)
whereğ‘Šğ‘are the convolutional weights and ğ‘›denotes the ğ‘›-th
layeroftheconvolutionallayers.Inparticular, ğ’•(ğ‘˜,0)=ğ’„ğ‘˜,where ğ’„ğ‘˜
denotesthecharacterembeddingvectorofthe ğ‘˜-thcharacterwithin
theğ‘–-thtoken.Inourapproach,wehavethreeconvolutionallayers
887for this character embedding layer. For the first two convolutional
layers, we use the zero padding and the sizes of the convolutional
kernel are set to 3 and 5, respectively.
GatingMechanism .Toincorporatethe semanticinformation
of each token with the previous outputs, we use a mechanism
namedGatingMechanism[ 36].Thismechanismincorporatesan
inputsemanticvector ğ’•ğ‘–withagivencontrolvector7withthemulti-
head mechanism. In this paper, we use the previous output vectors,
namely ğ’‚ğ‘–, as the control vector. The computation of the gating
layer in our model can be represented as
ğ›¼ğ‘œ
ğ‘–=ğ‘’ğ‘¥ğ‘(ğ’’ğ‘‡
ğ‘–ğ’Œğ‘œ
ğ‘–)/âˆš
ğ‘‘ (8)
ğ›¼ğ‘
ğ‘–=ğ‘’ğ‘¥ğ‘(ğ’’ğ‘‡
ğ‘–ğ’Œğ‘
ğ‘–)/âˆš
ğ‘‘ (9)
ğ’‰ğ‘–=(ğ›¼ğ‘œ
ğ‘–Â·ğ’—ğ‘œ
ğ‘–+ğ›¼ğ‘
ğ‘–Â·ğ’—ğ‘
ğ‘–)/(ğ›¼ğ‘œ
ğ‘–+ğ›¼ğ‘
ğ‘–) (10)
â„ğ‘’ğ‘ğ‘‘ğ‘ =[ğ’‰ğ‘–;Â·Â·Â·;ğ’‰ğ»] (11)
where ğ’’ğ‘–,ğ’Œğ‘œ
ğ‘–,ğ’—ğ‘œ
ğ‘–areallcomputedbyafully-connectedlayeroverthe
control vector ğ’‚ğ‘–;ğ’Œğ‘
ğ‘–,ğ’—ğ‘
ğ‘–are computed by another fully-connected
layer over the semantic vector ğ’•ğ‘–. After this computation, we en-
hancethevectorswiththesemanticinformation,andtheextracted
new features are denoted as ğ’„(ğ‘ğ‘œğ‘š)
1,ğ’„(ğ‘ğ‘œğ‘š)
2,Â·Â·Â·,ğ’„(ğ‘ğ‘œğ‘š)
ğ¿.
4.4.3 ConvolutionalLayer. Thefinalsub-layerintheencodermech-
anism is a set of convolutional layers. We follow the design of the
encoderproposed byVaswaniet al .[38] and adopt aset ofconvo-
lutional layers to extract the local features around each token. The
computation of the convolution layer can be represented as
ğ’šğ‘™
ğ‘–=ğ‘Šğ‘™[ğ’šğ‘™âˆ’1
ğ‘–âˆ’ğ‘¤;Â·Â·Â·;ğ’šğ‘™âˆ’1
ğ‘–+ğ‘¤] (12)
whereğ‘™denotesthe ğ‘™-thconvolutionallayerintheset, ğ‘Šğ‘™arethe
convolutional weights, ğ‘¤=(ğ‘˜âˆ’1)/2 andğ‘˜denotes the window
size. In particular, ğ’šğ‘™âˆ’1
ğ‘–is the output of the previous gating layer
ğ’„(ğ‘ğ‘œğ‘š)
ğ‘–. We use two convolutional layers in this sub-layer and add
the activation function ğºğ¸ğ¿ğ‘ˆ[14] between these convolutional
sub-layers. In particular, we use the zero padding in these layers.
4.5 Max Pooling
Afterallthese ğ‘mechanismsintheencoder,weadoptanadditional
convolutional layer as Equation 12, which is padded with a special
vector during convolution. Then, we get the final features of each
token. The features denote the high-level information of the input
natural language description / code. However, these features have
the same shape as the input. To facilitate further prediction for
code retrieval, we need to aggregate such features into a fixed-size
vector, which is regardless of the input size.
Max pooling has shown the power in aggregating features, thus,
weapplythemaxpoolingapproachovertheoutputsoftheencoder
and extract the fixed-size vector for each encoder.
7Thecontrolvectoristhespecialvectorsgiveninourapproach.Thisvectordecides
the weights of different vectors.4.6 Attention Layer
Theencodersencodetheinformationoftheinputnaturallanguage
description and the input code separately. However, it still lacks
the relations between two inputs even if we have used the prior
knowledge of the overlaps. To help the neural network learn such
relations between the two inputs, we adopt two attention layers
after the encoder.
As described in the previous section, the outputs of the encoder
combine the overlap information with semantic information (char-
acter embedding). Thus, we also apply the multi-head attentionlayer to the outputs of two encoders to extract the relations. As
for the description and the code, we design two separate attention
layers for them. The computation of the attention mechanism is
similartotheâ€œselfattentionâ€withdifferentinputs.Onelayertreats
the encodingof the descriptionas query( ğ‘„) andthe other treats
theencodingofthecodeasquery( ğ‘„).Thisdesignallowsthemodel
toextracttheweightedsumoftheoutputsoftwoencodersbasedoneachother.Aftertheattention,twoconvolutionallayersanda
max pooling layer are followed to integrate the features.
4.7 Prediction
After all the computation of the attention layer, we concatenate all
features.Theyarefurtherfedtoatwo-layerperceptronfollowed
by asoftmaxactivation. The output of these computation is the
classification probability of two classes. The first class denotes that
theinputnaturallanguagedescriptionandtheinputcodeisrelated,
whereasthesecondclassdenotesthattheinputnaturallanguage
description andthe input code isnot related. In ourapproach, the
predicted classification probabilityof the first class isthe relevancescore between the input natural language description and the code,
where the relevance score is computed by
ğ‘…(ğ‘„,ğ‘)=exp{â„1}
/summationtext.12
ğ‘—=1exp{â„ğ‘—}(13)
whereâ„ğ‘–is the input logit of softmax.
4.8 Training
Our model is trained by minimizing cross-entropy loss against the
groundtruth.Specifically,foreachtrainingdata <ğ‘„,ğ¶,ğ´ >where
ğ‘„isthedescription, ğ¶isthecode, ğ´denotesthegroundtruthclass.
The cross-entropy loss is computed by
ğ¿ğ‘œğ‘ ğ‘ (ğœƒ)=âˆ’2/summationdisplay.1
ğ‘–=1ğ‘”(ğ‘–)âˆ—logğœƒ(ğ‘–) (14)
whereğ‘”denotesthegroundtruthclass, ğœƒistheclassificationresult
predicted by the neural network.
4.9 Model Combination
Onthe basisof ourbasic modelintroduced above, wealsoconsider
an additional method that combines different models on code re-
trievaltasktogetherbyensemble.InspiredbyYaoetal .[42],where
theproposedCoaCorcombinescoderetrievalwithcodeannotation
forbetterperformance.Weconsidertocombinedifferentmodels
byintegratetherelevancescorescomputedbydifferentmodelsand
outputthefinalrelevancescoreforOCoR.Thescoreiscomputed
888by a linear combination as
ğ‘…(ğ‘„,ğ‘)=ğœ†âˆ—ğ‘†1+(1âˆ’ğœ†)âˆ—ğ‘†2 (15)
whereğ‘†1denotes the relevance score computed by OCoR, ğ‘†2is the
scorecomputedbythecombinedmodel, ğœ†isarealnumberbetween
0 and 1.
5 EXPERIMENT SETUP
In this section, we present the experimented setup. We will first
introduce the research questions8.
5.1 Research Question
Our evaluation aims to answer the following research questions:
â€¢RQ1 What is the performance of OCoR?
To answer this question, we conducted an experiment on
several established datasets and compared the performance
of OCoR with the existing state-of-the-art approaches.
â€¢RQ2 What is the contribution of each component in
OCoR?
ToanswerRQ2,westartfromthefullmodelofOCoR,and
in turn removed each component to understand the con-tribution of it. Then, we also replaced the metrics used inmeasuring the overlap score with longest common prefix
(LCP) and word embedding based similarity to better un-
derstandthecontributionofthecomponentoftheoverlap
matrix.
â€¢RQ3 Why does the model combination work?
In fact, the result of RQ1 will suggest that the model combi-
nationplacesasignificantroleintheoverallperformance.
To understand why different models can be combined, we
analyzed the distribution of the result predicted by different
models on the SQL dataset. More specifically, we selected
someexamplesfrom thesedatasetstoshow thedifferences
of the models.
5.2 Dataset
Ourexperimentisbasedontwoestablishedbenchmarks:theStaQC
benchmark[ 43], and the C# benchmark used in Iyer et al .[22]. The
StaQC benchmark contains 119,519 question-code pairs writtenin the SQL. These pairs are collected from Stack Overflow [
31],
makingitselfthelargest-to-dateinSQLdomain.Wefollowedthe
original train-dev-test split in StaQC, namely StaQC-train, StaQC-
val ,and StaQC-test. For better evaluation , we used two additional
test dataset namely â€œDEVâ€ and â€œEVALâ€ for SQL, are collected byIyer et al
.[22]. These datasets contain 110 and 100 code written
in SQL respectively. For every snippet, they use three differentreferences written by humans as the additional test cases. The
second benchmark contains 113,514 question-code pairs written in
C#collectedfromStackOverflow.WesplitthedatasetintoC#-train,
C#-val,andC#-testasIyeretal .[22,42]Thedetailedstatisticsof
these datasets are listed in Table 1.
For the StaQC benchmark, we took the training set of StaQC-
trainasthetrainingset,tooktheDEVsetasthedevelopmentset,
and took other three datasets, StaQC-test, StaQC-val, â€œEVALâ€, asthe test set. For the C# benchmark, we also followed the same
8The code of our experiment is available at https://github.com/anyone546/OCoR.experimentsettingsduringtrainingandtheC#-valwastreatedas
the development set in our experiment.
Notethattotesttheperformanceofacoderetrievalapproach,
we not only need the desirable question-code pair (the positive
answer), but also other code snippets as negative answers. We call
such a case containing a question and a set of code snippets as aretrieval case. We used the same retrieval cases used in existing
works [
22,42], where the counts of these cases are show in the
â€œNumber of Casesâ€ row in Table 1. Each retrieval case contains 1
positive code snippet and 49 negative code snippets.
5.3 Metrics
To measure the performance of our approach, we followed Yao
etal.[42]andusedastandardmetricscalledMeanReciprocalRank
(MRR) [7] in this paper.
The MRR metrics is computed over the entire dataset
ğ·={(ğ‘„1,ğ¶1),(ğ‘„2,ğ¶2),Â·Â·Â·,(ğ‘„ğ‘›,ğ¶ğ‘›)}:
ğ‘€ğ‘…ğ‘…=/summationtext.1ğ‘›
ğ‘–=11/ğ‘Ÿğ‘–
|ğ·|(16)
whereğ‘Ÿğ‘–denotes the ranking of ğ¶ğ‘–in theğ‘–-th query ğ‘„ğ‘–. In this
metrics,thehighervaluedenotesthebetterperformanceofcode
retrieval.
5.4 Implementation Details
WeimplementedourapproachbasedonTensorflow[ 1].Wesetthe
ğ‘=3,whichdenotesthateachencoderinourexperimentcontains
astackof3mechanisms.Wesettheembeddingsizeforboththe
characters and the overlap scores to 256. All hidden sizes were set
to 256 except that 1024 was used for both the first layer of the con-
volutional layer and the first layer in the MLP. During training, the
dropout[ 16]wasusedtoavoidoverfitting,wherethedropratewas
set to 0.2. Our model was optimizedby Adam optimizer [ 25] with
learning rate 0 .0001. For the model combination, we set the hyper-
parameter ğœ†to0.1.Thesehyper-parametersandparametersforour
model were chosen based on the development set (DEV is used),
which followed the existing state-of-the-art work [ 42]. Specifically,
for each query natural language description in the training corpus,
we randomly sampled 5 code snippets as the negative examples for
eachtrainingepoch.InOCoR,thenaturallanguagedescriptionand
the code snippet shared the same embedding weights.
5.5 Baselines
Inour experiment,we usedthe existingstate-of-art coderetrieval
approaches as the baselines for comparison.
â€¢DeepCodeSearch(DCS)[ 11].DCSjointlyembedstheinput
codesnippetsandtheinputnaturallanguagedescriptioninto
a high-dimensional vector space with an RNN based neural
network.Inthisway,acodesnippetanditscorresponding
naturallanguagedescriptionhavesimilarvectors,whichare
then used for computing the similarity between two inputs
by cosine similarity.
â€¢CODE-NN [ 22]. The core component of CODE-NN is an
LSTM-based RNN [ 17] with attention. This attention mech-
anismcomputestheprobabilityofannaturallanguagede-
scription,givenacodesnippet.Forcoderetrieval,givenan
889Statistics StaQC-train StaQC-val StaQC-test DEV EVAL C#-train C#-dev C#-test
Number of QC-pairs 89,688 11,932 17,899 330 300 77,816 17,849 17,849
Number of Cases - 11,900 17,850 6,600 6,000 - 17,800 17,800
Avg. tokens in description 9 9 9 10 15 12 12 12
Max. tokens in description 32 35 45 45 35 37 34
Avg. tokens in code 59 62 60 47 47 38 38 38
Max. tokens in code 3,367 2,774 2,672 291 291 290 300 310
Table1:Statisticsofthedatasetsweused.â€œNumberofQC-pairsâ€denotesthetotalamountofquestion-codepairsinthespecific
dataset. â€œNumber of Casesâ€ is the number of the retrieve cases for evaluation.
inputnaturallanguagedescription,CODE-NNcomputesthe
probability of the input for each code. After the computa-
tion, CODE-NN ranks the given code snippets based on the
probability.
â€¢CoaCor[ 42].CoaCorusedareinforcementlearning-based
frameworktocombinecoderetrievalandcodeannotation
together for enhancing the code retrieval. They also com-
bine the code retrieval approaches together by ensemble to
improvetheperformance.Inparticular,thebasicmodelof
CoaCor is denoted as QN-RLMRR, whereas the combined
models (the best performance) are denoted as QN-RLMRR+
CODE-NN.
6 RESULTS
In this section, we report the results of our experiment and answer
the research questions.
6.1 Performance of OCoR (RQ1)
The results of RQ1 are presented in Table 2.
We first compare the original OCoR with the original models
(Ori.inTable2).Asshown,amongthethreestate-of-the-artmodels,
OCoRachievesthebestperformanceonalldatasets.OCoRishigher
than the existing best results, by 9 .1% to 28.2% improvements.
Forthemodelcombination,wefirstcombineOCoRwiththeorig-
inal model QN-RLMRR(denoted as OCoR + QN-RLMRR). We select
the state-of-the-art models proposed by Yao et al .[42] (QN-RLMRR
+CODE-NN)asthebaselines.AsshowninTable2,ourapproach
significantly outperforms existing state-of-the-art models by 10
pointsimprovementonaverage.Inparticular,weachieved13 .1%to
22.3%improvementsonalldatasets,whichshowseffectivenessof
our approach. Then, we combine OCoR with the model combined
byY aoetal .(QN-RLMRR+CODE-NN),wherewealsoachievedthe
bestresults(OCoR+(QN-RLMRR+CODE-NN))amongalldatasets.
The results suggests that our approach is more effective than
existing state-of-the-art models on different datasets and different
program languages.
Answerto RQ1:OCoR hasagoodperformance (13 .1%to
22.3% improvements) compared with the existing state-of-
the-art approaches on all datasetscovering two program-
ming languages.6.2 The contribution of each component (RQ2)
To answer RQ2, we first conducted the ablation test on the SQL
dataset to figure out the contribution of each component. In this
subsection,weonlyconductedtheexperimentbasedontheorig-
inal OCoR, which aims to understand the contribution of each
component more clearly.
The model in the ablation test had the same setting with the
original OCoR except we removed each component in turn. The
resultsarepresentedinTable3.WefirstremovedtheinputoverlapscoresfromOCoR.Toremovethis,insteadofusingoverlapmatrices
as the inputs of the first mechanism in the encoder, we replacedit with the input tokens in natural language description / code.
Furthermore, we followed the previous joint model [ 6,11] and the
model was trained by minimizing the cosine similarity betweenthe natural language description and code as the . By applying
suchsettings,theperformancewasclosedtothepreviousapproach
based on word2vec which shows the effect of the overlap matrix.
To better understand the contribution of the metrics for com-
putingoverlapscores(namelyEquation2),wefurtherconducted
theexperimentonthesamedatasetsbutwithadifferentmetrics
of overlapscores. Thebaseline metriccompared withthe original
metric is wordsimilarity based on word embedding.We first used
theGloVe[ 32]topretrainthewordembeddingvectorbasedonthe
training set with BPE [ 34]. Then we use the cosine similarity of
ğ’˜1,ğ’˜2astheoverlapscore.TheresultsarepresentedinTable3.The
character-level metric achieves better performance on all datasets.
Thisresultshowsourmetricsaremoresuitablethanthetraditional
similarity matrix used in document retrieval for code retrieval.
We also replaced the original overlap metric with Longest Com-
monPrefix(LCP).Thelongestcommonprefixofapairofstrings
ğ‘andğ‘is the longest string ğ‘which is the prefix of both strings.
We useğ‘™ğ‘’ğ‘›(ğ‘)/ğ‘™ğ‘’ğ‘›(ğ‘),ğ‘™ğ‘’ğ‘›(ğ‘)/ğ‘™ğ‘’ğ‘›(ğ‘)as the overlap scores of two
strings,respectively.Inparticular,wealsocomputethescorebased
onthelongestcommonsuffix,andfinallyselectthebiggeroneas
the overlap score. The performance of this metric is slightly lower.
Theablationtestalsoindicatesthatthecharacter-levelinformation
is important to the code retrieval task.
Answerto RQ2:Eachcomponentcontributestotheoverall
performance of OCoR.
890Model EVAL StaQC-val StaQC-test C#Ori.DCS 0.555 0.534 0.529 0.441
CODE-NN 0.514 0.526 0.522 0.531
QN-RLMRR0.512 0.516 0.523 0.528
OCoR 0.601 0.647 0.643 0.682Com.QN-RLMRR+ CODE-NN 0.571 0.575 0.576 0.629
OCoR + QN-RLMRR0.630 0.658 0.677 0.746
OCoR + (QN-RLMRR+ CODE-NN) 0.646 0.665 0.685 0.764
Table 2: The results show the MRR of code retrieval among 50 examples. In this table, we divide the existing model into two
differentcategories.Thefirstcategory(Ori.),wheretheoriginalmodelisused,isinthe2to5rows.Thesecondcategory(Com.),
where different models are combined together by ensemble, is in the 6 to 9 rows.
Model EVAL StaQC-val StaQC-test
OCoR 0.601 0.647 0.643
- Overlap Score 0.420 0.545 0.538
Character-level Overlap âˆ’ â†’WordSimilarity 0.554 0.603 0.605
Overlapâˆ’ â†’LCP 0.591 0.628 0.632
Table3:TheablationtestonOCoR,whereOCoRdenotesthe
original model of our approach.

	 	
		
Figure6:Theoverlapsoftheprefectrankingofdifferentap-
proaches the among three datasets.
6.3 Model Combination Analysis (RQ3)
To answer RQ3, we try to figure out the reason why the model
combination works. We first implemented the existing approaches,
CoaCor (QN-RLMRR) and CODE-NN. Then, we studied the predic-
tionoverlapsoftheperfectrankingamongthedatasets.Foragiven
naturallanguagedescriptionandasetofcodesnippetswithonepositive code snippet, the â€œperfect rankingâ€ in this paper means
that the positive code snippet is ranked in the top-1.
TheresultsarepresentedinFigure 6.Asshown,onthesethree
datasets,16 .2%perfectrankingcasesonaveragecanbesolvedby
allthreeapproaches,whereas26 .1%,3.7%,2.3%(32.3%inall)perfect
rankingcasesonaveragecanonlysolvedbytheapproachOCoR,
CoaCor and CODE-NN respectively. Such 32 .3% cases show the
potentialimprovementsonmodelcombination,andthisiswhythe
model combination works well in our approach.
Tohelpunderstandthemodelcombination,wealsoconductedan
additionalcasestudy.Inthiscasestudy,weanalyzeOCoRwiththe
existing state-of-the-art model (CoaCor, QN-RLMRR+ CODE-NN).
Case study. Table 4 shows three examples that are ranked per-
fectlybyOCoRbutnotCoaCor.Asshown,therearemanyoverlaps
between the input natural language description and the code inSQL (e.g., the word â€œselectâ€ and â€œdataâ€ in the first example, row2,3; the word â€œtableâ€ and â€œtimeâ€ in the second example). In these
examples,theinformationofoverlapscoresisimportant,wherea
human can utilize this information and retrieved the target code
easily,andOCoRcatchessuchinformationsuccessfully.Existing
approaches like CoaCor do not utilize the information of over-
lapscoresproperly,wheretheCoaCorapproachdirectlyusesthe
token-level embedding for the neural network and replaces identi-
fiernameswithnumberedplaceholdertokens(e.g.,theSQLcode
in the second example is turned to â€œselect col0 (col1) from tab1â€ in
Table4).Thus,OCoRhasagoodperformanceontheseexamples,
while the CoaCor does not work well, which is the strength of
OCoR.
To understand the weakness of OCoR, we also conducted an-
other case study on examples where OCoR does not work wellcompared with the CoaCor. These examples are presented in Ta-
ble 5. As shown, in these examples there are few overlaps between
theinputnaturallanguagedescriptionandthecodeinSQL.Insuch
a situation, OCoR can hardly measure the overlap scores in thematrix, which makes it difficult to utilize the key information ofoverlap scores in OCoR. However, CoaCor, which combines the
annotation generation and code retrieval together, replaces identi-
fiernameswithnumberedplaceholders,andextractsthehigh-level
information of these situations. This is the reason why CoaCorhas a good performance on these examples. The cases show the
891Type Example
Description selecta formatted daterange from values in a table column
SQL Code selectdate_format(start date,â€™%mâ€™)+date_format(start date,â€™%dâ€™)+â€™-â€™+ date_format(end date,â€™%dâ€™)+â€™,â€™+
date_format (startdate, â€™%yâ€™) from yourtable;
Description SQL Insertmultiple Values where1 value comes fromaselectquery
SQL Code insertinto table2 ( telnumber , adress ) selectâ€™12324567890â€™ , applicatieid fromapplicatie wherename =
â€™pietâ€™ ;
Description Quick way to spacefill column 256chars SQL-Server 2012
SQL Code select space(256);
Table 4: The examples that ranked perfectly by OCoR but not CoaCor.
Type Example
Description how to use max and top in sql query in oracle?
SQL Code select id, item, quantity, date from (select id,
item, quantity, date from your_table order by
quantity desc, date desc) where rownum = 1;
Description find 1 level deep hierarchical relationship be-tween columns of a table for one of the top
level values
SQL Code select t2.cat_id, t2.subcat_id, t2.name from test
t1 join test t2 on t1.cat_id = t2.cat_id where
t1.subcat_id = 42 and t2.subcat_id <> 42 ;
Table 5: The examples that ranked perfectly by CoaCor but
not OCoR.
weaknessofOCoR,whichdoesnothaveagoodperformancewhen
theoverlapscoresarehardtomeasure.Itisprobablyagoodway
tocombinedifferentapproachestogetherandutilizethestrength
of each approach. Thus, we use the model combination to combine
the strengths of different approaches.
Answerto RQ3:Thethreetechniques complementseach
other, allowing the model combinations to produce better
results.
7 THREATS TO VALIDITY
Threatstointernalvalidity. Athreattointernalvalidityisthe
potentialfaultsintheimplementationofourexperiments.Toreduce
this threat, for the performance of original models, we directlyuse their reported performances [
42], and, for the performance
of combined models, we directly used their published code [ 42].
Furthermore, the implementation of our model was based on a
published model [36] to avoid faults in re-implementation.
Threatstoexternalvalidity. Our model was evaluated on the
StaQC and the C# benchmarks, which are widely used in previous
code retrieval approaches [ 22,42]. In these two benchmarks, allof the programs are collected from Stack Overflow, which givesa threat to external validity. However, we find that the overlap
relations we used also widely exist in datasets collected from other
sources such as GitHub [ 9]. For example, in CodeSearchChallenge
Corpus[21]whichisanothercoderetrievalbenchmarkcollected
from GitHub repositories, 98.6%, 95.4%, 94.18% and 96.8% of the
instanceshaveatleastoneoverlapforPython,Java,JavaScript,and
Go, respectively, while only 89.12% in the StaQC dataset used in
ourexperiment.Suchwidelyexistedrelationsshowthepotential
value of our approach when applied to the GitHub benchmarks.
Meanwhile,sinceourapproachwasonlytestedonSQLandJava
programs collected from Stack Overflow, further studies are alsoneeded to apply our model to other programming languages col-
lected from GitHub.
8 RELATED WORK
Code Retrieval. Coderetrievalin softwaredevelopmenthelps
developersreusetherelevancecodesnippetsamongalargescale
open-sourceprojects.Earlystudiesmostlyfocusonapplyingthe
informationretrievalmethodstocoderetrievaltask[ 2,11,12,15,
23,29,39]. With the development of deep learning, more and more
works try to use neural networks to code retrieval [ 11,22,42]. Gu
et al.[11] first proposed an LSTM-based RNN for code retrieval,
wheretheyencodetheinputnaturallanguagedescriptionandcode
intoavectorspaceandmeasurethecosinesimilaritybetweenthem.BasedonacodeannotationworkproposedbyIyeretal
.[22],where
they use a sequence-to-sequence model to generate the specificannotation by a given code, Yao et al
.[42] proposed CoaCor for
code retrieval,where they combinethe code annotationapproach
ofIyeretal .andthecoderetrievalapproachofGuetal .together
bya reinforcement learningframework. Differentfromtheseap-proaches, we focus on unitizing the overlap scores between the
natural language description and code. Based on this, we proposed
a novel neural architecture for code retrieval.
Overlap Information .Many works focus on using neural net-
works combined with overlap information in sentence pairs match-
ing [8,18,19]. Huet al .[18] firstproposed to usea neural network.
They adopted a stack of convolution layers to infer the relation
betweenthequestionandthegivenanswer.QiuandHuang[ 33]
introducedatransformationlayertousetheinteractionbetween
892thequestionandtheanswer.Theytriedtoutilizehiddenunitsto
extracttheoverlapsbasedonhiddenstates.Fuetal .[8]proposed
a kind of overlap features and combined it with a convolutional
network. Such overlap features compute the similarity betweentwo words via whether they are the same. It cannot utilize the
overlapbetweenwords(e.g.,theoverlapbetweenâ€œjoint_table_aâ€
and â€œtableâ€), which is important in encoding identifiers in code.
The atomic value of these overlap features cannot represent the
relation between identifiers and corresponding words. Thus, wedesign the overlap matrix based on longest common sub-string
tomeasurethedegreeoftheoverlap.Wealsoadoptsomespecial
neural components for this representation.
9 CONCLUSION AND FUTURE WORK
Inthispaper,weproposedanoveloverlap-awareneuralarchitec-
ture (OCoR) for code retrieval. Our approach makes use of theoverlap score between the natural language description and the
code by using the overlap matrix and the character embedding.
We evaluated our approach on several datasets. The experimen-
tal results show that OCoR achieves significant improvement com-
pared with existing state-of-the-art approaches. The further evalu-
ation shows that each component in our approach is important.
Futurework. Ourapproachisbuiltmainlyonthebasisofover-
lap scores between two inputs, especially for the natural language
description and code. The experimental results show that the over-
lapscorecanboosttheperformanceofthemodel.Itisinterestingtostudyasthefurtherworktotrymoremetricstomeasurethedegreeoftheoverlapsbetweentwostrings(e.g.,EditDistanceandLongest
CommonSub-string).Ourexperimentalsoshowsthepotentiality
oftheensemble(namelymodelcombination),whichmayalsobe
aneffectivewaytousesuchtechniquetocombinedifferentmetrics
toimprovetheperformance.Furthermore,OCoR,canbedirectly
applied to other programming languages (e.g., Java, Python andC++). Our model is designed for the general code retrieval task
andsomespecificfeaturesmaybeaddedtoitbygating.Itisalso
interesting to study as the further work.
ACKNOWLEDGMENTS
ThisworkissponsoredbytheNationalKeyResearchandDevel-
opmentProgramofChinaunderGrantNo.2017YFB1001803,and
National Natural Science Foundation of China under Grant Nos.
61672045 and 61922003.
REFERENCES
[1]MartÃ­n Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen,
Craig Citro, Greg S Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, et al .
2016. Tensorflow:Large-scalemachinelearningonheterogeneousdistributed
systems. arXiv preprint arXiv:1603.04467 (2016).
[2]Miltos Allamanis, Daniel Tarlow, Andrew D. Gordon, and Yi Wei. 2015. Bimodal
Modelling of Source Code and Natural Language. In Proceedings of the 32nd
International Conference on Machine Learning, ICML 2015, Lille, France, 6-11 July
2015 (JMLRProceedings),FrancisR.BachandDavidM.Blei(Eds.),Vol.37.Journal
ofMachineLearningResearch:WorkshopandConferenceProceedings,2123â€“
2132.
[3]Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. 2016. Layer normaliza-
tion.arXiv preprint arXiv:1607.06450 (2016).
[4]Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural Machine
Translation by Jointly Learning to Align and Translate. arXiv:cs.CL/1409.0473[5]Y. Bengio, P. Simard, and P. Frasconi. 1994. Learning long-term dependencies
with gradient descent is difficult. IEEE Transactions on Neural Networks 5, 2
(March 1994), 157â€“166. https://doi.org/10.1109/72.279181
[6]JoseCambronero,HongyuLi,SeohyunKim,KoushikSen,andSatishChandra.
2019. When Deep Learning Met Code Search. arXiv:cs.SE/1905.03813
[7]Nick Craswell. 2009. Mean reciprocal rank. Encyclopedia of Database Systems
(2009), 1703â€“1703.
[8]Jian Fu, Xipeng Qiu, and Xuanjing Huang. 2016. Convolutional deep neural
networks for document-based question answering. In Natural Language Under-
standing and Intelligent Applications. Springer, 790â€“797.
[9] github. 2020. https://github.com/. github.
[10]Alessandro Giusti, Dan C CireÅŸan, Jonathan Masci, Luca M Gambardella, and
JÃ¼rgenSchmidhuber.2013. Fastimagescanningwithdeepmax-poolingconvolu-
tionalneuralnetworks.In 2013IEEEInternationalConferenceonImageProcessing.
IEEE, 4034â€“4038.
[11]XiaodongGu,HongyuZhang,andSunghunKim.2018. Deepcodesearch.In 2018
IEEE/ACM 40th International Conference on Software Engineering (ICSE). IEEE,
933â€“944.
[12]SoniaHaiduc,GabrieleBavota,AndrianMarcus,RoccoOliveto,AndreaDeLucia,andTimMenzies.2013. Automaticqueryreformulationsfortextretrievalinsoft-
ware engineering. In 2013 35th International Conference on Software Engineering
(ICSE). IEEE, 842â€“851.
[13]Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2015. Deep Residual
Learning for Image Recognition. arXiv:cs.CV/1512.03385
[14]Dan Hendrycks and Kevin Gimpel. 2016. Bridging Nonlinearities and Stochastic
Regularizers with Gaussian Error Linear Units. CoRRabs/1606.08415 (2016).
arXiv:1606.08415 http://arxiv.org/abs/1606.08415
[15]EmilyHill,ManuelRoldan-Vega,JerryAlanFails,andGregMallet.2014.NL-based
queryrefinementandcontextualizedcodesearchresults:Auserstudy.In 2014
SoftwareEvolutionWeek-IEEEConferenceonSoftwareMaintenance,Reengineering,
and Reverse Engineering (CSMR-WCRE). IEEE, 34â€“43.
[16]Geoffrey E. Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, andRuslan R. Salakhutdinov. 2012. Improving neural networks by preventing co-
adaptation of feature detectors. arXiv:cs.NE/1207.0580
[17]SeppHochreiterandJÃ¼rgenSchmidhuber.1997. Longshort-termmemory. Neural
computation 9, 8 (1997), 1735â€“1780.
[18]Baotian Hu, Zhengdong Lu, Hang Li, and Qingcai Chen. 2015. Convolu-
tional Neural Network Architectures for Matching Natural Language Sentences.
arXiv:cs.CL/1503.03244
[19]HeHuaandJimmyLin.2016. PairwiseWordInteractionModelingwithDeep
Neural Networks for Semantic Similarity Measurement. In Conference of the
North American Chapter of the Association for Computational Linguistics: Human
Language Technologies.
[20]Cheng-Zhi Anna Huang, Ashish Vaswani, Jakob Uszkoreit, Ian Simon, Curtis
Hawthorne,NoamShazeer,AndrewM.Dai,MatthewD.Hoffman,MonicaDin-
culescu, and Douglas Eck. 2019. Music Transformer: Generating Music with
Long-Term Structure. In ICLR.
[21]Hamel Husain, Ho-Hsiang Wu, Tiferet Gazit, Miltiadis Allamanis, and Marc
Brockschmidt.2019. CodeSearchNetChallenge:EvaluatingtheStateofSemantic
Code Search. arXiv:cs.LG/1909.09436
[22]Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, and Luke Zettlemoyer. 2016.
Summarizingsourcecodeusinganeuralattentionmodel.In Proceedingsofthe
54thAnnualMeetingoftheAssociationforComputationalLinguistics(Volume1:
Long Papers). 2073â€“2083.
[23]Iman Keivanloo, Juergen Rilling, and Ying Zou. 2014. Spotting Working Code
Examples.In Proceedingsofthe36thInternationalConferenceonSoftwareEngi-
neering (ICSE2014).ACM,NewYork,NY,USA,664â€“675. https://doi.org/10.1145/
2568225.2568292
[24]Yoon Kim. 2014. Convolutional Neural Networks for Sentence Classification.
arXiv:cs.CL/1408.5882
[25]DiederikP.KingmaandJimmyBa.2014. Adam:AMethodforStochasticOpti-
mization. arXiv:cs.LG/1412.6980
[26]AlexKrizhevsky,IlyaSutskever,andGeoffreyEHinton.2012. Imagenetclassifica-tion with deep convolutional neural networks. In Advances in neural information
processing systems. 1097â€“1105.
[27]Edward Loper and Steven Bird. 2002. NLTK: the natural language toolkit. arXiv
preprint cs/0205028 (2002).
[28]Hong Mei and Lu Zhang. 2018. Can big data bring a breakthrough for software
automation? Science China Information Sciences 61 (05 2018), 056101. https:
//doi.org/10.1007/s11432-017-9355-3
[29]Meili Lu, X. Sun, S. Wang, D. Lo, and Yucong Duan. 2015. Query expansion via
WordNet for effective code search. In 2015 IEEE 22nd International Conference
on Software Analysis, Evolution, and Reengineering (SANER) . 545â€“549. https:
//doi.org/10.1109/SANER.2015.7081874
[30]Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient
Estimation of Word Representations in Vector Space. arXiv:cs.CL/1301.3781
[31] Stack Overflow. 2020. https://stackoverflow.com/. Stack Overflow.
893[32]JeffreyPennington,RichardSocher,andChristopherD.Manning.2014. GloVe:
GlobalVectorsforWordRepresentation.In EmpiricalMethodsinNaturalLan-
guage Processing (EMNLP). 1532â€“1543. http://www.aclweb.org/anthology/D14-
1162
[33]Xipeng Qiu and Xuanjing Huang. 2015. Convolutional Neural Tensor Network
Architecture for Community-Based Question Answering.. In IJCAI, Qiang Yang
andMichaelWooldridge(Eds.).AAAIPress,1305â€“1311. http://dblp.uni-trier.de/
db/conf/ijcai/ijcai2015.html#QiuH15
[34]Rico Sennrich, Barry Haddow, and Alexandra Birch. 2015. Neural Machine
Translation of Rare Words with Subword Units. arXiv:cs.CL/1508.07909
[35]Zeyu Sun, Qihao Zhu, Lili Mou, Yingfei Xiong, Ge Li, and Lu Zhang. 2019. A
grammar-based structural cnn decoder for code generation. In Proceedings of the
AAAI Conference on Artificial Intelligence, Vol. 33. 7055â€“7062.
[36]ZeyuSun,QihaoZhu,YingfeiXiong,YicanSun,LiliMou,andLuZhang.2020.
TreeGen:ATree-BasedTransformerArchitectureforCodeGeneration.In The
Thirty-FourthAAAIConferenceonArtificialIntelligence,AAAI2020,TheThirty-
Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020,
The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence,EAAI 2020, New York, NY, USA, February 7-12, 2020 . AAAI Press, 8984â€“8991.
https://aaai.org/ojs/index.php/AAAI/article/view/6430
[37]IlyaSutskever,OriolVinyals,andQuocVLe.2014. Sequencetosequencelearning
withneuralnetworks.In Advancesinneuralinformationprocessingsystems.3104â€“
3112.[38]Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, Åukasz Kaiser, and Illia Polosukhin. 2017. Attention is all
y o un eed .I nAdvances in neural information processing systems. 5998â€“6008.
[39]Venkatesh Vinayakarao, Anita Sarma, Rahul Purandare, Shuktika Jain, and
SaumyaJain.2017. Anne:Improvingsourcecodesearchusingentityretrieval
approach.In ProceedingsoftheTenthACMInternationalConferenceonWebSearch
and Data Mining. 211â€“220.
[40]Yao Wan, Zhou Zhao, Min Yang, Guandong Xu, Haochao Ying, Jian Wu, and
PhilipSYu.2018. Improvingautomaticsourcecodesummarizationviadeeprein-forcementlearning.In Proceedingsofthe33rdACM/IEEEInternationalConference
on Automated Software Engineering. 397â€“407.
[41]Mingzhou Xu, Derek F Wong, Baosong Yang, Yue Zhang, and Lidia S Chao. 2019.
Leveraginglocalandglobalpatternsforself-attentionnetworks.In Proceedings
ofthe57thAnnualMeetingoftheAssociationforComputationalLinguistics.3069â€“
3075.
[42]Ziyu Yao, Jayavardhan Reddy Peddamail, and Huan Sun. 2019. CoaCor: Code
AnnotationforCodeRetrievalwithReinforcementLearning. TheWorldWide
Web Conference on - WWW â€™19 (2019). https://doi.org/10.1145/3308558.3313632
[43]Ziyu Yao, Daniel S Weld, Wei-Peng Chen, and Huan Sun. 2018. Staqc: A system-
aticallyminedquestion-codedatasetfromstackoverflow.In Proceedingsofthe
2018 World Wide Web Conference. 1693â€“1703.
[44]Peng Zhou, Zhenyu Qi, Suncong Zheng, Jiaming Xu, Hongyun Bao, and Bo
Xu.2016. TextclassificationimprovedbyintegratingbidirectionalLSTMwith
two-dimensional max pooling. arXiv preprint arXiv:1611.06639 (2016).
894