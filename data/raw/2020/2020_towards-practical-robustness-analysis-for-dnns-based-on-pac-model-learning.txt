Towards Practical Robustness Analysis for DNNs based on
PAC-Model Learning
Renjue Li
lirj19@ios.ac.cn
SKLCS, Institute of Software, CAS
University of Chinese Academy of
Sciences
ChinaPengfei Yangâˆ—
yangpf@ios.ac.cn
SKLCS, Institute of Software, CAS
ChinaCheng-Chao Huang
chengchao@nj.iscas.ac.cn
Nanjing Institute of Software
Technology, ISCAS
Pazhou Lab
China
Youcheng Sun
youcheng.sun@qub.ac.uk
Queenâ€™s University Belfast
United KingdomBai Xue
xuebai@ios.ac.cn
SKLCS, Institute of Software, CAS
University of Chinese Academy of
Sciences
ChinaLijun Zhangâˆ—
zhanglj@ios.ac.cn
SKLCS, Institute of Software, CAS
University of Chinese Academy of
Sciences
China
ABSTRACT
To analyse local robustness properties of deep neural networks
(DNNs), we present a practical framework from a model learn-
ing perspective. Based on black-box model learning with scenario
optimisation, we abstract the local behaviour of a DNN via an
affine model with the probably approximately correct (PAC) guar-
antee. From the learned model, we can infer the corresponding
PAC-model robustness property. The innovation of our work is the
integration of model learning into PAC robustness analysis: that is,
weconstructaPACguaranteeonthemodellevelinsteadofsample
distribution,whichinducesamorefaithfulandaccuraterobustness
evaluation.This isin contrastto existingstatistical methodswith-
out model learning. We implement our method in a prototypical
tool named DeepPAC. As a black-box method, DeepPAC is scalable
and efficient, especially when DNNs have complex structures or
high-dimensionalinputs.WeextensivelyevaluateDeepPAC,with4baselines(usingformalverification,statisticalmethods,testingandadversarial attack) and 20 DNN models across 3 datasets, including
MNIST, CIFAR-10, and ImageNet. It is shown that DeepPAC out-
performsthestate-of-the-artstatisticalmethodPROVERO,andit
achieves more practical robustness analysis than the formal ver-ification tool ERAN. Also, its results are consistent with existing
DNN testing work like DeepGini.
CCS CONCEPTS
â€¢Security and privacy â†’Software and application security ;
â€¢Computing methodologies â†’Artificial intelligence.
âˆ—Corresponding authors
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ICSE 2022, May 21â€“29, 2022, Pittsburgh, PA, USA
Â© 2022 Association for Computing Machinery.
ACM ISBN 978-1-4503-9221-1/22/05...$15.00
https://doi.org/10.1145/3510003.3510143KEYWORDS
neural networks,PAC-model robustness,model learning, scenario
optimization
ACM Reference Format:
RenjueLi,PengfeiYang,Cheng-ChaoHuang,YouchengSun,BaiXue,andLi-
junZhang.2022.TowardsPracticalRobustnessAnalysisforDNNsbased
on PAC-Model Learning. In 44th International Conference on Software Engi-
neering(ICSEâ€™22),May21â€“29,2022,Pittsburgh,PA,USA. ACM,NewYork,
NY, USA, 13pages.https://doi.org/10.1145/3510003.3510143
1 INTRODUCTION
Deepneuralnetworks(DNNs)arenowwidelydeployedinmany
applications such as image classification, game playing, and the
recent scientific discovery on predictions of protein structure [ 58].
Adversarial robustness of a DNN plays the critical role for its trust-
worthyuse.Thisisespeciallytrueforforsafety-criticalapplications
suchasself-drivingcars[ 69].Studieshaveshownthatevenfora
DNNwithhighaccuracy,itcanbefooledeasilybycarefullycrafted
adversarialinputs [64].This motivatesresearchon verifyingDNN
robustnessproperties, i.e.,the predictionof theDNNremains the
same after bounded perturbation on an input. As the certifiable
criterion before deploying a DNN, the robustness radius should be
estimated or the robustness property should be verified.
In this paper, we propose a practical framework for analysing
robustness of DNNs. The main idea is to learn an affine model
which abstracts local behaviour of a DNN and use the learned
model (instead of the original DNN model) for robustness analysis.
Different from model abstraction methods like [ 4,17], our learned
modelisnotastrictlysoundover-approximation,butitvariesfrom
theDNNuniformlywithinagivenmarginsubjecttosomespecifiedsignificance level and error rate. We call such a model the probably
approximately correct (PAC) model.
There are several different approaches to estimating the max-
imum robustness radius of a given input for the DNN, includingformal verification, statistical analysis, and adversarial attack. Inthe following, we will first briefly explain the pros and cons of
each approach for and its relation with our method. Then, we will
highlight the main contributions in this paper.
21892022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:54:36 UTC from IEEE Xplore.  Restrictions apply. ICSE 2022, May 21â€“29, 2022, Pittsburgh, PA, USA Renjue Li, et al.
Bound via formal verification is often too conservative. A DNN
is a complex nonlinear function and formal verification tools [ 7,
33,38,59,60,68,84] cantypically handleDNNs withhundreds to
thousandsofneurons.ThisisdwarfedbythesizeofmodernDNNs
usedintherealworld,suchastheResNet50model[ 26]usedinour
experiment with almost 37 million hidden neurons. The advantage
of formal verification is that its resulting robustness bound is guar-
anteed,buttheboundisalsooftentooconservative.Forexample,
thestate-of-the-artformalverificationtoolERANisbasedonab-
stract interpretation [ 60] that over-approximates the computation
inaDNNusingcomputationallymoreefficientabstractdomains.
IftheERANverificationsucceeds,onecanconcludethatthenet-
workislocallyrobust;otherwise,duetoitsover-approximation,no
conclusive result can be reached and the robustness property may
or may not hold.
Estimationviastatisticalmethodsisoftentoolarge. Ifweweaken
the robustness condition by allowing a small error rate on the
robustnessproperty,itbecomesaprobabilisticrobustness(orquan-
titative robustness) property. Probabilistic robustness characterises
thelocalrobustnessinawaysimilartotheideaofthelabelchangerateinmutationtestingforDNNs[
71,72].In[5,6,11,44,74,75,78],
statisticalmethodsareproposed toevaluatelocalrobustnesswith
a probably approximately correct (PAC) guarantee. That is, witha given confidence, the DNN satisfies a probabilistic robustness
property,andwecallthis PACrobustness.However,aswearegoing
toseeintheexperiments(Section 5),thePACrobustnessestima-
tion via existing statistical methods is often unnecessarily large. In
thiswork,ourmethodsignificantlyimprovesthePACrobustness
bound, without loss of confidence or error rate.
Boundviaadversarialattackhasnoguarantee. Adversarialattack
algorithmsapplyvarioussearchheuristicsbasedone.g.,gradient
descentorevolutionarytechniquesforgeneratingadversarialin-
puts[1,13,43,85].These methodsmaybeable tofindadversarial
inputsefficiently,butarenotabletoprovideanysoundnessguar-
antee.Whiletheadversarialinputsfoundbytheattackestablishanupper bound of the DNN local robustness, it is not known whether
there are other adversarial inputs within the bound. Later, we will
use this upper bound obtained by adversarial attack, together with
the lower bound proved by the formal verification approach dis-cussed above, as the reference for evaluating the quality of our
PAC-model robustness results, and comparing them with the latest
statistical method.
Contributions .WeproposeanovelframeworkofPAC-model
robustness verification for DNNs. Inspiredby the scenario optimi-
sation technique in robust control design, we give an algorithmto learn an affine PAC model for a DNN. This affine PAC model
captureslocalbehaviouroftheoriginalDNN.Itissimpleenough
forefficient robustnessanalysis, andits PACguarantee ensuresthe
accuracyoftheanalysis.Weimplementouralgorithminaproto-
typecalledDeepPAC.WeextensivelyevaluateDeepPACwith20
DNNsonthreedatasets.DeepPACoutperformsthestate-of-the-art
statistical tool PROVERO with less running time, fewer samples
and,moreimportantly,muchhigherprecision.DeepPACcanassess
the DNN robustness faithfully when the formal verification and
existing statistical methods fail to generate meaningful results.Organisation of the paper. The rest of this paper is organized as
follows.InSect. 2,wefirstintroducethebackgroundknowledge.We
then formalize the novel concept PAC-model robustness in Sect. 3.
ThemethodologyisdetailedinSect. 4.Extensiveexperimentshave
been conducted in Sect. 5for evaluating DeepPAC. We discuss
related work in Sect. 6and conclude our work in Sect. 7.
2 PRELIMINARY
In this section, we first recall the background knowledge on theDNN and its local robustness properties. Then, we introduce thescenario optimization method that will be used later. In this fol-
lowingcontext,wedenote xiastheithentryofavector xâˆˆRm.
ForxâˆˆRmandÎ»âˆˆR, we define x+Î»as(x0+Î»,...,xm+Î»)/latticetop.
Givenx,yâˆˆRm, we write xâ‰¤yifxiâ‰¤yifori=1,...,m.W e
use0todenotethezerovector.For xâˆˆRm,itsLâˆž-normisdefined
as/bardblx/bardblâˆž:=max1â‰¤iâ‰¤m|xi|. We use the notation B(Ë†x,r):={xâˆˆ
Rm|/bardblxâˆ’Ë†x/bardblâˆžâ‰¤r}torepresenttheclosed Lâˆž-normballwiththe
centerË†xâˆˆRmand radius r>0.
2.1 DNNs and Local Robustness
Adeepneuralnetworkcanbecharacterizedasafunction f:Rmâ†’
Rnwithf=(f1,...,fn)/latticetop, wherefidenotes the function corre-
spondingtothe ithoutput.Forclassificationtasks,aDNNlabelsan
inputxwiththeoutputdimensionhavingthelargestscore,denoted
byCf(x):=argmax 1â‰¤iâ‰¤nfi(x).ADNNiscomposedbymultiple
layers: the input layer, followed by several hidden layers and an
outputlayerintheend.Ahiddenlayerappliesanaffinefunction
oranon-linearactivationfunctionontheoutputofpreviouslayers.
The function fis the composition of the transformations between
layers.
Example 2.1. We illustrate a fully connected neural network
(FNN), where each node (i.e., neuron) is connected with the nodes
from the previous layer. Each neuron has a value that is calculated
as the weighted sum of the neuron values in the previous layer,
plus a bias. For a hidden neuron, this value is often followed by an
activation function e.g., a ReLU function that rectifies any negative
valueinto0.InFig. 1,theFNNcharacterizesafunction f:R2â†’R2.
Theweightandbiasparametersarehighlightedontheedgesand
the nodes respectively. For an input x=(x1,x2)/latticetopâˆˆ[ âˆ’1,1]2,w e
havef(x)=(f1(x),f2(x))/latticetop.
Input 1
Input 2Output 1
Output 23
5
âˆ’10
âˆ’43
19
7[âˆ’1,1] âˆ’9 14
[âˆ’1,1] âˆ’10 âˆ’10
Figure 1: An FNN with two input neurons, two hidden neu-rons and two output neurons.
For a certain class label /lscript, we define the targeted score difference
function Î”as
Î”(x)=(f1(x)âˆ’f/lscript(x),...,fn(x)âˆ’f/lscript(x))/latticetop.(1)
2190
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:54:36 UTC from IEEE Xplore.  Restrictions apply. Towards Practical Robustness Analysis for DNNs based on PAC-Model Learning ICSE 2022, May 21â€“29, 2022, Pittsburgh, PA, USA
Straightforwardly,thisfunctionmeasuresthedifferencebetween
thescoreofthetargetedlabelandotherlabels.Forsimplicity,we
ignoretheentry f/lscript(x)âˆ’f/lscript(x)andregardthescoredifferencefunc-
tionÎ”as a function from RmtoRnâˆ’1. For any inputs Ë†xwith the
class label/lscript, it is clear that Î”(Ë†x)<0if the classification is correct.
For simplicity, when consideringan Lâˆž-norm ballwith thecenter
Ë†x, we denote by Î”the difference score function with respect to the
label ofË†x. Then robustness property of a DNN can therefore be
defined as below.
Definition2.2(DNNrobustness). GivenaDNN f:Rmâ†’Rn,an
inputË†xâˆˆRm, andr>0, we say that fis (locally) robustinB(Ë†x,r)
if for allxâˆˆB(Ë†x,r), we have Î”(x)<0.
Intuitively, local robustness ensures the consistency of the be-
haviour of a given input under certain perturbations. An input
x/primeâˆˆB(Ë†x,r)that destroys the robustness (i.e. Î”(x/prime)â‰¥0) is called
anadversarialexample.Notethatthispropertyisverystrictsothat
the corresponding verification problem is NP-complete, and the
exact maximum robustness radius cannot be computed efficiently
except for verysmall DNNs. Even estimatinga relatively accurate
lowerboundisdifficultandexistingsoundmethodscannotscale
to the state-of-the-art DNNs. In order to perform more practical
DNNrobustnessanalysis,thepropertyisrelaxedbyallowingsome
errors in the sense of probability. Below we recall the definition of
PAC robustness [5].
Definition 2.3 (PAC robustness). Given a DNN f:Rmâ†’Rn,a n
Lâˆž-normball B(Ë†x,r),aprobabilitymeasure PonB(Ë†x,r),asignifi-
cancelevel Î·,andanerrorrate Ïµ,theDNN fis(Î·,Ïµ)-PACrobust
inB(Ë†x,r)if
P(Î”(x)<0)â‰¥1âˆ’Ïµ (2)
with confidence 1 âˆ’Î·.
PACrobustnessisanstatisticalrelaxationandextensionofDNN
robustness in Def. 2.2. It essentially only focuses on the input sam-
ples,butmostlyignoresthebehavioralnatureoftheoriginalmodel.
Whentheinputspaceisofhighdimension,theboundariesbetween
benigninputsandadversarialinputswillbeextremelycomplexand
therequiredsamplingeffortwillbealsochallenging.Thus,anaccu-rateestimationofPACrobustnessisfarfromtrivial.Thismotivates
us to innovate the PAC robustness with PAC-model robustness in
this paper (Sect. 3).
2.2 Scenario Optimization
ScenariooptimizationisanothermotivationforDeepPAC.Ithas
been successfullyused in robustcontrol design forsolving a class
of optimization problems in a statistical sense, by only consider-ing a randomly sampled finite subset of infinitely many convex
constraints [9, 10].
Let us consider the following optimization problem:
min
Î³âˆˆÎ“âŠ†Rmb/latticetopÎ³
s.t.fÏ‰(Î³)â‰¤0,âˆ€Ï‰âˆˆÎ©,(3)
wherefÏ‰isaconvexandcontinuousfunctionofthe m-dimensional
optimization variable Î³for every Ï‰âˆˆÎ©, and both Î©andÎ“are
convex and closed. In this work, we also assume that Î©is bounded.
Inprinciple,itischallengingtosolve (3),asthereareinfinitelymanyconstraints. Calafiore et al. [ 9] proposed the following scenario
approach to solve (3) with a PAC guarantee.
Definition2.4. LetPbeaprobabilitymeasureon Î©.Thescenario
approach to handle the optimization problem (3)is to solve the
followingproblem.Weextract Kindependentandidenticallydis-
tributed(i.i.d.)samples (Ï‰i)K
i=1fromÎ©accordingtotheprobability
measure P:
min
Î³âˆˆÎ“âŠ†Rmb/latticetopÎ³
s.t.K/logicalanddisplay.1
i=1fÏ‰i(Î³)â‰¤0.(4)
Thescenarioapproachrelaxestheinfinitelymanyconstraints
in(3)by only considering a finite subset containing Kconstraints.
In [9], a PAC guarantee, depending on K, between the scenario
solution in (4)and its original optimization in (3)is proved. This
isfurtherimprovedby[ 10]inreducingthenumberofsamples K.
Specifically, the following theorem establishes a condition on K
for(4)which assures that its solution satisfies the constraints in (3)
statistically.
Theorem 2.5 ([ 10]).If (4) is feasible and has a unique optimal
solutionÎ³âˆ—
K, and
Ïµâ‰¥2
K(ln1
Î·+m), (5)
whereÏµandÎ·are the pre-defined error rate and the significance
level, respectively, then with confidence at least 1âˆ’Î·, the optimal
Î³âˆ—
Ksatisfies all the constraints in Î©but only at most a fraction of
probability measure Ïµ, i.e.,P(fÏ‰(Î³âˆ—
K)>0)â‰¤Ïµ.
In this work, we set Pto be the uniform distribution on the Î©
setin(3). Itis worthy mentioningthat Theorem 2.5stillholds even
if the uniqueness of the optimal Î³âˆ—
Kis not required, since a unique
optimal solution can always be obtained by using the Tie-break
rule [9] if multiple optimal solutions exist.
Thescenariooptimizationtechniquehasbeenexploitedinthe
context of black-box verification for continuous-time dynamicalsystems in [
81]. We will propose an approach based on scenario
optimization to verify PAC-model robustness in this paper.
3 PAC-MODEL ROBUSTNESS
The formalisation of the novel concept PAC-model robustness is
our first contribution in this work and it is the basis for developing
our method. We start from defining a PAC model. Let Fbe a given
set of high dimensional real functions (like affine functions).
Definition3.1(PACmodel). LetÐ´:Rmâ†’Rn,BâŠ†RmandPa
probability measure on B. LetÎ·,Ïµâˆˆ(0,1]be the given error rate
and significance level, respectively. Let Î»â‰¥0 be the margin. A
function /tildewideÐ´:Bâ†’RnâˆˆFisaPACmodelof Ð´onBw.r.t.Î·,Ïµand
Î», denoted by /tildewideÐ´â‰ˆÎ·,Ïµ,Î»Ð´,i f
P(||/tildewideÐ´(x)âˆ’Ð´(x)||âˆžâ‰¤Î»)â‰¥1âˆ’Ïµ, (6)
with confidence 1 âˆ’Î·.
In Def.3.1, we define a PAC model /tildewideÐ´as an approximation of the
original model Ð´with two parameters Î·andÏµwhich bound the
maximal significance level and the maximal error rate for the PAC
2191
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:54:36 UTC from IEEE Xplore.  Restrictions apply. ICSE 2022, May 21â€“29, 2022, Pittsburgh, PA, USA Renjue Li, et al.
model, respectively. Meanwhile, there is another parameter Î»that
bounds the margin between the PAC model and the original model.
Intuitively, the difference between a PAC model and the original
one is bounded under the given error rate Ïµand significance level
Î·.
ForaDNN f,ifitsPACmodel /tildewidefwiththecorrespondingmarginis
robust,then fisPAC-modelrobust.Formally,wehavethefollowing
definition.
Definition 3.2 (PAC-model robustness). Letf:Rmâ†’Rnbe a
DNN and Î”the corresponding score difference. Let Î·,Ïµâˆˆ(0,1]be
thegivenerrorrateandsignificancelevel,respectively.TheDNN
fis(Î·,Ïµ)-PAC-model robust in B(Ë†x,r), if there exists a PAC model
/tildewideÎ”â‰ˆÎ·,Ïµ,Î»Î”such that for all xâˆˆB(Ë†x,r),
/tildewideÎ”(x)+Î»<0. (7)
Weremindthat Î”isthescoredifferencefunctionmeasuringthe
difference between the score of the targeted label and other labels.
A locally robust DNN requires that Î”(x)<0, and a PAC-model
robust DNN requires the PAC upper bound of Î”, i.e./tildewideÎ”(x)+Î»,i s
always smaller than 0.
InFig.2,weillustratethepropertyspaceofPAC-modelrobust-
ness, by using the parameters Î·,ÏµandÎ». The properties on the
Î»-axis are exactly the strict robustness since Î”(x)is now strictly
upper-bounded by /tildewideÎ”(x)+Î». Intuitively, for fixed Î·andÏµ, a smaller
marginÎ»impliesabetterPACapproximation /tildewideÎ”(x)oftheoriginal
oneÎ”(x)and indicates that the PAC-model robustness is closer
to the (strict) robustness property of the original model. To esti-
matethemaximumrobustnessradiusmoreaccurately,weintend
to compute a PAC model with the margin Î»as small as possible.
Moreover, the proposed PAC-model robustness is stronger than
PAC robustness, which is proved by the following proposition.
Proposition3.3. IfaDNNfis(Î·,Ïµ)-PAC-modelrobustin B(Ë†x,r),
then it is(Î·,Ïµ)-PAC robust in B(Ë†x,r).
Proof. With confidence 1 âˆ’Î·we have
P(Î”(x)â‰¤0)â‰¥P( Î”(x)â‰¤/tildewideÎ”(x)+Î»)
â‰¥P(||/tildewideÎ”(x)âˆ’Î”(x)||âˆžâ‰¤Î»)â‰¥1âˆ’Ïµ,
which implies that fis(Î·,Ïµ)-PAC robust in B(Ë†x,r). /square
In this work, wo focus on the following problem:
Given a DNN f,a nLâˆž-norm ball B(Ë†x,r), a signifi-
cance level Î·, and an error rate Ïµ, we need to deter-
mine whether fis(Î·,Ïµ)-PAC-model robust.
Beforeintroducingourmethod,werevisitPACrobustness(Def. 2.3)
in our PAC-model robustness theory. Statistical methods like [ 5]
infer PAC robustness from samples and their classification output
in the given DNN. In our PAC-model robustness framework, these
methods simplify the model to a function Î¾:B(Ë†x,r)â†’{0,1},
where0referstothecorrectclassificationresultand1awrongone,
and infer the PAC-model robustness with the constant function
/tildewideÎ¾(x)â‰¡0o nB(Ë†x,r)as the model. In [ 2], the model is modified to a
constantscoredifferencefunction /tildewideÎ”â‰¡c.Thesemodelsaretooweak
todescribethebehaviourofaDNNwell.Itcanbepredictedthat,
ifwelearnaPACmodelwithanappropriatemodel,theobtained
ÏµÎ»Î·
	TUSJDU
robustnessPAC model robustness
Ogiven Î· and Ïµ  
Figure 2: Property space of PAC-model robustness.
PAC-modelrobustnesspropertywillbemoreaccurateandpractical,
and this will be demonstrated in our experiments.
4 METHODOLOGY
Inthissection,wepresentourmethodforanalysingthePAC-model
robustnessofDNNs. Theoverallframeworkis showninFig. 3.In
general, our method comprises of three stages: sampling, learning,
and analysing.
S1:We sample the input region B(Ë†x,r)and obtain the corre-
sponding values of the score difference function Î”.
S2:We learn aPACmodel /tildewideÎ”(x)â‰ˆÎ·,Ïµ,Î»Î”(x)of the scorediffer-
ence function from the samples.
S3:Weanalysewhether /tildewideÎ”(x)+Î»isalwaysnegativeintheregion
B(Ë†x,r)by computing its maximal values.
Fromthedescriptionabove,weseeitisablack-boxmethodsince
we only use the samples in the neighbour and their corresponding
outputs to construct the PAC model. The number of samples is
independentofthestructureandthesizeoforiginalmodels,which
willbringthe goodscalabilityandefficiency. Moreover,wearees-
sentiallyreconstructingapropermodeltodepictthelocalbehavior
oftheoriginalmodel.Comparedwiththestatisticalmethods,the
PACmodelcanpotentiallyextractmoreinformationfromthescore
differences of these samples, which supports us to obtain more
accurate results.
Note that our framework is constructive, and the PAC model
andits maximalpoints intheregion willbe constructedexplicitly
during the analysis. Then, we can obtain the maximal values of the
PACmodel,andinferthattheoriginalDNNsatisfiesthePAC-model
robustness when all maximal values are negative. Thus, DeepPAC
can be considered as a sound approach to verify the PAC-model
robustness.
4.1 Learning a PAC Model
To obtain a PAC model of the original score difference function
Î”(x), we first create a function template, and then determine its
parameters by model learning from the samples. Hereafter, we set
Fto be the set of affine functions, and consider the PAC model
/tildewideÎ”(x)tobeanaffinefunctionwithboundedcoefficients.Areason
forchoosinganaffinetemplateisthatthebehavioursofaDNNinasmall
Lâˆž-norm ball B(Ë†x,r)are very similar to some affine function
[53], due to the almost everywhere differentiability of DNNs. In
2192
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:54:36 UTC from IEEE Xplore.  Restrictions apply. Towards Practical Robustness Analysis for DNNs based on PAC-Model Learning ICSE 2022, May 21â€“29, 2022, Pittsburgh, PA, USA
DNN Score Differenceoutput input
PAC ModelMaximal Valuesmodel learningsampling
analysing
PAC  - model robustnessSUBSECT. 4.2SUBSECT. 4.1  & 4.3
Figure3:FrameworkofPAC-modelrobustnessanalysisbase
on model learning
otherwords,anaffinefunctioncanapproximatetheoriginalmodel
well enough in most cases to maintain the accuracy of our robust-
nessanalysis.Specifically,forthe ithdimensionoftheDNNoutput
layer,weset /tildewideÎ”i(x)=c/latticetop
ix=ci,0+ci,1x1+Â·Â·Â·+ci,mxm.Withex-
tracting a set of Kindependent and identically distributed samples
Ë†XâŠ†B(Ë†x,r),weconstructthefollowingoptimisationproblemfor
learning the affine PAC model /tildewideÎ”(x).
min
Î»â‰¥0Î»
s.t.âˆ’Î»â‰¤c/latticetop
ixâˆ’Î”i(x)â‰¤Î»,âˆ€xâˆˆË†X,i/nequal/lscript,
Lâ‰¤ci,kâ‰¤U, i/nequal/lscript,k=0,...,m.(8)
In the above formulation of PAC model learning, the problem boils
down to a linear programming (LP) optimisation. We reuse Î»to
denote the optimal solution, and /tildewideÎ”ito be the function whose co-
efficients ciare instantiated according to the optimal solution Î».
Specifically, we aim to compute a PAC model /tildewideÎ”ofÎ”. By Theo-
rem2.5, the confidence and the error rate can be ensured by a
sufficientlylargenumberofsamples.Namely,tomake (6)holdwith
confidence1 âˆ’Î·,wecanchooseany Kâ‰¥2
Ïµ(ln1
Î·+(m+1)(nâˆ’1)+1)
corresponding to the number of the variables in (8).
Forfixed Î·andÏµ,thenumberofsamples KisinO(mn),sothe
LP problem (8)containsO(mn)variables and O(mn2)constraints.
Therefore, the computational cost of the above LP-based approach
canquicklybecomeprohibitivewithincreasingthedimensionof
input and output.
Example4.1. FortheMNISTdatasetthereistheinputdimension
m=28Ã—28=784 and output dimension n=10. Even for Î·=
0.001,Ïµ=0.4,weneedtosolveanLPproblemwith7 ,065variables
andmorethan630,000constraints,whichtakesuptoomuchspace
(memory out with 10GB memory).
To further make the PAC model learning scale better with high-
dimensionalinputandoutput,wewillconsiderseveraloptimisa-
tions to reduce the complexity of the LP problem in Section 4.3.
FromtheLPformulationinEq. (8),itcanbeseenthatthePAC
model learning is based on the sampling set Ë†Xinstead of the norm
ballB(Ë†x,r). That is, though in this paper, for simplicity, B(Ë†x,r)
is assumed to be an Lâˆž-norm ball, our method also works with
Lp-norm robustness with 1 â‰¤p<âˆž.4.2 Analysing the PAC Model
We just detailed how to synthesise a PAC model /tildewideÎ”of the score
difference function Î”. When the optimisation problem in (8)is
solved, we obtain the PAC model /tildewideÎ”(x)â‰ˆÎ·,Ïµ,Î»Î”(x)of the score
differencefunction.Namely, /tildewideÎ”(x)Â±Î»approximatestheupper/lower
boundofthescoredifferencefunction Î”withthePACguarantee
respectively. As aforementioned, all maximal values of /tildewideÎ”+Î»being
negative implies the PAC-model robustness of the original DNN.
According to the monotonicity of affine functions, it is not hard
to computethe maximumpoint Ë˜x(i)of/tildewideÎ”i(x)in theregion B(Ë†x,r).
Specifically, for /tildewideÎ”i(x)in the form of c0+/summationtext.1m
j=1cjxj, we can infer
its maximum point directly as
Ë˜x(i)
j=/braceleftBiggË†xj+r,cj>0,
Ë†xjâˆ’r,cjâ‰¤0.
Notethatthechoiceof Ë˜x(i)
jisarbitraryforthecase cj=0.Here,we
chooseË†xjâˆ’ras an instance. Then let Ë˜xbe theË˜x(i)corresponding
to the maximum /tildewideÎ”i(Ë˜x(i)), and the PAC-model robustness of the
original DNN immediately follows if /tildewideÎ”(Ë˜x)+Î»<0. Besides, each
Ë˜x(i)is a potential adversarial example attacking the original DNN
with the classification label i, which can be further validated by
checking the sign of Î”i(Ë˜x(i)).
Example 4.2. We consider the neural network in Fig. 1. Given
an input Ë†x=(0,0)/latticetop, the classification label is Cf(Ë†x)=1. The
networkisrobustif f2(x)<f1(x)forxâˆˆB(Ë†x,1),orequivalently,
f2(x)âˆ’f1(x)<0.Thus,ourgoalistoapplythescenarioapproachto
learnthescoredifference Î”(x)=f2(x)âˆ’f1(x).Inthisexample,we
taketheapproximatingfunctionoftheform /tildewideÎ”(x)=c0+c1x1+c2x2
with constant parameters c0,c1,c2âˆˆ[ âˆ’100,100]to be synthesised.
For ease of exposition, we denote c=(c1,c2,c3)/latticetop.
We attempt to approximate Î”(x)by minimising the absolute
difference between it and the approximating function /tildewideÎ”(x). This
process can be characterised as an optimisation problem:
min
c,Î»Î»
s.t.|/tildewideÎ”(x)âˆ’Î”(x)| â‰¤Î»,âˆ€xâˆˆ[ âˆ’1,1]2,
câˆˆ[ âˆ’100,100]3,
Î»âˆˆ[ âˆ’100,100].(9)
To applythe scenarioapproach, wefirst needto extract aset of K
independentandidenticallydistributed samples Ë†XâŠ†[ âˆ’1,1]2,and
thenreducetheoptimisationproblem (9)tothelinearprogramming
problem by replacing the quantifier âˆ€xâˆˆ[ âˆ’1,1]2withâˆ€xâˆˆË†X
in the constraints. Theorem 2.5indicates that at least âŒˆ2
Ïµ(ln1
Î·+
4)âŒ‰samples are required to guarantee the error rate within Ïµ, i.e.
P(|/tildewideÎ”(x)âˆ’Î”(x)| â‰¤Î»)â‰¥1âˆ’Ïµ, with confidence 1 âˆ’Î·.
Taking the error rate Ïµ=0.01 and the confidence 1 âˆ’Î·=99.9%,
we need (at least) K=2182 samples in [âˆ’1,1]2. By solving the
resultinglinearprogramagain,weobtain c0=âˆ’22.4051,c1=2.800,
c2=âˆ’9.095, andÎ»=9.821.
For illustration, we restrict x1=1, and depict the functions Î”
and/tildewideÎ”in Fig.4. Our goal is to verify that the first output is always
larger than the second, i.e., Î”(x)=f2(x)âˆ’f1(x)<0. As described
above, according to the signs of the coefficients of /tildewideÎ”, we obtain
2193
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:54:36 UTC from IEEE Xplore.  Restrictions apply. ICSE 2022, May 21â€“29, 2022, Pittsburgh, PA, USA Renjue Li, et al.
Î”
Î”~
+Î»
-Î»
0 0.5 1 - 0.5 -10
Figure 4: The functions Î”and/tildewideÎ”inx2are depicted by fixing
x1=1.Itismarkedredwhere Î”(x)isnotboundedby /tildewideÎ”(x)Â±Î».
that/tildewideÎ”(x)attains the maximum value at x=(1,âˆ’1)/latticetopin[âˆ’1,1]2.
Therefore, the network is PAC-model robustness.
4.3 Strategies for Practical Analysis
We regard efficiency and scalability as the key factor for achieving
practical analysis of DNN robustness. In the following, we propose
three practical PAC-model robustness analysis techniques.
4.3.1 Component-basedlearning. AsstatedinSection 4.1,thecom-
plexityofsolving (8)canstillbehigh,soweproposecomponent-
based learning to reduce the complexity. As before, we use /tildewideÎ”i
to approximate Î”i(x)=fi(x)âˆ’f/lscript(x)for eachiwith the same
template.Theideaistolearnthefunctions Î”1,...,Î”nseparately,
andthencombinethesolutionstogether.Insteadofsolvingasin-
gle large LP problem, we deal with (nâˆ’1)individual smaller LP
problems,eachwith O(m)linearconstraints.Asaresult,wehave
/tildewideÎ”i(x)â‰ˆÎ·,Ïµ,Î»iÎ”i(x), from which we can only deduce that
P/parenleftBig/logicalanddisplay.1
i/nequal/lscript|/tildewideÎ”i(x)âˆ’Î”i(x)| â‰¤Î»i/parenrightBig
â‰¥1âˆ’(nâˆ’1)Ïµ
withtheconfidencedecreasingtoatmost1 âˆ’(nâˆ’1)Î·.Toguarantee
theerrorrateatleast Ïµandtheconfidenceatleast1 âˆ’Î·,weneedto
recomputetheerror Î»between /tildewideÎ”(x)andÎ”(x).Specifically,wesolve
the following optimisation problem constructed by resampling:
min
Î»Î»
s.t.|/tildewideÎ”i(x)âˆ’Î”i(x)| â‰¤Î»,
âˆ€xâˆˆË†X,i/nequal/lscript.(10)
whereË†Xis a set of Ki.i.d samples with Kâ‰¥2
Ïµ(ln1
Î·+1). Applying
Theorem 2.5again, we have /tildewideÎ”(x)â‰ˆÎ·,Ïµ,Î»Î”(x)as desired.
We have already relaxed the optimisation problem (8)into a
familyof (nâˆ’1)small-scaleLPproblems.If nistoolarge(e.g.for
Imagenetwith1000classes),wecanalsoconsidertheuntargeted
scoredifferencefunction Î”u(x)=f/lscript(x)âˆ’maxi/nequallfi(x).Byadopt-
ing the untargeted score difference function, the number of the
LP problems is reduced to one. The untargeted score difference
function improves the efficiency at expense of the loss of linearity,
which harms the accuracy of the affine model.
4.3.2 Focused learning. In this part, our goal is to reduce the com-
plexity further by dividing the learning procedure into two phases
with different fineness: i) in the first phase, we use a small set of
samplestoextractcoefficientswithbigabsolutevalues;andii)thesecoefficientsareâ€œfocusedâ€inthesecondphase,inwhichweusemoresplit
learn
splitsplit
learn
linear programmingÎ»c fixed coefficients
margin
linear programmingPAC Model
PHASE II PHASE I
Figure 5: A workflow of the stepwise splitting procedure.
The red color indicates the significant grids whose coeffi-
cients will be further refined, while the yellow color indi-
cates the grids whose coefficients have been determined.
samples to refine them. In this way, we reduce the number of vari-
ablesoverall,andwecallit focusedlearning,whichnamelyrefers
to focusing the model learning procedure on important features. It
is embedded in the component learning procedure.
The main idea of focused learning is depicted below:
(1)Firstlearningphase: Weextract K(1)i.i.d.samplesfromthe
input region B(Ë†x,r). We first learn Î”ion theK(1)samples.
Thus,ourLPproblemshave O(K(1))constraintswith O(m)
variables. For large datasets like ImageNet, the resulting LP
problemisstilltoolarge.Weuseefficientlearningalgorithms
such as linear regression (ordinary least squares) to boost
the first learning phase on these large datasets.
(2)Key featureextraction: After solvingthe LP problem(or the
linear regression for large datasets), we synthesise /tildewideÎ”(1)
ias
the approximating function. Let KeyFi(Îº)âŠ†{1,x1,...,xm}
denotethesetofextractedkeyfeaturesforthe ithcomponent
corresponding to the Îºcoefficients with the largest absolute
values in /tildewideÎ”(1)
i.
(3)Focused learning phase: We extract K(2)i.i.d. samples from
B(Ë†x,r). For these samples, we generate constraints only for
our key features in KeyFi(Îº)by fixing the other coefficients
using those in /tildewideÎ”(1)
i, and thus the number of the undeter-
minedcoefficientsisboundedby Îº.BysolvinganLPprob-
lemcomprisedoftheseconstraints,wefinallydeterminethe
coefficients of the features in KeyFi(Îº).
Wecandeterminethesamplesize K(2)andthenumberofkey
featuresÎºsatisfying
Îºâ‰¤K(2)Ïµ
2âˆ’ln1
Î·âˆ’1,
which can be easily inferred from Theorem 2.5. It is worth men-
tioningthat,focusedlearningnotonlysignificantlyimprovesthe
efficiency,butitalsomakesourapproachinsensitivetosignificance
levelÎ·and error rate Ïµ, because the first phase in focused learning
canprovideahighlyprecisemodel,andasmallnumberofsamplesaresufficienttolearnthePACmodelinthesecondphase.Thiswill
be validated in our experiments.
2194
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:54:36 UTC from IEEE Xplore.  Restrictions apply. Towards Practical Robustness Analysis for DNNs based on PAC-Model Learning ICSE 2022, May 21â€“29, 2022, Pittsburgh, PA, USA
4.3.3 Stepwise splitting. When the dimensionality of the input
spaceisveryhigh(e.g.,ImageNet),Thefirstlearningphaseoffo-
cusedlearningrequiresconstraintsgeneratedbytonsofsamples
tomakeprecisepredictionsonthekeyfeatures,whichisveryhard
andevenimpossibletobedirectlysolved.Forachievingbetterscal-ability,wepartitionthedimensionsofinput
{1,...,m}intogroups
{Gk}.Inanaffinemodel /tildewideÎ”i,forthevariableswithundeterminedco-
efficients in each certain group Gk, they share the same coefficient
ck. Namely, the affine model has the form of/summationtext.1
k/parenleftBig
ck/summationtext.1
iâˆˆGkxi/parenrightBig
.
Then, a coarse model can be learned.
We compose the refinement into the procedure of focused learn-
ingaforementioned(SeeFig. 5).Specifically,afteracoarsemodel
islearned,wefixthecoefficientsfortheinsignificantgroupsand
extract the key groups. The key groups are then further refined,and their coefficients are renewed by learning on a new batch of
samples.Werepeatthisprocedureiterativelyuntilmostcoefficients
oftheaffinemodelarefixed,andthenweinvokelinearprogram-
mingtocomputetherestcoefficientsandthemargin.Thisiterative
refinementcanberegardedasmulti-stagefocusedlearningwith
different fineness.
Inparticular,foracolourimage,wecanusethegridtodivideits
pixels into groups. The image has three channels corresponding to
thered,greenandbluelevels.Asaresult,eachgridwillgenerate
3 groups matching these channels, i.e. Gk,R,Gk,G, andGk,B. Here,
we determine the significance of a grid with the L2-norm of the
coefficients of its groups, i.e. (c2
k,R+c2
k,G+c2
k,B)1
2. Then the key
groups (saying corresponding to the top 25% significant grids) will
befurtherrefinedinthesubsequentprocedure.OnImageNet,we
initiallydividetheimageinto32 Ã—32grids,witheachgridofthe
size 7Ã—7. In each refinement iteration, we split each significant
grid into 4 sub-grids (see Fig. 5). We perform 6 iterations of such
refinementanduse20000samplesineachiteration.Anexample
onstepwisesplittingofanImageNetimagecanbefoundinFig. 8
in Sect.5.3.
5 EXPERIMENTAL EVALUATION
In this section, we evaluate our PAC-model robustness verifica-tion method. We implement our algorithm as a prototype calledDeepPAC. Its implementation is based on Python 3.7.8. We use
CVXPY [14] as the modeling language for linear programming and
GUROBI [ 25] as the LP solver. Experiments are conducted on a
Windows 10 PC with Intel i7 8700, GTX 1660Ti, and 16G RAM.
Three datasets MNIST [ 36], CIFAR-10 [ 35], and ImageNet [ 57] and
20 DNN models trained from them are used in the evaluation. The
details are in Tab. 1. We invoke our component-based learning and
focusedlearning forall evaluations,and applystepwise splitting
for the experiment on ImageNet. All the implementation and data
used in this section are publicly available1.
In the following, we are going to answer the research questions
below.
RQ1:Can DeepPAC evaluate local robustness of a DNN more
effectively compared with the state-of-the-art?
RQ2:Can DeepPAC retain a reasonable accuracy with higher sig-
nificance, higher error rate, and/or fewer samples?
1https://github.com/CAS-LRJ/DeepPACDataset Network Defense #Param Source
MNISTFNN1
â€”44.86K
â€”FNN2 99.71K
FNN3 239.41K
FNN4 360.01K
FNN5 480.61K
FNN6 1.65M
CNN1 â€”
89.61K
ERANCNN2 DiffAI
CNN3 PGD
CNN4 â€”
1.59M CNN5 PGD,Îµ=0.1
CNN6 PGD,Îµ=0.3
CIFAR-10CNN1 PGD 125.32K
CNN2 PGD,Îµ=2/2552.07MCNN3
PGD,Îµ=8/255ResNet18 11.17M
â€” ResNet50 23.52M
ResNet152 58.16M
ImageNetResNet50a PGD,Îµ=4/25525.56M MadryResNet50b PGD,Îµ=8/255
Table1:DatasetsandDNNsusedinourevaluation.Thecon-
volutionalneuralnetworks(CNN)forMNISTandCIFAR-10
are from ERAN [61]. The ResNet50 networks for ImageNetare from the python library â€œRobustnessâ€ [18] produced byMadryLab. The rest networks are trained by ourselves.
RQ3:
IsDeepPACscalabletoDNNswithcomplexstructureand
high dimensional input?
RQ4:IsthereaunderlyingrelationbetweenDNNlocalrobustness
verification and DNN testing (especially the test selection)?
5.1 Comparison on Precision
We first apply DeepPAC for evaluating DNN local robustness by
computingthemaximumrobustnessradiusandcompareDeepPAC
with the state-of-the-art statistical verification tool PROVERO [ 5],
whichverifiesPACrobustnessbystatisticalhypothesistesting.A
DNNverificationtoolreturnstrueorfalseforrobustnessofaDNN
givenaspecifiedradiusvalue.Abinarysearchwillbeconducted
forfindingthemaximumrobustnessradius.ForbothDeepPACandPROVERO, we set the error rate
Ïµ=0.01 and the significance level
Î·=0.001. We set K(1)=2000 and K(2)=8000 for DeepPAC.
In addition, we apply ERAN [ 60] and PGD [ 43] to bound the
exact maximum radius from below and from above, respectively.
ERANisastate-of-the-artDNNformalverificationtoolbasedon
abstract interpretation, and PGD is a popular adversarial attackalgorithm. In the experiments, we use the PGD implementationfrom the commonly used Foolbox [
52] with 40 iterations and a
relative step size of 0 .033, which are suggested by Foolbox as a
defaultsetting.NotethatexactrobustnessverificationSMTtools
like Marabou [ 33] cannot scale to the benchmarks used in our
experiment.
2195
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:54:36 UTC from IEEE Xplore.  Restrictions apply. ICSE 2022, May 21â€“29, 2022, Pittsburgh, PA, USA Renjue Li, et al.
FNN  1 FNN  2 FNN  3 FNN  4 FNN  5 FNN  6
CNN  1 CNN  2 CNN  3 CNN  4 CNN  5 CNN  6050100150200250
050100150200250
PROVERO Our (  DeepPAC  )ERANPGD the ranges containing 
exact maximum robustness radii
Figure 6: Each dash represents the maximum robustness radius for an input estimated by DeepPAC (blue) or PROVERO (red),
while each bar (white) gives an interval containing the exact maximum robustness radius, whose lower bound and upper
bound are computed by ERAN and PGD, respectively.
Werunallthetoolsonthefirst12DNNmodelsinTab. 1andthe
detailedresultsarerecordedinFig. 6.Inallcases,themaximumro-
bustnessradiusestimatedbythePROVEROisfarlargerthanthose
computed by other tools. In most cases, PROVERO ends up with a
maximum robustness radius over 100 (out of 255), which is even
larger than the upper bound identified by PGD. This indicates that,
while a DNN is proved to be PAC robust by PROVERO, adversarial
inputs can be still rather easily found within the verified bound. In
contrast,DeepPACestimatesthemaximumrobustnessradiusmore
accurately, which falls in between the results from ERAN and PGD
mostly. Since the range between the estimation of ERAN and PGD
containstheexactmaximumrobustnessradius,weconcludethat
DeepPAC isa moreaccurate toolthan PROVEROtoanalyse local
robustness of DNNs.
DeepPAC also successfully distinguishes robust DNN models
from non-robust ones. It tells that the CNNs, especially the ones
with defence mechanisms, are more robust against adversarial per-
turbations.Forinstance,24outof25imageshavealargermaximum
robustnessradiusonCNN1thanonFNN1,and21imageshavea
larger maximum robustness radius on CNN2 than on CNN1.
Otherthanthemaximumrobustnessradiusforafixedinput,the
overallrobustness ofaDNN, subjecttosomeradius value,canbe
denotedbytherateoftheinputsbeingrobustinadataset,called
â€œrobustnessrateâ€.InFig. 7,weshowtherobustnessrateof100input
images estimated by different tools on the 3 CIFAR-10 CNNs. Here,
we setK(1)=20000 and K(2)=10000.
PROVERO, similarly to the earlier experiment outcome, results
in robustness rate which is even higher than the upper boundestimation from the PGD attack, and its robustness rate resulthardly changes when the robustness radius increases. All suchCNN  1  ( CIFAR  )
20406080100
020406080100
20406080100CNN  2 ( CIFAR  ) CNN  3 ( CIFAR  )
2468 2468 24 6800
PROVERO ERAN Our (  DeepPAC  ) PGD
Figure7:RobustnessrateofdifferentCNNsundertheradius
of 2, 4, 6, and 8 on CIFAR-10.
comparisons reveal the limitations of using PAC robustness (by
PROVERO) that the verified results are not tight enough.
ERAN is a sound verification method, and the robustness rate
verifiedbyitisastrictlowerboundoftheexactresult.However,
this lower bound could be too conservative and ERAN quickly
becomes not usable. In the experiments, we find that it is hard for
ERAN to verify a robustness radius greater than or equal to 4 (out
of 255).
DeepPAC verifies greater robustness rate and larger robustness
radius,withhighconfidenceandlowerrorrate.Itsresultsfallsafelyinto the range bounded by ERAN and PGD. We advocate DeepPACasamorepracticalDNNrobustnessanalysistechnique.Itisshown
inourexperimentsthat,thoughDeepPACdoesnotenforce100%
guarantee,itcanbeappliedintoawiderrangeofadversarialsettings
(in contrast to ERAN) and the PAC-model verification results by
DeepPAC can be more trusted (in contrast to PROVERO) with
quantified confidence (in contrast to PGD).
2196
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:54:36 UTC from IEEE Xplore.  Restrictions apply. Towards Practical Robustness Analysis for DNNs based on PAC-Model Learning ICSE 2022, May 21â€“29, 2022, Pittsburgh, PA, USA
Answer RQ1: Themaximumrobustnessradiusestimatedby
DeepPAC is more precise than that by PROVERO, and our
DeepPAC is a more practical DNN robustness analysis method.
5.2DeepPAC with Different Parameters
Inthispart,weexperimentonthethreekeyparametersinDeepPAC:
theerrorrate Ïµ,thesignificancelevel Î·,andthenumberofsamples
K(1)in the first learning phase. The parameters Î·andÏµcontrol
the precision between the PAC model and the original model. The
numberofsamples K(1)determinestheaccuracyofthefirstlearning
phase. We evaluate DeepPAC under different parameters to check
thevariationofthemaximalrobustnessradius.Weseteither K(1)=
20000orK(1)=5000inourevaluationandthreecombinationsof
theparameters (Ïµ,Î·):(0.01,0.001),(0.1,0.001),and(0.01,0.1).Here,
wefixthenumberofkeyfeaturestobefifty,i.e. Îº=50,andcalculate
the corresponding number of samples K(2)in the focused learning
phase.
Theresultsarepresented inTab. 2.DeepPACrevealssomeDNN
robustnessinsightsthatwerenotachievablebyotherverification
work.Itisshownthat,theDNNs(theResNetfamilyexperimented)
canbemorerobustthanmanymaythink.Themaximumrobustnessradiusremainsthesameorslightlyalters,alongwiththeerrorrate
Î·andsignificance level Ïµvarying.This observationalso confirms
that the affine model used in DeepPAC abstraction converges well,
and the resulting error bound is even smaller than the specified
(large) error bound. Please refer to Sect. 4.1for more details.
DeepPAC is also tolerant enough with a small sampling size.
When the number of samples in the first learning phase decreases
fromK(1)=20,000 toK(1)=5,000, we can observe a minor de-
crease of the maximal robustness radius estimation. Recall that we
utilisethelearnedmodelinthefirstphaseoffocusedlearningto
extract the key features and provide coefficients to the less impor-
tant features. When the sampling number decreases, the learned
modelwouldbelesspreciseandthusmakevaguepredictionson
key features and make the resulting affine model shift from the
original model. As a result, the maximum robustness radius can be
smaller when we reduce the number of sampling in the first phase.
Inpractice,asitisshownbytheresultsinTab. 2,wedonotobserve
a sudden drop of the DeepPAC results when using a much smaller
sampling size.
AnswerRQ2: DeepPACshowsgoodtolerancetodifferentcon-
figurations of its parameters such as the error rate Ïµ, the signif-
icance level Î·, and the number of samples K(1).
5.3 Scalability
Robustnessverificationis awell-knowndifficultproblemon com-
plex networks with high-dimensional data. Most qualitative ver-ification methods meet a bottleneck in the size and structure of
the DNN. The fastest abstract domain in ERAN is GPUPoly [ 46], a
GPUacceleratedversionofDeepPoly.TheGPUPolycanverifya
ResNet18model ontheCIFAR-10datasetwith anaveragetime of
1021secondsunderthesupportofanNvidiaTeslaV100GPU.To
the best of our knowledge, ERAN does not support models on Ima-
geNet, which makes it limited in real-life scenarios. The statisticalInput Image NetworkÎ·,ÏµandK(1)
0.01,0.0010.1,0.0010.01,0.1
20K 5K 20K 5K 20K 5K
ResNet18 545454
ResNet50 888898
ResNet152 555555
ResNet18 16 14 15 14 15 14
ResNet50 12 11 12 12 12 11
ResNet152 10 9 10 9 10 9
ResNet18 111011101110
ResNet50 656565
ResNet152 989898
ResNet18 1 1 11 11
ResNet50 3 3 33 33
ResNet152 6 5 65 65
ResNet18 161316141614
ResNet50 171517151715
ResNet152 121012101210
Table2:Themaximumrobustnessradiusestimatedby Deep-
PAConCIFAR-10datasetusingdifferentparameters,i.e.sig-
nificancelevel Î·,errorrate Ïµ,andthenumberofsamplesin
the first learning phase K(1).
methodsalleviatethisdilemmaandextendtheirusefurther.The
state-of-the-artPACrobustnessverifierPROVEROneedstodraw
737297 samples for VGG16 and 722979 samples for VGG19 on av-
erage for each verification case on ImageNet. The average running
time isnear 2208.9 secondsand 2168.9 seconds(0.003 seconds per
sample)underthesupportofanNvidiaTeslaV100GPU.Wewill
showthatDeepPACcanverifythetighterPAC-modelrobustness
on ImageNet with less samples and time on much larger ResNet50
models.
In this experiment, we apply DeepPAC to the start-of-the-art
DNN with high resolution ImageNet images. The two ResNet50networks are from the python package named â€œrobustnessâ€ [
18].
WecheckPAC-modelrobustnessofthetwoDNNswiththesame
radius4(outof255).ThefirstevaluationisonasubsetofImageNetimagesfrom10classes[
27].ThesecondoneincludesImageNetim-
agesofall1,000classesandtheuntargetedscoredifferencefunction
is configured for DeepPAC. To deal with ImageNet, the stepwise
splitting mechanism in Sect. 4.3.3is adopted. An illustrating exam-
ple of the stepwise splitting is given in Fig. 8. As we expect, the
splittingrefinementproceduresuccessfullyidentifiesthesignificant
featuresofagolfball,i.e.theboundaryandthelogo.Itmaintains
2197
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:54:36 UTC from IEEE Xplore.  Restrictions apply. ICSE 2022, May 21â€“29, 2022, Pittsburgh, PA, USA Renjue Li, et al.
É‰
PAC  - model robust
Significant Grids Significance: from 0 to 0.3= 0.0481 É‰= 0.0467 É‰= 0.0387
É‰= 0.0331 É‰= 0.0390 É‰= 0.0388
Figure 8: Stepwise splitting procedures of DeepPAC , illus-
trated by heatmaps of grid significance. Top 25% significant
grids are colored yellow in the heatmap, which is split andrefined iteratively. The margin Î»of different refinement
stage is under the heatmap.
the accuracy of the learned model with much less running time.
The results are shown in Tab. 3.
For the10-class setup, we evaluatethe PAC-modelrobustness
on 50 images and it takes less than 1800 seconds on each case.
DeepPACfindsout30and29casesPAC-modelrobustforResNet50a
and ResNet50b, respectively. Because the two models have been
defensed,whenweperformthePGDattack,onlyoneadversarial
examples were found for each model, which means that PGD gives
noconclusionfortherobustnessevaluationonmostcasesunder
this setting. For the 1000-class dataset, the untargeted version of
DeepPAChasevenbetterefficiencywiththerunningtimeofless
than 800 seconds each, which mainly benefits from reducing the
scoredifferencefunctiontotheuntargetedone.DeepPACproves
10 and 6 out of 50 cases to be PAC-model robust on the 1000-class
setup,respectively.Forbothsetups,DeepPACuses121600samples
to learn a PAC model effectively.
Method Network Robust Min Max Avg
Targeted(10 classes)ResNet50a 30/50 1736.5 1768.8 1751.8ResNet50b 29/50 1722.1 1781.5 1746.5
Untargeted(1000 classes)ResNet50a 10/50 779.2 785.3 781.7ResNet50b 6/50 775.7 783.8 778.3
Table 3: The performance of DeepPAC analysing the two
ResNet50 models for ImageNet. â€œRobustâ€ represents the ro-bustness rate. â€œMinâ€, â€œMaxâ€, and â€œAvgâ€ are the minimum,maximum,andaverageoftherunningtime(second),respec-tively.
Answer RQ3:
The DeepPAC robustness analysis scales well
tocomplexDNNswithhigh-dimensionaldatalikeImageNet,
whichisnotachievedbypreviousformalverificationtools.It
shows superiority toPROVEROin bothrunningtime andthe
number of samples.Network DeepPAC ERAN PROVERO
FNN1 -0.3628 -0.3437 -0.3968
FNN2 -0.4851 -0.4353 -0.5142
FNN3 -0.4174 -0.3677 -0.4223
FNN4 -0.5264 -0.4722 -0.5234
FNN5 -0.4465 -0.6016 -0.5916
FNN6 -0.4538 -0.2747 -0.3949
CNN1 -0.7340 -0.7345 -0.8223
CNN2â‹† -0.6482 -0.6478 -0.4527
CNN3â‹† -0.7216 -0.6728 -0.5218
CNN4 -0.6035 -0.6127 -0.7771
CNN5â‹† -0.7448 -0.6833 -0.3874
CNN6â‹† -0.6498 -0.6094 -0.4763
Table 4: The Pearson correlation coefficient between the
maximum robustness radius estimation and the DeepGiniindex.TheDNNsaremarkedbyâ€œ â‹†â€iftheyaretrainedwith
defense mechanisms.
5.4 Relation with Testing Prioritising Metric
We also believe that there is a positive impact from practical DNN
verification work like DeepPAC on DNN testing. For example, the
toolDeepGiniusesGiniindex,whichmeasurestheconfidenceof
aDNNpredictiononthecorrespondinginput,tosortthetesting
inputs. In Tab. 4, we report the Pearson correlation coefficient
between the DeepGini indices and the maximal robustness radii
obtained by DeepPAC, ERAN and PROVERO from the experiment
in Sect.5.1.
As in Tab. 4,themaximumrobustnessradiusiscorrelatedtothe
DeepGiniindex,alargerabsolutevalueofthecoefficientimplies
astrongercorrelation. Itrevealsthedatathathas lowprediction
confidence is also prone to be lack robustness. From this phenome-
non, webelieve DeepGinican bealso helpful indata selectionfor
robustness analysis. Interestingly, the maximum robustness radius
computed by our DeepPAC has higher correlations with DeepGini
indexontheCNNs,whicharemorecomplex,thanonFNNs.Fur-
thermore,DeepPACshowsthestrongestcorrelationontheCNNs
trainedwithdefensemechanisms,whilethecorrelationbetween
PROVERO or ERAN and DeepGini is relatively weak on these net-
works. Intuitively, complex models with defense are expected to
be more robust. Again, we regard this comparison result as theevidence from DNN testing to support the superior of DeepPACover other DNN verification tools. From the perspective of test-ing technique, it is promising to combine these two methods for
achieving test selection with guarantee.
Answer RQ4: Themaximumrobustnessradiusestimatedby
DeepPAC,ERAN,andPROVEROareallcorrelatedtotheDeep-
Gini index, where DeepPAC and DeepGini show the strongest
correlation on robust models.
5.5 Case Study: Verifying Cloud Service API
To show the practicality of DeepPAC, we apply it to analyse the
robustnessofblack-boxmodelsforreal-worldcloudservices.The
case we studyhere is the image recognition APIprovided by Baidu
2198
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:54:36 UTC from IEEE Xplore.  Restrictions apply. Towards Practical Robustness Analysis for DNNs based on PAC-Model Learning ICSE 2022, May 21â€“29, 2022, Pittsburgh, PA, USA
Figure 9: The original image (left) gain the score (dandelion :
0.758,sky:0.600),andtheadversarialexamplegainthescore
(s k y:0.791,dandelion : 0.621).
AICloud2,whichacceptsanimageandreturnsapairlistintheform
of(labeli,scorei)to indicate the top classes the input recognised
to be. We use the image of a dandelion as the input, which is an
official example in its illustration.
By setting Î·=0.001 andÏµ=0.01, we verify the PAC-model
robustnessforitstoplabelâ€œdandelionâ€withintheradiusof5 /255.
A total of 49,600 samples are utilised in the whole procedure. By
DeepPAC, we obtain the PAC-model of the difference function, but
unfortunately, its maximal value in the input Lâˆžball is larger than
zero.Asanintermediateoutput,wegenerateapotentialadversarial
example via the PAC model. By feeding it back into the model, we
checkedthatitisatrueadversarialexamplewithâ€œskyâ€asitstop
label (see Fig. 9).
Aninterestingobservationisthatthelabelsoutputbytheimage
recognition API may be not independent. For instance, the class
labels â€œdandelionâ€ and â€œplantâ€ may appear in the output list at the
sametime,andbothofthemcanbeconsideredcorrectlabels.There-
fore, we believe that in the future new forms of DNN robustness
propertiesalsoneedtobestudiede.g.,thesumoftheoutputscores
forthecorrectlabels(â€œdandelionâ€andâ€œplantâ€)shouldbelargerthan
some threshold. DeepPAC is a promising tool to cope with these
emergingchallengeswhenconsideringreal-worldapplicationsof
DNN robustness analysis, by conveniently adjusting its difference
function.
6 RELATED WORK
Herewediscussmoreresultsontheverification,adversarialattacks
and testing for DNNs. A number of formal verification techniques
have been proposed for DNNs, including constraint-solving [ 8,16,
19,22,24,32,39,47],abstractinterpretation[ 21,37,59,60,84],layer-
by-layerexhaustivesearch[ 29],globaloptimisation[ 15,55,56],con-
vexrelaxation[ 31,49,50],functionalapproximation[ 76],reduction
totwo-playergames[ 77,79],andstar-set-basedabstraction[ 66,67].
Sampling-based methods are adopted to probabilistic robustness
verificationin[ 2,3,12,45,74,75].MostofthemprovidesoundDNN
robustness estimationin the formof a norm ball,but typically for
verysmallnetworksorwithpessimisticestimationofthenormball
radius.Bycontrast,statisticalmethods[ 5,6,11,28,44,74,75,78]
2https://ai.baidu.com/tech/imagerecognition/generalare more efficient and scalable when the structure of DNNs is com-
plex.TheprimarydifferencebetweenthesemethodsandDeepPAC
is that our method is model-based and thus more accurate. We use
samplestolearnarelativelysimplemodeloftheDNNwiththePAC
guarantee via scenario optimisation and gain more insights to the
analysis of adversarial robustness. The generation of adversarial
inputs [64] itself has been widely studied by a rich literature of ad-
versarialattackmethods.Somemostwell-knownrobustnessattack
methodsincludeFastGradientSign[ 23],Jacobian-basedsaliency
mapapproach[ 48],C&Wattack[ 13],etc.Thoughadversarialat-
tackmethodsgenerateadversarialinputsefficiently,theycannot
enforceguaranteeofanyformfortheDNNrobustness.Testingis
stilltheprimaryapproachforcertifyingtheuseofsoftwareprod-
ucts andservices. In recentyears, significant work hasbeen done
forthetestingforDNNssuchastestcoveragecriteriaspecialisedfor
DNNS [34,40,51,62,83] and different testing techniques adopted
for DNNs [ 30,41,42,54,63,65,70,80,82,86]. In particular, our
experiments show that the results from DeepPAC are consistent
with the DNN testing work for prioritising test inputs [ 20,73], but
with a stronger guarantee. This highlights again that DeepPAC is a
practical verification method for DNN robustness.
7 CONCLUSION AND FUTURE WORK
WeproposeDeepPAC,amethodbasedonmodellearningtoanal-
yse the PAC-model robustness of DNNs in a local region. With
the scenario optimisation technique, we learn a PAC model which
approximates the DNN within a uniformly bounded margin with a
PACguarantee.WiththelearnedPACmodel,wecanverifyPAC-
modelrobustnesspropertiesunderspecifiedconfidenceanderror
rate. Experimental results confirm that DeepPAC scales well on
large networks, and is suitable for practical DNN verification tasks.
As for future work, we plan to learn more complex PAC models
rather than the simple affine models, and we are particularly inter-
estedinexploringthecombinationofpracticalDNNverification
by DeepPACandDNN testing methodsfollowing thepreliminaryresults.
ACKNOWLEDGEMENTS
This work has been partially supported by Key-Area Research
and Development Program of Guangdong Province (Grant No.2018B010107004), Guangzhou Basic and Applied Basic Research
Project(GrantNo.202102021304),NationalNaturalScienceFounda-
tion of China (Grant No. 61836005), and Open Project of Shanghai
Key Laboratory of Trustworthy Computing (Grant No. OP202001).
REFERENCES
[1]Moustafa Alzantot, Yash Sharma, Supriyo Chakraborty, Huan Zhang, Cho-Jui
Hsieh,andManiB.Srivastava.2019. GenAttack:practicalblack-boxattackswith
gradient-free optimization. In GECCO 2019, Anne Auger and Thomas StÃ¼tzle
(Eds.). ACM, Prague, Czech Republic, 1111â€“1119.
[2]BrendonG.AndersonandSomayehSojoudi.2020. CertifyingNeuralNetwork
Robustness to Random Input Noise from Samples. arXiv:2010.07532 [cs.LG]
[3]BrendonG.AndersonandSomayehSojoudi.2020. Data-DrivenAssessmentof
DeepNeuralNetworkswithRandomInputUncertainty. arXiv:2010.01171 [cs.LG]
[4]Pranav Ashok, Vahid Hashemi, Jan KretÃ­nskÃ½, and Stefanie Mohr. 2020. Deep-
Abstract: Neural Network Abstraction for Accelerating Verification. In ATVA
2020 (LectureNotesinComputerScience,Vol.12302),DangVanHungandOleg
Sokolsky (Eds.). Springer, 92â€“107.
2199
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:54:36 UTC from IEEE Xplore.  Restrictions apply. ICSE 2022, May 21â€“29, 2022, Pittsburgh, PA, USA Renjue Li, et al.
[5]Teodora Baluta, Zheng Leong Chua, Kuldeep S Meel, and Prateek Saxena. 2021.
Scalablequantitativeverificationfordeepneuralnetworks.In ICSE2021.IEEE,
Madrid, Spain, 312â€“323.
[6]TeodoraBaluta,ShiqiShen,ShwetaShinde,KuldeepS.Meel,andPrateekSaxena.
2019. QuantitativeVerificationofNeuralNetworksandItsSecurityApplications.InCCS2019,November11-15,2019 ,LorenzoCavallaro,JohannesKinder,XiaoFeng
Wang, and Jonathan Katz (Eds.). ACM, London, UK, 1249â€“1264.
[7]AkhilanBoopathy,Tsui-WeiWeng,Pin-YuChen,SijiaLiu,andLucaDaniel.2019.
CNN-Cert:AnEfficientFrameworkforCertifyingRobustnessofConvolutional
Neural Networks. In AAAI 2019, January 27 - February 1, 2019 . AAAI Press,
Honolulu, Hawaii, USA, 3240â€“3247.
[8]Rudy Bunel,Jingyue Lu, IlkerTurkaslan, Philip H.S. Torr,Pushmeet Kohli, and
M.PawanKumar.2020. BranchandBoundforPiecewiseLinearNeuralNetwork
Verification. J. Mach. Learn. Res. 21 (2020), 42:1â€“42:39.
[9]GiuseppeCarloCalafioreandMarcoC.Campi.2006. Thescenarioapproachto
robust control design. IEEE Trans. Autom. Control. 51, 5 (2006), 742â€“753.
[10]MarcoC.Campi,SimoneGaratti,andMariaPrandini.2009.Thescenarioapproach
for systems and control design. Annu. Rev. Control. 33, 2 (2009), 149â€“157.
[11]LucaCardelli,MartaKwiatkowska,LucaLaurenti,NicolaPaoletti,AndreaPatane,andMatthewWicker.2019. StatisticalGuaranteesfortheRobustnessofBayesian
NeuralNetworks.In IJCAI2019,August10-16,2019,SaritKraus(Ed.).ijcai.org,
Macao, China, 5693â€“5700.
[12]Luca Cardelli, Marta Kwiatkowska, Luca Laurenti, and Andrea Patane. 2019.
RobustnessGuaranteesforBayesianInferencewithGaussianProcesses.In AAAI
2019,January27-February 1,2019 .AAAIPress,Honolulu,Hawaii,USA,7759â€“
7768.
[13]Nicholas Carlini and David Wagner. 2017. Towards evaluating the robustness of
neural networks. In S&P 2017. IEEE, IEEE Computer Society, San Jose, CA, USA,
39â€“57.
[14]StevenDiamondandStephenBoyd.2016. CVXPY:APython-embeddedmodeling
languagefor convexoptimization. Journalof MachineLearningResearch 17,83
(2016), 1â€“5.
[15]SouradeepDutta,SusmitJha,SriramSankaranarayanan,andAshishTiwari.2018.
Output Range Analysis for Deep Feedforward Neural Networks. In NFM 2018
(LectureNotesinComputerScience,Vol.10811),AaronDutle,CÃ©sarA.MuÃ±oz,and
Anthony Narkawicz (Eds.). Springer, Newport News, VA, USA, 121â€“138.
[16]RÃ¼diger Ehlers. 2017. Formal Verification of Piece-Wise Linear Feed-Forward
Neural Networks. In ATVA 2017. Springer, Pune, India, 269â€“286.
[17]Yizhak Yisrael Elboher, Justin Gottschlich, and Guy Katz. 2020. An Abstraction-
BasedFrameworkforNeuralNetworkVerification.In CAV2020 (LectureNotesin
ComputerScience,Vol.12224),ShuvenduK.LahiriandChaoWang(Eds.).Springer,
Los Angeles, CA, USA, 43â€“65.
[18]LoganEngstrom,AndrewIlyas,HadiSalman,ShibaniSanturkar,andDimitris
Tsipras. 2019. Robustness (Python Library). https://github.com/MadryLab/
robustness
[19]Chengdong Feng, Zhenbang Chen, Weijiang Hong, Hengbiao Yu, Wei Dong, and
JiWang.2018. BoostingtheRobustnessVerificationofDNNbyIdentifyingthe
Achillesâ€™s Heel. CoRRabs/1811.07108(2018). arXiv: 1811.07108
[20]YangFeng,QingkaiShi,XinyuGao,JunWan,ChunrongFang,andZhenyuChen.
2020. DeepGini: prioritizing massive tests to enhance the robustness of deepneural networks. In 29th ACM SIGSOFT International Symposium on Software
Testing and Analysis. ACM, Virtual Event, USA, 177â€“188.
[21]T.Gehr,M.Mirman,D.Drachsler-Cohen,P.Tsankov,S.Chaudhuri,andM.Vechev.
2018. AI2:SafetyandRobustnessCertificationofNeuralNetworkswithAbstract
Interpretation. In 2018 IEEE Symposium on Security and Privacy (S&P 2018). IEEE
Computer Society, San Francisco, California, USA, 948â€“963.
[22]Sumathi Gokulanathan, Alexander Feldsher, Adi Malca, Clark W. Barrett, and
Guy Katz. 2020. Simplifying Neural Networks Using Formal Verification. In
NFM 2020, USA, May 11-15, 2020, Proceedings (Lecture Notes in Computer Science,
Vol. 12229), Ritchie Lee, Susmit Jha, and Anastasia Mavridou (Eds.). Springer,
Moffett Field, CA, 85â€“93.
[23]Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. 2015. Explaining and
Harnessing Adversarial Examples. In ICLR 2015, Yoshua Bengio and Yann LeCun
(Eds.). San Diego, CA, USA.
[24]Divya Gopinath, Guy Katz, Corina S. Pasareanu, and Clark W. Barrett. 2018.
DeepSafe:AData-DrivenApproachforAssessingRobustnessofNeuralNetworks.
InATVA 2018, October 7-10, 2018, Proceedings (Lecture Notes in Computer Science,
Vol. 11138), Shuvendu K. Lahiri and Chao Wang (Eds.). Springer, Los Angeles,
CA, USA, 3â€“19.
[25]LLC Gurobi Optimization. 2021. Gurobi Optimizer Reference Manual. http:
//www.gurobi.com
[26]Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep Residual
LearningforImageRecognition.In CVPR2016.IEEEComputerSociety,LasVegas,
NV, USA, 770â€“778.
[27]Jeremy Howard. 2019. The Imagenette dataset. https://github.com/fastai/
imagenette[28]Pei Huang, Yuting Yang, Minghao Liu, Fuqi Jia, Feifei Ma, and Jian Zhang. 2021.
Ïµ-weakened Robustness of Deep Neural Networks. CoRRabs/2110.15764 (2021).
arXiv:2110.15764
[29]Xiaowei Huang, Marta Kwiatkowska, Sen Wang, and Min Wu. 2017. Safety Veri-
fication of Deep Neural Networks. In CAV 2017. Springer, Heidelberg, Germany,
3â€“29.
[30]Nargiz Humbatova, Gunel Jahangirova, and Paolo Tonella. 2021. DeepCrime:mutation testing of deep learning systems based on real faults. In 30th ACM
SIGSOFTInternationalSymposiumonSoftwareTestingandAnalysis .ACM,Virtual
Event, Denmark, 67â€“78.
[31]KyleD.Julian,ShivamSharma,Jean-BaptisteJeannin,andMykelJ.Kochenderfer.
2019. VerifyingAircraftCollisionAvoidanceNeuralNetworksThroughLinear
Approximations of SafeRegions. CoRRabs/1903.00762 (2019). arXiv:1903.00762
http://arxiv.org/abs/1903.00762
[32]GuyKatz,ClarkW.Barrett,DavidL.Dill,KyleJulian,andMykelJ.Kochenderfer.
2017. Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks. In
CAV 2017. Springer, Heidelberg, Germany, 97â€“117.
[33]Guy Katz, Derek A. Huang, Duligur Ibeling, Kyle Julian, Christopher Lazarus,
RachelLim,ParthShah,ShantanuThakoor,HaozeWu,AleksandarZeljic,DavidL.Dill,MykelJ.Kochenderfer,andClarkW.Barrett.2019. TheMarabouFrameworkforVerificationandAnalysisofDeepNeuralNetworks.In CAV2019(LectureNotes
in Computer Science, Vol. 11561), Isil Dillig and Serdar Tasiran (Eds.). Springer,
New York City, NY, USA, 443â€“452.
[34]Jinhan Kim, Robert Feldt, and Shin Yoo. 2019. Guiding deep learning system
testing using surprise adequacy. In ICSE 2019. IEEE, IEEE / ACM, Montreal, QC,
Canada, 1039â€“1049.
[35]AlexKrizhevskyetal .2009. Learningmultiplelayersoffeaturesfromtinyimages.
(2009).
[36]YannLÃ©cun,LeonBottou,YoshuaBengio,andPatrickHaffner.1998. Gradient-
based learning applied to document recognition. Proc. IEEE 86, 11 (1998), 2278â€“
2324.
[37] Jianlin Li, Jiangchao Liu, Pengfei Yang, Liqian Chen, Xiaowei Huang, and Lijun
Zhang. 2019. Analyzing Deep Neural Networks with Symbolic Propagation:
Towards Higher Precision and Faster Verification. In SAS 2019 (Lecture Notes
in Computer Science, Vol. 11822), Bor-Yuh Evan Chang (Ed.). Springer, Porto,
Portugal, 296â€“319.
[38]RenjueLi,JianlinLi,Cheng-ChaoHuang,PengfeiYang,XiaoweiHuang,Lijun
Zhang,BaiXue,andHolgerHermanns.2020. PRODeep:aplatformforrobustness
verification of deep neural networks. In ESEC/FSE â€™20, November 8-13, 2020,P r e m
Devanbu, Myra B. Cohen, and Thomas Zimmermann (Eds.). ACM, Virtual Event,
USA, 1630â€“1634.
[39]Wang Lin, Zhengfeng Yang, Xin Chen, Qingye Zhao, Xiangkun Li, Zhiming
Liu,andJifengHe.2019. RobustnessVerificationofClassificationDeepNeural
Networks via Linear Programming. In CVPR 2019, June 16-20, 2019. Computer
Vision Foundation / IEEE, Long Beach, CA, USA, 11418â€“11427.
[40]LeiMa,FelixJuefei-Xu,FuyuanZhang,JiyuanSun,MinhuiXue,BoLi,Chunyang
Chen, Ting Su, Li Li, Yang Liu, et al .2018. DeepGauge: Multi-granularity testing
criteria for deep learning systems. In ASE 2018. ACM, Montpellier, France, 120â€“
131.
[41]Lei Ma, Fuyuan Zhang, Jiyuan Sun, Minhui Xue, Bo Li, Felix Juefei-Xu, Chao
Xie, Li Li, Yang Liu, Jianjun Zhao, et al .2018. DeepMutation: Mutation testing of
deeplearningsystems.In ISSRE2018.IEEE,IEEEComputerSociety,Memphis,
TN, USA, 100â€“111.
[42]ShiqingMa,YingqiLiu,Wen-ChuanLee,XiangyuZhang,andAnanthGrama.
2018. MODE: automatedneuralnetworkmodeldebuggingvia statedifferential
analysis and input selection. In ESEC/FSE 2018 . ACM, Lake Buena Vista, FL, USA,
175â€“186.
[43]Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
Adrian Vladu. 2018. Towards Deep Learning Models Resistant to Adversarial
Attacks. In ICLR 2018. OpenReview.net, Vancouver, BC, Canada.
[44]RaviMangal,AdityaV.Nori,andAlessandroOrso.2019. Robustnessofneural
networks: a probabilistic and practical approach. In ICSE (NIER) 2019, May 29-31,
2019,AnitaSarmaandLeonardoMurta(Eds.).IEEE/ACM,Montreal,QC,Canada,
93â€“96.
[45]RaviMangal,AdityaV.Nori,andAlessandroOrso.2019. Robustnessofneural
networks:aprobabilisticandpracticalapproach.In ICSE(NIER)2019,Montreal,
QC, Canada, May 29-31, 2019 , Anita Sarma and Leonardo Murta (Eds.). IEEE /
ACM, Montreal, QC, Canada, 93â€“96.
[46]ChristophMÃ¼ller,GagandeepSingh,MarkusPÃ¼schel,andMartinT.Vechev.2020.
Neural Network RobustnessVerification on GPUs. CoRRabs/2007.10868 (2020).
arXiv:2007.10868 https://arxiv.org/abs/2007.10868
[47]Nina Narodytska, Shiva Prasad Kasiviswanathan, Leonid Ryzhyk, Mooly Sagiv,
and Toby Walsh. 2018. Verifying Properties of Binarized Deep Neural Networks.
InAAAI2018,SheilaA.McIlraithandKilianQ.Weinberger(Eds.).AAAIPress,
New Orleans, Louisiana, USA, 6615â€“6624.
[48]Nicolas Papernot, Patrick D. McDaniel, Somesh Jha, Matt Fredrikson, Z. Berkay
Celik, and Ananthram Swami. 2016. The Limitations of Deep Learning in Adver-
sarial Settings. In EuroS&P 2016, March 21-24, 2016. IEEE, SaarbrÃ¼cken, Germany,
2200
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:54:36 UTC from IEEE Xplore.  Restrictions apply. Towards Practical Robustness Analysis for DNNs based on PAC-Model Learning ICSE 2022, May 21â€“29, 2022, Pittsburgh, PA, USA
372â€“387.
[49]Brandon Paulsen, Jingbo Wang, and Chao Wang. 2020. ReluDiff: differential
verificationofdeepneuralnetworks.In ICSEâ€™20,27June-19July,2020,Gregg
Rothermel and Doo-Hwan Bae (Eds.). ACM, Seoul, South Korea, 714â€“726.
[50]Brandon Paulsen, Jingbo Wang, Jiawei Wang, and Chao Wang. 2020. NEUROD-
IFF: Scalable Differential Verification of Neural Networks using Fine-Grained
Approximation. In ASE 2020, September 21-25, 2020. IEEE, Melbourne, Australia,
784â€“796.
[51] KexinPei,YinzhiCao,JunfengYang,andSumanJana.2017. DeepXplore:Auto-
matedwhiteboxtestingofdeeplearningsystems.In 26thSymposiumonOperating
Systems Principles. ACM, Shanghai, China, 1â€“18.
[52]JonasRauber,WielandBrendel,andMatthiasBethge.2017. Foolbox:APython
toolbox to benchmark the robustness of machine learning models. In Reliable
MachineLearningintheWildWorkshop,34thInternationalConferenceonMachine
Learning.
[53]MarcoTÃºlioRibeiro,SameerSingh,andCarlosGuestrin.2016. "WhyShouldI
TrustYou?":ExplainingthePredictionsofAnyClassifier.In SIGKDD2016,August
13-17, 2016, Balaji Krishnapuram, Mohak Shah, Alexander J. Smola, Charu C.
Aggarwal,DouShen,andRajeevRastogi(Eds.).ACM,SanFrancisco,CA,USA,
1135â€“1144.
[54]VincenzoRiccioandPaoloTonella.2020. Model-basedexplorationofthefrontier
of behaviours for deep learning system testing. In ESEC/FSE 2020. ACM, Virtual
Event, USA, 876â€“888.
[55]Wenjie Ruan, Xiaowei Huang, and Marta Kwiatkowska. 2018. Reachability
Analysis of Deep Neural Networks with Provable Guarantees. In IJCAI 2018.
ijcai.org, Stockholm, Sweden, 2651â€“2659.
[56]Wenjie Ruan, Min Wu, Youcheng Sun, Xiaowei Huang, Daniel Kroening, and
Marta Kwiatkowska. 2019. Global Robustness Evaluation of Deep Neural Net-
works with Provable Guarantees for the Hamming Distance. In IJCAI 2019, Sarit
Kraus (Ed.). ijcai.org, Macao, China, 5944â€“5952.
[57]OlgaRussakovsky,JiaDeng,HaoSu,JonathanKrause,SanjeevSatheesh,SeanMa,ZhihengHuang,AndrejKarpathy,AdityaKhosla,MichaelBernstein,AlexanderC.
Berg, andLi Fei-Fei.2015. ImageNet Large ScaleVisual RecognitionChallenge.
IJCV115, 3 (2015), 211â€“252.
[58]AndrewW.Senior,RichardEvans,JohnJumper,JamesKirkpatrick,LaurentSifre,
TimGreen,ChongliQin,AugustinZÃ­dek,AlexanderW.R.Nelson,AlexBridgland,
HugoPenedones,StigPetersen,KarenSimonyan,SteveCrossan,PushmeetKohli,
David T. Jones, David Silver, Koray Kavukcuoglu, and Demis Hassabis. 2020.
Improved protein structure prediction using potentials from deep learning. Nat.
577, 7792 (2020), 706â€“710.
[59]Gagandeep Singh, Timon Gehr, Matthew Mirman, Markus PÃ¼schel, and Mar-
tin T. Vechev. 2018. Fast and Effective Robustness Certification. In NeurIPS 2018.
MontrÃ©al, Canada, 10825â€“10836.
[60]Gagandeep Singh, Timon Gehr, Markus PÃ¼schel, and Martin T. Vechev. 2019.
An abstract domain for certifying neural networks. PACMPL 3, POPL (2019),
41:1â€“41:30.
[61]ETHZurichSRILab,DepartmentofComputerScience.2020. ETHRobustness
Analyzer for Neural Networks (ERAN). https://github.com/eth-sri/eran
[62]YouchengSun,XiaoweiHuang,DanielKroening,JamesSharp,MatthewHill,and
RobAshmore.2019. Structuraltestcoveragecriteriafordeepneuralnetworks.
InICSE2019,JoanneM.Atlee,TevfikBultan,andJonWhittle(Eds.).IEEE/ACM,
Montreal, QC, Canada, 320â€“321.
[63]Zeyu Sun, Jie M Zhang, Mark Harman, Mike Papadakis, and Lu Zhang. 2020.
Automatic testing and improvement of machine translation. In ICSE 2020. ACM,
Seoul, South Korea, 974â€“985.
[64]ChristianSzegedy,WojciechZaremba,IlyaSutskever,JoanBruna,DumitruErhan,
Ian Goodfellow, and Rob Fergus. 2014. Intriguing properties of neural networks.
InICLR 2014. Banff, AB, Canada.
[65]Yuchi Tian, Kexin Pei, Suman Jana, and Baishakhi Ray. 2018. DeepTest: Auto-mated testing of deep-neural-network-driven autonomous cars. In ICSE 2018.
ACM, Gothenburg, Sweden, 303â€“314.
[66]Hoang-Dung Tran, Stanley Bak, Weiming Xiang, and Taylor T. Johnson. 2020.
Verification ofDeepConvolutional NeuralNetworks UsingImageStars.In CAV
2020 (LectureNotesinComputerScience,Vol.12224),ShuvenduK.LahiriandChao
Wang (Eds.). Springer, Los Angeles, CA, USA, 18â€“42.
[67]Hoang-Dung Tran, Diego Manzanas Lopez, Patrick Musau, Xiaodong Yang,Luan Viet Nguyen, Weiming Xiang, and Taylor T. Johnson. 2019. Star-BasedReachability Analysis of Deep Neural Networks. In FM 2019 (Lecture Notes in
ComputerScience,Vol.11800),MauriceH.terBeek,AnnabelleMcIver,andJosÃ©N.
Oliveira (Eds.). Springer, Porto, Portugal, 670â€“686.
[68]Hoang-Dung Tran, Xiaodong Yang, Diego Manzanas Lopez, Patrick Musau,Luan Viet Nguyen, Weiming Xiang, Stanley Bak, and Taylor T. Johnson. 2020.NNV: The Neural Network Verification Tool for Deep Neural Networks and
Learning-EnabledCyber-PhysicalSystems.In CAV2020,July21-24,2020,Proceed-
ings, Part I (Lecture Notes in Computer Science, Vol. 12224), Shuvendu K. Lahiri
and Chao Wang (Eds.). Springer, Los Angeles, CA, USA, 3â€“17.
[69]Chris Urmson and William Whittaker. 2008. Self-Driving Cars and the Urban
Challenge. IEEE Intell. Syst. 23, 2 (2008), 66â€“68.[70]JingyiWang, JialuoChen,YouchengSun, XingjunMa,DongxiaWang, JunSun,
andPengCheng.2021. RobOT:Robustness-orientedtestingfordeeplearning
systems. In ICSE 2021. IEEE, IEEE, Madrid, Spain, 300â€“311.
[71]Jingyi Wang, Guoliang Dong, Jun Sun, Xinyu Wang, and Peixin Zhang. 2019.
Adversarial sample detection for deep neural network through model mutation
testing. In ICSE 2019. IEEE, IEEE / ACM, Montreal, QC, Canada, 1245â€“1256.
[72]Jingyi Wang, Jun Sun, Peixin Zhang, and Xinyu Wang. 2018. Detecting Ad-
versarialSamplesforDeepNeuralNetworksthroughMutationTesting. CoRR
abs/1805.05010(2018). arXiv: 1805.05010 http://arxiv.org/abs/1805.05010
[73]Zan Wang, Hanmo You, Junjie Chen, Yingyi Zhang, Xuyuan Dong, and Wenbin
Zhang. 2021. Prioritizing Test Inputs for Deep Neural Networks via Mutation
Analysis. In ICSE 2021. IEEE, IEEE, Madrid, Spain, 397â€“409.
[74]Stefan Webb, Tom Rainforth, Yee Whye Teh, and M. Pawan Kumar. 2019. AStatistical Approach to Assessing Neural Network Robustness. In ICLR 2019.
OpenReview.net, New Orleans, LA, USA.
[75]Lily Weng, Pin-Yu Chen, Lam M. Nguyen, Mark S. Squillante, Akhilan Boopathy,
Ivan V. Oseledets, and Luca Daniel. 2019. PROVEN: Verifying Robustness ofNeural Networks with a Probabilistic Approach. In ICML 2019, 9-15 June 2019
(Proceedings of Machine Learning Research, Vol. 97), Kamalika Chaudhuri and
Ruslan Salakhutdinov (Eds.). PMLR, Long Beach, California, USA, 6727â€“6736.
[76]Tsui-Wei Weng, Huan Zhang, Hongge Chen, Zhao Song, Cho-Jui Hsieh, Luca
Daniel,DuaneS.Boning,andInderjitS.Dhillon.2018. TowardsFastComputationofCertifiedRobustnessforReLUNetworks.In ICML2018 (ProceedingsofMachine
Learning Research, Vol. 80), Jennifer G. Dy and Andreas Krause (Eds.). PMLR,
Stockholm, Sweden, 5273â€“5282.
[77]MatthewWicker,XiaoweiHuang,andMartaKwiatkowska.2018. Feature-GuidedBlack-BoxSafetyTestingofDeepNeuralNetworks.In TACAS2018 (LectureNotes
inComputerScience,Vol.10805),DirkBeyerandMariekeHuisman(Eds.).Springer,
Thessaloniki,Greece, 408â€“426.
[78] Matthew Wicker, Luca Laurenti, Andrea Patane, and Marta Kwiatkowska. 2020.
Probabilistic Safety for Bayesian Neural Networks. In UAI 2020, August 3-6, 2020
(Proceedings of MachineLearning Research, Vol.124), Ryan P.Adams and Vibhav
Gogate (Eds.). AUAI Press, virtual online, 1198â€“1207.
[79]MinWu,MatthewWicker,WenjieRuan,XiaoweiHuang,andMartaKwiatkowska.
2020. A game-based approximate verification of deep neural networks with
provable guarantees. Theor. Comput. Sci. 807 (2020), 298â€“329.
[80]XiaofeiXie,LeiMa,FelixJuefei-Xu,MinhuiXue,HongxuChen,YangLiu,Jianjun
Zhao, Bo Li, Jianxiong Yin, and Simon See. 2019. DeepHunter: a coverage-
guided fuzz testing framework for deep neural networks. In 28th ACM SIGSOFT
International Symposium on Software Testing and Analysis. ACM, Beijing, China,
146â€“157.
[81]BaiXue,MiaomiaoZhang,ArvindEaswaran,andQinLi.2020. PACModelCheck-
ing of Black-Box Continuous-Time Dynamical Systems. IEEE Trans. Comput.
Aided Des. Integr. Circuits Syst. 39, 11 (2020), 3944â€“3955.
[82]Ming Yan, Junjie Chen, Xiangyu Zhang, Lin Tan, Gan Wang, and Zan Wang.
2021. Exposing numerical bugs in deep learning via gradient back-propagation.
InESEC/FSE 2021. ACM, Athens, Greece, 627â€“638.
[83]Shenao Yan, Guanhong Tao, Xuwei Liu, Juan Zhai, Shiqing Ma, Lei Xu, and
XiangyuZhang.2020. Correlationsbetweendeepneuralnetworkmodelcoverage
criteriaandmodelquality.In ESEC/FSE2020.ACM,VirtualEvent,USA,775â€“787.
[84]PengfeiYang,RenjueLi,JianlinLi,Cheng-ChaoHuang,JingyiWang,JunSun,
BaiXue,andLijunZhang.2021. ImprovingNeuralNetworkVerificationthrough
Spurious Region Guided Refinement. In TACAS 2021 (Lecture Notes in Computer
Science, Vol. 12651), Jan Friso Groote and Kim Guldstrand Larsen (Eds.). Springer,
Luxembourg City, Luxembourg, 389â€“408.
[85]Hanwei Zhang, Yannis Avrithis, Teddy Furon, and Laurent Amsaleg. 2020. Walk-
ing on the edge: Fast, low-distortion adversarial examples. IEEE Transactions on
Information Forensics and Security 16 (2020), 701â€“713.
[86]MengshiZhang,YuqunZhang,LingmingZhang,CongLiu,andSarfrazKhurshid.
2018. DeepRoad:GAN-basedmetamorphictestingandinputvalidationframe-
work for autonomous driving systems. In ASE 2018. IEEE, ACM, Montpellier,
France, 132â€“142.
2201
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:54:36 UTC from IEEE Xplore.  Restrictions apply. 