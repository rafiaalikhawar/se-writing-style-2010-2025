Using Deep Learning to Generate Complete Log Statements
Antonio Mastropaolo
antonio.mastropaolo@usi.ch
SEART @ Software Institute
Università della Svizzera italiana
SwitzerlandLuca Pascarella
luca.pascarella@usi.ch
SEART @ Software Institute
Università della Svizzera italiana
SwitzerlandGabriele Bavota
gabriele.bavota@usi.ch
SEART @ Software Institute
Università della Svizzera italiana
Switzerland
ABSTRACT
Loggingisapracticewidelyadoptedinseveralphasesofthesoft-
warelifecycle.Forexample,duringsoftwaredevelopmentlogstate-
ments allow engineers to verify and debug the system by exposing
fine-grained information of the running software. While the bene-
fits of logging are undisputed, taking proper decisions about where
to inject log statements, whatinformation to log, and at which log
level(e.g.,error,warning)iscrucialfor theloggingeffectiveness.In
thispaper,wepresentLANCE( LogstAtemeNtreCommEnder),the
first approach supporting developers in all these decisions. LANCE
features a Text-To-Text-Transfer-Transformer (T5) model that has
been trained on 6,894,456 Java methods. LANCE takes as input
a Java method and injects in it a full log statement, including ahuman-comprehensible logging message and properly choosing
theneededloglevelandthestatementlocation.Ourresultsshow
that LANCE is able to (i) properly identify the location in the code
wheretoinject thestatementin 65.9%ofJavamethodsrequiringit;
(ii)selectingtheproperloglevelin66.2%ofcases;and(iii)generate
a completely correct log statement including a meaningful logging
message in 15.2% of cases.
CCS CONCEPTS
•Softwareanditsengineering →Softwaremaintenancetools .
KEYWORDS
Logging, Empirical Study, Machine Learning on Code
1 INTRODUCTION
Inspecting log messages is a popular practice that helps developers
inseveralsoftwaremaintenanceactivitiessuchastesting[ 11,12],
debugging [ 39], diagnosis [ 47,52], and monitoring [ 18,19]. Devel-
opers insert log statements to expose and register informationabout the internal behavior of a software artifact in a human-
comprehensiblefashion[ 36].Thedatageneratedisusedforruntime
andpost-mortemanalyses.Forexample,whendebugginglogstate-ments can support root cause analysis [
16,32], while once the soft-
wareisdeployedlogscanbeusedforperformancemonitoring[ 44]
or anomaly detection [14, 34, 49].
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
© 2022 Association for Computing Machinery.
ACM ISBN 978-1-4503-9221-1/22/05...$15.00
https://doi.org/10.1145/3510003.3511561Although technically possible, logging everything (e.g., every
exception) is inefficient and impracticable [ 53]. On the one hand, a
coarse-grainedloggingriskshidingruntimefailures,missinglog
messages useful for diagnoses [45].
Ontheotherhand,afine-grainedloggingrisksincreasingthe
overhead of log management and analysis [ 26]. To optimize the
quantity and quality of data generated, developers insert log state-
ments in strategic positions, specify appropriate log levels (e.g.,
error, debug, info), and define compact but comprehensible text
messages. Nonetheless, it remains a non-trivial task for developers
to decide where, what, and at which level to log [26, 46].
For these reasons, researchers have proposed techniques to sup-
portdevelopersindecidingwhatpartsofthesystemtolog[ 45],the
loglevelforloggingstatements[ 26,27,36,46],andthestructureof
logmessages[ 28].Forexample,Jia etal.[23]proposedanapproach
basedonassociationrulestoplaceerrorlogsaftercodebranches
such asifstatements. Li et al.[25] studied the use of topic mod-
eling for log placement at method-level. Also, two recent workstackled challenges related to log statements writing by adopting
deep learning (DL) models.
Liet al.[30], withDeepLV, pushed the boundaries of log recom-
mendation by suggesting and fixing log levels of already typed log
statements. DeepLVrelies on an ad-hoc DL network that combines
syntactic(i.e., AST)andcontextual(i.e., logmessage)information
extractedfromcodetosuggestanalternativelogginglevelwhen
needed. Li et al.[29] also proposed a second DL-based approach
to provide fine-grained ( i.e.,at the code block level) suggestions
aboutwheretoaddloggingstatements.Themodelcapturesboth
syntactic and semantic information of the source code and returns
abinaryvalueindicatingwhethertoaddornotalogstatementina
given block. While achieving great performance, these techniques
onlypartiallysupportdevelopersinloggingpractices.Indeed,none
of them can generate complete log statements providing to the
developer(i)thelocationwheretoinjectit,(ii)thecorrectloglevel
touse,and(iii)theactuallogstatementalsofeaturingtheneeded
natural language log message.
Inthispaper,wepresentLANCE( LogstAtemeNtreCommEnder),
anapproachaimedatexploitingtherecentlyproposedText-To-Text-
Transfer-Transformer (T5) model [ 38] to automatically generate
and inject complete logging statements in Java code. We started
by pre-training our model on a set of 6,832,859 Java methods. The
pre-traininghasbeenperformedthroughtwopre-trainingobjec-tives.Thefirstisaclassic“maskedtoken”objective,inwhichwe
randomly mask 15% of the code tokens in the Java methods asking
the model to guess them. This provides the model with general
knowledge about the Java language, including logging statements.
22792022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:59:43 UTC from IEEE Xplore.  Restrictions apply. ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Antonio Mastropaolo, Luca Pascarella, and Gabriele Bavota
Thesecondpre-trainingobjectiveprovidesasinputtothemodel
aJavamethodfromwhichlogstatementsoriginallypresentinit
have been removed, with the T5 in charge of guessing where a log
statementisneededbyaddingaspecial <LOG_STMT >token.This
providesthemodelwithadditionalknowledgeabout wherelogging
is needed. Once pre-trained, the model is fine-tuned to generate
completelogstatements.Inparticular,givenaJavamethodasinput
to LANCE, we ask it to inject a complete log statement where
needed. This means that LANCE must generate a complete log
statement and inject it in the proper location.
Inourevaluation,weaskedLANCEtoautomaticallygenerate
12,020 log statements and compared them to the ones manually
writtenbydevelopers.WefoundthatLANCEisableto(i)correctly
predicttheappropriatelocationofalogstatementin65.9%ofcases;
(ii) select a proper log level for the statement in 66.2% of cases; and
(iii)generateacompletelycorrectloggingstatement,includinga
meaningful natural language message in 15.2% of cases. Besides
suchaquantitativeanalysiswereportanddiscussqualitativeex-
amples of correct and wrong predictions generated by the model.
Significance ofresearch contribution. Ourworkrepresents
astepaheadintheautomatedsupportprovidedtodevelopersfor
logging activities. Indeed, LANCE is the first technique able to
generatecompleteloggingstatementsandtoinjectthemintheright
code location. LANCE is complementary to techniques suggesting
which parts of the system to log [ 45], since it assumes that the
method provided as input always needs a logging statement. Inother words, we do not tackle the problem of deciding whether
a code component (in our case, a Java method) needs a loggingstatement, but we assume that such a decision has already been
takenby anotherapproachor bythedeveloper itself.LANCEcan
then take care of injecting the needed logging statements.
We publicly release the code implementing our model and all
dataandadditionalscriptsusedinourstudyinacomprehensive
replication package [5].
2 LANCE: LOG STATEMENT RECOMMENDER
WestartbyoverviewingtheT5modelthatisatthecoreofLANCE
andbyexplaininghowweexploiteditfortheautomationoflogging
activities (Section 2.1). Then, we describe the process used to build
the datasets needed for its training, hyperparameter tuning and
evaluation(Section2.2).Section2.3detailsthetrainingofthemodel
andthehyperparametertuningweperformedtoidentifythebest
configurationtouseinourexperiments.Finally,Section2.4explains
how predictions are generated once the model has been trained.
2.1 Text-To-Text-Transfer-Transformer (T5)
Raffelet al.presented T5 [ 38] as a model that can be used to tackle
any Natural Language Processing (NLP) task that can be expressed
inatext-to-textformat.Thisbasicallymeansthatboththeinputand the output of the model are text strings. A single T5 model
canbetrainedtosupportmultipletasks,suchasmachinetransla-
tion (e.g., from English to Franch) and question answering. The T5
demonstrated state-of-the-art performance onseveral NLP bench-
marks[38].Also,ithasbeensuccessfullyusedtoautomatecode-
related tasks [33].WedonotdiscussallthearchitecturaldetailsofT5,thataredoc-
umentedin[ 38].However,itisworthmentioningthat,asthename
suggest, the T5 is a Transformer [ 42] model exploiting attention
layerstoweightthesignificanceofthedifferentpartscomposing
the input strings. This is particularly useful when dealing withcode-related tasks, since T5 can detect hidden and long-ranged
dependenciesamongtokens,withoutassumingthatnearesttokens
are more related than distant ones.
Forexample,thetokensrepresentingthedeclarationofalocal
variable in the first statement of a method are related to the tokens
implementing a return statement in which the value of such a
variable is returned (despite the fact that the two statements could
be far apart).
Inourwork,weexploitthespecificarchitecturereferredbyRaffel
etal.[38]asT5 small.Indeed,theauthorspresentdifferentversions
of the T5 (small, base, large, 3 Billion, and 11 Billion) differing in
complexity, size, and, consequently, training time. The T5 smallwe
adopted features a total of 60M parameters allowing reasonabletraining times with the hardware resources at our disposal. Thecode implementing the T5 model is available in our replication
package [5].
2.1.1 Instantiating T5 to Automate Logging Activities. TheT5model
is trained in two phases (i) pre-training, which allows defining a
shared knowledge-base useful for a large class of text-to-text tasks
(e.g.,guessing masked words in English sentences to learn about
the language); and (ii) fine-tuning, which specializes the model on
specificdownstreamtasks(e.g., machinetranslationtask).Bothpre-
trainingandfine-tuningcanbeperformedinamulti-tasksetting
(i.e.,a single model is trained on several tasks). Fig. 1 depicts the
tasksweadoptfortheT5pre-trainingandfine-tuning,whilethe
building of the needed datasets is detailed in Section 2.2.
Figure 1: Pre-training and fine-tuning tasks
2280
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:59:43 UTC from IEEE Xplore.  Restrictions apply. Using Deep Learning to Generate Complete Log Statements ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
Pre-training. Wetargetedatwo-foldgoalfortheT5pre-training:
(i)providethemodelwithknowledgeabouttheunderlyingpatterns
of the Java language; and (ii) allow the model to learn where a log
statement is needed in a given Java method, without focusing at
this stage on the log level and the message to print. Concerningthe first point, our first pre-training task (Task #P1 in Fig. 1) is a
classicdenoisingtask[ 38]inwhichwerandomlymask15%ofcode
tokens in each instance (i.e., a Java method) asking the model to
guess the masked tokens.
The second task (Task #P2 in Fig. 1), instead, asks the model
topredictthecorrect position ofalogstatementwithintheinput
method. Basically, we provide as input to the model a Java method
thatoriginallyhad nlogstatements( n≥1),withn−1logstatements
(i.e.,wecompletelyremoveonelogstatement).Then,weaskthe
model to predict where the removed log statement was and to
injectin thatpositiona special <LOG_STMT >tag.This meansthat
a method having nlog statements will appear ntimes in the pre-
training dataset, each time with a different log statement removed.
Fine-tuning. Oncethemodelispre-trained,thefine-tuningtask
(Task #FT in Fig. 1) specializes the model to the specific problem
we target, namely the injection of complete log statements. Also in
this case, the input is represented by a Java method that originally
hadnlog statements ( n≥1) from which we completely remove
onelogstatement(i.e., sameinputasTask#P2).However,asoutput,
we expect the model to inject the actual log statement in the right
position,choosingtherightloglevelandameaningfullogmessage.
2.2 Building the Training Datasets
Wedetailtheprocessusedtobuildboththepre-trainingandthefine-
tuningdataset.WeminedJavaprojectsonGitHub[ 2]byleveraging
the search tool by Dabic et al.[13]. The querying user interface [ 4]
allows to identify GitHub projects that meet specific selection cri-
teria. We selected all Java projects having at least 500 commits, 10
contributors, 10 stars, and not being forks (to reduce the chance
of mining duplicated code). The commits/contributors/stars filters
aim at discarding personal/toy projects. Instead, the decision of
onlyfocusingonJavaprojectssimplifiesthetoolchainneededfor
our study and allows to train the model on a coherent code corpus.
Thisprocessresultedin5,473candidateprojects.Wesuccessfully
clonedthelatestsnapshotof5,459ofthem(someprojectscannot
be cloned since they were deleted or made private). Then, to foster
evenmorethecohesivenessofourdataset,wedecidedtoselectonly
projects declaring a dependency towards Apache Log4j [ 1], a well-
known Java logging library. To identify these projects, we firstly
checked whether a POM(Project Object Model) file1was present in
theproject’sdirectory.Ifthiswasthecase,weparsedittocheck
whether it featured a Log4j dependency. If no POM file or no Log4j
dependency was found, the project was discarded. We found 1,465
Java projects having an explicit dependency towards Log4j.
Wethenused srcML[6]toextractfromtheseprojectsalltheir
Java methods ( ∼10M). Of these methods, ∼96% do not have log
statements. This still provides us with ∼320k methods featuring at
leastonelogstatement.Then,wefilteredoutallmethodshaving
#tokens≥512or#tokens<10,where #tokensrepresentsthenumber
of tokens composing a method (excluding comments).
1A POM file is used in Maven to declare dependencies towards Maven libraries.The filter on the maximum number of tokens is needed to limit
the computational expense of training DL-based models (similarchoices have been made in previous works [
17,40,41]). Finally,
we remove duplicate methods from the dataset to avoid overlap
betweentrainingandtestsetswebuiltfromthem.Thisleftuswith
6,909,280 methods, that we used to create the pre-training and the
fine-tuning datasets summarized in Table 1.
Table 1: Num. of methods in the datasets used in our study
Datasettrain eval test
w/ log w/a log w/ log w/ log
pre-training dataset
Task#P1 - 6,755,884 - -
Task#P2 76,975 - - -
fine-tuning dataset 61,597 - 7,699 7,125
We used all the methods not having log statement (w/a log in
Table1)tobuildthedatasetneededforthepre-trainingTask#P1
(i.e.,thedenoisingtaskinwhichwerandomlymask15%oftokens).
For the pre-training Task #P2 (i.e., guessing the correct position of
alogstatement),weused50%ofmethodswithlogstatements:A
method featuring nlog statements is present ntimes in the dataset,
each time with a different log statement removed.
Theremaining50%ofmethodsfeaturingalogstatementhave
beenusedinsteadforbuildingthefine-tuningdataset.Thelatter
has been split into 80% training, 10% evaluation, and 10% test. The
evaluation has been used to perform the hyperparameter tuning of
the model (Section 2.3), while the test set represents the instances
onwhichtheperformanceofLANCEhavebeenassessed(i.e., its
ability to generate correct log statements in the right location).
2.3 Model Training and Hyperparameter
Tuning
The pre-training has been performed for 300k steps. We used a 2x2
TPUtopology(8cores)fromGoogleColabtopre-trainthemodel
with a batch size of 128. As a learning rate, we use the Inverse
SquareRoot withthecanonicalconfiguration[ 38].Wealsousedthe
pre-training dataset and 3,244,116 English sentences coming from
theC4dataset[38]totraina SentencePiece model(i.e., atokenizer
for neural text processing). We decided to train the tokenizer onboth Java code and English natural language to make sure it can
deal with complex log messages. We set its size to 32k word pieces.
Once pre-trained, the model can be fine-tuned. However, be-
fore that, we performed the same hyperparameters tuning used by
Mastropaolo et al.[33] when employing the T5 for code-related
tasks: We do not tune the hyperparameters of the T5 model for
thepre-training(usingthedefaultones),butweexperimentwith
four different learning rates, namely constant learning rate (C-LR),
slanted triangular learning rate (ST-LR), inverse square learningrate (ISQ-LR), and polynomial learning rate (PD-LR). Our repli-cation package [
5] reports the exact setting used for each of the
experimented learning rates (e.g., the constant learning rate was
set to 0.001, etc.).
Before detailing the hyperparameter tuning, we must anticipate
that in our study (Section 3) we assess the performance of LANCE
in four different pre-training scenarios.
2281
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:59:43 UTC from IEEE Xplore.  Restrictions apply. ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Antonio Mastropaolo, Luca Pascarella, and Gabriele Bavota
First, to verify the impact on performance of the pre-training
phase, we perform an ablation study in which the model is not pre-
trained,butdirectlyfine-tuned(Nopre-trained scenario).Second,
wepre-trainamodelbyemployingamulti-taskpre-trainingsetting
inwhichbothourpre-trainingtasks(i.e., Task#P1and#P2inFig.1)
areused(Multi-task ).Finally,weassesstheperformanceofT5when
pre-trained by only using Task #P1 (Denoising-task ) or Task #P2
(LogStmt-task ).
Once pre-trained, all models are fine-tuned and compared. This
allowstoassessthecontributiontoperformance(ifany)brought
by the different pre-training strategies.
Having four different training scenarios and four possible learn-
ing rates, the hyperparameter tuningrequired building 16 models.
Wefine-tunedeachmodel(i.e., eachconfiguration)for100ksteps.
Then, we compute the percentage of correct predictions (i.e., cases
inwhichthemodelcaninjectacorrectlogstatementintheright
position)achievedintheevaluationset.Theachievedresultsare
reported in Table 2. The best configuration of each scenario (in
boldface)istheonethathasbeenusedinourstudytoassessthe
LANCE’s performance after fine-tuning the models for 200k steps.
Table 2: T5 hyperparameter tuning results
Experiment C-LR ST-LR ISQ-LR PD-LR
Multi-Task 11.84% 11.88% 12.30% 12.18%
LogStmt-Task 11.76% 11.74% 12.36% 11.70%
Denoising-Task 15.01% 13.62% 14.80% 15.12%
No Pre-training 12.64% 13.25% 13.12% 12.65%
2.4 Generating Predictions
Once the T5 model is trained, it can generate predictions using
differentdecodingstrategies.Forthisfirstworkonlogstatement
generation, we decided to target the greedy decoding strategy: Pre-
dictionsaregeneratedbyselectingthetokenwiththehighestprob-
ability of appearing in a specific position at each time step. This
meansthatforagiveninput,asinglepredictionisgenerated(i.e.,
the one considered the most likely by the model).
3 STUDY DESIGN
Thegoalof this study is to evaluate the performance of LANCE
inautomaticallygeneratingandinjectingcompleteloggingstate-
ments in Javamethods. The contextis represented bythe datasets
described in Section 2.
We aim at answering the following research questions (RQs):
RQ1:To what extent is LANCE able to correctly inject completelogging statements in Java methods? With RQ
1we aim at
assessingtheperformanceofthetrainedT5modelsingener-atingandinjectinginthecorrectpositionloggingstatements
in unseen Java methods. Besides quantitatively answer this
RQbyreportingthepercentageofcorrectpredictionsgener-
ated by LANCE, we manually inspected the generated log
statements to discuss interesting cases of correct and wrong
predictions.RQ2:How do different pre-training strategies impact the perfor-
mance of LANCE? RQ2analyzes the impact of different pre-
training strategies on LANCE’s performance. In particu-lar, we experiment with the four T5 variants described inSection2.3: NoPre-training, Multi-Task, LogStmt-Task,and
Denoising-Task.
3.1 Data Collection and Analysis
ToanswerRQ 1andRQ2werunagainstthetestset(Table1)thebest-
performingconfiguration(Section2.3)ofthefourmodelsoutput
of the different pre-trainings.
Then, we assess the accuracy of the predictions generated by
eachmodel.Inthisregard,werelyonthecode(i.e., logstatements)
manuallywrittenbydevelopersasagroundtruth.Thisisacommon
practice [ 17,30,40,41] concerning the definition of the oracle (i.e.,
the output the model is expected to generate). Hence, first, wecompute the percentage of correct predictions, namely cases in
whichLANCEcorrectlysynthesizesthelogstatement(i.e., boththe
loglevelandthelogmessagewerecorrect)whileinjectingitinthe
correctpositioninthemethod(i.e., thesamepositionadoptedby
developers). Successively, we assessed the extent to which LANCE
generates “partially correct” predictions. In particular, there arethree important “components” that the T5 model has to predict
when it comes to the addition of a log statement: its level, message,
and position (location in the method). We compute the percentage
ofcasesinwhichLANCEwasabletocorrectlypredict(i)atleast
oneofthesethree“components”(e.g., thelogleveliscorrect,butthe
messageaswellasthepositionaredifferentfromthereference);and
(ii)atleasttwoofthe“components”(e.g., theloglevelandmessage
arecorrect,butthestatementisinjectedinthewrongposition).Thethirdscenario(i.e., allthree“components”arecorrect)isrepresented
by the previously discussed correct predictions. The number of
instancesinthetestsetis12,020,whereeachinstancerepresents
oneofthe7,125JavamethodsinTable1withaspecificlogstatement
removed (one method can have multiple log statements).
Manual analysis. On top of this quantitative analysis, we also
performed qualitativeanalyses aimedat better understandingthe
strengths and weaknesses of LANCE. Besides reporting interesting
casesofperfectpredictionsgeneratedbyourapproach,wemanually
inspected a set of “wrong predictions” generated by the model.In particular, we focused on wrong predictions in which the log
level and the location were correct. This means that the difference
betweenthegeneratedandthetargetlogstatementwasthenatural
languagemessage.Suchadecisionwasdrivenbythegoalofour
manualanalysis,aimedatunderstandingwhetherthegeneratedlog,
while different, represented a good alternative to the reference one.
This is unlikely to happen if the log level or location is different
from the target or, at least, it is tough to judge for people not
directlyinvolvedinthedevelopmentofthecodeinwhichthelog
statement is injected (such as the authors who inspected these
wrongpredictions).Forthesereasons,werandomlyselected300wrong predictions in which, however, the log level and the log
locationwerecorrectlyguessedbythemodel.Then,twoauthors
manually inspected the original method with the log statement
writtenbythedevelopersandthesamemethodwiththestatement
generatedbyLANCEtoclassifyitinoneofthefollowingcategories:
2282
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:59:43 UTC from IEEE Xplore.  Restrictions apply. Using Deep Learning to Generate Complete Log Statements ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
(1)Same information : The generated log statement is seman-
tically equivalent to the target one. This could happen in
the case in which the log messages of the two statementsexpress the same information but with different wordings
(e.g.,“exception thrown when invoking method getPaper() ”vs
“getPaper()thrownanexception ”).Itevenhappens,aswewill
show, that LANCE proposes a more expressive log message
as compared to the one used by developers.
(2)Meaningful : The generated log statement includes an articu-
latedmessagethatcanbeunderstood,butitisnotequivalent
to the one present in the target log statement.
(3)Meaningless :Thegeneratedlogstatementincludesamessage
that is meaningless considering the context (i.e., the method
in which it has been injected) and/or the logging message
cannot be comprehended.
Thetwoauthorsanalyzedeachofthe300statementsindepen-
dently from each other, agreeing on the classification of 189 (63%)
logstatements.Theremaining111( ∼37%),representingconflicts,
have been solved by a third author not involved in the first stage.
The 300 instances to manually validate have been selected from
the predictions generated by the best-performing model. Such a
qualitative analysis is fundamental in our study since the quantita-
tivemetricsweadoptconsideraswrongpredictionsalsocasesin
whichthepredictedandthereferencelogstatementsareverysimi-
larorequivalent(e.g., theydifferforonewordinthelogmessage).
4 RESULTS DISCUSSION
Tosimplifythediscussionoftheresults,weanswerourresearch
questions together through a quantitative and qualitative analysis.
4.1 Quantitative Analysis
Table 3 reports the results achieved by the four experimented
modelsoutputofdifferentpre-trainingstrategies(i.e.,Multi-Task,
LogStmt-Task, Denoising-Task, and No pre-training ) in terms of cor-
rectpredictions.Table3showsthecorrectpredictionsforallcombi-nationsofthethree“components”topredict(i.e., loglevel,position
where to inject it, and log message). In other words, we analyze
casesinwhich(i)atleastoneofthethreecomponentstopredict
wascorrect(e.g., atleastthelevel),(ii)atleasttwowerecorrect(e.g.,
level andlocation), and (iii) theentire log statementwas correctly
synthesized (level, position, and message).
Table 3 can be read as follows. Each row includes three symbols
below the three components to predict. The check mark ( ) below
a component cindicates that the results reported in that row refer
tologstatementsinwhich cwascorrectlypredicted.Thedashmark
(—), instead, indicates that ccan be either correct or wrong for the
predictions in that row. Finally, the cross mark ( ) indicates that
thecomponentwaswronglypredictedforthecorrespondinglog
statements. For example, the very first line:
Level =∧Position =—∧Messaдe =—
indicates that the row reports the percentage of predictions in
which the log level was correctly predicted, independently from
the prediction of the position and message, which could be correct
or wrong. Instead, the third row:
Level =∧Position =∧Messaдe =reports cases in which the level was correctly predicted, but the
guessed position and the generated message were wrong. The row
labeledwith“All ”representsthemostchallengingscenariosince
it implies that the generated log statement was identical to the
referenceoneinallitsparts.Finally,thelastblackrowshowsthe
percentage and the absolute value of the instances in the test set
that cannot be parsed with a JavaParser [3] due to syntax errors.
Concerning RQ 2, the best-performing model is the one pre-
trainedbyusingonlythedenoisingtask(i.e., 15%ofmaskedtokens).
Indeed,itsperformanceissubstantiallysuperiortoT5pre-trained
in a multi-task setting. For example, in terms of completely correct
predictions,thismodelachievesa15.20%of“perfect”logstatements
versus the 12.32% of the multi-task model. Also, the Denoising-task
model is the one generating the lowest number of syntactically
wrong log statements (2.33%). While such a result might seem
surprising initially, a possible explanation could be the specific
pre-trainingandfine-tuningweperformed:Ourfine-tuningtask,
requiringthemodeltogenerateandinjectacompletelogstatement
in a Java method, is quite similar to the LogStmt-Task pre-training
task.Indeed,thelatterasksthemodeltoinjecta <LOG>placeholder
inthepositioninwhichalogstatementhasbeenremovedinaJavamethod.Thus,itispossiblethatsuchanadditionalpre-trainingdid
not benefit the model’s performance.
More in general, concerning the role played by the pre-training,
we observed a substantial boost of performance only in the case of
theDenoising-task (+2.51%ofperfectlypredictedlogstatements).
The other two pre-trainings only marginally improved the perfor-
manceofthebasemodel(seeTable3).Inthefollowing,wefocus
on the best-performing model.
LANCE correctly predicts the log level in 66.24% of cases, while
thepositioninwhichalogstatementshouldbeinjectediscorrectlyguessedin65.40%ofcases.Thistwo-foldachievement(i.e., loglevel
andposition)suggeststhatLANCEcaneffectivelysupportdevelop-ers with logging activities. Looking at the third row in Table 3, it is
insteadclearthatLANCEstrugglestogenerateloggingmessages
that are identical to the ones manually written by developers (suc-
cess in 16.90% of cases). This difference in performance among the
three log statement “components” to predict is kind of expected.
Indeed,loglevelandthepositionhaveaquitesmallsearchspace:
the log level can assume one out of six possible values in Log4j
(Trace,Debug,Info,Warn,Error, and Fatal), while the position in
which a log statement can be injected is bounded to the number
oftokenscomposingthemethods,beingatmost512.Instead,the
natural language log message can be written in many different
forms, reducing the chances of obtaining two identical sentences.
In 35% of cases, both the level and the position are correctly
guessed with, however, a wrong logging message, while in an addi-tional15.20%allthree“components”arecorrectlysynthesized.The
generation of the logging message basically acts as a sort of upper
bound for the performance of LANCE, with 16.90% of generated
logs having a correct message and an overall 15.20% of completely
correctlogstatements(i.e., level,position,andmessagearecorrect).
While LANCE performs quite well in predicting the log level
andposition,thereisstillalargepercentageoflogstatementsfor
which their prediction fails. However, the “magnitude” of the error
made in the prediction can substantially vary for both these tasks.
2283
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:59:43 UTC from IEEE Xplore.  Restrictions apply. ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Antonio Mastropaolo, Luca Pascarella, and Gabriele Bavota
Table 3: Correct predictions considering the three-dimensional challenges of injecting log statements.
Log Predictions
Level Position MessagePre-trainingNo Pre-trainingMulti-Task LogStmt-Task Denoising-Task1 out of 3 —— 60.37% 62.22% 66.24% 61.39%
—  — 60.20% 60.70% 65.40% 60.36%
——  13.74% 13.85% 16.90% 14.37%
  15.50% 16.27% 15.14% 16.09%
  15.06% 14.45% 13.94% 14.71%
  0.06% 0.10% 0.07% 0.05%2 out of 3  31.74% 32.79% 35.00% 31.73%
  0.29% 0.29% 0.35% 0.39%
  0.56% 0.60% 0.71% 0.75%All  12.32% 12.33% 15.20% 12.69%
5.77% 4.15% 2.33% 3.35%Wrong Syntax(694/12,020) (499/12,020) (281/12,020) (403/12,020)
Figure 2: Log level distance in the predictions generated by
LANCE. Zero indicates predictions having a correct level.
Concerning the log level, the six levels defined in Log4j can
be sorted based on their priority: (1) Trace, (2) Debug, (3) Info, (4)
Warn, (5) Error, and (6) Fatal. For example, the Infolevel is used for
logginginformationalmessagesandtrackingthebehaviorofthe
running software (e.g., methodmstarts the execution). In contrast,
the last level, Fatal, is designated for logging severe errors, or in
other words, for logging the behavior likely to compromise the
execution of the software (e.g., by causing a crash).
AwronglevelpredictionmadebyLANCEcouldrecommendthe
usageofInfoinsteadof Fatalaswellastheusageof Errorinstead
ofFatal. However, these two errors have a different magnitude,
with the first completely misleading the developer while the latter
resultinginasub-optimal(butstillacceptable)logleveldecision.
Fig. 2 depicts a histogram showing the number of instances in our
testsetforwhichtheloglevelpredictionhadadistancefromthe
target level going from 0 (i.e., the level was correctly predicted)Figure3:Distanceintermsof#Tokensbetweenthepositionofthelogstatementinthepredictionandinthetarget.Zeroindicates predictions injected in the right position.
to5(i.e.,theworst-casescenarioindicatinga Tracerecommended
instead of Fatalorvice versa ). While we report the results achieved
byallmodels,alsointhiscase,wefocusourdiscussiononthebest-
performing one (Denoising-task ). Note that not all 12,020 instances
from our test set are depicted in Fig. 2. Indeed, besides the ones
containing syntax errors (281 for the Denoising-task ), we also had
to exclude 557 instances for which the model did not recommend a
valid log level, making impossible the computation of the distance.
Asitcanbeseen,besidestheinstanceswithacorrectlypredicted
level(7,962),mostoftheerrorsarejustonelevelfarfromthetarget
(1,842–16.5%–instances), while very rarely the difference is higher
than two (483–4.3%–instances).
Fig. 3 depicts the same analysis performed, however, for the
prediction of the location where to inject the log statement. In this
case,thex-axisreportsthedistance(incodetokens)ofthepredicted
location from the target location.
2284
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:59:43 UTC from IEEE Xplore.  Restrictions apply. Using Deep Learning to Generate Complete Log Statements ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
The reported numbers must be interpreted as “up to ntokens
far” (e.g., up to 50, up to 100, etc.). As it can be seen, the wrong
locationsaremostlyinareasclosetothetargetlocation:Besides
the 7,890 correctly predicted, an additional 1,864 ( ∼17%) fall within
50 code tokens, while only 723 ( ∼6%) are more than 100 tokens far.
Finally, we investigated whether the performance of LANCE is
affected by the level of the log statement. Indeed, it is possible that
specific types of log statements are easier to predict than others.
Table4reportsforeachloglevelandforeachoftheexperimented
modelvariants:(i)thepercentageofpredictionsinwhichthelog
level was correctly predicted independently from the prediction of
the location and message (column “All”); and (ii) the percentage of
completely correct predictions (column “Corr. Pred.”).
AfirstobservationthatcanbemadefromTable4isthatLANCE
provides good and similar performance across all log levels. The
highest percentage of correct predictions is for the Errorlevel,
while the lowest is for the Warnlevel. Indeed, focusing on the
best-performing model, for 76.10% of Errorinstances in the test set
thelogleveliscorrectlyinferred,againstthe60.20%ofthe Warn
instances. Similarly, the percentage of completely correct predic-tions, moves from 23.40% (Error ) to 9.59% (Warn ). This finding is
consistent across all models and we believe it is due to the simpler
messagesusuallyadoptedinstatementsloggingerrors.Toverify
such a conjecture, we computed the number of characters com-posing log statements having different levels. We found that, on
average,Errorinstancesarecomposedby ∼70characters,against
the∼215 ofWarninstances. However, these numbers only tell part
ofthe story.Indeed,we foundthatthe Infolevel,which isthesec-
ond worst in terms of performance, features statements composed,
onaverage,by ∼79characters.Thus,despitebeingsimilarinsize
compared to the Errorinstances, we still observed a drop of perfor-
mance.WebelievethatthisresultisduetothefactthatmessagesinInfologstatementsaremuchmorevariegatedascomparedtoerror
messages.Finally,itisworthhighlightingthegoodperformance
achievedatthe Debuglevel,whichpointstothepossibleusageof
techniques such as LANCE in supporting bug localization activi-ties by recommending the injection of proper debug statements.
Clearly,additionalperformanceimprovementsareneededbefore
considering LANCE ready to be adopted by developers.
The analysis of the “wrong” predictions is difficult to perform
quantitativelyforlogmessagesasdoneforthelevelandtheposi-
tion. One possibility is to compute the BLEU (Bilingual Evaluation
Understudy) score [ 37] between the generated and the reference
messages. BLEU is used to assess the quality of an automatically
generatedtext.Suchascorerangesbetween0.0and1.0,with1.0in-dicatingthatthegeneratedandthereferencemessageareidentical.
WeadopttheBLEU-4variant,whichcomputestheoverlapinterms
of 4-grams between the generated and the reference messages.
Concerningthebest-performingmodel(similarfindingsholdfor
the other models), we obtained an average BLEU-4 of 0.15.
However, such a number is difficult to interpret since there is
no accepted threshold above which an automatically generated
textisconsideredofgoodquality.Forthisreason,werelyonthe
qualitative analysis introduced in Section 3.1 and discussed in the
following.4.2 Qualitative Analysis
Amongthe300“wrong”predictionsanalyzed,wefound85ofthem
(28.33%) to report the same information of the target predictions
(i.e.,the log message was different but semantically equivalent);
209(69.66%)toincludea meaningful butnotequivalentmessage;
and 6 (2%) to include meaningless messages. Thus, in the set of
predictionsweconsidered“wrong”inourquantitativeanalysisduetothedifferentlogmessagegeneratedascomparedtothereference
one, we can estimate a ∼28% of predictions that are still valuable.
To better understand the capability of LANCE in generating
log statements, we report in Fig. 4 three examples of (i) correctpredictions (top part of the figure), in which the generated log
statementisequivalenttotheonewrittenbydevelopersinallits
parts;and(ii)“wrongpredictions”classifiedinourmanualanalysis
as reporting the same information of the target prediction. Wesummarized the methods in order to only show statements thatare relevant to understand the injected log statement (irrelevant
statements are replaced by [...]).
Concerning the correct predictions, we just show the method
with the generated log statement that, as said, is identical to the
one written by the developers. In the first example 1, LANCE
injected a statement to log the state of the msgobject. What it
is interesting about this instance is that the model understood
theneedforinvokingthemethod ArrayConverter.bytesToHex-
Stringin order to obtain a human comprehensible representation
of the logged state.
In the second instance 2, LANCE inferred that if the ifcon-
dition is not satisfied (i.e., value instanceof NSDictionary ), this
indicates an unexpected value type for the passed parameter ( key).
In other words, the model mapped the instanceof operator to
possible issues related to object types.
The last correct prediction in Fig. 4 3shows instead the ability
ofLANCEtocomposelogmessagesbyusingtheappropriatesyntax
needed to concatenate several parameters to string elements. Inthis case, the log statement is just aimed at reporting when the
execution of a specific method starts.
Moving to the “wrong” but semantically equivalent predictions
(bottom part of Fig. 4), instance 4shows an interesting case in
whichthelogmessagesynthesizedbyLANCE(i.e., “Exceptiontrying
todeletesubscription’sconfigurationforsubscriptionID{} ”)iseven
moredetailedthantheonewrittenbydevelopers(i.e., “Couldnot
deletesubscriptionfor{} ).In5,instead,theoppositeoccurs(i.e., the
manuallywrittenmessageismoredetailed)withthetwomessages,
however, communicating similar information.
Finally,thelastexample 6showstwomessagesonlydiffering
foroneword(activated vs active ).Thisexampleisrepresentativeof
manyinstanceswefoundinwhichdifferenceswereevensmaller.
Forexample,weobservedcasesinwhichtheonlydifferencewas
the usage of letter case. Indeed, in our quantitative analysis we
decidedtobeconservative,consideringapredictionascorrectonlyifitmatchedthereferenceoneevenintermsoflettercase.Thiswas
donetoavoidconsideringascorrectpredictionsmakingawrong
usage of camelCase.
2285
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:59:43 UTC from IEEE Xplore.  Restrictions apply. ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Antonio Mastropaolo, Luca Pascarella, and Gabriele Bavota
Examples of correct predictions
public void  writeSignatureHandshakeAlgorithm (CertificateRequestMessage msg){ 
           appendBytes(msg.getSignatureHashAlgorithm().getValues());
           LOGGER.debug(“SignatureHashAlgorithm: “  + 
                  ArrayConverter.bytesToHexString(msg.getSignatureHashAlgorithm().getValue()));   }
public NSDictionary objectForKey(final String key) {
    final NSObject value = dict.objectForKey(key);
    [...]
    if (value instanceof  NSDictionary) { 
        return (NSDictionary) value; 
    }    log.warn(String.format( "Unexpected value type for serialized key %s" , key));
    return null;}
public ConnectionConsumer createConnectionConsumer( final Destination destination, 
                              final ServerSessionPool pool, final int maxMessages) throws JMSException  {
        if (ActiveMQRALogger.LOGGER.isTraceEnabled()) {
            ActiveMQRALogger.LOGGER.trace(
                     "createConnectionConsumer("  + destination + ", " + pool + ", " + maxMessages + ")");
        }        throw new IllegalStateException(ISE);}1
2
3
Examples “wrong” but semantically equivalent predictions (i.e., same information)
4private synchronized  CswSubscription deleteCswSubscription  (String subscriptionId) throws CswException  {
                [...]        try {            ServiceRegistration  sr = registeredSubscriptions.remove(subscriptionId);
            [...]
        } catch (Exception  e) {
            
            LOGGER.debug("Exception trying to delete subscription's configuration for subscription ID {}" , 
                          logSanitizedId, e);
            LOGGER.debug(“Could not delete subscription for {}", logSanitizedId, e);
        }
}LANCE log statement
TARGET log statement
public HandlerResult handle(ProcessState state, ProcessInstance process) {
        Secret secret = (Secret) state.getResource();        String secretValue = secret.getValue();        if (StringUtils.isNotBlank(secretValue)) {            try {
                secretsService.delete(secret.getAccountId(), secret.getValue());            } catch (IOException e) {
                                log.error("Error deleting secret {}: {}" , secret.getId(), e.getMessage());
                
                log.error("Failed to delete secret from storage [{}]", secret.getId(), e);
               
                           [...]
            }        }        return null;}LANCE log statement
TARGET log statement
public static void sendApplicationInstanceActivatedEvent (String appId, String instanceId) {
        if (log.isInfoEnabled()) {                         log.info( "Publishing application instance activated event: [application] "  + 
                      appId + " [instance] " + instanceId);
             log.info("Publishing application instance active event: [application]" + 
                      appId + "[instance]" + instanceId) ;
        }
        [...]}LANCE log statement
TARGET log statement5
6
Figure 4: Examples of log statements generated by LANCE
2286
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:59:43 UTC from IEEE Xplore.  Restrictions apply. Using Deep Learning to Generate Complete Log Statements ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
Table 4: Percentage of correct predictions by log statement level. Column “All” reports the percentage of predictions having
thecorrectloglevel(independentlyfromthecorrect/wrongpredictionoflocationandmessage);column“Corr.Pred.”reports
the percentage of completely correct predictions.
LevelT5 Multi-Task T5 LogStmt-Task T5 Denoising-Task T5 No Pre-training
All Corr. Pred. All Corr. Pred. All Corr. Pred. All Corr. Pred.
Trace 54.77% 7.34% 58.15% 7.48% 61.67% 11.16% 56.24% 7.93%
Debug 61.09% 13.21% 63.26% 13.34% 67.41% 16.19% 63.92% 13.98%
Info 56.53% 8.00% 57.66% 7.80% 60.76% 10.93% 56.56% 8.02%
Warn 54.90% 7.22% 56.94% 7.42% 60.20% 9.59% 55.02% 7.10%
Error 68.73% 20.71% 69.69% 20.56% 76.10% 23.40% 68.50% 21.05%
Fatal 61.36% 6.81% 65.90% 13.63% 59.09% 13.63% 68.18% 13.63%
5 THREATS TO VALIDITY
We discuss the threats to the validity of our study.
5.1 Construct validity
In our study we use the original code written by developers (inour case, log statements) as oracle, assuming that it represents a
goodtargetforourmodel.Thisassumptionhasbeenmadeinmany
previousworksapplyingmachinelearningoncode[ 7,17,20–22].
However, it is likely that both the training and the evaluation/test
datasets contain suboptimal log statements. In terms of training,
we expect the DL model to be able to deal with such a noise, not
learning unusual logging practices.
However, when it comes to the evaluation and test set, this
assumptioncanhaveastronginfluence,sinceweconsiderapre-diction correct only if it is equal to the log statement written bydevelopers. To at least partially address this threat we manually
analyzed a sample of wrong predictions, reporting the percentage
of them still being valuable while different from the reference.
5.2 Internal validity
We used the default T5 parameters from the original paper [ 38]
duringitspre-trainingandlimitedthehyperparametertuningto
thefine-tuning phaseand, inparticular, tothe learningrates (e.g.,
we did not variate the model architecture in terms of number of
layers).Thiswasdoneduetothehighcostoftrainingseveraldif-
ferentmodels.Weacknowledgethatexperimentingwithadditionalconfigurations maylead to better results. On topof this, itis worthmentioningthatweemployedthesimplestT5architecture(i.e., the
smallone)proposedbyRaffel etal.[38].Largermodelsarelikely
to push forward the results we achieved.
5.3 External validity
Whilethedatasetsusedinourstudyfeaturesthousandsofinstances,
welimited our experimentsto Javacode and,more specifically,to
projects relying on the Log4j library. Thus, our results are valid for
thisspecificcodepopulationandwedonotclaimgeneralizability
for other languages and logging frameworks.
However, excluding the building of the datasets that focused
on a specific context, there are no parts of our approach that are
customized for Java and/or for the Log4j library. Thus, LANCE can
be easily adapted and experimented in other contexts.6 RELATED WORK
Wefocusourdiscussionon(i)empiricalstudiesonloggingpractices,
and(ii)approachesproposedintheliteraturetosupportdevelopers
in logging activities. Due to lack of space, we do not discuss themany recent applications of deep learning to automate various
softwareengineeringtasks,pointingthereadertothesystematic
literature review by Watson et al.[43].
6.1 Empirical Studies on Logging Practices
Yuanetal.[46]conductedoneofthefirstempiricalstudyonlogging
practices in open-source systems, analyzing C and C++ projects.
Theyshowthatdevelopersmakemassiveusageoflogstatements
andcontinuouslyevolvethemwiththegoalofimprovingdebug-
ging and maintenance activities.
Fuet al.[15] studied the logging practices in two industrial
projects at Microsoft, investigating in particular which code blocks
aretypicallylogged.Theyalsoproposeatooltopredicttheneed
for a new log statement, reporting a 90% F-Score.
Chen [10] and Zeng et al.[48] extended the study of Yuan et al.
[46] to Java and Android systems, respectively. In particular, Chen
analyzed 21 Java-based open-source projects while Zeng et al.con-
sidered 1,444 open-source Android apps mined from F-Droid. Both
studies confirmed the results of Yuan et al.[46], finding a massive
presence of log statements in the analyzed systems.
Zhiet al.[50] investigated how logging configurations are used
andevolve,distilling10findingsaboutpracticesadoptedinlogging
management, storage, formatting, and configuration quality. Other
researchers studied the evolution and stability of log statements.
For example, Kabinna et al.[24] examined how developers of four
open source applications evolve log statements. They found thatnearly20-45%oflogstatementschangethroughoutthesoftware
lifetime.
Zhouet al.[51] explored the impact of logging practices on data
leakage in mobile apps. In addition, they propose MobiLogLeak to
automatically identify log statements in deployed apps that leak
sensitive data. Their study show that 4% of the analyzed apps leak
sensitive data.
Recently,Li etal.[26]conductedanextensiveinvestigationon
logging practice from a developer’s perspective. The goal of this
researchistopushthedesignofautomatedtoolsbasedonactual
developers’ needs (rather than on researchers’ intuition).
2287
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:59:43 UTC from IEEE Xplore.  Restrictions apply. ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Antonio Mastropaolo, Luca Pascarella, and Gabriele Bavota
Theauthorssurveyed66developersandanalyzed223logging-
related issue reports shedding light on the trade-off between costs
and benefits of logging practices in open source. The results show
thatdevelopersadoptan adhocstrategytocompensatecostsand
benefits while inserting logging statements for various activities
(e.g.,debugging).
The above-described papers lay the empirical foundations for
techniquessupportingdevelopersinloggingactivities(including
ourwork).ApproachessuchasLANCEcanhelpinreducingthecost
of logging while supporting developers in taking proper decisions
when they wish to add log statements.
6.2 Approaches on Logging Activities
Researchersproposedtechniquesandtoolstosupportdevelopers
in logging activities.
Logmessageenhancement. Yuanet al.[47] proposed LogEn-
hancer as a prototype to automatically recommend relevant vari-
ablevaluesforeachlogstatement,refactoringitsmessagetoinclude
suchvalues.Theirevaluationoneightsystemsdemonstratesthat
LogEnhancer can dramatically reduce the set of potential root
failure causes when inspecting log messages. Liu et al.[31] tackled
the same problem using, however, a customized deep learning net-
work. Their evaluation showed that the mean average precision of
their approach is over 84%.
Log placement. Other researchers targeted the suggestion of
the best code location for log statements [23, 25, 28]. For example,
Zhuet al.[53] presented LogAdvisor, an approach to recommend
wheretoaddlogstatements.Theevaluationof LogAdvisorontwo
Microsoft systems and two open-source projects reported an accu-
racyof60%whenappliedonpiecesofcodewithoutlogstatements.
Yaoetal.[44]tackledthesameprobleminthespecificcontextof
monitoring the CPU usage of web-based systems, showing that
their approach helps developers when logging.
Lietal.[29]proposedadeeplearningframeworktorecommend
logginglocationsatthecodeblocklevel.Theyreporta80%accuracy
in suggesting logging locations using within-project training, with
slightly worst results (67%) in a cross-project setting. Cândido et al.
[8] investigated the effectiveness of log placement techniques in
an industrial context. Their findings (e.g., 79% of accuracy) show
that models trained on open source code can be effectively used in
industry.
Log level recommendation. A third family of techniques fo-
cusonrecommendingtheproperloglevel( e.g.,error,warning,info)
for a given log statement [ 36,46]. Mizouchi et al.[35] proposed
PADLAasanextensionforApacheLog4jframeworktoautomati-
cally change the log level for better record of runtime information
in case of anomalies. The DeepLV approach proposed by Li et al.
[30] uses instead a deep learning model to recommend the level
of existing log statements in methods. DeepLV aggregates syntac-
tic and semantic information of the source code and showed its
superiority with respect to the state-of-the-art.
LANCE, as compared to the above discussed techniques, is able
torecommendcomplete logstatementsandwhereto inject them,
providing a more comprehensive support to software developers.7 CONCLUSION AND FUTURE WORK
We presented LANCE, the first approach able to synthesize com-
plete log statements and inject them in the right code location.
LANCE is built on top of the Text-To-Text-Transfer-Transformer
(T5)model[ 38].Webuiltadatasetcomposedof ∼7MJavamethods
thathavebeenusedfortrainingT5andtestingitsperformance.We
experimentedwithdifferentpre-trainingstrategies,showingthat
a simple denoising task (i.e., the model is asked to guess masked
tokens in Java methods) allows T5 to achieve good performance.
Inparticular,thebest-performingmodelcangeneratecompletely
correct log statements and inject them in the proper code location
in15.20%ofcases,withbetterperformanceachievedinthesimpler
tasks of selecting a proper log level (66.24%) and code location
(65.94%).
We also showed, through manual inspection of a sample of
“wrong”predictions,thattheresultsofourquantitativeanalysisare
a lower bound for LANCE’s performance. Indeed, a non-negligible
set (∼28%) of log statements classified as “wrong” due to differ-
encesbetween thegenerated andthetarget logmessage, actually
represents valuable recommendations.
Despitetheencouragingresults,weacknowledgethatLANCE
is just a first attempt in automatically generating complete log
statementsandadditionalimprovementsareneededbeforeitcan
beconsideredasavalidsupportfordevelopers.Thisobservation
guides our future research agenda, that will focus on:
•ImprovingLANCE’sperformance.Thiscouldbeachievedin
differentways.First,wewanttoexperimentwithmorecom-
plex and multi-modal source code representations that have
beenshowntoboosttheperformanceofDLtechniquesin
code-relatedtasks[ 9].Second,weplantoconsideradditional
pre-trainingobjectivesandtostudytheroleplayedbythe
sizeofthetrainingdatasetonLANCE’sperformance.Indeed,
itispossiblethatlargerdatasetssubstantiallyimproveper-
formance or that, instead, our dataset was already sufficient
for the learning, with its extension only leading to marginal
improvements. Finally, we want to enlarge our search space
intermsofhyperparameterstooptimizetheT5performance.
•Closing the circle by providing full logging support . While
LANCE can generate complete log statements, it cannot de-
cide whether a log statement is needed or not in a given
method. This limitation can be addressed in two ways. First,
by delegating such a decision to other techniques only in
chargeofdecidingwhich partsofasystemto log[ 45].Sec-
ond,bytrainingLANCEtoalsosupportsuchatask.Thiscan
be done by including in the fine-tuning dataset a mixture of
methods featuring and not featuring log statements, asking
themodeltodecidewhenalogstatementisneeded.Forthis
firstwork,wedecidedtonottacklesuchaproblemdueto
themanydifferentaspectsweneededtoexploreonlyforthe
problem of log statement generation.
2288
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:59:43 UTC from IEEE Xplore.  Restrictions apply. Using Deep Learning to Generate Complete Log Statements ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
8 DATA AVAILABILITY
All the code and data used in our study is publicly available in our
replicationpackage[ 5].Inparticular,weprovide:(i)thecodeneeded
topre-train,fine-tune,andruntheT5modeltogeneratepredictions;
(ii) the datasets we built for the model training, evaluation, and
testing; (iii) all predictions generated by the different variants of
the experimented model; and (iv) additional information needed to
replicateourstudy(e.g., theexactvaluesusedforthelearningrates
during hyperparameter tuning).
ACKNOWLEDGMENT
This project has received funding from the European Research
Council (ERC) under the European Union’s Horizon 2020 research
and innovation programme (grant agreement No. 851720).
REFERENCES
[1] [n.d.]. Apache Log4j. https://logging.apache.org/log4j/2.x/.
[2] [n.d.]. GitHub Website. https://www.github.com/.
[3] [n.d.]. Javaparser. https://javaparser.org.
[4] [n.d.]. MSR mining platform. https://seart-ghs.si.usi.ch.[5] [n.d.]. Replication Package. https://github.com/antonio-mastropaolo/LANCE.[6] [n.d.]. ScrML Website. https://www.srcml.org/.[7]
Miltiadis Allamanis, Hao Peng, and Charles A. Sutton. 2016. A Convolu-tional Attention Network for Extreme Summarization of Source Code. CoRR
abs/1602.03001(2016).
[8]Jeanderson Cândido, Jan Haesen, Maurício Aniche, and Arie van Deursen. 2021.
An ExploratoryStudy of LogPlacement Recommendation in anEnterprise Sys-
tem.IEEE/ACM 18th International Conference on Mining Software Repositories
(MSR)(2021).
[9]SaikatChakrabortyandBaishakhiRay.2021. OnMulti-ModalLearningofEditing
Source Code. arXiv:2108.06645 [cs.SE]
[10]BoyuanChenandZhenMingJackJiang.2017.Characterizingloggingpracticesinjava-based open source software projects–a replication study in apache software
foundation. Empirical Software Engineering 22, 1 (2017), 330–374.
[11]Boyuan Chen, Jian Song, Peng Xu, Xing Hu, and Zhen Ming Jiang. 2018. An
automatedapproachtoestimatingcodecoveragemeasuresviaexecutionlogs.InProceedingsofthe33rdACM/IEEEInternationalConferenceonAutomatedSoftware
Engineering. 305–316.
[12]Jinfu Chen, Weiyi Shang, Ahmed E Hassan, Yong Wang, and Jiangbin Lin. 2019.
An experience report of generating load tests using log-recovered workloads
at varying granularities of user behaviour. In 2019 34th IEEE/ACM International
Conference on Automated Software Engineering (ASE). IEEE, 669–681.
[13]OzrenDabic,EmadAghajani,andGabrieleBavota.2021. SamplingProjectsin
GitHubforMSRStudies.In 18thIEEE/ACMInternationalConferenceonMining
Software Repositories, MSR 2021. IEEE, 560–564.
[14]Min Du, Feifei Li, Guineng Zheng, and Vivek Srikumar. 2017. Deeplog: Anomaly
detection and diagnosis from system logs through deep learning. In Proceedings
ofthe2017ACMSIGSACConferenceonComputerandCommunicationsSecurity .
1285–1298.
[15]Qiang Fu, Jieming Zhu, Wenlu Hu, Jian-Guang Lou, Rui Ding, Qingwei Lin,Dongmei Zhang, and Tao Xie. 2014. Where do developers log? an empiricalstudy on logging practices in industry. In Companion Proceedings of the 36th
InternationalConference on Software Engineering . 24–33.
[16]Nentawe Gurumdimma, Arshad Jhumka, Maria Liakata, Edward Chuah, and
JamesBrowne.2016. Crude:Combiningresourceusagedataanderrorlogsfor
accurate error detection in large-scale distributed systems. In 2016 IEEE 35th
Symposium on Reliable Distributed Systems (SRDS). IEEE, 51–60.
[17]Sakib Haque, Alexander LeClair, Lingfei Wu, and Collin McMillan. 2020. Im-
provedAutomaticSummarizationofSubroutinesviaAttentiontoFileContext.
arXiv:2004.04881[cs.SE]
[18]Julian Harty, Haonan Zhang, Lili Wei, Luca Pascarella, Mauricio Aniche, and
Weiyi Shang. 2021. Logging Practices with Mobile Analytics: An Empirical
Study on Firebase. Proceedings of the 2021 8th International Conference on Mobile
Software Engineering and Systems (MOBILESoft-2021) (2021).
[19]Wilhelm Hasselbring and André van Hoorn. 2020. Kieker: A monitoring frame-
work for software engineering research. Software Impacts 5 (2020), 100019.
[20]Xing Hu, Ge Li, Xin Xia, David Lo, and Zhi Jin. 2018. Deep Code CommentGeneration. In Proceedings of the 26th Conference on Program Comprehension
(Gothenburg, Sweden). ACM, 200–210. https://doi.org/10.1145/3196321.3196334
[21]Xing Hu, Ge Li, Xin Xia, David Lo, and Zhi Jin. 2020. Deep code comment
generationwithhybridlexicalandsyntacticalinformation. SpringerEmpiricalSoftware Engineering 25 (2020), 2179–2217.
[22]Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, and Luke Zettlemoyer. 2016.
Summarizing Source Code using a Neural Attention Model. In Proceedings of the
54thAnnualMeetingoftheAssociationforComputationalLinguistics(Volume1:
Long Papers). 2073–2083.
[23]Zhouyang Jia, Shanshan Li, Xiaodong Liu, Xiangke Liao, and Yunhuai Liu. 2018.
SMARTLOG: Place error log statement by deep understanding of log intention.
In2018 IEEE 25th International Conference on Software Analysis, Evolution and
Reengineering (SANER). IEEE, 61–71.
[24]Suhas Kabinna, Cor-Paul Bezemer, Weiyi Shang, Mark D Syer, and Ahmed E
Hassan. 2018. Examining the stability of logging statements. Empirical Software
Engineering 23, 1 (2018), 290–333.
[25]HengLi,Tse-HsunPeterChen,WeiyiShang,andAhmedEHassan.2018.Studyingsoftware logging using topic models. Empirical Software Engineering 23, 5 (2018),
2655–2694.
[26]Heng Li, Weiyi Shang, Bram Adams, Mohammed Sayagh, and Ahmed E Hassan.
2020. Aqualitativestudyofthebenefitsandcostsofloggingfromdevelopers’
perspectives. IEEE Transactions on Software Engineering (2020).
[27]Heng Li, Weiyi Shang, and Ahmed E Hassan. 2017. Which log level should
developers choose for a new logging statement? Empirical Software Engineering
22, 4 (2017), 1684–1716.
[28]Zhenhao Li. 2020. Towards providing automated supports to developers on
writingloggingstatements.In ProceedingsoftheACM/IEEE42ndInternational
Conference on Software Engineering: Companion Proceedings. 198–201.
[29]Zhenhao Li, Tse-Hsun Chen, and Weiyi Shang. 2020. Where shall we log?
studyingandsuggestinglogginglocationsincodeblocks.In Proceedingsofthe
35thIEEE/ACMInternationalConferenceonAutomatedSoftwareEngineering.361–
372.
[30]Zhenhao Li, Heng Li, Tse-Hsun Peter Chen, and Weiyi Shang. 2021. DeepLV:
Suggesting Log Levels Using Ordinal Based Neural Networks. In 2021 IEEE/ACM
43rd International Conference on Software Engineering (ICSE). IEEE, 1461–1472.
[31]Zhongxin Liu, Xin Xia, David Lo, Zhenchang Xing, Ahmed E Hassan, and Shan-
ping Li. 2019. Which variables should i log? IEEE Transactions on Software
Engineering (2019).
[32]SiyangLu,BingBingRao,XiangWei,ByungchulTak,LongWang,andLiqiang
Wang.2017. Log-basedabnormaltaskdetectionandrootcauseanalysisforspark.
In2017 IEEE InternationalConference on Web Services (ICWS) . IEEE, 389–396.
[33]Antonio Mastropaolo, Simone Scalabrino, Nathan Cooper, David Nader-Palacio,
Denys Poshyvanyk, Rocco Oliveto, and Gabriele Bavota. 2021. Studying the
Usage of Text-To-Text Transfer Transformer to Support Code-Related Tasks. In
43rdIEEE/ACMInternationalConferenceonSoftwareEngineering,ICSE2021.IEEE,
336–347.
[34]WeibinMeng,YingLiu,YichenZhu,ShenglinZhang,DanPei,YuqingLiu,YihaoChen,RuizhiZhang,ShiminTao,PeiSun,etal
.2019. LogAnomaly:Unsupervised
DetectionofSequentialandQuantitativeAnomaliesinUnstructuredLogs..In
IJCAI, Vol. 19. 4739–4745.
[35]Tsuyoshi Mizouchi,Kazumasa Shimari,Takashi Ishio,andKatsuroInoue.2019.
PADLA: a dynamic log level adapter using online phase detection. In 2019
IEEE/ACM 27th International Conference on Program Comprehension (ICPC). IEEE,
135–138.
[36]AdamOliner,ArchanaGanapathi,andWeiXu.2012. Advancesandchallenges
in log analysis. Commun. ACM 55, 2 (2012), 55–61.
[37]Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. BLEU:
AMethodforAutomaticEvaluationofMachineTranslation.In Proceedingsof
the40thAnnualMeetingonAssociationforComputationalLinguistics (ACL’02).
311–318.
[38]Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang,
Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the LimitsofTransferLearningwithaUnifiedText-to-TextTransformer. JournalofMachine
Learning Research 21, 140 (2020), 1–67. http://jmlr.org/papers/v21/20-074.html
[39]MahadevSatyanarayanan,DavidCSteere,MasashiKudo,andHankMashburn.
1992. Transparent logging as a technique for debugging complex distributed
systems. In Proceedings of the 5th workshop on ACM SIGOPS European workshop:
Models and paradigms for distributed systems structuring. 1–3.
[40]Michele Tufano, Cody Watson, Gabriele Bavota, Massimiliano Di Penta, Martin
White,andDenysPoshyvanyk.2019. AnEmpiricalStudyonLearningBug-Fixing
Patches in the Wild via Neural Machine Translation. ACM Trans. Softw. Eng.
Methodol. 28, 4 (2019), 19:1–19:29.
[41]Rosalia Tufano, Luca Pascarella, Michele Tufano, Denys Poshyvanyk, andGabriele Bavota. 2021. Towards Automating Code Review Activities. In 2021
IEEE/ACM 43rd International Conference on Software Engineering (ICSE). IEEE,
163–174.
[42]Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, Ł ukasz Kaiser, and Illia Polosukhin. 2017. Attention is All
youNeed. In AdvancesinNeuralInformationProcessingSystems30,I.Guyon,U.V.
Luxburg,S.Bengio,H.Wallach,R.Fergus,S.Vishwanathan,andR.Garnett(Eds.).
Curran Associates, Inc.,5998–6008. http://papers.nips.cc/paper/7181-attention-
is-all-you-need.pdf
2289
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:59:43 UTC from IEEE Xplore.  Restrictions apply. ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Antonio Mastropaolo, Luca Pascarella, and Gabriele Bavota
[43]CodyWatson,NathanCooper,DavidNaderPalacio,KevinMoran,andDenys
Poshyvanyk. 2020. A Systematic Literature Review on the Use of Deep Learning
in Software Engineering Research. arXiv preprint arXiv:2009.06520 (2020).
[44]KundiYao,GuilhermeB.dePádua,WeiyiShang,SteveSporea,AndreiToma,and
SarahSajedi.2018. Log4perf:Suggestinglogginglocationsforweb-basedsystems’
performance monitoring. In Proceedings of the 2018 ACM/SPEC International
Conference on Performance Engineering. 127–138.
[45]Ding Yuan, Haohui Mai, Weiwei Xiong, Lin Tan, Yuanyuan Zhou, and Shankar
Pasupathy.2010. Sherlog:errordiagnosisbyconnectingcluesfromrun-timelogs.
InProceedingsofthefifteenthInternationalConferenceonArchitecturalsupport
for programming languages and operating systems. 143–154.
[46]DingYuan,SoyeonPark,andYuanyuanZhou.2012. Characterizingloggingprac-
ticesinopen-sourcesoftware.In 201234thInternationalConferenceonSoftware
Engineering (ICSE). IEEE, 102–112.
[47]Ding Yuan,Jing Zheng, SoyeonPark, YuanyuanZhou, and StefanSavage. 2012.
Improvingsoftwarediagnosabilityvialogenhancement. ACMTransactionson
Computer Systems (TOCS) 30, 1 (2012), 1–28.
[48]Yi Zeng, Jinfu Chen, Weiyi Shang, and Tse-Hsun Peter Chen. 2019. Studying
thecharacteristicsofloggingpracticesinmobileapps:acasestudyonf-droid.
Empirical Software Engineering 24, 6 (2019), 3394–3434.
[49]Xu Zhang, Yong Xu, Qingwei Lin, Bo Qiao, Hongyu Zhang, Yingnong Dang,Chunyu Xie, Xinsheng Yang, Qian Cheng, Ze Li, et al
.2019. Robust log-basedanomaly detection on unstable log data. In Proceedings of the 2019 27th ACM
JointMeetingonEuropeanSoftwareEngineeringConferenceandSymposiumon
the Foundations of Software Engineering. 807–817.
[50]ChenZhi,JianweiYin,ShuiguangDeng, MaoxinYe,MinFu,andTaoXie. 2019.
An exploratory study of logging configuration practice in Java. In 2019 IEEE
InternationalConferenceonSoftwareMaintenanceandEvolution(ICSME) .IEEE,
459–469.
[51]RuiZhou,MohammadHamdaqa,HaipengCai,andAbdelwahabHamou-Lhadj.
2020. MobiLogLeak: a preliminary study on data leakage caused by poor log-
gingpractices.In 2020IEEE27thInternationalConferenceonSoftwareAnalysis,
Evolution and Reengineering (SANER). IEEE, 577–581.
[52]XiangZhou,XinPeng,TaoXie,JunSun,ChaoJi,DeweiLiu,QilinXiang,and
ChuanHe.2019. Latenterrorpredictionandfaultlocalizationformicroservice
applicationsbylearningfromsystemtracelogs.In Proceedingsofthe201927th
ACM Joint Meeting on European Software Engineering Conference and Symposium
on the Foundations of Software Engineering. 683–694.
[53]Jieming Zhu, Pinjia He, Qiang Fu, Hongyu Zhang, Michael R Lyu, and Dong-
meiZhang.2015. Learningtolog:Helpingdevelopersmakeinformedlogging
decisions. In 2015 IEEE/ACM 37th IEEE International Conference on Software Engi-
neering, Vol. 1. IEEE, 415–425.
2290
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:59:43 UTC from IEEE Xplore.  Restrictions apply. 