Type4Py: Practical Deep Similarity Learning-Based Type
Inference for Python
Amir M. Mir
s.a.m.mir@tudelft.nl
Delft Universityof Technology
Delft,The NetherlandsEvaldas Latoškinas
e.latoskinas@student.tudelft.nl
Delft Universityof Technology
Delft,The Netherlands
Sebastian Proksch
s.proksch@tudelft.nl
Delft University of Technology
Delft,The NetherlandsGeorgios Gousios
gousiosg@fb.com
Meta
Menlo Park, USA
Abstract
Dynamic languages, such as Python and Javascript, trade static
typing for developer flexibility and productivity. Lack of static typ-
ingcancauserun-timeexceptionsandisamajorfactorforweak
IDE support. To alleviate these issues, PEP 484 introduced optional
type annotations for Python. As retrofitting types to existing code-
basesiserror-proneandlaborious,machinelearning(ML)-based
approaches have been proposed to enable automatic type infer-
ence based on existing, partially annotated codebases. However,
previousML-basedapproachesaretrainedandevaluatedonhuman-
provided type annotations, which might not always be sound, and
hencethismaylimitthepracticalityforreal-worldusage.Inthis
paper, we present Type4Py, a deep similarity learning-based hier-
archicalneuralnetworkmodel.Itlearnstodiscriminatebetween
similar and dissimilar types in a high-dimensional space, which
resultsinclustersoftypes.Likelytypesforarguments,variables,
andreturnvaluescanthenbeinferredthroughthenearestneigh-
bor search. Unlike previous work, we trained and evaluated ourmodel on a type-checked dataset and used mean reciprocal rank
(MRR) to reflect the performance perceived by users. The obtained
results show that Type4Pyachieves an MRR of 77.1%, which is a
substantial improvement of 8.1% and 16.7% over the state-of-the-art approaches
TypilusandTypeWriter , respectively. Finally, to
aid developers with retrofitting types, we released a Visual Stu-
dio Code extension, which uses Type4Pyto provide ML-based type
auto-completionfor Python.
Keywords
TypeInference,SimilarityLearning,MachineLearning,MeanRe-
ciprocal Rank, Python
ACM Reference Format:
Amir M. Mir, Evaldas Latoškinas, Sebastian Proksch, and Georgios Gousios.
2022.Type4Py:PracticalDeepSimilarityLearning-BasedTypeInferencefor
Python. In 44th International Conference on Software Engineering (ICSE ’22),
This work is licensed under a Creative Commons Attribution-NonCommercial 
International 4.0 License.
ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
© 2022 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-9221-1/22/05.
https://doi.org/10.1145/3510003.3510124May21–29, 2022,Pittsburgh, PA, USA. ACM, New York, NY, USA, 12 pages.
https://doi.org/10.1145/3510003.3510124
1 Introduction
Over the past years, dynamically-typed programming languages
(DPLs)havebecomeextremelypopularamongsoftwaredevelopers.
TheIEEESpectrumranksPythonasthemostpopularprogramming
language in 2021 [ 3]. It is known that statically-typed languages
arelesserror-prone[ 54]andthatstatictypesimproveimportant
qualityaspectsofsoftware[ 20],likethemaintainabilityofsoftware
systemsin termsof understandability, fixing type errors[ 23], and
earlybugdetection[ 20].Incontrasttothat,dynamiclanguagessuch
asPythonandJavaScriptallowrapidprototypingwhichpotentially
reduces development time [ 23,59], but the lack of static types in
dynamically-typedlanguagesoftenleadstotypeerrors,unexpected
run-timebehavior, and suboptimal IDE support.
To mitigate these shortcomings, the Python community intro-
ducedPEP484[60],whichaddsoptionalstatictypingtoPython3.5
and newer. Static type inference methods [ 19,24] can be employed
to support adding these annotations, which is otherwise a man-ual, cumbersome, and error-prone process [
46]. However, static
inferenceisimprecise[ 50],causedbydynamiclanguagefeatures
orbytherequiredover-approximationofprogrambehavior[ 39].
Moreover, static analysis is usually performed on full programs,
includingtheirdependencies,whichisslowandresource-intensive.
To address these limitations of static type inference methods,
researchershaverecentlyemployed MachineLearning (ML)tech-
niques for type prediction in dynamic languages [ 12,26,41,51].
The experimental results of these studies show that ML-based type
predictionapproachesaremoreprecisethanstatictypeinference
methods or they can also work with static methods in a comple-
mentary fashion [ 12,51]. Despite the superiority of ML-based type
prediction approaches, their type vocabulary is small and fixed-
sized(i.e.1,000types).Thislimitstheirtypepredictionabilityfor
user-definedandraretypes.Tosolvethisissue,Allamanisetal.[ 12]
recently introduced Typiluswhich does not constraint the type vo-
cabulary size and it outperforms the other models with small-sized
type vocabulary.
While the ML-based type inference approaches are effective, we
believethattherearetwomaindrawbacksintherecentprevious
work [12, 51]:
22412022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)
ICSE ’22, May 21–29,2022, Pittsburgh,PA, USA Miret al.
•The neural models are trained and evaluated on developer-
providedtypeannotations,whicharenotalwayscorrect[ 46,52].
This might be a (major) threat to the validity of the obtained
results.Toaddressthis,atypecheckershouldbeemployedto
detect and remove incorrect type annotations from the dataset.
•Although the proposed approaches [ 12,51] obtain satisfying
performance for Top-10, it is important for an approach to give
a correct prediction in Top-1 as developers tend to use the first
suggestion by a tool [ 48]. Like the API recommendation re-
search [25,36], the Mean Reciprocal Rank (MRR) metric should
alsobeusedforevaluation,which partiallyrewardsanapproach
where the correct API is not in the Top-1 suggestion.
Motivatedbytheabovediscussion,wepresent Type4Py,atypein-
ference approach based on deep similarity learning (DSL). The pro-
posedapproachconsistsofaneffectivehierarchicalneuralnetwork
thatmapsprogramsinto typeclusters inahigh-dimensionalfeature
space. Similarity learning has, for example, been used in Computer
Vision to discriminate human faces for verification [ 15]. Similarly,
Type4Pylearns how to distinguish between different types through
aDSL-basedhierarchicalneuralnetwork.Asaresult,ourproposed
approach can not only handle a very large type vocabulary, but
also it can be used in practice by developers for retrofitting type
annotations.Incomparisonwiththestate-of-the-artapproaches,
the experimental results show that Type4Pyobtains an MRR of
77.1%,whichis8.1%and16.7%higherthan Typilus[12]andType-
Writer[51],respectively.
Overall, this paper presents the following main contributions:
•Type4Py, a new DSL-based type inference approach.
•Atype-checked datasetwith5.1KPythonprojectsand1.2Mtype
annotations. Invalid type annotations are removed from both
trainingand evaluation.
•A VisualStudio Codeextension [ 9], whichprovides ML-based
type auto-completion for Python.
To foster future research, we publicly released the implementation
of theType4Pymodel and its dataset on Zenodo.1
Therest of the paperis organized as follows. Section 2 reviews
related work on static and ML-based type inference. The proposed
approach, Type4Py, is described in Section 3. Section 4 gives de-
tails about the creation of the type-checked dataset for evaluation.
TheevaluationsetupandempiricalresultsaregiveninSection5
and Section 6,respectively.Section 7 describes the deploymentof
Type4PyanditsusageinVisualStudioCode.Section8discussesthe
obtained results and gives future directions. Finally, we summarize
our work in Section 9.
2 Related Work
TypecheckingandinferenceforPython: In2014,thePythoncom-
munity introduced a type hints proposal [ 60] that describes adding
optionaltypeannotationstoPythonprograms.Ayearlater,Python
3.5wasreleasedwithoptionaltypeannotationsandthe mypytype
checker[ 33].ThishasenabledgradualtypingofexistingPython
programsandvalidatingaddedtypeannotations.Sincetheintroduc-
tionoftypehintsproposal,othertypecheckershavebeendeveloped
suchasPyType[8],PyRight[7], andPyre[6].
1https://doi.org/10.5281/zenodo.5913787Anumberofresearchworksproposedtypeinferencealgorithms
forPython[ 24,40,56].Thesearestatic-basedapproachesthathave
apre-definedsetofrulesandconstraints.Aspreviouslymentioned,
statictypeinferencemethodsareoftenimprecise[ 50],duetothe
dynamicnatureofPythonandtheover-approximationofprograms’
behavior by static analysis [39].
Learning-based type inference: In 2015, Rachev et al. [ 55] proposed
JSNice,aprobabilisticmodelthatpredictsidentifiernamesandtype
annotations for JavaScript using conditional random fields (CRFs).
The central idea of JSNice is to capture relationships between pro-
gram elements in a dependency network. However, the main issue
with JSNice is that its dependency network cannot consider a wide
context within a program or a function.
Xu et al. [ 64] adopt a probabilistic graphical model (PGM) to
predictvariabletypesforPython.Theirapproachextractsseveral
uncertaintype hintssuch asattribute access,variable names,and
dataflowbetweenvariables.AlthoughtheprobabilisticmodelofXu
etal.[64]outperformsstatictypeinferencesystems,theirproposed
systemis slow and lacks scalability.
ConsideringthementionedissueofJSNice,Hellendoornetal.[ 26]
proposedDeepTyper,asequence-to-sequenceneuralnetworkmodel
thatwastrainedonanalignedcorpusofTypeScriptcode.TheDeep-
Typer model can predict type annotations across a source code file
byconsideringamuchwidercontext.YetDeepTypersuffersfromin-
consistent predictions for the token-level occurrences of the same
variable. Malik et al. [ 41] proposed NL2Type, a neural network
model that predicts type annotations for JavaScript functions. The
basic idea of NL2Type is to leverage the natural language infor-
mation in the source code such as identifier names and comments.
TheNL2TypemodelisshowntooutperformboththeJSNiceand
DeepTyper at the task of type annotations prediction [41].
Motivated by the NL2Type model, Pradel et al. [ 51] proposed
the TypeWriter model which infers type annotations for Python.
TypeWriter is a deep neural network model that considers both
code context and natural language information in the source code.
Moreover, TypeWriter validates its neural model’s type predictions
by employing a combinatorial search strategy and an external type
checker.Weietal.[ 62]introducedLAMBDANET,agraphneural
network-based type inference for TypeScript. Its main idea is to
create a type dependency graph that links to-be-typed variables
withlogicalconstraintsandcontextualhintssuchasvariablesas-
signments and names. For type prediction, LAMBDANET employs
apointer-network-likemodelwhichenablesthepredictionofun-
seen user-defined types. The experimental results of Wei et al. [ 62]
show the superiority of LAMBDANET over DeepTyper.
Giventhatthenaturalconstraintssuchasidentifiersandcom-
ments are an uncertain source of information, Pandi et al. [ 47]
proposed OptTyper which predicts types for the TypeScript lan-
guage.Thecentralideaoftheirapproachistoextractdeterministic
information or logical constraints from a type system and combine
them with the natural constraints in a single optimization problem.
ThisallowsOptTypertomakeatype-correctpredictionwithoutvi-
olating the typing rules of the language. OptTyper has been shown
to outperform both LAMBDANET and DeepTyper [47].
Except for LAMBDANET, all the discussed learning-based type
inferencemethodsemploya(small)fixed-sizetypevocabulary,e.g.,
2242Type4Py: Practical Deep Similarity Learning-Based Type Inference for Python ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
Table 1: Comparison between Type4Py and otherlearning-based type inference approaches
Approach Sizeof type vocabulary ML modelType hints Supported Predictions
Contextual Natural Logical Argument Return Variable
Type4Py Unlimited HNN (2x RNNs)     
JSNice [55] 10+ CRFs     
Xu et al. [64] - PGM     
DeepTyper [26] 10K+ biRNN     
NL2Type [41] 1K LSTM     
TypeWriter [51] 1K HNN (3x RNNs)     
LAMBDANET [62] 100aGNN    
OptTyper [47] 100 LSTM     
Typilus [12] Unlimited GNN     
TypeBert [29] 40K BERT     
aNotethatLAMBDANET’spointer network model enables to predict user-defined types outside its fixed-size type vocabulary.
1,000types.Thishinderstheirabilitytoinferuser-definedandrare
types.Toaddressthis,Allamanisetal.[ 12]proposedTypilus,which
isagraphneuralnetwork(GNN)-basedmodelthatintegratesinfor-
mation from several sources such as identifiers, syntactic patterns,
anddataflowtoinfertypeannotationsforPython.Typilusisbased
onmetric-basedlearningandlearnstodiscriminatesimilarto-be-
typed symbols from different ones. However, Typilus requires a
sophisticatedsourcecodeanalysistocreateitsgraphrepresenta-
tions,i.e.dataflowanalysis.Veryrecently,inspiredby"BigData",
Jesse et al. [ 29] presented TypeBert, a pre-trained BERT model
with simple token-sequence representation. Their empirical results
show that TypeBert generally outperforms LAMBDANET. The dif-
ferences between Type4Pyand other learning-based approaches are
summarized in Table 1.
3 Proposed Approach
Thissectionpresentsthedetailsof Type4Pybygoingthroughthe
different steps of the pipeline that is illustrated in the overview
of the proposed approach in Figure 1. We first describe how we
extracttypehintsfromPythonsourcecodeandthenhowweuse
this informationto train the neural model.
3.1 Type Hints
WeextracttheAbstractSyntaxTree(AST)fromPythonsourcecode
files.BytraversingthenodesofASTs,weobtaintypehintsthatare
valuable for predicting types of function arguments, variables, and
return types. The obtained type hints are based on natural infor-
mation, codecontext,and import statementswhich are described
in this section.
Natural Information: As indicated by the previous work [ 27,41],
sourcecodecontainsusefulandinformalnaturallanguageinfor-
mation that is considered as a source of type hints. In DPLs, devel-
opers tend to name variables and functions’ arguments after their
expectedtype[ 44].Basedonthisintuition,weconsideridentifier
names as the main source of natural information and type hint.
Specifically, we extractthe name of functions ( Nf) and theirargu-
ments (Narдs) as they may provide a hint about the return type of
functionsandthetypeoffunctions’arguments,respectively.Wealso denote a function’s argument as Narдhereafter. For variables,
we extract their names as denoted by Nv.
CodeContext: Weextractallusesofanargumentinthefunction
body as a type hint. This means that the complete statement, in
which the argument is used, is included as a sequence of tokens.
Similarly,weextractallusesofavariableinitscurrentandinner
scopes.Also,allthereturnstatementsinsideafunctionareextracted
as they may contain a hint about the return type of the function.
Visible type hints (VTH): In contrast to previous work that only
analyzed the direct imports [ 51], we recursively extract all the
importstatementsinagivenmoduleanditstransitivedependen-
cies.Webuildadependencygraphforallimportsofuser-defined
classes,typealiases,and NewType declarationsForexample,ifmod-
uleAimports B.Typeand C.D.E, the edges ( A,B.Type) and ( A,
C.D.E) will be added to the graph. We expand wildcard imports
like from foo import * and resolve the concrete type refer-
ences. We consider the identified types as visibleand store them
withtheirfully-qualifiednametoreduceambiguity.Forinstance,
tf.Tensor andtorch.Tensor are different types. Although the
described inspection-based approach is slower than a pure AST-
basedanalysis,ourablationanalysisshowsthatVTHssubstantially
improve the performance of Type4Py(subsection 6.3).
3.2 Vector Representation
Inorderforamachinelearningmodeltolearnfromtypehints,they
arerepresentedasreal-valuedvectors.Thevectorspreserveseman-
tic similarities between similar words. To capture those, a word
embeddingtechniqueisusedtomapwordsintoa d-dimensional
vector space, Rd. Specifically, we first preprocess extracted iden-
tifiersandcodecontextsbyapplyingcommonNaturalLanguage
Processing (NLP) techniques. This preprocessing step involves tok-
enization, stop word removal, and lemmatization [ 30]. Afterwards,
we employ Word2Vec [43] embeddings to train a code embedding
Ec:w1,...,wl→Rl×dforbothcodecontextandidentifiertokens,
wherewiandldenote a single token and the length of a sequence,
respectively.Inthefollowing,wedescribethevectorrepresentation
ofallthethreedescribedtypehintsforbothargumenttypesand
return types.
2243ICSE ’22, May 21–29,2022, Pittsburgh,PA, USA Miret al.
Testing phaseType4Py modelAST extraction
Python source code files
user
pathsizedata
Code tokensIdentifiers....Identifier RNN
Code RNNVector
Visible type hintsLinear layerConcatenation
Type clustersfloat Tensor
strType4Py model
Test source code files
AST extraction &
Token embeddings
strToken Embeddings
Vector
Training phase
Figure 1: Overview of Type4Py approach
Identifiers: Given an argument’s type hints, the vector sequence of
the argumentis represented as follows:
Ec(Narд)◦s◦Ec(Nf)◦Ec(Narдs)
where◦concatenates and flattens sequences, and sis a separator2.
For a return type, its vector sequence is represented as follows:
Ec(Nf)◦s◦Ec(Narдs)
Last,a variable’s identifier is embedded as Ec(Nv).
Codecontexts: Forfunctionargumentsand variables,weconcate-
natethesequencesoftheirusagesintoasinglesequence.Similarly,
forreturntypes,weconcatenateallthereturnstatementsofafunc-
tionintoasinglesequence.Totruncatelongsequences,weconsider
a window of ntokens at the center of the sequence (default n=7).
Similar to identifiers, the function embedding Ecis used to convert
code contexts sequences into a real-valued vector.
Visible type hints: Given all the source code files, we build a fixed-
size vocabulary of visible type hints. The vocabulary covers the
majority of all visible type occurrences. Because most imported
visibletypesinPythonmodulesarebuilt-inprimitivetypessuch
asList,Dict, and their combinations. If a type is out of the visi-
bletypevocabulary,itisrepresentedasaspecial othertype.For
function arguments, variables, and return types, we create a sparse
binaryvectorofsize Twhoseelementsrepresentatype.Anelement
of the binary vector is set to one if and only if its type is present
in the vocabulary. Otherwise, the othertype is set to one in the
binary vector.
3.3 NeuralModel
Theneuralmodelofourproposedapproachemploysahierarchi-
cal neural network (HNN), which consists of two recurrent neural
networks(RNNs)[ 63].HNNsarewell-studiedandquiteeffective
for text and vision-related tasks [ 18,35,65]. In the case of type
prediction, intuitively, HNNs can capture different aspects of iden-
tifiersand code context. In the neural architecture (see Fig. 1), the
twoRNNsarebasedonlongshort-termmemory(LSTM)units[ 28].
Here, we chose LSTMs units as they are effective for capturing
long-range dependencies [ 22]. Also, LSTM-based neural models
2Theseparatoris a vector of ones with appropriate dimension.havebeenappliedsuccessfullytoNLPtaskssuchassentimentclas-
sification [ 53]. Formally, the output h(t)
iof thei-th LSTM unit at
the timestep tis defined as follows:
h(t)
i=tanh(st
i)σ/parenlefttpA/parenleftexA
/parenleftbtAbi+/summationdisplay.1
jUi,jx(t)
j+/summationdisplay.1
jWi,jh(t−1)
j/parenrighttpA/parenrightexA
/parenrightbtA(1)
whichhassigmoidfunction σ,currentinput vector xj,unitstate
st
iand has model parameters W,U,bfor its recurrent weights,
input weights and biases [ 22]. The two hierarchical RNNs allow
capturing different aspects of input sequences from identifiers and
code tokens. The captured information is then summarized into
two single vectors, which are obtained from the final hidden state
oftheircorrespondingRNN.ThetwosinglevectorsfromRNNsare
concatenatedwiththevisibletypehintsvectorandtheresulting
vector is passed through a fully-connected linear layer.
In previous work [ 41,51], the type prediction task is formulated
as a classification problem. As a result, the linear layer of their
neural model outputs a vector of size 1,000 with probabilities over
predicted types. Therefore, the neural model predicts unkonwn if it
has not seen a type in the training phase. To address this issue, we
formulatethetypepredictiontaskasaDeepSimilarityLearning
problem [ 15,34]. By using the DSL formulation, our neural model
learnstomapargument,variable,returntypesintorealcontinuous
space, called type clusters (also known as type space in [ 12]). In
other words, our neural model maps similar types (e.g. str) into
its own type cluster, which should be as far as possible from other
clustersoftypes.Unlikethepreviouswork[ 41,51],ourproposed
model can handle a very large type vocabulary.
To create the described type clusters, we use Triplet loss [14]
functionwhichisrecentlyusedforcomputervisiontaskssuchas
facerecognition[ 14].ByusingtheTripletloss,aneuralmodellearns
to discriminate between similar samples and dissimilar samples by
mappingsamplesintotheirownclustersinthecontinuousspace.
In the case of type prediction, the loss function accepts a type ta,a
typetpsameasta,and atype tnwhichisdifferentthan ta.Given
a positive scalar margin m, the Triplet loss function is defined as
follows:
L(ta,tp,tn)=max(0,m+/bardblex/bardblexta−tp/bardblex/bardblex−/bardblta−tn/bardbl)(2)
2244Type4Py: Practical Deep Similarity Learning-Based Type Inference for Python ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
The goal of the objective function Lis to make taexamples
closertothesimilarexamples tpthantotnexamples.Weusethe
Euclideanmetric to measure the distance of tawithtpandtn.
At prediction time, we first map a query example tqto the type
clusters.Thequeryexample tqcanbeafunction’sargument,the
return type of a function or a variable. Then we find the k-nearest
neighbor (KNN) [ 16] of the query example tq. Given the k-nearest
examples tiwith a distance difrom the query example tq, the
probability of tqhavinga type t/primecan be obtained as follows:
P(tq:t/prime)=1
Nk/summationdisplay.1
iI(ti=t/prime)
(di+ε)2(3)
whereIis the indicator function, Nis a normalizing constant,
andεis a small scalar (i.e. ε=10−10).
4 Dataset
Forthiswork,wehavecreatedanewversionofourManyTypes4Py
dataset[45],i.e.,v0.7.Therestofthissectiondescribesthecreation
ofthedataset.TofindPythonprojectswithtypeannotations,on
Libraries.io,wesearchedforprojectsthatdependonthe mypypack-
age [5], i.e., the official and most popular type checker for Python.
Intuitively, these projects are more likely to have type annotations.
Thesearchresultedin5.2KPythonprojectsthatareavailableon
GitHub.Initially,thedatasethas685Ksourcefilesand869Ktype
annotations.
4.1 Code De-duplication
OnGitHub,Pythonprojectsoftenhavefile-levelduplicates[ 38]and
alsocodeduplicationhasanegativeeffectontheperformanceofML
models when evaluating them on unseen code samples [ 11]. There-
fore, to de-duplicate the dataset, we use our code de-duplication
tool, CD4Py [ 2]. It uses term frequency-inverse document (TF-IDF)
[42]torepresentasourcecodefileasavectorin Rnandemploys
KNN search to find clusters of similar duplicate files. While as-
suming that the similarity is transitive [ 11], we keep a file from
each cluster and remove all other identified duplicate files from
the dataset. Using the described method, we removed around 400K
duplicatefiles from the dataset.
4.2 Augmentation
Similar to the work of Allamanis et al. [ 12], we have employed a
statictypeinferencetool,namely,Pyre[ 6]v0.9.0toaugmentour
initial dataset with more type annotations. However, we do note
thatwecouldonlyinferthetypeofvariablesusingPyre’s query
command.Inourexperience,thequerycommandcouldnotinfer
thetypeofargumentsandreturntypes.Thecommandacceptsa
list of files and returns JSON files containing type information.
ThankstoPyre’s inferredtypes,thedatasethas now3.3Mtype
annotationsintotal.TodemonstratetheeffectofusingPyreonthe
dataset,Figure2showsthepercentageoftypeannotationcoverage
for source code files with/without using Pyre. After using Pyre, of
288,760 source code files, 65% of them have more than 40% type
annotationcoverage.
4.3 Type Checking
Recent studies show that developer-provided types rarely type-
check and Python projects may contain type-related defects [ 31,
46,52].Therefore,webelieve thatitisessentialtotype-checktheFigure 2: The effect of using Pyre on the type annotation
coverage of source code files
dataset to eliminate noisy ground truth (i.e. incorrect type annota-
tions).Notonlynoisygroundtruthcanbeconsideredathreatto
the validity of results but also it may make the discrimination of
types in type clusters more difficult [ 21]. To clean the dataset from
noisy ground truth, we perform basic analysis as follows:
•First, we use mypy to type-check 288,760 source files in the
dataset. Of which, 184,752 source files are successfully type-
checked.
•Consideringtheremaining104,008sourcefiles,forfurtheranal-
ysis, we ignore source files that cannot be type-checked further
by mypy due to syntax error or other fatal exceptions. This
amountsto 63,735 source files in the dataset.
•Given 40,273 source files with type errors, we remove one type
annotation at a time from a file and run mypy. If it type-checks,
we include the file. Otherwise, we continue this step up to 10
times. This basic analysis fixes 16,861 source files with type
errors, i.e, 42% of the given set of files.
4.4 Dataset Characteristics
Table 2 shows the characteristics of our dataset after code de-
duplication,augmentation,andtype-checking.Intotal,thereare
more than 882K functions with around 1.5M arguments.Also, the
dataset has more than 2.1M variable declarations. Of which, 48%
have type annotations.
Figure3showsthefrequencyoftop10mostfrequenttypesinour
dataset.Itcanbeobservedthattypesfollowalong-taildistribution.
Unsurprisingly,thetop10mostfrequenttypesamountto59%of
typesinthedataset.Lastly,werandomlysplitthedatasetbyfiles
into three sets: 70% training data, 10% validation data, and 20% test
data. Table 3 shows the number of data points for each of the three
sets.
4.5 Pre-processing
Similartothepreviouswork[ 12,51],beforetrainingMLmodels,
we have performed several pre-processing steps:
•Trivialfunctionssuchas __str__and__len__arenotincluded
in the dataset. The return type of this kind of functions is
2245ICSE ’22, May 21–29,2022, Pittsburgh,PA, USA Miret al.
Table 2: Characteristics of the dataset used for evaluation
Metricsa,bOur dataset
Repositories 5,092
Files 201,613
Lines of codec11.9M
Functions 882,657
...withreturn type annotations 94,433 (10.7%)
Arguments 1,558,566
...withtype annotations 128,363 (14.5%)
Variables 2,135,361
...withtype annotations 1,023,328 (47.9%)
Types 1,246,124
...unique 60,333
aMetricsare counted after the ASTs extraction phase of our pipeline.
cCommentsandblank linesare ignored when counting lines of code.
Table3:Numberofdatapointsfortrain,validationandtest
sets
Argumenttype Return type Variable type
Training 90,114 37,803 426,235
Validation 9,387 3,932 48,518
Test 24,121 10,444 118,319
Total 108,888 (16.06%) 45,667 (6.74%) 523,271 (77.20%)
straightforward to predict, i.e., __len__ always returns int,
and would blur the results.
•We excluded AnyandNonetype annotations as it is not helpful
to predict these types.
•We performed a simple type aliasing resolving to make type
annotationsofthesamekindconsistent.Forinstance,wemap
[]toList,{}toDict, and Texttostr.
•We resolved qualified names for type annotations. For example,
arrayis resolved to numpy.array . This makes all the occur-
rences of a type annotation across the dataset consistent.
•Same as the work of Allamanis et al. [ 12], we rewrote the com-
ponents of a base type whose nested level is greater than 2
toAny.Forinstance,werewrite List[List[Tuple[int]]] to
List[List[Any]]] . This removes very rare types or outliers.
5 EvaluationSetup
Inthissection,wedescribethebaselinemodels,theimplementation
details and the training of the neural models. Lastly, we explain
evaluationmetricstoquantitativelymeasuretheperformanceof
ML-based type inference approaches.
5.1 Baselines
We compare Type4Pyto Typilus [ 12] and TypeWriter [ 51], which
are recent state-of-the-art ML-based type inference approaches for
Python. Considering Table 1, Type4Pyhas an HNN-based neuralFigure3:Top10mostfrequenttypes( Anyand Nonetypesare
excluded)
model whereas Typilus’s neural model is GNN-based. However,
Typilus has the same prediction abilities as Type4Pyand has no
limitationonthesizeoftypevocabularywhichmakesitanobvious
choiceforcomparison.Comparedwith Type4Py,TypeWriterhastwo
maindifferences.First,TypeWriter’stypevocabularyissmalland
pre-defined(i.e.1,000types)attrainingtime.Second,TypeWriter
cannotpredict the type of variables, unlike Type4Pyand Typilus.
5.2 Implementation Details and Environment
Setup
Weimplemented Type4PyandTypeWriterinPython3anditsecosys-
tem.WeextractthediscussedtypehintsfromASTsusingLibSA4Py[ 4].
Thedataprocessingpipelineisparallelizedbyemployingthe joblib
package. We use NLTK [ 37] for performing standard NLP tasks
suchastokenizationandstopworkremoval.TotraintheWord2Vec
model, the gensimpackageis used. For the neural model, we used
bidirectional LSTMs [ 57] in the PyTorch framework [ 49] to im-
plement the two RNNs. Lastly, we used the Annoy[ 1] package
to perform a fast and approximate nearest neighbor search. For
Typilus, we used its public implementation on GitHub [10].
We performed all the experiments on a Linux operating system
(Ubuntu18.04.5LTS).ThecomputerhadanAMDRyzenThread-
ripper 1920Xwith 24threads (@3.5GHz),64 GBof RAM,and two
NVIDIA GeForce RTX 2080 TIs.
5.3 Training
Toavoidoverfittingthetrainset,weappliedtheDropoutregular-
ization[58]totheinputsequencesexceptforthevisibletypes.Also,
we employed the Adam optimizer [ 32] to minimize the value of
the Triplet loss function. For both Type4Pyand TypeWriter, we em-
ployedthedataparallelismfeatureofPyTorchtodistributetraining
batches between the two GPUs with a total VRAM of 22 GB. For
theType4Pymodel,given 554Ktrainingsamples,a singletraining
epochtakesaround4minutes.Ittakes7secondsfortheTypeWriter
modelprovidingthatitstrainingsetcontains127Ktrainingsam-
ples3. Aside from the training sample size, Type4Pyis a DSL-based
3Note that TypeWriter uses only argument and return samples as it lacks the variable
prediction ability.
2246Type4Py: Practical Deep Similarity Learning-Based Type Inference for Python ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
Table 4: Value of hyperparameters for neural models
Hyperparameter Type4Py TypeWriter Typilus
Word embedding dimension (i.e. d) 100 100 N/A
Size of visible type hints vocabulary (i.e. T) 1024 1024 N/A
LSTM hidden nodes 256 256 N/A
GNN hidden nodes N/A N/A 64
Dimension of linear layer’s output 1536 1000 N/A
Number of LSTM’s layers 1 1 N/A
Learning rate 0.002 0.002 0.00025
Dropout rate 0.25 0.25 0.1
Number of epochs 25 25 500a
Batch size 5864 4096 N/A
Value ofkfor nearest neighbor search 10 N/A 10
Tripet loss’ margin value (i.e. m) 2.0 N/A 2.0
Model’s trainable parameters 4.6M 4.7M 650K
aThemodel stopped at epoch 38 due to the early stopping technique.
modelandhenceithastopredicttheoutputofthreedatapointsfor
everysingletrainingbatch(seeEq.2).Typiluscompletesasingle
training epoch in around 6 minutes4. For all the neural models,
the validation set is used to find the optimal number of epochs
for training. The value of the neural models’ hyperparameters is
reported in Table 4.
5.4 EvaluationMetrics
We measure the type prediction performance of an approach by
comparing the type prediction tpto the ground truth tдusing two
criteriaoriginallyproposed by Allamanis et al. [12]:
Exact Match: tpandtдare exactly the same type.
Base Type Match: ignoresalltypeparametersandonlymatchesthe
basetypes.Forexample, List[str] andList[int] wouldbe
considered a match.
In addition to these two criteria, as stated earlier, we opt for the
MRR metric [ 42], since the neural models predict a list of types for
agivenquery.TheMRRofmultiplequeries Qisdefinedasfollows:
MRR=1
|Q||Q|/summationdisplay.1
i=11
ri(4)
The MRR metricpartially rewards the neural models by giving a
score of1
rito a prediction if the correct type annotation appears
in rankr. Like Top-1 accuracy, a score of 1 is given to a prediction
forwhichtheTop-1suggestedtypeiscorrect.Hereafter,werefer
totheMRRoftheTop- npredictionsasMRR@ n.Weevaluatethe
neural models up to the Top-10 predictions as it is a quite common
methodology in the evaluation of ML-based models for code [ 12,
25, 51].
SimilartotheevaluationmethodologyofAllamanisetal.[ 12],
we consider types that we have seen more than 100 times in the
train setas commonorrareotherwise.Additionally, wedefine the
set ofubiquitous types, i.e., {str,int,list ,bool ,float}. These
typesareamongthetop10frequenttypesinthedataset(seeFig.3)
and they are excluded from the set of common types. Furthermore,
UnlikeType4Pyand Typilus, TypeWriter predicts unknown if the
expectedtypeisnotpresentinitstypevocabulary.Thus,tohave
4Thepublicimplementationof Typilus does not take advantage of our two GPUs.
Figure4:TheMRRscoreofthemodelsconsideringdifferent
top-npredictions
a valid comparison with the other two approaches, we consider
otherpredictionsbyTypeWriterinthecalculationofevaluation
metrics.
6 Evaluation
To evaluate and show the effectiveness of Type4Py, we focus on the
following research questions.
RQ1What is the general type prediction performance of Type4Py?
RQ2Howdoes Type4Pyperformwhileconsideringdifferentpredic-
tions tasks?
RQ3How do each proposed type hint and the size of type vocabu-
lary contribute to the performance of Type4Py?
6.1 Type Prediction Performance (RQ 1)
In this subsection, we compare our proposed approach, Type4Py,
withtheselectedbaselinemodelsintermsofoveralltypeprediction
performance.
Method:The models get trained on the training set and the test set
isusedtomeasurethetypepredictionperformance.Weevaluate
theneuralmodelsbyconsideringdifferenttop- npredictions,i.e.,
n={1,3,5,10}. Also, for this RQ, we consider all the supported
inference tasks by the models, i.e., arguments, return types, and
variables.
Results:Table5showstheoverallperformanceoftheneuralmodels
while considering different top- npredictions. Given the Top-10
prediction, Type4PyoutperformsbothTypilusandTypeWriterbased
on both the exact and base type match criteria (all). Specifically,
consideringtheexactmatchcriteria(alltypes), Type4Pyperforms
betterthanTypilusandTypeWriterattheTop-10predictionbya
margin of 5.9% and 11%, respectively. Moreover, it can be seen that
theType4Py’s performance drop is less significant compared to the
othertwomodelswhendecreasingthevalueof nfromTop-10to
Top-1.Forinstance,byconsideringTop-1ratherthanTop-10and
the exact match criteria (all), the performance of Type4Py, Typilus,
andTypeWriterdropby3.4%,7.2%,12.1%,respectively.Concerning
thepredictionofraretypes,Typilusslightlyperformsbetterthan
Type4Py,whichcanbe attributedtotheuseofanenhanced triplet
loss function. It is also worth mentioning that Type4Pyachieves
a 100% exact match for the ubiquitous types at Top-1, which is
remarkable.
2247ICSE ’22, May 21–29,2022, Pittsburgh,PA, USA Miret al.
Table 5: Performance evaluation of the neural models considering different top- npredictions
Top-npredictions Approach% Exact Match % Base Type Matcha
All Ubiquitous Common Rare All Common Rare
Top-1Type4Py 75.8 100.0 82.3 19.2 80.6 85.2 36.0
Typilus 66.1 92.5 73.4 21.6 74.2 81.6 41.7
TypeWriter 56.1 93.5 60.9 16.2 58.3 64.4 19.9
Top-3Type4Py 78.1 100.0 87.3 23.4 83.8 90.6 43.2
Typilus 71.6 96.2 83.0 26.8 79.8 88.7 49.2
TypeWriter 63.7 98.8 79.2 20.8 67.3 83.5 27.9
Top-5Type4Py 78.7 100.0 88.6 24.5 84.7 92.1 45.5
Typilus 72.7 96.7 85.1 28.2 80.9 90.1 51.0
TypeWriter 65.9 99.6 84.9 23.0 70.4 89.1 32.1
Top-10Type4Py 79.2 100.0 89.7 25.2 85.4 93.3 46.9
Typilus 73.3 97.04 86.4 28.9 81.5 90.9 51.9
TypeWriter 68.2 99.9 90.8 25.5 73.2 93.8 36.5
MRR@10Type4Py 77.1 100.0 85.1 21.4 74.1 79.9 29.4
Typilus 69.0 94.4 78.5 24.4 67.4 75.8 32.8
TypeWriter 60.4 96.1 71.3 19.1 56.5 68.0 19.7
aUbiquitoustypes are not a base type match. However, they are considered in the All column.
As stated earlier, developers are more likely to use the first sug-
gestionbyatool[ 48].Therefore,weevaluatedtheneuralmodelsby
theMRR@10metricatthebottomofTable5.Ideally,thedifference
betweentheMRR@10metricandtheTop-1predictionshouldbe
zero.However,this isverychallengingastheneuralmodelsarenot
100% confidentin theirfirst suggestion forall test samples.Given
the results of MRR@10, we observe that Type4Pyoutperforms both
TypilusandTypeWriterbyamarginof8.1%and16.7%,respectively.
In addition, we investigated the MRR score of the neural models
while considering different values of Top- n, which is shown in Fig-
ure4.Ascanbeseen, Type4Pyhasasubstantiallyhigherscorethan
theothermodelsacrossallvaluesof n.Moreover,theMRRscore
of all the three neural models almost converges to a fixed value
after MRR@3. Given the findings of the RQ1, we use MRR@10 and
the Top-1 prediction for the rest of the evaluation as we believe
this better shows the practicality of the neural models for assisting
developers.
6.2 DifferentPrediction Tasks (RQ 2)
Here, we compare Type4Pywith other baselines while consider-
ing different prediction tasks, i.e., arguments, return types, and
variables.
Method:SimilartotheRQ 1,themodelsaretrainedandtestedon
theentiretrainingandtestsets,respectively.However,weconsider
each prediction task separately while evaluating the models at
Top-1 and MRR@10.
Results:Table 6shows thetype predictionperformance ofthe ap-
proaches for the three considered prediction tasks. In general, con-
sidering the exact match criteria (all), Type4Pyoutperforms both
Typilus and TypeWriter in all prediction tasks at both Top-1 andMRR@10. For instance, considering the return task and Top-1,
Type4Pyobtains 56.4% exact matches (all), which is 13.9% and 5.7%
higher than that of Typilus and TypeWriter, respectively. Also, for
the same task, the Type4Py’s MRR@10 is 11.9% and 3.7% higher
comparedtoTypilusandTypeWriter,respectively.However,con-
cerningthepredictionofcommontypesandMRR@10,TypeWriter
performsbetterthanboth Type4PyandTypilusattheargumentand
returntasks.ThismightbeduetothefactthatTypeWriterpredicts
from the set of 1,000 types, which apparently makes it better at the
predictionofcommontypes.Moreover,both Type4PyandTypilus
have a much larger type vocabulary and hence they need more
training samples to generalize better providing that both argument
and return types together amount to 22.8% of all the data points
in the dataset (see Table 3). Lastly, in comparison with Typilus,
Type4Pyobtains 7.7% and 6.7% higher MRR@10 score for the exact
and base type match criteria (all), respectively.
6.3 AblationAnalysis (RQ 3)
Here,weinvestigatehoweachproposedtypehintandthesizeof
type vocabulary contribute to the overall performance of Type4Py.
Method:For ablation analysis, we trained and evaluated Type4Py
with 5 different configurations, i.e., (1) complete model (2) w/o
identifiers(3)w/ocodecontext(4)w/ovisibletypehints(5)w/a
vocabularyoftop1,000types.SimilartothepreviousRQs,wemea-
sure the performance of Type4Pywith the described configurations
at Top-1 and MRR@10.
Results:Table 7 presents the performance of Type4Pywith the five
describedconfigurations.Itcanbeobservedthatallthreetypehints
contributesignificantlytotheperformanceof Type4Py.Codecontext
hasthe mostimpactonthe model’sperformancecompared tothe
2248Type4Py: Practical Deep Similarity Learning-Based Type Inference for Python ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
Table 6: Performance evaluation of the neural models considering different tasks
Metric Task Approach% Exact Match % Base Type Match
All Ubiquitous Common Rare All Common Rare
Top-1 predictionArgumentType4Py 61.9 100.0 64.5 17.4 63.9 69.3 20.1
Typilus 53.8 83.3 46.6 23.7 57.0 52.5 29.6
TypeWriter 58.4 93.6 61.3 19.6 60.1 64.4 22.1
ReturnType4Py 56.4 100.0 59.3 14.4 60.3 65.4 20.9
Typilus 42.5 84.0 41.6 12.3 49.9 49.5 24.8
TypeWriter 50.7 93.3 59.9 9.2 54.1 64.4 15.0
VariableaType4Py 80.4 100.0 86.8 20.7 85.9 89.1 44.6
Typilus 71.4 95.1 80.5 22.5 80.7 89.1 48.6
MRR@10ArgumentType4Py 64.2 100.0 69.5 20.7 59.9 62.2 20.6
Typilus 58.7 87.9 55.4 27.5 56.0 52.2 28.1
TypeWriter 63.3 96.2 72.4 23.0 59.6 69.3 22.7
ReturnType4Py 57.9 100.0 63.3 16.1 52.9 55.8 18.5
Typilus 46.0 86.9 49.8 14.3 44.9 46.6 21.4
TypeWriter 54.2 95.9 68.9 10.9 49.9 65.1 14.2
VariableaType4Py 81.4 100.0 89.1 22.7 79.1 85.0 34.1
Typilus 73.7 96.3 84.7 25.1 72.4 82.7 36.1
aNotethatTypeWriter cannot predict the type of variables.
Table 7: Performance evaluation of Type4Py with differentconfigurations
Metric Approach% Exact Match % Base Type Match
All Ubiquitous Common Rare All Common Rare
Top-1 predictionType4Py 75.8 100.0 82.3 19.2 80.6 85.2 36.0
Type4Py(w/o identifiers) 72.7 100.0 71.8 17.4 76.5 73.9 30.9
Type4Py(w/o code context) 67.9 100.0 59.2 11.4 70.6 63.3 17.9
Type4Py(w/o visible type hints) 65.4 86.2 71.9 15.8 70.0 74.9 31.5
Type4Py(w/ top 1,000 types) 74.5 100.0 83.3 12.9 79.1 86.3 28.5
MRR@10Type4Py 77.1 100.0 85.1 21.4 74.1 79.9 29.4
Type4Py(w/o identifiers) 73.8 100.0 74.6 19.2 69.3 66.6 25.1
Type4Py(w/o code context) 69.7 100.0 63.9 13.6 63.8 55.4 17.7
Type4Py(w/o visible type hints) 68.6 89.3 76.2 18.2 65.8 70.1 26.2
Type4Py(w/ top 1,000 types) 75.6 100.0 86.2 14.2 72.4 81.7 22.8
othertwotypehints.Forinstance,whenignoringcodecontext,the
model’sexactmatchscoreforcommontypesdropssignificantlyby
23.1%. After code context, visible type hints have a large impact on
the performance of the model. By ignoring VTH, the model’s exact
matchforubiquitoustypesreduces from100% to 86.2%.Although
the Identifiers type hint contributes substantially to the prediction
of common types, it has a less significant impact on the overall
performance of Type4Pycompared to code context and VTH. In
summary,weconcludethatcodecontextandVTHarethestrongest
type hints for our type prediction model.Bylimitingthetypevocabularyof Type4Pytothetop1,000types,
similar to TypeWriter, we observe that the model’s performance
forcommontypesisslightlyimprovedwhileitsperformancefor
rare types is reduced significantly, i.e., 7.2% considering MRR@10.
This is expected as the model’s type vocabulary is much smaller
compared to the complete model’s.
7 Type4Py in Practice
To make the Type4Pymodel practical, we developed an end-to-end
solution including a web server and a Visual Studio Code (VSC)
extension. We deployed this as an openly accessible web service
2249ICSE ’22, May 21–29,2022, Pittsburgh,PA, USA Miret al.
Figure 5: A type auto-completion example from VSC. The code has not seen during training. The expected return type is
Optional[str] .
that serves requests from the VSC extension. In this section, we
describe the deployment components of Type4Py.
7.1 Deployment
Todeploythepre-trained Type4Pymodelforproduction,weconvert
theType4Py’sPyTorchmodeltoanONNXmodel[ 17]whichenables
querying the model on both GPUs and CPUs with faster inference
speed.ThankstoAnnoy[ 1],fastandmemory-efficientKNNsearch
is performed to suggest type annotations from type clusters.
7.2 Web Server
We have implemented asmall Flask application tohandle concur-
rent type prediction requests from users with Nginx as a proxy.
Thisenablesustohavequiteanumberofasynchronousworkers
thathaveaninstanceof Type4Py’sONNXmodelplusTypeClusters
each. Specifically, the web application receives a Python source file
via a POST request, queries an instance of the model, and finally it
gives the file’s predicted type annotations as a JSON response.
7.3 VisualStudio Code Extension
Asstatedearlier,retrofittingtypeannotationsisadauntingtaskfor
developers. To assist developers with this task, we have released a
Visual StudioCodeextensionfor Type4Py[9],which usesthe web
server’s API to provide ML-based type auto-completion for Python
code.Figure5showsanexampleofatyperecommendationfrom
theVSCIDE.Asofthiswriting,theextensionhas909installson
theVisualStudioMarketplace.Basedontheuser’sconsent,theVSC
extensiongatherstelemetrydataforresearchpurposes.Specifically,
accepted types, their rank in the list of suggestions, type slot kind,
identifiers’name,andidentifiers’linenumberarecapturedfromthe
VSC environment and sent to our web server. In addition, rejected
typepredictionsarecapturedwhenatypeauto-completionwindow
is closed without accepting a type.
ByanalyzingthegatheredtelemetrydatafromJul.’21toAug.’21
and excluding the author(s), of 26 type auto-completion queries, 19
typeannotationswereacceptedbytheextension’susers.Moreover,
the average of accepted type annotations per developer is 69.6%.
Giventhatthegatheredtelemetrydataisprettysmall,wecannot
drawaconclusionregardingtheperformanceof Type4Pyinpractice.
However, our telemetry infrastructure and concerted efforts to
broaden the user base will enable us to improve Type4Pyin the
future.8 Discussion and Future Work
Based on the formulated RQs and their evaluation in Section 6, we
provide the following remarks:
•WeusedPyre[ 6],astatictypeinferencetool,toaugmentour
datasetwithmore typeannotations.However, thiscanbecon-
sideredasa weaklysupervisionlearningproblem[ 66],meaning
thatinferredtypesbythestatictoolmightbenoisyorimprecise
despite the pre-processing steps. To eliminate this threat, we
employed a static type checker, mypy, to remove source files
with type errors from our dataset. Future work can devise a
guided-searchanalysistofixtypeerrorsinsourcefiles,which
mayimprove the fix rate.
•It would be ideal for ML-basedmodels to give a correct predic-
tion in their first few suggestions, preferably Top-1, as develop-
ers tend to use the first suggestion by a tool [ 48]. Therefore, dif-
ferentfrompreviousworkonML-basedtypeprediction[ 12,51],
weusetheMRRmetricinourevaluation.Webelievethatthe
MRRmetricbetterdemonstratesthepotentialandusefulnessof
ML models to be used by developers in practice. Overall, con-
sidering the MRR metric, Type4Pysignificantly outperforms the
state-the-art ML-based type prediction models, namely, Typilus
and TypeWriter.
•Consideringtheoveralltypepredictionperformance(RQ 1),both
Type4Pyand Typilus generally perform better than TypeWriter.
This could be attributed to the fact that the two models map
typesintoahigh-dimensionalspace(i.e.typeclusters).Hence
this not only enables a much larger type vocabulary but also
significantly improves their overall performance, especially the
prediction of rare types.
•GiventheresultsofRQ 1andRQ2,ourHNN-basedneuralmodel,
Type4Py, has empirically shown to be more effective than the
GNN-based model of Typilus. We attribute this to the inherent
bottleneckofGNNswhichisover-squashinginformationintoa
fixed-sizevector[ 13]andthustheyfailtocapturelong-rangein-
teraction.However,ourHNN-basedmodelconcatenateslearned
features into a high-dimensional vector and hence it preserves
informationand itslong-rangedependencies.
•According to the results of ablation analysis (RQ 3), the three
proposed type hints, i.e., identifiers, code context, and VTHs
are all effective and positively contribute to the performance of
2250Type4Py: Practical Deep Similarity Learning-Based Type Inference for Python ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
Type4Py.Thisresultdoesnotcomeattheexpenseofgeneraliz-
ability; our visible type analysis is not more sophisticated than
whatanIDElikePyCharmorVSCodedotodetermineavailable
types for, e.g., auto-completion purposes.
•BothType4Pyand Typilus cannot make a correct prediction for
types beyond their pre-defined (albeit very large) type clusters.
Forexample,theycurrentlycannotsynthesizetypes,meaning
thattheywillneversuggestatypesuchas Optional[Dict[str,
int]]if it does not exist in their type clusters. To address this,
future research can explore pointer networks [ 61] or a GNN
model that captures type system rules.
•We believe that Type4Py’s VSC extension is one step forward
towards improving developers’ productivity by using machine-
aided code tools. In this case, the VSC extension aids Python
developerstoretrofittypesfortheirexistingcodebases.After
gathering sufficiently large telemetry data from the usage of
Type4Py,wewillstudyhowtoimprove Type4Py’srankingand
qualityof predictions for, ultimately, a better user experience.
9 Summary
In this paper, we present Type4Py, a DSL-based hierarchical neural
networktypeinferencemodelforPython.Itconsidersidentifiers,
code context, and visible type hints as features for learning to pre-
dicttypes.Specifically,theneuralmodellearnstoefficientlymap
typesofthesamekindintotheirownclustersinahigh-dimensional
space,andgiventypeclusters,the k-nearestneighborsearchisper-
formed to infer the type of arguments, variables, and functions’
return types. We used a type-checked dataset with sound type
annotationstotrainandevaluatetheML-basedtypeinferencemod-
els. Overall, the results of our quantitative evaluation show that
theType4Pymodeloutperformsotherstate-of-the-artapproaches.
Most notably, considering the MRR@10 score, our proposed ap-
proach achieves a significantly higher score than that of Typilus
and TypeWriter’s by a margin of 8.1% and 16.7%, respectively. This
indicates that our approach gives a more relevant prediction in its
first suggestion, i.e., Top-1. Finally, we have deployed Type4Pyin
an end-to-end fashion to provide ML-based type auto-completion
inthe VSCIDEandaid developerstoretrofittype annotationsfor
theirexisting codebases.
Acknowledgments
Thisresearchwork wasfunded by H2020grant 825328(FASTEN).
Wethanktheanonymousreviewersfortheirvaluablefeedbackand
comments.
References
[1] [n.d.]. Annoy. https://github.com/spotify/annoy. Accessed on: 2022-02-08.
[2][n.d.]. CD4Py:CodeDe-DuplicationforPython. https://github.com/saltudelft/
CD4Py. Accessed on: 2022-02-07.
[3][n.d.]. IEEESpectrum’stheTopProgrammingLanguages2021. https://spectrum.
ieee.org/top-programming-languages. Accessed on: 2022-02-07.
[4][n.d.]. LibSA4Py: Light-weight static analysis for extracting type hints and
features. https://github.com/saltudelft/libsa4py. Accessed on: 2022-02-08.
[5][n.d.]. Mypy:AstatictypecheckerforPython3. https://mypy.readthedocs.io/.
Accessed on: 2022-02-07.
[6][n.d.]. Pyre:Aperformanttype-checkerforPython3. https://pyre-check.org/.
Accessed on: 2022-02-07.
[7][n.d.]. PyRight. https://github.com/microsoft/pyright. Accessed on: 2022-02-07.
[8] [n.d.]. PyType. https://github.com/google/pytype. Accessed on: 2022-02-07.
[9][n.d.]. Type4Py’sVisualStudioCodeextension. https://marketplace.visualstudio.
com/items?itemName=saltud.type4py. Accessed on: 2022-02-08.[10][n.d.]. Typilus’publicimplementation. https://github.com/typilus/typilus. Ac-
cessed on: 2022-02-08.
[11]Miltiadis Allamanis. 2019. The adverse effects of code duplication in machine
learningmodelsofcode.In Proceedingsofthe2019ACMSIGPLANInternational
SymposiumonNewIdeas,NewParadigms,andReflectionsonProgrammingand
Software. 143–153.
[12]Miltiadis Allamanis, Earl T Barr, Soline Ducousso, and Zheng Gao. 2020. Typ-
ilus: neural type hints. In Proceedings of the 41st ACM SIGPLAN Conference on
Programming Language Design and Implementation . 91–105.
[13]UriAlonandEranYahav.2020. OntheBottleneckofGraphNeuralNetworksand
itsPracticalImplications.In InternationalConferenceonLearningRepresentations .
[14]De Cheng, Yihong Gong, Sanping Zhou, Jinjun Wang, and Nanning Zheng. 2016.
Person re-identification by multi-channel parts-based cnn with improved triplet
lossfunction.In 2016IEEEConferenceonComputerVisionandPatternRecognition
(CVPR). 1335–1344.
[15]Sumit Chopra, Raia Hadsell, and Yann LeCun. 2005. Learning a similarity metric
discriminatively, with application to face verification. In 2005 IEEE Computer
Society Conference on Computer Vision and Pattern Recognition (CVPR’05) , Vol. 1.
IEEE,539–546.
[16]Thomas Cover and Peter Hart. 1967. Nearest neighbor pattern classification.
IEEEtransactionson information theory 13,1 (1967), 21–27.
[17] ONNXRuntimedevelopers. 2021. ONNX Runtime. https://onnxruntime.ai/.
[18]YongDu,WeiWang,andLiangWang.2015. Hierarchicalrecurrentneuralnet-
work for skeleton based action recognition. In 2015 IEEE Conference on Computer
VisionandPatternRecognition (CVPR) . 1110–1118.
[19]Michael Furr, Jong-hoon An, Jeffrey S Foster, and Michael Hicks. 2009. Static
typeinferenceforRuby.In Proceedingsofthe2009ACMsymposiumonApplied
Computing . 1859–1866.
[20]ZhengGao,ChristianBird,andEarlTBarr.2017. Totypeornottotype:quantify-
ingdetectablebugsinJavaScript.In 2017IEEE/ACM39thInternationalConference
on Software Engineering (ICSE) . IEEE, 758–769.
[21]LuísPFGarcia,AndréCPLFdeCarvalho,andAnaCLorena.2015. Effectoflabel
noiseinthecomplexityofclassificationproblems. Neurocomputing 160(2015),
108–119.
[22]Ian Goodfellow, Yoshua Bengio, AaronCourville,and Yoshua Bengio.2016. Deep
learning. Vol. 1. MIT press Cambridge.
[23]StefanHanenberg,SebastianKleinschmager,RomainRobbes,ÉricTanter,and
Andreas Stefik. 2014. An empirical study on the impact of static typing on
softwaremaintainability. EmpiricalSoftwareEngineering 19,5(2014),1335–1382.
[24]Mostafa Hassan, Caterina Urban, Marco Eilers, and Peter Müller. 2018. Maxsmt-
basedtypeinferenceforpython3.In InternationalConferenceonComputerAided
Verification . Springer, 12–19.
[25]Xincheng He, Lei Xu, Xiangyu Zhang, Rui Hao, Yang Feng, and Baowen Xu.
2021. PyART:PythonAPIRecommendationinReal-Time.In 2021IEEE/ACM43rd
InternationalConferenceon Software Engineering (ICSE) . IEEE, 1634–1645.
[26]VincentJHellendoorn,ChristianBird,EarlTBarr,andMiltiadisAllamanis.2018.
Deeplearningtypeinference.In Proceedingsofthe26thACMJointMeetingon
European Software Engineering Conference and Symposium on the Foundations of
Software Engineering . 152–162.
[27]AbramHindle,EarlTBarr,ZhendongSu,MarkGabel,andPremkumarDevanbu.
2012. On the naturalness of software. In 2012 34th International Conference on
Software Engineering (ICSE) . IEEE, 837–847.
[28]SeppHochreiterandJürgenSchmidhuber.1997.Longshort-termmemory. Neural
computation 9, 8 (1997), 1735–1780.
[29]Kevin Jesse, Premkumar T Devanbu, and Toufique Ahmed. 2021. Learning type
annotation: is big data enough?. In Proceedings of the 29th ACM Joint Meeting on
European Software Engineering Conference and Symposium on the Foundations of
Software Engineering . 1483–1486.
[30]Daniel Jurafsky and James H. Martin. 2009. Speechand Language Processing (2nd
Edition). Prentice-Hall, Inc., USA.
[31]Faizan Khan, Boqi Chen, Daniel Varro, and Shane Mcintosh. 2021. An Empirical
Study of Type-Related Defects in Python Projects. IEEE Transactions on Software
Engineering (2021).
[32]Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic opti-
mization. arXivpreprint arXiv:1412.6980 (2014).
[33] J Lehtosalo et al. 2017. Mypy-optional static typing for python.
[34]Wentong Liao, Michael Ying Yang, Ni Zhan, and Bodo Rosenhahn. 2017. Triplet-
based deep similarity learning for person re-identification. In Proceedings of the
IEEEInternationalConferenceon Computer Vision Workshops . 385–393.
[35]FaguiLiu,LaileiZheng,andJingzhongZheng.2020. HieNN-DWE:Ahierarchical
neuralnetworkwithdynamicwordembeddingsfordocumentlevelsentiment
classification. Neurocomputing 403(2020),21–32.
[36]Xiaoyu Liu, LiGuo Huang, and Vincent Ng. 2018. Effective API recommendation
without historical software repositories. In Proceedings of the 33rd ACM/IEEE
InternationalConferenceon Automated Software Engineering . 282–292.
[37]Edward Loper and Steven Bird. 2002. NLTK: The Natural Language Toolkit.
InProceedingsoftheACL-02WorkshoponEffectiveToolsandMethodologiesfor
2251ICSE ’22, May 21–29,2022, Pittsburgh,PA, USA Miret al.
Teaching Natural Language Processing and Computational Linguistics . 63–70.
[38]Cristina VLopes, Petr Maj,Pedro Martins, Vaibhav Saini,Di Yang, Jakub Zitny,
HiteshSajnani,andJanVitek.2017. DéjàVu:amapofcodeduplicatesonGitHub.
Proceedings of the ACM on Programming Languages 1, OOPSLA (2017), 1–28.
[39]Magnus Madsen. 2015. Static analysis of dynamic languages . Ph.D. Dissertation.
Aarhus University.
[40]Eva Maia, Nelma Moreira, and Rogério Reis. 2012. A static type inference for
python.Proceedings of the 6th Workshop on Dynamic Languages and Applications
5, 1 (2012), 1.
[41]Rabee Sohail Malik, Jibesh Patra, and Michael Pradel. 2019. NL2Type: inferring
JavaScript function types from natural language information. In 2019 IEEE/ACM
41stInternationalConferenceon Software Engineering (ICSE) . IEEE, 304–315.
[42]Christopher D Manning, Hinrich Schütze, and Prabhakar Raghavan. 2008. Intro-
ductionto information retrieval . Cambridge university press.
[43]TomasMikolov,IlyaSutskever,KaiChen,GregSCorrado,andJeffDean.2013.
Distributed representations of words and phrases and their compositionality. In
Advances in neural information processing systems . 3111–3119.
[44]Nevena Milojkovic, Mohammad Ghafari, and Oscar Nierstrasz. 2017. Exploiting
type hints in method argument names to improve lightweight type inference. In
2017 IEEE/ACM 25th International Conference on Program Comprehension (ICPC) .
IEEE,77–87.
[45]Amir M.Mir,Evaldas Latoskinas,and Georgios Gousios.2021. ManyTypes4Py:
ABenchmarkPythonDatasetforMachineLearning-BasedTypeInference.In
IEEE/ACM18thInternationalConferenceonMiningSoftwareRepositories(MSR) .
IEEE ComputerSociety,585–589. https://doi.org/10.1109/MSR52588.2021.00079
[46]John-Paul Ore, Sebastian Elbaum, Carrick Detweiler, and Lambros Karkazis.
2018. Assessingthetypeannotationburden.In Proceedingsofthe33rdACM/IEEE
InternationalConferenceon Automated Software Engineering . 190–201.
[47]Irene Vlassi Pandi, Earl T Barr, Andrew D Gordon, and Charles Sutton. 2020.
OptTyper: Probabilistic Type Inference by Optimising Logical and Natural Con-
straints.arXivpreprint arXiv:2004.00348 (2020).
[48]ChrisParninandAlessandroOrso.2011. Areautomateddebuggingtechniquesac-
tually helping programmers?. In Proceedings of the 2011 international symposium
on software testing and analysis . 199–209.
[49]AdamPaszke,SamGross,FranciscoMassa,AdamLerer,JamesBradbury,Gregory
Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al .
2019. Pytorch: An imperative style, high-performance deep learning library. In
Advances in neural information processing systems . 8026–8037.
[50]Zvonimir Pavlinovic. 2019. Leveraging Program Analysis for Type Inference . Ph.D.
Dissertation.New York University.
[51]MichaelPradel, Georgios Gousios, Jason Liu, and Satish Chandra. 2020. Type-
writer: Neural type prediction with search-based validation. In Proceedings of
the 28th ACM Joint Meeting on European Software Engineering Conference and
Symposiumon the Foundations of Software Engineering . 209–220.
[52]IngkaratRak-amnouykit,DanielMcCrevan,AnaMilanova,MartinHirzel,and
Julian Dolby. 2020. Python 3 types in the wild: a tale of two type systems. In
Proceedings of the 16th ACM SIGPLAN International Symposium on Dynamic
Languages . 57–70.
[53]GuozhengRao,WeihangHuang,ZhiyongFeng,andQiongCong.2018. LSTM
with sentence representations for document-level sentiment classification. Neu-
rocomputing 308(2018),49–57.
[54]BaishakhiRay,DarylPosnett,VladimirFilkov,andPremkumarDevanbu.2014.
A large scale study of programming languages and code quality in github. In
Proceedingsofthe22ndACMSIGSOFTInternationalSymposiumonFoundationsof
Software Engineering . 155–165.
[55]Veselin Raychev, Martin Vechev, and Andreas Krause. 2015. Predicting program
properties from big code. In ACM SIGPLAN Notices , Vol. 50. ACM, 111–124.
[56]MichaelSalib.2004. FasterthanC:StatictypeinferencewithStarkiller. inPyCon
Proceedings, Washington DC (2004),2–26.
[57]Mike Schuster and Kuldip K Paliwal. 1997. Bidirectional recurrent neural net-
works.IEEEtransactionson Signal Processing 45,11 (1997), 2673–2681.
[58]Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan
Salakhutdinov.2014. Dropout:asimplewaytopreventneuralnetworksfrom
overfitting. Thejournalof machine learning research 15,1 (2014), 1929–1958.
[59]Andreas StuchlikandStefan Hanenberg.2011. Static vs.dynamic typesystems:
anempiricalstudyabouttherelationshipbetweentypecastsanddevelopment
time.InProceedings of the 7th symposium on Dynamic languages . 97–106.
[60]Guido Van Rossum, Jukka Lehtosalo, and Lukasz Langa. 2014. PEP 484–type
hints.Index of Python Enhancement Proposals (2014).
[61]OriolVinyals,MeireFortunato,andNavdeepJaitly.2015. Pointernetworks.In
Advances in neural information processing systems . 2692–2700.
[62] Jiayi Wei, Maruth Goyal, Greg Durrett, and Isil Dillig. 2019. LambdaNet: Proba-
bilisticTypeInferenceusingGraphNeuralNetworks.In InternationalConference
on Learning Representations .
[63]Ronald J Williams and David Zipser. 1989. A learning algorithm for continually
runningfullyrecurrentneuralnetworks. Neuralcomputation 1,2(1989),270–280.
[64]ZhaoguiXu,XiangyuZhang,LinChen,KexinPei,andBaowenXu.2016. Python
probabilistic type inference with natural language support. In Proceedings of the2016 24th ACM SIGSOFT International Symposium on Foundations of Software
Engineering . ACM, 607–618.
[65]JianmingZheng,FeiCai,WanyuChen,ChongFeng,andHonghuiChen.2019.
Hierarchical neural representation fordocument classification. Cognitive Com-
putation11,2 (2019), 317–327.
[66]Zhi-HuaZhou.2018. Abriefintroductiontoweaklysupervisedlearning. National
sciencereview 5, 1 (2018), 44–53.
2252