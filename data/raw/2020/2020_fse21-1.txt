Context-Aware and Data-Driven Feedback Generation for
Programming Assignments
Dowon Song
Korea University
Republic of Korea
dowon_song@korea.ac.krWoosuk Lee
Hanyang University
Republic of Korea
woosuk@hanyang.ac.krHakjoo Ohâˆ—
Korea University
Republic of Korea
hakjoo_oh@korea.ac.kr
ABSTRACT
Recently, various techniques have been proposed to automatically
provide personalized feedback on programming exercises. The cut-
ting edge of which is the data-driven approaches that leverage a
corpus of existing correct programs and repair incorrect submis-
sions by using similar reference programs in the corpus. However,
current data-driven techniques work under the strong assumption
that the corpus contains a solution program that is close enough
to the incorrect submission. In this paper, we present Cafe , a new
data-driven approach for feedback generation that overcomes this
limitation. Unlike existing approaches, Cafe uses a novel context-
aware repair algorithm that can generate feedback even if the in-
correct program differs significantly from the reference solutions.
We implemented Cafe for OCaml and evaluated it with 4,211 real
student programs. The results show that Cafe is able to repair 83%
of incorrect submissions, far outperforming existing approaches.
CCS CONCEPTS
â€¢Software and its engineering â†’Automatic programming .
KEYWORDS
Program Repair, Program Synthesis
ACM Reference Format:
Dowon Song, Woosuk Lee, and Hakjoo Oh. 2021. Context-Aware and Data-
Driven Feedback Generation for Programming Assignments. In Proceed-
ings of the 29th ACM Joint European Software Engineering Conference and
Symposium on the Foundations of Software Engineering (ESEC/FSE â€™21), Au-
gust 23â€“28, 2021, Athens, Greece. ACM, New York, NY, USA, 13 pages.
https://doi.org/10.1145/3468264.3468598
1 INTRODUCTION
In recent years, there has been a surge of interest in automatic
feedback generation for programming assignments [ 1,5,12,19,20,
22,33,35,36,39,40,43]. As the demand for programming education
grows, it is becoming increasingly difficult for an instructor to
provide personalized feedback to a large number of students. Simply
âˆ—Corresponding author
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece
Â©2021 Association for Computing Machinery.
ACM ISBN 978-1-4503-8562-6/21/08. . . $15.00
https://doi.org/10.1145/3468264.3468598providing an instructorâ€™s solution as feedback is unsatisfactory, as
studentsâ€™s attempts typically diverge from the reference solution.
The goal of automatic feedback generation technology is to help
students to understand what they did wrong and how to fix it
without manual effort of instructors.
Data-Driven Feedback Generation .Among prior techniques,
data-driven approaches [ 12,17,34,42,43] are arguably the current
state-of-the-art. The main idea of these techniques is to leverage a
corpus of existing correct programs, and repair an incorrect pro-
gram by using similar reference solutions in the corpus. In contrast
to approaches that require intervention of instructors [ 5,19,39],
data-driven techniques are fully automatic and yet show impressive
performance in repairing introductory programming exercises.
However, existing data-driven techniques have a significant
shortcoming. That is, they rely on a strong assumption that the
corpus contains a solution program that is close to the incorrect
program. For example, two notable techniques, Clara [12] and
Sarfgen [43], assume a solution exists that is equivalent to the
incorrect program modulo control flows. This assumption, how-
ever, does not hold always [ 22], especially when providing feedback
beyond introductory-level exercises. In this case, constructing a
corpus with the close-program assumption becomes a challenge.
Our Approach .In this paper, we present Cafe , a new data-
driven feedback generation technique that overcomes the above
limitation. Unlike existing approaches, Cafe can generate feedback
even when the incorrect submission is substantially different from
reference solutions.
The keystone of Cafe is its context-aware, function-level repair
algorithm. Cafe primarily targets sizable programming exercises,
where students are freely allowed to define and use their own helper
functions. To repair such a program, Cafe does not seek to find
a solution program that matches the submission in its entirety;
instead, it leverages multiple, partially-matching references. More
specifically, Cafe works at the function level, aiming to separately
repair each function in the incorrect program by (1) finding a match-
ing function from the corpus, (2) computing their difference, and (3)
extracting a patch from the difference. A main challenge with this
approach is how to find the matching function that is useful for re-
pair. Our key idea to solve this problem is to infer and compare the
original intent of the functions by analyzing their calling contexts in
the respective programs, which robustly identifies useful references
even when functions have different syntax and semantics.
We evaluated Cafe in a real classroom setting. The original moti-
vation of this work was to develop a feedback generation system for
our own programming course, where we use OCaml and newcom-
ers to functional programming often have a hard time. Thus, weESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece Dowon Song, Woosuk Lee, and Hakjoo Oh
implemented Cafe for OCaml and evaluated it with 664 incorrect
and 3,547 correct student programs collected from the course over
the past few years. In total, Cafe successfully repaired 83% (548/664)
of incorrect submissions, vastly outperforming FixML [22], a recent
feedback generation technique for OCaml, whose fix rate was 35%
(234/664). We also confirmed that existing data-driven approaches
are ineffective for our dataset; replacing our context-aware ap-
proach by the matching algorithm of Sarfgen [43] decreased the
fix rate from 83% to 59%. Finally, we conducted a user study, which
shows Cafe is actually helpful for students.
Contributions .We summarize our contributions below:
â€¢We present Cafe , a new context-aware and data-driven feed-
back generation technique for programming assignments.
â€¢We evaluate Cafe in a realistic setting and make the tool
and benchmarks publicly available.1
2 OVERVIEW
2.1 Motivating Example
Let us consider a programming exercise asking students to write
a function diff: aexp * string -> aexp , which takes an arith-
metic expression ( aexp ) and a variable name ( string ), and per-
forms symbolic differentiation. Arithmetic expressions are defined
in OCaml datatype as follows:
type aexp = Const of int | Var of string | Power of (string * int)
| Sum of aexp list | Times of aexp list
An arithmetic expression is either constant integer ( Const ), vari-
able ( Var), exponentiation ( Power ), sum of arithmetic expressions
(Sum), or product of arithmetic expressions ( Times ). The function
diff should produce an expression that results from differentiat-
ing the given expression with respect to the given variable. For
example, diff (Sum [Power ("x", 2); Const 1], "x") , i.e.,
differentiating ğ‘¥2+1w.r.t.ğ‘¥, outputs Times [Const 2; Var "x"]
denoting 2âˆ—ğ‘¥.
Figure 1 shows an incorrect program written by a student in
our class, which implements diff with three helper functions:
timediff ,sumdiff , and differ . The functions timediff andsumdiff
are intended to compute the derivatives of the product and sum
ofaexp lists, respectively. The function differ performs actual
differentiation using timediff andsumdiff , and handles other
base cases. Note that the program erroneously handles the case
of multiplication ( Times ). For example, diff (Times [Var "x";
Var "y"], "x") produces Times [Const 1; Const 0] , while the
expected answer is Var "y" .
Despite its simple manifestation, fixing the bug correctly and
providing right feedback is nontrivial even for instructors. For
correct repair, we need to change three places. First, the student
implemented timediff based on a wrong product rule, (ğ‘“Â·ğ‘”)â€²=
ğ‘“â€²Â·ğ‘”â€², and therefore the body of timediff needs to be rewritten
based on the proper rule, i.e., (ğ‘“Â·ğ‘”)â€²=ğ‘“â€²Â·ğ‘”+ğ‘“Â·ğ‘”â€². Second, we need
to rewrite sumdiff because it depends on the incorrect definition
oftimediff . Finally, the last line of differ (line 18) should be
changed in accordance with the correct product rule.
1https://github.com/kupl/LearnMLGiven the buggy program, test cases, and a corpus of 218 solution
programs, Cafe repaired the program as shown in Figure 1 in 5 sec.
To use the proper product rule, it replaced lines 4â€“6 of timediff
by line 7 and line 18 of differ by line 19. Then, it modified the
body of sumdiff to reflect the change. Note that the generated
repair is not only correct but also instructive; indeed, it is identical
to what we would manually provide to the student. For example,
Cafe shows that the redundancy between sumdiff anddiffer
can be effectively eliminated by making a recursive call to diff .
Compared to existing data-driven techniques [ 12,34,42,43], the
most distinguishing feature of Cafe is its ability to generate feed-
back by collectively using multiple, dissimilar reference solutions.
Each of timediff ,sumdiff , and differ in Figure 1 was fixed us-
ing different solutions; Cafe repaired timediff using gettimes
in Figure 2(a), sumdiff using diff_sum in Figure 2(b), and differ
using diffh in Figure 2(c). All of these reference programs are
substantially different from the program in Figure 1, as none of the
218 solutions in our corpus had a matching control-flow structure,
which implies that existing data-driven techniques [ 12,34,42,43]
would fail to generate the desired feedback.
2.2 How Cafe Works
Now we discuss the high-level ideas of our approach on the
student attempts to apply : â€œGiven a list lof integers and a target
operation oâˆˆ{ADD,SUB}, write a function that increments (resp.
decrements) each element of lby1if the operation is addition,
i.e.,o=ADD(resp. subtraction, i.e., o=SUB)â€. Figure 3aâ€“3c show
three student submissions of the programming assignment: ğ‘ƒis
incorrect, while ğ‘ƒ1andğ‘ƒ2are functionally correct. We differently
name the top-level functions that the three submissions implement
to distinguish them ( ğ‘ƒ:apply ,ğ‘ƒ1:apply1 , and ,ğ‘ƒ2:apply2 ).
Our goal is to automatically generate modifications that make
the incorrect submission ğ‘ƒcorrect as a guided feedback by using
the existing correct student solutions ğ‘ƒ1andğ‘ƒ2. The program ğ‘ƒis
functionally wrong in decrementing list elements. We can correct
ğ‘ƒby (i) modifying the expression h+1at line 7 to be h-1and (ii)
changing (dec_all tl) at line 13 to (hd-1)::(dec_all tl) .
Context-Aware Matching .The first step is to find a matching
relation between functions in the student submissions. We say that
two functions ğ‘“andğ‘”match, written ğ‘“âˆ¼ğ‘”if the functions are
invoked and call other functions under compatible contexts . Here, we
mean contexts by conditions over execution paths when function
calls occur. We say two path conditions compatible if there exists
an input that exercises both of the two execution paths.
Based on this notion, Cafe finds the following matching relation:
inc_allâˆ¼add_list,dec_allâˆ¼sub_list , and applyâˆ¼apply1 .
We consider two types of function contexts: (a) incoming contexts
describing under what path conditions the function is invoked by
other functions, and (b) outgoing contexts describing under what
conditions the function invokes other functions. For example, the
incoming contexts of dec_all ,add_list , and sub_list (denoted
ğ›¿dec_all,ğ›¿add_list, andğ›¿sub_list, respectively) are as follows:
ğ›¿dec_allâ‰¡i=(l,o)âˆ§l=(hd::tl)âˆ§( o=SUB)
ğ›¿add_listâ‰¡i=(l1,o1)âˆ§l1=(hd1::tl1)âˆ§( o1=ADD)
ğ›¿sub_listâ‰¡i=(l2,o2)âˆ§l2=(hd2::tl2)âˆ§( o1=SUB)Context-Aware and Data-Driven Feedback Generation for Programming Assignments ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece
1let rec diff (e,x) =
2let rec timediff (tlst,x) =
3 match tlst with [] -> [] | hd::tl ->
4(-) (match hd with Const c -> (Const c)::timediff(tl,x)
5(-) | Var v -> if v=x then (Const 1)::timediff(tl,x) else (Const 0)::timediff(tl,x)
6(-) | Power (v,c) -> if v=x then (Times[Const c;Power(v,c-1)])::timediff(tl,x) else (Const 0)::timediff(tl,x))
7(+) if tl=[] then [diff (hd, x)] else [Times ([diff (hd, x)]@tl)] @ [Times ([hd]@[Sum (timediff (tl, x))])]
8in let rec sumdiff (slst,x) =
9 match slst with [] -> [] | hd::tl ->
10(-) (match hd with Const c -> (Const 0)::(sumdiff (tl,x))
11(-) | Var v -> if v=x then (Const 1)::(sumdiff (tl,x)) else (Const 0)::(sumdiff (tl,x))
12(-) | Power (v,c) -> if v=x then (Times [Const c;Power(v,c-1)])::(sumdiff (tl,x)) else (Const 0)::(sumdiff (tl,x))
13(-) | Sum lst -> (Sum (sumdiff (lst,x)))::(sumdiff (tl,x)) | Times lst -> (Times (timediff (lst,x)))::(sumdiff (tl,x)))
14(+) (diff (hd, x))::(sumdiff (tl, x))
15 in let rec differ (e,x) =
16 match e with Const c -> Const 0 | Var v -> if v=x then Const 1 else Const 0
17 | Power (v,c) -> if v=x then Times [Const c;Power(v,c-1)] else Const 0 | Sum lst -> Sum (sumdiff (lst,x))
18(-) | Times lst -> Times (timediff (lst,x))
19(+) | Times lst -> Sum (timediff (lst,x))
20 in differ (e, x)
Figure 1: A real incorrect student submission and the feedback generated by Cafe
1let rec check (l, str) = ...
2let rec diff (aexp, str) = ...
3and gettimes (l, str) =
4match l with | [] -> [] | hd::tl ->
5if tl=[] then [diff (hd, str)] ...
6and getsum (l, str) = ...
(a) Program used to fix timediff1let rec diff (e, x) = ...
2and diff_sum (lst, key) =
3match lst with hd::tl -> ...
4and diff_time (lst, key, x, y) =
5let rec f (lst, key, p, q) = ... in
6 if x > y then [] else ...
(b) Program used to fix sumdiff1let rec diff (aexp, str) =
2let rec diffh (aexp, str) = ...
3 | Sum l -> Sum (sum (l, str))
4and times (aexp, str, acc) = ...
5and sum (aexp, str) = ...
6in diffh (aexp, str)
(c) Program used to fix differ
Figure 2: Three different solution programs chosen by Cafe to repair the program in Figure 1
1let rec inc_all l =
2match l with [] -> []
3| h::t -> (h+1)::(inc_all t)
4
5let rec dec_all l =
6match l with [] -> []
7| h::t -> (h+1)::(dec_all t)
8
9let apply ((l, o) as i) =
10 match l with [] -> []
11 | hd::tl -> match o with
12 | ADD -> (hd+1)::(inc_all tl)
13 | SUB -> (dec_all tl)
(a) Incorrect program ( ğ‘ƒ)1let rec add_list l 1=
2match l 1with [] -> []
3| h 1::t 1-> (h 1+1)::(add_list t 1)
4
5
6
7
8
9let rec apply1 ((l 1, o 1) as i) =
10 match l 1with [] -> [] | hd 1::tl 1->
11 let i '= (tl 1,o) in match o 1with
12 | ADD -> (hd 1+1)::(add_list tl 1)
13 | SUB -> (hd 1-1)::(apply1 i ')
(b) Correct program ( ğ‘ƒ1)1let id x = x
2
3
4
5let rec sub_list l 2=
6match l 2with [] -> []
7| h 2::t 2-> (h 2-1)::(sub_list t 2)
8
9let rec apply2 ((l 2, o 2) as i) =
10 match l 2with [] -> id []
11 | hd 2::tl 2-> match o 2with
12 | ADD->(hd 2+1)::(apply2 (tl 2, o 2))
13 | SUB->(hd 2-1)::(sub_list tl 2)
(c) Correct program ( ğ‘ƒ2)
Figure 3: A running example to illustrate how Cafe works
where iis called input variable representing the input simultane-
ously provided to the top-level functions. Over these contexts, Cafe
concludes dec_allâˆ¼sub_list because the formula ğ›¿dec_allâˆ§
ğ›¿sub_list is satisfiable meaning that there exists a value for ithat
leads to invoking both functions. On the other hand, Cafe concludes
dec_allâ‰add_list because the formula ğ›¿dec_allâˆ§ğ›¿add_list is
unsatisfiable (âˆµSUBâ‰ ADD) meaning that there is no value for
ithat results in invoking both functions. After a similar process,Cafe concludes inc_allâˆ¼add_list . Also, based on outgoing
contexts, Cafe concludes applyâˆ¼apply1 .
Note that context-aware matching differs crucially from conven-
tional syntactic or semantic matching used in prior data-driven
techniques [ 12,34,42,43]. For example, existing approaches would
match dec_all with add_list because they are equivalent in syn-
tax and semantics. However, this matching is undoubtedly useless;ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece Dowon Song, Woosuk Lee, and Hakjoo Oh
we need to find a function useful for repair, rather than merely
finding similar one.
Extracting Repair Templates .Next, Cafe learns fixes for each
function in a buggy submission from its corresponding function in
a correct submission. We support insertion/deletion of conditional
branches, modifying subexpressions, and adding new function defi-
nitions. Especially, changing control flows and defining new func-
tions are beyond the capability of the state-of-the-art feedback
generation systems.
We learn such a fix by extracting a repair template from the
correct submissions and instantiating it to be fit into the buggy sub-
mission. Cafe learns a repair template by syntactically differencing
matched functions. For example, Cafe identifies a discrepancy be-
tween the subexpression h+1indecl_all andh2-1insub_list ,
and derives the template
Modify(7,h+1â†’â–¡intâˆ’1) (1)
which means one way to fix ğ‘ƒis to replace the expression h+1at
line 7 by an expression of the form â–¡int-1whereâ–¡intcan be filled
by some integer variable. Similarly, Cafe produces the following
template by differencing apply andapply1 :
Modify(13,dec_all tlâ†’(â–¡intâˆ’1)::(â–¡int listÃ—ğœ
â†’int listâ–¡int listÃ—ğœ))
(2)
whereğœdenotes the algebraic data type for ADDorSUB.
Instantiating Templates .Next Cafe instantiates the templates
by filling the holes with proper variables to obtain concrete fixes.
Each hole with a type is filled with a variable available at the loca-
tion with the same type. From the template (1), Modify(7,h+1â†’
hâˆ’1)is generated because his the only available integer variable
at line 7, which is correct. From the template (2), the first hole can
be filled with hdbecause it is the only available integer variable at
line 13, and the following partially completed template is obtained.
Modify(13,dec_all tlâ†’(hdâˆ’1)::(â–¡int listÃ—ğœ
â†’int listâ–¡int listÃ—ğœ))
Unfortunately, there is no variable of type int listÃ—ğœâ†’int list
(apply is unavailable as it is not recursive). In such a case, we just
enumerate all function identifiers as candidates for the hole and
obtain the partially completed templates:
Modify(13,dec_all tlâ†’(hdâˆ’1)::(dec_allâ–¡int list))
Modify(13,dec_all tlâ†’(hdâˆ’1)::(inc_allâ–¡int list))
Note that the annotated type of the last hole has been changed in
accordance with the type of dec_all andinc_all . The last hole is
filled with tl, which is an available variable of type int list . Finally,
we obtain the following set A:
ï£±ï£´ï£´ ï£²
ï£´ï£´ï£³Modify(7,h+1â†’hâˆ’1),
Modify(13,dec_all tlâ†’(hdâˆ’1)::(dec_all tl)),
Modify(13,dec_all tlâ†’(hdâˆ’1)::(inc_all tl))ï£¼ï£´ï£´ ï£½
ï£´ï£´ï£¾
Finding a Patch .By trying each subset of A,Cafe finds that
applying the first two fixes in sequence corrects the buggy submis-
sion. Note that Cafe produced a patch that preserves the original
intent of the program as much as possible by using the existing
helper function dec_all instead of simply removing it and making
apply recursive.3 PROBLEM DEFINITION
In this section, we define our problem of data-driven feedback
generation for programming assignments. We first define a pro-
gram model that captures key aspects of Meta Language (ML)-like
languages and introduce notations that allow us to formalize our
algorithm in the next section.
Language .To formalize our approach, we consider an idealized
functional language similar to the core of ML, with the additional
property that we label all expressions. Our target language fea-
tures algebraic data types and recursive functions. A program is an
expression defined as follows:
ğ‘’âˆˆExp (Expressions) ğ‘¥âˆˆVId (Variables)
ğ‘“âˆˆFId (Functions) Id=VIdâˆªFId (Identifiers)
â„“âˆˆLabel (Labels) ğœâˆˆType (Types)
ğ‘’::=ğ‘›|ğ‘¥|ğœ†ğ‘¥.ğ‘’|ğ‘’1âŠ•ğ‘’2|ğ‘’1ğ‘’2|ğœ…(ğ‘’1,Â·Â·Â·,ğ‘’ğ‘(ğœ…))
|ğœ…âˆ’ğ‘–(ğ‘’)|letğ‘¥=ğ‘’1inğ‘’2|let recğ‘“(ğ‘¥)=ğ‘’1inğ‘’2
|matchğ‘’withğ‘ğ‘–â†’ğ‘’ğ‘–ğ‘˜
ğ‘::=ğœ…(ğ‘¥1,Â·Â·Â·,ğ‘¥ğ‘›)|_ğœ::=int|ğ‘‡|ğœ1â†’ğœ2
We assume each expression is associated with a unique label. Ex-
pressionğ‘’associated with a label â„“âˆˆL is denoted by ğ‘’â„“. For the
sake of better readability, we will often elide â„“when the label is not
necessary for discussion. In addition, when we determine equality
of two expressions, we do not consider their labels and only check
if they are syntactically equivalent.
The syntax of expressions is standard: application is written
ğ‘’1ğ‘’2,ğœ…ranges over data type constructors, ğ‘(ğœ…)denotes the arity
ofğœ…,ğœ…âˆ’ğ‘–denotes a destructor which extracts the ğ‘–-th subcompo-
nent of a constructor ğœ…, and letbindings for variables and recursive
functions are allowed. For conciseness, we assume that all func-
tions take a single argument and are not mutually recursive (our
implementation in Section 5 is not limited by these restrictions
though). We use ML-style pattern match expressions in which each
patternğ‘binds subcomponents of a constructor ğœ…, or the under-
score (_) called the wildcard pattern. We use ğ‘ğ‘–â†’ğ‘’ğ‘–ğ‘˜to denote
ğ‘1â†’ğ‘’1| Â·Â·Â· |ğ‘ğ‘˜â†’ğ‘’ğ‘˜. Types include the integer type int,
user-defined algebraic data types ğ‘‡, and function types ğœ1â†’ğœ2.
We will use some notations regarding expressions throughout
the remaining sections. We use âˆ’â†’âˆ—to denote the standard multi-
step call-by-value operational relation. To denote the set of all
subexpressions of expression ğ‘’, we will use Sub(ğ‘’). The size of
expressionğ‘’will be denoted by|ğ‘’|. Identifiers of functions defined in
an expression ğ‘’will be denoted by functions(ğ‘’)(i.e.,functions(ğ‘’)=
{ğ‘“âˆˆFId|let recğ‘“(ğ‘¥)=ğ‘’1inğ‘’2âˆˆSub(ğ‘’)}). Identifiers used in an
expressionğ‘’will be denoted by vars(ğ‘’).
Setting .We assume that each student submission ğ‘ƒâˆˆExphas
no type error, and is in the following form: let recğ‘“(ğ‘¥)=ğ‘’inğ‘“ ğ‘¥ğœ„
whereğ‘“is a top-level function that the student is asked to imple-
ment, andğ‘¥ğœ„is a special variable which we call input variable . In
Fig. 3a â€“ 3c, apply ,apply1 , and apply2 are the top-level functions,
and the variable ican be regarded as the input variable. For con-
vinience, we also assume that all labels and identifiers in the pile of
entire submissions are unique with exception of the input variable
that all the submissions have in common. This assumption enablesContext-Aware and Data-Driven Feedback Generation for Programming Assignments ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece
to use the following global functions: (1) body :FIdâ†’Expthat re-
turns the body of a function, (2) param :FIdâ†’VIdthat returns the
parameter variable of a function, and (3) type :(LabelâˆªId)â†’ Type
that returns the type of an expression with a given label or a vari-
able.
Problem .Assuming some (possibly infinite) set Valof values,
a set of test cases T âŠ† ValÃ—Valis used to determine the cor-
rectness of each submission. The submission ğ‘ƒis correct (denoted
correct(ğ‘ƒ,T)) iffâˆ€(ğ‘–,ğ‘œ) âˆˆT.(ğœ†ğ‘¥ğœ„. ğ‘ƒ)ğ‘–âˆ’â†’âˆ—ğ‘œ.Otherwise, the
submission is buggy.
Our problem is defined as follows: given a buggy submission
ğ‘ƒğ‘âˆˆExp, a corpus of correct submissions Pğ‘âŠ†Exp, and a set
of test casesT, derive a correct submission ğ‘ƒâˆ‰Pğ‘fromğ‘ƒğ‘with
minimal changes (the notion of the minimality will be detailed in
Section 4.2.3).
4 ALGORITHM
In this section, we describe our data-driven feedback generation
algorithm. Section 4.1 formalizes calling contexts and how to find
a matching relation between functions. Section 4.2 describes the
repair algorithm that extracts repair templates from reference func-
tions and uses them to correct a buggy submission.
4.1 Context-Aware Matching
We formally define the notion of context-aware matching. From
each function call in all the given submissions, we collect calling
contexts. A context ğ›¿âˆˆCtxis a path condition on the input variable
under which a function is invoked. Formally, path conditions are
defined below:
ğ›¿::=true|false|ğ‘’=ğ‘’|Â¬ğ›¿|ğ›¿âˆ§ğ›¿.
Calling contexts are defined as follows:
Definition 4.1 (Calling context). A calling context is a triple âŸ¨ğ‘“,ğ›¿,ğ‘”âŸ©âˆˆ
FIdÃ—CtxÃ—FIdwhereğ‘“is a function, ğ‘”is another function called in
the body of ğ‘“, andğ›¿is a path condition under which the function
call happens.
We first perform a path-sensitive 0-CFA on all the submissions to
obtain calling contexts. Like the standard 0-CFA [ 32], the analysis
information at any given expression is the set of possible evaluation
results of the expression. Here, evaluation results are expressions in
which the input variable is a free variable. We add path sensitivity
by making our analysis track information separately for different
execution paths. The analysis computes a dataflow state ğœâˆˆ(Idâˆª
Label)Ã—Ctxâ†’P( Exp)âˆª{âŠ¤}.
Figure 4 depicts a subset of the constraint generation rules; the
full set can be found in the supplementary material. The judge-
mentğ›¿âŠ¢âŸ¦ğ‘’âŸ§â„“â†©â†’ğ¶can be read as â€œthe analysis of expression ğ‘’
with labelâ„“generates set constraints ğ¶over dataflow state ğœunder
a current path condition ğ›¿â€. While solving the constraints via a
least-fix point computation, special constraints of kinds fn,cn, and
patare interpreted by the constraint solver to generate additional
concrete constraints by referring to an intermediate analysis result.
For example, from a constraint fnğ›¿â„“1:â„“2=â‡’â„“, for every func-
tionğœ†ğ‘¥.ğ‘’â„“0
0that the analysis (eventually) concludes the expression
labeledâ„“1may evaluate to, additional constraints are generated tocapture value flow from the actual argument expression â„“2to formal
function argument ğ‘¥, and from the function result to the calling
expressionâ„“. To enforce termination, we use a standard widening
operator that transforms each collected expression whose size is
greater than a threshold into âŠ¤.
Note that the analysis for collecting calling contexts does not
affect the correctness of the overall algorithm but just determines
the effectiveness of matching.
We derive calling contexts from a result of the path-sensitive
0-CFA as follows: given submissions ğ‘ƒâ„“1
1,Â·Â·Â·,ğ‘ƒâ„“ğ‘šğ‘š, we collect set
constraints ğ¶ğ‘–for each submission such that trueâŠ¢âŸ¦ğ‘ƒğ‘–âŸ§â„“ğ‘–â†©â†’ğ¶ğ‘–,
and obtain the least solution ğœğ‘–. We collect a set of calling contexts
Î”=Î”1âˆªÂ·Â·Â·âˆª Î”ğ‘šwhere each Î”ğ‘–is
Ã˜
ğ‘“âˆˆfunctions(ğ‘ƒğ‘–)
ğ›¿âˆˆCtx{âŸ¨ğ‘“,ğ›¿,ğ‘”âŸ©|(ğ‘’â„“1
1ğ‘’2)âˆˆSub(body(ğ‘“)),ğ‘”âˆˆğœğ‘–(â„“1,ğ›¿)}.
We also conjoin the analysis results from the submissions and obtain
ğœ=Ãƒ
1â‰¤ğ‘–â‰¤ğ‘šğœğ‘–, which will also be used in Section 4.2.
Example 4.2. Consider the invocation to sub_list in the body
of the function apply2 in Figure 3c. We will show how a calling
context representing this function invocation is derived. From the
parameter definition binding variables l2ando2inapply2 where
the initial path condition is true, we first generate the following
constraints over a dataflow state ğœ.
pairâˆ’1(i)âˆˆğœ(l2,true) (3)
pairâˆ’2(i)âˆˆğœ(o2,true) (4)
In the outer pattern matching match l2with cons(hd2,tl2)â†’Â·Â·Â· ,
from (3), we generate the following constraint making o2under
a path condition: ğœ(o2,true)âŠ†ğœ(o2,pairâˆ’1(i)=cons(hd2,tl2)
|                               {z                               }
ğ›¿).
Under the current path condition ğ›¿, in the inner pattern match-
ingmatch o2with SUBâ†’...sub_listâ„“tl2where we assume
sub_list is associated with label â„“, the constraint sub_listâˆˆ
ğœ(â„“,ğ›¿âˆ§pairâˆ’2(i)=SUB)is generated from (4). After computing
a least solution satisfying these constraints, we obtain a calling
contextâŸ¨apply2,ğ›¿âˆ§pairâˆ’2(i)=SUB,sub_listâŸ©.
Now we are ready to measure similarity between arbitrary two
functions using the calling contexts. Given two functions ğ‘“andğ‘”,
we compute a distance between the two functions as follows:
dist(ğ‘“,ğ‘”)=ğ‘¤1Ã—|ğ¶ğ¶ğ‘“,ğ‘”
in|âˆ’1+ğ‘¤2Ã—|ğ¶ğ¶ğ‘“,ğ‘”
out|âˆ’1
whereğ‘¤{1,2}are coefficients that can be adjusted via statistical
learning.ğ¶ğ¶ğ‘“,ğ‘”
in(resp.ğ¶ğ¶ğ‘“,ğ‘”
out) is called incoming (resp. outgoing)
compatible calling context and defined as follows:
ğ¶ğ¶ğ‘“,ğ‘”
in={(ğ›¿,ğ›¿â€²)|ğ›¿,ğ›¿â€²âˆˆCtx,âŸ¨_,ğ›¿,ğ‘“âŸ©,âŸ¨_,ğ›¿â€²,ğ‘”âŸ©âˆˆÎ”,ğ‘†ğ´ğ‘‡(ğ›¿âˆ§ğ›¿â€²)}
ğ¶ğ¶ğ‘“,ğ‘”
out={(ğ›¿,ğ›¿â€²)|ğ›¿,ğ›¿â€²âˆˆCtx,âŸ¨ğ‘“,ğ›¿, _âŸ©,âŸ¨ğ‘”,ğ›¿â€²,_âŸ©âˆˆÎ”,ğ‘†ğ´ğ‘‡(ğ›¿âˆ§ğ›¿â€²)}
If bothğ‘“andğ‘”do not have any callers (resp. callees), we do not
consider the term involving ğ¶ğ¶ğ‘“,ğ‘”
in(resp.ğ¶ğ¶ğ‘“,ğ‘”
out). Note that the more
compatible pairs of calling contexts two functions have, the shorter
distance they have between. Based on this notion of distance, we
are equipped with the following matching function that takes aESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece Dowon Song, Woosuk Lee, and Hakjoo Oh
ğ›¿âŠ¢âŸ¦ğ‘›âŸ§â„“â†©â†’ğ‘›âˆˆğœ(â„“,ğ›¿)ğ›¿âŠ¢âŸ¦ğ‘¥âŸ§â„“â†©â†’ğ‘¥âˆˆğœ(ğ‘¥,ğ›¿)âˆ©ğœ(â„“,ğœ) (ğ‘¥âˆˆ{ğ‘¥ğœ„}âˆªFId)
ğœ(ğ‘¥,ğ›¿)âŠ†ğœ(â„“,ğœ) ( o.w.)âŸ¦ğ‘’âŸ§â„“â€²â†©â†’ğ¶
ğ›¿âŠ¢âŸ¦ğœ†ğ‘¥.ğ‘’â„“â€²âŸ§â„“â†©â†’ğœ†ğ‘¥.ğ‘’âˆˆğœ(â„“,ğ›¿)âˆªğ¶
ğ›¿âŠ¢âŸ¦ğ‘’1âŸ§â„“1â†©â†’ğ¶1ğ›¿âŠ¢âŸ¦ğ‘’2âŸ§â„“2â†©â†’ğ¶2
ğ›¿âŠ¢âŸ¦ğ‘’1ğ‘’2âŸ§â„“â†©â†’ğ¶1âˆªğ¶2âˆªfnâ„“1:â„“2=â‡’â„“ğœ†ğ‘¥.ğ‘’â„“0
0âˆˆğœ(â„“1,ğ›¿)
fnğ›¿â„“1:â„“2=â‡’â„“â†©â†’{ğœ(â„“2,ğ›¿)âŠ†ğœ(ğ‘¥,ğ›¿),ğœ(â„“0,ğ›¿)âŠ†ğœ(â„“,ğ›¿)}
ğ›¿âŠ¢âŸ¦ğ‘’âŸ§â„“â€²â†©â†’ğ¶
ğ›¿âŠ¢âŸ¦ğœ…âˆ’ğ‘–(ğ‘’â„“â€²)âŸ§â„“â†©â†’ğ¶âˆªcnğœ…âˆ’ğ‘–
ğ›¿â„“â€²=â‡’â„“ğ‘’âˆˆğœ(â„“â€²,ğ›¿)
cnğœ…âˆ’ğ‘–
ğ›¿â„“â€²=â‡’â„“â†©â†’ğœ…âˆ’ğ‘–(ğ‘’)âˆˆğœ(â„“,ğ›¿)ğ›¿âŠ¢âŸ¦ğ‘’âŸ§â„“0â†©â†’ğ¶0
ğ›¿âŠ¢âŸ¦matchğ‘’â„“0withğ‘ğ‘–â†’ğ‘’ğ‘–ğ‘˜âŸ§â„“â†©â†’ğ¶0âˆªpatğ›¿â„“0:ğ‘ğ‘–â†’ğ‘’ğ‘–ğ‘˜=â‡’â„“
ğ‘’0âˆˆğœ(â„“0,ğ›¿)ğ›¿âˆ§ğ‘Ÿ1âŠ¢ğ‘’1â†©â†’ğ¶1
ğ›¿âˆ§ğ‘Ÿ2âŠ¢ğ‘’2â†©â†’ğ¶2
Â·Â·Â·
ğ›¿âˆ§ğ‘Ÿğ‘˜â†©â†’ğ¶ğ‘˜ğ‘Ÿğ‘–=(ğ‘’0=ğ‘ğ‘– (ğ‘–=1)
ğ‘’0=ğ‘ğ‘–âˆ§Ã“
1â‰¤ğ‘—<ğ‘–ğ‘’0â‰ ğ‘ğ‘—(o.w.)ğ¶ğ¹ğ‘‰=Ã
1â‰¤ğ‘–â‰¤ğ‘˜{ğœ(ğ‘¥,ğ›¿)âŠ†ğœ(ğ‘¥,ğ›¿âˆ§ğ‘Ÿğ‘–)|ğ‘¥âˆˆğ¹ğ‘‰(ğ‘’ğ‘–)}
ğ¶âŠ”=Ã
1â‰¤ğ‘–â‰¤ğ‘˜{ğœ(â„“ğ‘–,ğ›¿âˆ§ğ‘Ÿğ‘–)âŠ†ğœ(â„“,ğ›¿)}
patğ›¿â„“0:ğ‘ğ‘–â†’ğ‘’â„“ğ‘–
ğ‘–ğ‘˜
=â‡’â„“â†©â†’Ã
1â‰¤ğ‘–â‰¤ğ‘˜ğ¶ğ‘˜âˆªğ¶ğ¹ğ‘‰âˆªğ¶âŠ”âˆªÃ
1â‰¤ğ‘–â‰¤ğ‘˜,ğ‘ğ‘–=ğœ…(ğ‘¥1,Â·Â·Â·,ğ‘¥ğ‘›){ğœ…âˆ’ğ‘—(ğ‘’0)âˆˆğœ(ğ‘¥ğ‘—,ğ›¿)|1â‰¤ğ‘—â‰¤ğ‘›}
Figure 4: Constraint generation rules for our path-sensitive 0-CFA (selected). The special constraints of kinds fn, cn, and pat
are interpreted by the constraint solver to generate additional concrete constraints.
function in a buggy submission and returns a function in a correct
submission to be referred for correction:
M=ğœ†ğ‘ƒğ‘.{ğ‘“â†¦â†’ argmin
ğ‘ƒğ‘âˆˆPğ‘
ğ‘”âˆˆfunctions(ğ‘ƒğ‘)
type(ğ‘“)=type(ğ‘”)dist(ğ‘“,ğ‘”)|ğ‘“âˆˆfunctions(ğ‘ƒğ‘)}.
Note that we only consider functions of the same type.
Example 4.3. Suppose we want to measure the distance between
dec_all andsub_list , and the distance between dec_all and
add_list in Figure 3. After the 0-CFA analysis, we obtain the
following calling contexts.
âŸ¨apply,pairâˆ’1(i)=cons(hd,tl)âˆ§pairâˆ’2(i)=SUB
|                                                        {z                                                        }
ğ›¿1,dec_allâŸ©
âŸ¨dec_all,ğ›¿1âˆ§consâˆ’2(pairâˆ’1(i))=cons(h,t)
|                                             {z                                             }
ğ›¿2,dec_allâŸ©
âŸ¨apply1,pairâˆ’1(i)=cons(hd1,tl1)âˆ§pairâˆ’2(i)=ADD
|                                                           {z                                                           }
ğ›¿3,add_listâŸ©
âŸ¨add_list,ğ›¿3âˆ§consâˆ’2(pairâˆ’1(i))=cons(h1,t1)
|                                                {z                                                }
ğ›¿4,add_listâŸ©
âŸ¨apply2,pairâˆ’1(i)=cons(hd2,tl2)âˆ§pairâˆ’2(i)=SUB
|                                                           {z                                                           }
ğ›¿5,sub_listâŸ©
âŸ¨sub_list,ğ›¿5âˆ§consâˆ’2(pairâˆ’1(i))=cons(h2,t2)
|                                                {z                                                }
ğ›¿6,sub_listâŸ©
Â·Â·Â·
Withğ‘¤1=1andğ‘¤2=2that we are using in our implementation,
dist(dec_all,sub_list)=|{(ğ›¿1,ğ›¿5),(ğ›¿2,ğ›¿6)}|âˆ’1+2Â·|{(ğ›¿2,ğ›¿6)}|âˆ’1
=2.5
whereas dist(dec_all,add_list)=âˆas the two functions do not
share any compatible calling contexts.
In case of tie, we pick the most syntactically similar function. To
measure the syntactic similarity, we use the method of embedding
ASTs into numerical vectors, which is called the position-aware
characteristic vectors proposed by Wang et al . [43] . We compute
Euclidean distances between vectors to obtain the syntactic dis-
tances.4.2 Repair Algorithm
In this subsection, we explain how to extract repair templates from
correct submissions and instantiate them to generate patches. In
particular, our goal is to obtain a sequence of edit actions that
transform a given buggy submission into a new correct one. This
sequence is called edit script . We consider the following edit actions:
â€¢Modify(â„“,ğ‘’)replaces the old subexpression at label â„“by the
new expression ğ‘’.
â€¢Insert(â„“,ğ‘â†’ğ‘’)adds a new pattern matching case ğ‘â†’ğ‘’
into a match expression associated with label â„“.
â€¢Delete(â„“,ğ‘â†’ğ‘’)removes an existing pattern matching case
ğ‘â†’ğ‘’from a match expression associated with label â„“.
â€¢Define(ğ‘“)adds a new definition of function ğ‘“into the expres-
sion. If we apply this action into an expression ğ‘’, the resulting
expression would be let recğ‘“(param(ğ‘“))=body(ğ‘“)inğ‘’.
4.2.1 Learning Repair Templates. We generate edit scripts by in-
stantiating templates (which we call repair templates ) collected from
correct submissions. A repair template is a variant of an edit action
where each expression in Modify orInsert action does not have
any variables but just holes . Each hole is annotated with a type and
plays a role as a placeholder that can be replaced with a variable of
the type. The set Expâ–¡of expressions with holes is similarly defined
asExpin the followings.
ğ‘’â–¡âˆˆ Expâ–¡
ğ‘’â–¡::=â–¡ğœ|ğ‘›|ğœ†ğ‘¥.ğ‘’â–¡|ğ‘’â–¡,1âŠ•ğ‘’â–¡,2|ğ‘’â–¡,1ğ‘’â–¡,2
|ğœ…(ğ‘’â–¡,1,Â·Â·Â·,ğ‘’â–¡,ğ‘(ğœ…))|ğœ…âˆ’ğ‘–(ğ‘’â–¡)
|letğ‘¥=ğ‘’â–¡,1inğ‘’â–¡,2
|let recğ‘“(ğ‘¥)=ğ‘’â–¡,1inğ‘’â–¡,2
|matchğ‘’â–¡withğ‘â–¡,ğ‘–â†’ğ‘’â–¡,ğ‘–ğ‘˜
ğ‘â–¡::=ğœ…(â–¡ğœ1,Â·Â·Â·,â–¡ğœğ‘˜)|_
An expression with holes can be considered an abstraction of multi-
ple expressions. The abstraction function ğ›¼ğ‘’:Expâ†’Expâ–¡, which
we apply to expressions in correct submissions to extract templates,
is defined as follows (to avoid unnecessary clutter, we omit simpleContext-Aware and Data-Driven Feedback Generation for Programming Assignments ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece
inductive cases):
ğ›¼ğ‘’(ğ‘›)=ğ‘› ğ›¼ğ‘’(ğ‘¥â„“)=â–¡â„“
type(ğ‘¥)ğ›¼ğ‘’(ğœ†ğ‘¥.ğ‘’)=ğœ†ğ‘¥.ğ›¼ğ‘’(ğ‘’)
Â·Â·Â·
ğ›¼ğ‘’(matchğ‘’withğ‘ğ‘–â†’ğ‘’ğ‘–ğ‘˜)
=matchğ›¼ğ‘’(ğ‘’)withğ‘ğ‘–â†’ğ›¼ğ‘’(ğ‘’ğ‘–)ğ‘˜
ğ›¼ğ‘(ğœ…(ğ‘¥1,Â·Â·Â·,ğ‘¥ğ‘(ğœ…)))=ğœ…(ğ›¼ğ‘’(ğ‘¥1),Â·Â·Â·,ğ›¼ğ‘’(ğ‘¥ğ‘(ğœ…)))ğ›¼ğ‘(_)=_
When abstracting a variable into a hole, we preserve its label. The
label is used in various ways, which will be described later in the
next subsection.
Now we describe how to generate repair templates. Given a
buggy submission ğ‘ƒand the matching function M, we obtain a set
of templatesT=Tğ·âˆªTğ‘€whereTğ·is a set of templates of kind
Define defined as follows:
Tğ·={Define(ğ‘”)|ğ‘“âˆˆfunctions(ğ‘ƒ),ğ‘”âˆˆcallees(body(M(ğ‘“)))}.
In other words, we collect all the auxiliary functions used in ref-
erence solutions. The function callees :Expâ†’P( FId)returns all
functions that may be invoked in a given expression. The set Tğ‘€
includes templates of kinds Modify ,Insert , and Delete defined as
follows:
Tğ‘€=Ã˜
{ğ‘‡|ğ‘“âˆˆfunctions(ğ‘ƒ),âŸ¦body(ğ‘“),body(M(ğ‘“))âŸ§â‡ğ‘‡}.
The judgementâŸ¦ğ‘’,ğ‘’â€²âŸ§â‡ğ‘‡can be read as â€œby differencing a buggy
expressionğ‘’and a reference expression ğ‘’â€², we extract a set ğ‘‡of
edit action templates that can be potentially used to correct ğ‘’â€.
Figure 5 depicts a subset of inference rules for extracting templates
for a given pairs of expressions. The full set is deferred to the
supplementary material.
Example 4.4. Suppose we extract a set ğ‘‡of templates from sub_list
for correcting dec_allin Figure 3. We extract templates ğ‘‡such
thatâŸ¦ğ‘’1,ğ‘’2âŸ§â‡ğ‘‡whereğ‘’1isbody(sub_list)with labelsâ„“1..6and
ğ‘’2isbody(dec_all)with labelsâ„“â€²
1..6:
ğ‘’1=match lâ„“1with
ğ‘1â†’empty
|ğ‘2â†’cons((hâ„“2+1)â„“3,dec_allâ„“4tâ„“5)â„“6
ğ‘’2=match lâ„“â€²
1
2with
ğ‘â€²
1â†’empty
|ğ‘â€²
2â†’cons((hâ„“â€²
2
2âˆ’1)â„“â€²
3,sub_listâ„“â€²
4tâ„“â€²
5
2)â„“â€²
6
andğ‘1=ğ‘â€²
1=empty ,ğ‘2=cons(h,t), andğ‘â€²
2=cons(h2,t2).
By the inference rule for differencing two matching expressions
in Figure 5, we first compare lâ„“1andl2â„“â€²
1and derive a template
Modify(â„“1,â–¡int list). Since both{ğ›¼ğ‘(ğ‘1),ğ›¼ğ‘(ğ‘2)}and{ğ›¼ğ‘(ğ‘â€²
1),ğ›¼ğ‘(ğ‘â€²
2)}
are{empty ,cons(â–¡int,â–¡int list)}and the expressions matched for
ğ‘1andğ‘â€²
1are the same, we compare the matched expressions for
ğ‘2andğ‘â€²
2labeledâ„“6andâ„“â€²
6respectively. By the rule for differencing
two constructors, we additionally derive Modify(â„“3,ğ›¼ğ‘’(h2âˆ’1))=
Modify(â„“3,â–¡â„“â€²
2
intâˆ’1),Modify(â„“4,â–¡int listâ†’int list), and Modify(â„“5,â–¡int list).
4.2.2 Generating Edit Scripts. We instantiate the collected tem-
plates into edit actions using the following concretization functionğ›¾ğ‘ƒğ‘’:Expâ–¡â†’P( Exp)parametrized by a buggy submission ğ‘ƒ.
ğ›¾ğ‘ƒğ‘’(ğ‘›)={ğ‘›}ğ›¾ğ‘ƒğ‘’(ğœ†ğ‘¥.ğ‘’â–¡)={ğœ†ğ‘¥.ğ‘’|ğ‘’âˆˆğ›¾ğ‘ƒğ‘’(ğ‘’â–¡)}
Â·Â·Â·
ğ›¾ğ‘ƒğ‘’(matchğ‘’â–¡,0withğ‘ğ‘–â†’ğ‘’â–¡,ğ‘–ğ‘˜)
={matchğ‘’0withğ‘ğ‘–â†’ğ‘’ğ‘–ğ‘˜|ğ‘’ğ‘–âˆˆğ›¾ğ‘ƒğ‘’(ğ‘’â–¡,ğ‘–)}
Most importantly,
ğ›¾ğ‘ƒ
ğ‘’(â–¡â„“
ğœ)={ğ‘¥âˆˆğ‘‰|type(ğ‘¥)=ğœ} (âˆƒğ‘¥âˆˆğ‘‰.type(ğ‘¥)=ğœ)
ğ‘‰ (otherwise)
whereğ‘‰=vars(ğ‘ƒ)âˆª{ğ‘¥âˆˆFId|ğ›¿âˆˆCtx.ğ‘¥âˆˆğœ(â„“,ğ›¿)}is the set
of candidate variables for the given hole â–¡â„“ğœ. Note that the label
â„“always originates from a correct submission. We consider not
only variables in ğ‘ƒbut also function identifiers reachable at â„“as
candidates for the hole. This is because we may copy function
definitions in correct submissions (via Define actions) into ğ‘ƒand
letğ‘ƒinvoke the newly added functions. In case of no candidate
variable of type ğœ, we just enumerate all the variables in ğ‘‰.
Over a buggy submission ğ‘ƒusing the concretization function,
we may obtain the following set Aof edit actions.
A={Modify(â„“,ğ‘’)|Modify(â„“,ğ‘’â–¡)âˆˆTğ‘€,ğ‘’âˆˆğ›¾ğ‘ƒğ‘’(ğ‘’â–¡)}
âˆª{Insert(â„“,ğ‘â†’ğ‘’)|Insert(â„“,ğ‘â†’ğ‘’â–¡)âˆˆTğ‘€,ğ‘’âˆˆğ›¾ğ‘ƒğ‘’(ğ‘’â–¡)}
âˆª{Delete(â„“,ğ‘â†’ğ‘’)|Delete(â„“,ğ‘â†’ğ‘’)âˆˆTğ‘€}
âˆªTğ·.
However, this method is not scalable in practice as the number of
concretized edit actions is potentially exponential to the number of
holes in the template (despite the type-based pruning). To reduce the
number of candidates for the holes, we use the following improved
concretization function Ëœğ›¾ğ‘ƒğ‘’, which is similarly defined as ğ›¾ğ‘ƒğ‘’except
for the following case:
Ëœğ›¾ğ‘ƒ
ğ‘’(â–¡â„“
ğœ)=
ğ‘‰ğœ|â„“(ğ‘‰ğœ|â„“â‰ âˆ…)
ğ›¾ğ‘ƒğ‘’(â–¡â„“ğœ)otherwise
whereğ‘‰ğœ|â„“is the set of variables of type ğœinğ‘‰that may take the
same value reachable at label â„“. Formally,
ğ‘‰ğœ|â„“={ğ‘¥âˆˆğ‘‰|type(ğ‘¥)=ğœ,âˆƒğ›¿,ğ›¿â€².ğœ(ğ‘¥,ğ›¿)âˆ©ğœ(â„“,ğ›¿â€²)â‰ âˆ…}.
This heuristic is inspired by the variable-usage based ğ›¼-conversion
ofSarfgen [43] but we analyze the usage more accurately using
the result of our path-sensitive 0-CFA.
Example 4.5. Recall the template Modify(â„“3,â–¡â„“â€²
2
intâˆ’1)derived in
Example 4.4. When concretizing â–¡â„“â€²
2
int, we only consider the variable
has a candidate for the hole because
ğœ(h,ğ›¿1)âˆ‹consâˆ’1(consâˆ’2(pairâˆ’1(i)))
ğœ(â„“â€²
2,ğ›¿5)âˆ‹consâˆ’1(consâˆ’2(pairâˆ’1(i)))
whereğ›¿1andğ›¿5are the path conditions defined in Example 4.3.
Changing Annotated Types during Instantiation .For ease
of presentation, we have presented our instantiation method as if
types associated with holes could never change after they were de-
termined. In the actual implementation, we change the types during
the course of instantiation. Whenever a hole is filled with a vari-
able, we perform type inference to change types of the other holes
accordingly. An example case is the instantiation of the template
(2) described in Section 2.2.ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece Dowon Song, Woosuk Lee, and Hakjoo Oh
âŸ¦ğ‘›1,ğ‘›2âŸ§â‡âˆ…ğ‘›1=ğ‘›2âŸ¦ğ‘¥â„“1
1,ğ‘¥â„“2
2âŸ§â‡{Modify(â„“1,â–¡â„“2
type(â„“2))}âŸ¦ğ‘’1,ğ‘’2âŸ§â‡ğ‘‡
(âŸ¦ğœ†ğ‘¥1.ğ‘’1),(ğœ†ğ‘¥2.ğ‘’2)âŸ§â‡ğ‘‡âŸ¦ğ‘’1,ğ‘’â€²
1âŸ§â‡ğ‘‡1âŸ¦ğ‘’2,ğ‘’â€²
2âŸ§â‡ğ‘‡2
âŸ¦(ğ‘’1ğ‘’2),(ğ‘’â€²
1ğ‘’â€²
2)âŸ§â‡ğ‘‡1âˆªğ‘‡2
âŸ¦ğ‘’0,ğ‘’â€²
0âŸ§â‡ğ‘‡0ğ‘‡ğ‘€=Ã{ğ‘‡ğ‘—|1â‰¤ğ‘—â‰¤ğ‘˜,âŸ¦ğ‘’ğ‘—,ğ‘’â€²
ğ‘—âŸ§â‡ğ‘‡ğ‘—,ğ›¼ğ‘(ğ‘ğ‘—)=ğ›¼ğ‘(ğ‘â€²
ğ‘—)}
ğ‘‡ğ¼={Insert(â„“,ğ‘ğ‘—â†’ğ›¼ğ‘’(ğ‘’ğ‘—))|1â‰¤ğ‘—â‰¤ğ‘š,ğ›¼ğ‘(ğ‘ğ‘—)âˆˆ{ğ›¼ğ‘(ğ‘â€²
ğ‘–)}ğ‘›
ğ‘–=1\{ğ›¼ğ‘(ğ‘ğ‘–)}ğ‘š
ğ‘–=1}
ğ‘‡ğ·={Delete(â„“,ğ‘ğ‘—â†’ğ‘’ğ‘—)|1â‰¤ğ‘—â‰¤ğ‘›,ğ›¼ğ‘(ğ‘ğ‘—)âˆˆ{ğ›¼ğ‘(ğ‘ğ‘–)}ğ‘›
ğ‘–=1\{ğ›¼ğ‘(ğ‘â€²
ğ‘–)}ğ‘š
ğ‘–=1}
âŸ¦(matchğ‘’0withğ‘ğ‘–â†’ğ‘’ğ‘–ğ‘›),(matchğ‘’â€²
0withğ‘â€²
ğ‘–â†’ğ‘’â€²
ğ‘–ğ‘š)âŸ§â‡ğ‘‡0âˆªğ‘‡ğ‘€âˆªğ‘‡ğ¼âˆªğ‘‡ğ·
âŸ¦ğ‘’1,ğ‘’â€²
1âŸ§â‡ğ‘‡1Â·Â·Â· âŸ¦ğ‘’ğ‘˜,ğ‘’â€²ğ‘›âŸ§â‡ğ‘‡ğ‘›
âŸ¦ğœ…(ğ‘’1,Â·Â·Â·,ğ‘’ğ‘›),ğœ…(ğ‘’â€²
1,Â·Â·Â·,ğ‘’â€²ğ‘›)âŸ§â‡Ã
1â‰¤ğ‘–â‰¤ğ‘›ğ‘‡ğ‘–âŸ¦ğ‘’â„“1
1,ğ‘’â„“2
2âŸ§â‡{Modify(â„“1,ğ›¼ğ‘’(ğ‘’2))}(ğ‘’1andğ‘’2are of different kinds.)
Figure 5: Inference rules for extracting edit action templates for given two expressions (selected).
Algorithm 1 TheCafe Algorithm
Input: A buggy submission ğ‘ƒğ‘, a set of correct submissions Pğ‘,
and a set of test cases T
Output: A programğ‘ƒğ‘satisfying all the test cases in T
1:Aâ†âˆ… âŠ²Set of edit actions
2:Pâ†Pğ‘âˆª{ğ‘ƒğ‘}
3:ğœâ†result of the path-sensitive 0CFA on P
4:Î”â†all calling contexts derivable from ğœ
5:DeriveMfromÎ” âŠ²M:FIdâ†’FId
6:Tâ† ExtractTemplates(M,Î”,ğ‘ƒğ‘,Pğ‘)
7:forğ‘‡âˆˆTdo
8:Aâ†Aâˆª InstantiateTemplate (ğ‘‡,ğ‘ƒğ‘,ğœ)
9:ğ‘›â†1
10:repeat âŠ²ğ¸: edit script comprising ğ‘›edit actions
11: foreach permutation ğ¸ofğ‘›elements ofAdo
12:ğ‘ƒâ†applyğ¸intoğ‘ƒğ‘
13: ifcorrect(ğ‘ƒ,T)then
14: returnğ‘ƒ
15:ğ‘›â†ğ‘›+1
16:untilğ‘›â‰¤|A|
4.2.3 Overall Algorithm. Putting all together, Algo. 1 depicts the
Cafe algorithm. We first perform the path-sensitive 0CFA on all the
submissions and obtain the result ğœ(line 3). Then, we derive calling
contexts from the analysis result (line 4). From the calling contexts,
we obtain the matching function Mthat maps each function in
the buggy submission ğ‘ƒğ‘to a function in a correct submission that
is most likely to be useful for repair (line 5). Using the matching
function, we collect repair templates (line 6). By instantiating the
templates, we obtain a set of edit actions that can be applicable to
ğ‘ƒğ‘(lines 7 â€“ 8). The main loop (lines 10 â€“ 16) applies each possible
sequence of the edit actions into ğ‘ƒğ‘in turn. The variable ğ‘›denotes
the number of edit actions that can be used, which is initialized to
be1(line 9). We apply each edit script into ğ‘ƒğ‘(line 12) and check if
the submission has been fixed based on the given test cases (line
13). If we have fixed the submission, we return it as a final result
(line 14). Otherwise, we increase ğ‘›by1(line 15) and repeat the
main loop.
The algorithm enumerates edit scripts in increasing size, guar-
anteeing to find a minimal edit script in the following sense.Definition 4.6 (Minimality). Given an incorrect submission ğ‘ƒğ‘
and a set of possible edit actions A, an edit script ğ¸comprising the
edit actions inAto correctğ‘ƒğ‘is minimal if there does not exist an
edit scriptğ¸â€²such that|ğ¸â€²|<|ğ¸|andğ¸â€²fixesğ‘ƒğ‘.
4.2.4 Optimizations. When generating edit actions of kind Define
that add new function definitions into a target buggy submission,
we avoid functions that incur a long subsequent call chain to prevent
Cafe from generating huge patches (currently, we only consider
immediate callees of a reference function). Additionally, when gen-
erating edit scripts by permuting edit actions, we avoid generating
duplicated edit scripts that lead to the same effect by not respecting
orders between edit actions targetting different labels.
4.3 Discussion
Limitation of Context-Aware Matching .Our context-aware
matching may produce imprecise results for functions called with
trivial contexts. For example, suppose that there are two functions
called under empty contexts (i.e., no path conditions are accumu-
lated in their callers), and they should not be matched. In this case,
context-aware matching would match them because their contexts
are equivalent as empty contexts. We mitigated this shortcoming by
applying the idea of context tunneling [ 18] and updating contexts
at call-sites only when they are non-empty. For example, suppose
we measure the similarity between two functions that have empty
incoming contexts. In this case, we can apply context tunneling,
so the callee inherits the callersâ€™ incoming contexts rather than
producing empty contexts. We can further mitigate the issue of
trivial contexts by falling back to existing syntactic matching: when
the contexts are trivial (even after context tunneling), we can use
the syntactic matching of Sarfgen rather than our context-aware
matching.
Applicability to Other Languages .Although we formalized
our approach for a functional language, the ideas of Cafe may work
for other languages (e.g., Python) as well. First, the core idea can
be applicable to any programs that consist of multiple functions,
regardless of whether the language is functional or imperative.
Second, the ideas of extracting repair templates from syntactic
discrepancies and instantiating obtained templates can also be easily
adapted for other languages whose syntax is defined inductively.
One feature of OCaml that CAFE particularly assumes is that it
is a statically typed language. CAFE uses static type information toContext-Aware and Data-Driven Feedback Generation for Programming Assignments ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece
prune out unnecessary function/variable mappings (i.e., excluding
type-inconsistent pairs). This type-based optimization can be read-
ily used for imperative languages with static typing such as C and
Java. For dynamic languages like Python, CAFE is still applicable
simply without the optimization (which might degrade the perfor-
mance of CAFE slightly) or with extra type information computed
by a static analysis.
5 EVALUATION
We evaluate Cafe to answer the following research questions:
â€¢Performance of Cafe : How effectively can Cafe repair
incorrect programs? How does it compare to the state-of-
the-art for OCaml [22]? (Section 5.1)
â€¢Comparison with Prior Data-Driven Approaches : How
does our approach compare to the existing data-driven ap-
proaches (Section 5.2)
â€¢Helpfulness : How helpful is Cafe for students? Is the gen-
erated feedback useful for students? (Section 5.3)
We implemented Cafe in about 7,000 lines of OCaml code. Al-
though we formalized our approach for an ideal language, our
implementation can handle all student programs in our class with-
out any modification. We used the Z3 SMT solver for checking
compatibility of path conditions. All experiments were conducted
on an iMac with Intel i5 CPU and 16GB memory.
5.1 Performance of Cafe
Setting .We collected 4,211 OCaml programs from 10 exercises
used in our class over the last few years, which include most of
benchmarks used in our prior work [ 22].2To distinguish correct
and incorrect programs, we used 10â€“33 test cases per exercise These
test cases have been carefully designed to detect various types of
errors over the few years. All programs are compilable with no
syntax or type errors. The description of the benchmark programs
is given in Table 1. We classify the programming exercises into three
levels, i.e., introductory (#1-#4), intermediate (#5-#7), and advanced
(#8-#10), based on the code size and the ratio of incorrect to correct
programs. Although code sizes look rather small, our benchmark
set includes a number of notable programs (e.g., with 7 helper
functions). Some examples programs are in the supplementary
material. We compared Cafe with FixML [22], the state-of-the-
art feedback generation tool for OCaml programs. FixML repairs
incorrect programs using search-based program synthesis. Because
FixML requires test cases and a solution program, we gave FixML
an instructor-provided solution for each exercise and the same set
of test cases as ours. We set time budget to 60 seconds per program
for both Cafe andFixML .
Result .Table 1 shows that Cafe is far more effective than FixML
in repairing student submissions. In total, Cafe successfully fixed
83% (548/664) of the buggy submissions, while the fix rate of FixML
was 35% (234/664). Note that Cafe consistently achieves high fix
rates for intermediate (82%, 95/116) and advanced problems (79%,
351/443), while FixML does not perform well for intermediate (47%,
2We excluded four exercises from [ 22] because they do not contain sufficient number of
programs, or they require program-specific testing drivers that make the specification
of problem unclear.54/116) and advanced problems (25%, 109/443). One key contributor
to the high fix rate of Cafe was its capability of modifying multi-
ple expressions with diverse repair strategies (e.g., insertion and
deletion of branches, introduction of new functions). By contrast,
FixML is limited to fixing single-location bugs.
We manually validated the correctness of patches, and Table 1
reports correct patches only. Since both Cafe andFixML use test
cases as correctness specifications, they may produce test-suite-
overfitted patches that satisfy given test cases but still contain errors.
Originally, FixML generated 264 patches, among which 30 were
overfitted to test cases. Because those patches are incorrect feed-
back, we only include 234 correct patches in Table 1. On the other
hand, Cafe produced no incorrect patches. This was because Cafe
leverages common templates extracted from solutions.
More qualitative analysis on the result is as follows. Notably,
Cafe successfully fixed complex programs such as one with 7 func-
tions and the call depth of 4. The generated patches were also
non-trivial. Cafe modified 31% expressions of the original pro-
grams on average. Furthermore, we found that 25% (135/548) of
the fixed errors are patched by repairing at least two functions
simultaneously. When we investigated the statistics of edit actions
used in patches, the distribution of each four templates ( Modify ,
Insert ,Delete ,Define ) was 79%, 8%, 2%, and 10%, respectively.
The performance of Cafe was not very sensitive to the amount
of available data. For example, when we used 50% of the correct
programs as a corpus, the fix rate remained almost the same: 82%
(542/664, averaged over five random trials). When we used 10% of
the correct programs, the fix rate decreased to 78% (517/664).
Limitation .We identified representative cases that Cafe can
fail to produce patches. Timeout due to the large search space was
the most common reason. For example, a buggy submission required
Cafe to modify all (eight) if-then-else expressions in the program;
Cafe is unlikely to generate such a large fix. Also, Cafe sometimes
failed due to the lack of proper patch candidates caused by matching
failure. In our experiments, potential imprecise matching discussed
in Section 4.3 rarely happened (after applying context tunneling).
For example, in problem 10, we observed that only five failures
(9.8%, 5/51) were due to imprecise matching.
5.2 Comparison with Prior Techniques
We could not compare Cafe directly with existing data-driven tools
as they target different languages [ 12,34,43] and rely on language-
specific features [ 34]. However, to see how much Cafe advances the
existing techniques, we implemented two variants, called Prog and
Func , ofCafe .Prog andFunc are identical to Cafe except that
â€¢Prog uses the program-level matching of Sarfgen [43],
â€¢Func uses it at the function level.
From the corpus of correct programs, Prog selects a program that
is most similar to the given incorrect program, where we compute
the similarity using the technique of Sarfgen [43], i.e., position-
aware characteristic vector embedding. Thus, the performance gap
between Prog andCafe hints at how Cafe performs compared to
Sarfgen .Func applies the matching algorithm of Sarfgen at the
function level and therefore it partially enjoys the benefit of our
approach (i.e., using multiple solutions via function-level matching).ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece Dowon Song, Woosuk Lee, and Hakjoo Oh
Table 1: Performance comparison of Cafe andFixML . â€œ#Wrongâ€ and â€œ#Correctâ€ report the numbers of incorrect and cor-
rect submissions for each problem, respectively. â€œ#Funcâ€: the average, minimum, and maximum numbers of functions in
buggy submissions. â€œLOCâ€: the average, minimum, and maximum lines of code of buggy submissions. â€œTimeâ€: average patch-
generation time (in sec). â€œ#Fix (Rate)â€: #correct patches generated by each tool and the patch rate.
No Problem Description #Wrong #Correct#Func LOC FixML Cafe
avg(min-max) avg(min-max) Time #Fix (Rate) Time #Fix (Rate)
1 Finding a maximum element in a list 45 171 1.6 (1-3) 5 (1-9) 0.3 40 (89%) 0.0 45 (100%)
2 Checking membership in a binary tree 19 117 1.1 (1-3) 9 (5-13) 3.1 12 (63%) 0.0 19 (100%)
3 Mirroring a binary tree 9 88 1.0 (1-1) 6 (3-9) 0.1 7 (78%) 0.0 9 (100%)
4 ComputingÃğ‘˜
ğ‘–=ğ‘—ğ‘“(ğ‘–)forğ‘—,ğ‘˜, andğ‘“ 32 704 1.1 (1-2) 4 (2-10) 1.6 12 (38%) 2.1 29 (91%)
5 Composing functions 49 454 1.5 (1-3) 5 (2-11) 11.8 26 (53%) 1.1 42 (86%)
6 Removing redundant elements in a list 32 125 2.3 (1-5) 12 (5-24) 4.1 10 (31%) 3.0 23 (72%)
7 Arithmetic of user-defined natural numbers 35 412 2.2 (1-5) 13 (7-23) 23.3 18 (51%) 1.0 30 (86%)
8 Evaluating a propositional formula 111 597 2.1 (1-8) 29 (13-64) 1.5 44 (40%) 0.5 78 (70%)
9 Checking the validity of a lambda term 141 661 2.7 (1-7) 20 (6-47) 1.5 23 (16%) 1.8 133 (94%)
10 Dfferentiating an algebraic expression 191 218 2.1 (1-9) 29 (7-114) 1.1 42 (22%) 3.0 140 (73%)
Total / Average 664 3,547 2.0 (1-9) 20 (1-114) 3.9 234 (35%) 1.6 548 (83%)
P1 P2 P3 P4 P5 P6 P7 P8 P9 P10050100Fix Rate (%)Prog Func Cafe
Figure 6: Comparison with existing data-driven techniques.
Thus, comparing Func andCafe shows the sole impact of using
our context-aware matching against the matching of Sarfgen .
The result shows that existing data-driven techniques are un-
likely to be effective for our dataset. Figure 6 compares the fix
rates of Prog ,Func , and Cafe on the same dataset as Figure 1. On
average, Prog achieved a fix rate of 59%. Simply extending the ex-
isting technique at the function level ( Func ) did not improve its
performance significantly (67%). This is because, as illustrated in
Section 2.2, simply aiming to find syntactically or semantically simi-
lar functions is unlikely to find a useful reference. Cafe was slightly
superior to the existing syntactic approach in terms of efficiency
and patch quality. When we compared the Cafe to the variant of
Sarfgen (Prog ),Cafe was faster than Prog (1.6 seconds vs. 1.9
seconds), which implies that context-aware matching can be as
efficient as the embedding method of Sarfgen . In addition, we
found that Cafe modified less expressions than Prog (31% and 33%
respectively).
5.3 User Study
We recruited 16 undergraduate students from our course. The stu-
dents were asked to solve the 10 programming exercises in Table 1.
Then, we graded their submissions and provided feedback for er-
roneous ones using Cafe . Finally, students answered the surveyA Buggy
Submission
Reference
SolutionsCafe TestML [40]Correct
CodePatch Candidate
Test Cases
Figure 7: Enhanced Cafe with automatic test generator
questions about the generated feedback: (Q1) Is the feedback cor-
rect and easy to understand? (Q2) Does the provided feedback help
you understand the mistake? (Q3) Do you think Cafe can be actu-
ally useful in our class? For each question, students were asked to
choose between 1 (strongly disagree) and 5 (strongly agree). Also,
we asked student to leave additional textual comments for each
question. For Q1, Q2, and Q3, 14, 13, and all participants agreed
(with scores 4 or 5), respectively. The comments the participants left
include: " Cafe generates clever patches while keeping my codeâ€™s
structure", "Unlike the TAâ€™s solution code, the personalized feed-
back is easier to understand because it is derived form mine", and
"It will help because it not only tells me the error, but also teaches
me how to fix it".
5.4 Cafe with Automatic Test Case Generation
A limitation of Cafe is the reliance on manually-provided test cases,
which hinders its use in real deployment: the quality of feedback
depends on the quality of test cases but coming up with high-quality
test cases requires massive human effort. In Table 1, we used manual
test cases carefully refined over the few years, but such test cases
are not always available. Below, we check if this limitation can be
alleviated with the aid of automatic test generation techniques.
As shown in Figure 7, we built an enhanced version of Cafe
in combination with TestML [40].TestML is a recent counter-
example generation tool for OCaml programming exercises, which
takes two programs and tries to generate a test case on whichContext-Aware and Data-Driven Feedback Generation for Programming Assignments ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece
Table 2: Cafe with automatic test generation.
NoCafe w/oTestML Cafe with TestML
#Tests #Fix Time #Tests (min-max) #Fix Time
8 18 78 0.5 4 (1-14) 79 124.5
9 33 133 1.8 3 (1-8) 133 123.6
10 28 140 3.0 5 (1-13) 141 124.8
the two programs behave differently. The enhanced Cafe in Fig-
ure 7 combines Cafe andTestML in a loop. Note that it no longer
requires manual test cases for patch validation. Instead, it uses
TestML as a correctness oracle. When TestML fails to generate
a counter-example for the submission and a solution (randomly
chosen from the corpus), we regard the current patch candidate as
a correct repair. Otherwise, TestML augments the set of test cases,
which is initially empty, with the generated counter-example, and
Cafe is re-run with new test cases. The loop repeats until one of
two components fails. We set the time budget for Cafe andTestML
to 60 and 120 seconds, respectively.
Table 2 compares Cafe with and without TestML (results for
Problems 8â€“10 only due to the lack of space). For Cafe without
TestML , #Tests reports the number of manual test cases for each
exercise. For Cafe withTestML , #Tests shows the average, smallest,
and largest number of test cases generated by TestML during the
process in Figure 7. The results show that the enhanced system
with TestML reproduces the results in Table 1. Indeed, Cafe with
TestML generated three new patches and we confirmed they are
correct. This was because Cafe now uses a smaller number of test
cases and spends less time in patch validation. Despite the overhead,
we found that combining Cafe andTestML increases the usability
significantly by reducing the instructorâ€™s burden of crafting test
cases and validating generated patches.
6 RELATED WORK
Automatic feedback generation has received an increasing amount
of attention over the last years [ 1,2,5,7,10â€“14,19,20,22,23,27,
31, 33, 35, 36, 39, 40, 43]. We discuss closely-related work below.
Our work builds upon but represents a significant departure from
prior data-driven feedback generation techniques [ 12,17,34,42,43].
Clara [12] is a clustering-based method that uses control flows and
dynamic traces to find a correct solution. Similarly, Sarfgen [43]
represetns ASTs as vectors to find similar solution programs. These
syntactic approaches could be improved using semantic features [ 34,
42]; however, those features are designed with imperative languages
in mind and not readily applicable to Cafe . These data-driven
approaches assume that there exists a close enough correct program
in the corpus and Cafe aims to address this limitation by leveraging
multiple, partially-matching programs.
Refactory [17] resolves the strict control flow matching prob-
lem of existing works [ 12,43] by generating semantic-preserving
references through refactoring. Note, however, that Refactory still
relies on the control flow structures of refactored reference pro-
grams. On the other hand, our key observation in this paper is
that conventional syntactic/semantic matching is not suitable for
finding useful references when target programs consist of multiplesub-functions. In this setting, â€œsimilarâ€ reference functions are un-
likely to be useful for repair (Section 2.2). To address this issue, we
present a new method, context-aware matching, which matches
functions by analyzing how they are used in programs (rather than
comparing syntactic similarity).
Rite [37] and FixML [22] are state-of-the-art techniques for
repairing student programs written in OCaml. Unlike ours, however,
Rite can fix type errors only. FixML [22] uses program synthesis to
repair general errors specified by test cases. However, FixML cannot
fix multi-location errors, which consequently leads to a low fix rate.
In this paper, we showed that Cafe outperforms FixML .
AutoGrader [ 39] and CoderAssist [ 19] are approaches that re-
quire manual effort. AutoGrader is a model-based technique to
generate feedback by using constraint-based program synthesis.
sk_p [ 35] addresses the limitation of AutoGrader by using a seq2seq
neural network but is limited to small Python programs. CoderAs-
sist generates verified feedback for introductory programming as-
signments but requires instructor-validated submissions.
Our work belongs to program repair techniques that use test
cases as correctness criteria. Automatic program repair has a large
volume of prior work [ 9,30], which broadly classified into tech-
niques for particular error types [ 4,8,16,21,26,38,41,44,47] and
general-purpose techniques [ 3,24,25,28,29,45,46]. In particular,
our work is similar to [ 28] in that both techniques use reference
programs but our goal is to provide feedback on student programs.
Our context-aware matching is also related to existing program
embedding techniques [ 6,15]. For example, Func2 vec[6] is used
to identify similar functions based on call relationships of functions.
By contrast, our technique finds similar functions based on function
contexts.
7 CONCLUSION
We presented a new technique that advances the existing data-
driven approaches for automatically generating feedback on pro-
gramming assignments. Unlike prior approaches, which works
under the assumption that close enough reference programs exist
in the corpus, Cafe can repair an incorrect submission by using
multiple, partially-matching reference programs. To achieve this,
we presented a new, context-aware repair algorithm. Evaluation
results with real student submissions show that Cafe has a high
fix rate and produces quality feedback actually useful for students.
ACKNOWLEDGMENTS
This work was supported by Institute of Information & communi-
cations Technology Planning & Evaluation(IITP) grant funded by
the Korea government(MSIT) (No.2020-0-01337,(SW STAR LAB)
Research on Highly-Practical Automated Software Repair) and Sam-
sung Research Funding & Incubation Center of Samsung Electronics
under Project Number SRFC-IT1701-51. This research was partly
supported by the MSIT(Ministry of Science and ICT), Korea, under
the ICT Creative Consilience program(IITP-2021-2020-0-01819) su-
pervised by the IITP(Institute for Information & communications
Technology Planning & Evaluation) and the National Research
Foundation of Korea (NRF) grant funded by the Korea government
(MSIT) (2020R1C1C1014518, 2021R1A5A1021944).ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece Dowon Song, Woosuk Lee, and Hakjoo Oh
REFERENCES
[1]U. Z. Ahmed, P. Kumar, A. Karkare, P. Kar, and S. Gulwani. 2018. Compila-
tion Error Repair: For the Student Programs, From the Student Programs. In
2018 IEEE/ACM 40th International Conference on Software Engineering: Software
Engineering Education and Training (ICSE-SEET) . 78â€“87.
[2]Umair Z. Ahmed, Nisheeth Srivastava, Renuka Sindhgatta, and Amey Karkare.
2020. Characterizing the Pedagogical Benefits of Adaptive Feedback for Com-
pilation Errors by Novice Programmers. In Proceedings of the ACM/IEEE 42nd
International Conference on Software Engineering: Software Engineering Education
and Training (Seoul, South Korea) (ICSE-SEET â€™20) . Association for Computing Ma-
chinery, New York, NY, USA, 139â€“150. https://doi.org/10.1145/3377814.3381703
[3]Johannes Bader, Andrew Scott, Michael Pradel, and Satish Chandra. 2019. Getafix:
Learning to Fix Bugs Automatically. Proc. ACM Program. Lang. 3, OOPSLA, Article
159 (Oct. 2019), 27 pages. https://doi.org/10.1145/3360585
[4]Xi Cheng, Min Zhou, Xiaoyu Song, Ming Gu, and Jiaguang Sun. 2017. IntPTI:
Automatic Integer Error Repair with Proper-type Inference. In Proceedings of
the 32Nd IEEE/ACM International Conference on Automated Software Engineering
(Urbana-Champaign, IL, USA) (ASE 2017) . IEEE Press, Piscataway, NJ, USA, 996â€“
1001. http://dl.acm.org/citation.cfm?id=3155562.3155693
[5]Loris Dâ€™Antoni, Roopsha Samanta, and Rishabh Singh. 2016. Qlose: Program
Repair with Quantiative Objectives. In 27th International Conference on Computer
Aided Verification (CAV 2016) (27th international conference on computer aided
verification (cav 2016) ed.).
[6]Daniel DeFreez, Aditya V. Thakur, and Cindy Rubio-GonzÃ¡lez. 2018. Path-Based
Function Embedding and Its Application to Error-Handling Specification Mining.
InProceedings of the 2018 26th ACM Joint Meeting on European Software Engineer-
ing Conference and Symposium on the Foundations of Software Engineering (Lake
Buena Vista, FL, USA) (ESEC/FSE 2018) . Association for Computing Machinery,
New York, NY, USA, 423â€“433. https://doi.org/10.1145/3236024.3236059
[7]A. Drummond, Y. Lu, S. Chaudhuri, C. Jermaine, J. Warren, and S. Rixner. 2014.
Learning to Grade Student Programs in a Massive Open Online Course. In 2014
IEEE International Conference on Data Mining . 785â€“790. https://doi.org/10.1109/
ICDM.2014.142
[8]Qing Gao, Yingfei Xiong, Yaqing Mi, Lu Zhang, Weikun Yang, Zhaoping Zhou,
Bing Xie, and Hong Mei. 2015. Safe Memory-leak Fixing for C Programs. In
Proceedings of the 37th International Conference on Software Engineering - Volume
1(Florence, Italy) (ICSE â€™15) . IEEE Press, Piscataway, NJ, USA, 459â€“470. http:
//dl.acm.org/citation.cfm?id=2818754.2818812
[9]L. Gazzola, D. Micucci, and L. Mariani. 2019. Automatic Software Repair: A
Survey. IEEE Transactions on Software Engineering 45, 1 (Jan 2019), 34â€“67. https:
//doi.org/10.1109/TSE.2017.2755013
[10] Elena L. Glassman, Jeremy Scott, Rishabh Singh, Philip J. Guo, and Robert C. Miller.
2015. OverCode: Visualizing Variation in Student Solutions to Programming
Problems at Scale. ACM Trans. Comput.-Hum. Interact. 22, 2, Article 7 (March
2015), 35 pages. https://doi.org/10.1145/2699751
[11] Sumit Gulwani, Ivan RadiÄek, and Florian Zuleger. 2014. Feedback Generation
for Performance Problems in Introductory Programming Assignments. In Pro-
ceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of
Software Engineering (Hong Kong, China) (FSE 2014) . Association for Computing
Machinery, New York, NY, USA, 41â€“51. https://doi.org/10.1145/2635868.2635912
[12] Sumit Gulwani, Ivan RadiÄek, and Florian Zuleger. 2018. Automated Clustering
and Program Repair for Introductory Programming Assignments. In Proceedings
of the 39th ACM SIGPLAN Conference on Programming Language Design and Im-
plementation (Philadelphia, PA, USA) (PLDI 2018) . Association for Computing Ma-
chinery, New York, NY, USA, 465â€“480. https://doi.org/10.1145/3192366.3192387
[13] Rahul Gupta, Aditya Kanade, and Shirish Shevade. 2019. Neural Attribution
for Semantic Bug-Localization in Student Programs. In Advances in Neural
Information Processing Systems 32 , H. Wallach, H. Larochelle, A. Beygelzimer,
F. d'AlchÃ©-Buc, E. Fox, and R. Garnett (Eds.). Curran Associates, Inc., 11884â€“
11894.
[14] Andrew Head, Elena Glassman, Gustavo Soares, Ryo Suzuki, Lucas Figueredo,
Loris Dâ€™Antoni, and BjÃ¶rn Hartmann. 2017. Writing Reusable Code Feedback
at Scale with Mixed-Initiative Program Synthesis. In Proceedings of the Fourth
(2017) ACM Conference on Learning @ Scale (Cambridge, Massachusetts, USA)
(L@S â€™17) . Association for Computing Machinery, New York, NY, USA, 89â€“98.
https://doi.org/10.1145/3051457.3051467
[15] Jordan Henkel, Shuvendu K. Lahiri, Ben Liblit, and Thomas Reps. 2018. Code Vec-
tors: Understanding Programs through Embedded Abstracted Symbolic Traces. In
Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering
Conference and Symposium on the Foundations of Software Engineering (Lake
Buena Vista, FL, USA) (ESEC/FSE 2018) . Association for Computing Machinery,
New York, NY, USA, 163â€“174. https://doi.org/10.1145/3236024.3236085
[16] Seongjoon Hong, Junhee Lee, Jeongsoo Lee, and Hakjoo Oh. 2020. SAVER:
Scalable, Precise, and Safe Memory-Error Repair. In Proceedings of the ACM/IEEE
42nd International Conference on Software Engineering (Seoul, South Korea) (ICSE
â€™20). Association for Computing Machinery, New York, NY, USA, 271â€“283. https:
//doi.org/10.1145/3377811.3380323[17] Yang Hu, Umair Z. Ahmed, Sergey Mechtaev, Ben Leong, and Abhik Roychoud-
hury. 2019. Re-Factoring Based Program Repair Applied to Programming As-
signments. In Proceedings of the 34th IEEE/ACM International Conference on Auto-
mated Software Engineering (San Diego, California) (ASE â€™19) . IEEE Press, 388â€“398.
https://doi.org/10.1109/ASE.2019.00044
[18] Minseok Jeon, Sehun Jeong, and Hakjoo Oh. 2018. Precise and Scalable Points-
to Analysis via Data-Driven Context Tunneling. Proc. ACM Program. Lang. 2,
OOPSLA, Article 140 (Oct. 2018), 29 pages. https://doi.org/10.1145/3276510
[19] Shalini Kaleeswaran, Anirudh Santhiar, Aditya Kanade, and Sumit Gulwani. 2016.
Semi-Supervised Verified Feedback Generation. In Proceedings of the 2016 24th
ACM SIGSOFT International Symposium on Foundations of Software Engineering
(Seattle, WA, USA) (FSE 2016) . Association for Computing Machinery, New York,
NY, USA, 739â€“750. https://doi.org/10.1145/2950290.2950363
[20] Dohyeong Kim, Yonghwi Kwon, Peng Liu, I. Luk Kim, David Mitchel Perry,
Xiangyu Zhang, and Gustavo Rodriguez-Rivera. 2016. Apex: Automatic Program-
ming Assignment Error Explanation. In Proceedings of the 2016 ACM SIGPLAN
International Conference on Object-Oriented Programming, Systems, Languages,
and Applications (Amsterdam, Netherlands) (OOPSLA 2016) . Association for Com-
puting Machinery, New York, NY, USA, 311â€“327. https://doi.org/10.1145/2983990.
2984031
[21] Junhee Lee, Seongjoon Hong, and Hakjoo Oh. 2018. MemFix: Static Analysis-
based Repair of Memory Deallocation Errors for C. In Proceedings of the 2018
26th ACM Joint Meeting on European Software Engineering Conference and Sym-
posium on the Foundations of Software Engineering (Lake Buena Vista, FL, USA)
(ESEC/FSE 2018) . ACM, New York, NY, USA, 95â€“106. https://doi.org/10.1145/
3236024.3236079
[22] Junho Lee, Dowon Song, Sunbeom So, and Hakjoo Oh. 2018. Automatic Diagnosis
and Correction of Logical Errors for Functional Programming Assignments.
Proc. ACM Program. Lang. 2, OOPSLA, Article 158 (Oct. 2018), 30 pages. https:
//doi.org/10.1145/3276528
[23] X. Liu, S. Wang, P. Wang, and D. Wu. 2019. Automatic Grading of Programming
Assignments: An Approach Based on Formal Semantics. In 2019 IEEE/ACM 41st
International Conference on Software Engineering: Software Engineering Education
and Training (ICSE-SEET) . 126â€“137. https://doi.org/10.1109/ICSE-SEET.2019.
00022
[24] Fan Long and Martin Rinard. 2015. Staged Program Repair with Condition
Synthesis. In Proceedings of the 2015 10th Joint Meeting on Foundations of Software
Engineering (Bergamo, Italy) (ESEC/FSE 2015) . ACM, New York, NY, USA, 166â€“178.
https://doi.org/10.1145/2786805.2786811
[25] Fan Long and Martin Rinard. 2016. Automatic Patch Generation by Learning
Correct Code. In Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT Sympo-
sium on Principles of Programming Languages (St. Petersburg, FL, USA) (POPL â€™16) .
ACM, New York, NY, USA, 298â€“312. https://doi.org/10.1145/2837614.2837617
[26] A. Marginean, J. Bader, S. Chandra, M. Harman, Y. Jia, K. Mao, A. Mols, and A.
Scott. 2019. SapFix: Automated End-to-end Repair at Scale. In Proceedings of the
41st International Conference on Software Engineering: Software Engineering in
Practice (Montreal, Quebec, Canada). IEEE Press, Piscataway, NJ, USA, 269â€“278.
https://doi.org/10.1109/ICSE-SEIP.2019.00039
[27] V. J. Marin, T. Pereira, S. Sridharan, and C. R. Rivero. 2017. Automated Per-
sonalized Feedback in Introductory Java Programming MOOCs. In 2017 IEEE
33rd International Conference on Data Engineering (ICDE) . 1259â€“1270. https:
//doi.org/10.1109/ICDE.2017.169
[28] Sergey Mechtaev, Manh-Dung Nguyen, Yannic Noller, Lars Grunske, and Abhik
Roychoudhury. 2018. Semantic Program Repair Using a Reference Implementa-
tion. In Proceedings of the 40th International Conference on Software Engineering
(Gothenburg, Sweden) (ICSE â€™18) . Association for Computing Machinery, New
York, NY, USA, 129â€“139. https://doi.org/10.1145/3180155.3180247
[29] Sergey Mechtaev, Jooyong Yi, and Abhik Roychoudhury. 2016. Angelix: Scalable
Multiline Program Patch Synthesis via Symbolic Analysis. In Proceedings of the
38th International Conference on Software Engineering (Austin, Texas) (ICSE â€™16) .
ACM, New York, NY, USA, 691â€“701. https://doi.org/10.1145/2884781.2884807
[30] Martin Monperrus. 2018. Automatic Software Repair: A Bibliography. ACM
Comput. Surv. 51, 1, Article 17 (Jan. 2018), 24 pages. https://doi.org/10.1145/
3105906
[31] Andy Nguyen, Christopher Piech, Jonathan Huang, and Leonidas Guibas. 2014.
Codewebs: Scalable Homework Search for Massive Open Online Programming
Courses. In Proceedings of the 23rd International Conference on World Wide Web
(Seoul, Korea) (WWW â€™14) . Association for Computing Machinery, New York,
NY, USA, 491â€“502. https://doi.org/10.1145/2566486.2568023
[32] Flemming Nielson, Hanne R. Nielson, and Chris Hankin. 1999. Principles of
Program Analysis . Springer-Verlag, Berlin, Heidelberg.
[33] Sagar Parihar, Ziyaan Dadachanji, Praveen Kumar Singh, Rajdeep Das, Amey
Karkare, and Arnab Bhattacharya. 2017. Automatic Grading and Feedback Using
Program Repair for Introductory Programming Courses. In Proceedings of the
2017 ACM Conference on Innovation and Technology in Computer Science Education
(Bologna, Italy) (ITiCSE â€™17) . Association for Computing Machinery, New York,
NY, USA, 92â€“97. https://doi.org/10.1145/3059009.3059026Context-Aware and Data-Driven Feedback Generation for Programming Assignments ESEC/FSE â€™21, August 23â€“28, 2021, Athens, Greece
[34] David M. Perry, Dohyeong Kim, Roopsha Samanta, and Xiangyu Zhang. 2019.
SemCluster: Clustering of Imperative Programming Assignments Based on Quan-
titative Semantic Features. In Proceedings of the 40th ACM SIGPLAN Conference
on Programming Language Design and Implementation (Phoenix, AZ, USA) (PLDI
2019) . Association for Computing Machinery, New York, NY, USA, 860â€“873.
https://doi.org/10.1145/3314221.3314629
[35] Yewen Pu, Karthik Narasimhan, Armando Solar-Lezama, and Regina Barzilay.
2016.ğ‘†ğ‘˜ğ‘: A Neural Program Corrector for MOOCs. In Companion Proceedings
of the 2016 ACM SIGPLAN International Conference on Systems, Programming,
Languages and Applications: Software for Humanity (Amsterdam, Netherlands)
(SPLASH Companion 2016) . Association for Computing Machinery, New York,
NY, USA, 39â€“40. https://doi.org/10.1145/2984043.2989222
[36] Reudismam Rolim, Gustavo Soares, Loris Dâ€™Antoni, Oleksandr Polozov, Sumit
Gulwani, Rohit Gheyi, Ryo Suzuki, and BjÃ¶rn Hartmann. 2017. Learning Syntactic
Program Transformations from Examples. In Proceedings of the 39th International
Conference on Software Engineering (Buenos Aires, Argentina) (ICSE â€™17) . IEEE
Press, 404â€“415. https://doi.org/10.1109/ICSE.2017.44
[37] Georgios Sakkas, Madeline Endres, Benjamin Cosman, Westley Weimer, and
Ranjit Jhala. 2020. Type Error Feedback via Analytic Program Repair. In Proceed-
ings of the 41st ACM SIGPLAN Conference on Programming Language Design and
Implementation (London, UK) (PLDI 2020) . Association for Computing Machinery,
New York, NY, USA, 16â€“30. https://doi.org/10.1145/3385412.3386005
[38] Alex Shaw, Dusten Doggett, and Munawar Hafiz. 2014. Automatically Fixing C
Buffer Overflows Using Program Transformations. In Proceedings of the 2014 44th
Annual IEEE/IFIP International Conference on Dependable Systems and Networks
(DSN â€™14) . IEEE Computer Society, Washington, DC, USA, 124â€“135. https://doi.
org/10.1109/DSN.2014.25
[39] Rishabh Singh, Sumit Gulwani, and Armando Solar-Lezama. 2013. Automated
Feedback Generation for Introductory Programming Assignments. In Proceedings
of the 34th ACM SIGPLAN Conference on Programming Language Design and
Implementation (Seattle, Washington, USA) (PLDI â€™13) . Association for Computing
Machinery, New York, NY, USA, 15â€“26. https://doi.org/10.1145/2491956.2462195
[40] Dowon Song, Myungho Lee, and Hakjoo Oh. 2019. Automatic and Scalable
Detection of Logical Errors in Functional Programming Assignments. Proc. ACMProgram. Lang. 3, OOPSLA, Article 188 (Oct. 2019), 30 pages. https://doi.org/10.
1145/3360614
[41] Rijnard van Tonder and Claire Le Goues. 2018. Static Automated Program Repair
for Heap Properties. In Proceedings of the 40th International Conference on Software
Engineering (Gothenburg, Sweden) (ICSE â€™18) . ACM, New York, NY, USA, 151â€“162.
https://doi.org/10.1145/3180155.3180250
[42] Ke Wang, Rishabh Singh, and Zhendong Su. 2018. Dynamic Neural Program Em-
beddings for Program Repair. In 6th International Conference on Learning Represen-
tations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track
Proceedings . OpenReview.net. https://openreview.net/forum?id=BJuWrGW0Z
[43] Ke Wang, Rishabh Singh, and Zhendong Su. 2018. Search, Align, and Repair:
Data-Driven Feedback Generation for Introductory Programming Exercises. In
Proceedings of the 39th ACM SIGPLAN Conference on Programming Language
Design and Implementation (Philadelphia, PA, USA) (PLDI 2018) . Association for
Computing Machinery, New York, NY, USA, 481â€“495. https://doi.org/10.1145/
3192366.3192384
[44] Westley Weimer. 2006. Patches as better bug reports. In Proceedings of the 5th
international conference on Generative programming and component engineering .
ACM, 181â€“190.
[45] Westley Weimer, ThanhVu Nguyen, Claire Le Goues, and Stephanie Forrest. 2009.
Automatically Finding Patches Using Genetic Programming. In Proceedings of the
31st International Conference on Software Engineering (ICSE â€™09) . IEEE Computer
Society, Washington, DC, USA, 364â€“374. https://doi.org/10.1109/ICSE.2009.
5070536
[46] Yingfei Xiong, Jie Wang, Runfa Yan, Jiachen Zhang, Shi Han, Gang Huang, and Lu
Zhang. 2017. Precise Condition Synthesis for Program Repair. In Proceedings of the
39th International Conference on Software Engineering (Buenos Aires, Argentina)
(ICSE â€™17) . IEEE Press, Piscataway, NJ, USA, 416â€“426. https://doi.org/10.1109/
ICSE.2017.45
[47] Xuezheng Xu, Yulei Sui, Hua Yan, and Jingling Xue. 2019. VFix: Value-flow-
guided Precise Program Repair for Null Pointer Dereferences. In Proceedings
of the 41st International Conference on Software Engineering (Montreal, Quebec,
Canada) (ICSE â€™19) . IEEE Press, Piscataway, NJ, USA, 512â€“523. https://doi.org/10.
1109/ICSE.2019.00063