UTANGO: Untangling Commits with Context-Aware,
Graph-Based, Code Change Clustering Learning Model
Yi Li
New Jersey Institute of Technology
New Jersey, USA
yl622@njit.eduShaohua Wangâˆ—
New Jersey Institute of Technology
New Jersey, USA
davidsw@njit.eduTien N. Nguyen
University of Texas at Dallas
Texas, USA
tien.n.nguyen@utdallas.edu
ABSTRACT
During software evolution, developers make several changes and
commit them into the repositories. Unfortunately, many of them
tangle different purposes, both hampering program comprehension
and reducing separation of concerns. Automated approaches with
deterministic solutions have been proposed to untangle commits.
However, specifying an effective clustering criteria on the changes
in a commit for untangling is challenging for those approaches.
In this work, we present UTango , a machine learning (ML)-
based approach that learns to untangle the changes in a commit. We
develop a novel code change clustering learning model that learns to
cluster the code changes, represented by the embeddings, into dif-
ferent groups with different concerns. We adapt the agglomerative
clustering algorithm into a supervised-learning clustering model
operating on the learned code change embeddings via trainable pa-
rameters and a loss function in comparing the predicted clusters and
the correct ones during training. To facilitate our clustering learn-
ing model, we develop a context-aware, graph-based, code change
representation learning model , leveraging Label, Graph-based Con-
volution Network to produce the contextualized embeddings for code
changes , that integrates program dependencies and the surround-
ing contexts of the changes. The contexts and cloned code are also
explicitly represented, helping UTango distinguish the concerns.
Our empirical evaluation on C# and Java datasets with 1,612 and
14k tangled commits show that it achieves the accuracy of 28.6%â€“
462.5% and 13.3%â€“100.0% relatively higher than the state-of-the-art
commit-untangling approaches for C# and Java, respectively.
CCS CONCEPTS
â€¢Software and its engineering â†’Software evolution .
KEYWORDS
Commit Untangling; Deep Learning; Code Change Embeddings
ACM Reference Format:
Yi Li, Shaohua Wang, and Tien N. Nguyen. 2022. UTANGO: Untangling Com-
mits with Context-Aware, Graph-Based, Code Change Clustering Learning
âˆ—Corresponding Author
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore
Â©2022 Association for Computing Machinery.
ACM ISBN 978-1-4503-9413-0/22/11. . . $15.00
https://doi.org/10.1145/3540250.3549171Model. In Proceedings of the 30th ACM Joint European Software Engineering
Conference and Symposium on the Foundations of Software Engineering (ES-
EC/FSE â€™22), November 14â€“18, 2022, Singapore, Singapore. ACM, New York,
NY, USA, 12 pages. https://doi.org/10.1145/3540250.3549171
1 INTRODUCTION
During software evolution, developers make changes over time to
perform software maintenance tasks. The changes to source files
committed to the repository in the same transaction are referred
to as a change set or a commit . For separation of concerns, each
commit should be about one purpose or concern regarding the
programming task at hand. Unfortunately, it has been reported that
many commits tangle different concerns including the changes for
bug-fixing, refactoring, enhancements, improvements, or documen-
tation [ 10,11,19,21,26]. Such change sets are called tangled code
changes ortangled commits [10,11]. The prior work reported two
reasons for tangled commits from developersâ€™ perspective: time
pressure in committing the changes, and unclear relations between
the concerns for code changes [22].
Tangled commits pose several issues in software development.
First, they affect software quality as they hamper program compre-
hension [ 26] and reduce the separation of concerns in code changes
[22]. Second, the tangled commits might contain the bug-fixing
changes for one bug that are mixed with the fixes for other bugs as
well as other types of changes for refactoring, enhancements, or
documentation [ 10,11,21]. Those tangled commits have negative
impact on the accuracy of bug prediction or bug localization models
that rely on the changes mined from the repository [ 10,11]. Those
models are significantly affected by the tangled commits as they
consider an entire commit as for fixing or non-fixing.
Recognizing the need of tools that untangle, i.e., decompose a
commit into untangled changes, researchers have proposed several
approaches. The automated commit-untangling approaches can be
broadly classified into two categories: mining software repositories [6,
10, 11, 14, 15], and program analysis [4, 20, 22, 24].
First, the earlier approaches leveraged mining software reposito-
ries (MSR) techniques to untangle commits. Herzig et al. [10,11]
utilize a confidence voter technique with agglomerative clustering
on change operations for untangling. The voters consider data de-
pendencies, call graphs, change couplings, and distances. Kirinuki
et al. [14,15] consider a commit as tangled if it includes another
commit in the past. However, there are tangled commits whose
parts have not occurred in the past. Dias et al. [6] use confidence vot-
ers on the fine-grained change events in an editor. The confidence
scores are converted into the similarity scores via a Random For-
est Regressor, which are then used in an agglomerative clustering
algorithm to partition the tangled changes.
221
ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore Yi Li, Shaohua Wang, and Tien N. Nguyen
The second category of untangling approaches leverage the static
analysis techniques. Roover et al. [20] use program slicing to seg-
ment a commit across a Program Dependency Graph (PDG). How-
ever, it is limited in handling inter-procedural and cross-file depen-
dencies. Barnett et al. [4] use def-use chains, and cluster them. If the
def-use chain all falls into a method, it is considered as trivial, oth-
erwise, non-trivial. Because ignoring the trivial clusters, it can miss
tangled concerns. Flexeme [ 22] uses multi-version PDG augmented
with name flows in the edges, and applies agglomerative cluster-
ing using graph similarity on that graph to untangle the commits.
SmartCommit [ 24] uses a graph-partitioning algorithm on a graph
representation to capture the relations among code changes (hard
and soft links, refactoring links, cosmetic links, etc.).
Despite their successes, the state-of-the-art untangling commit
techniques still have limitations. First, the boundaries across con-
cerns in a commit do not necessarily and naturally map to clustering
criteria of a clustering algorithm running on the PDG, name flows,
program slices, change operations, or the changes themselves. The
concerns might be linked via multiple edges. To apply a cluster-
ing algorithm on the PDG, program slices, or change graphs, it is
challenging to deterministically specify the right criteria to obtain
perfect partitions matching with the concerns. Second, the goal
is to decompose the changes in a commit. However, the existing
approaches do not consider a change w.r.t. the context of surrounding
code with a clear distinction of the changed elements and the un-
changed ones in the context . Such context could help distinguish the
concerns for the changes. Finally, not all the changes in the same
concern need to have program dependencies among them. The
logic connection among the co-changed code in the same commit
could be due to the reasons different than program dependencies.
For example, two pieces of cloned code realizing the same bubble
sorting algorithm have the same bug, e.g., at the comparison opera-
tor. They might be changed for the same concern to fix that logic
bug despite that they have no data/control dependency.
To address those challenges, in this paper, we propose UTango ,
anovel code change clustering learning model that learns to un-
tangle a commit by clustering the code changes (represented by the
embeddings) into groups for different concerns. While deterministic
clustering criteria on the PDG, slices, or change operations do not
always produce the clusters that naturally map to the boundaries
between the concerns, a machine learning (ML) model is expected
to learn to cluster the changes, thus, untangling a commit. Our ML
model learns from the changes belonging to the same concerns in
the version history. To build the training data for such learning, we
adapt Herzig et al. [10]â€™s method to mine the changes for the same
concerns in the version history (Section 3). To facilitate learning to
cluster code changes, we develop a context-aware, graph-based,
code change representation learning (RL) model , leveraging
Label, Graph-based Convolution Network [ 5] to produce the con-
textualized embeddings for code changes .
Our clustering learning model and context-aware, graph-based
RL model have the following unique characteristics that facili-
tates the untangling of code changes. First, we use Label-GCN
(Graph Convolutional Network) [ 5] to model the changes and sur-
rounding code by integrating both the versions before and after
changes in a multi-version program dependence graph, ğ›¿-PDG [ 22].
ğ›¿-PDG encodes the program dependencies among the changed andunchanged statements . Second, to decompose the changes, we ex-
plicitly represent the surrounding code context of each change . The
explicit representation of the context could help UTango learn
the important features of a change (e.g., code structures, data/con-
trol dependencies) to distinguish its concern among others. Third,
UTango also considers an implicit relationship: the cloned code
that is similar to the changed code under study. The idea is that
thetwocloned code with similar logic might be changed in the same
manner in the same concern in a commit . Fourth, to untangle a
commit, in our code change clustering learning model, agglomera-
tive clustering runs on contextualized embeddings for code changes
that integrates richer, encoded information than the PDG or pro-
gram slices, thus, helping better distinguish the concerns of the
changes. Finally, we adapt the agglomerative clustering algorithm
into a supervised-learning clustering model with trainable parame-
ters and a loss function to adjust the parameters by comparing the
predicted clusters and the correct ones during training.
We have conducted several experiments to evaluate UTango .
Our experimental results on a real-world C# dataset with 1,612
tangled commits show that UTango achieves the accuracy of 36.4%,
28.6%, 55.2%, and 462.5% relatively higher than the baseline ap-
proaches Flexeme [ 22],ğ›¿-PDG+CV [ 22], Herzig et al. [10], and
Barnett et al. [4].UTango can correctly cluster 39% of the changed
statements into correct concerns. We also evaluated UTango in
a Java dataset with 14k+ tangled commits. The results show that
UTango achieves 13.3%â€“100% accuracy relatively higher than the
state-of-the-art approaches including SmartCommit [ 24]. Our sensi-
tivity analysis shows that all designed components in UTango con-
tributes positively to its accuracy. We show that the changed state-
ments in the same concerns are projected nearer to each other than
the ones in different concerns, helping UTango better in change
clustering. The key contributions of this work include:
1.UTango : an ML-based, commit-untangling approach
with a novel code change clustering learning model. It is
the first ML model that learns to untangle the commit by learn-
ing to cluster the code changes. UTango learns from the changes
belonging to the same concern in the version history. We adapt ag-
glomerative clustering into a supervised-learning clustering model.
2. A novel context-aware, graph-based representation learn-
ing for code changes. We design GCN-based model to produce
thecontextualized embeddings for the code changes , that integrates
program dependencies, changes, contexts, and cloned code.
3. Extensive empirical evaluation. We evaluated UTango
against the state-of-the-art approaches for untangling commits to
show its better performance. Our tool and data are available at [ 3].
2 MOTIVATION
2.1 Motivating Examples
Let us present a few real-world examples to motivate UTango .
2.1.1 Example 1. Figure 1 shows the changes at the commit r1192
of the JHotDraw project with the log â€œFixes NPE and implements
indentation of XML elementsâ€ . This is a tangled commit with two
concerns/purposes: 1) the fix for Null Pointer Exception occurred
at lines 4,7, and 10 of the Drawing class (the null argument was
replaced with Collections.emptyList() ); 2) the implementation of the
indentation of XML elements occurred at lines 16â€“18, and a few
222UTANGO: Untangling Commits with Context-Aware, Graph-Based, Code Change Clustering Learning Model ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore
1 Commit r1192: Fixes NPE and implements indentation of XML elements.
2 /trunk/jhotdraw8/src/main/java/org/jhotdraw8/draw/Drawing.java
3 ...
4 - public final static Key<List<URLÂ» AUTHOR_STYLESHEETS = new ...
(â€œauthorStylesheetsâ€, List.., new Class<?>[]{URI.class},., null);
5 + public final static Key<List<URIÂ» AUTHOR_STYLESHEETS = new ...
(â€œauthorStylesheetsâ€, List.class, new Class<?>[]{URI.class},...,
Collections.emptyList());
6 ...
7 - public final static Key<List<URIÂ» USER_AGENT_STYLESHEETS = new
SimpleFigureKey<>(â€œuserAgentStylesheetsâ€, List.class, new
Class<?>[]{URI.class},..., null);
8 + public final static Key<List<URIÂ» USER_AGENT_STYLESHEETS = new
SimpleFigureKey<> (â€œuserAgentStylesheetsâ€, List.class, new
Class<?>[]{URI.class},..., Collections.emptyList());
9 ...
10 - public final static Key<List<StringÂ» INLINE_STYLESHEETS=new ...
(â€œinlineStylesheetsâ€,List...,new Class<?>[]{String.class},.,null);
11 + public final static Key<List<StringÂ» INLINE_STYLESHEETS=new ...
(â€œinlineStylesheetsâ€, List.class, new Class<?>[]{String.class},...,
Collections.emptyList());
12 //------------------------------------------------------------------------
13 /trunk/jhotdraw8/src/main/java/org/jhotdraw8/draw/io/SimpleXmlIO.java
14 public Document toDocument(Drawing ..., Collection<Figure> selection)...{
15 for (Figure child : ordered) {
16 - writeNodeRecursively(doc, docElement, child);
17 -}
18 - docElement.appendChild(doc.createTextNode(â€œ...â€));
19 + writeNodeRecursively(doc, docElement, child, linebreak);
20 +}
21 + docElement.appendChild(doc.createTextNode(linebreak));
22 return doc; ...
23 }
Figure 1: A Tangled Commit at r1192 of JHotDraw
1 Commit r1023: Fixes bugs in FigureStyleManager
2 /trunk/jhotdraw8/src/main/java/org/jhotdraw8/draw/Drawing.java
3
4 - public final static Key<List<URIÂ» AUTHOR_STYLESHEETS = new
.(â€œauthorStylesheetsâ€, List.class, "<URI>",,..., null);
5 + public final static Key<List<URIÂ» AUTHOR_STYLESHEETS = new
.(â€œauthorStylesheetsâ€, List.., new Class<?>[]{URI.class},., null);
6
7 - public final static Key<List<URIÂ» USER_AGENT_STYLESHEETS=new
.(â€œuserAgentStylesheetsâ€, List.class, "<URI>",..., null);
8 + public final static Key<List<URIÂ» USER_AGENT_STYLESHEETS=new
SimpleFigureKey<> (â€œuserAgentStylesheetsâ€, List.class, new
Class<?>[]{URI.class},..., null);
9
10 - public final static Key<List<StringÂ» INLINE_STYLESHEETS=new
.(â€œinlineStylesheetsâ€, List.class, "<String>",..., null);
11 + public final static Key<List<StringÂ» INLINE_STYLESHEETS=new
.(â€œinlineStylesheetsâ€,List..,new Class<?>[]{String.class},.,null);
Figure 2: Same Statements as in r1192 were Changed at r1023
of JHotDraw and Belonged to Only One Concern
other lines of code in the SimpleXmlIO class and one line of code in
theDrawing class (not shown).
2.1.2 Example 2. Figure 2 shows the changes committed at r1023
earlier in JHotDraw. The changes at the lines 4, 7, and 10 of the
Drawing class were to the same statements as the ones in the r1192
commit in Figure 1. However, the commit at r1023 was for only one
concern as stated in the commit log â€œFixes bugs in FigureStyleM-
anagerâ€ . This example motivates us to build a ML model to learn
from the co-changes for the same concern in the version history to
untangle the current commit.
Observation 1 [Learn to Cluster Code Changes]. History of
the co-changed statements with the same concern could be a good
source for a machine learning model to learn to cluster the changed
statements, thus, untangling the current commit .
2.1.3 Example 3. Figure 3 shows another example in JHotDraw
project. At the commit r463, two changes at line 3 and line 13
are exactly the same with the addition of figure.isSelectable() to1 public void mousePressed(MouseEvent evt) {
2 ...//SelectionTool.java
3 - if (figure != null)
4 + if (figure != null && figure.isSelectable())
5 newTracker = createDragTracker(figure);
6 } else {
7 if (! evt.isShiftDown()) {...}
8 }
9 //-----------------------------------------------------------------------
10 protected void updateHoverHandles(DrawingView view, Figure f) {
11 ...// SelectAreaTracker.java
12 figure = f;
13 - if (figure != null)
14 + if (figure != null && figure.isSelectable())
15 hoverHandles.addAll(figure.createHandles(-1)); ...
16 }
Figure 3: Same Change in two Contexts for Different Con-
cerns at r463 of JHotDraw
check whether a figure is selectable or not. However, those two
exact changes occurred in two different methods mousePressed and
updateHoverHandles for two different concerns/purposes as noted in
the commit log. Line 4 was aimed to fix the tracking of a dragging
object as the mouse is pressed ( â€œFixed bug where setSelectable() on a
dragging figure did not workâ€ ). Line 14 was a fix for a different bug
as the hovered object needs to be selected ( â€œSelection classes now
check the flag on the hovering figures to be selected. â€ ). The addition of
figure.isSelectable() is common for checking if a figure is selectable
in the two tasks of dragging and hovering a figure. Without the
surrounding contexts, one could not tell whether two changes are
for the same purpose or not.
Observation 2 [Context]. The surrounding context consisting of
un-changed code is crucial to determine the concern of a change. The
same change in two contexts could be for different concerns .
Figure 1 also gives us an interesting observation. The changes
to fix the NPE at lines 4, 7, and 10 are exactly the same: nullâ†’
Collections.emptyList() . The three statements are cloned code of one
another to support for different stylesheets (author, user agent, and
inline stylesheets). In fact, the changes in Figure 2 also occurred
at the cloned statements. The three changes belong to the same
concern/purpose since they serve as a fix for the same logic despite
that there is no program dependency among them. The existing un-
tangling approaches [ 4,20,22,24] that require the explicit program
dependencies among the changes with the same purpose will not
classify these committed code as belonging to the same concern.
Observation 3 [Implicit Dependencies]. Two fragments of cloned
code have the same/similar logic, thus, have implicit dependencies,
and could be modified in the same manner to serve the same purpose.
2.2 Key Ideas
Inspired from the above observations, we propose UTango with
the following ideas.
2.2.1 Key Idea 1 [Code Change Clustering Learning Model]. Instead
of deciding a deterministic clustering criterion on the concrete arti-
facts (PDGs, program slices, code changes, operations, or change
graphs), from Observation 1, we build an ML model to untangle the
commits by learning to cluster code changes represented by embed-
dings, w.r.t. different concerns. The model learns from the history
of the co-changed statements in the same commits for the same
223ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore Yi Li, Shaohua Wang, and Tien N. Nguyen
concerns, and applies to cluster the changes in the current commit.
We also modify an agglomerative clustering algorithm into a super-
vised-learning clustering model via trainable parameters and a loss
function to compare the predicted and correct clusters.
2.2.2 Key Idea 2 [Context-aware, Graph-based Representation Learn-
ing for Code Changes]. We design a context-aware, graph-based,
representation learning model to learn the contextualized embed-
dings for the code changes that integrates program dependencies
among the program elements, and the contexts of code changes.
Leveraging the changes in the same concern in the history, we
train a Label, Graph-based Convolution Network [ 5] to learn the
embeddings and learn to cluster them. For prediction, we build a
supervised-learning agglomerative clustering algorithm that oper-
ates on the embeddings of code changes to produce the clusters for
the purpose of untangling the commit. We expect that supervised-
learning clustering on vectors is more effective than on those arti-
facts since the embeddings capture richer information integrated
from dependencies and contexts.
2.2.3 Key Idea 3 [Explicit Context Representation as a Weight to
Compute Vectors for Code Changes]. As seen in Observation 2, the
contexts of the code changes can help distinguish their concerns in
the commits. We represent code changes and the surrounding con-
text of a change via the multi-version program dependence graph,
ğ›¿-PDG [ 22], consisting of the elements of both versions before and
after the changes, and program dependencies. The context is defined
as the surrounding nodes of the changed statement node in that
graph. The Label-GCN is used to model the statements and their
program dependencies in ğ›¿-PDG as well as to learn the vector rep-
resenting the context for a change. The context vectors are then
used as the weights in learning contextualized embeddings for the
code changes.
2.2.4 Key Idea 4 [Implicit Dependencies among Cloned Code]. As
seen in Observation 3, the cloned code exhibits implicit depen-
dencies with regard to whether they can be changed in the same
commits for the same concerns. Thus, during the process of produc-
ing the final result, we also integrate the code clone relationships
to adjust the clusters produced by the clustering learning model.
3 APPROACH OVERVIEW
3.1 Important Concepts
Let us first define some important concepts used in UTango .
Definition 1 (Program Dependence Graph). Theprogram
dependency graph (PDG) [7] is a directed graph with a set ğ‘of
nodes and a set ğ¸of edges such that each node ğ‘›âˆˆğ‘represents
a program statement or a conditional expression; each edge ğ‘’âˆˆğ¸
represents the data or control flow among the statements.
Figure 4 shows the code change in a commit in which the state-
mentint next = i + 1; is replaced by var next = i + 1; . Figure 4 (a)
and (b) display the PDGs of the method FormatYear before and after
the change. All the nodes of the PDG before the change are marked
withğ‘–, and those of the PDG after the change are marked with ğ‘—.
Definition 2 (Multi-version Program Dependence Graph).
(ğ›¿-PDG ). Ağ›¿-PDGğ‘–,ğ‘—is a directed graph generated from the disjoint
union of all nodes and edges in the PDGs at versions ğ‘–andğ‘—[22].
Figure 4: Multi-Version Program Dependence Graph
Figure 4(c) displays the multi-version PDGğ‘–,ğ‘—(ğ›¿-PDGğ‘–,ğ‘—) that are
built from the two versions ğ‘–andğ‘—of the method FormatYear before
and after the change. In ğ›¿-PDGğ‘–,ğ‘—, the nodes labeled with either ğ‘–
orğ‘—appear only in the PDG for the version ğ‘–or the version ğ‘—. The
nodes labeled with ğ‘–,ğ‘—appear in the PDGs at both the versions.
Definition 3 (Changed/Un-changed Nodes). In the multi-
version PDG, ğ›¿-PDGğ‘–,ğ‘—for the versions before and after the change,
the changed nodes represent the changed statements, and are labeled
with eitherğ‘–orğ‘—, while the un-changed nodes are labeled with ğ‘–,ğ‘—.
In Figure 4(c), the node labeled with ğ‘–represents the deleted
statement, the node labeled with ğ‘—represents the added one, while
the nodes labeled with ğ‘–,ğ‘—are for the un-changed statements.
Definition 4 (Context). The context ğ¶of a changed node ğ‘›
is a sub-graph of the multi-version ğ›¿-PDGğ‘–,ğ‘—that includes all the
un-changed nodes within the ğ‘˜-hop neighbors of the changed node ğ‘›,
together with all the inducing edges among them.
In Figure 4(c), when ğ‘˜=1, the context for the changed node/state-
ment at line 5 consists of all three nodes labeled with ğ‘–,ğ‘—because
they are one hop from the changed node for â€˜ int next = i + 1; â€™.
3.2 Architecture Overview
Figure 5 illustrates the overview of our model, UTango .
3.2.1 Step 1. Building Multi-version PDG ( ğ›¿-PDGğ‘–,ğ‘—) and Contexts.
The first step is to build the ğ›¿-PDGğ‘–,ğ‘—graph and extract the context
sub-graphs for each changed statement from the two versions ğ‘–
andğ‘—before and after the changes. We adopt the multi-version
graph building algorithm from Flexeme [ 22]. Specifically, we first
generate the PDGs for both versions ğ‘–andğ‘—. We use the Git diff tool
on the source code to determine the changed and unchanged nodes
for the statements. The added nodes are kept in ğ›¿-PDGğ‘–,ğ‘—with the
labelsğ‘—as they appear in the newer version ğ‘—. We also retain the
deleted nodes and use the label ğ‘–for them. The unchanged nodes
between the versions are matched by using string similarity among
the respective statements to filter the candidates and line-span
proximity to rank them. When considering the edge changes, we
back-propagate the delete nodes to the edges flowing into them. We
also add all the unmatched edges in the newer version ğ‘—to the multi-
version PDGğ‘–,ğ‘—as the edges relevant to the added nodes. Details on
buildingğ›¿-PDGğ‘–,ğ‘—can be found in another document [22].
224UTANGO: Untangling Commits with Context-Aware, Graph-Based, Code Change Clustering Learning Model ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore
Figure 5: UTango : Architecture Overview
After constructing ğ›¿-PDGğ‘–,ğ‘—, for each changed node in the graph,
we collect all unchanged nodes within the ğ‘˜-hops and all their induc-
ing edges to build a sub-graph as the context for the changed node.
ğ›¿-PDGğ‘–,ğ‘—and the contexts for the changed nodes will be used as the
input for the next step. This step of building ğ›¿-PDGğ‘–,ğ‘—and contexts
is used in both training and predicting processes.
3.2.2 Step 2. Context-aware, Graph-based, Code Change Clustering
Learning Model. The task of this model is to learn to cluster the
code changes , represented by the changed nodes and corresponding
contexts inğ›¿-PDGğ‘–,ğ‘—. For that, UTango first learns to construct the
contextualized embeddings to represent the code changes via
our novel context-aware, graph-based code change represen-
tation learning model . In that model, to build the contextualized
embeddings, we leverage the Label-GCN [ 5] that can deal with
the nodes with multiple labels (used to denote the versions ğ‘–,ğ‘—) to
learn the representation vector ğ‘£for each node ğ‘›in the graph. For
a changed node ğ‘›ğ‘, we collect the vectors for the un-changed nodes
in the context for ğ‘›ğ‘into a matrix. We use a fully connected layer
to convert the matrix into a vector ğ‘£ğ‘ğ‘¡ğ‘¥to encode the contextual
information for the node ğ‘›ğ‘. The context vector ğ‘£ğ‘ğ‘¡ğ‘¥is then used
asa weight to represent the impact of the context on the learning to
produce the final vector for the changed node ğ‘›ğ‘.
With the contextualized embeddings built for all the changed
nodes inğ›¿-PDGğ‘–,ğ‘—, our code change clustering learning model
uses the hierarchical agglomerative clustering algorithm to cluster
the changed nodes represented by their embeddings. That clustering
algorithm is adapted into a supervised-learning clustering model
as follows. During training, we know the correct clusters of the
changed nodes from the training data. We define a trainable thresh-
oldfor the linkage when merging the smaller clusters into a larger
one. The trainable parameters of the model and the trainable thresh-
old are computed over many iterations in training as the predicted
clusters are compared against the correct clusters in the oracle. We
design a loss function considering such comparison to adjust the
modelâ€™s parameters over the iterations. For predicting, the trained
model is used to cluster the changed nodes in ğ›¿-PDGğ‘–,ğ‘—. The changed
nodes in the same cluster are treated as having the same concern.
3.2.3 Step 3. Updating Clusters via Code Clone Detection. After
having the resulting clusters from Step 2, we use a code clone
detection tool to detect if there is a cloned statement ğ‘ â€²ğ‘šof a changed
statementğ‘ ğ‘šin theğ›¿-PDGğ‘–,ğ‘—. If so, we check the clusters containing
ğ‘ ğ‘šandğ‘ â€²ğ‘š. When the clusters are different, we merge those clusters
for one concern if needed. After iterating over all the changed
statementsğ‘ ğ‘š, we obtain the final resulting clusters.3.3 Training and Predicting Processes
3.3.1 Training and Predicting. All the steps in Figure 5 are shared
between the training and predicting processes. The key difference
is that in training, the ground truth labels with respect to the clus-
ters (concern 1, concern 2, etc.) for the changed statements are
known, while in predicting, UTango predicts the clusters (concern
1, concern 2, etc.), and finally updates them via our code clone de-
tection process. During clustering the changes in a new commit, the
number of clusters is unknown and will be decided by our model.
3.3.2 Training Corpus. To train our clustering learning model, we
need to have a corpus of the past commits that were un-tangled into
multiple clusters, each for a different concern. We reuse the data col-
lection methodology by Herzig et al. [10], which was later used by
Partachi et al. [22], to build the artificial corpus of tangled commits.
The method mimics the way of a developer committing multiple
consecutive work units as a single patch, thus, mimics the tangled
commits that (s)he makes. The goal is to compose the tangled com-
mits from the atomic ones that were mined from the repositories.
Specifically, we detected the atomic commits and tangled them
to produce the tangled commits in a training dataset. We consider
the commits to satisfy the following conditions: 1) the changes
have been committed by the same developer within 14 days with
no commit by the same developer in-between them; 2) the change
namespaces whose names have a large prefix match; 3) the commits
contain frequently-changed-together files; and 4) the commit logs
do not contain â€œfixâ€, â€œbugâ€, â€œfeatureâ€, etc. multiple times. With this
data collection methodology, we can obtain the tangled commits
consisting of the clusters of atomic changes for training.
4 CONTEXT-AWARE, GRAPH-BASED, CODE
CHANGE, CLUSTERING LEARNING MODEL
After the first step, we obtain the multi-version ğ›¿-PDGğ‘–,ğ‘—and the
contexts of the changes (Section 3). We present in this section our
context-aware, graph-based, code change (CC) clustering learning
model. Our clustering learning model has two tasks: 1) taking the
computedğ›¿-PDGğ‘–,ğ‘—to learn the representation vectors (embed-
dings) for the changed code, and 2) performing clustering on those
embeddings to cluster the changed statements. During training, we
have the ground truth on the clusters of the changed statements,
thus, we have the cluster labels (concern 1, concern 2, etc.) for
the changed nodes in ğ›¿-PDGğ‘–,ğ‘—. During predicting (i.e., clustering),
the inputğ›¿-PDGğ‘–,ğ‘—will be fed into the trained clustering learning
model to produce the cluster labels for the changed nodes. Note: for
a givenğ›¿-PDGğ‘–,ğ‘—, the number of clusters is unknown to our model,
225ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore Yi Li, Shaohua Wang, and Tien N. Nguyen
Figure 6: Context-aware, Graph-based, Code Change, Clustering Learning Model
and will be decided by the model during agglomerative clustering.
Let us detail those two tasks of our clustering learning model.
4.1 Representation Learning for Code Changes
This task aims to build the vector representations (i.e., embeddings)
for the code changes (i.e., changed statements) represented by the
changed nodes in ğ›¿-PDGğ‘–,ğ‘—. A characteristic of the embeddings
for code changes is context-aware orcontextualized : the same code
change in different contexts will have different embeddings.
4.1.1 Label, Graph Convolutional Network (Label-GCN). To achieve
that, UTango first feeds the multi-version ğ›¿-PDGğ‘–,ğ‘—to a graph-
based ML model to learn the contextualized embeddings for the
nodes in the graph. Since ğ›¿-PDGğ‘–,ğ‘—contains the labels (i.e., ğ‘–,ğ‘—,
(ğ‘–,ğ‘—)) representing the (un)changes, we use Label-GCN [ 5] to learn
the graph structure and the node features with change labels.
Similar to GCN [ 13], Label-GCN [ 5] takes the graph with node
features as input and produces the vectors for the nodes, when
considering the features of the neighboring nodes of each node.
In addition, for the current node, in the first layer, Label-GCN
considers the change labels of the neighboring nodes as part of the
feature vectors. It computes the vectors in the first layer as follows:
ğ»1=ğœ[(Ë†ğ´ğ‘‹âˆ’ğ‘‘ğ‘–ğ‘ğ‘”(Ë†ğ´)ğ¾âˆ‘ï¸
ğ‘—=1ğ‘’ğ‘—ğ‘’ğ‘‡
ğ‘—)ğ‘Š0] (1)
Ë†ğ´=Ëœğ·âˆ’1
2Ëœğ´Ëœğ·âˆ’1
2 (2)
Ëœğ´=ğ´+ğ¼ (3)
Whereğ»is the output for the first hidden layer; ğ´is the adjacency
matrix; Ëœğ·is the diagonal node degree matrix; ğ‘Šis the weight
matrix;ğ‘‹is the input and ğ‘‹âˆˆğ‘…ğ‘›ğ‘¥(ğ‘‘+ğ¾);ğ‘›is the number of
nodes;ğ‘‘is the dimension of node features; ğ¾is the number of
types of change labels in the input; ğ‘’ğ‘—ğ‘’ğ‘‡
ğ‘—a single-entry matrix;
andâˆ’ğ‘‘ğ‘–ğ‘ğ‘”(Ë†ğ´)Ãğ¾
ğ‘—=1ğ‘’ğ‘—ğ‘’ğ‘‡
ğ‘—is used to eliminates the self-loops for the
components of the feature vectors corresponding to the labels.
In Label-GCN, the following layers after the first layer follow
the same process as in the GCN model [ 13] to compute the hidden
states. The computation in a following layer ğ‘™is as follows:
ğ»ğ‘™+1=ğœ(Ë†ğ´ğ»ğ‘™ğ‘Šğ‘™),ğ‘™â‰¥1 (4)
4.1.2 Using Label-GCN to Model ğ›¿-PDGğ‘–,ğ‘—.Let us explain how we
process the multi-version ğ›¿-PDGğ‘–,ğ‘—to produce the input for the
Label-GCN model. For each node ğ‘›of a statement ğ‘ inğ›¿-PDGğ‘–,ğ‘—, we
breakğ‘ down into the code tokens ğ‘¡, and build the vector ğ‘’ğ‘¡forğ‘¡using a word embedding technique [ 23]. The vector for the node ğ‘›
is the average vector ğ´ğ‘£ğ‘”ğ‘›of the vectors of all the tokens ğ‘¡within
the corresponding statement ğ‘ . Because each node ğ‘›has a change
labelğ‘–,ğ‘—, or(ğ‘–,ğ‘—)for the versions, we combine ğ´ğ‘£ğ‘”ğ‘›with the one-
hot vector of the length 3 representing the labels ğ‘–,ğ‘—, or(ğ‘–,ğ‘—). As
a result, the combined vector ğ‘£ğ‘›(with the length of ğ‘™ğ‘’ğ‘›(ğ´ğ‘£ğ‘”ğ‘›)+3)
is the node feature vector forğ‘›. Then, we build the graph with the
same structure as ğ›¿-PDGğ‘–,ğ‘—in which a node ğ‘›is replaced with the
node feature vector ğ‘£ğ‘›, and feed that graph to the Label-GCN model
to obtain the embeddings ğ‘‰ğ‘›for all the nodes ğ‘›inğ›¿-PDGğ‘–,ğ‘—.
4.1.3 Building Contexts and Contextualized Embeddings. After us-
ing Label-GCN, we obtain the vectors ğ‘‰ğ‘›for all the nodes ğ‘›. For
a changed node ğ‘›ğ‘, we collect the nodes in its context ğ‘ğ‘¡ğ‘¥(i.e., all
un-changed nodes that are the ğ‘˜-hop neighbors of ğ‘›together with
all the inducing edges among them). We merge all the vectors for
the nodes in ğ‘ğ‘¡ğ‘¥into a matrix accordingly to the order of the state-
ments in source code. We then use a fully-connected layer to build
the vectorğ‘£ğ‘ğ‘¡ğ‘¥representing the context ğ‘ğ‘¡ğ‘¥of the changed node
ğ‘›ğ‘. Finally, we perform a cross-product between the context vector
ğ‘£ğ‘ğ‘¡ğ‘¥and the vector ğ‘‰ğ‘›ğ‘produced by Label-GCN for a changed node
ğ‘›ğ‘, to build the contextualized embedding ğ‘‰âˆ—ğ‘›ğ‘forğ‘›ğ‘.
Figure 6 illustrates the process of building the contextualized
embeddings for the code change example in Figure 4. ğ‘†3, ...,ğ‘†7are
the statements at the corresponding lines. After building ğ›¿-PDGğ‘–,ğ‘—,
UTango goes through the process described in Section 4.1.2 (i.e.,
building token embeddings, statement embeddings, and combining
with the labels) to produce the node feature vectors ğ‘£ğ‘›for the nodes
inğ›¿-PDGğ‘–,ğ‘—. The Label-GCN model takes the graph with the vectors
ğ‘£ğ‘›to produce the graph with the same structure in which each node
is represented by the vector ğ‘‰ğ‘›(ğ‘‰3, ...,ğ‘‰7). Let us use the node for
ğ‘‰6as an example. The context of 1-hop neighbors includes ğ‘‰3,ğ‘‰4,
andğ‘‰7. By merging those vectors as a matrix and passing through
a fully connected layer, we obtain the vector ğ‘£ğ‘ğ‘¡ğ‘¥representing the
1-hop context for ğ‘‰6. The cross-product vector ğ‘‰âˆ—
6=ğ‘£ğ‘ğ‘¡ğ‘¥Ã—ğ‘‰6is the
contextualized embedding representing the changed statement ğ‘†6.
4.2 Learning to Cluster Code Changes
4.2.1 Supervised-Learning Hierarchical Agglomerative Clustering.
After building the contextualized embeddings ğ‘‰âˆ—ğ‘›ğ‘for all the changed
nodesğ‘›ğ‘inğ›¿-PDGğ‘–,ğ‘—,UTango performs clustering on those vectors
to untangle the commit. We modified the hierarchical agglomera-
tive clustering algorithm [ 18] into a supervised-learning clustering
model to cluster those vectors based on the clusters of code changes
226UTANGO: Untangling Commits with Context-Aware, Graph-Based, Code Change Clustering Learning Model ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore
in the training data. Specifically, the training process for our code
change clustering learning model works as follows.
Step 1. We treat each changed node ğ‘›ğ‘as a separate cluster ğ¶ğ¿ğ‘.
Step 2. We merge any two clusters whose cluster similarity is the
largest and higher than a threshold ğ‘‡.
Step 3. We repeat the merging in Step 2 to form larger clusters
until there is no cluster that can be merged. After this step, we
obtain the predicted clusters ğ¶ğ¿at the current iteration.
Step 4. The predicted clusters ğ¶ğ¿at this iteration are compared
against the correct clusters ğ¶ğ¿ğ‘œğ‘Ÿğ‘ğ‘ğ‘™ğ‘’ in the ground truth. We de-
velop a loss function for our training to minimize the differences
between the predicted clusters ğ¶ğ¿and the correct clusters ğ¶ğ¿ğ‘œğ‘Ÿğ‘ğ‘ğ‘™ğ‘’ .
The parameters and the trainable threshold ğ‘‡will be updated ac-
cordingly to the loss function for the next iteration. The training
will stop when the process converges and we obtain the most suit-
able parameters for our clustering learning model.
Next, let us explain the key components in our algorithm.
4.2.2 Cluster Similarity. To compute the similarity between two
clustersğ¶ğ¿1andğ¶ğ¿2, we take all the pairs of the changed nodes
(ğ‘›1,ğ‘›2)whereğ‘›1âˆˆğ¶ğ¿1andğ‘›2âˆˆğ¶ğ¿2. We then compute the cosine
similarity between the corresponding vectors ğ‘‰âˆ—ğ‘›1andğ‘‰âˆ—ğ‘›2for each
pair. The similarity between two clusters is calculated as the average
of all the similarity scores of all the pairs (ğ‘›1,ğ‘›2).
4.2.3 Trainable Threshold T. In our model, we treat the merging
thresholdğ‘‡between smaller clusters as a trainable parameter .ğ‘‡is
updated after each iteration in accordance with the criteria defined
in the loss function as any other parameters of the model.
4.2.4 Loss Function. We need to have a loss function that mini-
mizes the differences between the predicted set of clusters ğ¶ğ¿={ğ¶ğ¿1,
ğ¶ğ¿2,...,ğ¶ğ¿ğ‘€}and the correct set ğ¶ğ¿ğ‘œğ‘Ÿğ‘ğ‘ğ‘™ğ‘’ ={ğ¶ğ‘œ1,ğ¶ğ‘œ 2,...,ğ¶ğ‘œğ‘}in
the oracle. Because the predicted and correct sets might have dif-
ferent numbers of clusters ( ğ‘€â‰ ğ‘), we first make them have the
same sizeM=ğ‘šğ‘ğ‘¥(ğ‘€,ğ‘)by adding the empty clusters to the
smaller set between ğ¶ğ¿andğ¶ğ¿ğ‘œğ‘Ÿğ‘ğ‘ğ‘™ğ‘’ . Because we do not know
what predicted cluster ğ¶ğ¿ğ‘–inğ¶ğ¿is mapped to a cluster ğ¶ğ‘œğ‘—in the
correct setğ¶ğ‘œğ‘Ÿğ‘ğ‘ğ‘™ğ‘’ , we consider all possible orders of the clusters
in bothğ¶ğ¿andğ¶ğ¿ğ‘œğ‘Ÿğ‘ğ‘ğ‘™ğ‘’ . The number of clusters is usually small
(â‰¤6 as reported in [ 21]), thus, it is manageable to consider all M!
possible orders in ğ¶ğ¿and allM!possible orders in ğ¶ğ‘œğ‘Ÿğ‘ğ‘ğ‘™ğ‘’ .
Let us consider an order in ğ¶ğ¿={ğ¶ğ¿â€²
1,...,ğ¶ğ¿â€²
M}, and an order
inğ¶ğ‘œğ‘Ÿğ‘ğ‘ğ‘™ğ‘’ ={ğ¶ğ‘œâ€²
1,...,ğ¶ğ‘œâ€²
M}. For a changed statement ğ‘ ğ‘with the
corresponding changed node ğ‘›ğ‘inğ›¿-PDGğ‘–,ğ‘—, we build the 1-hot
vectorğ‘‹of the lengthMthat represents the cluster for the node ğ‘›ğ‘
predicted by the model as follows. If ğ‘›ğ‘is predicted to belong to a
clusterğ¶ğ¿â€²
ğ‘–, the value at the ğ‘–ğ‘¡â„position of the vector ğ‘‹will be set
to 1, otherwise it is set to 0. For example, if M=4 and the changed
nodeğ‘›ğ‘is predicted to belong to the cluster ğ¶ğ¿â€²
3, the vector ğ‘‹is
{0,0,1,0}. Similarly, we build the 1-hot vector ğ‘Œto represent the
correct cluster for ğ‘›ğ‘in the oracle: if ğ‘›ğ‘belongs to a cluster ğ¶ğ‘œâ€²
ğ‘–,
the value at the ğ‘–ğ‘¡â„position of the vector ğ‘Œis 1, otherwise it is 0.
For a specific order in ğ¶ğ¿={ğ¶ğ¿â€²
1,...,ğ¶ğ¿â€²
M}, and a specific order
inğ¶ğ‘œğ‘Ÿğ‘ğ‘ğ‘™ğ‘’ ={ğ¶ğ‘œâ€²
1,...,ğ¶ğ‘œâ€²
M}, for a changed node ğ‘›ğ‘, we use the cross-
entropy loss function in the multi-class classification: ( ğ‘‹={ğ‘¥1,...,
ğ‘¥M},ğ‘Œ={ğ‘¦1,...,ğ‘¦M}are the predicted and correct vectors for ğ‘›ğ‘)ğ¿ğ‘œğ‘ ğ‘ (ğ‘‹,ğ‘Œ)=âˆ’Mâˆ‘ï¸
ğ‘–=1ğ‘Šğ‘–ğ‘™ğ‘œğ‘”ğ‘’ğ‘¥ğ‘(ğ‘¥ğ‘–)
ğ‘’ğ‘¥ğ‘(ÃM
ğ‘—=1ğ‘¥ğ‘—)ğ‘¦ğ‘– (5)
To adjust Formula 5 for our clustering problem, we consider all
possible orders in the cluster set ğ¶ğ¿and those in ğ¶ğ‘œğ‘Ÿğ‘ğ‘ğ‘™ğ‘’ . The cross-
entropy loss function for a changed node ğ‘›ğ‘of a changed statement
ğ‘ ğ‘is the minimum value among all the values on the right-hand
side of Formula 5. That is, our loss function is computed as follows.
ğ¿ğ‘œğ‘ ğ‘ â€²(ğ‘‹,ğ‘Œ)=min
ğ‘ğ‘™ğ‘™(M!)2
ğ‘œğ‘Ÿğ‘‘ğ‘’ğ‘Ÿğ‘ (âˆ’Mâˆ‘ï¸
ğ‘–=1ğ‘Šğ‘–ğ‘™ğ‘œğ‘”ğ‘’ğ‘¥ğ‘(ğ‘¥ğ‘–)
ğ‘’ğ‘¥ğ‘(ÃM
ğ‘—=1ğ‘¥ğ‘—)ğ‘¦ğ‘–) (6)
The loss function for each changed node ğ‘›ğ‘will be used for the
model to adjust the parameters in the next iteration.
4.2.5 Predicting/Clustering Process. After training, we obtain all
modelâ€™s parameters and the trainable merging threshold. For cluster-
ing,UTango takes ağ›¿-PDGğ‘–,ğ‘—as input and generates the resulting
set of clusters ğ¶ğ¿.
5 UPDATING CLUSTERS VIA CODE CLONE
DETECTION
Becauseğ›¿-PDGğ‘–,ğ‘—might not cover the changed statements that are
clones of one another, we use a code clone detection tool [ 25] to find
the changes that might belong to the same concerns but having no
data/control dependencies with one another. The clone detection
tool returns a list of clone candidates in the clone groups with
different sizes. First, we consider only the clone groups with the
cloned fragments containing the changed statements. If multiple
clone fragments contain the same changed statement, we choose
the clone fragment with the largest size to avoid the duplication
(because the larger clone contains the smaller one).
After predicting/clustering the changed nodes/statements as
explained in Section 4, we have marked each changed statement
with a concern. For each changed statement ğ‘ ğ‘in a clone group, we
check the clusters of its cloned statements and update the cluster
forğ‘ ğ‘via majority voting. For example, a changed statement ğ‘ ğ‘
marked with concern 1, and it belongs to a cloned fragment in
which the other statements in that fragment and their clones are
marked with concern 2 in their majority, then we change ğ‘ ğ‘to be
about concern 2. If there is no majority, we adjust the cluster of ğ‘ ğ‘
to the concern/cluster with a lower index for consistency.
6 EMPIRICAL EVALUATION
6.1 Research Questions
To evaluate UTango , we seek to answer the following questions:
RQ1. Comparative Study on an C# Dataset. How well does
UTango perform in comparison with the state-of-the-art commit-
untangling approaches on an C# dataset?
RQ2. Comparative Study on a Java Dataset. How well does
UTango perform in comparison with the state-of-the-art commit-
untangling approaches on a Java dataset?
RQ3. Within-Project Analysis. How well does UTango perform
when training and testing are done in the same project?
RQ4. Sensitivity Analysis. How do the key features in UTango
affect its overall performance?
227ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore Yi Li, Shaohua Wang, and Tien N. Nguyen
RQ5. Code Change Embedding Analysis. What are the prop-
erties of the contextualized embeddings from our context-aware,
graph-based representation learning model for code changes? The
answer will show the contribution of code change embeddings.
6.2 Datasets
We have conducted our evaluation on two datasets. The first one
is a C# dataset that has been used in the commit-untangling work,
Flexeme [ 22]. This C# dataset contains 1,612 tangled commits (each
hasâ‰¤3 concerns) in 9 Github projects. We use this C# dataset for all
RQs except RQ2. In RQ2, to evaluate UTango on Java and compare
against the state-of-the-art SmartCommit [ 24] (working on Java
only), we collected a new dataset by following the same process in
that paper. The Java dataset contains +14K tangled commits in 10
GitHub projects. The number of concerns in a commit is from 2â€“32.
6.3 Experimental Methodology
6.3.1 RQ1. Comparison with Existing Approaches on C# Dataset.
Baselines. We compared UTango against the state-of-the-art commit-
untangling approaches that work on C# (see more details in Sec-
tion 8): Barnett et al. [4], Herzig et al. [10], Flexeme [ 22], andğ›¿-
PDG+CV [ 22] (ğ›¿-PDG+CV is a model introduced by the authors
of Flexeme via combining their ğ›¿-PDG with confidence voting in
Herzig et al. [10]).
Procedure. We took all the commits in the C# dataset and sorted
them in the chronological order based on the creation time of the
commit logs. For UTango , we then used 80% of the oldest commits
for training, 10% of the next oldest ones for tuning, and the latest
10% of the commits for testing. For the baselines, all of them do not
need training, thus, we ran them on the 10% testing data. We did
not use the setting of leave-one-out by project (testing on part of a
project and training on other 8 projects). The reason is that after
sorting in a chronological order, we could not test on the oldest
project due to no training data. Even with the 2nd-5th oldest ones,
there is no sufficient training data of the commits that came from
the older projects and before the test commits in those projects.
We tuned UTango with autoML [ 1] for the following key hyper-
parameters to have the best performance: (1) Epoch size (100, 200,
300); (2) Batch size (64, 128, 256); (3) Learning rate (0.001, 0.003,
0.005, 0.010); (4) Vector length of word embeddings and its output
(150, 200, 250, 300). We empirically set the context size of 2 (RQ4).
6.3.2 RQ2. Comparison with Existing Approaches on Java Dataset.
Baselines. We compare UTango with the state-of-the-art untangling
approach that works on Java source code, SmartCommit [ 24], and
the baselines used in their paper: Base-1 [ 24] (a rule-based approach
that puts all changes into one group), Base-2 [ 24] (a rule-based
approach that puts the changes in each file into one group), and
Base-3 [ 24] (a rule-based approach that considers only def-use,
use-use and same-enclosing-method relations).
Procedure. We used the same procedure, tuning (with autoML [ 1]),
and parameters as in RQ1 on the Java dataset. The baselines do not
need training, thus, we ran them on the 10% testing data.
6.3.3 RQ3. Within-Project Analysis. We randomly selected one of
the largest projects from each dataset: the CommandLine project in C#
and the netty project in Java. For each project, we sorted all of thecommits in the chronological order based on commit time. We split
the commits into 80%, 10%, 10% for training, tuning, and testing,
and using the older data for training and the newer data for tuning
and testing. We separately trained, fine-tuned, and tested a model
under study on the commits in each project.
6.3.4 RQ4. Sensitivity Analysis. We built the variants of UTango
by removing its important components, one at a time. First, we
removed from UTango the context by not using the context vector
when computing the vector for a changed statement. Second, we
removed from UTango the clone detection component and used the
resulting clusters from the code change clustering learning model
as the final results. Third, we studied the impact of the size K of a
context on the accuracy. We also studied the impact of the data size.
We used the C# dataset and the same setting/procedure as in RQ1.
6.3.5 RQ5. Code Change Embedding Analysis. We use statistical
ğ‘-test to confirm/refute the hypothesis that the changed statements
in the same concerns are projected nearer to one another than the
changed ones in different concerns in the vector space.
Evaluation Metrics. We use two evaluation metrics. First, ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘
is defined as the percentage of the changed statements that are
labeled with a correct cluster/concern in all the statements in a
commit: Accuracyc=#ğ‘â„ğ‘ğ‘›ğ‘”ğ‘’ğ‘‘ğ‘ ğ‘¡ğ‘šğ‘¡ğ‘ ğ‘¤.ğ‘ğ‘œğ‘Ÿğ‘Ÿğ‘’ğ‘ğ‘¡ğ‘ğ‘™ğ‘¢ğ‘ ğ‘¡ğ‘’ğ‘Ÿğ‘ 
#ğ‘ğ‘™ğ‘™ğ‘â„ğ‘ğ‘›ğ‘”ğ‘’ğ‘‘ğ‘ ğ‘¡ğ‘šğ‘¡ğ‘ ğ‘–ğ‘›ğ‘ğ‘œğ‘šğ‘šğ‘–ğ‘¡. Note that a
model might label the statements with a different permutation of
cluster labels than the one in the ground truth. For example, we have
five statements and three concerns. A model can predict [3,1,1,2,2]
and the ground truth has [1,2,2,3,3]. A naive evaluation would give
an accuracy of 0.0. However, a permutation of the labels for clusters
would give indeed an accuracy of 1.0. Thus, we use the Hungarian
Algorithm [ 16] to find the permutation that gives the maximum
accuracy, and use that for ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘.
In RQ1, for the comparison with Flexeme [ 22], we also used
another metric that was used in their paper, which is similar to
ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘except that it considers all statements: Accuracya=
#ğ‘ ğ‘¡ğ‘šğ‘¡ğ‘ ğ‘¤.ğ‘ğ‘œğ‘Ÿğ‘Ÿğ‘’ğ‘ğ‘¡ğ‘ğ‘™ğ‘¢ğ‘ ğ‘¡ğ‘’ğ‘Ÿğ‘ 
#ğ‘ğ‘™ğ‘™ğ‘ ğ‘¡ğ‘šğ‘¡ğ‘ ğ‘–ğ‘›ğ‘ğ‘œğ‘šğ‘šğ‘–ğ‘¡. We also consider all label permutations.
7 EXPERIMENTAL RESULTS
7.1 RQ1. Comparative Study on C# Dataset
7.1.1 General Results. Table 1 shows the comparison on ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘
when it was measured on the changed statements. As seen, UTango
improves Barnett et al. , Herzig et al. ,ğœâˆ’PDG+CV, and Flexeme in
overallğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘by462.5%, 55.2%, 28.6% , and 36.4% , respectively.
Table 2 shows the results on ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘. Whenğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘was
measured on all the statements (changed and un-changed) in a com-
mit, the results for all models are higher because they have correct
classifications for the changed statements by default. We include
ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘for the comparison purpose with Flexeme (as its authors
used this metric in their paper). As seen, UTango also improves
Barnett et al. , Herzig et al. ,ğœâˆ’PDG+CV, and Flexeme by 584.6%,
32.8%, 7.2%, and9.9% in overallğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘, respectively. UTango â€™s
accuracies are consistently better than those of the baselines for
all the projects with respect to different numbers of concerns in
a commit ( #ğ¶s=2 or 3, Table 1). Some data points are unavailable
since those commits are older in the chronological order and appear
only in the training data, but not in the testing data.
228UTANGO: Untangling Commits with Context-Aware, Graph-Based, Code Change Clustering Learning Model ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore
Table 1: RQ1. Comparison on C# Dataset ( ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘%)
Barnett et al. Herzig et al.ğ›¿âˆ’PDG + CV Flexeme UTango
#Cs 2 3 OA 2 3 OA 2 3 OA 2 3 OA 2 3 OA
CL 14 *14 28 *28 34 *34 34 *3446 *46
CM * * * * * * * * * * * * * * *
HF 10 13 11 27 29 28 34 37 35 30 35 31 43 48 45
HU 13 *13 27 *27 30 *30 33 *3344 *44
LE 8 6 8 29 24 29 35 34 35 33 36 33 44 47 45
NA * * * * * * * * * * * * * * *
NJ 7 * 7 28 *28 34 *34 27 *2741 *41
NI 10 *10 26 *26 37 *37 32 *3246 *46
RS 911 9 31 30 31 30 36 31 32 35 33 42 49 43
OA 8 6 8 31 25 29 35 34 35 32 36 33 44 47 45
CL:Commandline, CM:CommonMark, HF:Hangfire, HU:Humanizer,
LE:Lean, NA:Nan cy, NJ:Newtonsoft.Json, NI:Ninject, RS:RestSharp,
OA: Overall, *: No avail data point.
Table 2: RQ1. Comparison on C# Dataset ( ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘%)
Barnett et al. Herzig et al.ğ›¿âˆ’PDG + CV Flexeme UTango
#Cs 2 3 OA 2 3 OA 2 3 OA 2 3 OA 2 3 OA
CL 18 21 19 67 48 64 77 84 80 82 92 82 90 *90
CM 20 *20 65 *65 90 *90 70 *70 * * *
HF 16 13 15 70 54 64 84 88 87 86 68 79 84 91 86
HU 18 31 18 64 42 62 69 *69 83 57 81 89 *89
LE 19 12 18 69 62 69 84 71 84 77 82 80 87 90 88
NA 9 8 9 70 56 67 86 80 86 81 92 84 * * *
NJ 15 11 15 71 56 71 86 69 82 71 52 71 83 *83
NI 14 *14 57 *57 94 *94 80 *8091 *91
RS 12 14 12 71 69 70 74 53 70 82 89 82 87 88 87
OA 14 11 13 69 62 67 83 84 83 81 84 81 88 91 89
CL:Commandline, CM:CommonMark, HF:Hangfire, HU:Humanizer,
LE:Lean, NA:Nan cy, NJ:Newtonsoft.Json, NI:Ninject, RS:RestSharp,
OA: Overall, *: No avail data point.
(a)ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘
(b)ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘
Figure 7: Boxplots for Results in Table 1 and Table 2.
Orange Boxes: 2-concern data, Yellow Boxes: 3-concern data
Figure 7 shows the boxplots for both ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘andğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘
results in Tables 1 and 2. The orange boxes are for the commits with
two concerns, while the yellow ones are for those with three con-
cerns. As seen, the median accuracy of UTango is higher than those
of all baselines on both types of two and three concerns. Moreover,
the gap (in %) between UTango and the baselines in ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘is
larger than the gap between them in ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘because all models
have correct classifications by default for the changed statements,
which are many more than the changed statements.
7.1.2 Accuracy Results for Concerns with Different Sizes. To better
understand UTango â€™s accuracy on concerns with different sizes,
Figure 8: Accuracies for Concerns with Different Numbers
of Statements in C# dataset
Table 3: RQ2. Comparison on Java Dataset ( ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘%)
Base-1 Base-2 Base-3 SmartCommit UTango
SB 14 23 21 29 32
ES 19 22 27 34 36
RJ 18 28 24 31 33
GU 21 31 25 33 37
RE 22 24 19 29 34
DU 15 19 18 24 29
GH 22 27 24 33 35
ZX 21 29 20 34 38
DR 17 29 18 32 34
EB 13 22 21 27 31
OA 17 25 23 30 34
SB: spring-boot, ES: elasticsearch, RJ: RxJava, GU:guava, RE: retrofit, DU:
dubbo, GH: ghidra, ZX: zxing, DR: druid, EB: EventBus, OA: Overall
we collected all concerns with different numbers of changed state-
ments and measured the accuracies for them. As seen in Figure 8,
ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘values for the concerns of small sizes (having 1â€“22
changed statements) are higher (ranging from 47%â€“54%). That is,
among all the changed statements, UTango correctly classified
about 50% of them into the correct clusters. For the larger concerns,
ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘decreases as expected because it is more challenging to
get correct classifications for more changed statements in a concern.
However,ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘decreases gradually with the lowest value of
â‰ˆ36%. Note: there are a few commits with the addition of large
files of+1.3k lines.
Despite challenges with large concerns, UTango correctly classi-
fied100% of all the changed statements for 15 commits with up to 19
statements. Flexeme fails to reach 100% for those commits. There
are only 9 commits that Flexeme correctly classified all the changed
statements and UTango did not reach 100%. Both models correctly
classified 100% of all the changed statements of 4 commits.
Training of UTango on80%of C# dataset takes 1.75 hours and
predicting on 10%of C# dataset takes 1.3-2.5 seconds per commit.
7.2 RQ2. Comparative Study on Java Dataset
7.2.1 General Results. Table 3 shows ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘when it was mea-
sured on the changed statements for Java code. As seen, on the
Java dataset, UTango improves Base-1, Base-2, Base-3, and Smart-
Commit in overall ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘by100.0%, 36.0%, 47.8% , and 13.3% ,
respectively. UTango â€™s accuracies are consistently better than those
of the baselines for all subject projects. Figure 9 shows the boxplot
forğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘result in Table 3. As seen, the median accuracy of
UTango is higher than those of the baselines.
229ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore Yi Li, Shaohua Wang, and Tien N. Nguyen
Figure 9: Boxplots for Results in Table 3
Figure 10: Accuracies for Concerns with Different Numbers
of Statements in Java dataset
7.2.2 Accuracy Results for Concerns with Different Sizes. As seen
in Figure 10, ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘values for the concerns of smaller sizes
(having 1â€“22 changed statements) are higher (ranging from 37%â€“
45%). That is, among all the changed statements, UTango correctly
classified 41% of them into the correct clusters. For larger concerns,
ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘decreases gradually. Even in the concerns with up to
336 changed statements, ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘is>=30%. The lowest accuracy
is 24%. Moreover, it correctly classified 100% of all the changed state-
ments for 95 commits in which SmartCommit failed to reach 100%.
There are 88 commits that SmartCommit correctly classified all the
changed statements and UTango did not reach 100%. Both models
correctly classified 100% of all changed statements of 21 commits.
Training of UTango on80%of the Java dataset takes 17 hours
and predicting on 10% of Java dataset takes 1.5-4.2 seconds per
commit. Note: the Java dataset is much larger than the C# dataset.
7.3 RQ3. Within-Project Analysis
Table 4 shows UTango â€™s results in the within and cross-project
settings. As seen, with sufficient within-project data, ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘in
the within-project setting is slightly better than that of the cross-
project setting for both C# and Java projects. This is expected since
the changes in the same project could be more similar than the
changes across projects. Thus, UTango works well in both within-
and cross-project settings for C# and Java projects.
7.4 RQ4. Sensitivity Analysis
Table 5 shows the accuracy results when the key components in
UTango were removed. As seen, while both context and clone
detection positively contribute to UTango â€™s accuracy, the context
plays a more important role as expected. Without the context vector,Table 4: RQ3. Results for Within- and Cross-project Settings
Project Within-Project Cross-Project
CommandLine (C#) 0.47 0.46
spring-boot (Java) 0.34 0.32
Table 5: RQ4. Impacts of Key Features on Accuracy
ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘
# concerns 2 3 Overall
UTango w/o Context 0.38 0.43 0.40
UTango w/o Clone Detection 0.42 0.44 0.43
UTango 0.44 0.47 0.45
Table 6: RQ4. Impact of the Number ğ‘˜of Hops for Context
ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘
#concerns 2 3 Overall
UTango (ğ‘˜=1) 0.42 0.45 0.43
UTango (ğ‘˜=2) 0.44 0.47 0.45
UTango (ğ‘˜=3) 0.43 0.45 0.44
UTango (ğ‘˜=4) 0.40 0.44 0.42
UTango (ğ‘˜=5) 0.41 0.44 0.42
UTango (Full Graph) 0.39 0.43 0.41
Table 7: Impact of the Size of Training Data
Splitting on C# dataset 80%/10%/10% 70%/15%/15% 60%/20%/20%
%ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ğ‘45% 42% 37%
the accuracy decreases by 13.7%, 8.5%, and 11.1% for the commits
with two, three, and all concerns, respectively. Without the clone
detection, the accuracy decreases by 4.5%, 6.4%, and 4.4% for the
commits with two, three, and all concerns, respectively.
Table 6 shows the accuracy when we vary the size ğ‘˜of a context
(i.e., the number of hops from the changed node). As seen, when
the number of surrounding nodes of the changed node increases
fromğ‘˜=1â€“2, the accuracy increases and reaches its peak at ğ‘˜=2. As
ğ‘˜=1, the immediate surrounding nodes cannot capture well the rele-
vant nodes for UTango to distinguish the concerns of the changed
statements. With two hops from the changed node, the context
seems to sufficiently contain the crucial nodes w.r.t. determining
the concerns. However, as the size continues to increase, the accu-
racy decreases. When the entire graph is used as the context, the
accuracy is the lowest. If more nodes are considered in the context,
more noises are added as more irrelevant data is used. The trend is
the same for the commits with two, three, or all concerns.
As seen in Table 7, the training dataâ€™s size has impact on accuracy.
The more training data, the higher the accuracy. Even reducing it
from 80% to 60%, UTango â€™s accuracy is still higher than Flexemeâ€™s.
7.5 RQ5. Analysis on Code Change Embeddings
To study the projections of the changed statements in the same
and different concerns, we first randomly chose the commits with
two or more clusters/concerns and in one of the cluster/concern,
there are at least two changed statements. Let us use ğ¶to denote
that cluster/concern. We randomly chose two changed statements
ğ‘†1andğ‘†2inğ¶. We then randomly selected another changed state-
mentğ‘†3such thatğ‘†3âˆ‰ğ¶andğ‘†3belongs to another cluster in the
same commit with ğ‘†1andğ‘†2. We measured the distance ğ‘‘1(ğ‘†1,ğ‘†2)
230UTANGO: Untangling Commits with Context-Aware, Graph-Based, Code Change Clustering Learning Model ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore
Figure 11: Code Change Embedding Visualization via t-SNE
andğ‘‘2(ğ‘†1,ğ‘†3). We repeated the process for all the commits satis-
fying the above conditions to get 384 triples of ( ğ‘†1,ğ‘†2,ğ‘†3). Based
on the population in our dataset, the size of 384 samples gives
the confidence level of 95% and the confidence interval of 5%. We
used statistical ğ‘-value to confirm our hypothesis ğ»1:ğ‘‘1(ğ‘†1,ğ‘†2)â‰¤
ğ‘‘2(ğ‘†1,ğ‘†3). The null-hypothesis is ğ»0:ğ‘‘1(ğ‘†1,ğ‘†2)>ğ‘‘2(ğ‘†1,ğ‘†3).
When we set the significance level ğ›¼=0.05, theğ‘-value is 0.03
(calculated on these 384 samples). In this case, the ğ‘-value is smaller
thanğ›¼, meaning the null hypothesis would be rejected at the level
ofğ›¼=0.05. Thus, our hypothesis ğ»1:ğ‘‘1(ğ‘†1,ğ‘†2)â‰¤ğ‘‘2(ğ‘†1,ğ‘†3)is con-
firmed. That is, the changed statements in the same concerns are
projected nearer to one another than the changed statements in dif-
ferent concerns. This result is an indication that our context-aware,
graph-based embeddings for code changes are helpful for UTango in
clustering the code changes via the embeddings into different concerns .
For illustration, we randomly picked a commit in our above sam-
ple. The commit contains three concerns in which one concern has
4 changed statements, another one has 12 changed statements, and
the last one has 6 changed statements. We used the ğ‘¡-distributed
stochastic neighbor embedding (t-SNE) [ 2] to visualize the embed-
dings of the changed statements in the vector space. t-SNE is a
statistical method for visualizing high-dimensional data by giving
each data point its projected location in a two-dimensional vector
space. As seen in Figure 11, we marked the embeddings for the
changed statements in each concern with a different color. The
correctly clustered changes are within the corresponding boundary
for a concern. Despite that UTango misclassified a few statements,
we can observe that the changes in each concern are projected to
the nearby locations in the vector space. This figure illustrates that
the our code change embeddings facilitate our supervised-learning
clustering model to correctly cluster the changed statements.
7.6 Discussions
7.6.1 Threats to Validity. Our study is only on C# and Java projects.
Our methodology is language-independent. The datasets of tangle
commits were built artificially from atomic commits. However, this
methodology was used in Flexeme [ 22] and Herzig et al. [11]. De-
spite that we did not use the setting of leave-one-out by project, our
setting reflects the actual use of our tool in which all the commits
in other projects that occurred before the current commit are used.
7.6.2 Limitations. UTango is less accurate for the commits with
too many changed statements ( >=40), or with too many concerns
(>=20). As with any data-driven approaches, it does not work well
with little data. We currently integrate only the code clone relations.We will explore other types of implicit relations, e.g., in event-driven
source code, or other links as in SmartCommit.
Trade-offs between UTango and program-analysis approaches:
without needing a threshold for clustering, UTango is more flexible
in learning the boundaries among clusters than PA approaches,
which rely on explicit program dependencies for clustering. Despite
needing no training data, Flexeme requires a median time of 9.56
seconds to untangle a commit. UTango takes only 1.3-2.5 seconds.
8 RELATED WORK
Tangled commits have been reported by researchers to have nega-
tive impacts on software maintenance [10, 11, 19, 21, 22, 24, 26].
Mining Software Repositories. Herzig et al. [10,11] combine confi-
dence voting with agglomerative clustering. Each confidence voter
is responsible for an important aspect, e.g., call-graphs, change
couplings, data dependencies, and distance measures. In Kirinuki et
al.â€™s [14,15], if there is a commit ğ‘šincluding the same changes as
a past commit and other changes, the commit ğ‘šis called inclusive
change and considered as tangled. Dias et al. [6] uses confidence
voting on fine-grained change events in an IDE and partition them.
Static Analysis. Roover et al. â€™s approach [ 20] builds PDG and com-
putes the changes to the ASTs of the files in a commit. It then
groups these fine-grained changes according to the slices through
the PDG they belong to. ClusterChanges [ 4] relates separate re-
gions of change within a changeset of a commit by using static
analysis to uncover relationships such as definitions and their uses
present in these regions. UTango adapts multi-version PDG from
Flexeme [ 22], however, we build the contextualized embeddings
for the code changes and a model to learn to cluster, rather than
clustering using graph similarity on multi-version PFG. SmartCom-
mit [ 24] uses a graph partition algorithm on code changes related
via several types of links, representing different purposes.
There are a rich literature on supervised hierarchical cluster-
ing [ 8,9,12,17,27,28]. The dissimilarity between cluster pairs is
measured via a linkage function ğ¹[9,28]. Learningğ¹is performed
by training the pairwise dissimilarity function to predict dissimilar-
ity for all within- and across-cluster data pairs [ 12,28]. InUTango ,
supervised-learning clustering is made with the loss function.
9 CONCLUSION
We present UTango , a ML-based approach that learns to untangle
the changes in a commit. We develop a novel code change clus-
tering learning model that learns to cluster the code changes, rep-
resented by the embeddings, into different groups with different
concerns. UTango overcomes the key issue with the static analysis
approaches in which the boundaries across concerns in a commit do
not naturally map to clustering criteria. Our ML direction fits well
with this problem thanks to a methodology from Herzig et al. [11]
and Flexeme [ 22], to collect the changes in the same concern and
merge them to build tangled commits to form a training dataset.
ACKNOWLEDGMENTS
This work was supported in part by the US National Science Founda-
tion (NSF) grants CNS-2120386, CCF-1723215, CCF-1723432, TWC-
1723198, and the US National Security Agency (NSA) grant NCAE-
C-002-2021 on Cybersecurity Research Innovation.
231ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore Yi Li, Shaohua Wang, and Tien N. Nguyen
REFERENCES
[1] 2021. The NNI autoML tool . https://github.com/microsoft/nni
[2]2022. T-SNE . https://scikit-learn.org/stable/modules/generated/sklearn.manifold.
TSNE.html
[3] 2022. UTango. https://github.com/Commit-Untangling/commit-untangling
[4]Mike Barnett, Christian Bird, JoÃ£o Brunet, and Shuvendu K. Lahiri. 2015. Helping
Developers Help Themselves: Automatic Decomposition of Code Review Change-
sets. In Proceedings of the 37th International Conference on Software Engineering -
Volume 1 (Florence, Italy) (ICSE â€™15) . IEEE Press, 134â€“144.
[5]Claudio Bellei, Hussain Alattas, and Nesrine Kaaniche. 2021. Label-GCN: An
Effective Method for Adding Label Propagation to Graph Convolutional Networks.
CoRR abs/2104.02153 (2021). arXiv:2104.02153 https://arxiv.org/abs/2104.02153
[6]MartÃ­n Dias, Alberto Bacchelli, Georgios Gousios, Damien Cassou, and StÃ©phane
Ducasse. 2015. Untangling fine-grained code changes. In 2015 IEEE 22nd Inter-
national Conference on Software Analysis, Evolution, and Reengineering (SANER) .
341â€“350. https://doi.org/10.1109/SANER.2015.7081844
[7]Jeanne Ferrante, Karl J. Ottenstein, and Joe D. Warren. 1987. The Program
Dependence Graph and Its Use in Optimization. ACM Trans. Program. Lang. Syst.
9, 3 (jul 1987), 319â€“349. https://doi.org/10.1145/24039.24041
[8]Thomas Finley and Thorsten Joachims. 2005. Supervised Clustering with Support
Vector Machines. In Proceedings of the 22nd International Conference on Machine
Learning (Bonn, Germany) (ICML â€™05) . Association for Computing Machinery,
New York, NY, USA, 217â€“224. https://doi.org/10.1145/1102351.1102379
[9]Anupam Guha, Mohit Iyyer, Danny Bouman, and Jordan L. Boyd-Graber. 2015.
Removing the Training Wheels: A Coreference Dataset that Entertains Humans
and Challenges Computers. In HLT-NAACL . 1108â€“1118. http://aclweb.org/
anthology/N/N15/N15-1117.pdf
[10] Kim Herzig, Sascha Just, and Andreas Zeller. 2016. The Impact of Tangled Code
Changes on Defect Prediction Models. Empirical Softw. Engg. 21, 2 (apr 2016),
303â€“336. https://doi.org/10.1007/s10664-015-9376-6
[11] Kim Herzig and Andreas Zeller. 2013. The Impact of Tangled Code Changes. In
Proceedings of the 10th Working Conference on Mining Software Repositories (San
Francisco, CA, USA) (MSR â€™13) . IEEE Press, 121â€“130.
[12] Kian Kenyon-Dean, Jackie Chi Kit Cheung, and Doina Precup. 2018. Resolving
Event Coreference with Supervised Representation Learning and Clustering-
Oriented Regularization. In Proceedings of the Seventh Joint Conference on Lexical
and Computational Semantics . Association for Computational Linguistics, New
Orleans, Louisiana, 1â€“10. https://doi.org/10.18653/v1/S18-2001
[13] Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with
Graph Convolutional Networks. In 5th International Conference on Learning
Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track
Proceedings . OpenReview.net. https://openreview.net/forum?id=SJU4ayYgl
[14] Hiroyuki Kirinuki, Yoshiki Higo, Keisuke Hotta, and Shinji Kusumoto. 2014.
Hey! Are You Committing Tangled Changes?. In Proceedings of the 22nd In-
ternational Conference on Program Comprehension (Hyderabad, India) (ICPC
2014) . Association for Computing Machinery, New York, NY, USA, 262â€“265.
https://doi.org/10.1145/2597008.2597798
[15] Hiroyuki Kirinuki, Yoshiki Higo, Keisuke Hotta, and Shinji Kusumoto. 2016.
Splitting Commits via Past Code Changes. In 2016 23rd Asia-Pacific Software
Engineering Conference (APSEC) . 129â€“136. https://doi.org/10.1109/APSEC.2016.
028[16] H. W. Kuhn. 1955. The Hungarian method for the assignment problem. Naval
Research Logistics Quarterly 2, 1-2 (1955), 83â€“97.
[17] Yang Liu, Jing Liu, Zechao Li, Jinhui Tang, and Hanqing Lu. 2013. Weakly-
Supervised Dual Clustering for Image Semantic Segmentation. In 2013 IEEE
Conference on Computer Vision and Pattern Recognition . 2075â€“2082. https://doi.
org/10.1109/CVPR.2013.270
[18] Daniel MÃ¼llner. 2011. Modern hierarchical, agglomerative clustering algorithms.
arXiv:1109.2378 [stat.ML]
[19] Emerson Murphy-Hill, Chris Parnin, and Andrew P. Black. 2012. How We
Refactor, and How We Know It. IEEE Transactions on Software Engineering 38, 1
(2012), 5â€“18. https://doi.org/10.1109/TSE.2011.41
[20] Ward Muylaert and Coen De Roover. 2018. [Research Paper] Untangling Com-
posite Commits Using Program Slicing. In 2018 IEEE 18th International Work-
ing Conference on Source Code Analysis and Manipulation (SCAM) . 193â€“202.
https://doi.org/10.1109/SCAM.2018.00030
[21] Hoan Anh Nguyen, Anh Tuan Nguyen, and Tien N. Nguyen. 2013. Filtering noise
in mixed-purpose fixing commits to improve defect prediction and localization.
In2013 IEEE 24th International Symposium on Software Reliability Engineering
(ISSRE) . 138â€“147. https://doi.org/10.1109/ISSRE.2013.6698913
[22] Profir-Petru PÃ¢rundefinedachi, Santanu Kumar Dash, Miltiadis Allamanis, and
Earl T. Barr. 2020. Flexeme: Untangling Commits Using Lexical Flows. In Proceed-
ings of the 28th ACM Joint Meeting on European Software Engineering Conference
and Symposium on the Foundations of Software Engineering (Virtual Event, USA)
(ESEC/FSE 2020) . Association for Computing Machinery, New York, NY, USA,
63â€“74. https://doi.org/10.1145/3368089.3409693
[23] Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe:
Global Vectors for Word Representation. In Empirical Methods in Natural Lan-
guage Processing (EMNLP) . 1532â€“1543. http://www.aclweb.org/anthology/D14-
1162
[24] Bo Shen, Wei Zhang, Christian KÃ¤stner, Haiyan Zhao, Zhao Wei, Guangtai Liang,
and Zhi Jin. 2021. SmartCommit: A Graph-Based Interactive Assistant for Activity-
Oriented Commits. In Proceedings of the 29th ACM Joint Meeting on European
Software Engineering Conference and Symposium on the Foundations of Software
Engineering (Athens, Greece) (ESEC/FSE 2021) . Association for Computing Ma-
chinery, New York, NY, USA, 379â€“390. https://doi.org/10.1145/3468264.3468551
[25] Jeffrey Svajlenko and Chanchal Kumar Roy. 2017. Fast and flexible large-scale
clone detection with CloneWorks.. In ICSE (Companion Volume) . 27â€“30.
[26] Yida Tao, Yingnong Dang, Tao Xie, Dongmei Zhang, and Sunghun Kim. 2012.
How Do Software Engineers Understand Code Changes? An Exploratory Study
in Industry. In Proceedings of the ACM SIGSOFT 20th International Symposium
on the Foundations of Software Engineering (Cary, North Carolina) (FSE â€™12) .
Association for Computing Machinery, New York, NY, USA, Article 51, 11 pages.
https://doi.org/10.1145/2393596.2393656
[27] Jun Tie, Wenying Chen, Chong Sun, Tengyue Mao, and Guanglin Xing. 2019.
The application of agglomerative hierarchical spatial clustering algorithm in tea
blending. Cluster Computing 22 (05 2019). https://doi.org/10.1007/s10586-018-
1813-z
[28] Nishant Yadav, Ari Kobren, Nicholas Monath, and Andrew Mccallum. 2019. Su-
pervised Hierarchical Clustering with Exponential Linkage. In Proceedings of
the 36th International Conference on Machine Learning (Proceedings of Machine
Learning Research, Vol. 97) , Kamalika Chaudhuri and Ruslan Salakhutdinov (Eds.).
PMLR, 6973â€“6983. https://proceedings.mlr.press/v97/yadav19a.html
232