Understanding the Topics and Challenges of GPU Programming
by Classifying and Analyzing Stack Overflow Posts
Wenhua Yang
College of Computer Science and
Technology, Nanjing University of
Aeronautics and Astronautics
Nanjing, China
ywh@nuaa.edu.cnChong Zhang
State Key Lab for Novel Software
Technology, Nanjing University
Nanjing, China
nju_zc@smail.nju.edu.cnMinxue Pan‚àó
State Key Lab for Novel Software
Technology, Nanjing University
Nanjing, China
mxp@nju.edu.cn
ABSTRACT
GPUs have cemented their position in computer systems, not re-
stricted to graphics but also extensively used for general-purpose
computing. With this comes a rapidly expanding population of
developers using GPUs for programming. However, programming
with GPUs is notoriously difficult due to their unique architecture
and constant evolution. A large number of developers have en-
countered problems of one kind or another, and many of them have
turned to Q&A sites for help. Unfortunately, there has been no prior
work to comprehensively study the topics discussed and challenges
encountered by developers in GPU programming. To fill this knowl-
edge gap, we conduct a comprehensive study to understand the
topics and challenges of GPU programming using Stack Overflow.
We collect 25,269 relevant posts from Stack Overflow, propose a
novel approach that combines automatic techniques and manual
thematic analysis to extract topics, and build a taxonomy of topics
with detailed discussions of the popularity, difficulty, and chang-
ing trends of these topics. In addition, we analyzed relevant posts
through extensive manual efforts to understand the challenges of
each topic and to summarize them for future research.
CCS CONCEPTS
‚Ä¢General and reference ‚ÜíEmpirical studies ;‚Ä¢Software and
its engineering‚ÜíParallel programming languages .
KEYWORDS
GPU programming, Stack Overflow, topic taxonomy
ACM Reference Format:
Wenhua Yang, Chong Zhang, and Minxue Pan. 2023. Understanding the
Topics and Challenges of GPU Programming by Classifying and Analyzing
Stack Overflow Posts. In Proceedings of the 31st ACM Joint European Software
Engineering Conference and Symposium on the Foundations of Software Engi-
neering (ESEC/FSE ‚Äô23), December 3‚Äì9, 2023, San Francisco, CA, USA. ACM,
New York, NY, USA, 13 pages. https://doi.org/10.1145/3611643.3616365
‚àóCorresponding author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
ESEC/FSE ‚Äô23, December 3‚Äì9, 2023, San Francisco, CA, USA
¬©2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0327-0/23/12. . . $15.00
https://doi.org/10.1145/3611643.36163651 INTRODUCTION
Graphics processing technology has evolved to deliver unique ben-
efits in the world of computing. Graphics Processing Units (GPUs)
have become one of the most important types of computing tech-
nology for both personal and business computing [ 26,36,51]. De-
signed for parallel processing, GPUs provide incredible acceleration
in workloads that take advantage of their highly parallel nature
and are originally used in applications such as graphics and video
rendering. Because of their remarkable computational power, devel-
opers have also started to harness the power of GPUs to accelerate
additional workloads in high performance computing, deep learn-
ing, and more [ 12]. GPUs have become an indispensable part of
modern computing.
GPU programming has seen success recently as GPUs have be-
come more flexible and programmable. The number of developers
using GPUs for programming and software development is also ex-
panding. Take CUDA, one of the most widely used GPU computing
platforms developed by NVIDIA, as an example: since being intro-
duced in 2006, it has been supported by an installed base of over 500
million CUDA-enabled GPUs in notebooks, workstations, compute
clusters, and supercomputers [ 37]. Nowadays, a large number of de-
velopers are programming with GPUs. However, GPU programming
is difficult. On the one hand, GPU programming poses specific chal-
lenges to developers compared to sequential programming. GPU
programming requires developers to take additional data move-
ment [ 65], data synchronization [ 68], and data precision [ 27] into
account compared to traditional programming. On the other hand,
even for experienced developers, it can be challenging to keep pace
with the rapid evolution of GPU technologies as GPU platforms
and hardware advance and the application areas of GPUs expand.
Not surprisingly, many developers have encountered challenges
when programming with GPUs. These challenges are evidenced
by the questions frequently raised in developers‚Äô Q&A forums. Ob-
serving this, van den Haak et al. [ 63] conducted an analysis of 376
OpenCL and CUDA-related questions on Stack Overflow, with the
aim of determining whether the raised concerns in those sampled
questions could be addressed by current formal verification tools.
While their study offers a targeted perspective of the challenges that
developers may encounter and provides valuable insights into the
capabilities and prospects of formal verification tools in resolving
OpenCL and CUDA programming-related issues, a gap remains for
a comprehensive study that provides an expansive understanding
of the wide spectrum of challenges that developers face in GPU
programming.
1444
ESEC/FSE ‚Äô23, December 3‚Äì9, 2023, San Francisco, CA, USA Wenhua Yang, Chong Zhang, and Minxue Pan
To fill this knowledge gap, this paper presents a comprehensive
empirical study to understand the topics discussed and challenges
encountered by developers in GPU programming. In light of the
surge of interest in GPU programming and the extensive applica-
tions of GPUs, this study can help developers quickly understand
fundamental difficulties, avoid common pitfalls in GPU program-
ming, and enable researchers and GPU platform vendors to better
help software engineers conduct GPU programming in a more tar-
geted way. Considering that developers often ask questions about
their problems and confusion on professional Q&A forums, e.g.,
Stack Overflow (SO), it has been a common practice for researchers
to understand the topics and challenges in dealing with different
engineering tasks by analyzing Q&A posts [ 4,5,17,22,56,73].
Therefore, to understand the topics discussed and the challenges
faced by developers in GPU programming, we analyze the relevant
posts on SO, which is one of the most popular Q&A forums for
developers and allows developers to seek technical advice from
other developers and experts. In summary, our study collects and
analyzes 25,269 SO posts regarding GPU programming to under-
stand topics discussed and challenges encountered by developers
in GPU programming. Based on these posts, we focus our study on
the following research questions.
RQ1: Topics and taxonomy. What GPU topics do developers ask
about, and what is the taxonomy of those GPU topics?
RQ2: Characteristics of topics. How are the GPU topics charac-
terized in terms of popularity, difficulty, and changing trends?
RQ3: Challenges. What are the challenges faced by developers
for each GPU topic in the taxonomy?
As GPU programming covers a broad range of topics, the premise
for the success of this study is the effective identification of the top-
ics. Widely-used unsupervised approaches, such as Latent Dirichlet
Allocation (LDA) [ 11], can extract topics directly from an entire
corpus of posts, but require the number of topics to be determined
prior to topic extraction and may produce variations of topics over
different runs. GPU programming is an emerging concept and lacks
of a topic taxonomy, making the LDA inapplicable to the task. To
address this problem, we propose a novel bottom-up approach to
topic extraction by first extracting a set of keywords from each
post and then using selected representative keywords to manually
extract meaningful topics. Such an approach combines automatic
techniques and manual analysis, and can achieve a balance between
efficiency and effectiveness. We organized the extracted topics into
a hierarchical taxonomy and classified posts into their correspond-
ing topics. We then analyzed the topic characteristics in terms of
popularity, difficulty, and changing trends, as well as the challenges
faced by developers in each topic.
Our study leads to the following primary findings: 1) Topics and
taxonomy. The GPU-related posts cover a wide range of topics,
up to 39 in total, indicating the complexity of GPU programming.
Most of them fall into the Programming category, but the categories
ofEnvironment and Application also occupy a substantial share,
indicating that as a new class of programming, its programming
environment and target applications are challenging for develop-
ers. 2) Characteristics of topics. GPU topics are popular overall,
and among them, the topics related to basic concepts, installing
GPU development environments, and especially the deep learn-
ing framework TensorFlow, are the most popular, indicating thatGPU programming is attracting new developers and AI program-
mers. Difficulty peaks with TensorFlow, installation, and config-
uration topics, suggesting stringent demands in deploying GPU
programming frameworks. 3) Challenges. For those topics, we have
identified a list of challenges, most of which are not seen in tradi-
tional programming, but are specific to GPU programming. The
majority of these revealed challenges remain unresolved, pointing
researchers and developers to possible future work.
In summary, our study delivers the following key contributions:
‚Ä¢We construct a taxonomy of challenges in GPU programming
by leveraging a blend of automated methods and manual
analysis on a large collection of SO posts;
‚Ä¢We not only undertake a quantitative exploration of topic
popularity, difficulty, and trends, but also reveal the specific
challenges within each topic through a qualitative analysis;
‚Ä¢We discuss the implications of our findings from both re-
search and practice perspectives and provide a curated dataset
of GPU programming posts to foster future research.
2 METHODOLOGY
Here, we describe step by step the methodology used in the study.
Figure 1 shows an overview of the methodology of our study.
Step 1: Download Stack Overflow dataset. In this step of our
study, we download the SO dataset from Stack Exchange Data
Dump [ 24]. The metadata of each post is composed of its identifier,
post type (i.e., question or answer), creation date, title, body, tags,
view count, score, favorite count, and the identifier of the accepted
answer for the post if the post is a question. Besides, one to five tags
can be attached to a post specifying its topics. The contributor who
posted a question can mark an answer as accepted to the question.
Our SO dataset, denoted as S, covers posts from July 31, 2008.
Step 2: Identify relevant questions. To identify GPU-related
questions from SO, we utilize the tags of questions. We build a set
of tags related to GPU to extract relevant questions from SO. We
first select the questions whose tag fields include ‚Äú <gpu> ‚Äù fromS
as our initial dataset T. Then, we construct a candidate tag set ùúÅ
by extracting all tags of questions in T. Since not all of the tags in
ùúÅare significantly relevant to GPU, we further refine ùúÅto exclude
irrelevant tags. To determine which tags are significantly relevant
to GPU, we leverage two heuristics (i.e., ùõºandùõΩ) commonly used in
existing work [ 4,70]. The heuristic ùõº(i.e., the number of questions
with tag ùëßinTdividing the number of questions with tag ùëßinS)
measures the relevance of a tag ùëßinùúÅto GPU, and the heuristic ùõΩ
(i.e., the number of questions with tag ùëßinTdividing the number
of questions inT) measures the significance of a tag ùëßinùúÅ.
We consider a tag ùëßsignificantly relevant to GPU if its ùõºandùõΩ
values are higher than or equal to specific thresholds. To decide the
appropriate thresholds for ùõºandùõΩ, we first set a series of thresholds
to be selected for each of them, which are set by referring to existing
work [ 4,70]. Specifically, we have both six candidates for ùõº(0.05,
0.1, 0.15, 0.2, 0.25, 0.3) and ùõΩ(0.005, 0.01, 0.015, 0.02, 0.025, 0.03). This
resulted in a total of 36 ( 6√ó6) distinct configurations for creating the
final set ùúÅof tags. These various configurations led to ùúÅcontaining
between 3 and 15 elements. The range in size was manageable
enough to allow for a manual inspection, and the first two authors
collaborated to determine which configuration provided the most
1445Understanding the Topics and Challenges of GPU Programming by Classifying and Analyzing SO Posts ESEC/FSE ‚Äô23, December 3‚Äì9, 2023, San Francisco, CA, USA
‚ûÉConstruct topics taxonomy
Classify questions
Inductively construct and refine taxonomy‚ûÑDetermine characteristics of topics
PopularityDifficultyTrends‚ûÇExtract GPU topics: combing automatic techniques and manual thematic analysis3.1 Automatically extract and select representative keywords3.2 Aggregate posts with similar representative keywords‚Ä¶
3.3 Manually extract meaningful topics from grouped posts  ‚ûÖIdentify challenges for GPU topics: content analysis
‚ûÄDownload Stack Overflow dataset
‚ûÅIdentify relevant questions
Figure 1: An overview of the six steps employed in the study methodology.
relevant and representative tags based on a careful review. In the
end, we selected the configuration where ùõºtakes 0.1 and ùõΩtakes
0.01, as this configuration yields the most adequate results. The
final tag set ùúÅincludes cuda, gpu, gpgpu, opencl, nvidia, thrust . Using
these tags we identified the final set of questions F, i.e., selecting
those questions from Sthat contain at least one of the above tags.
As a result, we obtained 25,269 questions in F, forming the final
dataset to be analyzed.
Step 3: Extract GPU topics. To obtain GPU topics from F, we
first preprocess the question set to reduce the noise for the next
step of the analysis, similar to existing work [ 4,5,22]. Specifi-
cally, we remove code snippets, URL address, HTML tags, stop
words, numbers, punctuation marks, and non-alphabetic charac-
ters. Then, we use Porter Stemmer [ 52] to reduce words to their
stemmed representations, e.g., ‚Äúsynchronous‚Äù is reduced to ‚Äúsyn-
chron‚Äù. In particular, ‚Äúperformance‚Äù remains unchanged to prevent
the potential confusion with ‚Äúperform‚Äù. Then, we can extract top-
ics from the posts. Since there are many research efforts study-
ing what developers are discussing on SO, researchers have pro-
posed various methods to extract topics from SO posts. We can
roughly divide them into two categories: automatic extraction tech-
niques [ 4‚Äì6,8,9,22,56,60,70,73] and manual thematic analysis
methods [ 2,10,17,19,61,74]. Automatic topic extraction tech-
niques are represented by LDA [ 4‚Äì6,8,9,22,56,60,70,73], along
with some machine learning methods, such as random forests [ 11],
conditional random fields [ 3], and support vector machines [ 11,21].
Manual thematic analysis relies on manual processing. These meth-
ods provide us with a very valuable reference, however, they all
have apparent drawbacks when applied to our problem. Specifically,
automatic techniques are essentially unsupervised algorithms and
it is difficult to obtain generated topics with good quality and gran-
ularity. Taking LDA for example, as described in [ 11], LDA may
produce meaningless topics with ambiguous and confusing words,
which is confirmed in [ 11]. Meanwhile, it is necessary to specify
the total number of topics with LDA [ 11], which is hard to decide
in advance. Having this number too large or small can both nega-
tively affect the granularity and quality of generated topics. Despite
efforts to improve LDA [ 55], problems persist. The unsupervised
nature of automatic extraction techniques can lead to variable re-
sults, impairing reproducibility. Manual thematic analysis becomes
too time-consuming and labor-intensive if a sufficient number of
posts are to be selected.
Therefore, we propose a novel approach to extracting topics by
combining automatic techniques and manual thematic analysis. Wefirst use YAKE! [ 15,16], a feature-based keyword extraction tool
used by many researchers [ 32,66,72], to extract the top ten key-
words for each question. The higher the keyword ranks, the more
relevant it is to the question. For a very few posts (1.8%), fewer than
ten keywords are generated due to overly short question body text
contents. We have acquired 35,523 keywords from our dataset F,
and 409 of them that occur in more than 100 questions are selected
for further analysis considering their representativeness. Then, we
manually extract meaningful topics from the posts based on these
409 keywords. The extraction process follows a bottom-up manner,
i.e., we first aggregate posts with the same or similar keywords
together and then manually determine the topics from these posts
and their keywords. It can be seen that our extraction approach
differs from the idea of LDA, which first determines a fixed number
of topics and then divides the dataset into each topic. Our approach
is to extract topics based on the posts and to keep expanding the top-
ics without first fixing all the topics. The advantage of our approach
is that we can obtain a finer granularity of topics by considering
both the content of posts and the relationships between them in
the manual extraction process. In the manual analysis process, we
discard common and generalized keywords that are frequently used
in various SO posts but do not belong to any specific domain, such
as ‚Äúwork‚Äù, and overly coarse-grain keywords [ 19], such as ‚Äúopencl‚Äù,
and ‚Äúnvidia‚Äù. We finally selected 97 representative keywords and
extracted 39 specific topics from them. We provide the details of
these topics and keywords in Section 3.
Step 4: Construct topics taxonomy. Few studies have systemat-
ically explored the questions developers may have in the emerging
field of GPU development. Recognizing this, we believe it is nec-
essary to provide further analysis of the topics. Therefore, after
extracting the topics, we construct the topic taxonomy to help
readers understand the hierarchy of topics more clearly. We first
determine to which topics the questions belong, since in the previ-
ous step, we only aggregated similar questions together and did not
classify them by the topic. We can use the posts to better construct
the topic hierarchy, which is also needed for the subsequent analy-
sis of topic popularity and difficulty. We use a multi-stage matching
method to classify questions into these topics.
In the first stage, since the title of a question consists of several
words and properly summarizes the main content of the question,
we classify questions with the help of titles, i.e., if a keyword of a
topic appears in the title of a question, we classify the question into
that topic. If the title of the question does not contain any keyword
corresponding to a topic, we leave them for the next stage. In the
1446ESEC/FSE ‚Äô23, December 3‚Äì9, 2023, San Francisco, CA, USA Wenhua Yang, Chong Zhang, and Minxue Pan
second stage, we leverage the ten keywords generated by Yake! for
each question in the previous step to classify it. We traverse the
ten keywords in the order from high to low of the relevance for
each of the questions, and once the keyword matches with a topic
keyword, we classify the question into the corresponding topic.
In the third stage, since we selected keywords with more than
100 occurrences (among 25,269 questions in F) in Step 3, there
exist a small number of questions that are not covered by these
keywords, so we manually classify these questions. These questions
are mainly general questions (e.g., ‚ÄúIs it possible to use OpenCL via
ssh?‚Äù), basic conceptual questions, and other unclassified questions.
Thus, we introduce three other classes ‚ÄúGeneral‚Äù, ‚ÄúBasic concept‚Äù,
and ‚ÄúOthers‚Äù for classification. The first two stages of classification
are automatic, and they successfully handle 22,795 (90.2%) questions
and the remaining 2,474 questions (9.8%) are manually classified. In
this process, there are cases where a question is classified to more
than one topic, which is also in line with the reality, as a question can
involve more than one topic. The distribution among 25,269 posts
is as follows: 15,863 to one topic, 7,338 to two, 1,770 to three, 278 to
four, and 20 to five topics. Following existing studies [ 20,57], the
topic taxonomy is inductively constructed and refined by grouping
similar topics and categorizing lower-level into higher-level ones.
Two authors collaborate and engage in discussions to form groups,
with a third arbitrator to facilitate consensus in conflicts.
Reliability analysis. To validate the question classification
results of questions, two of the authors experienced in GPU pro-
gramming independently verify the outcomes of randomly-sampled
questions for reliability. We refer to [ 58] to determine the sampling
size for each topic. In the end, we sampled 7,409 classified ques-
tions in total to conduct reliability analysis. Each of the sampled
questions is labeled with True orFalse to indicate the correctness
of our classification method‚Äôs results. The inter-rater agreement
during the independent checking is 0.868 measured by Cohen‚Äôs
Kappa, indicating almost perfect agreement, and they reach agree-
ment on conflicting questions with the help of a third arbitrator.
Based on the manually labeled results, we conducted a hypothesis
testing, whose null hypothesis is that fewer than 90% questions of
the topic are classified correctly with a confidence level of 95%. The
result of hypothesis testing rejects the null hypothesis, demonstrat-
ing the reliability of our classification method. Details are in the
supplemental materials (c.f. Section 10). To ensure the reliability
of selected keywords and the constructed taxonomy, two authors
independently classified the topics, then aligned their results. Dis-
agreements were resolved through discussion, with a third party
for adjudication when needed.
Step 5: Determine characteristics of topics. For the topic pop-
ularity, we first use three metrics that have been used by existing
work [ 5,6,35,56,69] to measure the popularity of GPU topics
based onF. The first metric is the average number of views for all
the questions of a topic. The second metric is the average number
of questions of a topic that are marked as favorites by users. The
third metric is the average score of questions of a topic. Meanwhile,
in addition to the mean values, we also calculate the medians for
these three data values, such as the median number of views. We
measure the difficulty of GPU topics using three metrics adopted
from previous works [ 4,17,22,62,69]. The first one is the percent-
age of questions with no accepted answer. The second metric is thepercentage of questions with no answer, i.e., these questions have
not been answered. The third metric is the median response time
needed for a question to receive an accepted answer. Since GPUs
are evolving rapidly, it is of significance to explore the trends in
these GPU topics. We investigate the trends of these topics since SO
was proposed. Specifically, to track the trend of each GPU topic, we
count the number of questions related to that topic in each year, and
the percentage of questions related to that topic among questions
of all GPU topics. These two metrics can provide a straightforward
representation of the trend of change for a topic.
Step 6: Identify challenges for GPU topics. Questions related
to GPU programming have been extensively asked on SO, indicat-
ing that developers are encountering a spectrum of difficulties in
GPU programming. This step aims to understand the challenges
in GPU programming by analyzing the questions classified to each
GPU topic in Step 4. To select representative questions for each
topic, we adopt the metric, i.e., Accumulated Post Score [ 7], which
considers the up votes, down votes, comment count, answer count,
and favorite count of the questions. For the questions classified
under each topic, we sort them by the accumulated post score of
the questions, and select the top 50 questions for analysis if the
percentage of questions under that topic is less than 3%, otherwise
the top 100 questions are selected for manual analysis. As a result,
we obtain a dataset of 2,650 questions used for identifying chal-
lenges. The size of this dataset is larger than those used in existing
studies [ 11,17,73,74], which also require manual analysis of SO
posts. We then follow a common qualitative analysis procedure,
i.e., content analysis [ 59], to inspect and identify challenges from
the selected posts. Two of the authors independently validated the
results and reached agreement by discussion.
3 RQ1: GPU TOPICS AND TAXONOMY
Table 1 shows the GPU topics extracted from Ffollowing Step 3
as discussed in Section 2. In total, we obtained 39 meaningful and
fine-grained GPU topics, whose stemmed representative keywords
are given in Column 2 of Table 1. For example, the first topic ‚Äúarray‚Äù
and the second topic ‚Äúmatrix‚Äù both concern specific data structures
in programming. Developers ask questions about a broad spectrum
of topics on GPU such as application in multimedia (e.g., image
and graphic processing) and GPU-related hardware (e.g., driver
and card). In general, these topics can be divided into three main
categories, which are programming, environment, and application.
Figure 2 illustrates the hierarchical taxonomy of topics in GPU de-
velopment. The innermost ring presents these three main categories
of topics classified at the highest level of the hierarchy. Program-
ming is concerned about a series of basic programming issues in
GPU development, such as data structures and the grammar of pro-
gramming language. Environment refers to various software and
hardware environment factors that affect whether GPU programs
can run smoothly, for example, configuration and drivers. Appli-
cation is concerned with how GPUs are used in various domains,
since modern GPUs are engaged in many complex computations,
such as multimedia and deep learning.
A hierarchy for GPU topics that developers ask questions about
on SO is constructed by grouping of similar topics into categories
and lower-level categories into higher-level categories, as discussed
1447Understanding the Topics and Challenges of GPU Programming by Classifying and Analyzing SO Posts ESEC/FSE ‚Äô23, December 3‚Äì9, 2023, San Francisco, CA, USA
Array4.3%Matrix2.6% Schedule2.5% Algorithm2.5% Vector1.7% Data Frame1.6% Data Structure & Algorithm14.9%Kernel & Thread13.5%Kernel8.2% Thread5.3% Memory9.5%API & Library8.9%Grammar5.2%Debug4.9%Performance3.8%API4.6% Library4.3% Function1.9% Variable1.0% Pointer0.8% Class0.5% Struct0.4% Header0.3% Template0.3% Basic Concept1.4%General Question0.6%Deployment12.9%Compile5.3% Install2.5% Configure2.1% Build1.7% Link0.6% Device5.0%Card1.9% Architecture1.6% Driver1.2% Hardware0.3% Monitor2.3%Tool0.8%Multimedia9.3%Deep Learning Framework6.0%Others1.0%
Image Processing4.6% Graphics Programming3.9% Tensorflow4.1% Video0.8%Pytorch1.0%Keras0.5%Theano0.5%
Programming62.7%Docker0.6%Environment21.0%Application16.3%
Figure 2: Taxonomy of GPU topics, their categories, and
percentages of their questions.Table 1: GPU topics and their stemmed keywords.
Topic name Representative keywords
Array arrai
Matrix matrix, matric
Schedule parallel, synchron, queue
Data Frame int, doubl, float, integ
Vector vector
Algorithm algorithm, optim
Kernel kernel
Thread thread, block, warp, grid
Memory memori, buffer
API api, cudamemcpi, cudamalloc
Library librari, thrust, cufft, cubla
Function function
Variable variabl
Pointer pointer
Class class
Struct struct
Header header
Template templat
Debug error, wrong, fail, debug, crash, warn, fault
Performance speed, slow, faster, slower, performance, acceler
Compile compil, nvcc, gcc
Install instal
Build build, cmake
Link link
Configure configur
Card card, gtx, geforc, tesla
Architecture architectur, sm, core, ram, cach
Driver driver
Hardware hardwar
Monitor measur, monitor, profil, smi
Tool toolkit, sdk
Image Processing imag, opencv, draw, pixel, textur
Graphics Programming render, shader, opengl
Video video, ffmpeg
Tensorflow tensorflow, tf
Pytorch pytorch
Keras kera
Theano theano
Docker docker
in Section 2. The largest share among these three categories are
questions related to programming. More than three-fifths (62.7%)
of the questions asked by developers fall into the programming
category, followed by the category of environment at 21.0%, and
lastly, the category of application at 16.3%. The dark gray sector
blocks in the outermost circle correspond to the 39 extracted topics.
It is worth mentioning that other three classes (i.e., ‚Äúgeneral‚Äù, ‚Äúbasic
concept‚Äù, and ‚Äúothers‚Äù) introduced in Step 4 of Section 2 for manual
classification of questions are also shown in the outermost circle.
The upper level of the bottom level topics are the categories (e.g.,
deep learning framework and deployment) that we have grouped
for related bottom topics, which in turn can be further categorized
into each of the three categories at the highest level. In particular,
some of the topics (e.g., debug and monitor) are already standalone,
and instead of grouping them further, we categorize them directly
to the highest level. In the category of programming, we have
topics on Data Structure & Algorithm (the largest share among
programming), Kernel & Thread ,Memory ,API & Library ,Grammar ,
Debug ,Performance ,Basic Concepts , and General Questions . The
topics in the category of environment include Deployment ,Device ,
Monitor , and Tool. In the category of application, the topics are
divided into Multimedia ,Deep Learning Framework , and Others
according to their application domains.4 RQ2: CHARACTERISTICS OF TOPICS
Popularity. We investigate the popularity of the 40 GPU program-
ming topics on SO to understand which topics developers are more
likely to be confused about. As described by Step 5 in Section 2,
the popularity of GPU topics is measured by the average and me-
dian values of views, favorites, and scores. Among them, we use
the average number of views as the main metric, since a popular
question tends to attract more developers to view it. Still, the other
metrics are also informative to estimate the popularity of a topic.
Table 2 gives the results of topics‚Äô popularity, sorted by the average
number of views. Due to space limitations, we have filtered out
topics whose number of questions accounts for less than 1% of F
(the percentage of questions for each topic is given in Figure 2), but
we provide the complete results for all topics in our supplementary
materials (c.f. Section 10).
As we can see from Table 2, ‚ÄúInstall‚Äù, ‚ÄúBasic Concepts‚Äù, ‚ÄúCard‚Äù,
‚ÄúTensorFlow‚Äù, and ‚ÄúDriver‚Äù are the top five most popular topics
being asked. These topics draw an average view count that exceeds
three thousand, and their median view counts also hold relatively
high positions in the ranking, with the first two being notably
prominent. The first two topics are so popular mainly due to the
fact that they are about getting started with GPU programming,
such as how to install GPU development environments and basic
1448ESEC/FSE ‚Äô23, December 3‚Äì9, 2023, San Francisco, CA, USA Wenhua Yang, Chong Zhang, and Minxue Pan
Table 2: Popularity measures of GPU topics.
TopicViews Favorites Scores
Avg. Med. Avg. Med. Avg. Med.
Install 6552.8 861.5 1.0 1.0 3.4 1.0
Basic Concepts 3917.7 828.0 2.2 2.0 5.5 2.0
Card 3663.6 658.0 0.8 1.0 2.7 1.0
TensorFlow 3585.9 435.0 0.9 1.0 2.8 1.0
Driver 3253.1 534.0 0.6 1.0 2.3 1.0
Monitor 2620.1 529.0 0.8 1.0 2.5 1.0
Build 2437.6 664.0 0.6 1.0 1.8 1.0
Compile 2388.2 663.0 0.7 1.0 2.0 1.0
Library 2107.6 535.5 0.8 1.0 2.3 1.0
Configure 2058.3 510.0 0.5 1.0 1.7 1.0
Thread 2047.3 406.0 1.1 1.0 2.4 1.0
Architecture 1941.4 473.5 1.0 1.0 2.3 1.0
API 1732.8 509.0 0.7 1.0 2.0 1.0
Debug 1666.2 493.0 0.3 1.0 1.2 0
Data Frame 1647.5 595.0 0.5 1.0 1.7 1.0
Function 1620.1 504.0 0.5 1.0 1.6 1.0
Performance 1596.6 466.5 0.8 1.0 2.7 1.0
Memory 1580.0 491.0 0.7 1.0 1.8 1.0
Algorithm 1554.1 461.0 1.2 1.0 2.6 1.0
Schedule 1439.1 422.0 0.8 1.0 2.1 1.0
Graphics Programming 1424.9 556.0 0.7 1.0 2.2 1.0
Kernel 1390.8 482.0 0.5 1.0 1.4 1.0
Image Processing 1382.8 576.0 0.5 1.0 1.3 1.0
Array 1364.5 460.0 0.5 1.0 1.1 0
Vector 1344.7 501.0 0.6 1.0 1.4 1.0
Matrix 1332.5 437.5 0.6 1.0 1.3 1.0
Overall average 2217.32 540.44 0.77 1.04 2.16 0.96
concepts of GPU programming. Since an ever-increasing number
of developers are learning about and getting started with GPU pro-
gramming, questions related to these topics receive a high number
of views. We can also observe that questions explaining basic GPU
concepts to developers receive the highest average favorites (2.2),
and many of these questions are for novice GPU programmers. Top-
ics ‚ÄúCard‚Äù and ‚ÄúDriver‚Äù are both about GPU devices, and it is easy
to understand why they are more popular, since unlike traditional
software development, GPU programming requires developers to
know more about the devices and hardware. After all, to start GPU
programming, developers first need to get their GPU hardware and
software environments set up. In addition, as GPUs continue to
expand application use in AI and deep learning, the topic ‚ÄúTensor-
Flow‚Äù receives increasing attention. In comparison, topics related
to specific programming details (e.g., topics belonging to data struc-
ture and algorithm) are less popular. This is primarily due to the
large number and diversity of questions related to these topics. We
also analyzed all question views on SO (based on S), revealing
an average and median of 2,601 and 310 views, respectively. By
contrast, the average view for GPU topics is lower, which might be
due to that GPU questions were asked more recently in comparison
to many longstanding questions on SO that accrue views over time
(e.g., a question [ 39] posted 12 years ago has over 4 million views).
However, the median view for GPU topics is higher than for all
questions on SO, indicating an elevated interest in this field. Fur-
thermore, GPU topics‚Äô average views exceed those of well-studied
subjects, such as concurrency (1,641) [ 4], big data (1,364) [ 5], and se-
curity (1,696) [ 70]. The average and median values for favorites and
scores of GPU questions were 0.77, 1.04, and 2.16, 0.96, respectively,
contrasted with 0.61, 1, and 2.17, 0 for all SO questions.Table 3: Difficulty measures of GPU topics.
Topic % w/o acc. % w/o ans. Hrs to acc.
TensorFlow 69.3 30.9 8.8
Install 57.4 17.6 9.9
Configure 56.5 19.7 6.1
Performance 55.5 18.3 4.6
Driver 53.4 19.1 12.4
Image Processing 52.8 18.5 6.4
Build 50.8 14.6 15.0
Graphics Programming 49.1 19.3 5.6
Monitor 48.8 17.7 6.8
Architecture 48.5 15.0 3.5
Card 47.9 16.3 2.7
Schedule 47.9 14.2 4.6
Debug 47.5 14.7 3.9
Algorithm 46.0 11.1 3.6
Memory 44.2 13.8 3.2
Compile 43.3 11.4 4.7
API 42.2 11.7 2.5
Kernel 41.8 9.5 3.5
Matrix 40.6 11.4 3.9
Basic Concepts 40.4 7.0 1.8
Library 40.0 10.3 3.5
Vector 39.0 7.5 2.3
Data Frame 38.4 7.9 2.2
Thread 38.1 6.5 2.0
Array 36.2 6.9 3.0
Function 36.1 11.0 2.3
Overall average 46.60 13.92 4.95
Difficulty. Identifying the most difficult topics enables devel-
opers to prioritize challenging ones, especially if a topic is both
popular and difficult, warranting increased attention. As described
in Section 2, the difficulty of GPU topics is measured using the
percentage of questions with no accepted answers (‚Äú% w/o acc.‚Äù),
the percentage of questions with no answers (‚Äú% w/o ans.‚Äù), and
the median time to get an accepted answer (‚ÄúHrs to acc.‚Äù). To put it
intuitively, a topic is considered more difficult if most of its related
questions do not have accepted answers. In the meantime, the other
metrics can also help us understand the difficulty of the topic. Ta-
ble 3 presents the results of the difficulty measures of GPU topics,
sorted by the percentage of questions with no accepted answers.
Similar to popularity, we have also filtered out topics whose number
of questions is less than 1% of Fdue to space limitations. Also, a
small number of questions is likely to produce a random bias in
the metrics. Nevertheless, the complete results of all topics are also
included in our supplementary materials (c.f. Section 10).
From Table 3, we can see that among the first few topics, the
percentage of no accepted answers for the first topic ‚ÄúTensorFlow‚Äù
(69.3%) is relatively high compared to the other ones, and the re-
maining ones do not differ too much. On the one hand, TensorFlow
is a relatively new technology, and thus not many developers fully
understand this technology in the early stage, which makes fewer
developers able to provide accepted answers. On the other hand,
TensorFlow is constantly being updated, making it necessary for
developers to keep learning. Additionally, ensuring TensorFlow
running on the GPU poses particular challenges for developers,
which has been raised by many developers, e.g., questioners com-
plained that ‚Äú I am having a hard time trying to run a tensorflow
program in the GPU 1. ‚Äù [47] and ‚Äú I have been trying to run some
TensorFlow training on some machine with GPUs...whenever I try to
do so I get some type of error... ‚Äù [49]. Similarly, topics related to GPU
1449Understanding the Topics and Challenges of GPU Programming by Classifying and Analyzing SO Posts ESEC/FSE ‚Äô23, December 3‚Äì9, 2023, San Francisco, CA, USA
(a) API & Library
 (b) Basic Concepts
 (c) Data Structure & Algorithm
 (d) Debug
(e) Deep Learning Framework
 (f) Deployment
 (g) Device
 (h) General Questions
(i) Grammar
 (j) Kernel & Thread
 (k) Memory
 (l) Monitor
(m) Multimedia
 (n) Others
 (o) Performance
 (p) Tool
Figure 3: The trends of topics over the years. The blue lines represent the number of questions and the red lines represent the
percentage of topic-specific questions relative to all GPU-related questions.
deployment (e.g., ‚ÄúConfigure‚Äù and ‚ÄúBuild‚Äù) and devices (e.g., ‚ÄúDriver‚Äù
and ‚ÄúCard‚Äù) that enable programming environments are ranked
relatively high on the list. For example, ‚ÄúConfigure‚Äù has the second
fewest answers (19.7%), and ‚ÄúBuild‚Äù has the longest time to receive
accepted answer (15.0 hours). It implies that developers are likely
to encounter a variety of problems when they get started with GPU
programming and prepare their programming environments. Then,
questions related to the performance of GPU are also considered
relatively difficult, followed by some application-specific topics
such as ‚ÄúImage Processing‚Äù and ‚ÄúGraphics Programming‚Äù. In con-
trast, some common topics related to parallelism (e.g., ‚ÄúKernel‚Äù and
‚ÄúThread‚Äù) and basic operations (e.g., data structures and grammar)
in GPU programming are ranked lower in difficulty. For reference,
we also calculated the three metrics for all questions on SO, yielding
48.79%, 14.26%, and 0.40, respectively. These values suggest that
while the proportions of questions without accepted answers and
unanswered questions for GPU topics are similar to those for all SO
questions, the duration to receive an accepted answer for GPU top-
ics is notably longer. After analyzing topic popularity and difficulty,
we naturally examined their interrelation using Kendall correlation
analysis, however, the results indicate no significant correlation.
Trends. Figure 3 shows the results for these GPU topics. Here,
we present the results by the upper level category to which the
topic belongs (the hierarchy is given in Figure 2), except for those
topics that are stand-alone such as ‚ÄúDebug‚Äù and ‚ÄúPerformance‚Äù
(their upper level is the highest level). Two reasons inform thischoice. First, space limitations preclude detailing numerous bottom-
level topics. Second, a topic‚Äôs upper-level category better indicates
field trends as some bottom-level topics are too narrowly focused
(e.g., ‚ÄúTemplate‚Äù in Grammar) or have too small a percentage (e.g.,
‚ÄúHeader‚Äù in Grammar) to adequately reflect trends. Each sub-figure‚Äôs
blue line represents question trends, while the red line depicts the
question percentage trend.
As shown in the figure, since SO‚Äôs inception in 2008, questions in
almost all categories initially grew, differing in growth onset. Most
categories began growing around 2010, while the deep learning
framework, reflecting its recent development, saw a rapid increase
starting in 2015, peaking in 2020, and maintaining a high percentage
thereafter. This aligns with deep learning‚Äôs evolution and current
popularity, corroborating the results of popularity measures. Simi-
larly, deployment-related questions have also stayed at a high level,
which is consistent with the results in popularity and difficulty,
further illustrating the prevalence and challenging nature of de-
ployment in GPU programming. Differently, we can observe that
the percentage of multimedia-related questions was the highest at
the very beginning (more than 25%), after which the percentage of
questions decreased and then remained at a relatively stable level.
This is because GPUs, originally designed to accelerate graphics ren-
dering, have evolved into other, more varied application domains.
Questions on basic concepts declined after initial growth, but de-
spite the low question count, the high number of views suggests
1450ESEC/FSE ‚Äô23, December 3‚Äì9, 2023, San Francisco, CA, USA Wenhua Yang, Chong Zhang, and Minxue Pan
these questions have become classic to some extent. This reflects a
maturation and stabilization of GPU-related concepts.
The general trend of most other categories (e.g., Data Structure
& Algorithm) follow a similar trend of initially rising and then
stabilizing, peaking around 2013, as with ‚ÄúKernel & Thread‚Äù during
GPUs‚Äô rapid growth period. The trend curves of categories ‚ÄúGeneral
Questions‚Äù, ‚ÄúTool‚Äù, and ‚ÄúOthers‚Äù are quite different from other cate-
gories, but they maintain a low question count, possibly biased by
the low number. Categories like ‚ÄúDeep Learning Framework‚Äù, ‚ÄúDe-
ployment‚Äù, ‚ÄúData Structure & Algorithm‚Äù, and ‚ÄúAPI & Library‚Äù have
maintained a relatively high number or percentage of questions
recently, showing questions in these categories are encountered by
many different developers.
5 RQ3: CHALLENGES
5.1 Programming
Data Structure & Algorithm. The topics in this category include
Array ,Matrix ,Schedule ,Algorithm ,Vector , and Data Frame , which
are ranked in descending order by the percentage of questions.
Array: Despite being basic in traditional programming, arrays
pose challenges in GPU programming. Most SO queries about ar-
rays deal with routine operations like creating arrays in CUDA,
dynamic allocation, and sorting. Besides, the use of 2D/3D arrays
is particularly challenging for developers, and we have observed
many questions concerning the allocation and representation of
2D/3D arrays. Matrix: One of the main challenges for developers
here is to distinguish the difference between matrix operations on
CPUs and GPUs. For instance, developers need to understand the
differences in computational precision and speed of matrix multi-
plication between CPUs and GPUs, such as numpy on CPUs versus
gnumpy on GPUs. Implementing and optimizing matrix transposi-
tion efficiency on GPUs is a common issue, as is the operation of
large, sparse matrices (like multiplication) on GPUs.
Schedule: The most significant challenge in schedule is about
parallelization, e.g., parallelization of loops (especially for nested
loops), which has attracted the attention of many developers. On
the other hand, parallel reduction, which is used in parallel pro-
gramming to reduce the elements of an array into a single result,
is also a challenge that developers often struggle with, e.g., the
problem of memory management in parallel reduction with CUDA.
Algorithm: A term that appears a lot in algorithm-related questions
is optimization, which mainly involves the time and space efficiency
of the algorithm. It is also concerned about various algorithms, such
as sorting and recursion. In particular, how to implement classi-
cal algorithms in GPU attracts much attention, e.g., triangulation
algorithm, AES algorithm, and Dijkstra‚Äôs algorithm. Hence, devel-
opers need more help in choosing the suitable implementation of
different algorithms and in comparing the differences between the
algorithms implemented in GPUs and CPUs.
Vector: A vector can be regarded as a specific dynamic array, and
the most frequent questions are concerned with vector types, data
transfer, and operations such as the summation and multiplication
of vectors. It is challenging for developers to fully understand the
differences (e.g., float2, float3, and float4 in CUDA) and advantages
(e.g., unit2 and unit4 in CUDA) among various vector types. Passing
vector data between programs is also troublesome for developers,for example, how to pass vectors from C++ to the OpenCL ker-
nel.Data Frame: It covers challenges in performing operations on
specific data types, such as type conversion and bitwise opera-
tion, with the most prevalent questions regarding the operations of
float points. In addition, comparisons between unsigned and signed
data and precision issues (e.g., ‚ÄúOpenCL floating point precision
management‚Äù [42]) are also highlighted concerns for developers.
Kernel & Thread. Questions in this category have been one of
the most-widely discussed ones for GPU developers (accounting for
13.5%). Kernel: The questions are mainly about the launch of kernel,
parameters of kernel, and the nesting of kernel. Many developers
have doubts about the understanding (e.g., how the kernel reads
parameter values) and using of kernel parameters (e.g., how to pass
two-dimensional arrays as kernel parameters), so errors are often
reported in the kernel calls. Whether kernel calls are synchronous
or asynchronous and how to call another kernel from one kernel
are also common questions from developers. Thread: There are two
types of challenges that stand out in this category. One is about the
organization of threads and the other is about the synchronization
of threads. Threads are organized in blocks, and multiple blocks
form a grid. The question of the size of threads, blocks, and grids
(e.g., what is the maximum number of blocks per grid) and how to
set the appropriate size for them has confused developers.
Memory. Among 39 topics, questions related to Memory consti-
tute the largest number (9.5%), reflecting the complexity of manag-
ing different types of memory in GPU programming. For example,
there are host memory, global or device memory, local memory,
constant memory, and shared memory in CUDA, and host mem-
ory, global memory, private memory in OpenCL. It is a challenge
for developers to distinguish between these memory differences.
Besides, developers have asked a number of questions about mem-
ory management (e.g., ‚ÄúOpenCL: Correct results on CPU not on
GPU: how to manage memory correctly?‚Äù [ 40]), memory allocation
(e.g., ‚ÄúCUDA Memory Allocation accessible for both host and de-
vice‚Äù [ 38]), and some specific memory issues about shared memory
(e.g., bank conflicts) and local memory (e.g., limitation of size).
API & Library. In GPU programming, there are many libraries
with numerous APIs provided by different frameworks to help de-
velopers perform various computations conveniently. However,
their sheer volume and functional similarity pose challenges in
selecting and using suitable ones. API: Developers are more con-
cerned about the combinatorial use of APIs and what APIs are
available in GPU programming that have the same functionality
as their counterparts in traditional programming. There are also
many questions about comparing differences between similar APIs
(e.g., cudaMallocManaged andcudaMalloc ), and complaints from
developers about the API documentation (e.g., lack of examples
and pitfall prevention instructions). Library: The most prominent
challenges related to libraries are the selection of libraries and the
comparison of similar libraries. Furthermore, developers are of-
ten confused about the use of some specific libraries. Examples of
libraries that are often asked for include Thrust (a parallel algo-
rithms library), cuFFT (a fast Fourier transform library), and cuBLAS
(an implementation of Basic Linear Algebra Subprograms).
Grammar. With GPU programming rapidly advancing, numer-
ous languages now offer extended support, attracting more devel-
opers. Consequently, developers face challenges associated with
1451Understanding the Topics and Challenges of GPU Programming by Classifying and Analyzing SO Posts ESEC/FSE ‚Äô23, December 3‚Äì9, 2023, San Francisco, CA, USA
the syntax of these varied programming languages. The category
ofGrammar involves questions on many aspects of a program-
ming language, including Function ,Variable ,Pointer ,Class ,Struct ,
Template , and Header . These questions are basically about the lan-
guage‚Äôs own mechanisms, such as the use of inline functions and
the instantiation of templates, and many of them currently are not
specifically related to the features of GPU programming.
Debug. Debugging is an essential part of programming. The
most highlighted term in this category is error, which indicates that
GPU programming is error-prone. Debug concerns the questions
about locating and fixing bugs during GPU program development,
e.g., identification of the cause of crash [ 41] and warning [ 43]. There
are many types of errors, several of which are often mentioned,
such as errors caused by device, driver, and import errors.
Performance. It is common for developers to struggle with
the disappointing running speed of their programs, as explained
by the developer in [ 46]. In particular, developers are interested
in maximizing GPU potential computation power to improve the
speed of program execution, which is challenging [ 44]. There are
several common classes of challenges in this category. The first class
is about performance comparisons, e.g., between GeForce GPUs and
Quadro GPUs, between GPUs and CPUs, and between CUDA and
OpenCL. The second class concerns performance and memory, such
as using texture memory to improve performance, access speed of
OpenCL private memory and local memory, and the performance
bottleneck of CUDA memory allocation. The third class is how to
monitor and evaluate GPU performance, which overlaps slightly
with the topic monitor, but focuses only on performance.
Basic Concepts andGeneral Questions. These two categories
are added during the manual classification of questions, and their
shares are small (1.4% and 0.6%, respectively). Basic Concepts in-
cludes questions about background knowledge of GPU develop-
ment, such as ‚ÄúWhat does SIMD mean?‚Äù [ 50]. The number of ques-
tions in this category is small but popular, especially in the early
days of GPU programming. This is mainly because many begin-
ners learn and understand GPU programming by browsing these
questions and answers on SO. The second category is about gen-
eral questions that are not related to other specific topics in GPU
programming, e.g., ‚ÄúHow to create LLVM structure value?‚Äù [45].
5.2 Environment
Deployment. This category focuses on issues related to the deploy-
ment of GPU development platforms such as CUDA and OpenCL.
It covers questions on six topics: Compile ,Install ,Configure ,Build ,
Link, and Docker , the first five of which correspond to the different
tasks, and the last of which is about enabling and using GPUs in-
side a Docker container. Each topic‚Äôs questions basically depict the
challenges developers face when undertaking the associated task.
Compile: Many questions in this category are concerned with
the use of commands gccandnvcc . This is because different GPU
computing platforms have limited support for GCC and NVCC
versions, making it easy to run into compatibility issues when com-
piling. In addition, when compiling GPU programs under different
operating systems, it can be a challenge for some developers to
select and configure the compiler to avoid compilation errors (espe-
cially compatibility issues). Install: As we can see from the resultsof RQ2, this topic ranks high in terms of difficulty. GPU program-
ming requires the installation of various platforms and software.
However, different platforms and software are constantly being
updated, which raises many compatibility issues. Therefore, there
are many questions about how to confirm that a software, platform,
or driver is installed or successfully installed, and how to uninstall
and install a specific version. Configure: Configuring the CUDA
kernel is the most frequently mentioned issue, such as not knowing
how to configure its parameters or configuring parameters that
cause errors. Some developers complained that the CUDA kernel
startup parameters are not clearly explained. In addition, there
are many configuration questions related to Visual Studio, mainly
about what configuration is needed to perform GPU programming
in Visual Studio. Build: The questions in this category are mostly
developers asking how to solve problems they encounter when
building GPU programs, the most common of which are errors
related to CMake. Link andDocker are basically questions or errors
that developers encounter when linking and using Docker (e.g. how
to link CUDA code to C/C++ projects), but there are many types of
questions/errors and no particular focus. However, the number of
questions in them is significant. Furthermore, we can learn from
RQ2 that Deployment has been a notable struggle for developers of
GPU programming. Therefore, researchers are expected to propose
automated deployment techniques to simplify deployment tasks
(e.g., eliminating compatibility issues) for developers.
Device. Questions in this category are mainly about GPU de-
vices. Card: Given the variety of GPU card versions from different
vendors, developers grapple with issues like distinguishing card
differences, compatibility with GPU platforms, and uncertainty
about the appropriate APIs for gathering card information when
programming. Architecture: It is concerned about the whole hard-
ware architecture (e.g., Fermi, Kepler, and Maxwell) and its concrete
components such as stream multiprocessor, core, and cache. These
questions focus on the characteristics of these architectures and
how to understand them. Driver: The most common term in this
category is version, and many of the challenges developers face are
related to driver version, such as not having enough driver version
for the CUDA runtime version. Another challenge is that some
developers are unclear about how to obtain information about dri-
vers in programming. Hardware: The most highlighted issue in this
category is about hardware emulation, i.e., how to simulate GPUs
without GPU hardware support. Another requirement of interest
to developers is the use of GPUs for hardware acceleration, but
many questions actually tie back to the configuration of operating
systems.
Monitor. GPU monitoring can help developers track GPU per-
formance or overall GPU resource usage, so many developers use
it and raise a number of questions about it (accounting for 2.3%
ofF). The use of the monitoring tool nvidia-smi leaves many de-
velopers with doubts, and the questions related to it are the most
pronounced in this category. There are also some questions about
getting specific execution information such as GPU temperature,
GPU computation, GPU usage history, and GPU FLOPS (floating
point operations per second). Tool. Most of the questions are about
installing and configuring the CUDA toolkit and OpenCL SDK, but
the number is small and developers do not find it difficult.
1452ESEC/FSE ‚Äô23, December 3‚Äì9, 2023, San Francisco, CA, USA Wenhua Yang, Chong Zhang, and Minxue Pan
5.3 Application
Multimedia. In the early days of the development of modern GPUs,
the number of multimedia-related questions on SO is very high, and
now the number is relatively small. This indicates that developers
are becoming more familiar with the use of GPUs for multimedia.
However, there are still challenges for developers in this area.
Image Processing: Many of the early questions in this category
are about OpenCV and OpenCL, such as image format conversion
and image manipulation in OpenCV. Currently there are not many
such questions, but more questions about the new features brought
by OpenCV updates and how to combine OpenCV with other pro-
gramming tools. Graphics Programming: The trend of questions
in this category is similar to that of image processing, but the dif-
ference is that OpenGL is the focus here. Shading and rendering
are among the most frequently mentioned features, and questions
relatd to them are often asked as OpenGL is being updated. Video:
There are relatively few questions here, most of which are related
to video streaming and FFmpeg (a video and audio converter).
Deep Learning Framework. Recently, we are seeing more ques-
tions about GPUs and deep learning on SO. This category deals with
questions about deep learning frameworks that provide a bridge for
developers to use GPUs to train deep neural networks. There are
several frameworks, such as TensorFlow ,PyTorch ,Keras , and Theano .
TensorFlow is based on Theano, while PyTorch is based on Torch,
and Keras is the high-level API of TensorFlow. The number of ques-
tions related to TensorFlow dominated, followed by PyTorch. This
is understandable since TensorFlow is the most popular framework
for deep learning production environments and has a large commu-
nity. Since TensorFlow has been proposed more recently, how to
successfully run TensorFlow on GPUs is the most frequently asked
question, which includes TensorFlow installation, configuration,
and version compatibility. In addition, there are some specific errors
reported when running TensorFlow code, among which errors re-
lated to dynamic libraries are very common. The types of questions
under other frameworks are similar to those in TensorFlow, and the
most prominent challenge is also how to get them to run success-
fully on GPUs. Meanwhile, GPUs impose programming constraints
to avoid training anomalies, and yet, many GPU interfaces and
usage scenarios are not well documented [ 48], causing problems
for developers. One of the most admired characteristics of GPUs
is their ability to compute processes in parallel, and thus GPUs
can be used for massive distributed computational processes, e.g.,
training deep learning models. With deep learning‚Äôs evolution, an
increasing number of developers apply it in GPU programming, so
researchers need to be better equipped to help them overcome the
challenges involved, as echoed in [73].
6 IMPLICATIONS
Our findings offer contributions to GPU development research and
also harbor practical implications for both developers and vendors,
imparting valuable insights into the field.
6.1 Research
The implications of our study for researchers are multifaceted.
Firstly, the taxonomy we have proposed can assist researchers
in systematically understanding the challenges in the diverse topicsof GPU programming. Researchers can concentrate on prevalent is-
sues within these topics while, simultaneously, our detailed analysis
of the challenges for each topic, presented in Section 5, allows ev-
ery individual challenge to potentially become a research question.
For instance, the parallelism challenge within the Schedule topic is
crucial for heavy computational workloads, such as training large
models. However, manually writing parallel programs presents its
own difficulties. Consequently, researchers can explore strategies to
identify parallelizable code segments to enhance parallelism, whilst
ensuring that the automatically generated parallel programs are
error-free.
Secondly, our analysis of topic popularity, difficulty, and chang-
ing trends facilitates researchers in prioritizing their research tasks.
A representative example is the Deployment topic, of which the
challenges consistently maintain a high rank, whether assessed in
terms of popularity, difficulty, or changing trends. To the best of our
knowledge, there is few research on deployment issues, indicating a
neglected area. However, there are numerous potential research op-
portunities within this topic, such as improving checks for software
and hardware compatibility necessary for deployment, identifying
prerequisite dependencies for deployment, automatically locating
error causes when they occur, or even simpler tasks such as creating
clear, detailed deployment documentation for systematic learning
and troubleshooting by developers.
Finally, this study indicates that issues related to GPU program-
ming are abundant on SO, not only highlighting the worthiness of
researching challenges in GPU programming, but also suggesting
that SO posts contain a wealth of knowledge regarding solutions
to these challenges. Thus, researchers can utilize the data on SO to
design solutions to problems or propose automated solution extrac-
tion methods for problem resolution, documentation construction,
and more.
6.2 Practice
For GPU program developers, the taxonomy of topics could serve as
a guide to identify key problem areas and challenges they might face
during development. By referring to the taxonomy and correspond-
ing discussion, developers can anticipate potential pitfalls and make
informed decisions about the trade-offs involved in GPU program-
ming. Furthermore, by understanding the challenges compiled from
the analysis of posts, developers can better equip themselves to
preemptively tackle these issues. For instance, the analysis of topics
such as Data Structures ,Algorithm ,Memory , and Performance un-
derscores the inherent contrasts in computational precision, speed,
and optimal implementation between GPUs and CPUs, thereby
illuminating the necessity for distinct strategies in handling ma-
trix operations, algorithm implementation, and the optimization of
memory data layouts and access patterns in GPU programming.
Our study provides GPU vendors with practical implications for
enhancing their products and services. The identified challenges
faced by developers underline areas for possible hardware and soft-
ware improvements. For instance, the high ranking of deployment-
related challenges and the medium-high ranking of monitoring-
related challenges in both popularity and difficulty, suggest areas
for focused attention. Vendors should invest in refining deployment
tools or enhancing documentation to increase product ease-of-use.
1453Understanding the Topics and Challenges of GPU Programming by Classifying and Analyzing SO Posts ESEC/FSE ‚Äô23, December 3‚Äì9, 2023, San Francisco, CA, USA
Moreover, the development of more powerful and intuitive moni-
toring tools is necessary for mitigating the monitoring-related chal-
lenges. By addressing these identified areas, vendors can improve
product usability and potentially elevate overall user satisfaction.
7 THREATS TO VALIDITY
Selection of data source. Following previous work [ 4,5,19,22,69,
70], we choose SO as our sole data source. This is a potential threat,
as SO may not capture all developer questions, and we may miss
valuable insights from other sources. However, considering that
SO is a very active community with many participating developers,
including novices and experts, we believe this threat is reduced.
Selection of tags. The creation of our tag set could introduce bias
as the selected tags may not cover all GPU-related questions. To
mitigate this risk, we followed established approaches [ 4,5,22,70]
and conducted experiments to derive an appropriate tag set. Never-
theless, the final selection of tags could be influenced by individual
experiences. To mitigate this, we engaged two researchers in the
validation process to enhance the reliability and validity of the final
tag selection.
Construction of topic taxonomy. During the classification of
questions to topics, a small proportion of questions (9.8%) were
manually categorized, which could introduce imprecision. To en-
sure validity, we sampled over 7,000 questions for reliability testing
and conducted hypothesis testing. The results validated the relia-
bility of our classification. The creation of the taxonomy is based
on topics. Although the number of the topics are manageable, the
manual effort involved carries potential threats. To mitigate these
risks, we strictly adhered to established methods and guidelines for
the inductive construction and refinement of the topic taxonomy.
Two researchers collaborated to discuss results and reach consen-
sus with the assistance of an arbitrator when necessary, thereby
enhancing the reliability of the results. We also provide a detailed
account of our manual analysis procedures in Section 2 to facilitate
an understanding of any potential threats.
8 RELATED WORK
Studies using SO data. SO is one of the most popular Q&A website
for professional and enthusiast programmers, which has attracted
increasing research interest, with topics relating to community
dynamics, human factors, and technical issues [ 34]. There exist
many studies investigating how SO knowledge benefits developers‚Äô
daily software development [ 1,64]. In addition, researchers also
analyze a series of features of the whole SO data, such as ques-
tion categories [ 11], community model [ 33], topics and trends [ 9].
More specifically, SO has been widely used as data source to ex-
plore developers‚Äô concerns in developing various types of soft-
ware and facing different programming tasks, such as big data [ 5],
docker [ 22], security [ 70], concurrency [ 4], mobile applications [ 56],
web applications [ 6], privacy [ 60], deep learning [ 17,25,73,74], and
computer vision [ 19]. Particularly, in [ 63], SO data was utilized to as-
sess formal verification tools for GPU programming issues, mainly
potential bugs and performance problems. The study focused on
questions explicitly related to CUDA and OpenCL, excluding other
topics. 376 SO questions were selected and manually categorized
via card sorting into three primary themes: memory, threads andsynchronization, and general issues. Each theme contained two sub-
themes related to bugs and performance. In contrast to [ 63], our
study aims to derive an understanding of the topics and challenges
in GPU programming. This necessitated a broader analysis of SO
data and a more sophisticated topic extraction method, resulting
in a comprehensive taxonomy of GPU programming topics and an
in-depth discussion of the associated challenges.
Research on GPU programming. Over the last few decades,
many studies have revealed the huge potential and broad prospect
of GPU computing because of its highly parallel programmable
capacity [ 26,36,51]. Therefore, there are many efforts to study
GPU computing, especially for the comparison of GPU and CPU in
performance [ 28], architecture [ 13] and specific algorithms [ 53]. De-
spite GPUs‚Äô current high capacity, researchers are still working on
methods to further improve GPUs‚Äô capabilities [ 67,71]. Meanwhile,
there is another large category of studies that focus on applying
GPUs to non-graphics application domains, to name a few, deep
learning [18], cloud computing [54], and automatic driving[75].
In addition, GPU programming itself has attracted increasing
amounts of attention from researchers. For example, to help devel-
opers get started with GPU programming, researchers discussed
various guidelines for GPU programming such as thread and mem-
ory handling [ 14]. The verification of GPU kernel has also been
the focus of many researchers. They have proposed a variety of
approaches based on Satisfiability Modulo Theories (SMT) [ 30],
test amplification [ 29], and symbolic execution [ 31] to verify the
GPU kernel. These approaches aim to detect bugs such as data
races, incorrectly synchronized barriers, and bank conflicts. Also
for debugging, Hou et al. [ 23] present a debugger for GPU stream
programs through automatic dataflow recording and visualization.
With dataflow recording, the debugger automatically detects com-
mon memory errors such as out-of-bound access, uninitialized data
access, and race conditions. Although there are plenty of research
efforts on GPU programming, they all focus on a specific type of
problem (e.g., GPU kernel) and cannot represent all the challenges
developers may face in GPU programming. Our work conducts the
first study to understand various challenges that developers may
encounter in GPU programming using SO posts.
9 CONCLUSION
In this paper, we conduct a large-scale empirical study to understand
the topics and challenges of GPU programming based on 25,269
SO posts. We employ automated methods and invest extensive
manual effort to build a taxonomy of topics for GPU programming
and analyze the popularity, difficulty, and changing trends of these
topics. In addition, we summarize the challenges organized by topic,
highlighting potential future work for researchers and developers.
10 DATA AVAILABILITY
This paper offers a dataset of posts related to GPU programming at
https://doi.org/10.5281/zenodo.8248161.
ACKNOWLEDGMENT
This work was partially supported by the National Natural Science
Foundation of China (Nos. 61972193, 61972197) and the Natural
Science Foundation of Jiangsu Province (No. BK20201292).
1454ESEC/FSE ‚Äô23, December 3‚Äì9, 2023, San Francisco, CA, USA Wenhua Yang, Chong Zhang, and Minxue Pan
REFERENCES
[1]Rabe Abdalkareem, Emad Shihab, and Juergen Rilling. 2017. What do developers
use the crowd for? a study using stack overflow. IEEE Software 34, 2 (2017),
53‚Äì60.
[2]Emad Aghajani, Csaba Nagy, Olga Lucero Vega-M√°rquez, Mario Linares-V√°squez,
Laura Moreno, Gabriele Bavota, and Michele Lanza. 2019. Software Documenta-
tion Issues Unveiled. In Proceedings of the 41st International Conference on Software
Engineering (Montreal, Quebec, Canada) (ICSE ‚Äô19) . IEEE Press, 1199‚Äì1210.
https://doi.org/10.1109/ICSE.2019.00122
[3]Md Ahasanuzzaman, Muhammad Asaduzzaman, Chanchal K. Roy, and Kevin A.
Schneider. 2018. Classifying stack overflow posts on API issues. In 2018 IEEE
25th International Conference on Software Analysis, Evolution and Reengineering
(SANER) . 244‚Äì254. https://doi.org/10.1109/SANER.2018.8330213
[4]Syed Ahmed and Mehdi Bagherzadeh. 2018. What Do Concurrency Developers
Ask about? A Large-Scale Study Using Stack Overflow. In Proceedings of the
12th ACM/IEEE International Symposium on Empirical Software Engineering and
Measurement (Oulu, Finland) (ESEM ‚Äô18) . Association for Computing Machinery,
New York, NY, USA, Article 30, 10 pages. https://doi.org/10.1145/3239235.
3239524
[5]Mehdi Bagherzadeh and Raffi Khatchadourian. 2019. Going Big: A Large-
Scale Study on What Big Data Developers Ask. In Proceedings of the 2019 27th
ACM Joint Meeting on European Software Engineering Conference and Sympo-
sium on the Foundations of Software Engineering (Tallinn, Estonia) (ESEC/FSE
2019) . Association for Computing Machinery, New York, NY, USA, 432‚Äì442.
https://doi.org/10.1145/3338906.3338939
[6]Kartik Bajaj, Karthik Pattabiraman, and Ali Mesbah. 2014. Mining questions
asked by web developers. In Proceedings of the 11th Working conference on mining
software repositories . 112‚Äì121.
[7]Kartik Bajaj, Karthik Pattabiraman, and Ali Mesbah. 2014. Mining Questions
Asked by Web Developers. In Proceedings of the 11th Working Conference on
Mining Software Repositories (Hyderabad, India) (MSR 2014) . Association for
Computing Machinery, New York, NY, USA, 112‚Äì121. https://doi.org/10.1145/
2597073.2597083
[8]Abdul Ali Bangash, Hareem Sahar, Shaiful Chowdhury, Alexander William Wong,
Abram Hindle, and Karim Ali. 2019. What Do Developers Know about Machine
Learning: A Study of ML Discussions on StackOverflow. In Proceedings of the
16th International Conference on Mining Software Repositories (Montreal, Quebec,
Canada) (MSR ‚Äô19) . IEEE Press, 260‚Äì264. https://doi.org/10.1109/MSR.2019.00052
[9] Anton Barua, Stephen W Thomas, and Ahmed E Hassan. 2014. What are devel-
opers talking about? an analysis of topics and trends in stack overflow. Empirical
Software Engineering 19, 3 (2014), 619‚Äì654.
[10] Ohad Barzilay, Christoph Treude, and Alexey Zagalsky. 2013. Facilitating crowd
sourced software engineering via stack overflow. In Finding Source Code on the
Web for Remix and Reuse . Springer, 289‚Äì308.
[11] Stefanie Beyer, Christian Macho, Martin Pinzger, and Massimiliano Di Penta. 2018.
Automatically Classifying Posts into Question Categories on Stack Overflow.
InProceedings of the 26th Conference on Program Comprehension (Gothenburg,
Sweden) (ICPC ‚Äô18) . Association for Computing Machinery, New York, NY, USA,
211‚Äì221. https://doi.org/10.1145/3196321.3196333
[12] Robert A. Bridges, Neena Imam, and Tiffany M. Mintz. 2016. Understanding GPU
Power: A Survey of Profiling, Modeling, and Simulation Methods. ACM Comput.
Surv. 49, 3, Article 41 (sep 2016), 27 pages. https://doi.org/10.1145/2962131
[13] Andr√© Rigland Brodtkorb and Trond Runar Hagen. 2008. A comparison of
three commodity-level parallel architectures: Multi-core CPU, Cell BE and GPU.
InInternational Conference on Mathematical Methods for Curves and Surfaces .
Springer, 70‚Äì80.
[14] Andr√© R Brodtkorb, Trond R Hagen, and Martin L S√¶tra. 2013. Graphics process-
ing unit (GPU) programming strategies and trends in GPU computing. J. Parallel
and Distrib. Comput. 73, 1 (2013), 4‚Äì13.
[15] Ricardo Campos, V√≠tor Mangaravite, Arian Pasquali, Al√≠pio Jorge, C√©lia Nunes,
and Adam Jatowt. 2020. YAKE! Keyword extraction from single documents using
multiple local features. Information Sciences 509 (2020), 257‚Äì289.
[16] Ricardo Campos, V√≠tor Mangaravite, Arian Pasquali, Al√≠pio M√°rio Jorge, C√©lia
Nunes, and Adam Jatowt. 2018. Yake! collection-independent automatic keyword
extractor. In European Conference on Information Retrieval . Springer, 806‚Äì810.
[17] Zhenpeng Chen, Yanbin Cao, Yuanqiang Liu, Haoyu Wang, Tao Xie, and Xuanzhe
Liu. 2020. A Comprehensive Study on Challenges in Deploying Deep Learning
Based Software. In Proceedings of the 28th ACM Joint Meeting on European Software
Engineering Conference and Symposium on the Foundations of Software Engineering
(Virtual Event, USA) (ESEC/FSE 2020) . Association for Computing Machinery,
New York, NY, USA, 750‚Äì762. https://doi.org/10.1145/3368089.3409759
[18] Henggang Cui, Hao Zhang, Gregory R. Ganger, Phillip B. Gibbons, and Eric P.
Xing. 2016. GeePS: Scalable Deep Learning on Distributed GPUs with a GPU-
Specialized Parameter Server. In Proceedings of the Eleventh European Conference
on Computer Systems (London, United Kingdom) (EuroSys ‚Äô16) . Association for
Computing Machinery, New York, NY, USA, Article 4, 16 pages. https://doi.or
g/10.1145/2901318.2901323[19] Alex Cummaudo, Rajesh Vasa, Scott Barnett, John Grundy, and Mohamed Ab-
delrazek. 2020. Interpreting Cloud Computer Vision Pain-Points: A Mining
Study of Stack Overflow. In Proceedings of the ACM/IEEE 42nd International
Conference on Software Engineering (Seoul, South Korea) (ICSE ‚Äô20) . Associ-
ation for Computing Machinery, New York, NY, USA, 1584‚Äì1596. https:
//doi.org/10.1145/3377811.3380404
[20] Andrew Forward and Timothy C. Lethbridge. 2008. A Taxonomy of Software
Types to Facilitate Search and Evidence-Based Software Engineering. In Pro-
ceedings of the 2008 Conference of the Center for Advanced Studies on Collab-
orative Research: Meeting of Minds (Ontario, Canada) (CASCON ‚Äô08) . Associa-
tion for Computing Machinery, New York, NY, USA, Article 14, 13 pages.
https://doi.org/10.1145/1463788.1463807
[21] Kevin A Hallgren. 2012. Computing inter-rater reliability for observational data:
an overview and tutorial. Tutorials in quantitative methods for psychology 8, 1
(2012), 23.
[22] Mubin Ul Haque, Leonardo Horn Iwaya, and M. Ali Babar. 2020. Challenges in
Docker Development: A Large-Scale Study Using Stack Overflow. In Proceedings
of the 14th ACM / IEEE International Symposium on Empirical Software Engineering
and Measurement (ESEM) (Bari, Italy) (ESEM ‚Äô20) . Association for Computing
Machinery, New York, NY, USA, Article 7, 11 pages. https://doi.org/10.1145/
3382494.3410693
[23] Qiming Hou, Kun Zhou, and Baining Guo. 2009. Debugging GPU Stream
Programs through Automatic Dataflow Recording and Visualization. In ACM
SIGGRAPH Asia 2009 Papers (Yokohama, Japan) (SIGGRAPH Asia ‚Äô09) . Associ-
ation for Computing Machinery, New York, NY, USA, Article 153, 11 pages.
https://doi.org/10.1145/1661412.1618499
[24] Stack Exchange Inc. 2021. Stack Exchange Dump. https://archive.org/details/st
ackexchange. Retrieved on December 22, 2022.
[25] Md Johirul Islam, Giang Nguyen, Rangeet Pan, and Hridesh Rajan. 2019. A
Comprehensive Study on Deep Learning Bug Characteristics. In Proceedings of
the 2019 27th ACM Joint Meeting on European Software Engineering Conference
and Symposium on the Foundations of Software Engineering (Tallinn, Estonia)
(ESEC/FSE 2019) . Association for Computing Machinery, New York, NY, USA,
510‚Äì520. https://doi.org/10.1145/3338906.3338955
[26] Stephen W Keckler, William J Dally, Brucek Khailany, Michael Garland, and
David Glasco. 2011. GPUs and the future of parallel computing. IEEE micro 31, 5
(2011), 7‚Äì17.
[27] Pradeep V Kotipalli, Ranvijay Singh, Paul Wood, Ignacio Laguna, and Saurabh
Bagchi. 2019. AMPT-GA: Automatic Mixed Precision Floating Point Tuning for
GPU Applications. In Proceedings of the ACM International Conference on Super-
computing (Phoenix, Arizona) (ICS ‚Äô19) . Association for Computing Machinery,
New York, NY, USA, 160‚Äì170. https://doi.org/10.1145/3330345.3330360
[28] Victor W. Lee, Changkyu Kim, Jatin Chhugani, Michael Deisher, Daehyun Kim,
Anthony D. Nguyen, Nadathur Satish, Mikhail Smelyanskiy, Srinivas Chennupaty,
Per Hammarlund, Ronak Singhal, and Pradeep Dubey. 2010. Debunking the
100X GPU vs. CPU Myth: An Evaluation of Throughput Computing on CPU
and GPU. SIGARCH Comput. Archit. News 38, 3 (jun 2010), 451‚Äì460. https:
//doi.org/10.1145/1816038.1816021
[29] Alan Leung, Manish Gupta, Yuvraj Agarwal, Rajesh Gupta, Ranjit Jhala, and
Sorin Lerner. 2012. Verifying GPU Kernels by Test Amplification. In Proceedings
of the 33rd ACM SIGPLAN Conference on Programming Language Design and
Implementation (Beijing, China) (PLDI ‚Äô12) . Association for Computing Machinery,
New York, NY, USA, 383‚Äì394. https://doi.org/10.1145/2254064.2254110
[30] Guodong Li and Ganesh Gopalakrishnan. 2010. Scalable SMT-Based Verifica-
tion of GPU Kernel Functions. In Proceedings of the Eighteenth ACM SIGSOFT
International Symposium on Foundations of Software Engineering (Santa Fe, New
Mexico, USA) (FSE ‚Äô10) . Association for Computing Machinery, New York, NY,
USA, 187‚Äì196. https://doi.org/10.1145/1882291.1882320
[31] Guodong Li, Peng Li, Geof Sawaya, Ganesh Gopalakrishnan, Indradeep Ghosh,
and Sreeranga P. Rajan. 2012. GKLEE: Concolic Verification and Test Generation
for GPUs. In Proceedings of the 17th ACM SIGPLAN Symposium on Principles
and Practice of Parallel Programming (New Orleans, Louisiana, USA) (PPoPP
‚Äô12). Association for Computing Machinery, New York, NY, USA, 215‚Äì224.
https://doi.org/10.1145/2145816.2145844
[32] Qiang Li, Jinke Song, Dawei Tan, Haining Wang, and Jiqiang Liu. 2021. PDGraph:
A Large-Scale Empirical Study on Project Dependency of Security Vulnerabilities.
In2021 51st Annual IEEE/IFIP International Conference on Dependable Systems and
Networks (DSN) . IEEE, 161‚Äì173.
[33] Lena Mamykina, Bella Manoim, Manas Mittal, George Hripcsak, and Bj√∂rn Hart-
mann. 2011. Design Lessons from the Fastest Q&a Site in the West. In Proceedings
of the SIGCHI Conference on Human Factors in Computing Systems (Vancouver,
BC, Canada) (CHI ‚Äô11) . Association for Computing Machinery, New York, NY,
USA, 2857‚Äì2866. https://doi.org/10.1145/1978942.1979366
[34] Sarah Meldrum, Sherlock A. Licorish, and Bastin Tony Roy Savarimuthu. 2017.
Crowdsourced Knowledge on Stack Overflow: A Systematic Mapping Study
(EASE‚Äô17) . Association for Computing Machinery, New York, NY, USA, 180‚Äì185.
https://doi.org/10.1145/3084226.3084267
[35] Sarah Nadi, Stefan Kr√ºger, Mira Mezini, and Eric Bodden. 2016. Jumping through
hoops: Why do Java developers struggle with cryptography APIs?. In Proceedings
1455Understanding the Topics and Challenges of GPU Programming by Classifying and Analyzing SO Posts ESEC/FSE ‚Äô23, December 3‚Äì9, 2023, San Francisco, CA, USA
of the 38th International Conference on Software Engineering . 935‚Äì946.
[36] John Nickolls and William J. Dally. 2010. The GPU Computing Era. IEEE Micro
30, 2 (2010), 56‚Äì69. https://doi.org/10.1109/MM.2010.41
[37] NVIDIA. 2022. https://developer.nvidia.com/about-cuda. Retrieved on April 12,
2022.
[38] Stack Overflow. 2009. https://stackoverflow.com/questions/1739659/cuda-me
mory-allocation-accessible-for-both-host-and-device. Retrieved on December
22, 2022.
[39] Stack Overflow. 2012. https://stackoverflow.com/questions/5963269/how-to-
make-a-great-r-reproducible-example. Retrieved on June 5, 2023.
[40] Stack Overflow. 2012. https://stackoverflow.com/questions/8823862/opencl-corr
ect-results-on-cpu-not-on-gpu-how-to-manage-memory-correctly. Retrieved
on December 22, 2022.
[41] Stack Overflow. 2012. https://stackoverflow.com/questions/9509068/second-
iteration-crash-order-irrelevant. Retrieved on December 22, 2022.
[42] Stack Overflow. 2013. https://stackoverflow.com/questions/17588042/opencl-
floating-point-precision-management. Retrieved on December 22, 2022.
[43] Stack Overflow. 2013. https://stackoverflow.com/questions/18203992/spurio
us-warning-about-string-constants-using-a-macro-in-opencl. Retrieved on
December 22, 2022.
[44] Stack Overflow. 2013. https://stackoverflow.com/questions/18016802/how-can-
one-enhance-the-utilization-of-processors-for-faster-data-processing. Re-
trieved on December 22, 2022.
[45] Stack Overflow. 2013. https://stackoverflow.com/questions/15785644/how-to-
create-llvm-structure-value. Retrieved on December 22, 2022.
[46] Stack Overflow. 2015. https://stackoverflow.com/questions/29544310/arrayfire-
evaluation-of-equations-running-really-slowly. Retrieved on December 22,
2022.
[47] Stack Overflow. 2016. https://stackoverflow.com/questions/35951487/tensorflow-
only-works-with-gpu-0. Retrieved on December 22, 2022.
[48] Stack Overflow. 2016. https://stackoverflow.com/questions/38559755/how-to-
get-current-available-gpus-in-tensorflow. Retrieved on December 22, 2022.
[49] Stack Overflow. 2017. https://stackoverflow.com/questions/42403501/how-does-
one-have-tensorflow-not-run-the-script-unless-the-gpu-was-loaded-succes.
Retrieved on December 22, 2022.
[50] Stack Overflow. 2019. https://stackoverflow.com/questions/55226548/what-does-
simd-mean. Retrieved on December 22, 2022.
[51] John D. Owens, Mike Houston, David Luebke, Simon Green, John E. Stone, and
James C. Phillips. 2008. GPU Computing. Proc. IEEE 96, 5 (2008), 879‚Äì899.
https://doi.org/10.1109/JPROC.2008.917757
[52] M. F. Porter. 1997. An Algorithm for Suffix Stripping . Morgan Kaufmann Publishers
Inc., San Francisco, CA, USA, 313‚Äì316. https://pythonspot.com/nltk-stop-words/
[53] Michael Rauter and David Schreiber. 2012. A GPU accelerated fast directional
chamfer matching algorithm and a detailed comparison with a highly optimized
cpu implementation. In 2012 IEEE Computer Society Conference on Computer
Vision and Pattern Recognition Workshops . IEEE, 68‚Äì75.
[54] Vignesh T. Ravi, Michela Becchi, Gagan Agrawal, and Srimat Chakradhar. 2011.
Supporting GPU Sharing in Cloud Environments with a Transparent Runtime
Consolidation Framework. In Proceedings of the 20th International Symposium
on High Performance Distributed Computing (San Jose, California, USA) (HPDC
‚Äô11). Association for Computing Machinery, New York, NY, USA, 217‚Äì228.
https://doi.org/10.1145/1996130.1996160
[55] Jonas Rieger, J√∂rg Rahnenf√ºhrer, and Carsten Jentsch. 2020. Improving Latent
Dirichlet Allocation: On Reliability of the Novel Method LDAPrototype. In Natu-
ral Language Processing and Information Systems , Elisabeth M√©tais, Farid Meziane,
Helmut Horacek, and Philipp Cimiano (Eds.). Springer International Publishing,
Cham, 118‚Äì125.
[56] Christoffer Rosen and Emad Shihab. 2016. What are mobile developers asking
about? a large scale study using stack overflow. Empirical Software Engineering
21, 3 (2016), 1192‚Äì1223.
[57] C.B. Seaman. 1999. Qualitative methods in empirical studies of software en-
gineering. IEEE Transactions on Software Engineering 25, 4 (1999), 557‚Äì572.
https://doi.org/10.1109/32.799955
[58] Ma Shi-xiao, Dong Wen-yan, Wang Tong, and Xi Qiu-hong. 2010. Sample size
design and empirical research based on PPS and stratified sample survey. In The
2nd International Conference on Information Science and Engineering . 573‚Äì575.
https://doi.org/10.1109/ICISE.2010.5691614
[59] Robert Smith. 2011. Quantitative Narrative Analysis. The International Journal
of Entrepreneurship and Innovation 12 (02 2011), 78‚Äì79. https://doi.org/10.5367/ijei.2011.0021
[60] Mohammad Tahaei, Kami Vaniea, and Naomi Saphra. 2020. Understanding
Privacy-Related Questions on Stack Overflow . Association for Computing Machin-
ery, New York, NY, USA, 1‚Äì14. https://doi.org/10.1145/3313831.3376768
[61] Amjed Tahir, Aiko Yamashita, Sherlock Licorish, Jens Dietrich, and Steve Counsell.
2018. Can you tell me if it smells? a study on how developers discuss code smells
and anti-patterns in stack overflow. In Proceedings of the 22nd International
Conference on Evaluation and Assessment in Software Engineering 2018 . 68‚Äì78.
[62] Christoph Treude, Ohad Barzilay, and Margaret-Anne Storey. 2011. How do
programmers ask and answer questions on the web?(nier track). In Proceedings
of the 33rd international conference on software engineering . 804‚Äì807.
[63] Lars B. van den Haak, Anton Wijs, Mark van den Brand, and Marieke Huisman.
2020. Formal Methods for GPGPU Programming: Is the Demand Met?. In Inte-
grated Formal Methods: 16th International Conference, IFM 2020, Lugano, Switzer-
land, November 16‚Äì20, 2020, Proceedings (Lugano, Switzerland). Springer-Verlag,
Berlin, Heidelberg, 160‚Äì177. https://doi.org/10.1007/978-3-030-63461-2_9
[64] Bogdan Vasilescu, Vladimir Filkov, and Alexander Serebrenik. 2013. StackOver-
flow and GitHub: Associations between Software Development and Crowd-
sourced Knowledge. In 2013 International Conference on Social Computing . 188‚Äì
195. https://doi.org/10.1109/SocialCom.2013.35
[65] Hao Wang, Sreeram Potluri, Miao Luo, Ashish Kumar Singh, Sayantan Sur, and
Dhabaleswar K. Panda. 2011. MVAPICH2-GPU: optimized GPU to GPU commu-
nication for InfiniBand clusters. Computer Science - Research and Development
26, 3 (01 Jun 2011), 257‚Äì266. https://doi.org/10.1007/s00450-011-0171-3
[66] Jiexin Wang, Adam Jatowt, and Masatoshi Yoshikawa. 2021. Event Occurrence
Date Estimation based on Multivariate Time Series Analysis over Temporal Doc-
ument Collections. In Proceedings of the 44th International ACM SIGIR Conference
on Research and Development in Information Retrieval . 398‚Äì407.
[67] Linnan Wang, Jinmian Ye, Yiyang Zhao, Wei Wu, Ang Li, Shuaiwen Leon Song,
Zenglin Xu, and Tim Kraska. 2018. Superneurons: Dynamic GPU Memory
Management for Training Deep Neural Networks. In Proceedings of the 23rd ACM
SIGPLAN Symposium on Principles and Practice of Parallel Programming (Vienna,
Austria) (PPoPP ‚Äô18) . Association for Computing Machinery, New York, NY, USA,
41‚Äì53. https://doi.org/10.1145/3178487.3178491
[68] Mingyuan Wu, Lingming Zhang, Cong Liu, Shin Hwei Tan, and Yuqun Zhang.
2019. Automating CUDA Synchronization via Program Transformation. In 2019
34th IEEE/ACM International Conference on Automated Software Engineering (ASE) .
748‚Äì759. https://doi.org/10.1109/ASE.2019.00075
[69] Wenhua Yang, Chong Zhang, Minxue Pan, Chang Xu, Yu Zhou, and Zhiqiu Huang.
2022. Do Developers Really Know How to Use Git Commands? A Large-Scale
Study Using Stack Overflow. ACM Trans. Softw. Eng. Methodol. 31, 3, Article 44
(apr 2022), 29 pages. https://doi.org/10.1145/3494518
[70] Xin-Li Yang, David Lo, Xin Xia, Zhi-Yuan Wan, and Jian-Ling Sun. 2016. What
security questions do developers ask? a large-scale study of stack overflow posts.
Journal of Computer Science and Technology 31, 5 (2016), 910‚Äì924.
[71] Myung Kuk Yoon, Keunsoo Kim, Sangpil Lee, Won Woo Ro, and Murali An-
navaram. 2016. Virtual Thread: Maximizing Thread-Level Parallelism beyond
GPU Scheduling Limit. In Proceedings of the 43rd International Symposium on
Computer Architecture (Seoul, Republic of Korea) (ISCA ‚Äô16) . IEEE Press, 609‚Äì621.
https://doi.org/10.1109/ISCA.2016.59
[72] Shuying Zhang, Tianyu Zhao, and Tatsuya Kawahara. 2020. Topic-relevant
response generation using optimal transport for an open-domain dialog system.
InProceedings of the 28th International Conference on Computational Linguistics .
4067‚Äì4077.
[73] Tianyi Zhang, Cuiyun Gao, Lei Ma, Michael Lyu, and Miryung Kim. 2019. An Em-
pirical Study of Common Challenges in Developing Deep Learning Applications.
In2019 IEEE 30th International Symposium on Software Reliability Engineering
(ISSRE) . 104‚Äì115. https://doi.org/10.1109/ISSRE.2019.00020
[74] Yuhao Zhang, Yifan Chen, Shing-Chi Cheung, Yingfei Xiong, and Lu Zhang. 2018.
An Empirical Study on TensorFlow Program Bugs. In Proceedings of the 27th ACM
SIGSOFT International Symposium on Software Testing and Analysis (Amsterdam,
Netherlands) (ISSTA 2018) . Association for Computing Machinery, New York, NY,
USA, 129‚Äì140. https://doi.org/10.1145/3213846.3213866
[75] Shanglin Zhou, Mimi Xie, Yufang Jin, Fei Miao, and Caiwen Ding. 2021. An End-
to-end Multi-task Object Detection using Embedded GPU in Autonomous Driving.
In2021 22nd International Symposium on Quality Electronic Design (ISQED) . 122‚Äì
128. https://doi.org/10.1109/ISQED51717.2021.9424308
Received 2023-03-02; accepted 2023-07-27
1456