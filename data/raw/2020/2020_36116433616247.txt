Design byContract for Deep LearningAPIs
Shibbir Ahmed
shibbir@iastate.edu
Iowa StateUniversity
USASayem Mohammad Imtiaz
sayem@iastate.edu
Iowa StateUniversity
USASamantha SyedaKhairunnesa
skhairunnesa@fsmail.bradley.edu
Bradley University
USA
BrenoDantasCruz
bdantasc@iastate.edu
Iowa StateUniversity
USAHridesh Rajan
hridesh@iastate.edu
Iowa StateUniversity
USA
ABSTRACT
DeepLearning(DL)techniquesareincreasinglybeingincorporated
incriticalsoftwaresystemstoday.DLsoftwareisbuggytoo.Recent
workinSEhascharacterizedthesebugs,studiedÔ¨Åxpatterns,and
proposed detection and localization strategies. In this work, we
introduceapreventativemeasure.Weproposedesignbycontract
for DL libraries, DL Contract for short, to document the properties
ofDLlibrariesandprovidedeveloperswithamechanismtoidentify
bugsduringdevelopment.While DLContract buildsonthetradi-
tional design by contract techniques, we need to address unique
challenges. In particular, we need to document properties of the
trainingprocessthatarenotvisibleatthefunctionalinterfaceof
theDLlibraries.Tosolvetheseproblems,wehaveintroducedmech-
anisms that allow developers to specify properties of the model
architecture, data, and training process. We have designed and im-
plemented DLContract forPython-basedDLlibrariesandusedit
to document the properties of Keras, a well-known DL library. We
evaluateDLContract intermsofeÔ¨Äectiveness,runtimeoverhead,
and usability. To evaluate the utility of DL Contract , we have de-
veloped 15 sample contracts speciÔ¨Åcallyfor training problemsand
structuralbugs.Wehaveadoptedfourwell-vettedbenchmarksfrom
priorworksonDLbugdetectionandrepair.FortheeÔ¨Äectiveness,
DLContract correctlydetects259bugsin272real-worldbuggypro-
grams,fromwell-vettedbenchmarks providedinprior workonDL
bug detection and repair. We found that the DL Contract overhead
isfairlyminimalfortheusedbenchmarks.Lastly,toevaluatethe
usability,we conductedasurvey oftwenty participantswhohave
usedDL Contract to Ô¨Ånd and Ô¨Åx bugs. The results reveal that DL
Contract can be very helpful to DL application developers when
debuggingtheircode.
CCSCONCEPTS
‚Ä¢Softwareanditsengineering ‚ÜíSpeciÔ¨Åcationlanguages ;‚Ä¢
Computing methodologies ‚ÜíMachine learning .
ESEC/FSE ‚Äô23, December 3‚Äì9, 2023, San Francisco, CA,USA
¬©2023 Copyright heldby theowner/author(s).
ACM ISBN 979-8-4007-0327-0/23/12.
https://doi.org/10.1145/3611643.3616247KEYWORDS
Deeplearning,API contracts,speciÔ¨Åcation language
ACM Reference Format:
Shibbir Ahmed,Sayem Mohammad Imtiaz, SamanthaSyeda Khairunnesa,
Breno Dantas Cruz, and Hridesh Rajan. 2023. Design by Contract for Deep
Learning APIs. In Proceedings of the 31st ACM Joint European Software
Engineering Conference and Symposium on the Foundations of Software Engi-
neering(ESEC/FSE‚Äô23),December3‚Äì9,2023,SanFrancisco,CA,USA. ACM,
NewYork, NY, USA, 13pages.https://doi.org/10.1145/3611643.3616247
1 INTRODUCTION
Deep learning is a popular tool for solvingcomplex software devel-
opment problems such as NLP and vision, but research has shown
thatdeeplearningmodelsalsohaveuniquebugs[ 33,36,37,66].To
address this, SE researchers have focused on detecting and localiz-
ingthesebugs [ 46,57,62]. In thiswork, we explore analternative
approachtoimprovethereliabilityofdeeplearningsoftware,de-
sign by contract (DbC). Traditional DbC [ 19,41,43,48] provides
supportforwritingpreconditionsandpostconditionsatAPIs.How-
ever, prior work does not provide mechanisms for documenting
properties of the model architecture, data, and training process,
whicharecrucialforapplyingDbCtodeeplearningAPIs.Recent
researchhasproposedtechniquesforinferringtheseproperties,but
DbC aims toprovidespeciÔ¨Åcation mechanisms for programmers.
We propose a DbC methodology for deep learning libraries,
calledDLContract .Itexposesmeta-levelpropertiesoftheDLtrain-
ingprocessandmodelstructureasvariables,called MLvariable ,for
useinwritingcontracts.Unlikegrey-boxcontracts[ 23]thatexpose
partoftheprogram, MLvariable providesahigher-levelabstraction
of the training process and model structure. They are similar to
speciÔ¨Åcation-onlyÔ¨Åelds[ 27] inobject-oriented programs[ 42,49],
but abstract away from the details of the DL model.
We have developed DL Contract for Python and a runtime as-
sertion checking framework for DL Contract . We have applied con-
tracts to key API methods of the Keraslibrary and evaluated them
using four benchmarks for deep learning bug detection from prior
works[52,57,62,65],comprising272 Kerascodes.Ourresultsshow
that theKeraslibrary with contracts can identify 95% of such bugs
duringruntimechecking.Additionally,wehaveevaluatedtheanno-
tation overhead of DL Contract and found it to be zero for users of
DLlibraries.Thismeansthatusersdonotneedtoaddanycontract
annotationstotheircodeinordertobeneÔ¨Åtfromourapproach.We
havealsoadded15contractstothemodelcompilationandtraining
Thiswork islicensedunderaCreativeCommonsAttribution4.0Interna-
tional License.
94
ESEC/FSE ‚Äô23, December3‚Äì9, 2023,San Francisco, CA, USA ShibbirAhmed, Sayem Mohammad Imtiaz, Samantha Syeda Khairunnesa,Breno Dantas Cruz, andHrideshRajan
%XJJ\&RGHZLWKSRRUUHVXOW7UDLQLQJ$FFXUDF\
'/&RQWUDFWDQQRWDWHG.HUDVOLEUDU\

80/$87
$87275$,1(5
<RXUPRGHOVWLOOKDVWUDLQLQJSUREOHPV>
H[SORGH
@DUH VWLOOH[LVW
\RXFDQWU\RWKHUVROXWLRQV8VH
KHBXQLIRUP
DVWKHNHUQ HO
LQLWLDOL]HU8VLQJ
WDQK
DFWLYDWLRQLQHDFKOD\HUV
DFWL YDWLRQ
8VH
%DWFK1RUPDOL]DWLRQ
OD\HUVDIWHUHDFK'HQVHOD\HUVL QWKH
PRGHO VHFRQGV
1HXUD/LQW
/HDUQHU  !$ODVWOD\HUDFWLYDWLRQLVUHTXLUHGWRWUDQVIRU PORJLWV
LQWRSUREDELOLWLHVIRUFODVVLILFDWLRQSUREOHPPLVVLQJVL JPRLG/RVV
VKRXOGEHFRUUHFWO\GHILQHGFRQQHFWHGWROD\HUDFFRUGL QJWRLQSXW
FRQGLWLRQVLHVKDSHDQGW\SHSRVWBDFWLYDWLRQ VHFRQGV%DWFK OD\HU(UURULQ'HOWD:HLJKWVWHUPLQDWLQJWUDLQLQJ 
VHFRQGV
6WDWHRIWKHDUWGHEXJJLQJWRROV
(SRFKVPVVWHS
ORVVDFFXUDF\YDOBORVVYDOB DFFXUDF\
VHFRQGV.HUDVZLWKRXWDQ\GHEXJJLQJWRROV
'HHS/RFDOL]H
&RQWUDFW9LRODWLRQFRPSLOHDFWLYDWLRQBIXQFWLRQIRUPXOWLFOD VVVKRXOGQRWEHUHOX
&RQWUDFW9LRODWLRQFRPSLOHDFWLYDWLRQBIXQFWLRQIRUPXOWLFODV VVKRXOGEHVRIWPD[ORVVVKRXOGEHFDWHJRUL FDOBFURVVHQWURS\
&RQWUDFW9LRODWLRQIRU6HTXHQWLDOILWGDWDVKRXOGEHQRUPDOL]HG WUDLQLQJGDWDVKRXOGQRWEHZLWKLQDQG VHFRQGV%DWFK OD\HU(UURULQ'HOWD:HLJKWVWHUPLQDWLQJWUDLQLQJ
&KDQJHWKHDFWLYDWLRQIXQFWLRQDWOD\HU VHFRQGV 'HHS'LDJQRVLV>&ULWLFDO0LVVLQJ6RIWPD[OD\HUEHIRUHORVV!:DUQLQJ/DVWP RGHOOD\HU
KDVQRQOLQHDUDFWLYDWLRQ! VHFRQGV
Figure1:Buggycode [ 2,3,6,7,9]achieves 9.78%trainingaccuracy. Similarcorrectcode[ 10]achieves‚àº99%trainingaccuracy.
methodsofthe KerasAPIandevaluated257correctprograms,Ô¨Ånd-
ing 18 false positives due to the randomness eÔ¨Äect during training.
Toevaluatethe usabilityofthecontract-enabled Keraslibrary,we
conducted a user study with 20 participants with varying levels of
expertiseinDLapplicationdevelopment.Wefoundthat DLCon-
tractenabledKerasis veryhelpful to developers in debugging DL
software. Also, writing DL Contract and integrating DL Contract
withKerasisaneasierprocessfortheAPIdesigners.Ourevalua-
tion also shows that the runtime overhead of checking contracts is
fairlyminimal.Weobtainedthattheruntimeoverheadincreasesby
around 15% compared to the baseline. DL Contract can be disabled
duringproduction to result inzerooverhead.
Our contributionsare as follows:
‚Ä¢Anovelmethodologyforwritingandcheckingcontractsfor
deeplearninglibrariesbyspecifyingDLAPIswithprecon-
ditions andpostconditions.
‚Ä¢Aframework[ 15]thatisextensibleandgeneralizedtodiÔ¨Äer-
ent classes of DL bugs and maps contract violation as a bug,
symptoms as the constraint to check, and contract violation
messagesas suggestionsto Ô¨Åxbugs.
‚Ä¢ThenotionofspecifyingDL-speciÔ¨Åccontractsbyabstracting
theDLmodelarchitecture,itsdataproperties,andtraining
behavior.
‚Ä¢A collection of 15 contracts that prevents prevalent training
problems andstructuralbugsinDL programs.
‚Ä¢An annotated version of Keraswith the DL Contract as a
virtual environment ( @Keras) [11]. Developers can use this
@Kerasenvironment for debugging without any annotation
overheadandminimal runtimeoverhead( ‚âà15%).2 MOTIVATION
To highlight the diÔ¨Éculty in specifying deep learning APIs and
the need for DL Contract , consider a simple Convolutional Neural
Network (CNN) code shown in Fig. 1. This code is intended for
digit classiÔ¨Åcation when implemented correctly, as outlined in the
Kerasdocumentation [ 10], it achieves 99% training accuracy on
theMNISTdataset.Inthecorrectversion,imagesarenormalized
to the range [0,1] before being processed by a Sequential model
with a speciÔ¨Åc layer architecture. The model is conÔ¨Ågured using
theCompile API and trained using the FitAPI, and the evaluate
API isusedto calculatethe lossandaccuracy.
However, as shown in Fig. 1, the code snippet contains three
bugs (on lines 19, 20, and 22) which result in low accuracy and
high training time. These bugs are speciÔ¨Åc to DL programs [ 62]
andmaynotcausecrashes.Forexample,online19,theincorrect
activation function, ‚Äòrelu‚Äô is used in the last layer of the Dense
API [2,5,6]. Additionally, on line 20, the incorrect loss function of
‚Äòbinary_crossentropy‚Äôisappliedinthe Compile API[2,3,9].Lastly,
on lines 5 and 6, the data is not normalized before being fed into
theFitAPI [6,7].
This example also illustrates another challenge for specifying
DL APIs. All DL APIs work on a shared DL model, where early
APIsconstructthemodelandlaterAPIs,suchas fit,compile,and
evaluate , make use of it. To write pre/postconditions for DL APIs,
havingaccesstoonlytheformalparametersandreturnvaluesof
theAPIsisnotsuÔ¨Écient.Correctusagedependsonthemodelstate
at the point of the API call. DL Contract addresses these challenges
and canhelp preventsuch bugs byprovidingaclearspeciÔ¨Åcation
ofthe intendedbehaviorof deep learningAPIs.
95Designby Contract forDeep Learning APIs ESEC/FSE ‚Äô23, December3‚Äì9, 2023,San Francisco, CA, USA
3 DEEPLEARNINGCONTRACTS
In theDL Contract approach, we abstract the data properties, ex-
pected output, model architecture, and training behavior of a DNN
model and specify the properties of DL APIs connected via a com-
putationgraph.Wegatherandinspectnecessaryconditionsfrom
three sources (details in ¬ß 4.1). We Ô¨Ålter out the obligations from
the DL app developer as preconditions and expectations from DL
softwareinas postconditions .Here,weuseanovelruntimeasser-
tion check in DL computation. In the contract checker modules
Ô¨Årstparsethosecontractsandtranslatethemintotemplates.Those
templates are validated to handle the exception if it occurs. If a
contract is violated, the user receives a contract violation message
Otherwise, the API returns the normal execution output. Thus, our
proposedsolution generalizestootherbugsandmodel categories
inthisway.Itwouldbeeasyforlibrarydeveloperstospecifythe
contracts for other types of bugs following these procedures of DL
Contract.
Next,wepresentthedesignandusageof DLContract ,including
examplesandour approach for abstractingDL relatedproperties.
3.1 WritingDeepLearning Contract
DL Contract uses an annotation-based approach [ 18,28] to add
contractsto DLAPIs, which allowslibrary developersto addcon-
tractswithoutmodifyingcompilersandbuildtools.Thismeansthat
softwareusingDLAPIsdoesnotneedtobemodiÔ¨Åed.DLlibrary
developerscanadd preconditions thatmustbesatisÔ¨Åedbeforethe
API iscalled and postconditions that theAPIguarantees tobe true
uponcompletion.
3.1.1 Syntax. To use contracts in a deep learning library, it is nec-
essary to annotate the API with @contract and@new_contract .
Thisallowslibrarydeveloperstocreateexpressionsforchecking
speciÔ¨Åed contracts. DL Contract can check types such as tensors
andmodelobjects,aswellassimpledatatypeslikestrings,Ô¨Çoats,
numbers, arrays, and booleans. It utilizes logical operators like
AND(,)andOR(|)andallowsforarithmeticandcomparisonexpres-
sions.Additionally, DLContract canbeusedtocheckconstraints
ofvariousmodelpropertiesduringtraining andabstraction.
3.1.2 Illustrative Example. To create a contract, a library devel-
oper annotates a DL API using @contract and@new_contract .
Inside@contract , the developer deÔ¨Ånes types and functions for
checking contracts. Using @new_contract , the developer writes
functions for performing computations necessary for a contract
andforcheckingpreconditionsandpostconditions.Forinstance,
in Example 3.1, a contract is imposed as a precondition on the
Kerastraining function Fitto ensure that data is within a speci-
Ô¨Åedrangebeforetraining.Topreventthistypeofbug,afunction
data_normalization isdeclaredasacontractdeÔ¨Ånitionusingthe
@contract annotation (line 8) using the parameter x. Inside the
@contract annotation, in the data_normalization function (line
2),thedeveloperfurthercomputestogettherangeoftrainingdata,
declared as normalization_interval as aML variable (line 3).
Thedevelopercanspecifytheappropriaterangeofthe MLvariable
withinthe contract checker function. The condition ischecked on
line 4 and if the contract is violated, a suggestion to Ô¨Åx the issue is
raisedonline7.1@new_contract
2defdata_normalization(x):
3normalization_interval = np.max(x) - np.min(x)
4if(normalization_interval >2.0):
5 msg = "Data should be normalized before training,train and
6 test data should be divided by value " + str( np.max(x))
7 raiseContractException(msg)
8@contract(x=‚Äôdata_normalization‚Äô)
9deffit(self, x=None, y=None,...):
Example 3.1:Acontract on FitAPIinside Keraslibrary
WhenabuggyDLprogrammakesuseofthisannotatedAPI, DL
Contractwillthrowthe following error.
ContractViolated: Data should be normalized before training, train and test
data should be divided by value 255.0.
Example 3.2illustratestheuseof DLContract topreventover-
Ô¨Åttingbugs[ 46],inwhichamodelhas hightraining accuracybut
low test accuracy. A contract is speciÔ¨Åed on the validation loss and
traininglosstocheckforincreasingdiÔ¨Äerencesinvalidationloss
anddecreasingdiÔ¨Äerencesintrainingloss[ 57],whichisacommon
causeofoverÔ¨Åtting.Thisexpectationisencodedasapostcondition.
1@new_contract
2defoverfitting(history):
3i=0
4whilei<=(len(history.epoch)-2):
5 epochNo = i + 2
6 diff_loss = history[ 'loss'][i + 1] - history[ 'loss'][i]
7 diff_val_loss = history[ 'val_loss '][i + 1] -
8 history[ 'val_loss '][i]
9 i += 1
10 if(diff_val_loss >0.0):
11 if(diff_loss <=0.0):
12 msg = "After Epoch"+str(epochNo)+",diff_val_loss="
13 +str('%.4f'% diff_val_loss)+" anddiff_loss="
14 +str('%.4f'% diff_loss) + "causes overfitting"
15 raiseContractException(msg)
16@contract(returns=‚Äôoverfitting‚Äô)
17deffit(self, x=None, y=None,...): return self.history
Example 3.2:OverÔ¨Åtting Contracton FitAPI
To prevent overÔ¨Åtting, a contract can be added to the output
oftheFitmethodin Kerasusing@contract andapostcondition
can be checked using the overfitting function speciÔ¨Åed with
returns (line 16). In this function, the contract writer uses the
obtained history object to compute diff_loss anddiff_val_-
loss(line 6-7) and checks if the diÔ¨Äerence between validation
loss of consecutive epochs tends to increase while the diÔ¨Äerence
between training loss continues to decrease. If this condition is not
met, a contract violation message is thrown and when a buggy DL
program usesthis annotated API, DL Contract will throwan error.
ContractViolated: After Epoch: 11, diff_val_loss = 0.34 and diff_loss = -0.12
causes overfitting.
3.2 DL Contract Approach
Next, we present our approach and describe the technical chal-
lengesinDLcontractchecking,suchastheneedforcontext-aware
MLvariable (¬ß3.2.1),assertiontechniques(¬ß 3.2.2),andsupportfor
contracts across multiple APIs in the ML pipeline (¬ß 3.2.3). Also, we
discussourtechnique‚Äôssupportforpost-trainingcontractchecking
(¬ß3.2.4).
3.2.1 AbstractionofDL-specificPropertiestoContracts. Toenforce
DbCtechniquefordeeplearningAPIs,amechanismisneededto
capturemodelabstraction,dataproperties,andtrainingbehavior
beyondjusttheformalparametersandreturnvaluesoftheDLAPIs.
Standardcontractsonlyenforceconstraintsonthevaluesofformal
96ESEC/FSE ‚Äô23, December3‚Äì9, 2023,San Francisco, CA, USA ShibbirAhmed, Sayem Mohammad Imtiaz, Samantha Syeda Khairunnesa,Breno Dantas Cruz, andHrideshRajan
parameters and return values of an API method or attributes of an
API class. Additionally, machine learning APIs are not isolated, but
connected through a computational graph [ 16]. Therefore, specify-
ing contracts on one API with its formal parameters alone is not
suÔ¨Écient inthe DL-speciÔ¨Åc settings.
Fig.2describesascenarioinwhichthedeveloperwantstoadda
contracttothemethod densetoensurethattheactivationfunction
for the last layer is not relu[8]. Additionally, the developer wants
tochecktheappropriatelossfunctionparameterforthe Compile
API Fig.2. The problem with this scenario is that the conventional
DesignbyContract(DbC)techniquecannotspecifythiscontracton
amodel‚ÄôsAPIwithoutcausingfalsealarmsincorrectcodesbecause
itonly allowsfor checking contracts oneachAPI ofamodel.
To solve such problem, we design a way to write DL Contract
using functions that allows to compute subset of meta-information
withMLvariable abstractingmodelarchitecture,dataproperties,
training behavior. Fig. 2shows one way to solve this challenge us-
ingDL Contract . In this solution, activation , andloss_func are
computed in speciÔ¨Åed @new_contract contract_checker func-
tionswhere activation istheparameteroflastlayer DenseAPI
andloss_func istheparameterof CompileAPI.Thisishow DL
Contractmechanismenablesspecifyingandcheckingcontractwith
abstractedmodelpropertieswhich worksonanystageofcomputa-
tiongraph pipeline.
3.2.2 DL Contract Runtime Assertion Technique. A model is more
than what the conÔ¨Åguration script deÔ¨Ånes. Many properties of the
modelonlybecometractableduringtraining.Asaresult,a DLCon-
tractmust enable a runtime assertion technique that allows enforc-
ingcontractsbeyondformalparameters,unliketraditionalcontract
checkers. Furthermore, it must be possible to impose contracts on
diÔ¨Äerentpipelinestagesofthemodeling,i.e.,datapreprocessing,
duringmodelbuilding,andtraining,etc.Tothatend,wepropose
aDL Contract checker with such capabilities by enabling library
developers to annotate APIs. Eventually, DL Contract annotations
beneÔ¨Åtend-userstochecktheirmodel,dataproperties,andtraining
behaviorat diÔ¨Äerentstagesinthe DL pipeline.
OurmethodoutlinedinAlgorithm 1showsthestepsinvolvedin
parsing and checking contracts in a library. It consists of two steps:
registeringnewcontractsdeÔ¨Ånedbythelibrarydeveloperandpars-
ingandvalidatingnewlydeÔ¨Ånedcontractsappliedtothefunctions
deÔ¨Ånedbythelibrarydeveloper.Theframeworkinspectsthelibrary
codebasetoÔ¨Åndcustomuser-deÔ¨ÅnedcontractsdeÔ¨Ånedasfunctions
withthe@new_contract annotation.Theusageof @new_contract
onafunctioninvokesthe register_new_contract method,which
storesareferencetothefunctioninadictionary.Thiswayofan-
notating contracts allows writing contracts using abstracted DL
properties as discussed in section 3.2.1. For instance, if a library
developer writes a contract with any of the properties of /u1D45A/u1D45C/u1D451/u1D452/u1D459
objectandchecksasapreconditionbeforemodelcompilationor
before model training, our technique allows doing that in this way
(moredetailsinExample 3.3)whichisdiÔ¨Äerentthanthetraditional
way of writing contract. The contract_checker method is used
to intercept and validate such contracts applied to user-deÔ¨Åned
functions with the @contract annotation before the function is
executed.Themethodparsestheannotationreference,obtainsaAlgorithm1 DL Contract Checker
1:procedure contract_checker(userFRef,annoteRef)
2:fArgs‚Üê/u1D453/u1D45C/u1D45F/u1D45A/u1D44E/u1D459_/u1D44E/u1D45F/u1D454/u1D462/u1D45A/u1D452/u1D45B/u1D461/u1D460(/u1D462/u1D460/u1D452/u1D45F/u1D439/u1D445/u1D452/u1D453)
3:argContrDict‚Üê/u1D45D/u1D44E/u1D45F/u1D460/u1D452_/u1D450/u1D45C/u1D45B/u1D461/u1D45F/u1D44E/u1D450/u1D461(/u1D44E/u1D45B/u1D45B/u1D45C/u1D461/u1D44E/u1D461/u1D452/u1D445/u1D452/u1D453)
4:for each (fArg,cond)inargContrDict do
5: aArg‚Üê/u1D44E/u1D450/u1D461/u1D462/u1D44E/u1D459_/u1D44E/u1D45F/u1D454/u1D462/u1D45A/u1D452/u1D45B/u1D461/u1D460 (fArg,userFRef )
6: template‚Üê/u1D45D/u1D44E/u1D45F/u1D460/u1D452_/u1D461/u1D452/u1D45A/u1D45D/u1D459/u1D44E/u1D461/u1D452(cond)
7: template./u1D450‚Ñé/u1D452/u1D450/u1D458_/u1D450/u1D45C/u1D45B/u1D461/u1D45F/u1D44E/u1D450/u1D461(aArg)
8:returnCondition‚Üê/u1D45D/u1D44E/u1D45F/u1D460/u1D452_/u1D450/u1D45C/u1D45B/u1D461/u1D45F/u1D44E/u1D450/u1D461(annoteRef)
9:aArgs‚Üê/u1D44E/u1D450/u1D461/u1D462/u1D44E/u1D459_/u1D44E/u1D45F/u1D454/u1D462/u1D45A/u1D452/u1D45B/u1D461/u1D460(userFRef)
10:result‚Üê/u1D462/u1D460/u1D452/u1D45F/u1D439/u1D445/u1D452/u1D453(aArgs)
11:returnTemplate‚Üê/u1D45D/u1D44E/u1D45F/u1D460/u1D452_/u1D461/u1D452/u1D45A/u1D45D/u1D459/u1D44E/u1D461/u1D452(returnCondition)
12:returnTemplate ./u1D450‚Ñé/u1D452/u1D450/u1D458_/u1D450/u1D45C/u1D45B/u1D461/u1D45F/u1D44E/u1D450/u1D461(result)
13:returnresult
14:procedure register_new_contract(funcRef) ‚ä≤@new_contract
15:identiÔ¨Åer‚Üê/u1D454/u1D452/u1D461/u1D439/u1D462/u1D45B/u1D450/u1D441/u1D44E/u1D45A/u1D452(funcRef)
16:newContRegister[identiÔ¨Åer]‚ÜêfuncRef
17:procedure parse_template(cond)
18:iflen(cond)>1then ‚ä≤multiple conditions
19: subclauses‚Üê[ ]
20: forc‚ààconddo
21: subclauses‚Üê/u1D45D/u1D44E/u1D45F/u1D460/u1D452_/u1D461/u1D452/u1D45A/u1D45D/u1D459/u1D44E/u1D461/u1D452(c)
22: returnAnd(subclauses)
23:ifistype(cond)then ‚ä≤if it is cond type
24: returnCheckType(cond)
25:ifcond/u1D716newContRegister then ‚ä≤if it is callable
26: returnCheckCallable(newContRegister[cond])
dictionaryofconditionsappliedtothefunction‚Äôsarguments,and
validates the conditions using the visitor designpattern.
Consideracontract, @contract(loss=‚Äòstr,contract_func‚Äô) .
It validates the loss function and the validation takes place in-
side a user-deÔ¨Åned contract, contract_func . The contract body is
storedinargContrDict as<loss,(str,contract_func) >.Then,
it obtains the value for the argument loss. The method parse_-
template isusedtoobtainavalidationtreefortheconditionsby
composing validation classes (in Algorithm 2). In the example of
losscontract,an Andclassisobtained,witheachconditionasasub-
clause.IftheÔ¨Årstcondition, str,issatisÔ¨Åed,a CheckType validation
class is returned. If the second condition is a user-deÔ¨Åned function,
aCheckCallable validationclassisreturned.Thecomposedvali-
dation tree is returned in a template variable. Each validation class
implementsthemethod check_contract .Tovalidatethetemplate,
check_contract isinvokedontherootvalidationclass,whichis
And. If validation fails for any subclause, Andraises an exception.
Theargumentonwhichacontractisimposedisvalidated.Ifprecon-
ditions are satisÔ¨Åed, the postconditions are validated. The returned
result ofthe userfunction isvalidatedas per written contracts.
3.2.3 Contextualized Inter-API Call Contracts. The next challenge
istoensurethat DLContract canbewritteninvolvingmultipleAPIs
atdiÔ¨ÄerentstagesoftheDLpipeline.Tosolvethisproblem, DLCon-
tractis designed to write multiple functions using @new_contract
annotationsthattakeformalparametersacrossmultipleDLAPIs.
Forexample,whenthenumberofthetargetclassis2(i.e.,binary
classiÔ¨Åcation),theactivationfunctionofthelastlayershouldnot
besoftmax orrelu[3,5,9] (which is a type of contract within
the same DenseAPI) and loss function should be ‚Äòbinary_cross-
entropy‚Äô [ 2,3] (which is an inter-argument contract with diÔ¨Äerent
APIs, i.e.,between last layer and CompileAPI).Althoughthe best
activationfunctionforhiddenlayersisReLu[ 30],ifReLuisused
on the last layer, it will set all the negative output to zero, thus
97Designby Contract forDeep Learning APIs ESEC/FSE ‚Äô23, December3‚Äì9, 2023,San Francisco, CA, USA
 Compile
loss= 'binary_crossentropy'Compile API has loss parameter  
Computation Graph for DL model compilationDL Contract  Annotation using activation , loss functions
Buggy DL Code
Dense API has activation parameter  
Figure 2: DL Contract approachusing activation andlossfunctions involving multiple APIs inDLcomputation graph
Algorithm2 CheckContract
1:classCheckContract
2:procedure abstractcheck_contract(value)
3:endclass
4:classCheckCallable(CheckContract)
5:procedure init(funcRef)
6: callable‚ÜêfuncRef
7:procedure check_contract(value)
8: ifcallable(value)/u1D45F/u1D44E/u1D456/u1D460/u1D452/u1D451 /u1D452/u1D465/u1D450/u1D452/u1D45D/u1D461/u1D456/u1D45C/u1D45B then
9: raise/u1D450/u1D45C/u1D45B/u1D461/u1D45F/u1D44E/u1D450/u1D461/u1D438/u1D465/u1D450/u1D452/u1D45D/u1D461/u1D456/u1D45C/u1D45B ()
10:endclass
11:classAnd(CheckContract)
12:procedure init(subclauses)
13: subclauses‚Üêsubclauses
14:procedure check_contract(value)
15: forsc‚ààsubclauses do
16: ifsc./u1D450‚Ñé/u1D452/u1D450/u1D458_/u1D450/u1D45C/u1D45B/u1D461/u1D45F/u1D44E/u1D450/u1D461(value)/u1D45F/u1D44E/u1D456/u1D460/u1D452/u1D451 /u1D452/u1D465/u1D450/u1D452/u1D45D/u1D461/u1D456/u1D45C/u1D45B then
17: raise/u1D450/u1D45C/u1D45B/u1D461/u1D45F/u1D44E/u1D450/u1D461/u1D438/u1D465/u1D450/u1D452/u1D45D/u1D461/u1D456/u1D45C/u1D45B ()
18:endclass
19:classCheckType(CheckContract)
20:procedure init(type)
21: expected _type‚Üêtype
22:procedure check_contract(value)
23: actual_type‚Üê/u1D454/u1D452/u1D461/u1D434/u1D450/u1D461/u1D462/u1D44E/u1D459/u1D447/u1D466.alt/u1D45D/u1D452(value)
24: ifactual_type‚àâexpected _typethen
25: raise/u1D450/u1D45C/u1D45B/u1D461/u1D45F/u1D44E/u1D450/u1D461/u1D438/u1D465/u1D450/u1D452/u1D45D/u1D461/u1D456/u1D45C/u1D45B ()
26:endclass
leadingtoanaccuracyproblem.Topreventsuchkindsofproblems
in model architecture, library developers can write DL Contract
usingtheactivationandlossfunctionforthebinaryandmulti-class
classiÔ¨Åcationaccordingtotheexperts‚Äôsuggestion[ 2,3].Ourinsight
isthatsuchtypesofcontractscanbeaddedtodeeplearningmodel-
compilation API, i.e., KerasCompile, exposing objects capturing
the entire modelproperties.
1@new_contract
2defcontract_checkerfunc1(model):
3 last_layer_output = int(str((model.layers[len(model.l ayers)
4 - 1]).output_shape).split( ',').pop(-1).strip( ')'))
5 activation_func = str(model.layers[len(model.layers) - 1].6 __getattribute__( 'activation ')).split()[1]
7 if(last_layer_output >= 3):
8 if(activation_func not in 'softmax '):
9 msg1='For multiclass classification activation_func
10 should be softmax '
11 raiseContractException(msg1)
12@new_contract
13defcontract_checkerfunc2(loss):
14if(lossnot in 'categorical_crossentropy '):
15 msg2 = 'loss should be categorical crossentropy '
16 raiseContractException(msg2)
17@contract(self=‚Äômodel, contract_checkerfunc1‚Äô)
18@contract(loss=‚Äôstr, contract_checkerfunc2‚Äô)
19defcompile(self,optimizer=‚Äôrmsprop‚Äô,loss=None,metrics=None,...):
Example 3.3: Last layer activation and loss function contract
onKerasCompile API
Example 3.3shows lastlayeractivationandlossfunction contract
appliedto KerasCompileAPI,whichassertsbefore CompileAPI
execution. Here, contract_checker1 has been annotated with
modelobject type on line 17 and contract_checker2 has been
annotated using lossparameter with string type on line 18. Here,
last_layer_output andactivation_func are computed on line
3andline5from modelobject.Thelossfunctionhasbeenaformal
parameterof CompileAPI,and contract_checkerfunc2 checks
the condition on line 14 and shows a message with suggestions
to Ô¨Åx if a contract violation occurs for both DenseandCompile
APIs. As those speciÔ¨Åed contacts are ANDed one after another
for one contract (last layer activation and loss function), ‚Äòcon-
tract_checkerfunc2‚Äô is only executed if ‚Äòcontract_checkerfunc1‚Äô is
executed. Since ‚Äòcontract_checkerfunc1‚Äô checks whether the num-
ber of classes‚â•3, then ‚Äòcheckerfunc2‚Äô would also know if the
programrunsamulticlassclassiÔ¨Åcation.InExample 3.3,onlines
17‚Äì18,‚Äòcontract_checkerfunc1‚Äôand‚Äòcontract_checkerfunc2‚Äôhave
been enforcedtogether. A caseof that contract violationisshown
below,
ContractViolated: For multiclass classification activation_func should be
softmax, loss should be categorical crossentropy.
98ESEC/FSE ‚Äô23, December3‚Äì9, 2023,San Francisco, CA, USA ShibbirAhmed, Sayem Mohammad Imtiaz, Samantha Syeda Khairunnesa,Breno Dantas Cruz, andHrideshRajan
3.2.4 Post-training Contracts. The challenge of capturing DNN
trainingbehavioratdiÔ¨ÄerentstagesoftheDLpipelinecanbead-
dressed with our proposed DL Contract . Library developers can
specifydesiredtrainingbehaviorfortheirDLsoftwarebyadding
training-relatedcontractsonpropertiessuchas,gradientsrate,gra-
dientspercentageetc.Trainingbehavior-relatedpropertiesindicate
the expected output from the DL model, so this is a postcondition.
Therootcausebehindatrainingproblemcouldbeclientobligation
in hidden layers APIs such as activation function, which is a pa-
rameter of DenseAPI (this is a precondition) We might encounter
suchtypesofpreconditionsandpostconditionsinDL-speciÔ¨Åcset-
tings, and contracts can be speciÔ¨Åed using @new_contract and
@contract annotations in our proposed approach. To handle such
cases,DLContract advocatesspecifyingcontractsaspostconditions
onDLtrainingAPIs,e.g., KerasFitAPI,whichprovidesdetailed
training history. Based on the supplied contract checking function
in@new_contract ,wecomputerelevanttrainingpropertiesfrom
thehistoryobjectsuchas validationaccuracy ,lossvalue ,gradient
rateetc. Algorithm 1(lines 8‚Äì13) describes how we check and vali-
datepostconditionsinourframework.Example 3.2demonstrates
this type ofpostconditioncontract.
4 EVALUATION
In this section, we aim to answer the following research questions:
‚Ä¢RQ1(EÔ¨Äectiveness) :HoweÔ¨Äectiveis DLContract inreal
world programs?
‚Ä¢RQ2 (Applicability) : IsDL Contract enabledKerasappli-
cabletoÔ¨Åndperformance(i.e.,lowaccuracy,hightraining
time) bugs?
‚Ä¢RQ3(EÔ¨Éciency) :HoweÔ¨Écientis DLContract fordetecting
DL performance bugsinterms ofprecision andrecall?
‚Ä¢RQ4 (Overhead) :Whatistheoverhead ofthe DL Contract
comparedto relatedworks interms ofruntime?
‚Ä¢RQ5 (Usability) : How useful is the DL Contract enabled
KerasindevelopingDL Apps?
First, in order to evaluate our approach, we collect contracts
by following the procedure described in ¬ß 4.1. We implemented DL
Contract(in ¬ß4.2)using ourproposed approach(in ¬ß 3.2).Thenwe
conductedexperimentsusingthesetups(in¬ß 4.3).Finally,wereport
results andanalysis(in¬ß 4.4).
4.1 DeepLearning ContractsCollection
In this section, we describe the process of contract collection used
intheevaluation.WehaveidentiÔ¨Åedcontractsrelatedtothemodel,
data,andtrainingproperties.Thesecontractspreventstructureand
training bugs, which lead to performance issues (i.e., low accuracy,
hightraining time).DLlibrarieslike Kerasdoesnot provideerror
messagesforsuchtypesofbugsyet.Fig. 3showshowwecollected
theconditionsof DLContract . In1,weabstractthedataproperties,
expectedoutput,modelarchitecture,trainingbehaviorofaDNN
model. In 2, we gather and inspect necessary conditions from
three sources. We used the oÔ¨Écial Keraslibrary documentation [ 4].
In particular, we followed the selection criterion from DL bugs
frompriorworks[ 34,36,37]whilefocusingontheAPIsusedfor
model compilation and training. Again, we collected a list of state-
of-the-art research articles and their benchmarks of buggy andTable 1: Collected contracts targeting DNN structural and
logicalbugs,improperdata,and training problems
Classof bugs DLContractData bugsDatanormalization problem Precondition: normalization_interval ‚â§2,
Postcondition: TrueStructuraland logic bugsIncorrect activation and loss
function: regressionPrecondition: activation=‚Äòlinear |tanh‚Äô, loss_func=‚Äòmse‚Äô,
Postcondition: True
Incorrect activation and loss
function: binary classiÔ¨ÅcationPrecondition: activation=‚Äòsigmoid‚Äô, loss_func=‚Äòbinary_crossentropy‚Äô,
Postcondition: True
Incorrect activation and loss
function: multiclass classiÔ¨Åca-
tionPrecondition: activation=‚Äòsoftmax‚Äô,
loss_func=‚Äòcategorical_crossentropy‚Äô,
Postcondition: True
Incorrect activation and loss
function:multilabelmulticlass
classiÔ¨ÅcationPrecondition: activation=‚Äòsigmoid‚Äô, loss_func=‚Äòbinary_crossentropy‚Äô,
Postcondition: True
Incorrect activation in hidden
layersPrecondition: activation !=linear,
Postcondition: True
Incorrect hyperparameter Precondition: learn_rate >0.0000007, <0.01,Postcondition: TrueTrainingproblemOverÔ¨Åtting Precondition: True, Postcondition: diÔ¨Ä_val_loss <0,diÔ¨Ä_loss‚â§0
High validationaccuracy Precondition: True,
Postcondition: val_acc_threshold <0.95,diÔ¨Ä_val_acc_train_acc <0.05
High dropoutrate Precondition: dropout_rate >0.5
Dying relu Precondition: activation!=‚Äòtanh |exponential|relu|sigmoid‚Äô
Postcondition: zero_gradients_percentage ‚â§/u1D706
Vanishing gradient Precondition: activation!=‚Äòtanh |exponential|relu|sigmoid‚Äô
Postcondition: gradients_rate >/u1D6FD1, norm_kernel >/u1D701
Explodinggradient Precondition: activation!=‚Äòtanh |exponential|relu|sigmoid‚Äô
Postcondition: gradients_rate_EG </u1D6FD2, gradient_value!=nan
Oscillatingloss Precondition: True,
Postcondition: accuracy_Ô¨Çuctuation_rate ‚â§/u1D702, val_acc_diÔ¨Ä >=/u1D6FF
Slow convergence Precondition: True, Postcondition: acc_diÔ¨Ä >=/u1D6FF
Expected Output
  Model Architecture 
Gather & Inspect2API Documentation
Research articles
Collected benchmark
of buggy and correct
DL programs 
Training Behavior
    Variables
    Conditions
Abstracted
Precondition
Obligations from   
DL app DeveloperExpectation from  
DL Software3
4
Postcondition1Data Properties
DL Contract  
Figure 3:Methodologyto collect deeplearning contracts
correctDLprograms[ 34,36,37].Theselectioncriterionforthese
articles is that if the work in question solves DL performance bugs
and renders the conditions that lead to these bugs. We Ô¨Ålter out
the obligations from DL app developer as preconditions (in3) and
expectationfromDLsoftwareas postconditions (in4).Thisprocess
resulted in the collection of 15 contracts. A detailed table( Table 1)
with collected contracts with corresponding bugs are shared in the
supplementary material[ 12].
4.2 Implementation
To implement DL Contract , we extended the open-source package
PyContracts [32].PyContracts allows developers to declare con-
straintsonmethodparametersandreturnvalues.Wehaveextended
PyContracts to support tensor, model types, as existing DL APIs
require additional preconditions and postconditions [ 39]. We have
addressedallthe technical challenges describedin¬ß 3.2.
4.3 ExperimentalSetup
To evaluate DL Contract onKeras, we modify the library by im-
portingtheextended PyContracts packageinlibrarycodes.Wealso
decorate respective KerasAPIs with relevant implemented con-
tracts that prevent performance bugs (in ¬ß 4.1). We have conducted
all the experiments on a machine with a 2 GHz Quad-Core Intel
Corei7and32GB1867MHzDDR3RAMrunningthemacOS11.14.
99Designby Contract forDeep Learning APIs ESEC/FSE ‚Äô23, December3‚Äì9, 2023,San Francisco, CA, USA
Table 2:EÔ¨Äectiveness of DL Contract inreal world programs targeting diÔ¨Äerentclass ofbugsusingcollected benchmarks
DeepLocalize UMLAUT AUTOTRAINER NeuraLintDL Contracts targetingclass of bugsSO GHCIF-10 FMNIST Blob Circle MNIST CIF-10 SOGH#Contract
Violation
ImproperData Data normalization problem 5 2 1 1 - - - -11 11
Incorrectactivation & loss function 17 5 1 1 - - - -65 35
Incorrectactivation inhidden layers 3 1 1 1 - - - --- 6 Structural bugs
Incorrectlearningrate 1 1 1 1 - - - --- 4
OverÔ¨Åtting 1 - - - - - - --- 1
Highvalidationaccuracy 2 1 1 1 - - - --- 5
Highdropout rate 1 1 1 1 - - - -1- 5
Dying relu 1 - - -4 9 23 36-- 73
Vanishing gradient - - - -16 36 34 35-- 121
Exploding gradient - - - -11 18 21 20-- 70
Oscillating loss 1 - - -1 3 1 --- 6Trainingproblem
Slow convergence 5 2 - -28 41 19 42-- 137
* Numbersrepresented totalcontract violations in realworldbuggy programsfrom DeepLocalize ,UMLAUT ,AUTOTRAINER ,NeuraLint benchmarks;SO, GH, CIF-10 indicates
benchmarkfrom StackOverÔ¨Çow , GitHub, CIFAR-10respectively, ‚Äú-‚Äùindicates contractsaresatisÔ¨Åed and did not trigger a violation in buggy programs.
Table 3:Applicabilityof DL Contract comparing against KerasCallbacks, Deeplocalize[ 62]andDL Contract (full table[ 14])
DeepLocalizeBuggyCode Correct Code
Benchmark Original TOnNaN ES(‚Äôloss‚Äô) ES(‚Äôaccuracy‚Äô) Union(TOnNaN,ES) DeepLocalize DLContract Original DLContract RT
Source # RT RTBug# RTBug# RTBug# RT Bug # RTBug# RTBug# RT RTOverhead
StackOverÔ¨Çow 30 42.20 30.15 224.92 1924.76 2318.53 27 447.05 276.41 29 34.60 37.93 0.22
GitHub 11 352.90 439.88 0299.18 6269.70 7160.77 7 2772.77 79.23 10 345.04 27.37 0.23
* Total detected bugs in buggy and correct codes (#), KerasdebuggingTerminateOnNan (TOnNan),EarlyStopping(monitor=‚Äôloss‚Äô) (ES(loss),EarlyStopping(monitor=‚Äôaccuracy‚Äô
(ES(accuracy))
Table 4:Applicabilityof DL Contract ,Runtimecomparison between UMLAUT callback [ 57]andDL Contract
BenchmarkBuggy Code Correct Code
Original UMLAUT DL Contract Original UMLAUT DL Contract UMLAUT DL Contract
Runtime Bug Runtime Bug Runtime Runtime Runtime Runtime RuntimeOverhead RuntimeOverhead
A1 (CIFAR-10) 1318.99 Y 8.85 Y 28.52 1376.04 1455.99 1353.81 1.06 0.02
A2 (CIFAR-10) 1483.26 Y 8.93 Y 24.80 1459.21 1384.75 1478.52 0.95 0.01
A3 (CIFAR-10) 1455.93 Y 140.98 Y 23.56 1483.29 1251.69 1497.94 0.84 0.01
B1 CIFAR-10 1493.12 Y 152.57 Y 16.28 1420.40 1049.76 1438.59 0.74 0.01
B2 (CIFAR-10) 1319.18 Y 8.85 Y 26.58 1448.27 792.97 1440.55 0.55 0.01
B3 (CIFAR-10) 1692.83 Y 664.60 Y 669.83 1463.87 795.15 1499.39 0.54 0.02
A1 (F-MNIST) 17.09 Y 7.02 Y 23.25 16.84 15.55 22.76 0.92 0.35
A2 (F-MNIST) 17.04 Y 9.61 Y 18.62 16.36 15.59 24.57 0.95 0.50
A3 (F-MNIST) 15.69 Y 9.61 Y 18.30 16.36 14.34 23.52 0.88 0.44
B1 (F-MNIST) 17.90 Y 9.87 Y 21.06 15.93 14.96 22.92 0.94 0.44
B2 (F-MNIST) 15.96 Y 7.16 Y 18.94 16.96 14.48 23.93 0.85 0.41
B3 (F-MNIST) 17.62 Y 12.31 Y 31.85 15.39 14.85 24.06 0.96 0.56
Benchmark selection: To answer the RQs, we compare and
contrastDL Contract against four recently-published DL perfor-
mance bug localization benchmarks [ 52,57,62,65]. TheDeepLo-
calize‚Äôs benchmark proposed by Wardat et al.[62] consists of 41
executable Kerascodes with buggy and correct versions of DL pro-
grams from Stack OverÔ¨Çow (30) and GitHub (11). For the UMLAUT
benchmark[ 57],wefollowedtheirprocedure.AUTOTRAINER[ 65]
reportedtheirtool‚Äôsresultson495DLprogramswhere262have
training problems Here, we have utilized 4 out of 6 datasets which
are comprised of sequential models. NeuraLint [ 52] utilized a total
of63buggyprogramsofcrashandperformancebugs.Wehaveused
16buggyprogramsfromthebenchmarkwhichdoesnotyieldcrash
bugs. We have considered all 4 of these benchmarks as ‚Äúunseen‚Äù
because wehavenot seentheir buggyandcorrect programsbefore
writing andimplementingcontracts.
Metrics: We recorded the total execution time utilization for all
techniques when analyzing buggy and correct programs from the
benchmarksandcomputedoverhead.Also,werecordedhowmany
bugsweredetectedbyeachapproach.ForcomputingtheeÔ¨ÉciencyofDL Contract , we utilize performance metrics as precision, recall
following prior work [ 46,65].
We consider the benchmarks as ground truth for buggy and
correct programs. Here, a false positive indicates that a bug was
detectedinthecorrectprogram.Truepositiverepresentsifabugis
detected in a buggy program. A false negative indicates that there
is no bug detected in a buggy program. Lastly, if there is no bug
detected in acorrectprogram, we consider that asatrue negative.
We collectedthereal-worldtimeelapsedbetweentheprogram
entryandprogramexitusingthepythontimemodule.Wecollected
this information for both correct and buggy programs Ô¨Åve times to
reduce randomness, following [ 61,65]. To isolate the other process
and void interference in this experiment, we executed only one
programunderanalysisinastandaloneenvironmentinsidetheIDE.
WestartrecordingthetimefromthebeginningofaDLprogram
untiltheÔ¨Årstcontractviolationhasbeenthrown,andtherestofthe
execution is halted in the buggy program. For the correct program
andifthereisnocontractviolation,weobtainedtheelapsedtime
until the complete executionof the program.
100ESEC/FSE ‚Äô23, December3‚Äì9, 2023,San Francisco, CA, USA ShibbirAhmed, Sayem Mohammad Imtiaz, Samantha Syeda Khairunnesa,Breno Dantas Cruz, andHrideshRajan
4.4 Results andAnalysis
4.4.1 RQ1 (EÔ¨Äectiveness). To demonstrate the eÔ¨Äectiveness of DL
Contract in real-worldprograms, we have utilized 4benchmarks
of DL performance bugs.Table 2shows the results of DL Contract
targetingdiÔ¨Äerentclassofbugs. We have developed a totalof15
contractsand annotatedonmodelcompilationandtraining Keras
APIsusing DLContract approachtargetingdiÔ¨Äerentclassesofbugs
relatedtoimproperdata, structuralbugs, and trainingproblems. In
particular,eachrowrepresentsthenumberofcontractviolations
in buggy programswhere DL Contract successfullydetectedbugs
and terminated the program execution. We observe that in the last
‚ÄòContract Violation‚Äô column, those 15 contracts trigger a total of
474 contract violation messages in 272 buggy programs. In Table 2,
‚Äú-‚Äù indicates contracts were used but did not trigger a violation for
that class of bugs. For example, AUTOTRAINER mainly focuseson
trainingproblems,whichiswhythereisnocontractviolationin-
volving structural and improper data-related bugs. Those contracts
(postcondition)violationshavebeentriggeredby DLContract using
abstracted trainingproperties. DeepLocalize ,UMLAUT ,NeuraLint
benchmarks consist of structural and data bugs, that precondition
violationtriggersusing MLvariable relatedtomodelabstraction.
DLContract didnotdetectbugsin13outof272programs.Wehave
investigated these undetected bugs and discussed in ¬ß 4.4.2. We
also evaluated that the same 15 contracts were used in 257 correct
programs in benchmarks. We found 18 contract violations as false
positives,mainlyduetorandomnessfactor[ 55,67]duringtraining.
In summary,DL Contract is eÔ¨Écientin real-world DL programs.
4.4.2 RQ2(Applicability). Table3,4,5,and6showtheapplicability
ofDL Contract on real-world benchmarks comprising of perfor-
mance bugs in DL software. Each table highlights and summarizes
the results of Buggy and Correct programs.
Table3shows the summary of the results [ 14] of deploying
theDeepLocalize benchmark.Pleaserefertosupplementarymate-
rial[15]formoredetails.Table 3showsthat DLContract candetect
39 out of 41 buggy programs with precise contract violation
messages.Outoftheseresults,29arefrom StackOverÔ¨Çow and9out
fromGitHub.Also,whencomparedwith KerasandDeepLocalize
callbacks. Kerasdebugging techniques TerminateOnNan ,EarlyStop-
ping(monitor=‚Äôloss‚Äô) ,EarlyStopping(monitor=‚Äôaccuracy‚Äô) andDeepLo-
calizecan detect 2, 24, 28, 32, and 34 respectively [ 62]. Again, 2
out of 41 were not detected from DeepLocalize [ 62] benchmark.
SO52800582 and GH[2] were missed because generalized contracts
cannot be applied on weight initialization and optimizer. Finally,
regardingbugdetectionspeed, DLContract is200timesfasterthan
DeepLocalize and11 times fasterthan Kerascallbacks.
Table4shows that DL Contract applies to all 12 buggy pro-
gramsfrom the UMLAUT benchmark. In terms of computation
overhead, we observed DL Contract has lower runtime than UM-
LAUT(in ¬ß4.4.4). Lastly, we have manually veriÔ¨Åed the contract
breaches reported by DL Contract and found no false alarms for
buggy programs.
Table5showsthat DLContract hasdetected 195bugsin203
buggyprograms intheAUTOTRAINERbenchmark.While AUTO-
TRAINER reportsthesymptomsof5trainingproblems, DLContract
detects bugs as postcondition violations.We observedthat both ap-
proaches detect the Slow Change in accuracy (SC) more often thantheotherfoursymptoms.8outof203buggyprogramsinAUTO-
TRAINER[ 65]benchmarkwerenotdetectedduetotherandomness
in DNN training. In terms of runtime, DL Contract is slightly faster
thanAUTOTRAINER .Inparticular, DLContract takesonaverage
241.19seconds,while AUTOTRAINER 248.43seconds.Lastly, outof
188correctprograms, DLContract misdetected3programs .
Furtherinvestigationrevealedthatthosemisdetectionsweredue
to data normalization issues,unsupportedby AUTOTRAINER .
Table6shows how DL Contract performs on 16 bugscompared
totheNeuraLint tool.DLContract detected13outof16bugs in
theNeuraLint benchmark.3outof16fromthe NeuraLint bench-
mark [52] were missed because we investigated that we had no
layer properties related contracts written. NeuraLint detects 14
outof16bugsbut DLContract requireslesstimethan NeuraLint .
Inparticular DLContract onaveragerequired5.10secondswhile
NeuraLint9.80seconds.ThesebuggyprogramsusecommonAPI
methods such as Compile andFit, which were annotated with 15
DLContracts.These272buggyprogramshavecommonrootcauses
and symptoms. For instance, AUTOTRAINER [ 65] benchmark con-
sists of 203 buggy programs, with 5 diÔ¨Äerent training problems. By
writing 5 contracts on the Ô¨Åt method targeting those problems, DL
Contractdetects195outof203bugs. Insummary,DLContractis
applicable to detect performance bugs in real-worldbuggy programs
withgood accuracy.
4.4.3 RQ3 (EÔ¨Äiciency). We have measured the eÔ¨Éciency of DL
Contract using 4 benchmarks DeepLocalize [ 62], UMLAUT [ 57],
AUTOTRAINER [ 65], NeuraLint [ 52] (in Table 7). We have eval-
uated257correct(clean)real-worldprogramsandfound18false
positives. We have found 10 FPs in DeepLocalize , 0 inUMLAUT ,
3 inAUTOTRAINER , and 5 in NeuraLint benchmark. In terms of
eÔ¨Éciency,ourevaluationresultsshowthat DLContract hassimilar
accuracy to UMLAUT (12 TPs and no FPs) but has lower time con-
sumption (in Fig. 4). Regarding the AUTOTRAINER benchmark, DL
Contractcouldnotdetectbugsduetotheaccuracythreshold[ 65]
(0.6) due to randomness factor during training. Regarding the Neu-
raLintbenchmark,weobserved3FN.As DLContract doesnothave
contracts on layer properties yet. Compared to other tools using
DeepLocalize benchmark,wefound DeepLocalize ,AUTOTRAINER ,
UMLAUT ,NeuraLint ,DeepDiagnosis [61] resultedin 19,14,14,35
TPand22,27,23,6FNrespectively[ 13].DeepDiagnosis reported
70 FP and 67 FN in correct codes from AUTOTRAINER benchmark.
In summary, DL Contract eÔ¨Éciently detects performance bugs in
real-world buggyprograms.
SuperiorityofDLContract: PriorworkspeciÔ¨ÅcallyDeepLocal-
ize [62], UMLAUT[ 57], AUTOTRAINER [ 65],DeepDiagnosis [61]
and NeuraLint [ 52] are not comprehensive enough to detect dif-
ferentclassesofstructuralandtrainingbugs.Furthermore,these
approaches depend on speciÔ¨Åc implementations such as model for-
mat (.h5), semantic change in model architecture, and rely upon
additional debugging or veriÔ¨Åcation facilities, e.g., Kerascallbacks
(DeepLocalize ,UMLAUT ,AUTOTRAINER ),andGroovemodelchecker
(NeuraLint ). Also,DeepLocalize ,UMLAUT ,NeuraLint didnot com-
puteFPandFN. AUTOTRAINER computedFP,FNonlywith AU-
TOTRAINER benchmark. All 4 baseline techniques did not com-
pareagainstanyotherbenchmarksexcepttheirownbenchmarks.
DeepLocalize [55]invokescallbacksaftereachepochandcomputes
101Designby Contract forDeep Learning APIs ESEC/FSE ‚Äô23, December3‚Äì9, 2023,San Francisco, CA, USA
Table 5:Applicabilityof DL Contract ,Runtime(RT) comparison with AUTOTRAINER [ 65](AT) and DL Contract (DLC)
Buggy Correct
Benchmark
#AT DLC
#Original AT DLCOverhead Overhead
DatasetDetected Symptoms# Postcondition Violation# AT DLC
VGEGDRSCOL RTVGEGDRSCOLRT RTSym # RTViol # RT Runtime Runtime
Blob 481210 829 413.83 65430 111.95 39 8.62 0 9.22 011.79 0.070 0.368
Circle 711010 943 716.50 10 8941 311.54 36 16.06 012.28 216.27 0.235 0.013
CIFAR-10 46 58328 21302.06 5163743 0487.43 35 1186.50 01898.54 01528.16 0.600 0.288
MNIST 38 83421 8688.02 8132319 1423.55 78 466.22 0535.90 2535.51 0.149 0.149
Total/Avg 203 353124121 21505.10 294273133 5233.62 188 419.35 0613.99 4522.93 0.464 0.247
* Count (#), Vanishing Gradient(VG),ExplodeGradient(EG), DyingRelu(DR), SlowChange in Accuracy (SC), OscillatingLoss (OL),Symptom (Sym), Contract Violation(Viol)
Table 6:Applicabilityof DL Contract ,Runtimeoverheadcomparison with NeuraLint[ 52]andDL Contract
BenchmarkBuggy Code CorrectCode
Original NeuraLint DLContract Original NeuraLint DLContract RuntimeOverhead RuntimeOverhead
Runtime Bug Runtime Bug Runtime Runtime Runtime Runtime NeuraLint DLContract
50555434 2.73 Y 18.72 Y 4.77 2.66 6.29 4.78 1.37 0.80
34311586 3.17 Y 9.62 Y 4.81 3.09 3.18 5.12 0.03 0.66
50079585_1 2.88 Y 18.02 Y 5.11 2.75 6.52 4.92 1.37 0.79
51749207 2.80 Y 17.89 Y 4.87 2.68 5.89 4.84 1.20 0.81
58844149 3.03 Y 8.46 Y 5.06 2.89 6.28 5.01 1.17 0.73
33969059 5.20 Y 5.20 Y 6.53 2.62 2.64 4.63 0.01 0.77
44322611 2.93 Y 8.80 N 4.94 2.62 2.69 4.62 0.02 0.76
55776436 3.11 Y 10.78 Y 5.27 3.04 3.06 5.15 0.01 0.69
60566498 2.87 Y 16.57 Y 4.74 2.74 7.38 4.86 1.69 0.77
GH1 2.90 Y 5.13 Y 5.04 2.96 7.71 4.97 1.60 0.68
GH2 2.83 Y 5.52 N 4.91 2.80 6.94 4.86 1.48 0.74
GH3 3.05 Y 5.51 Y 4.96 3.00 6.70 4.89 1.23 0.63
GH4 4.43 Y 8.50 N 6.44 4.04 137.13 5.99 32.94 0.48
GH5 2.78 Y 7.42 Y 4.88 2.78 6.38 4.82 1.30 0.74
GH6 2.74 N 5.20 Y 4.69 2.68 6.14 4.66 1.29 0.74
GH7 2.72 N 5.39 Y 4.59 2.71 5.97 4.61 1.20 0.70
Total/Average 3.14 14 9.80 13 5.10 2.88 13.81 4.92 2.99 0.72
Table7:DLContract eÔ¨ÉciencyondiÔ¨Äerentbuggyandcorrect
benchmarks
DLContract
Benchmark FPTPFNTNPrecision Recall
DeepLocalize 1039231 0.80 0.95
UMLAUT 012012 1.00 1.00
AUTOTRAINER 3195 8185 0.98 0.96
NeuraLint 513311 0.72 0.81
metrics to detect numeric bugs which take lots of time. AUTO-
TRAINER [58] requires the model in a speciÔ¨Åc format and needs
toÔ¨Ånishthetrainingtodetectbugsandthenprovidesolutionsas
Ô¨Åxes.InthecaseofUMLAUT[50],withoutasemanticchangeof
model, the tool will report a false alarm. NeuraLint [48] requires
graphcomputationfromthemodelandperformsstaticchecking
withsomespeciÔ¨Åedruleswhichyieldalonger runtime.
4.4.4 RQ4(Overhead). Wehavecomputedtheruntimeoverhead
ofDL Contract usingUMLAUT ,DeepLocalize ,NeuraLint , andAU-
TOTRAINER benchmark.Figure 4showstheruntimeoverheadof
DL Contract .DL Contract (DLC) runtime overhead is lower than
the one of all approaches. In particular, DL Contract is 4.31, 3.69,
1.85, and 4.15 times more eÔ¨Écient in terms of runtime overhead
thanDeepLocalize ,UMLAUT ,AUTOTRAINER , andNeuraLint . The
runtimeoverheadofDLContractisminimalbecausethetechnique
only checks model structure-related preconditions before model
compilationAPIandtraining-relatedpostconditionsbeforetrain-
ing. Unlike techniques DeepLocalize ,UMLAUT ,AUTOTRAINER ,
that rely on Kerascallbacks, DL Contract does not invoke model
DLoc DLC UM DLC AT NL DLC DLC
Deeplocalize (DLoc) 
BenchmarkUMLAUT (UM) 
BenchmarkAUTOTRAINER (AT) 
BenchmarkNeuraLint (NL) 
Benchmark00.51.01.52.02.53.03.5Runtime OverheadFigure 4:Comparisonofruntime overhead
compilation or training APIs multiple times to monitor metrics pe-
riodicallyduring orafter training.SpeciÔ¨Åcally, NeuraLint requires
graph computation from model and performs static checking with
somespeciÔ¨Åed rules,yieldinglonger runtime. Also, We measured
that the runtime overhead increases by around 15% compared to
the baseline Keras.In summary, DL Contract incurs less runtime
overheadcompared to existingdeep learning debuggingtools.
4.4.5 RQ5 (Usability). We have evaluated the usability of DL Con-
tractannotated Kerasin terms of its usefulness to Ô¨Ånd and Ô¨Åx bugs
while developing DL programs. Also, we evaluate separately the
eÔ¨Äorts of API designers to write and integrate DL Contract . To that
end,weperformauserstudyfollowingIRBguidelinesandcollected
feedbackonusing DL Contract annotated Keras.
102ESEC/FSE ‚Äô23, December3‚Äì9, 2023,San Francisco, CA, USA ShibbirAhmed, Sayem Mohammad Imtiaz, Samantha Syeda Khairunnesa,Breno Dantas Cruz, andHrideshRajan
RQ5.1 (Usefulness) : How useful is the DL Contract enabled
KerasindevelopingDL Apps?
RQ5.2(Easiness) :Howeasyistowrite DLContract andinte-
grateitwithDL library APIs?
Participants: Afterfollowingsimilarprocedure[ 24,57]from
priorworkwerecruited20participantsfromuniversitymailinglists
forourstudy(17Ph.D.,2MSstudents,andaPost-doc).Participants
were asked to self classify their level of expertise from 1 - beginner
to5-expertandweobtainedtheirexpertiselevel:programming
(/u1D707=3.3,/u1D70E=1.0), debugging ( /u1D707=2.9,/u1D70E=1.4), using existing
neural networks ( /u1D707=2.9,/u1D70E=1.1), and developing new DNNs ( /u1D707=
2.5,/u1D70E=1.2), and developing other ML algorithms ( /u1D707=2.7,/u1D70E=1.3).
So, the average/mean ( /u1D707) of the expertise levels is more than 2.5 in
allofthe 20 selectedparticipants.
StudyDesign,ProcedureandTasks: Participantscompleted
anhour-longonlinestudyontheirmachines.Eachparticipantcom-
pletedtwosessionswithcorrespondingtasks.Aftereachsession,
participantscompletedsurveyquestionsonlineviaQualtrics.For
RQ5, in session 1, we provided the necessary environment to ex-
ecute buggy programs in regular Keras(baseline condition) and
DLContract enabledKeras.Weprovided3buggyversionsofran-
domlychosenreal-worldprogramswith3diÔ¨Äerentperformance
bugs related to model architecture, data properties, and training
behavior.Thebuggyprogramshavelowaccuracyandhightrain-
ing time issues. We asked the participants to execute the buggy
programs using both regular KerasandDL Contract enabledKeras.
Then,weaskedparticipantstodetectandÔ¨Åxthebuggyprograms
by using the outputs from both regular Kerasand DL Contract-
enabledKeras. Finally, we asked participants the survey questions
regardingtheirexperienceusing DLContract .ForRQ5,insession2,
weÔ¨Årstprovidetutorialtoparticipantsonhowtowritecontracts
onKerasAPI. Then, we asked them to write 3 similar contracts
with instructions. After completing the sessions, participants Ô¨Ålled
up a survey indicating their experience while using DL Contract
enabledKerasto detect and Ô¨Åx bugs as a DL application developer.
Inthatsurvey,participantsalsosharedtheirexperienceaboutthe
writingprocessof DLContract asalibrarydeveloper.Thedetails
of the survey questions for session 1 and session 2 are provided in
the supplementary material[ 15].
Results and Discussion: RQ5.1 (Usefulness): For all 3 buggy
programs in session 1, none of the participants was able to Ô¨Ånd
any of the bugs in the baseline condition (regular Keras). That is
becauseKerasdoes not inform users about such types of perfor-
mance bugs. However, participants were able to detect and Ô¨Åx the
bugsbyfollowing DLContract enabledKeras‚Äôscontractviolation
messages.Furthermore,surveyresponsesindicatethat DLContract
enabledKerashelpsparticipantstodetectandÔ¨ÅxbugseÔ¨Éciently.
In particular, on a 5-point Likert scale questions (1 = Not helpful to
5 = Very Helpful), participants rated their experience on questions.
Participants indicated that, DL Contract enabledKeraswas very
helpfulto65%( /u1D707=4.55,/u1D70E=0.67)indetectingbugsindeeplearn-
ing programs that yield unexpected performance (low accuracy,
high training time). 25% rated helpful (rating 4), and 10% of par-
ticipants rated reasonablyhelpful (rating 3). Therefore, 90% of the
participantsrespondedpositively(rating >3)regardingthiscriteria.
Likewise,95%ofparticipantsratedpositively(rating >3)aboutthe
message from DL Contract Ô¨Åxing those bugs ( /u1D707=4.75,/u1D70E=0.54).
Q1: Rate how DL Contract enabled Keras 
helped you to detect bugs in deep learning 
programs that yield unexpected performance 
(low accuracy, high training time)
Q2: Rate how well do the 
messages from DL Contract 
enabled Keras helped you to 
fix those bugs.
Q3: Rate how useful would 
DL Contract enabled Keras 
be to help you develop DL 
applications.Q4: If you are involved in doing a 
class or research project that 
requires DNNs, rate how useful 
would DL Contract enabled Keras 
be for you.Figure 5: Survey results with participants ratings on how
usefulis DL Contract enabled Kerasindeveloping DLApps
Again,90%oftheparticipantsrated positively(rating >3) speciÔ¨Å-
cally, 55% of the participants indicates that it would be very useful
todevelopDLapplications( /u1D707=4.45,/u1D70E=0.67).Ifparticipantsare
involved in doing a class orresearchproject that requires DNNs,
80% rated positively especially, 55% of the participants rated DL
ContractenabledKerasas very helpful( /u1D707=4.30,/u1D70E=0.90).
RQ5.2 (Easiness): Regarding how easy is to write DL Contract on
top ofKerasAPIs, we have obtained that 65% of the participants
ratesthewritingprocessofacontractto Keraspositively(Rating
> 3). Regarding the rating of the writing process of a contract
toKeras, the participants‚Äô rating ( /u1D707=3.8,/u1D70E=0.67) is moderate
(35%), easy (50%), very easy(15%) as illustrated in Fig. 6. About
the integration of the written contract with Keraslibrary, 60% of
theparticipantsratedpositively( /u1D707=3.75,/u1D70E=0.69).Thedetailed
breakdown rating of integration of the written contract with Keras
library, the participants‚Äô ratings is moderate 40%), easy (45%), very
easy(15%)asshowninFig. 6.Insummary,wehaveevaluatedthat
DL Contract enabled Keras is very helpful to developers in debugging
DL software, and writing and integrating DL Contract is very easy to
API designers.
Q5: Rate how difficult it was to write a 
contract to DL Contract enabled Keras.Q6: Rate how difficult it was to integrate the 
written contract for Keras library.
Figure6:Surveyresultswithparticipantsratingsonhoweasy
isto write DL Contract on DLlibrary APIs
4.5 Limitations
Our proposed DL Contract approach has been evaluated primar-
ilyonproblemsrelatedtomultilabel,multiclass,binaryclassiÔ¨Åca-
tion, and regression with various structural and logical bugs in the
sequentialDNNmodelarchitectureandcommontrainingissues.
Further research is needed to apply and evaluate our approach for
other types of bugs and model categories. Despite this, the concept
of using contracts in deep learning isnot limited to Kerasand can
103Designby Contract forDeep Learning APIs ESEC/FSE ‚Äô23, December3‚Äì9, 2023,San Francisco, CA, USA
beextendedtootherDLlibraries.Whileourpaperillustratesthe
ideaofdeeplearningcontractsfor Keras,ourcontributioncanbe
generalized to other DL libraries like TensorFlow, PyTorch. We
focused on Kerasto keep the implementation eÔ¨Äort manageable
andleveragethis library‚Äôs large body ofbenchmarks.
4.6 Threatsto Validity
OurproposedapproachmaybeaÔ¨Äectedbyexternalthreats,such
asimprecisepreconditionandpostconditiondeÔ¨Ånitionsobtained
fromlibrarydocumentation, StackOverÔ¨Çow posts,andGitHubcom-
mits.However,wehaveadopteddeÔ¨Ånitionsfromrecentresearch
studies[37,46,66]tomitigatethis.Thresholdparametersmayalso
causefalsepositivesinsomenewreal-worldprograms.Additionally,
implementationusing PyContracts mayhaveunforeseeninternal
threats,butourgeneralopen-sourceframeworkcanbeextended
using reproduciblepackage [ 15]withdetailedresults.
5 RELATED WORK
SpeciÔ¨Åcation of Deep Neural Networks: The closest related
ideasinthespeciÔ¨ÅcationofDNNsinclude[ 31,58,59].While[ 58]
provides an overview of the opportunities and challenges of for-
malizing and reasoning about DNN properties, it does not propose
any methodology for writing and checking speciÔ¨Åcations for deep
learning libraries. In contrast, [ 31] presents a technique for com-
puting input and layer properties from a feed-forward network
using input-output characterizations as formal contracts. Addi-
tionally, [ 59] introduces a method for repairing neural network
classiÔ¨ÅersbyinferringthecorrectspeciÔ¨Åcations.Both[ 31]and[59]
proposeinferencetechniques,whileourtechniqueproposesaspec-
iÔ¨ÅcationandcheckingtechniquethatenablesthespeciÔ¨Åcationof
DLlibrariesandchecksthosecontractsinclientcodeusingthose
libraries,thuspreventingbugsandprovidingÔ¨Åxsuggestions.Re-
cently,anempiricalstudy[ 38]reportscategoriesofrequiredML
contracts, whichmayhelpdesigners ofcontract languages.
Deep Learning Testing, Debugging, and Repairing: Prior
work on DL testing, debugging, and repairing includes DeepLo-
calize [62], MODE [ 46],AUTOTRAINER [65],DeepDiagnosis [61],
DeepFD[25],Ariadne [ 29],Lagouvardos[ 40],Nikanjam etal.[52],
SHAPETRACER [ 44], and Tensfa [ 63]. These approaches focus on
detecting and localizing bugs, but DL Contract supports documen-
tation of expected behavior. While DL Contract checker can also
double as abug detection tool, in the long term, developers would
alsobeneÔ¨ÅtfromthedocumentationandwritemorecorrectDLpro-
grams. Empirical studies [ 26,34,36,37,56,64,66] have motivated
the need for DL bug repair, but none propose a DbC methodology
likeDL Contract .
Existing DbC Methodology: Existing DbC frameworks for
Python,suchasPyContracts[ 32],Pylint[ 1],andPyTA[ 45],donot
have the capability to check contracts for properties of models and
data,ormonitortrainingbehaviorofDLmodels.Theseframeworks
donotaddressthetechnicalchallengesofcheckingcontractsbe-
yondAPIparameters,contractsinvolvingmultipleAPIsatdiÔ¨Äerent
stagesoftheMLpipeline,andcontractsonintermediateproperties
tospecifydesiredtrainingbehavior.Additionally, DLContract ‚Äôsuse
of runtime assertions is distinct from checking runtime properties,
such as interpreting statecharts [ 47]. To the best of our knowledge,theconceptofapplyingDbCovertheDLcomputationalgraphand
specifying DL-speciÔ¨Åc contracts isnovel.
API Misuse Detection: There have been some API misuse
detection techniques such as, [ 60], which examines the usage of
machinelearning(ML)cloudAPIsinopen-sourceapplications.This
work Ô¨Ånds that many of these applications contain API misuses
that degrade their functionality and performance, leading to the
developmentofautomatedcheckersforidentifyingsuchmisuses.
[52]tacklesAPIMisuse(APIM)bugsstaticallybysomerulesthat
occurwhenpractitionersmisunderstandtheusageofdeeplearning
APIs. Such misusage leads to inconsistencies between the designed
DLprogramandtheAPI‚Äôsusageconditions,potentiallyresulting
inreducedeÔ¨Äectivenessorruntimeexceptions.ExistingAPImis-
usedetectionmethodsmaynotbesuitableforcheckingcontracts
written by library API designers that capture properties of models,
data,andtrainingbehavioratvariousprogrampointsduringrun-
time. To address this limitation, our approach overcomes technical
challenges associated with checking contracts beyond formal API
parameters,handlingcontractsinvolvingmultipleAPIsatdiÔ¨Äerent
stagesoftheMLpipeline,andspecifyingintermediateproperties
for desiredtraining behavior.
6 CONCLUSIONSAND FUTUREWORK
Inthiswork,weproposedanovelmethodforcheckingcontractsfor
deeplearninglibrariesbyspecifyingDLAPIswithpreconditions
andpostconditions.Ourapproachisextensibleandgeneralizable,
allowing for the abstraction of model architecture, data properties,
andtrainingbehavior.Wedeveloped15sampleDLcontractstarget-
ing common bugs and found they eÔ¨Äectively prevented structural
bugsandtrainingproblems.Additionally,ouruserstudyshowedthe
usabilityof DLContract whenappliedtotheKeraslibrary.Wehave
submitted an API design proposal for its incorporation in future
releases of Keras. Possible future work includes static validation,
unittesting,andinferringcontractsforadditionallibraries.With
ongoingresearchondecomposingDNNintomodules[ 35,53,54],
weintendtowritecontractsfortheexpectedbehaviorofaDNN
module eÔ¨Äectively. We want to explore writing contracts to pre-
ventnonfunctionalbugssuchasfairnessbugs[ 20,21].Wewould
also like to extend our approach to prevent additional types of
bugs in diÔ¨Äerent stages of the ML pipeline [ 22]. We can adapt tech-
niques [50,51] for collecting contracts from mined models with
improvedperformance interms of accuracyandtraining time.
7 DATA AVAILABILITY
The replication packages and results are available in this reposi-
tory [17]that can be leveragedbyfurther research.
ACKNOWLEDGMENTS
Weacknowledge thereviewersfortheirinsightful comments.We
also thank the user study participants. This material is based upon
worksupportedbytheNationalScienceFoundationunderGrant
CCF-15-18897,CNS-15-13263,CNS-21-20448,CCF-19-34884,and
CCF-22-23812. All opinions are of the authors and do not reÔ¨Çect
the viewofsponsors.
104ESEC/FSE ‚Äô23, December3‚Äì9, 2023,San Francisco, CA, USA ShibbirAhmed, Sayem Mohammad Imtiaz, Samantha Syeda Khairunnesa,Breno Dantas Cruz, andHrideshRajan
REFERENCES
[1] 2016. Pylint.https://pylint.pycqa.org/en/latest/
[2]2021. CNN with keras, accuracy not improving. https://stackoverflow.com/ques
tions/50079585/ . [Online;accessed Feb-2023].
[3]2021. HowtotrainandtuneanartiÔ¨Åcialmultilayerperceptronneuralnetwork
using Keras? https://stackoverflow.com/questions/34673164/ . [Online; accessed
Feb-2023].
[4] 2021. KerasAPI reference. https://keras.io/api/ . [Online;accessed Feb-2023].
[5]2021. Keras unreasonnably slower than TensorFlow. https://stackoverflow.com/
questions/47352366/ . [Online;accessed Feb-2023].
[6]2021. Loss becomes NaN. https://stackoverflow.com/questions/55328966/ .
[Online;accessed Feb-2023].
[7]2021. Low accuracy after training a CNN. https://stackoverflow.com/questions/
59325381/ . [Online;accessed Feb-2023].
[8]2021. Multilabel Text ClassiÔ¨Åcation using TensorFlow. https://stackoverflow.co
m/questions/35400065/multilabel-text-classiÔ¨Åcation-using-tensorÔ¨Çow . [Online;
accessed Feb-2023].
[9]2021. SigmoidlayerinKeras. https://stackoverflow.com/questions/45442843/ .
[Online;accessed Feb-2023].
[10]2021. Simple MNIST convnet example from Keras documentation. https://keras.
io/examples/vision/mnist_convnet/ . [Online;accessed Feb-2023].
[11]2023. An annotated version of Keras with the DL Contract (@Keras). https:
//github.com/shibbirtanvin/DLContract/tree/main/Rep roducibilityPackage/%
40Keras. [Online;accessed Aug-2023].
[12]2023. Collected Contracts Table in the Repo. https://github.com/shibbirtanv
in/DLContract/blob/main/Appendix/ListofContracts.pdf . [Online; accessed
Aug-2023].
[13]2023. Comparison of DeepDiagnosis with DL Contract in Anonymous Repo.
https://github.com/shibbirtanvin/DLContract/tree/main/Results/Experimental
Evaluation . [Online;accessed Aug-2023].
[14]2023. DeepLocalize Full Results in the Reposioty. https://github.com/shibbirtanv
in/DLContract/tree/main/Results/ExperimentalEvaluation/DeepLocalize_Resu
lts.pdf. [Online;accessed Aug-2023].
[15]2023. ReposiotyofDLContract. https://github.com/shibbirtanvin/DLContract .
[Online;accessed Aug-2023].
[16]Mart√≠nAbadi,PaulBarham,JianminChen,ZhifengChen,AndyDavis,JeÔ¨Ärey
Dean,MatthieuDevin,SanjayGhemawat,GeoÔ¨ÄreyIrving,MichaelIsard,Man-
junathKudlur,JoshLevenberg,RajatMonga,SherryMoore,DerekG.Murray,
Benoit Steiner, Paul Tucker, Vijay Vasudevan, Pete Warden, Martin Wicke, Yuan
Yu, and Xiaoqiang Zheng. 2016. TensorFlow: A System for Large-Scale Machine
Learning. In Proceedings of the 12th USENIX Conference on Operating Systems
DesignandImplementation (Savannah,GA,USA) (OSDI‚Äô16) .USENIXAssociation,
USA,265‚Äì283.
[17]Shibbir Ahmed, Sayem Mohammad Imtiaz, Samantha Syeda Khairunnesa,
Breno Dantas Cruz, and Hridesh Rajan. 2023. Replication Package of the ES-
EC/FSE2023PaperEntitled"DesignbyContractforDeepLearningAPIs‚Äô" .https:
//doi.org/10.5281/zenodo.8271853 The replication packages and results are avail-
ableinthisGitHubrepository[https://github.com/shibbirtanvin/DLContract]
that canbeleveraged by further research.
[18]MikeBarnett,RobertDeLine,ManuelF√§hndrich,BartJacobs,K.RustanM.Leino,
Wolfram Schulte, and Herman Venter. 2008. The Spec# Programming System:
ChallengesandDirections . SpringerBerlinHeidelberg,Berlin,Heidelberg,144‚Äì
152.https://doi.org/10.1007/978-3-540-69149-5_16
[19]Mike Barnett, Manuel F√§hndrich, K Rustan M Leino, Peter M√ºller, Wolfram
Schulte, and Herman Venter. 2011. SpeciÔ¨Åcation and veriÔ¨Åcation: the Spec#
experience. Commun. ACM 54, 6 (2011), 81‚Äì91. https://doi.org/10.1145/1953122.
1953145
[20]Sumon Biswasand Hridesh Rajan. 2020. Dothe Machine Learning Models on a
CrowdSourcedPlatformExhibitBias?AnEmpiricalStudyonModelFairness.
InProceedingsofthe28thACMJointMeetingonEuropeanSoftwareEngineering
ConferenceandSymposiumontheFoundationsofSoftwareEngineering (Virtual
Event, USA) (ESEC/FSE 2020) . Association for Computing Machinery, New York,
NY, USA,642‚Äì653. https://doi.org/10.1145/3368089.3409704
[21]SumonBiswasandHrideshRajan.2021. FairPreprocessing:TowardsUnderstand-
ing Compositional Fairness of Data Transformers in Machine Learning Pipeline.
InProceedingsofthe29thACMJointMeetingonEuropeanSoftwareEngineering
ConferenceandSymposiumontheFoundationsofSoftwareEngineering (Athens,
Greece)(ESEC/FSE 2021) . Association forComputing Machinery, NewYork, NY,
USA,981‚Äì993. https://doi.org/10.1145/3468264.3468536
[22]Sumon Biswas, Mohammad Wardat, and Hridesh Rajan. 2022. The Art and
Practice of Data Science Pipelines: A Comprehensive Study of Data Science
Pipelines in Theory, in-the-Small, and in-the-Large. In Proceedings of the 44th
InternationalConferenceonSoftwareEngineering (Pittsburgh,Pennsylvania) (ICSE
‚Äô22). Association for Computing Machinery, New York, NY, USA, 2091‚Äì2103.
https://doi.org/10.1145/3510003.3510057
[23]Martin B√ºchi and Wolfgang Weck. 1999. The Greybox Approach: When Blackbox
SpeciÔ¨Åcations Hide Too Much . Technical Report 297. Turku Center for Computer
Science. http://tinyurl.com/ywmuzy .[24]Margaret Burnett, Robin Counts, Ronette Lawrence, and Hannah Hanson. 2017.
GenderHCl andmicrosoft:Highlightsfromalongitudinalstudy. In 2017IEEE
Symposium on Visual Languages and Human-Centric Computing (VL/HCC) . 139‚Äì
143.https://doi.org/10.1109/VLHCC.2017.8103461
[25]Jialun Cao, Meiziniu Li, Xiao Chen, Ming Wen, Yongqiang Tian, Bo Wu, and
Shing-Chi Cheung. 2022. DeepFD: Automated Fault Diagnosis and Localization
for Deep Learning Programs. In Proceedings of the 44th International Conference
on Software Engineering (Pittsburgh, Pennsylvania) (ICSE ‚Äô22) . Association for
ComputingMachinery,NewYork,NY,USA,573‚Äì585. https://doi.org/10.1145/35
10003.3510099
[26]ZhenpengChen,YanbinCao,YuanqiangLiu,HaoyuWang,TaoXie,andXuanzhe
Liu.2020. AComprehensiveStudyonChallengesinDeployingDeepLearning
BasedSoftware.In Proceedingsofthe28thACMJointMeetingonEuropeanSoftware
EngineeringConferenceandSymposiumontheFoundationsofSoftwareEngineering
(Virtual Event, USA) (ESEC/FSE 2020) . Association for Computing Machinery,
NewYork, NY, USA,750‚Äì762. https://doi.org/10.1145/3368089.3409759
[27]Yoonsik Cheon, Gary Leavens, Murali Sitaraman, and Stephen Edwards. 2005.
ModelVariables:CleanlySupportingAbstractioninDesignbyContract:Research
Articles. Softw.Pract.Exper. 35,6 (may2005),583‚Äì599.
[28]PascalCuoq,FlorentKirchner,NikolaiKosmatov,VirgilePrevosto,JulienSignoles,
and Boris Yakobowski. 2012. Frama-C. In Software Engineering and Formal
Methods,GeorgeEleftherakis,MikeHinchey,andMikeHolcombe(Eds.).Springer
Berlin Heidelberg, Berlin, Heidelberg, 233‚Äì247.
[29]Julian Dolby, Avraham Shinnar, Allison Allain, and Jenna Reinen. 2018. Ariadne:
Analysis for Machine Learning Programs. In Proceedings of the 2nd ACM SIG-
PLAN International Workshop on Machine Learning and Programming Languages
(Philadelphia, PA, USA) (MAPL 2018) . Association for Computing Machinery,
NewYork, NY, USA,1‚Äì10. https://doi.org/10.1145/3211346.3211349
[30]Konstantin Eckle and Johannes Schmidt-Hieber. 2019. A comparison of deep
networks with ReLU activation function and linear spline-type methods. Neural
Networks 110(2019), 232‚Äì242.
[31]Divya Gopinath, Hayes Converse, Corina Pasareanu, and Ankur Taly. 2019.
PropertyInferenceforDeepNeuralNetworks.In 201934thIEEE/ACMInterna-
tional Conference on Automated Software Engineering (ASE) . 797‚Äì809. https:
//doi.org/10.1109/ASE.2019.00079
[32]Brett Graham, William Furr, Karol Kuczmarski, Bernhard Biskup, and Adam
Palay. 2010. PyContracts .https://andreacensi.github.io/contracts//
[33]NargizHumbatova,GunelJahangirova,GabrieleBavota,VincenzoRiccio,Andrea
Stocco, and Paolo Tonella. 2020. Taxonomy of Real Faults in Deep Learning Sys-
tems.InProceedingsofthe ACM/IEEE 42nd InternationalConference onSoftware
Engineering (Seoul, South Korea) (ICSE ‚Äô20) . Association for Computing Machin-
ery, NewYork, NY, USA,1110‚Äì1121. https://doi.org/10.1145/3377811.3380395
[34]NargizHumbatova,GunelJahangirova,GabrieleBavota,VincenzoRiccio,Andrea
Stocco, and Paolo Tonella. 2020. Taxonomy of Real Faults in Deep Learning Sys-
tems.InProceedingsofthe ACM/IEEE 42nd InternationalConference onSoftware
Engineering (Seoul, South Korea) (ICSE ‚Äô20) . Association for Computing Machin-
ery, NewYork, NY, USA,1110‚Äì1121. https://doi.org/10.1145/3377811.3380395
[35]SayemMohammadImtiaz,FraolBatole,AsthaSingh,RangeetPan,BrenoDantas
Cruz, and Hridesh Rajan. 2023. Decomposing a Recurrent Neural Network
into Modules for Enabling Reusability and Replacement. In 2023 IEEE/ACM 45th
International Conference on Software Engineering (ICSE) . 1020‚Äì1032. https:
//doi.org/10.1109/ICSE48619.2023.00093
[36]Md Johirul Islam, Giang Nguyen, Rangeet Pan, and Hridesh Rajan. 2019. A
ComprehensiveStudyonDeepLearningBugCharacteristics.In Proceedingsof
the201927thACMJointMeetingonEuropeanSoftwareEngineeringConference
and Symposium on the Foundations of Software Engineering (Tallinn, Estonia)
(ESEC/FSE 2019) . Association for Computing Machinery, New York, NY, USA,
510‚Äì520. https://doi.org/10.1145/3338906.3338955
[37]Md Johirul Islam, Rangeet Pan, Giang Nguyen, and Hridesh Rajan. 2020. Repair-
ing Deep Neural Networks: Fix Patterns and Challenges. In Proceedings of the
ACM/IEEE42ndInternationalConferenceonSoftwareEngineering (Seoul,South
Korea)(ICSE‚Äô20) .AssociationforComputingMachinery,NewYork,NY,USA,
1135‚Äì1146. https://doi.org/10.1145/3377811.3380378
[38]Samantha Syeda Khairunnesa, Shibbir Ahmed, Sayem Mohammad Imtiaz,
Hridesh Rajan, and Gary T. Leavens. 2023. What Kinds of Contracts Do ML
APIsNeed? EmpiricalSoftwareEngineering 1,1 (March2023).
[39]SiÔ¨ÅsLagouvardos,JulianDolby,NevilleGrech,AnastasiosAntoniadis,andYannis
Smaragdakis. 2020. Static Analysis of Shape in TensorFlow Programs. In 34th
European Conference on Object-Oriented Programming (ECOOP 2020) (Leibniz
International Proceedings in Informatics (LIPIcs), Vol. 166) , Robert Hirschfeld and
Tobias Pape (Eds.). Schloss Dagstuhl‚ÄìLeibniz-Zentrum f√ºr Informatik, Dagstuhl,
Germany, 15:1‚Äì15:29. https://doi.org/10.4230/LIPIcs.ECOOP.2020.15
[40]SiÔ¨ÅsLagouvardos,JulianDolby,NevilleGrech,AnastasiosAntoniadis,andYannis
Smaragdakis. 2020. Static Analysis of Shape in TensorFlow Programs. In 34th
EuropeanConferenceonObject-OrientedProgramming,ECOOP2020,November15-
17, 2020, Berlin, Germany (Virtual Conference) (LIPIcs, Vol. 166) , Robert Hirschfeld
andTobiasPape(Eds.).SchlossDagstuhl-Leibniz-Zentrumf√ºrInformatik,15:1‚Äì
15:29.https://doi.org/10.4230/LIPIcs.ECOOP.2020.15
105Designby Contract forDeep Learning APIs ESEC/FSE ‚Äô23, December3‚Äì9, 2023,San Francisco, CA, USA
[41]GaryT.Leavens,AlbertL.Baker,andClydeRuby.2006. PreliminaryDesignof
JML:ABehavioralInterfaceSpeciÔ¨ÅcationLanguageforJava. SIGSOFTSoftw.Eng.
Notes31,3 (May2006),1‚Äì38. https://doi.org/10.1145/1127878.1127884
[42]K. Rustan M. Leino. 1995. Toward Reliable Modular Programs . Ph.D. Dissertation.
California Institute of Technology. Available as Technical Report Caltech-CS-
TR-95-03..
[43]K. Rustan M. Leino. 2010. Dafny: An Automatic Program VeriÔ¨Åer for Functional
Correctness. In Logic for Programming, ArtiÔ¨Åcial Intelligence, and Reasoning ,
Edmund M. Clarke and Andrei Voronkov (Eds.). Springer Berlin Heidelberg,
Berlin, Heidelberg, 348‚Äì370. https://doi.org/10.1007/978-3-642-17511-4_20
[44]Chen Liu, Jie Lu, Guangwei Li, Ting Yuan, Lian Li, Feng Tan, Jun Yang, Liang
You, and Jingling Xue. 2021. Detecting TensorFlow Program Bugs in Real-World
IndustrialEnvironment.In 202136thIEEE/ACMInternationalConferenceonAuto-
mated Software Engineering (ASE) . 55‚Äì66.https://doi.org/10.1109/ASE51524.202
1.9678891
[45]Nigel Fong Lorena Buciu, Simon Chen and et al. 2016. PyTA.https://www.cs.tor
onto.edu/~david/pyta/index.html/
[46]ShiqingMa,YingqiLiu,Wen-ChuanLee,XiangyuZhang,andAnanthGrama.
2018. MODE:AutomatedNeuralNetworkModelDebuggingviaStateDiÔ¨Äerential
Analysis andInputSelection. In Proceedingsofthe2018 26thACM JointMeeting
on European Software Engineering Conference and Symposium on the Foundations
ofSoftwareEngineering (LakeBuenaVista,FL,USA) (ESEC/FSE2018) .Association
for Computing Machinery, New York, NY, USA, 175‚Äì186. https://doi.org/10.114
5/3236024.3236082
[47]TomMens,AlexandreDecan,andNikolaosISpanoudakis.2019. Amethodfor
testingandvalidatingexecutablestatechartmodels. Software&SystemsModeling
18,2 (2019), 837‚Äì863. https://doi.org/10.1007/s10270-018-0676-3
[48]B. Meyer. 1992. Applying ‚Äôdesign by contract‚Äô. Computer 25, 10 (1992), 40‚Äì51.
https://doi.org/10.1109/2.161279
[49]Peter M√ºller. 2001. Modular SpeciÔ¨Åcation and VeriÔ¨Åcation of Object-Oriented
programs. Ph.D.Dissertation.FernUniversit√§tHagen,Germany. http://tinyurl.
com/jtwot
[50]GiangNguyen,SumonBiswas,andHrideshRajan.2023. FixFairness,Don‚ÄôtRuin
Accuracy: Performance Aware Fairness Repair using AutoML. In ESEC/FSE‚Äô2023:
The 31st ACMJoint EuropeanSoftware EngineeringConferenceandSymposiumon
the FoundationsofSoftwareEngineering (SanFrancisco, California).
[51]Giang Nguyen, Md Johirul Islam, Rangeet Pan, and Hridesh Rajan. 2022. Manas:
Mining Software Repositories to Assist AutoML. In Proceedings of the 44th In-
ternational Conference on Software Engineering (Pittsburgh, Pennsylvania) (ICSE
‚Äô22). Association for Computing Machinery, New York, NY, USA, 1368‚Äì1380.
https://doi.org/10.1145/3510003.3510052
[52]Amin Nikanjam, Houssem Ben Braiek, Mohammad Mehdi Morovati, and Foutse
Khomh. 2021. Automatic Fault Detection for Deep Learning Programs Using
GraphTransformations. ACMTrans.Softw.Eng.Methodol. 31,1,Article14(sep
2021),27pages. https://doi.org/10.1145/3470006
[53]Rangeet Pan and Hridesh Rajan. 2020. On Decomposing a Deep Neural Network
into Modules. In Proceedings of the 28th ACM Joint Meeting on European Software
EngineeringConferenceandSymposiumontheFoundationsofSoftwareEngineering
(Virtual Event, USA) (ESEC/FSE 2020) . Association for Computing Machinery,
NewYork, NY, USA,889‚Äì900. https://doi.org/10.1145/3368089.3409668
[54]Rangeet Pan and Hridesh Rajan. 2022. Decomposing Convolutional Neural
Networks into Reusable and Replaceable Modules. In Proceedings of the 44th
InternationalConferenceonSoftwareEngineering (Pittsburgh,Pennsylvania) (ICSE
‚Äô22).AssociationforComputingMachinery,NewYork,NY,USA,524‚Äì535. https:
//doi.org/10.1145/3510003.3510051
[55]Hung Viet Pham, Shangshu Qian, Jiannan Wang, Thibaud Lutellier, Jonathan
Rosenthal, Lin Tan, Yaoliang Yu, and Nachiappan Nagappan. 2021. Problems
and Opportunities in Training Deep Learning Software Systems: An Analysis
of Variance. In Proceedings of the 35th IEEE/ACM International Conference onAutomated Software Engineering (Virtual Event, Australia) (ASE ‚Äô20). Association
for Computing Machinery, New York, NY, USA, 771‚Äì783. https://doi.org/10.114
5/3324884.3416545
[56]VincenzoRiccio,GunelJahangirova,AndreaStocco,NargizHumbatova,Michael
Weiss, and Paolo Tonella. 2020. Testing machine learning based systems: a
systematic mapping. Empirical Software Engineering 25, 6 (2020), 5193‚Äì5254.
https://doi.org/10.1007/s10664-020-09881-0
[57]EldonSchoop,ForrestHuang,andBjoernHartmann.2021. UMLAUT:Debug-
ging Deep Learning Programs Using Program Structure and Model Behavior. In
Proceedingsofthe 2021CHIConferenceonHumanFactorsinComputingSystems
(Yokohama,Japan) (CHI‚Äô21).AssociationforComputing Machinery,NewYork,
NY, USA,Article310, 16pages. https://doi.org/10.1145/3411764.3445538
[58]Sanjit A. Seshia, Ankush Desai, Tommaso Dreossi, Daniel J. Fremont, Shromona
Ghosh,EdwardKim,SumukhShivakumar,MarcellVazquez-Chanlatte,andXi-
angyu Yue. 2018. Formal SpeciÔ¨Åcation for Deep Neural Networks. In Automated
TechnologyforVeriÔ¨ÅcationandAnalysis .SpringerInternationalPublishing,Cham,
20‚Äì34.https://doi.org/10.1007/978-3-030-01090-4_2
[59]Muhammad Usman, Divya Gopinath, Youcheng Sun, Yannic Noller, and Co-
rinaS.PƒÉsƒÉreanu.2021. NNrepair: Constraint-basedRepairofNeuralNetwork
ClassiÔ¨Åers. In Computer Aided VeriÔ¨Åcation: 33rd International Conference, CAV
2021,VirtualEvent,July20‚Äì23,2021,Proceedings,PartI .Springer-Verlag,Berlin,
Heidelberg, 3‚Äì25. https://doi.org/10.1007/978-3-030-81685-8_1
[60]Chengcheng Wan, Shicheng Liu, Henry HoÔ¨Ämann, Michael Maire, and Shan Lu.
2021. AreMachineLearningCloudAPIsUsedCorrectly?.In Proceedingsofthe
43rd International Conferenceon Software Engineering (Madrid, Spain) (ICSE ‚Äô21) .
IEEE Press,125‚Äì137. https://doi.org/10.1109/ICSE43902.2021.00024
[61]Mohammad Wardat, Breno Dantas Cruz, Wei Le, and Hridesh Rajan. 2022.
DeepDiagnosis: Automatically Diagnosing Faults and Recommending Action-
able Fixes in Deep Learning Programs. In Proceedings of the 44th International
Conference on Software Engineering (Pittsburgh, Pennsylvania) (ICSE ‚Äô22) . As-
sociation for Computing Machinery, New York, NY, USA, 561‚Äì572. https:
//doi.org/10.1145/3510003.3510071
[62]Mohammad Wardat, Wei Le, and Hridesh Rajan. 2021. DeepLocalize: Fault
LocalizationforDeepNeuralNetworks.In Proceedingsofthe43rdInternational
ConferenceonSoftwareEngineering (Madrid,Spain) (ICSE‚Äô21) .IEEEPress,251‚Äì262.
https://doi.org/10.1109/ICSE43902.2021.00034
[63]DangweiWu,BeijunShen,YutingChen,HeJiang,andLeiQiao.2021. Tensfa:
Detecting and Repairing Tensor Shape Faults in Deep Learning Systems. In 2021
IEEE32ndInternationalSymposiumonSoftwareReliabilityEngineering(ISSRE) .
11‚Äì21.https://doi.org/10.1109/ISSRE52982.2021.00014
[64]Ru Zhang, Wencong Xiao, Hongyu Zhang, Yu Liu, Haoxiang Lin, and Mao Yang.
2020. An Empirical Study on Program Failures of Deep Learning Jobs. In Pro-
ceedings ofthe ACM/IEEE42nd InternationalConferenceonSoftwareEngineering
(Seoul,SouthKorea) (ICSE‚Äô20) .AssociationforComputingMachinery,NewYork,
NY, USA,1159‚Äì1170. https://doi.org/10.1145/3377811.3380362
[65]XiaoyuZhang,JuanZhai,ShiqingMa,andChaoShen.2021. AutoTrainer:An
Automatic DNN Training Problem Detection and Repair System. In Proceedings
ofthe43rdInternationalConferenceonSoftwareEngineering (Madrid,Spain) (ICSE
‚Äô21). IEEE Press,359‚Äì371. https://doi.org/10.1109/ICSE43902.2021.00043
[66]YuhaoZhang,YifanChen,Shing-ChiCheung,YingfeiXiong,andLuZhang.2018.
AnEmpiricalStudyonTensorFlowProgramBugs.In Proceedingsofthe27thACM
SIGSOFT International Symposium on Software Testing and Analysis (Amsterdam,
Netherlands) (ISSTA2018) .AssociationforComputingMachinery,NewYork,NY,
USA,129‚Äì140. https://doi.org/10.1145/3213846.3213866
[67] DonglinZhuang,XingyaoZhang,ShuaiwenSong,andSaraHooker.2022. Ran-
domnessinNeuralNetworkTraining:CharacterizingtheImpactofTooling.In
ProceedingsofMachineLearning and Systems , D. Marculescu,Y. Chi, and C. Wu
(Eds.), Vol. 4. 316‚Äì336. https://proceedings.mlsys.org/paper_Ô¨Åles/paper/2022/Ô¨Ål
e/427e0e886ebf87538afdf0badb805b7f-Paper.pdf
106