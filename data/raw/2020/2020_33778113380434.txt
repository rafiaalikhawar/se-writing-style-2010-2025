HARP: Holistic Analysis for Refactoring Python-Based Analytics
Programs
Weijie Zhou
wzhou9@ncsu.edu
North Carolina State University
Raleigh, NCYue Zhao
yzhao30@fb.com
Facebook
Menlo Park, CA
Guoqiang Zhang
gzhang9@ncsu.edu
North Carolina State University
Raleigh, NCXipeng Shen
xshen5@ncsu.edu
North Carolina State University
Raleigh, NC
ABSTRACT
Modern machine learning programs are often written in Python,
with the main computations specified through calls to some highly
optimized libraries (e.g., TensorFlow, PyTorch). How to maximize
the computing efficiency of such programs is essential for many
application domains, which has drawn lots of recent attention. This
work points out a common limitation in existing efforts: they focus
their views only on the static computation graphs specified by li-
brary APIs, but leave the influence from the hosting Python code
largely unconsidered. The limitation often causes them to miss the
big picture and hence many important optimization opportunities.
This work proposes a new approach named HARP to address the
problem. HARP enables holistic analysis that spans across com-
putation graphs and their hosting Python code. HARP achieves it
through a set of novel techniques: analytics-conscious speculative
analysis to circumvent Python complexities, a unified representa-
tion augmented computation graphs to capture all dimensions of
knowledge related with the holistic analysis, and conditioned feed-
back mechanism to allow risk-controlled aggressive analysis. Refac-
toring based on HARP gives 1.3‚Äì3X and 2.07X average speedups
on a set of TensorFlow and PyTorch programs.
CCS CONCEPTS
‚Ä¢Software and its engineering ‚ÜíAutomated static analysis ;
Data flow architectures ;‚Ä¢Computing methodologies ‚ÜíMachine
learning .
KEYWORDS
machine learning program, computation graph, dynamic language,
program analysis
ACM Reference Format:
Weijie Zhou, Yue Zhao, Guoqiang Zhang, and Xipeng Shen. 2020. HARP:
Holistic Analysis for Refactoring Python-Based Analytics Programs. In
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
ICSE ‚Äô20, May 23‚Äì29, 2020, Seoul, Republic of Korea
¬© 2020 Association for Computing Machinery.
ACM ISBN 978-1-4503-7121-6/20/05. . . $15.00
https://doi.org/10.1145/3377811.338043442nd International Conference on Software Engineering (ICSE ‚Äô20), May 23‚Äì
29, 2020, Seoul, Republic of Korea. ACM, New York, NY, USA, 12 pages.
https://doi.org/10.1145/3377811.3380434
1 INTRODUCTION
For machine learning applications, computing efficiency is essential,
for the growing scale of datasets and the needs for timely responses
in various applications. A pattern common in today‚Äôs analyticsapplications isPython+X, where, main computations are written
with APIs of some libraries X(e.g., TensorFlow, PyTorch) while the
host code is written in Python which connects all pieces together.
We call them Python-based analytics programs.
Such programs have some common features. We draw on Tensor-
Flow [ 1] as an example for explanation. Like some other packages,
TensorFlow was initially introduced for a specific scope (Deep
Learning), but then evolved for a broader scope (Analytics and Sci-
entific Computing). At its core, TensorFlow builds on the dataflow
programming model. In developing a TensorFlow program, a devel-oper writes code by calling TensorFlow APIs to specify the intendedcomputations, and makes a call to the TensorFlow runtime. The call
triggers the execution of those APIs, which constructs a computa-
tion graph; the TensorFlow runtime optimizes the graph, and then
executes it. This approach represents one of the popular program-
ming paradigms used by modern machine learning and analytics
frameworks.
The recent years have seen a number of efforts for enhancing
the performance of Python-based analytics programs. For exam-
ple, the XLA project [ 18] and the R-Stream-TF project [ 31] try to
improve the runtime performance of TensorFlow by utilizing com-
piler techniques to transform dataflow graphs (e.g., fusing multiple
operations).
However, despite the many efforts, a large room for performance
improvement is left elusive for current optimizers to harvest. We be-lieve that one of the fundamental reasons is that current efforts have
all focused on the dataflow graphs embodied by the invocationsof library APIs in a program. Although dataflow graphs usually
capture the core computations of an analytics program, limiting the
view on them may lose the big picture that the host code provides,
and hence many large-scoped optimization opportunities.
Listing 1 offers an example. This codelet is part of the core com-
putations in Deep Dictionary Learning [ 24]. The firstfive lines of
the code specify the core computations and hence the structure of
5062020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE)
ICSE ‚Äô20, May 23‚Äì29, 2020, Seoul, Republic of Korea Weijie Zhou, Yue Zhao, Guoqiang Zhang, and Xipeng Shen
the dataflow graph. Line 1 defines ùê¥as a variable as its value needs
to be updated through the execution; Lines 2 and 3 define ùê∑andùëã
as place holders for they will hold the input values; Line 4 specifies
the formula for calculating the new value of ùê¥through a series of
calls to the high-level TensorFlow mathematics functions; Line 5
specifies an update to ùê¥with the new value. Line 6 is a Python
loop statement, and Line 7 calls TensorFlow API "sess.run" (a block-
ing API) to invoke TensorFlow runtime to actually construct the
dataflow graph and execute it; it passes the actual parameters ùê∑_
andùëã_ to the two place holders.
The following pseudo-code shows what the codelet implements:
ùëì ùëúùëü ùëñ<ùêºùë°ùëíùëü :
ùê¥=ùê∑(ùëã‚àíùê∑ùëáùê¥)
where each of the capitalized letters represents a multidimensional
array (called a tensor), and ùê∑andùëãare input tensors and remain
constant across the loop iterations.
The implementation by the codelet in Listing 1 contains some
redundant computations, which can be seen if we expand the math-
ematical formula in the pseudo-code to ùê∑ùëã‚àíùê∑ùê∑ùëáùê¥. Because terms
ùê∑ùëãandùê∑ùê∑ùëáare invariant across the loop iterations, they can be
hoisted outside the loop, computed once and reused for all iterations
as shown as follows:
ùë°1=ùê∑ùëã
ùë°2=ùê∑ùê∑ùëá
ùëì ùëúùëü ùëñ<ùêºùë°ùëíùëü :
ùê¥=ùë°1‚àíùë°2ùê¥
Even though the redundant computations are not hard to see
at the pseudo-code level, it cannot be recognized or optimized by
either TensorFlow or any of the previously proposed optimizers
designed for TensorFlow programs. Moreover, even if we rewrite
the code to better expose the redundancy as in Listing 2, prior
optimizers still cannot detect the redundant computations.
The reason is that all these tools focus only on the dataflow graph
composed through the TensorFlow APIs, while the redundancy
comes from the interplay between those TensorFlow API calls and
the other Python code that hosts those calls. Take Listing 1 for
instance, without analyzing the host Python code, it is impossible
to tell that D and X are invariant across the forloop and hence
ùê∑ùëãandùê∑ùê∑ùëáare also loop invariants, as the computation graph
does not capture the loop in the host code and its relation with
the data in the graph. On the other hand, general Python codeoptimizers cannot find out the redundancy either as they do not
understand the necessary semantics of the TensorFlow APIs. Other
examples include partially repeated computations involved two
separate API calls, the mis-use of computation graph construction
APIs as computation APIs in a loop and causing millions of graph
nodes to be generated unnecessarily (See Section 4.3).
This work proposes a new approach named HARP ( Holistic
Analysis for Refactoring Python-Based Analytics Programs) to ad-
dress the problem. We next gives an overview of HARP, the main
challenges and our contributions.
2 OVERVIEW OF HARP
To overcome the aforementioned limitation of existing tools, an
initial option we considered was to create an automatic static code
optimizer with a holistic view. It is however impractical: Python is aListing 1: Example from Deep Dictionary Learning ("tf" forthe namespace of TensorFlow)
1 A = t f . V a r i a b l e ( t f . z e r o s ( shape =[N , N ] ) , dtype = t f . f l o a t 3 2 )
2 D = t f . p l a c e h o l d e r ( shape =[N , N] , dtype = t f . f l o a t 3 2 )3 X = t f . p l a c e h o l d e r ( shape =[N , N] , dtype = t f . f l o a t 3 2 )4 R = t f . matmul (D, t f . s u b t r a c t ( X , t f . matmul ( t f . t r a n s p o s e (D)
, A) ) )
5 L = t f . a s s i g n (A , R )6for iin range ( I t e r ) :
7 r e s u l t = s e s s . run ( L , f e e d _ d i c t = {D : D_ , X : X_ } )
Listing 2: Listing 1 in a Different Form
1 . . .2 t 1 = t f . matmul (D, X)3 t 2 = t f . matmul (D, t f . t r a n s p o s e (D) )4 R = t f . s u b s t r a c t ( t1 , t f . matmul ( t2 , A) )5 L = t f . a s s i g n (A , R )
6 for iin range ( I t e r ) :
7 r e s u l t = s e s s . run ( L , f e e d _ d i c t = {D : D_ , X : X_ } )
dynamically-typed language, the complexities of which (listed later)
form some major barriers for static optimizers to work effectively.
A pure dynamic optimizer on the other hand is complicated to
develop and causes runtime overhead and delays.
The strategy we finally took is to create a refactoring assistant,
which provides suggestions for developers to use in refactoring
the code. This strategy allows aggressive analysis on incomplete
information. Even though the suggestions may not be always cor-
rect, as the tool provides enough feedback on the assumptions it
uses, the developers can avoid the risks while taking advantage of
the often correct suggestions. HARP is the first tool that enables
holistic analysis that spans across dataflow graphs and their hosting
Python code. HARP achieves it through several novel features:
(1) Speculative analysis. HARP relies heavily on static analysis.
As a dynamically-typed scripting language, Python poses many
difficulties to static analysis, such as unknown types, operator over-
loading, dynamic dispatch of higher-order functions, and so on.
HARP circumvents the complexities with two key insights: Many
Python complexities rarely appear in analytics programs or can
be ignored; for those that do matter, they can often be treated suc-
cessfully through speculations on common patterns in analytics
applications. HARP materializes the insights throughspeculative
analysis.
(2) Uniform representation. Holistic analysis requires a coherent
way with a uniform structure to represent the computations and
relations attained from both the host and the computation graph.
The representation must be inclusive in the sense that it must con-
tain necessary info from both the host and the library‚Äîincluding
necessary high-level semantics (e.g., side effects, expected tensor
type) of APIs. It, at the same time, must be amenable for automatic
inferences for optimization opportunities. HARP introduces aug-
mented computation graphs, a uniform representation that augmentscomputation graphs with relations attained from the host code andsome light annotations of library APIs. It uses Datalog as the media
to create the coherent representation for holistic analysis.
(3) Informative and extensible interface. HARP employs a Datalog-
based interface such that code analysis modules can be simply
507HARP: Holistic Analysis for Refactoring Python-Based Analytics Programs ICSE ‚Äô20, May 23‚Äì29, 2020, Seoul, Republic of Korea
expressed in Datalog rules in a declarative manner. Through the in-
terface, we equip HARP with a set of predefined rules for detecting
common inefficiencies on the augmented computation graphs. The
interface also allows users to easily extend HARP with extra rules.
Meanwhile, we equip HARP with a conditioned feedback mechanism,
through which, HARP gives users not only suggestions for coderefactoring but also the assumptions it holds in its speculations.
This feature helps control the risks of the speculative analysis, and
allows HARP to offer likely useful suggestions despite language
complexities.
To evaluate the efficacy of HARP, we implement it as a plugin of
PyCharm based on IntelliJ1and develop the support for TensorFlow
and PyTorch. HARP is effective in finding optimization opportu-
nities that are elusive to prior techniques. Code refactoring based
on the findings yield 1.3-3X performance improvement on a GPU
machine. We further conduct a user study, which helps confirm the
productivity benefits of this refactoring tool.
We do not claim using Datalog for program analysis as our con-
tribution. Many previous papers have applied Datalog for program
analysis and shown promising productivity [ 2,14,37‚Äì39]. The key
contributions of this work are four-fold:
‚Ä¢It points out the limited view of existing tools as a fundamen-tal barrier to harvest important opportunities for refactoring
modern machine learning applications for performance.
‚Ä¢It provides several insights important for circumventing lan-
guage complexities in machine learning applications, andproposes ways to leverage common patterns in machine
learning to enable effective speculative analysis.
‚Ä¢It develops augmented computation graphs as unified way to
host all dimensions of knowledge related with the holistic
analysis.
‚Ä¢It creates HARP, the first holistic analysis-based tool for
machine learning code refactoring, and demonstrates its
effectiveness in a range of applications.
The current implementation of HARP focuses on supporting Ten-
sorFlow and PyTorch [ 29] programs for their increasing popularity,
and also for their representatives of two paradigms in computation
graph construction: TensorFlow builds static computation graphs,
while PyTorch defines dynamic graph. We next provide some back-
ground knowledge and then describe each part of HARP in detail.
3 BACKGROUND
This section presents background knowledge on TensorFlow, Py-
Torch, and Datalog.
3.1 TensorFlow
A TensorFlow program works in a ‚Äúdefine-and-execute‚Äù way [ 13].
Its execution first creates a computation graph which then gets
optimized and executed by the runtime. High level languages such
as Python are often used as the host language in defining the com-
putations, and low-level languages such as C-family languages are
often used to implement the runtime system for the purpose ofperformance efficiency. A TensorFlow program can be regardedas a mix of two program components: Thefirst part, called "host
1http://www.jetbrains.orgHost
codeAPI
TF Systemexecute
SessionComputation
Graph
Figure 1: High-level relations among host code, TF system,and computation graphs.
program", contains the computation that is directly executed by thefront-end language. The second part is the computation represented
by the ‚Äúcomputation graph‚Äù.
Computation graphs. In TensorFlow, the computation graph is a
directed graph composed of a set of nodes and edges:
‚Ä¢Nodes instantiates operations (e.g., ‚Äúmatrix multiply‚Äù or ‚Äúsig-
moid‚Äù). Each operation can have zero or more inputs and
zero or more outputs.
These operations get dispatched to devices (CPU, GPU) by
the runtime.
‚Ä¢Edges represent the values communicated between opera-
tions. The most common types of values in TensorFlow are
tensors, which are ùëÅ-dimensional arrays. Their elements can
have one of the primitive types (e.g., int32 ,float32 , or
string). Tensors on edges are stateless and immutable.
‚Ä¢There are some special nodes and edges. For example, a
tf.Variable creates a variable, which represents stateful
value and is mutable. It is represented as a node in the graph
carrying the variable name as its label. In addition, there are
control dependency edges which indicate controls of the
execution order of operations.
Host program and graph execution. In a typical TensorFlow pro-
gram, the responsibilities of the host program include preparingdata for the computation, hosting the API calls that define the
computation graph, and controlling its executions.
The host program interacts with computation graphs and the
underlying TensorFlow (TF) system through the session API. It
calls session.run which prompts the TF system to execute the
computation graph. The call may specify a set of output nodes
whose values are to be fetched, and a set of input tensors to be fed
into the graph. Figure 1 illustrates the relations.
A computation graph can be executed multiple times. It is impor-
tant to note that tensors do not survive across one execution of the
graph (e.g., one session.run); the memory holding them is allocated
and reclaimed automatically. In contrast, values of variable nodes
persist across executions.
3.2 PyTorch
PyTorch is another popular machine learning framework. Similar
to the TensorFlow, the PyTorch program can also be regarded as a
mix of the Python host program and the underlying computation
graph of operations, which will be dispatched to runtime kernels
in the execution. However, unlike TensorFlow, the PyTorch builds
the computation graph dynamically. In other words, the PyTorch
508ICSE ‚Äô20, May 23‚Äì29, 2020, Seoul, Republic of Korea Weijie Zhou, Yue Zhao, Guoqiang Zhang, and Xipeng Shen
Analytics  
programHost program
Computation
GraphHARP compiler¬†
&¬†
graph¬†generatorAugmented 
Graph 
Inference engineOptimization
opportunities
and
conditionsAnalysis ruleAnalysis rule
Library APIProperties
(OfÔ¨Çine)
Figure 2: The overall system diagram.
constructs the computation graph on-the-fly so the computation
graph can change every time it is executed.
3.3 Datalog
Datalog is a popular logic programming language based on the
first order logic. In Datalog, program logic is expressed in terms
of relations, represented as facts and rules, and computations are
in queries over these relations. Two basic constructs are term and
atom. A term is either an entity (constant) or a variable2. An atom
is a predicate with a list of terms as arguments. It is in form of
ùëù(ùëã1,ùëã2, . . . ,ùëãùëõ), where ùëùis a predicate and ùëãùëñare terms. A ground
atom orfact is a predicate with only constant arguments. Many
facts together form a Datalog database.
Datalog rules express logical inferences, in the following form:
ùê¥: -ùêµ1,ùêµ2, . . . ,ùêµùëõ.
which reads ‚Äú ùêµ1andùêµ2and ... and ùêµùëõtogether imply ùê¥‚Äù, where
each symbol is an atom.
A Datalog program is a collection of rules. When it runs on a
fact database, it infers a new set of facts by applying the rules to the
known facts. Datalog can define recursive relations and recursive
queries naturally and is declarative.
4 THE HARP SOLUTION
This section presents HARP in detail. Figure 2 outlines the over-
all structure of HARP. HARP code analysis extracts the relevant
information from the host code and the computation graphs, and
represents them in a unified format, augmented computation graph,
written in Datalog atoms. Meanwhile, through some light anno-
tations, we equip HARP with the knowledge on the high-level
properties of the library APIs, including the side-effects of APIs,
argument types and returning types. With all the relevant informa-
tion captured and represented in an analyzable manner, for a rule
(predefined in HARP or given by users) describing code inefficiency
patterns, the Datalog inference engine can identify optimization
opportunities that span across boundaries between host code and
API calls. HARP is equipped with a list of predefined rules on code
inefficiency, which are derived through our analysis of 112 real-
world analytics applications, listed in Table 1 and elaborated in
Section 4.3. We next explain HARP and how it addresses the main
challenges in enabling holistic analysis.
2By conversion, lowercase for constants and uppercase for variables.Listing 3: An example machine learning codelet
1def dfdx ( x , param , f ) :
2 z = f ( x , param )
3 z . backward ( [ t o r c h . o n e s _ l i k e ( z ) ] )
4 dfdx_v = x . grad
5 return dfdx_v
4.1 Overcoming Language Complexities
Thefirst challenge this work encounters is Python complexities.
As an important step outlined in Figure 2, the HARP analyzer must
capture the important interactions between the host Python code
and the computation graphs. As a dynamically-typed scripting lan-
guage, Python poses many difficulties to the static analysis, which
are summarized in Table 2. These complexities cause unknown
types and undecidable operations or function calls.
Listing 3 shows such an example. The function dfdx calculates
the partial derivative of a function with regard to the input x. Due
to the dynamic feature of Python, it is hard for static analysis to
precisely determine the types of its input parameters.
HARP circumvents the difficulties by leveraging insights ob-
tained specially on analytics applications. The first insight is that
many Python complexities rarely appear in analytics programs or
can be ignored. Table 2 reports the number of appearances of each
type of complexity in 112 real-world analytics applications that we
have surveyed in two GitHub collections3. These two collections
contain some TensorFlow and PyTorch programs representing a
variety of tasks in machine learning, ranging from natural language
processing to image processing, object detection, and so on. In the
survey, we ran our static Python code analyzer (sec 4.2.2) on each
of the programs, which reports places that give static analysis a
hard time. We then manually examined those cases. Among the
112 applications, the most frequent complexity is dynamic type
changes, but the frequency is still only 14.
The second insight is that for those complexities that do matter,
they can often be treated successfully through speculations.
The speculations are based on some common patterns observed
in analytics applications. Analytics applications, due to the com-
mon features of the domain, exhibit some patterns. For instance, in
PyTorch code, the type of a variable that has a member function
"grad" or "backward" is usually a tensor with all floating-point val-
ues. That pattern can then help speculate on the types of variables
ùë•andùëßin Listing 3. Although using names for speculation is in
general not fully reliable, we observed that doing that for some
common functions in machine learning domain gives correct spec-
ulations in most of times. Table 3 lists some of the patterns we
attained through our studies on our collection of machine learning
applications. Listing 3 belongs to the second pattern in Table 3.
When encountering a complexity in its static analysis of a given
Python program, HARP resorts to the common patterns. If the
conditions match, HARP resolves the complexity speculatively.
Such speculations allow HARP to carry on its code analysis
even in the presence of the complexities. That makes it possible to
provide refactoring suggestions that are likely (not guaranteed) to
be valid and beneficial. Speculations could be wrong; the developer
3https://github.com/jtoy/awesome-tensorflow; https://github.com/ritchieng/the-
incredible-pytorch
509HARP: Holistic Analysis for Refactoring Python-Based Analytics Programs ICSE ‚Äô20, May 23‚Äì29, 2020, Seoul, Republic of Korea
Table 1: Some Inefficiency Patterns Predefined in HARP
No. Inefficiency Code Patterns Potential Optimization‚Äôs
1 Mistake the computation construction for compu-
tation execution (TensorFlow)‚Ä¢Use computation graph construction APIs inside loop.
‚Ä¢The APIs are primitive operators such as tf.add, tf.mul, etc.Do the computation in
theSession.
2 Loop redundancy ‚Ä¢Loop invariant computation inside loop Hoist the loop invariant
out of the loop
3 Common subgraph computation ‚Ä¢Two consecutive executed computation graphs have common intermediate nodes.
‚Ä¢The value of the common nodes are invariant across the executions.Cache the last common
nodes and reuse the
value.
4 Plain forloop for computation (TensorFlow) ‚Ä¢Use the plain Python loop for building computation graph.
‚Ä¢The code inside the loop only reference nodes in the computation graph but not
other data on the host side.Replace the plainPython loop with
tf.while_loop
5 Miss performance tuning for static graph (Py-
Torch)‚Ä¢The dynamically constructed computation graph remains the same across loops: no
conditional branch or dynamic dispatch.
‚Ä¢Size of the input data is not changed.
‚Ä¢Iteration number is non-trivial (>5).Turn on the CUDAspecific optimiza-tion tuning such as
torch.backends.cudnn
6 Scalar computation that can be vectorized ‚Ä¢Simple forloop contains straight line code with neither function calls nor branches.
‚Ä¢Computation on vector data type (list of number, array, etc).
‚Ä¢No vector dependence.Use array or tensor type
and their vectorized op-
erations.
Table 2: Python language complexities for static analysis
and appearing frequencies in 112 machine learning appli-
cations.
Python Language Complexities # programs with the complexity
Data dependent conditional branch 3
Static unknown function dispatch 4
Higher-order function 10
Customized operator overload 2
Dynamic attribute setting 4
Dynamic type changes 14
Dynamic-typed container 12
Table 3: Some of the machine learning patterns leveraged
for speculative analysis.
No. Class of patterns
1 Access to an object through its attribute, such as foo.bar, or an
index, such as foo[bar], is speculated as side effect free.
2 The type of an object can be speculated based on the names of
itsfields and methods visited locally if the names are common
machine learning names (e.g., those in Figure 3).
3 If a Python list is (speculatively) converted to a tensor, it is
speculated that the elements in the list share the same type.
4 If all branches of a condition statement return variables with
the same type, they speculatively share the same type.
5 I/O operations are normally used for loading data and logging,
thus they are speculated as having no unexpected side effects.
torch.utils.data.Dataset(),¬†transforms.CenterCrop(), 
transforms.Normalize(), torch.from_numpy(t),¬† transforms.functional.adjust_brightness(img‚Ä¶),¬† torch.ones_like(a),¬†torch.add(a,b),¬†Tensor[:,:,...],¬† Tensor.abs(),¬†Tensor.add(b),¬†Tensor.min(),¬†Tensor.copy(),¬† Tensor.dim(),¬†Tensor.size(),¬†Tensor.permute(),¬† Tensor.reshape(),¬†Tensor.type_as(),¬†Tensor.Ô¨Çoat(),¬† Tensor.detach(),¬†Tensor.cuda(), Tensor.unsqueeze_() ...
 
 
Figure 3: Some common function names used in HARP ashints for speculative analysis.
needs to make the final judgment. To assist the developers in the
process, HARP records all speculations, and reports them when itprovides the corresponding refactoring suggestions, as Section 4.4
details.
4.2 Unified Representation through
Augmented Computation Graphs
For holistic analysis, it is preferred that all the needed information
of the program is represented in an analyzable form. It implies threequestions: (1) what information to get, (2) how to get it, and (3) how
to represent it. HARP answers these questions by following several
design principles:
‚Ä¢First, the representation should be amenable for software
inference, but also easy to understand for humans. The rep-
resentation can then be used for not only program analysis,
but also as a kind of documentation.
‚Ä¢Second, the set of information to collect from the program
are intended to be used in a variety of analysis; hence, their
definitions should be general rather than tailored to some
particular analysis.
‚Ä¢Third, the representation should also be extensible. Thus,
specification for new properties and other sources of infor-
mation can be added easily.
We next explain the solutions from HARP in detail.
4.2.1 Info to Attain: Semantic Definitions. The relevant informa-
tion for holistic analysis comes from both the host Python code and
the computation graphs. For simplicity of explanation, we use "se-
mantics" to refer to all4. Both host code and the computation graph
carry many-fold semantics, defining the set that is most relevant to
large-scoped inefficiencies is the key.
Semantics from Computation Graph. As mentioned in Section 3, a
computation graph consists of two types of objects, nodes and edges.
Each node represents an operation that consumes or produces
values. Each edge represents the values that are output from, or
input to a node, namely, the values that flow along the edge. We use
TensorFlow as the example to explain the set of semantics HARP
captures from nodes and edges.
4The meaning goes beyond traditional language semantics, referring to any properties
or knowledge about a programming language construct.
510ICSE ‚Äô20, May 23‚Äì29, 2020, Seoul, Republic of Korea Weijie Zhou, Yue Zhao, Guoqiang Zhang, and Xipeng Shen
For a node (TF operation), HARP captures four-fold semantics
(1)control_inputs, referring to the set of operations on which this
operation has a control dependency; (2) inputs, which are the list
of tensor inputs of the operation; (3) outputs, which are the list of
output tensors of the operation; and (4) type of computation, such as
Add,MatMul . HARP contains the set of common computation types,
including those supported in ONNX [ 8], a standard for representing
deep learning models; more can be easily added.
For an edge (TF value), HARP captures some important proper-
ties: kind, dtype, shape, constant or variable. The first, kind, is about
which kind of edge it is. We distinguish two different kinds of edges
based on their different purposes [1]:
‚Ä¢Tensor edges convey the immutable tensors of the data. In
TensorFlow, all data are modeled as tensors and there is no
need to distinguish tensors or scalars.
‚Ä¢Control edges do not carry values. They are special edges
used to constrain the order of execution.
The second property, dtype, is the type of data carried on the
edge, which can be any of the supported data types in TensorFlow.
The third property, shape, records the shape of the tensor, which is
a list [ùê∑0,ùê∑1, . . . ,ùê∑ùëë‚àí1]storing the size of each dimension of the
tensor. The final property indicates whether the tensor on the edge
isconstant or mutable.
Semantics from Host Code. For TensorFlow, HARP captures the
following semantics that closely relate with the core computation:
(1) The operations that invoke TensorFlow APIs to define the
computation graph. For example, the statement c = tf.add(a, b)
in the host program defines an Add operation in the computation
graph. These APIs are high order functions that return operations.
We convert them into ‚Äúoperation creation‚Äù nodes whose outputs
are special edges representing ‚Äúoperations‚Äù.
(2) The invocation of the session API which prompts graph
executions. This is also the interface for the host-computation graph
interaction.
(3) The control flow of the host program.
(4) The processing of data that is to be consumed by the com-
putation graph, which includes calls to other library APIs (e.g.,
Numpy).
4.2.2 Collecting Semantics through HARP Compiler. Deriving the
semantics is done through our HARP compiler and computation
graph dumping. The compiler is developed based on Jedi [ 33], a
static analyzer of Python programs.
Computation graph. The step to get the semantics of the compu-
tation graph is as follows. For TensorFlow programs, the compiler
inserts a graph dumping call (and a follow-up exit) at the place in
the program where the computation graph is built (e.g., invocation
of "run()" of a tf.Session object), and then runs the program on a
provided sample input. The computation graph is then dumped in a
format easy to parse. For most programs, the automatic method can
succeed. In rare cases when the code does not follow the common
patterns, HARP provides feedback and users can insert the dumping
call (as part of HARP interface). The exported graph is in a format
called GraphDef , which can be easily parsed to get the structure
relations and properties of nodes and edges. For PyTorch programs,we use an approach similar to existing tools (AutoGraph [ 25] and
JANUS [11]) to create the computation graphs.
Host program. To get the semantics from the host program, both
dataflow analysis and control flow analysis are necessary. Two
properties of machine learning applications ease the process. First,
the set of data that requires attention is limited. Since the datais fed into the graph through the
session API, we only need to
focus on data in the feed list. Thus, the domain of the dataflowanalysis is largely narrowed down. Second, in most of the deeplearning or machine learning programs, the data has a straight-
forward workflow. For example, a typical flow of the input data is
that it starts from being read from the external storage or beinggenerated from other components of the program, and then it is
converted to some tensor variables. The variable is then provided
to the computation graph as the input data. So the data of interest
often exhibits a linear control flow. HARP lowers the representation
of some control flow structures by following existing practice [ 7]
(e.g, lowering ifstatement to switch andmerge primitives). HARP
compiler circumvents Python language complexities through the
speculative analysis described in the earlier section. It records the
assumptions it uses when applying a speculation, which will be
used later as part of the feedback to users.
4.2.3 Representing Semantics: Augmented Computation Graph. We
design augmented computation graph for HARP to use to seamlessly
integrate the host code semantics with those of the computationgraph. To make the representation amenable for existing logicinference engines to use, we represent all semantics as Datalog
atoms using a single vocabulary.
Augmented Computation Graph. Extensions are added to the
default computation graph to accommodate each category of se-
mantics from the host code.
‚Ä¢HARP uses inter-procedural graph to model the interplay
between host code and the computation graph. The inputsto a computation graph are treated as function parameters
and the outputs as function returns. The analysis can hence
take advantage of standard inter-procedural analysis.
‚Ä¢For the control flow structure in the host program, the most
important one is the loop structure, which creates a local
scope containing a set of computations. To encode its se-mantics, a loop is modeled as a special operation node in
the augmented graph. For any computation inside the loop,
there is a control edge from the loop node to the node rep-
resenting the computation. If a data is loop variant, there
is an extra tensor edge from the loop operation to it. Edges
go from a loop node only to operations in the host program,
which then may connect to the operations in the computa-
tion graph. It is worth noting that, the relations between the
loop operation and the other nodes reflect dependencies,
rather than traditional structures in the abstract syntax tree
(AST) of the host program.
‚Ä¢For the influence to host data dependencies and control flows
from calls to other library functions (e.g., Numpy ), HARP gets
the semantics through library annotations. Particularly, we
annotation library APIs such as type signature, side-effect.
511HARP: Holistic Analysis for Refactoring Python-Based Analytics Programs ICSE ‚Äô20, May 23‚Äì29, 2020, Seoul, Republic of Korea
Listing 4: Specifications for edges
1 edge ( < edge_id > , kind , <kind >) .
2 edge ( < edge_id > , dtype , < d a t a _ t y p e >) .3 edge ( < edge_id > , shape , < t e n s o r _ s h a p e >) .
Listing 5: API Misusage Example from StackOverflow
1 x = t f . V a r i a b l e ( . . . )2 . . .3for _in range ( 1 e6 ) :
4 x = x + 15 . . .
6 s e s s . run ( . . . )
Datalog Atoms. The augmented graph is represented in HARP in
the form of Datalog atoms. In our design, each atom only describes
one attribute of the object. This is for the flexibility and extensi-
bility. For example, if new attributes for the tensor is needed for
new analysis, they can be added to the semantic schema without
breaking the existing specifications and rules.
Listing 4 shows the main kinds of atoms for edges (TF values),
corresponding to the three kinds of semantics defined for edges.
The atoms of nodes are in similar forms but with different keywords
for different semantics.
4.3 Inefficiency Detection Rules and Engines
With the augmented computation graph written in Datalog atoms,
program analysis algorithms can be written in Datalog rules. This
design has several benefits. First, the declarative interface provided
by the logic programming lowers the bar for writing complicated
algorithms than the imperative interface of traditional compilers
does. Second, the semantics of machine learning programs often
center around the graph structure. The relational and recursivenature of logic programming languages makes it a goodfit for
the graph-based analysis. For example, in Datalog, the template of
recursive algorithms are as simple as follows:
1 r e c u r s i v e _ r e l a t i o n ( EdgeFrom , EdgeTo ) : ‚àíd i r e c t _ r e l a t i o n (
EdgeFrom , EdgeTo ) .
2 r e c u r s i v e _ r e l a t i o n ( EdgeFrom , EdgeTo ) : ‚àíd i r e c t _ r e l a t i o n (
EdgeFrom , EdgeMid ) , r e c u r s i v e _ r e l a t i o n ( EdgeMid ,
EdgeTo ) .
The template queries the relation between every pair of edges.
The template simulates the process of computing the transitive
closure of the graph. It starts from the existing facts (the direct
relation) and inference other facts through recursive propagation.
Rules for nodes can be defined similarly.
Through analysis of 112 real-world analytics programs5, we
summarized a list of code inefficiency patterns in Table 1. We next
illustrate the simplicity in defining corresponding rules for detect-
ing inefficiency on the augmented graphs.
Example 1: API sanitizing. Thefirst inefficiency in Table 1 is
misuse of the library APIs on constructing computation graphs. Thecode pattern is that those APIs are used inside a loop, causing many
nodes to be created unnecessarily, as Listing 5 shows. HARP has
5https://github.com/jtoy/awesome-tensorflow; https://github.com/ritchieng/the-
incredible-pytorchListing 6: RBM codelet
1 a l p h a = 0 . 5
2 a = t f . p l a c e h o l d e r ( " f l o a t " , [ 1 0 0 ] )3 b = t f . p l a c e h o l d e r ( " f l o a t " , [ 7 8 4 ] )
4 W = t f . V a r i a b l e ( t f . random ( [ 7 8 4 , 1 0 0 ] ) )
5 x = t f . p l a c e h o l d e r ( " f l o a t " , [ None , 7 8 4 ] )67 h0 = t f . nn . sigmoid ( t f . matmul ( x , W) )8 h1 = t f . nn . sigmoid ( t f . matmul ( h0 , t f . t r a n s p o s e (W) ) + b )
9 v1 = t f . nn . sigmoid ( t f . matmul ( h1 , W) + a )
10
11 y1 = t f . reduce_mean ( x
‚àív1 , 0 )
12 y2 = t f . reduce_mean ( h1 ‚àív1 , 0 )
1314 with t f . S e s s i o n ( ) as s e s s :15 s e s s . run ( t f . i n i t i a l i z e _ a l l _ v a r i a b l e s ( ) )16 for _in range ( 1 0 ) :
17 for s t a r t , end in i n d i c e s :
18 X , A , B = data_gen ( s t a r t : end )
19 _y1 = s e s s . run ( y1 , f e e d _ d i c t = { x : X , a : A , b : B } )
20 A = a l p h a ‚àóA
21 _y2 = s e s s . run ( y2 , f e e d _ d i c t = { x : X , a : A , b : B } )
ax
bh0
v1y2y1
h1
W
Figure 4: The simplified dataflow graph for Listing 6. The
square nodes represent data variables and circle nodes rep-resent operations. The labels inside the operation nodes in-dicate their output names.
rules (called ‚ÄúAPI sanitizing rules‚Äù) to detect such API misuses. The
rules are simple, thanks to the augmentation graph representation
and the declarative interface HARP uses. The code below expresses
the pattern of ‚Äúincluding operation creating APIs inside a loop‚Äù:
op (O, type , " OpCreation " ) , op (O, i n s i d e L o o p , " loopID " ) ?
where control_edge indicates the operation is inside a loop.
Another use case of the sanitizing rule is to help shape inference.
In TensorFlow, the shapes of some tensors can be unspecified, whicharedynamic shapes. At runtime, the TensorFlow system would need
to infer the shape based on the input data, and then propagate theinfo to other tensors that depend on these input tensors. Dynamic
shapes are hurdles for TensorFlow to simplify computation graphs
or enable efficient memory allocations.
In many of the cases with dynamic shapes, however, the input
data can actually be determined from the host code (e.g., deeplearning with a fixed batch size). But as TensorFlow compilers
focus on computation graphs only, it cannot do the shape inference
in advance. The holistic analysis by HARP addresses the limitation
and detects unnecessary dynamic shapes.
Example 2: Detecting computation redundancy. A more interest-
ing use of the HARP framework is to hunt for the computationredundancies (patterns two and three in Table 1) that are elusive
to the existing tools and subtle to see by programmers. We demon-
strate it on the example in Listing 2 of Section 1. Figure 5 shows the
augmented computation graph including the relevant operations
512ICSE ‚Äô20, May 23‚Äì29, 2020, Seoul, Republic of Korea Weijie Zhou, Yue Zhao, Guoqiang Zhang, and Xipeng Shen
Listing 7: Dependency checking rules
1 d i r e c t _ d e p ( E1 , E2 ) : ‚àíi n p u t _ e d g e ( Node , E1 ) , o u t p u t _ e d g e (
Node , E2 ) .
2 dep ( E1 , E2 ) : ‚àíd i r e c t _ d e p ( E1 , E2 ) .
3 dep ( E1 , E2 ) : ‚àíd i r e c t _ d e p ( E1 , X) , dep ( X , E2 ) .
Listing 8: Shape consistency checking rules
1 shape ( E , S ) : ‚àíf e e d _ i n ( E ) , S == shape_check ( E ) .
2 shape ( E , S ) : ‚àíout_edge ( Node , E ) , f i n d a l l ( IE , i n p u t _ e d g e (
Node , IE ) , I E s ) , shape_check ( Node , IEs , S ) .
from the host program. It captures all the constant information and
the scope of the loop. Through constant propagation, HARP infers
that t1andt2are invariant across the loop and thus they can be
hoisted. The suggested code refactoring is to change the data type
oft1andt2totf.Variable , making their values survive across
the loop iterations and get reused.
Another example is to detect common sub-computation redun-
dancy as the one shown in Listing 6. Figure 4 shows a simplified
dataflow graph corresponding to the RBM codelet. The outputs _y1
and_y2both need the intermediate value h0,h1andv1. Node a
affects v1, but h0, h1 have the same values in the computations of
_y1and_y2according to the Python code in Listing 6. Therefore, po-
tentially, the values of h0andh1produced during the session.run
for_y1could be reused for the session.run that produces _y2.
To detect such common sub-computation redundancy, rules are
written to find intermediate values common to multiple fetched
values, such that they can be potentially cached and reused. The
core of the detection algorithm is to analyze the dependencies of
the values. The data dependency atoms are shown in Listing 7.
One can query for finding common dependencies. For example,
if we have two fetched values ùëú1 and ùëú2, we can use the following
query to find operations that both ùëú1 and ùëú2 depend on:
1 common_dep ( X , o1 , o2 ) : ‚àídep ( X , o1 ) , dep ( X , o2 ) .
By adding an extra check, whether ùëú1 and ùëú2 belong to two
different sessions, one can then find cases worth caching the value
ofùëãin one session and reusing it in the other session.
There are some other rules in HARP, including constant propa-
gation, which finds all constant variables, finding for-loop for vic-
timization‚Äôs, which finds for-loops in Python code that operate on
container objects likely containing elements of the same type and
unlikely having loop-carried dependency, static graph identification,
which identifies graphs that remain unchanged across iterations,
useless tensor detection, which finds tensors that are not used. These
analyses all lead to some potential optimizations. For static graph
identification, for instance, the knowledge would allow the inclusion
of some special flags ( torch.backends.cudnn.benchmark ) which
would allow PyTorch engine to apply some aggressive optimizations
to such graphs to improve the performance.
Inference engine. The inference engine of HARP is the Datalog
inference engine with an extension to allow the invocations of
external side effect-free imperative functions. The shape_check
function in Listing 8 is such an example. It checks the shape con-
sistency which means if an operator node has an outgoing edgeT
t2mul
mul
submulD
t1D X
A
A
Figure 5: Constant propagation on augmented computationgraph identifies loop invariants (the shadowed nodes).
(output), its shape should comply with the expected shape of the
operation and the inputs. For example, for matrix multiplication of
A and B, the output should have a shape of Rows(A) X Columns(B).As the check requires shape calculations, it is simple to write in im-
perative programming language but cumbersome in pure Datalog
predicates. By extending Datalog predicates with imperative func-
tions, HARP creates conveniences for the development of inference
rules. Caution must be taken to make sure that the extension does
not break the safety of the Datalog deduction. In the shape_check
example, since the function has no side-effect on the Datalog atoms,
it is regarded as a safe extension.
4.4 Informative Feedback
When the analysis by HARP involves speculations, the results could
be wrong. HARP provides conditioned feedback to keep the risks
controlled. The principle is to report also the assumptions HARP
uses in its speculations when it offers refactoring suggestions. Fig-
ure 6 provides an example output from HARP, after it is integrated
into the IDE PyCharm through IntelliJ. In this example, HARP
identifies TensorFlow computation redundancies among the lines
that invoke sess.run() . Then the IDE plugin highlights involved
code lines. When the mouse hovers over the highlighted lines, a
tooltip prompts the suggestion for the optimization, as well as the
assumptions that HARP takes in providing the suggestion. The
feedback needs correlate graph nodes and edges with source code
of the program. To facilitate it, HARP compiler conducts a prepro-
cessing of the given program by rewriting it to add unique name
to each computation graph construction statement. For example,
c = tf.add(a, b) , becomes c = tf.add(a, b, name= "id") ,
where "id" is a unique name managed by HARP. Then, the default
TensorFlow backend automatically assigns that unique name to the
corresponding node in the computation graph.
5 EVALUATION
In this section, we report the evaluations of the efficacy of the
proposed HARP approach. We demonstrate how it can help diag-
nose TensorFlow and PyTorch programs to find subtle pitfalls and
optimization opportunities that are elusive to existing tools. We
report the significant performance improvement of the correspond-
ing refactored code, as well as the effectiveness and benefits of the
speculative analysis. We further report a user study on the usability
of HARP as a refactoring tool for programmers.
513HARP: Holistic Analysis for Refactoring Python-Based Analytics Programs ICSE ‚Äô20, May 23‚Äì29, 2020, Seoul, Republic of Korea
Figure 6: Example feedback from HARP on a Restricted
Boltzmann machine (RBM) implementation.
Table 4: Hardware platforms used in the experiments.
Intel¬ÆCPU NVIDIA¬ÆGPU
CPU Xeon E5-1607GeForce GTX TI-
TAN X
Freq. 3.00 GHz 1.08 GHz
Cores 4 3072
Memory 16GB DDR3 1.9 GHz12GB GDDR5 3.5
GHz
Memory
Bandwidth34.1 GB/s 168 GB/s
OS/Driver Ubuntu 18.04 CUDA 9.0
Compiler GCC (6.2) NVCC (9.0)
Table 5: Benchmarks and Datasets.
Benchmark Application Dataset
dict-learn Dictionary Learning [ 24]Random generated (size:
1000X1000)
rbm [22] Restricted Boltzmann
Machine [10]MNIST [19]
char-rnn [20] Recurrent Neural Net-
works [16]Shakespeare work [17]
style-
transfer [30]Neural Style Transfer [ 9] VGG-16 model, input size of
224X224
deep-q-net [15] Deep Q-Network [35] OpenAI Gym [3]
seq2seq Variable Length RNN Blog Authorship Cor-
pus [32]
cycleGAN [40] Image to image transla-
tionCityscapes dataset [5]
cholesky Cholesky Decomposition Random generated (size:
10000 √ó10√ó10)
5.1 Experimental Setup
The hardware specifications for the evaluation platform are detailed
in Table 4. The benchmarks are tested with GPU acceleration. The
implementation of HARP is based on the Python static analysis
tool Jedi [ 33] and the inference engine is written based on Flix[23].
HARP is integrated into the IDE PyCharm through IntelliJ to serveTable 6: Potential efficiency problems reported by HARP.
Benchmark Inefficiency reported by HARP True
(pattern numbers defined in Table 1) positive
dict-learn 2. Loop redundancy Y
4. Plain forloop for computation N
rbm 3. Common subgraph computation Y
char-rnn 4. Plain forloop for computation Y
6. Scalar computation that can be vectorized:
Case IN
6. Scalar computation that can be vectorized:
Case IIY
style-
transfer3. common subgraph computation Y
4. Plain forloop for computation Y
deep-q-net 3.Common subgraph computation Y
seq2seq 4. Plain forloop for computation Y
cycleGAN 5. Miss performance tuning for static graph Y
cholesky 6. Scalar computation that can be vectorized Y
Table 7: Speedups by HARP-guided code refactoring.
Benchmark No. of Ops /
EdgesLibrary default
exec. time
(s)Speedup Line of
source
codes
dict-learn 20 / 24 TensorFlow 3.09 3.0 57
rbm 83 / 102 TensorFlow 28 2.4 61
char-rnn 248 / 261 TensorFlow 25.5 1.3 462
style-
transfer129 / 131 TensorFlow 15.9 1.6 365
deep-q-
net887 / 1379 TensorFlow 58.4 2.6 534
seq2seq 999 / 1343 TensorFlow 15.9 1.5 379
cycleGAN 4721 / 5935 PyTorch 442 1.4 670
cholesky N/A PyTorch 0.4 2.8 109
for code refactoring. Table 5 lists all the benchmarks. These bench-
marks are outside the 112 surveyed benchmarks for identifying
the speculation and optimization patterns. We collect these bench-
marks from published work or real-world TensorFlow and PyTorch
programs. They implement a range of machine learning algorithmsfor machine learning. Table 5 also shows the input dataset for each
benchmark. These benchmarks are based on Python 3.6, Tensor-Flow 1.5, and PyTorch 0.4.1. In our experiment, each benchmark
was executed multiple times; we saw only marginal fluctuations in
the execution time, and hence reported the mean value.
5.2 Performance Analysis
We focus on the inefficiency patterns listed in the table 1 in the
experiments. More rules can be inserted to detect more patterns.
Table 6 reports the inefficiency patterns that the HARP finds in
those benchmarks. It reports 1‚Äì3 potential inefficiencies in each of
the benchmarks. Two out of the 12 inefficiencies are false alarms.
One of the false alarms happens on dict-learn . HARP suggests
that the Python forloop can be replaced with the tf.while_loop .
Although the suggestion is valid, due to the existence of the loop
redundancy, the other suggestion is more efficient. The majority of
suggestions show useful insights and optimization hints. With the
help of more rules, false alarms could be further reduced. It is worth
noting that as these optimizations all span across both the Python
host code and library APIs, none of the prior methods [ 18,28,31]
canfind these opportunities for their limited scopes of analysis.
514ICSE ‚Äô20, May 23‚Äì29, 2020, Seoul, Republic of Korea Weijie Zhou, Yue Zhao, Guoqiang Zhang, and Xipeng Shen
Table 7 reports the speedups brought by refactoring that follows
the suggestions from HARP. The baseline is the performance of the
default programs running on the default TensorFlow and PyTorch
systems; these systems conduct the state-of-the-art optimizations,
but limit their views and optimizations to the computation graphs
only. The results show 1.3-3.0X speedups, confirming that the sug-
gestions from HARP are effective in fixing the efficiency problems
that are elusive to existing optimizing systems. In the evaluation,
we use the dataset included in the original application whenever it
is available. We have also experimented with 2-10X larger datasets
and observed similar speedups.
All these benchmarks except the cholesky implement some kind
of machine learning algorithms as Table 5 shows. The cholesky
measured the computations of Cholesky decomposition which is
useful for efficient numerical solutions. HARP constructs an aug-
mented computation graph for it to represent its 29 operations and
host-side controls.
Thedict-learn problem has already been discussed in Listing 2.
After the enabled loop invariant elimination, its performance on
GPU improves by 3 .02ùëã. For the rmbandstyle-transfer bench-
marks, the intermediate results of multiple sub-graphs depending
on the common inputs are cached and reused. The speedups are
respectively 2.0X and 1.6X. For char-rnn , HARP suggests trans-
forming to the tf.while_loop instead of the plain Python loop to
implement the repeated RNN cells.
Due to the dynamic feature of the PyTorch framework, com-
putation graphs are constructed in each iteration. This dynamic
property prevents optimizations that apply to static graphs. How-
ever, for cycGAN , the inference by HARP leads to the conclusion
that the graph is invariant across iterations. HARP hence suggests
autotuning and specialization for the underlying CUDA implemen-
tation by turning on torch.backends.cudnn option. The seq2seq
andcholesky contain loops that cannot be vectorized by existing
methods for the unknown data types of their container objects.
The analysis by HARP leads to the speculation on the uniform
type of their elements and the lack of loop-carried dependencies. It
suggests vectorization to the corresponding loops.
To assess the benefits brought from the speculative analysis,
we disable the speculations for the several benchmarks on which
speculations are used by HARP. Due to the static time unknowntypes, the analyzer is unable to infer the potential vectorization
opportunities for seq2seq andcholesky . For another benchmark,
dict-learn , without speculative analysis and the API knowledge,
the analyzer cannot tell the loop invariant calculations.
Wrong speculations happen once in the experiments, due to an
unconventional usage of decorator @property of Python. Codelet 9
illustrates it. Based on the first pattern in Table 3, the analyzer spec-
ulates that batches.next is side effect free and returns the same
value in each iteration of the loop. However, the implementation
ofbatches.next actually exploits the decorator @property and
returns different values at each access. The informative feedback
from HARP help programmers easily find the wrong speculations.
Table 7 also reports the numbers of nodes and edges in the
computation graphs. They reflect on the complexities of the graphs,
but do not necessarily indicate the complexities of the problems.
For example, complex computations such as an entire CNN layer
can be wrapped into a single operation in a graph.Listing 9: Codelet causing speculation errors
1c l a s s B a t c h e s :
2 . . .
3 @property
4 def next ( ) :
5 . . .
6 . . .
7def t r a i n ( s e l f , s e s s i o n , ops , b a t c h e s , n_epochs ) :
8 for iin range ( n_epochs ) :
9 s e s s i o n . run ( ops , f e e d _ d i c t = { s e l f . i n p u t s :
b a t c h e s . next } )
The analysis by HARP takes 32‚Äì973ms on these benchmarks.
The refactoring based on the suggestions from HARP varies from
several minutes to two hours (including debugging time), depend-
ing on the complexity of the benchmark. The benchmark char-rnn
takes the longest time to refactor since it requires embedding dy-
namic control flows into static graphs. It is worth noting that as
these optimizations all span across both the Python host code and
library APIs, none of the prior methods [ 18,28,31] can find these
opportunities for their limited scopes of analysis.
5.3 Usability Evaluation by User Study
To evaluate usability of HARP as a refactoring tool, we conduct a
controlled experiment with 12 participants. The hypothesis to test
is as follows: Given a sub-optimal program of interest, HARP can
help users more easily find optimization opportunities and optimize
the code to a more performant version.
All of the 12 participants are graduate students in computer sci-
ence. Ten of them were familiar with Python programming; among
the ten, three had written some beginner-level TensorFlow code
before, and two had written beginner-level PyTorch code before, the
otherfive haven‚Äôt written either TensorFlow or PyTorch code before.
Before the study, the participants were given a 45-minute lecture
on the basics of Python, TensorFlow, and PyTorch. To eliminate
the variance on experiment environments, we set up all the re-
quired software on our GPU server (Table 4) for the students to run
performance measurements. The benchmarks include dict_learn ,
char-rnn, rbm) and cycleGAN.
We conduct a two-stage user study to examine the usability of
HARP. All of the students were asked to find the inefficiencies of
these programs and to optimize them if possible. In the first stage,
they were not using the HARP but were allowed to use any other
resources they could find. They were asked to turn in their analysis
results and the optimization results in a week. Only a few students
successfully optimized some of the programs (4 for dict_learn ,
2 for rbm, 0 for char-rnn andcycleGAN ). The speedups they got
were 1.85X on dict_learn and 2.05X on rbmon the GPU server.
In the second stage, the students were asked to optimize those
programs with the help of HARP and submit the results in another
week. The students were asked to use only the feedback provided
by the HARP to optimize the programs.
Each of the programs was successfully optimized by 11 of the
12 students, and received 1.1‚Äì2.85X speedups. Program char-rnn
is an exception. HARP suggest to use tf.while_loop to integrate
itsforloop into the computation graph. Students unfamiliar with
TensorFlow failed making the code changes as that would need a
515HARP: Holistic Analysis for Refactoring Python-Based Analytics Programs ICSE ‚Äô20, May 23‚Äì29, 2020, Seoul, Republic of Korea
major rewriting of the code to embed dynamic control flows into
static graphs.
In stage 1, it took the students on average 50, 88, 135, 130 mins
trying to find inefficiencies in each of the four programs, and at
least 72 mins to refactor a program. In Stage 2, the time in finding
inefficiencies is reduced to 13‚Äì37 mins, and refactoring a program
took no more than 43 mins. As stage 2 happened after stage 1, the
familiarity to the code that the students had attained in stage 1
could have contributed to the reduction of the analysis and refactor-
ing times. But the significant increase of success rates in refactoring
offers evidences on the usefulness of HARP. The questionnairesaccompanied with the study provided further confirmations: All
students said that HARP was useful in helping them find valid opti-
mizations. One suggestion is to make HARP offer some examples
on the suggested optimizations.
5.4 Threats to Validity
Besides the possible bias in the user study mentioned earlier, this
part discusses two extra threats to validity. Our framework is evalu-ated based on Python 3.6, TensorFlow 1.5 and PyTorch 0.4.1. As new
versions are released, the APIs and the underlying implementation
may change, and invalidate the refactoring patterns or optimization
opportunities which are effective in the experiment. However, the
goal of our work is to provide a framework to ease the analysis
rather than to focus on particular patterns mentioned in this paper.
New patterns are easy to be included in the future.
Although the programs in the evaluation represent real-world
programs on Github, they cannot reflect the version in the process
of the development. Analyzing these programs cannot simulatehow our tool helps in the real programming process. HARP has
the potential to give suggestions during development of a program
through the integration in IDE; a detailed study is left for future.
6 RELATED WORK
There are some other work on suggesting optimizations to devel-
opers [ 6,26,27] on other programs, and many frameworks (e.g.,
XLA [ 18], TVM [ 4],Tensor Comprehension [ 36], Caffe [ 12]) for
Deep Learning optimizations. This current study distinctively fo-
cuses on the special barrier for optimizations of Python programs
that use modern machine learning libraries, and emphasizes holistic
treatment.
AutoGraph [ 25] and JANUS [ 11] create Deep Learning computa-
tion graphs from imperative Python code. HARP leverages a similar
idea in creating computation graphs for PyTorch code, but has a
different focus, identifying inefficiencies spanning across the bound-
aries of host code and libraries; the inefficiencies in the evaluation
section can be identified by neither AutoGraph nor JANUS.
A recent work [ 28] proposes a kind of intermediate representa-
tion called Weld IR to support optimizations across multiple libraries
and reported promising results. It focuses on the main computa-
tions represented in the libraries rather than the API misuses or the
interplay between the library calls and the host code. It requires
some manual changes to the library APIs such that their calls can
generate Weld IR at runtime. HARP, on the other hand, requires no
modifications to the library APIs.There is a body of work on declarative program analysis [ 2,14,
37]. Speculative analysis has been explored in some prior studies
on program optimizations. Lin and others [ 21] demonstrate that the
result of speculative alias analysis can enable speculative register
promotion. A recent work [ 34] uses several speculation techniques
in the implementation of a just-in-time compiler for R.
HARP receives inspirations from the prior work. It is distinctive
in being the first tool that enables holistic analysis of Python-based
analytics applications, and detects large-scoped inefficiency thatare elusive to existing solutions. It features novel insights on cir-
cumventing Python complexities, analytics-conscious speculative
analysis, the design of augmented computation graphs, and the in-
formative feedback scheme for risk controls.
7 CONCLUSION
The diverse programming paradigms and the reliance on high level
abstraction are common features of modern computing. They bring
challenges to the program analysis and optimizations. Current
optimizers are limited in their views of the libraries, and lack the
abilities to analyze across the mixed program models or to utilize
high level domain knowledge. We believe that an efficient system
to overcome these shortcomings needs to be able to synthesize
knowledge from difference aspects of the applications of the target
libraries. And a friendly interface for encoding high-level semanticsof abstractions is essential. HARP is a step towards a more effective
approach to advanced analysis for modern applications. It proves
effective in analyzing machine learning programs, helping identify
the subtle optimization opportunities for the applications. Further
development directions include extending this method to a broader
range of libraries and programming frameworks, and combining
the approach with runtime analysis and optimization techniques.
ACKNOWLEDGMENT
This material is based upon work supported by the National Science
Foundation (NSF) under Grant No. CCF-1525609 and CCF-1703487.
Any opinions, findings, and conclusions or recommendations ex-
pressed in this material are those of the authors and do not neces-
sarily reflect the views of NSF.
REFERENCES
[1]Mart√≠n Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey
Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et al .
2016. TensorFlow: A System for Large-Scale Machine Learning.. In OSDI, Vol. 16.
265‚Äì283.
[2]Martin Bravenboer and Yannis Smaragdakis. 2009. Strictly Declarative Spec-
ification of Sophisticated Points-to Analyses. In Proceedings of the 24th ACM
SIGPLAN Conference on Object Oriented Programming Systems Languages and
Applications (Orlando, Florida, USA) (OOPSLA ‚Äô09). ACM, New York, NY, USA,
243‚Äì262. https://doi.org/10.1145/1640089.1640108
[3]Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schul-
man, Jie Tang, and Wojciech Zaremba. 2016. OpenAI Gym. arXiv preprint
arXiv:1606.01540 (2016).
[4]Tianqi Chen, Thierry Moreau, Ziheng Jiang, Haichen Shen, Eddie Q. Yan, Leyuan
Wang, Yuwei Hu, Luis Ceze, Carlos Guestrin, and Arvind Krishnamurthy. 2018.
TVM: End-to-End Optimization Stack for Deep Learning. CoRR abs/1802.04799
(2018). arXiv:1802.04799 http://arxiv.org/abs/1802.04799
[5]Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus En-
zweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele. 2016.
The cityscapes dataset for semantic urban scene understanding. In Proceedings of
the IEEE conference on computer vision and pattern recognition. 3213‚Äì3223.
[6]Luca Della Toffola, Michael Pradel, and Thomas R Gross. 2015. Performance
problems you can fix: A dynamic analysis of memoization opportunities. In ACM
516ICSE ‚Äô20, May 23‚Äì29, 2020, Seoul, Republic of Korea Weijie Zhou, Yue Zhao, Guoqiang Zhang, and Xipeng Shen
SIGPLAN Notices, Vol. 50. ACM, 607‚Äì622.
[7]TensorFlow developers. 2016. Implementation of Control Flow in TensorFlow.
Technical Report.
[8]Facebook and Microsoft. 2018. Open Neural Network Exchange. https://onnx.ai/.
[9]Leon A Gatys, Alexander S Ecker, and Matthias Bethge. 2015. A neural algorithm
of artistic style. arXiv preprint arXiv:1508.06576 (2015).
[10] Geoffrey E Hinton. 2012. A practical guide to training restricted Boltzmann
machines. In Neural networks: Tricks of the trade. Springer, 599‚Äì619.
[11] Eunji Jeong, Sungwoo Cho, Gyeong-In Yu, Joo Seong Jeong, Dong-Jin Shin,
Taebum Kim, and Byung-Gon Chun. 2019. Speculative Symbolic Graph Execution
of Imperative Deep Learning Programs. ACM SIGOPS Operating Systems Review
53, 1 (jul 2019), 26‚Äì33. https://doi.org/10.1145/3352020.3352025
[12] Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan Long,
Ross Girshick, Sergio Guadarrama, and Trevor Darrell. 2014. Caffe: Convolu-
tional architecture for fast feature embedding. In Proceedings of the 22nd ACM
international conference on Multimedia. ACM, 675‚Äì678.
[13] Wesley M. Johnston, J. R. Paul Hanna, and Richard J. Millar. 2004. Advances in
Dataflow Programming Languages. ACM Comput. Surv. 36, 1 (March 2004), 1‚Äì34.
https://doi.org/10.1145/1013208.1013209
[14] JTransformer. 2018. The JTransformer project. http://sewiki.iai.uni-bonn.de/
research/jtransformer/.
[15] Arthur Juliani. 2018. Deep Reinforcement Learning Agents. https://github.com/
awjuliani/DeepRL-Agents.
[16] Andrej Karpathy. 2015. The unreasonable effectiveness of recurrent neural
networks. Andrej Karpathy blog (2015).
[17] Andrej Karpathy. 2016. Shakespeare Work. https://cs.stanford.edu/people/
karpathy/char-rnn/shakespear.txt. Accessed: 2018-4-16.
[18] Chris Leary and Todd Wang. 2017. XLA: TensorFlow, compiled. TensorFlow Dev
Summit (2017).
[19] Yann LeCun, Corinna Cortes, and CJ Burges. 2010. MNIST handwritten digit
database. AT&T Labs [Online]. Available: http://yann. lecun. com/exdb/mnist 2
(2010).
[20] Chen Liang. 2018. Char-RNN implemented using TensorFlow. https://github.
com/crazydonkey200/tensorflow-char-rnn.
[21] Jin Lin, Tong Chen, Wei-Chung Hsu, Pen-Chung Yew, Roy Dz-Ching Ju, Tin-Fook
Ngai, and Sun Chan. 2003. A Compiler Framework for Speculative Analysis and
Optimizations. In Proceedings of the ACM SIGPLAN 2003 Conference on Program-
ming Language Design and Implementation (San Diego, California, USA) (PLDI
‚Äô03). ACM, New York, NY, USA, 289‚Äì299. https://doi.org/10.1145/781131.781164
[22] Peng Liu. 2018. RBM/DBN implementation with tensorflow. https://github.com/
myme5261314/dbn_tf.
[23] Magnus Madsen, Ming-Ho Yee, and Ond≈ô ej Lhot√°k. 2016. From Datalog to Flix:
A Declarative Language for Fixed Points on Lattices. In Proceedings of the 37th
ACM SIGPLAN Conference on Programming Language Design and Implementation
(Santa Barbara, CA, USA) (PLDI ‚Äô16). ACM, New York, NY, USA, 194‚Äì208. https:
//doi.org/10.1145/2908080.2908096
[24] Shahin Mahdizadehaghdam, Ashkan Panahi, Hamid Krim, and Liyi Dai. 2018.Deep Dictionary Learning: A PARametric NETwork Approach. (2018). https:
//doi.org/arXiv:1803.04022[25] Dan Moldovan, James M Decker, Fei Wang, Andrew A Johnson, Brian K Lee,
Zachary Nado, D Sculley, Tiark Rompf, and Alexander B Wiltschko. 2018. Au-
toGraph: Imperative-style Coding with Graph-based Performance. (oct 2018).
arXiv:1810.08061 http://arxiv.org/abs/1810.08061
[26] Adrian Nistor, Linhai Song, Darko Marinov, and Shan Lu. 2013. Toddler: Detecting
performance problems via similar memory-access patterns. In Proceedings of the
2013 International Conference on Software Engineering. IEEE Press, 562‚Äì571.
[27] Oswaldo Olivo, Isil Dillig, and Calvin Lin. 2015. Static detection of asymptotic
performance bugs in collection traversals. In ACM SIGPLAN Notices, Vol. 50.
ACM, 369‚Äì378.
[28] Shoumik Palkar, James J Thomas, Anil Shanbhag, Deepak Narayanan, HolgerPirk, Malte Schwarzkopf, Saman Amarasinghe, Matei Zaharia, and Stanford
InfoLab. 2017. Weld: A common runtime for high performance data analytics. In
Conference on Innovative Data Systems Research (CIDR).
[29] Adam Paszke, Sam Gross, Soumith Chintala, and Gregory Chanan. 2017. Pytorch.
[30] Magnus Erik Hvass Pedersen. 2018. TensorFlow Tutorials. https://github.com/
Hvass-Labs/TensorFlow-Tutorials.
[31] Benoƒ±t Pradelle, Benoƒ±t Meister, Muthu Baskaran, Jonathan Springer, and RichardLethin. 2017. Polyhedral Optimization of TensorFlow Computation Graphs. In 6th
Workshop on Extreme-scale Programming Tools (ESPT-2017) at The International
Conference for High Performance Computing, Networking, Storage and Analysis
(SC17).
[32] Jonathan Schler, Moshe Koppel, Shlomo Argamon, and James W Pennebaker. 2006.Effects of age and gender on blogging.. In AAAI spring symposium: Computational
approaches to analyzing weblogs, Vol. 6. 199‚Äì205.
[33] Open source. 2018. Jedi - an awesome autocompletion/static analysis library for
Python. https://jedi.readthedocs.io/en/latest/
[34] Lukas Stadler, Adam Welc, Christian Humer, and Mick Jordan. 2016. Optimizing
R Language Execution via Aggressive Speculation. In Proceedings of the 12th
Symposium on Dynamic Languages (Amsterdam, Netherlands) (DLS 2016). ACM,
New York, NY, USA, 84‚Äì95. https://doi.org/10.1145/2989225.2989236
[35] Hado Van Hasselt, Arthur Guez, and David Silver. 2016. Deep Reinforcement
Learning with Double Q-Learning.. In AAAI, Vol. 16. 2094‚Äì2100.
[36] Nicolas Vasilache, Oleksandr Zinenko, Theodoros Theodoridis, Priya Goyal,
Zachary DeVito, William S. Moses, Sven Verdoolaege, Andrew Adams, and Albert
Cohen. 2018. Tensor Comprehensions: Framework-Agnostic High-Performance
Machine Learning Abstractions. CoRR abs/1802.04730 (2018). arXiv:1802.04730
http://arxiv.org/abs/1802.04730
[37] Mathieu Verbaere, Ran Ettinger, and Oege de Moor. 2006. JunGL: A scriptinglanguage for refactoring. In Proceedings of the 28th international conference on
Software engineering. ACM, 172‚Äì181.
[38] John Whaley, Dzintars Avots, Michael Carbin, and Monica S. Lam. 2005. Using
Datalog with Binary Decision Diagrams for Program Analysis. In Proceedings of
the Third Asian Conference on Programming Languages and Systems (Tsukuba,
Japan) (APLAS‚Äô05). Springer-Verlag, Berlin, Heidelberg, 97‚Äì118.
[39] Jan Wielemaker, Tom Schrijvers, Markus Triska, and Torbj√∂rn Lager. 2012. SWI-
Prolog. Theory and Practice of Logic Programming 12, 1-2 (2012), 67‚Äì96.
[40] Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. 2017. UnpairedImage-to-Image Translation using Cycle-Consistent Adversarial Networks. In
Computer Vision (ICCV), 2017 IEEE International Conference on.
517