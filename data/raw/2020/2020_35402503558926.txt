COREQQA: A COmplianceREQuirements Understanding using
Question Answering Tool
Sallam Abualhaija
sallam.abualhaija@uni.lu
University ofLuxembourg
LuxembourgChetanArora
chetan.arora@deakin.edu.au
DeakinUniversity
AustraliaLionelC.Briand
lionel.briand@uni.lu
University ofLuxembourg
Luxembourg
& University ofOttawa
Canada
ABSTRACT
We introduce COREQQA, a tool for assisting requirements engi-
neers in acquiring a better understanding of compliance require-
ments by means of automated Question Answering. Extracting
compliance-related requirements by manually navigating through
alegal document is both time-consumingand error-prone.CORE-
QQA enables requirements engineers to pose questions in natu-
ral language about a compliance-related topic given some legal
document,e.g.,askingabout databreach .Thetoolthenautomat-
ically navigates through the legal document and returns to the
requirements engineer alist oftext passages containingthe possi-
ble answers to the input question. For better readability, the tool
also highlights the likely answers in these passages. The engi-
neer can then use this output for specifying compliance require-
ments. COREQQA is developed using advanced large-scale lan-
guagemodelsfromBERT‚Äôsfamily.COREQQAhasbeenevaluated
onfourlegaldocuments.Theresultsofthisevaluationarebriefly
presented in the paper. The tool is publicly available on Zenodo
(https://doi.org/10.5281/zenodo.6653514 ).
CCSCONCEPTS
¬∑Software and its engineering ‚ÜíRequirements analysis ;¬∑
Computing methodologies ‚ÜíInformationextraction .
KEYWORDS
RequirementsEngineering (RE),RegulatoryCompliance,Natural
LanguageProcessing(NLP),QuestionAnswering,LanguageModels
(LMs),BERT.
ACM ReferenceFormat:
SallamAbualhaija,ChetanArora,andLionelC.Briand.2022.COREQQA:A
COmplianceREQuirementsUnderstandingusingQuestionAnsweringTool.
InProceedings of the 30th ACM Joint European Software Engineering Confer-
ence and Symposium on the Foundations of Software Engineering (ESEC/FSE
‚Äô22), November 14≈õ18, 2022, Singapore, Singapore. ACM, New York, NY, USA,
5pages.https://doi.org/10.1145/3540250.3558926
ESEC/FSE ‚Äô22,November 14≈õ18, 2022, Singapore, Singapore
¬©2022 Copyright held bytheowner/author(s).
ACM ISBN978-1-4503-9413-0/22/11.
https://doi.org/10.1145/3540250.35589261 INTRODUCTION
With the growing reliance on personal data and confidential in-
formation,softwaresystemsareincreasinglysubjecttocompliance
against regulations to enforce necessary safeguards for informa-
tionprotectionandhumansafety[ 13,16].Failingtocomplywith
relevantregulationscanleadtolegal,fiscalorreputationalimpli-
cations for an organization. Regulatory compliance is regarded as
an essential yet challenging task by the Requirements Engineering
(RE) community [ 5,18,21].
In this paper, we propose the tool COREQQA ( Compliance
Requirements Understanding using QuestionAnswering). CORE-
QQA is motivated by actual practical needs, considering that re-
quirementsengineersarebeingincreasinglyinvolvedinsoftware
compliance against relevant regulations, e.g., all software systems
inEuropemust comply withGDPR (Regulation(EU)2016/679)≈õ
the European regulationon dataprotection, privacy andpersonal
datatransfer [ 11].Manuallyhandlingcompliancerequirementsis
tedious and error-prone since requirements engineers have to read
through entire legal documents. Such documents are usually hefty,
containcomplicatednaturallanguage(NL)structures,frequently
refer to external regulations, and are not easy to peruse without
legalexpertise [ 2,20].
An automated Question Answering (QA) tool such as CORE-
QQA helps requirements engineers efficiently navigate through
the compliance-related content of legal documents. QAisthe task
of automatically finding the answer to a question posed in NL
from a given text passage. In our work, we refer to a single text
passage as a context span . Instead of reviewing long, complex le-
galdocuments, COREQQA enables requirements engineers toask
a question about a compliance-related topic, and then returns a
list of relevant context spans in which the answer is likely to be
found. This way, COREQQA pinpoints the requirements engineers
to the portions of the legal document where they need to invest
theirefforts andtime.
We illustrate inFigure 1, the QAassistanceprovided byCORE-
QQAtoarequirementsengineer,whoisinterestedinunderstanding
the regulations related topersonal data breach. The example ques-
tionisspecificallyrelatedtotheprocessforhandlingpersonaldata
breaches.TheanswertothisquestionisminedintheGDPRtext.
The legal obligations with regard to handling data breaches can
have a significant impact on the software development process,
e.g., sending notifications to different responsible agents within
legally-binding time constraints. COREQQA assists the require-
ments engineer in retrieving relevant information to define the
This work is licensed under a Creative Commons Attribution-
NonCommercial 4.0 InternationalLicense.
1682
ESEC/FSE ‚Äô22, November14≈õ18, 2022,Singapore, Singapore Sallam Abualhaija, ChetanArora,andLionel Briand
  When the personal data breach is 
likely to result in a high risk to the 
rights and freedoms of natural 
persons, the controller shall 
communicate the personal data 
breach to the data subject without 
undue delay . (‚Ä¶)
As soon as the controller becomes 
aware that a personal data breach 
has occurred, the controller should 
notify the personal data breach to 
the supervisory authority  without 
undue delay and , where feasible, 
not later than 72 hours after having 
become aware of it (‚Ä¶)
The controller should communicate 
to the data subject a personal data 
breach , without undue delay , where 
that personal data breach is likely to 
result in a high risk to the rights and 
freedoms of the natural person in 
order to allow him or her to take the 
necessary precautions (‚Ä¶)Relevant Context Span #1
What is the procedure for 
handling personal data 
breach?
Requirements
 Engineer
Relevant Context Span #2 Relevant Context Span #3
Requirements
 Engineer
Regulation (EU) 2016/679 - 
GDPR Document
Figure 1: Example of COREQQA‚Äôs QA assistance on
GDPR [11].
respective compliance requirements for handling data breaches
for the software system under development. As we elaborate in
Section2, COREQQA returns as output the top- ùëÅ1relevant con-
textspansfromagiven legal documentandthe potential answers
highlightedin the context spans. COREQQA builds onlarge-scale
natural language processing (NLP) language models for solving
the QA task (also widely known as machine reading comprehension
(MRC) task [14]). QA models for MRC generally assume that for
each question, the relevant context span (containing the answer) is
knownapriori.DevelopingapracticalQAtoolwiththisrestriction
is infeasible, as requirements engineers have no means of know-
ing the exact context span with the correct answer in advance.
Therefore,inCOREQAAwefirstfindtop- ùëÅrelevantcontextspans
whichlikelycontaintheanswer.Todoso,wecomputethesemantic
similarity between each context span in the legal document and
the input question. Then, we demarcate the answer to the input
questionusing the QA models.
Wefurtherobservethatinformationrelevanttoansweringthe
question could be found in multiple non-contiguous context spans
(i.e.,differentsectionsinthesamelegaldocument).Forexample,the
top-3 context spans selected in Figure 1are all directly relevant for
answering the question. The first two spans (retrieved from differ-
entsectionsofthedocument)explaintheprocessofcommunicating
breachdetailstothedatasubject,whilethethirdspanspecifieshow
tocommunicatebreachdetailstothesupervisoryauthorities.Thus,
byretrievingmultiplerelevantspans andfurtherhighlightingthe
likelyanswers,COREQQAenablestherequirementsengineerto
specify a complete and precise set of compliance requirements. We
leave configuring the ùëÅparameter to the requirements engineer.
While selecting higher values of ùëÅentails more time and effort for
1ùëÅisaconfigurableparameterandisset ùëÅ=3fortheexamplequestioninthefigurereviewingtheretrievedcontextspans,webelievethatusingCORE-
QQA is still much more cost-effective in practice than manually
traversingthe entire legal document for the answer.
In the remainder of this tool demonstration paper, we elabo-
ratethearchitectureofthetool,thedatasetthatwegeneratedfor
developingCOREQQA as well as an end-to-endusage scenario.
2 TOOL ARCHITECTURE
Theend-to-endarchitectureofCOREQQAisillustratedinFig-
ure2.COREQQAaimsatansweringagivenquestionposedbya
requirementsengineerinNLonsomelegaldocument.Below,we
elaboratethemainstepsofthetoolmarkedas1≈õ3inFigure 2.We
implementedCOREQQA inPython3.8.
2.1 Text Preprocessing
In the first step, COREQQA parses the legal document and applies
a simpleNLP pipeline which is composedof tokenization and sen-
tencesplitting.Thetoolthenappliesasetofregularexpressions
for normalizing the text (e.g., removing periods from the ending of
acronyms,≈ÇArt.≈æbecomes≈ÇArt≈æ).Themotivationfornormalizing
the text is to improve the accuracy of sentence splitting. We opera-
tionalize the NLP pipeline using NLTK library [ 6,17], and the re
modulein Python for regular expressions2. In this step, we further
partitionthelegaldocumentintocontextspans.Duetotechnical
constraints of underlying QA models, the maximum size of each
context span is 512 tokens. To maintain coherence, we split the
document into paragraphs first, and then check their size. Each
paragraph fitting this size limitation is regarded as one context
span. Otherwise, we split the paragraph into half, and check the
size again. This process is iteratively performed until size limita-
tions are met. The output of this step is the list of context spans
representing the inputlegal document.
2.2 Relevant Context Retrieval
In the second step, COREQQA computes the semantic similar-
ity between the input question and each context span generated
from the previous step. We implement this step using the BERT
cross-encoder(BCE)modelavailableintheSentence-Transformer
2.1.0 [19] provided by Hugging Face3. BCE takes as input two text
fragments,andreturnsasoutputascorebetween0and1indicating
how semantically similar the two fragments are, with 1 being iden-
tical. To assess the relevance of the context span, we first compute
BCEbetweenthequestionandeachsentenceinthecontextspan
andthenassigntothecontextspanthemaximumscoreachieved
by any sentence. The intuition behind this computation strategy is
thatonlyaportionofthecontextspanisexpectedtocontainthe
likely answer to the inputquestion.
Oncewecomputeascorepercontextspan,werankthespansin
descendingorder.Wedothisusingthesortfunctionfrom pandas
inPython4.Theresultofthisstepisalistoftop- ùëÅrelevantcontext
spanstotheinputquestion.Wekeepthevalue Nasaparameter
thatcanbeinitializedbytherequirementsengineer.Thevalueof
ùëÅdepends on the practical context in which COREQQA is applied.
2https://docs/python.org/3.8/library/re/
3https://huggingface.co/
4https://pandas.pydata.org
1683COREQQA:A COmplianceREQuirements UnderstandingusingQuestion AnsweringTool ESEC/FSE ‚Äô22, November14≈õ18, 2022,Singapore, Singapore
Legal Document
Requirements 
EngineerQUESTION?
Text Preprocessing and Partitioning1TokenizeationSentence SplittingNormalizationREGEX (.*)Context Span Generation
CONTEXT 
SPANSRELEVANT 
CONTEXT SPANS CONTEXTs & 
ANSWERs C1, A1
CN, ANPOSSIBLE ANSWERS
Answer ExtractionAnswer DemarcatorRoBERTa-QA
Relevant Context RetrievalRankingSelection
Similarity Computation$N
BCEReview
2 34Final Output 
Representation
Figure 2:Overview oftheend-to-endarchitecture ofCOREQQA.
Selectinglargevalues(e.g., ‚â•10)entailsthattherequirementsengi-
neerwillreviewmanycontextspanstogainabetterunderstanding
ofthecompliancerequirementsassociatedwiththequestion.Se-
lecting small ùëÅvalues (e.g., ‚â§3) entails less context spans to be
reviewed,butalsoahigherriskfortherightanswernottobefound
inanyofthetop- ùëÅrelevantspans.InFigure 1,weshowanexample
oftop-3contextspansretrievedinthisstep.Thedefaultvalueof
the configurable parameter ùëÅis set to 5 in COREQQA, based on
previous experiments [ 2].
2.3 AnswerExtraction
Inthelaststep,wepassonthetop- ùëÅcontextspansdeemedrelevant
in the previous step together with the input question to a pre-
trained QA model. In our work, we apply the Transformers library
toextractanswersforthegivenquestionusingtheRoBERTaQA
model(roberta-base-squad2-distilled ). RoBERTathenextractsfrom
each context span a potential answer for the input question. In
Figure1,wehighlighttheextractedanswersingreen.Wenotethat
theengineerhasaccesstothecontextspansalreadyintheprevious
step. Thus, this step is not essential for providing assistance to the
requirementsengineerinunderstandingthequestionsrelatedto
compliance requirements. However, highlighting the answer in the
context span improves readability and leads to a more efficient
reviewingprocess.Inpractice,whentheengineerselectsalarger
numberùëÅ(say10),itisthenadvantageoustodemarcatetheanswer
automatically to help the engineer quickly navigate through the
contextspans.
2.4 Final OutputRepresentation
For presenting the final output of the tool to the requirements
engineer, we export for each question the top- ùëÅcontext spans
and the highlighted answers within these context spans as a Mi-
crosoftWorddocument.Thedocumentalsoshowsforeachcontextspanaconfidencescore(range0≈õ1)oftheanswerhighlightedin
the span. This confidence score is automatically assigned to the
extracted answer by the QA model. We use the python-docx li-
brary v0.8.11 ( https://python-docx.readthedocs.io ) for exporting
the output and visualizing highlighted answers in the relevant
top-ùëÅcontextspans.
3 EVALUATION
COREQQAhasbeenevaluatedonfourlegaldocuments,wherein
the question-answer pairs were identified by two experts ≈õ one
expert in legal informatics and the other in requirements engineer-
ing[2]. In the following, we describe the fourdocuments:
‚Ä¢GDPRorGeneralDataProtectionRegulation(EU)2016/679isthe
European privacy law that harmonises the data protection, privacy
andpersonaldatatransferrequirements[ 11].Theexpertsidentified
36 question-answer pairs from the entire document. The document
waspartitionedin301contextspansbythe≈ÇTextPreprocessing≈æ
step ofFigure 2.
‚Ä¢Directive (EU) 2019/770 is the European directive for regulat-
ing the supply of digital content or digital services, and laying
down rules for contracts between any trader and consumer of
digital content or service [ 9]. The experts identified 33 question-
answer pairs in this document, and the document was split into
120contextspans.
‚Ä¢Directive(EU)2019/771 istheEuropeandirectiveconcerningthe
sale of goods [ 10]. Directive (EU) 2019/771 complements Directive
(EU)2019/770,asitformalisesthecontractsonthesaleofgoodsthat
contain digital elements that require digital content or service. For
example,theregulationsrelatedtothecontractsofthesmartphone
arecoveredbyDirective(EU)2019/771,whereastheregulationsfor
operating systems or apps on the smartphone might be covered by
Directive (EU) 2019/770. The experts identified 19 question-answer
1684ESEC/FSE ‚Äô22, November14≈õ18, 2022,Singapore, Singapore Sallam Abualhaija, ChetanArora,andLionel Briand
pairsinDirective(EU)2019/771,andthedocumenttextwassplit
into102contextspans.
‚Ä¢Luxembourg Law of 25 March 2020 is an amendment to nu-
merous existing finance and banking related laws in Luxembourg.
Theamendmentwasintendedtosetduediligencemeasuresfora
centralelectronicdataretrievalsystemrelatedtobankaccountsand
safe-depositboxesinLuxembourg,andwasasteptowardstackling
moneylaundering[ 1].Theexpertsidentified19question-answer
pairsinthislegaldocument.Thedocumenttextwassplitinto23
contextspans.
To identify the most accurate similarity metric for context span
retrieval,wecomparedBCE(Section 2.2)withTF-IDFsimilarity[ 3]
≈õametriccommonlyusedintheNLPdomain.BCEwassignificantly
moreaccuratethanTF-IDFinourexperiments.Overall,fromthe
107questionsoverthefourdocuments,BCEretrievesthecorrect
context span for 100 questions (for the top- 5spans). In addition to
RoBERTa,wefurtherevaluatedthreeQAmodels,namelyBERT[ 8],
ALBERT [ 15], ELECTRA [ 7] for answer extraction (Section 2.3).
RoBERTawasdeemedthemostaccurateasitcorrectlyextracted
the answers for 97 questions.
WealsoanalyzedthequestionswhereCOREQQAdidnothighly
rankthecorrectcontextspan(withintop-5)orRoBERTamodeldid
notextractthecorrectanswer.Ouranalysisshowedthatgeneric
questions, such astheones formulated for definingorelaborating
onalegalconcept,werenotcorrectlyanswered.Thisisbecausethe
legaldocument(orevenagivencontextspan)wouldusuallycontain
severalinstancesofsuchlegalconcept,thusmisleadingboththe
contextspanretrievalandanswerextractionstepsofCOREQQA.
Wealsorealizedthatcomplicatedquestions(e.g.,withcomposite
conditions)were difficult to answer for COREQQA.
Lastbut not least, COREQQA answers questions within reason-
ableexecutiontime.Thus,inshort,ourevaluationindicatesthat
COREQQAproducesaccurateresultsandisfitforusebyrequire-
ments engineers in practice. For answering one question from a
legaldocument includinganaverageof 620sentences,COREQQA
requires atotalof ‚âà34 seconds.
4 USAGESCENARIO
Inthissection,wedescribeanend-to-endexampleillustrating
howourtoolcanbeappliedinpracticebyarequirementsengineer.
LetKoopaApp be a new system under development. KoopaApp is a
gymfitnessappformaintainingusers‚Äôworkoutinformationand
otherhealth-relateddata.KoopaAppaccessespersonalinformation
such as the location from other apps on the users‚Äô smartphone.
Duringthepandemic,suchapplicationsoftenraisedconcernsabout
privacy. Forexample, several health applications were analyzedfor
privacy-relatedissuesinthe RE literature [ 4,12].
Arequirementsengineer( Daisy)isinchargeofspecifyingthe
KoopaApprequirements,includingcompliancerequirements.As
an example, we focus only on a subset of compliance requirements
relatedtoprivacyanddataprotection.Daisy(asisoftenthecase
in most software projects) is not very familiar with the privacy
regulations, yet she knows well the functionalities and characteris-
ticsoftheKoopaApp.Duringtheelicitationofrequirements,Daisy
identifiesasetoffunctionalitiesthatmakeuseofpersonaldataandare thus subject to compliance. Some of these functionalities are
relatedtothesecurityofcollectedpersonal data.We assumehere
thatDaisyorherteamareawareoftherelevantlegaldocumentsfor
theirproject.Suggestingrelevantdocumentsisbeyondthescope
ofCOREQQA.Accountingtopossiblesecuritythreats,Daisyposes
a question (≈ÇWhat is the procedure for handling a personal data
breach?≈æ) using the COREQQA tool on the GDPR [ 11]. COREQQA
inturnprovidesthe outputshowninFigure 1.
From the output of COREQQA, Daisy is able to formulate the
followingcompliancerequirements(prefixedwiththeID ùê∂ùëÖ)under
the labelUsers Data Breach .
NotifyUsersabouttheData Breach.
ùê∂ùëÖ1.If a data breach is identified on the KoopaApp server, the
KoopaApp-NotifyService shallinformthe affectedusers.
ùê∂ùëÖ2.TheKoopaApp-NotifyServiceshallemailtheaffecteduserson
theregisteredemailaddressandstorethe‚Äòuserinformed‚Äôresponse
onthe server.
ùê∂ùëÖ3.TheKoopaApp-NotifyServiceshallnotifytheaffectedusers
onthe app andstore the ‚Äòread‚Äôresponse onthe server.
NotifytheCIO aboutthe Data Breach.
ùê∂ùëÖ4.If a data breach is identified on the KoopaApp server, the
KoopaApp-NotifyService shall send an email to the Chief Informa-
tion Officer notifying the breach, within 72 hours of its occurrence.
The four compliance requirements fulfill the regulations pro-
videdinFigure 1.
5 CONCLUSION
WepresentedCOREQQA≈õatoolforassistingrequirementsengi-
neers in better understanding compliance requirements through
question-answeringbasedonregulatoryorlegaldocuments.CORE-
QQA is developed using a manually created dataset that combines
a joint effort of a requirements engineer and a legal expert over
four diverse legal documents. The tool is based on recent large-
scale language models that are pre-trained for question-answering.
Specifically,thetoolappliestheSentenceBERTcrossencoderfor
retrievingthemostrelevanttextpassagesfromalegaldocumentfor
a given question. The tool further employs the RoBERTa question-
answeringmodelforhighlightingthelikelyanswerstothequestion
inthe retrievedtextpassages.
In future,we plantoconduct auserstudy toassesshow useful
COREQQA isinpractice.
ACKNOWLEDGMENTS
This paper was supported by Central Legislative Service (SCL) ≈õ
GovernmentofLuxembourg,theLuxembourgNationalResearch
Fund (FNR) under grants PUBLIC2-17/IS/11801776, and by NSERC
ofCanadaunderthe Discovery andCRC programs.
REFERENCES
[1]2020. Lawof25March2020(coordinatedversion)establishingacentralelectronic
dataretrievalsystemrelatedtoIBANaccountsandsafe-depositboxes. https:
//www.cssf.lu/en/Document/law-of-25-march-2020-data-retrieval/
[2]Sallam Abualhaija, Chetan Arora, Amin Sleimi, and Lionel Briand. 2022. Au-
tomated Question Answering for Improved Understanding of Compliance Re-
quirements:AMulti-DocumentStudy.In 30thIEEEInternationalRequirements
Engineering Conference (RE‚Äô22) .
[3]AkikoAizawa.2003. Aninformation-theoreticperspectiveoftf≈õidfmeasures.
Information Processing & Management 39, 1 (2003), 45≈õ65. https://doi.org/10.
1016/S0306-4573(02)00021-3
1685COREQQA:A COmplianceREQuirements UnderstandingusingQuestion AnsweringTool ESEC/FSE ‚Äô22, November14≈õ18, 2022,Singapore, Singapore
[4]Muneera Bano, Chetan Arora, Didar Zowghi, and Alessio Ferrari. 2021. The Rise
and Fall of COVID-19 Contact-Tracing Apps: when NFRs Collide with Pandemic.
In2021IEEE29thInternationalRequirementsEngineeringConference(RE) .IEEE,
106≈õ116. https://doi.org/10.1109/RE51729.2021.00017
[5]Brian Berenbach, Daniel J Paulish, Juergen Kazmeier, and Arnold Rudorfer. 2009.
Software&systemsrequirementsengineering:inpractice . McGraw-HillEducation.
[6]Steven Bird, Ewan Klein,and EdwardLoper.2009. NaturalLanguage Processing
with Python . O‚ÄôReilly.
[7]Kevin Clark, Minh-Thang Luong, Quoc V. Le, and Christopher D. Manning.
2020. ELECTRA: Pre-training Text Encoders as Discriminators Rather Than
Generators. CoRRabs/2003.10555 (2020). https://doi.org/10.48550/arXiv.2003.
10555arXiv:2003.10555
[8]Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018.
BERT: Pre-training of Deep Bidirectional Transformers for Language Under-
standing. CoRRabs/1810.04805(2018). https://doi.org/10.48550/arXiv.1810.04805
arXiv:1810.04805
[9]EU (2019/770). 2019. Directive (EU) 2019/770 of the European Parliament and
oftheCouncilof20May2019oncertainaspectsconcerningcontractsforthe
supply of digital content and digital services, OJL 136,22.5.2019, p.1≈õ27. http:
//data.europa.eu/eli/dir/2019/770/oj
[10]EU (2019/771). 2019. Directive (EU) 2019/771 of the European Parliament and of
theCouncilof 20May 2019 on certainaspects concerning contractsforthesale
ofgoods,amendingRegulation(EU)2017/2394andDirective2009/22/EC,and
repealingDirective1999/44/EC,OJL136,22.5.2019,p.28≈õ50. http://data.europa.
eu/eli/dir/2019/771/oj
[11]EU (GDPR). 2016. Regulation (EU) 2016/679ofthe EuropeanParliament andof
the Council of 27 April 2016 on the protection of natural persons with regard
totheprocessingofpersonaldataandonthefreemovementofsuchdata,and
repealing Directive 95/46/EC (General Data Protection Regulation), OJ L 119,
4.5.2016, p. 1≈õ88. http://data.europa.eu/eli/reg/2016/679/oj
[12]Mattia Fazzini, Hourieh Khalajzadeh, Omar Haggag, Zhaoqing Li, Humphrey
Obie, Chetan Arora, Waqar Hussain, and John Grundy. 2022. CharacterizingHumanAspectsinReviewsofCOVID-19Apps.In 9thIEEE/ACMInternational
Conference on Mobile Software Engineering and Systems .https://doi.org/10.1145/
3524613.3527814
[13]Marijn Janssen, Paul Brous, Elsa Estevez, Luis S Barbosa, and Tomasz Janowski.
2020. Datagovernance:OrganizingdatafortrustworthyArtificialIntelligence.
Government Information Quarterly 37, 3 (2020), 101493. https://doi.org/10.1016/j.
giq.2020.101493
[14]DanJurafskyandJamesH.Martin.2020. SpeechandLanguageProcessing (3rd
ed.).https://web.stanford.edu/~jurafsky/slp3/ (visited on2022-01-04).
[15]Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush
Sharma, and Radu Soricut. 2019. ALBERT: A Lite BERT for Self-supervised
Learning of Language Representations. CoRRabs/1909.11942 (2019). https:
//doi.org/10.48550/arXiv.1909.11942 arXiv:1909.11942
[16]Dorothy E Leidner and Olgerta Tona. 2021. The CARE Theory of Dignity Amid
Personal DataDigitalization. MIS Quarterly 45,1 (2021).
[17]Edward Loper and Steven Bird. 2002. NLTK: The Natural Language Toolkit.
InProceedingsoftheACL-02WorkshoponEffectiveToolsandMethodologiesfor
TeachingNatural Language Processingand ComputationalLinguistics .
[18]Paul N Otto and Annie I Ant√≥n. 2007. Addressing legal requirements in require-
mentsengineering.In 15thIEEEinternationalrequirementsengineeringconference
(RE2007). IEEE,5≈õ14. https://doi.org/10.1109/RE.2007.65
[19]NilsReimersand IrynaGurevych.2019. Sentence-BERT:SentenceEmbeddings
using Siamese BERT-Networks. CoRRabs/1908.10084 (2019). https://doi.org/10.
48550/arXiv.1908.10084 arXiv:1908.10084
[20]AminSleimi,MarcelloCeci,NicolasSannier,MehrdadSabetzadeh,LionelBriand,
and John Dann. 2019. A Query System for Extracting Requirements-Related
InformationfromLegalTexts.In 27thIEEEInternationalRequirementsEngineering
Conference . IEEE.https://doi.org/10.1109/RE.2019.00041
[21]Amin Sleimi, Nicolas Sannier, Mehrdad Sabetzadeh, Lionel Briand, and John
Dann. 2018. Automated Extraction of Semantic Legal Metadata using Natural
Language Processing. In Proceedings ofthe26th IEEEInternational Requirements
Engineering Conference .https://doi.org/10.1109/re.2018.00022
1686