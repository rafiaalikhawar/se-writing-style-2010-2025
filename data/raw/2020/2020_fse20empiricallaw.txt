Fuzzing:On the ExponentialCost ofVulnerability Discovery
Marcel Böhme
Monash University, Australia
marcel.boehme@acm.orgBrandon Falk
GamozoLabs, LLC,USA
bfalk@gamozolabs.com
ABSTRACT
We present counterintuitive results for the scalability of fuzzing.
Given the same non-deterministic fuzzer, finding the same bugs
linearly fasterrequireslinearly more machines.For instance,with
twicethemachines,wecanfind allknownbugs inhalfthetime.Yet,
finding linearly more bugs in the same time requires exponentially
more machines. For instance, for every new bugwe want to find
in 24 hours, we might need twice more machines. Similarly for
coverage. With exponentially more machines, we can cover the
same code exponentially faster, but uncovered code only linearly
faster. In other words, re-discovering the same vulnerabilities is
cheap but finding new vulnerabilities is expensive. This holds even
underthe simplifying assumption of noparallelizationoverhead.
WederivetheseobservationsfromoverfourCPUyearsworth
of fuzzing campaigns involving almost three hundred open source
programs,twostate-of-the-artgreyboxfuzzers,fourmeasuresof
code coverage, and two measures of vulnerability discovery. We
provideaprobabilisticanalysisandconductsimulationexperiments
to explainthis phenomenon.
CCS CONCEPTS
•Software andits engineering →Software testing .
KEYWORDS
softwaretesting,scalability,probabilisticanalysis,coveragefrontier
ACMReference Format:
MarcelBöhmeandBrandonFalk.2020.Fuzzing:OntheExponentialCostof
VulnerabilityDiscovery.In Proceedingsofthe28thACMJointEuropeanSoft-
ware Engineering Conference and Symposium on the Foundations of Software
Engineering (ESEC/FSE ’20), November 8ś13, 2020, Virtual Event, USA. ACM,
NewYork, NY, USA, 12pages.https://doi.org/10.1145/3368089.3409729
1 INTRODUCTION
Fuzzinghasbecomeoneofthemostsuccessfulvulnerabilitydiscov-
erytechniques.Forinstance,Googlehasbeencontinuouslyfuzzing
itsownsoftwareandopensourceprojectsonmorethan25,000ma-
chines since December 2016 and found about 16k bugs in Chrome
and11kbugsinover 160OSS projectsÐonlybyfuzzing[ 25].
Thosebugsthatarefoundandreportedarefixed.Hence,lessnew
bugsarefoundwiththeavailableresources.Itwouldbereasonable
to increase the available resources to maintain a good bug finding
Permissionto make digitalor hard copies of allorpart ofthis work for personalor
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthefirstpage.Copyrights forcomponentsofthisworkownedbyothersthanthe
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or
republish,topostonserversortoredistributetolists,requirespriorspecificpermission
and/or a fee. Request permissions from permissions@acm.org.
ESEC/FSE ’20, November 8ś13, 2020, Virtual Event, USA
©2020 Copyright heldby the owner/author(s). Publicationrightslicensed to ACM.
ACM ISBN 978-1-4503-7043-1/20/11...$15.00
https://doi.org/10.1145/3368089.3409729
R^2=97.26%
Exponential Cost
1 2 4 8 16 3201234
#machines#Additional vulns discovered
Linear cost
1 2 4 8 16 32 64 1281 min5 min15 min1 hour6 hours
#machinesTime to expose same #vulns
Figure 1: Each vuln. discovery requires exponentially more
machines (left). Yet, exponentially more machines allow to
find thesamevulnerabilities exponentially faster (right).
rate.Sothen,howisanincreaseintheamountofavailableresources
relatedto an increaseinvulnerabilitydiscovery?
Suppose Google has stopped finding new bugs when fuzzing
their software systems on 25 thousand machines for one month.
So,Googledecidestoruntheirfuzzerson100xmore(2.5 million)
machines for one month, finding five (5) new criticalbugs. Once
thesearefixed,howmany unknown criticalbugswouldanattacker
findinamonththatwasrunningthesamefuzzersetupon5 million
machines? What if the attacker had 250 millionmachines? We
proposeanempiricallawthatwouldsuggestthattheattackerwith
2xmore(5million)machinesfindsanunknowncriticalbugwith
∼15% likelihood or less while the attacker with 100x more (250
million!) machines only finds five (5) unknown critical bugs or less.
Weconductedfuzzingexperimentsinvolvingoverthreehundred
opensourceprojects(incl.OSS-Fuzz[ 15],FTS[19]),twopopular
greyboxfuzzers( LibFuzzer [12]andAFL[ 26]),fourmeasuresof
code coverage ( LibFuzzer ’s feature and branch coverage as well as
AFL’s path and map/branch coverage) and two measures of vulner-
ability discovery (#known vulns. found and #crashing campaigns).
Fromtheobservations,wederiveempiricallaws,whichareaddi-
tionally supported and explained by our probabilistic analysis and
simulation experiments. An empirical law is a stated fact that is
derivedbasedonempirical observations (e.g.,Moore’slaw).
Wemeasurethecostofvulnerabilitydiscoveryasthenumber
of łmachinesž required to discoverthe next vulnerabilitywithin a
giventimebudget.The numberofmachines ismerelyanabstraction
of the number of inputs generated per minute. Twice the machines
cangeneratetwicetheinputsperminute.Conceptually,onefuzzing
campaignremains onecampaignwhereinputsarestillgenerated
sequentiallyÐonly#machinestimesasfast.Weassumeabsolutely
nosynchronizationoverhead.Formutation-basedfuzzers,anyseed
that is added to the corpus is immediately available to all other
machines. Notethat this gives usa lower bound on thecost ofvul-
nerability discovery: Our analysis is optimistic. If we took synchro-
nization overhead into account, the cost of vulnerability discovery
wouldfurther increasewiththe number of physical machines.
749ESEC/FSE ’20, November8–13,2020,VirtualEvent, USA MarcelBöhme andBrandon Falk
Our first empirical law suggests thata non-deterministic fuzzer
that generates exponentially more inputs per minute discovers
only linearly more vulnerabilities within a given time budget. This
meansthat(a)giventhesametimebudget,thecostforeachnew
vulnerability is exponentially more machines (cf. Fig. 1.left) and
(b)giventhesame#machines,thecostofeachnewvulnerability
isexponentiallymoretime.Infact,wecanshowthisalsoforthe
coverage of a new program statement or branch, the violation of a
newassertion, orany otherdiscrete program property ofinterest.
Our second empirical law suggests that a non-deterministic
fuzzerwhichgeneratesexponentiallymoreinputsperminutedis-
covers the same number of vulnerabilities also exponentially faster
(cf. Fig.1.right). This means if we want to find the same set of
vulnerabilitiesinhalfthetime,ourfuzzerinstanceonlyneedsto
generatetwice as manyinputsper minute(e.g.,on2x #machines).
Given the same time budget and non-deterministic fuzzer, an at-
tacker with exponentially more machines discovers a given known
vulnerability exponentially faster but some unknown vulnerability
onlylinearlyfaster.Similarly,withexponentiallymoremachines,
thesame code is covered exponentially faster, but uncovered code
onlylinearlyfaster.Inotherwords,re-discoveringthesamevulner-
abilities (or achieving the same coverage) is cheap but finding new
vulnerabilities(orachievingmorecoverage)isexpensive.Thisis
under the simplifying assumption of nosynchronization overhead.
Wemakeanattemptatexplainingourempiricalobservationsby
probabilisticallymodellingthefuzzingprocess.Startingfromthis
model, we conduct simulation experiments that generate graphs
thatturnoutquitesimilartothoseweobserveempirically.Wehope
thatourprobabilisticanalysisshedssomelightonthescalabilityof
fuzzingandthecostofvulnerabilitydiscovery:Whyisitexpensive
to cover newcode but cheap to cover the same code faster?
2 EMPIRICALSETUP
2.1 Research Questions
RQ.1Giventhesamenon-deterministicfuzzerandtime-budget,
what is the relationship between the number of available
machines andthe number ofadditional speciesdiscovered ?
RQ.2Giventhesamenon-deterministicfuzzerandtime-budget,
what is the relationship between the number of available
machinesandthe timetodiscoverthesamenumberofspecies ?
RQ.3Giventhesamenon-deterministicfuzzerandtime-budget,
whatistherelationshipbetweenthenumberofavailablema-
chines and the probability to discover a given (set of) species ?
We call our dependent variables as łspeciesž (explained in Sec. 2.4).
2.2 Non-DeterministicFuzzers
Forourexperiments,weusethetwomostpopularnon-deterministic,
coverage-based greybox fuzzers, LibFuzzer and AFL. Both fuzzers
recieve different kinds of coverage-feedback and implement dif-
ferent coverage-guided heuristics. LibFuzzer isa unit-levelfuzzer
whileAFL isasystem-level fuzzer.
LibFuzzer [12]isastate-of-the-artgreyboxfuzzerdeveloped
at Google and is fully integrated into the FTS and OSS-Fuzz bench-
marks.LibFuzzer is a coverage-based greybox fuzzer which seeks
to cover program łfeaturesž. Generated inputs that cover a new
feature are added to the seed corpus. A featureis a combination ofthebranchthatiscoveredandhowoftenitiscovered.Forinstance,
two inputs (exercising the same branches) have a different feature
set if one exercises a branch more often. Hence, feature coverage
subsumes branch coverage .LibFuzzer aborts the fuzzingcampaign
as soon as the first crash is found or upon expiry of a set time-
out.Inourexperiments,weleveragethedefaultconfigurationof
LibFuzzer if not otherwiserequiredbythe benchmark.
AFL[26]isoneofthemostpopulargreyboxfuzzers.Incontrast
toLibFuzzer ,AFLdoesnotrequireaspecificfuzzdriverandcanbe
directlyrunonthecommandlineinterface(CLI)ofaprogram.AFL
isacoverage-basedgreyboxfuzzerwhichseekstomaximizebranch
coverage.Generatedinputsthatexerciseanewbranch,orthesame
branch sufficiently more often, are added to the seed corpus. In
AFL terminology, the number of explored łpathsž is actually the
number ofseedsinthe seedcorpus.
2.3 BenchmarksandSubjects
We chose a wide range of open-source projects and real-world
benchmarks. Together, we generated more than four CPU years
worthofdatabyfuzzingalmostthreehundreddifferentopensource
programs from variousdomains.
OSS-Fuzz [15](263programs,58.3MLoC,6hours,4repetitions )
is an open-source fuzzing platform developed by Google for the
large-scale continuous fuzzing of security-critical software. At the
time of writing OSS-Fuzz featured 1,326 executable programs in
176open-sourceprojects.Weselected263programstotaling58.3
millionlinesofcodebychoosingsubjectsthatdidnotcrashorreach
the saturation point in the first few minutes and that generated
morethan1,000executionspersecond.Evenforthechosensubjects,
we noticed that the initial seed corpora provided by the project
areoftenforsaturation:Featurediscoveryhaseffectivelystopped
shortly after the beginning of the campaign. It does not give much
room for further discovery. Hence, we removed all initial seed
corporas.Weran LibFuzzer forallprogramsfor6hoursand,given
the large number ofsubjects,repeatedeachexperiment 4times.
FTS[20](25programs,2.0MLoC,6hours,20repetitions )isastan-
dard set of real-world programs used by Google to evaluate fuzzer
performance. The subjects are widely-used implementations of file
parsers, protocols,and data bases (e.g.,libpng,openssl, and sqlite),
amongst others. Each subject contains at least one known vulnera-
bility (CVE), some of which require weeks to be found. The Fuzzer
TestSuite(FTS)allowstocomparethecoverageachievedaswellas
thetimetofindthefirstcrashontheprovidedsubjects.Whenre-
porting coverage results, we removed those programs where more
than 15% of runs crash (leaving 13 programs with 1.2M LoC). As
LibFuzzer aborts when the first crash is found, the coverage re-
sults for those subjects would be unreliable. We set a 8GB memory
limitandran LibFuzzer for6hours.Togainstatisticalpower,we
repeatedeachexperiment 20 times.
Open-Source (6 programs, 6.1M LoC, 96 hours, 10 repetitions )
is a set of open-source programs from a wide range of domains,
includinganetworksniffer(wireshark)andavideoandaudiocodec
library (ffmpeg). We ran the default configuration of AFL on all
programsfor96hours,exceptforlibxml2,whereweranAFLfor
90 days,i.e.,2160 hours. We repeatedeachexperiment 10 times.
750Fuzzing: On the ExponentialCost of VulnerabilityDiscovery ESEC/FSE ’20, November8–13,2020,VirtualEvent, USA
2.4 VariablesandMeasures
Weexploreseveraldefinitionsofspeciesaslistedbelow.Wecollect
this information from the standard output of LibFuzzer and the
plot_data file of AFL. We vary one indepent variable (#machines)
andmeasure six dependent variables.
#Machines (#cores,#hyperthreads)isanabstractionofthenum-
ber of inputs the fuzzer can generate per minute. Twice the ma-
chinescangeneratetwicetheinputsperminute.Conceptually,this
isstillasinglefuzzingcampaignwhereinputsarestillgenerated
sequentially .Weassumeabsolutelynosynchronizationoverhead
andthatanydiscoveredseed,addedtothecorpus,is immediately
availabletoallothermachines.Notethatthisgivesusa lowerbound
on the cost of vulnerability discovery: Our analysis is optimistic.
Ifwetook synchronization overheadintoaccount,thecostofvul-
nerability discovery would further increase with the number of
physical machines.
Datascaling .Inordertovarythenumberofavailablemachines,
we scale our existing data. For OSS-Fuzz and FTS, we measured
ourdependentvariablesinover3,000fuzzingcampaignsof6 hours.
For Open-Source, we measured our dependent variables in 50 cam-
paigns of 7 daysand 10 campaigns of3 months. Again, we assume
that for each fuzzing campaign twice the machines can generate
twicetheinputsperminutewithzerosynchronizationoverhead.
Hence, we employ a simple scaling strategy: We first make sure
thattimestartsfromzeroatthebeginningofthefuzzingcampaign.
Then,givenascalingfactor 2x,wedivideeach timestamp by2x.
Wemakenoothermodifications. Wemakedataandscriptsavailable
here:https://doi.org/10.6084/m9.figshare.11911287 .
#Vulnerabilities (FTS). FTS consists of 25 programs, each con-
taining a known vulnerability. For each run of LibFuzzer on each
program, we measure the time needed and number of test cases
generated to discover the corresponding vulnerability, i.e., when
thefirst crashisreported.From this information, we can compute
the averagenumber ofvulnerabilitiesfoundat any given time.
#Crashingcampaigns (LibFuzzer ).Whentheprogramcrashes
duringfuzzing,i.e.,abugisfound,thentheentirefuzzingcampaign
crashes.Thisisthedefaultbehaviorof LibFuzzer .Fromthetime
stampofthecrash,wecancomputethetotalnumberofcampaigns
that have crashedat any give time.
#Features (LibFuzzer ).Theclassiccoverage-feedbackfor Lib-
Fuzzeris the feature (reported as ft:). The LLVM documentation
explains: LibFuzzer łuses different signals to evaluate the code
coverage: edge coverage, edge counters, value profiles, indirect
caller/callee pairs, etc. These signals combined are called featuresž.
#Edges(LibFuzzer ). In addition to the number of features, Lib-
Fuzzeralsoreportsthenumberofedgescovered(reportedas cov:).
The proportionofcovered edges versus thetotal number of edges
gives the classic branchcoverage.
#Seeds(AFL). The classic measure of progress for AFL is the
numberofseedsaddedtothecorpus(reportedas paths_total ).It
isoftenreportedasthemeasureoffuzzereffectiveness[ 5].How-
ever,ithasbeenarguedthatthenumberofseedsaddedisstrictly
dependentontheorderinwhichtheseedsareadded[ 11].Hence,
we also provide the number of branches covered (#branches) as
anothermeasure offuzzereffectiveness.
R^2=98.83%
 R^2 (F)=99.87%
R^2 (E)=99.60%
#Crashing campaigns
 #Features and #Edges
1 2 4 8 1 2 4 80e+002e+054e+056e+05
0255075
#machines
#Crashing Campaigns #Features covered #Edges covered
Figure2:(#Crashes,#Features,#Edges@OSS-Fuzz).Average
number of additional species discovered when fuzzing all
263 programs in OSS-Fuzz simultaneously with LibFuzzer
for45minutes as afunction ofavailablemachines (4reps).
%Map Coverage (AFL). Another measure of progress for the
AFLgreyboxfuzzerismapcoverage(reportedas map_size ).AFL
receives coverage feedback via a shared memory map. For each
branch that is exercised, the coverage instrumentation writes to an
indexinthismap.Thepercentageindicesthataresetinthismap
gives the mapcoverage.
2.5 Setup andInfrastructure
Allexperimentsfor FTSwereconductedonamachinewithIntel(R)
Xeon(R)Platinum81702.10GHzCPUswith104coresand126GB
of main memory. All experiments for OSS-Fuzz were conducted on
amachinewithIntel(R)Xeon(R)CPUE5-2699v42.20GHzwitha
totalof88coresand504GBofmainmemory.Allexperimentsfor
Open Source were conducted on Intel(R) Xeon(R) CPUE5-2600 2.6
GHzwithatotalof40coresand64GBofmainmemory.Toensurea
fair comparison, we always ran all schedules simultaneously (same
workload),eachschedulewasboundtoone(hyperthread)core,and
20%ofcores were left unusedto avoid interference.
3 EMPIRICAL RESULTS
RQ1. NumberofAdditionalSpecies Discovered
Giventhesamenon-deterministicfuzzerandtime-budget,weinves-
tigate therelationship between thenumber ofavailable machines
(i.e.,thenumberofinputsgeneratedperminute)andthenumber
ofadditionalspecies discovered.
Presentation .Foreachbenchmarkandspecies,weshowline
plots(geom_line )oftheadditionalnumberofspeciesdiscovered
(lineary-axis)asthenumberofavailablemachinesincreases(ex-
ponential x-axis). With each line plot, we show the R2standard
measure of goodness-of-fit for a linear regression ( lm). AnR2of
100% would mean that the linear regression explains all of the vari-
ation,andthatallobservationsfallexactlyontheregressionline.
We also show the standard error of a linear regression (grey band).
OSS-Fuzz . The results for running LibFuzzer on the almost
threehundredprogramsinOSS-Fuzzareshownin Figure2.Wecan
clearly observe linear increase in the number of additional species
discoveredasexponentiallymoremachinesbecomeavailable.In
fact,fittingalinearregressionmodeltothelogarithmofthenumber
751ESEC/FSE ’20, November8–13,2020,VirtualEvent, USA MarcelBöhme andBrandon Falk
R^2=98.56%
 R^2=97.26%
1min campaign
 8min campaign
1 2 4 8 16 32 64 128 256 1 2 4 8 16 3201234
012345678
#machines#Additional vulns discovered
(a)#Vulnerabilities@FTS.Average number of additionalvulnerabilities found when
fuzzing all25programsin FTS simultaneouslywith LibFuzzer for 1 or8 mins,
respectively, as the number of available machinesincreases (20 repetitions).
R^2 (F)=99.13%
R^2 (E)=95.82%
R^2 (F)=99.29%
R^2 (E)=98.00%
R^2 (F)=98.57%
R^2 (E)=97.21%
R^2 (F)=99.77%
R^2 (E)=99.60%
R^2 (F)=99.63%
R^2 (E)=99.57%
R^2 (F)=97.42%
R^2 (E)=97.81%
R^2 (F)=97.92%
R^2 (E)=96.43%
R^2 (F)=90.20%
R^2 (E)=94.47%
R^2 (F)=96.98%
R^2 (E)=95.99%
R^2 (F)=98.30%
R^2 (E)=94.16%
R^2 (F)=98.80%
R^2 (E)=97.39%
R^2 (F)=99.88%
R^2 (E)=99.27%
re2−2014−12−09
 vorbis−2017−12−11
 wpantund−2018−02−27
libxml2−v2.9.2
 openssl−1.1.0c−x509
 openthread−2018−02−27−radio
harfbuzz−1.3.2
 lcms−2017−03−21
 libjpeg−turbo−07−2017
boringssl−2016−02−12
 freetype2−2017
 guetzli−2017−3−30
1 2 4 8 1 2 4 8 1 2 4 80100200300400500
050100150
0250500750
02000400060000250050007500
03006009001200
0200400600
02004006000100200300
0100200300400
05001000150020002500
0200400600800
#machinesNumber of more features covered
coverage Features Edges
(b) #Featuresand #Edges @ FTS.Averagenumber of additionalnumber of features/
edges covered when fuzzing these 12 programs in FTS with LibFuzzer for 45 minutes,
as the number of available machinesincreases (20 repetitions).
Figure 3:#Vulns, #Features,#Edges @FTSbenchmark.
of machines and the difference in species discovered, we observe a
very high goodness-of-fit ofR-squared( R2) greater than98%.
Ontheleftof Figure2,wecanseethatthecostofmakingone
morefuzzingcampaigncrashbecauseanerrorhasbeenfoundis
exponential. On the right of Figure 2, we can see that the cost of
covering one more feature or one more edge is also exponential. It
isinterestingtoobservethattheslopesoftheincreasediffer.Thisis
because the number of features is larger than the number of edges.
FTS.Theresultsforrunning LibFuzzer onthe25programsin
OSS-Fuzz are shown in Figure 3. Again, we can clearly observe
linearincreaseinthenumberofadditionalspeciesdiscoveredasex-
ponentiallymoremachinesareavailable.Fittingalinearregression
libxml2
1 4 16 64 256 1024025005000750010000
#machines#Additional seeds added
libxml2
1 4 16 64 256 10240.0000.0250.0500.0750.100
#machines%Additional map coverage
(a)#Seedsand %Map Coverage@ LibXML2.Averagenumber of additionalseeds
added and averagepercentage map covered when fuzzing LibXML2 in Open Source
with AFLfor 45minsas the number of available machinesincreases (10 reps).
R^2=88.10%
R^2=97.63%
R^2=97.92%
R^2=99.87%
R^2=94.92%
R^2=81.31%
libxml2
 openssl
 wireshark
ffmpeg
 json
 libjpeg−turbo
1 2 4 8 16 32 64 1 2 4 8 16 32 64 1 2 4 8 16 32 6402505007501000
02550750306090
02004006000100200300400500
0100020003000
#machines#Additional seeds added
R^2=89.39%
R^2=87.82%
R^2=82.86%
R^2=98.23%
R^2=94.24%
R^2=73.17%
libxml2
 openssl
 wireshark
ffmpeg
 json
 libjpeg−turbo
1 2 4 8 16 32 64 1 2 4 8 16 32 64 1 2 4 8 16 32 640.0000.0010.002
0.000000.000050.000100.000150.000200e+002e−054e−05
0.0000.0010.0020.0030e+001e−042e−04
0.000.010.020.03
#machines%Additional map coverage
(b) #Seedsand %Map Coverage@ Open Source. Averagenumber of additionalseeds
added (toptworows)and averagepercentage map covered (bottom tworows)when
fuzzing allsix programsin the Open Source benchmarkwith AFL for 45minutes as
the number of available machinesincreases (10 repetitions).
Figure 4:#Seeds, %Map Coverage @ Open Source.
modeltothelogarithmofthenumberofmachinesandthediffer-
ence in species discovered, we observe a very high goodness-of-fit
ofR-squared( R2) greater than97%(exceptfor vorbis).
In terms of the additional number of features covered, for the
averageprogramintheFTSbenchmarkthe R2measureis98.1%.In
termsoftheadditionalnumberofedgescovered,fortheaverage
programintheFTSbenchmarkthe R2measureis96.9%.Onlyfor
vorbis, the R2-measure isbelow95%.
FTSistheonlybenchmarkwherewecancountthenumberof
vulnerabilities exposed in a fuzzing campaign of the entire bench-
mark (Figure 3.a). It is interesting to observe how the number of
machinesmustincreaseinordertofindthenextvulnerability.Each
newvulnerabilityfoundcomes at an exponential cost.
752Fuzzing: On the ExponentialCost of VulnerabilityDiscovery ESEC/FSE ’20, November8–13,2020,VirtualEvent, USA
OpenSource . The results for running AFL on the six programs
intheOpenSourcebenchmarkareshownin Figure4.Intermsof
additional seedsadded(Figure4.b,toprows),weobservealinear
increase as exponentially more machines are available for three
out of six programs ( R2>97%). For the remaining three programs,
an exponential increase in the number of machines cannot even
achieve alinearincrease inthe numberofadditionalseedsadded,
makingitevenmoreexpensive.Intermsofadditional mapcoverage
(Figure 4.b, bottom rows), we mostly observe a sub-linear behavior
where adding exponentially more machines cannot even achieve a
linearincreaseinthenumberofadditionalseedsadded.Forwire-
shark,thereisnodifferencebetweenthemapcoverageachieved
byeightmachinesin45minutesandthemapcoverageachievedby
64 machines inthesametime. However, for LibXML2we observe
an unexpectedincrease.
We investigatedthesuddenincreaseintheadditional mapcov-
erageachievedinLibXML2bycontinuingthefuzzingcampaigns
forthreemonths,whichcorrespondstorunningthefuzzeron2880
machinesfor45minutes( Figure4.a).Intermsofboth,additional
seeds added and additional map coverage, we identified two linear
phases. In each phase, the goodness-of-fit of a linear regression
modelisR2>99%.
⋆First empirical law . Our results from over four CPU years
worth of fuzzing involving almost three hundred open source pro-
grams, two state-of-the-art greybox fuzzers, four measures of code
coverage,andtwomeasuresofvulnerabilitydiscoverysuggestthat
anon-deterministic fuzzerthat generates exponentiallymore inputs
per minutediscoversonly linearlymorenew speciesorless.
RQ2. Time to DiscovertheSame #Species
Giventhesamenon-deterministicfuzzerandtime-budget,weinves-
tigate therelationship between thenumber ofavailable machines
(i.e.,thenumberofinputsgeneratedperminute)andthetimeto
discover the same number ofspecies.
Presentation .Suppose,whenrunningthefuzzerforsixhours
onasinglemachine,thefuzzerdiscovers S1manyspecies.Weshow
line plots ( geom_line ) of the reduction in time for that fuzzer to
discoverthe same numberof species S1(exponential y-axis)as the
number of available machines increases, i.e., the number of inputs
that can be generated per minute increases (exponential x-axis).
Figure5onlyshowstheplotsforsomebenchmarks.Theotherplots
look very similar andprovidenoextrainformation.
Results. The results for running LibFuzzer on the almost three
hundred programs in OSS-Fuzz and the six programs in FTS are
shown in Figure 5. We can see that running LibFuzzer on 512
machines instead of one machine reduces the time to make 166
fuzzing campaigns crash from five hours and fifty five minutes
(5h55m) to under one minute ( <00h01m; Fig. 5.a-left). Similarly,
runningLibFuzzer on512machinesinsteadofonemachinereduces
theaveragetimetoexposethesamevulnerabilitiesinFTSfromfive
hours and fourty minutes (5h40m) to under one minute ( <00h01m;
Fig.5.a-right). Together, 512 machines are also sufficient to achieve
thesamecoverageinunderoneminuteasonemachineachievesin
sixhours(Fig. 5.b).Thisisreasonable:If LibFuzzer cangenerate
512timesmoreinputsperminute,then LibFuzzer canmakethe
same progressin1/512-thofthe time.OSS−Fuzz benchmark (#vulnerabilities)
1 8 64 512 40961 sec1 min1 hour6 hours
#machinesTime to expose same #vulnsFTS benchmark (#vulnerabilities)
1 8 64 512 40961 sec1 min1 hour6 hours
#machinesTime to expose same #vulns
(a) Time to expose the same number of vulnerabilities in OSS-Fuzz (left) and the same
number of crashing campaigns in FTS (right) as a singlemachinein six hours if
exponentially moremachineswereavailable.
re2−2014−12−09 vorbis−2017−12−11 wpantund−2018−02−27libxml2−v2.9.2 openssl−1.1.0c−x509 openthread−2018−02−27−radioharfbuzz−1.3.2 lcms−2017−03−21 libjpeg−turbo−07−2017boringssl−2016−02−12 freetype2−2017 guetzli−2017−3−30
1 8 64 512 4096 1 8 64 512 4096 1 8 64 512 40961 sec1 min1 hr6 hours
1 sec1 min1 hr6 hours
1 sec1 min1 hr6 hours
1 sec1 min1 hr6 hours1 sec1 min1 hr6 hours
1 sec1 min1 hr6 hours
1 sec1 min1 hr6 hours
1 sec1 min1 hr6 hours1 sec1 min1 hr6 hours
1 sec1 min1 hr6 hours
1 sec1 min1 hr6 hours
1 sec1 min1 hr6 hours
#machinesTime to achieve same coverage
(b) Time to achievethe same coverageas running the fuzzerona singlemachinefor
six hours if the fuzzerwould run onexponentially moremachines.
Figure5:#Vulns,#Features@FTSand#Crashes@OSS-Fuzz.
⋆Second empirical law . Ourresultssuggest that anon-deter-
ministic fuzzer thatgeneratesexponentially moreinputs perminute
discoversthesamenumber ofspeciesalsoexponentially faster.
RQ3. Probabilityto DiscoverGivenSpecies
Giventhesamenon-deterministicfuzzerandtime-budget,weinves-
tigate therelationship between thenumber ofavailable machines
(i.e.,thenumberofinputsgeneratedperminute)andtheprobability
to discover agiven (setof) species.
Presentation . We estimate the probability of an event to occur
inagiven time budget and for agiven number of machines as the
proportion of runs where the event occurs in the given time budget
forthegivennumberofmachines.Forinstance,if75%ofrunshave
discovered a given vulnerability in the given time budget using
sixteen machines, then the probability to discoverthe vulnerability
within the time budget using sixteen machines is 75%. We show
lineplots( geom_line )oftheprobabilitythatthefuzzerdiscovers
a given (set of) species ( lineary-axis) as the number of available
machinesincreases,i.e.,thenumberofinputsthatcanbegenerated
per minuteincreases(exponential x-axis).
Results. The results for the probability to discover a vulnera-
bility in the FTS benchmark by running LibFuzzer for up to six
hours are shown in Figure 6. Our first observation is that the plots
haveaverysimilarshapetothatin Figure8.leftwhichshowsthe
result of our probabilistic analysis of the third empirical law for
non-deterministic blackbox fuzzers. For the bottom three rows, the
probability remains close to zero at the beginning, increases at an
753ESEC/FSE ’20, November8–13,2020,VirtualEvent, USA MarcelBöhme andBrandon Falk
pcre2−10.00 proj4−2017−08−14 woff2−2016−05−06llvm−libcxxabi−2017−01−27 openssl−1.0.2d openssl−1.1.0c−bignumlibpng−1.2.56 libssh−2017−1272 libxml2−v2.9.2c−ares−CVE−2016−5180 harfbuzz−1.3.2 lcms−2017−03−21
1 4 16 64 256 1024 1 4 16 64 256 1024 1 4 16 64 256 10240%25%50%75%100%
0%25%50%75%100%
0%25%50%75%100%
0%25%50%75%100%
#machinesProbability to discover the vulnerability
Figure 6: Probability that the vulnerability has been discov-
ered in twenty seconds given the available number of ma-
chines(solidline).Averagenumberofmachinesrequiredto
find thevulnerabilityintwentyseconds(dashed line).
ever faster rate until it reaches the dashed line (i.e., the average
#machineswherethevulnerabilityisdiscovered),slowsdownagain
untilitreachesalmostone,andthenremainsclosetooneforthe
remainder. In fact, the discovery probability curve appears to be
very similar to asigmoid curve.
Our second observation is that for different vulnerabilities of-
ten a different average number of machines are required to expect
vulnerabilitydiscovery(dashedline).Theharfbuzzandlcmsvul-
nerabilities are never discovered while the c-ares vulnerability has
beendiscoveredinalltwentyrunsinundertwentysecondsalready
on a single machine (top row). We confirmed that adding up the
individual discovery probabilities yields a linear increase in the
number of vulnerabilities discoveredwith an exponential increase
inthe number ofavailable machines (cf. Figure 3.a&Figure 10 ).
The resultsfor theprobability tocoveratleasta givennumber
offeatures S′inthe FTSbenchmark byrunning LibFuzzer for up
tosixhoursareshownin Figure7.Wefixed S′arbitrarilyashalf
thenumberoffeaturesthat LibFuzzer coversononemachinein
six hours. This value of S′allows us to actually observe a transi-
tion from probability zero to one for most of the subjects. Again,
wemakethesameobservations.Mostimportantly,theplotslook
similartothesigmoidshapethatwehaveseenforoursimulation
results in Figure 8.left.
⋆Third empirical law . Our results suggest that for a non-
deterministic fuzzer that generates exponentially more inputs per
minute the probability of discovering a given (set of) species seems to
increase exponentially until discovery is expected, whence the rate of
increase slows down and thecurveapproachesprobability one.S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639S'=1639
S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051S'=3051
S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889S'=5889
S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=5760S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588S'=7588
S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960S'=960
S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539S'=1539
S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=700S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009S'=1009
S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680S'=680
S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828S'=1828
S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430S'=7430re2−2014−12−09 vorbis−2017−12−11 wpantund−2018−02−27libxml2−v2.9.2 openssl−1.1.0c−x509 openthread−2018−02−27−radioharfbuzz−1.3.2 lcms−2017−03−21 libjpeg−turbo−07−2017boringssl−2016−02−12 freetype2−2017 guetzli−2017−3−30
1 4 16 64 256 1024 1 4 16 64 256 1024 1 4 16 64 256 10240%25%50%75%100%
0%25%50%75%100%
0%25%50%75%100%
0%25%50%75%100%
#machinesProbability to cover at least S' features
Figure 7: Probability that at least S′features are covered
in twenty seconds given the available number of machines
(solidline),where S′ishalfthenumberoffeaturesthat Lib-
Fuzzercan cover in six hours on one machine, on average.
We also show the average number of machines needed to
discoveratleast S′featuresintwentyseconds(dashedline).
4 PROBABILISTIC ANALYSIS
4.1 ProbabilisticModel ofFuzzing
Wemakeanattemptatexplainingourempiricalobservationsby
probabilisticallymodellingthefuzzingprocess.Startingfromthis
model, we conduct simulation experiments that generate graphs
thatturnoutquitesimilartothoseweobserveempirically.Since
the underlying probabilistic model is straightforward for blackbox
fuzzers,we focus only on the blackbox fuzzing process . Nevertheless,
we hope that our probabilistic analysis sheds some light on our
empiricalobservationsforgreyboxfuzzingandonthescalabilityof
non-deterministic fuzzingin general:Why is it expensive to cover
newcode but cheap to cover the same code faster?
WeborrowtheSTADSprobabilisticmodeloffuzzingfromBöhme
[2].Anon-deterministicfuzzer generatesprograminputsbysam-
plingwithreplacementfromtheprogram’sinputspace.Let Pbe
theprogramthatwewishtofuzz.Wecallas P’sinputspace DDDthe
setofallinputsthat Pcan take.Fuzzing Pisastochasticprocess
F={Xn|Xn∈ DDD}N
n=1(1)
ofsampling Ninputswithreplacement fromtheprogram’sinput
space.Wecall Fasfuzzingcampaign andatoolthatperforms F
asnon-deterministicblackboxfuzzer .Suppose,wecansubdividethe
input space DDDintoSindividual subdomains { Di}S
i=1calledspecies.
754Fuzzing: On the ExponentialCost of VulnerabilityDiscovery ESEC/FSE ’20, November8–13,2020,VirtualEvent, USA
0.00.20.40.60.81.0
2025210215220225230235
#machinesDiscovery Probability
10−510−410−310−210−1100101
2025210215220225230235
#machinesDiscovery Probability (log−scale)
Figure 8: Probability Qexp(x)=S(2xn)to discover a given
species within a given time budget as the number of ma-
chinesincreasesexponentially(solidline).Wealsoshowthe
inflectionpoint x0ofQexp(x)(greylines)andanexponential
curve(dashedline)thatintersects Qexp(x)atx=0andx=x0
andthatstartsoutwiththesameslopeas Qexp(x)atx=0but
grows slower than Qexp(x)in the interval x∈ [0,x0]. We let
theprobability qthatthespecieshas notbeendiscoveredon
one machine ( x=0) within the time budget be q=1−10−6,
and the exponential be abx+cwherea=1.03722×10−6,
b=1.95092,andc=−3.722×10−8.
AninputXn∈Fis said to discoverspeciesDiifXn∈ Diand
theredoesnotexistapreviouslysampledinput Xm∈Fsuchthat
m<nandXm∈ Di(i.e.,Diis sampled for the first time). An
input’s species is defined based on the dynamic program properties
thatareusedastheevaluationcriteriaofthefuzzer.Forinstance,
each branch that is exercised by input Xn∈ DDDcan be identified
as a species. The discovery of the new species, i.e., branch, then
correspondsto an increaseinbranchcoverage.
We letpi=P[Xn∈ Di]be the probability that Xnbelongs to
Difori: 1≤i≤Sandt: 1≤n≤N. The expected number of
speciesS(n)discoveredbyanon-deterministic blackbox fuzzeris
S(n)=S/summationdisplay.1
i=1/bracketleftbig
1−(1−pi)n/bracketrightbig
=S−S/summationdisplay.1
i=1(1−pi)n.(2)
Intuitively, we can understand a non-deterministic blackbox
fuzzer as sampling with replacement from an urn with colored
balls,whereeachballcanhaveoneormoreof Scolors.Thespecies
discoverycurve S(n)representsthenumberofcolorsthatweexpect
todiscoverwhen sampling nballs.Here,a ballis aninputwhile a
ball’scolorsare the input’s species.
Fuzzing approaches . We can distinguish a generation-based
and a mutation-based approach [ 14]. Ageneration-based fuzzer
generates random inputs from scratch. A mutation-based fuzzer
generatesrandominputsbymodifyingexistinginputsinagiven
seed corpus. A mutation-based fuzzer is non-deterministic, as it
chooses the seed to fuzz, the location in the chosen seed to mutate,
andthemutationoperatorstoapplyatthechosenlocationsallat
random.A greyboxfuzzer isamutation-basedfuzzerthataddstothe
corpus generatedinputsthat increasecoverage. A grammar-guided
generation-based fuzzer can generate program inputs that are valid
w.r.t. a given grammar by random sampling from that grammar
[10]. Agrammar-guided mutation-based fuzzer can generate valid
inputsbyparsingaseedasparsetree,randomlymutatingtheparse
tree,andre-constituting the modifiedtree [ 17].Machinesandtimebudget . We explore two related problems
andshowthat,undersimplifyingassumptions,theyrepresentthe
same case. Firstly, we explore how the number of species discovered
within a fixed time budget increases as the number of machines
increases.FromEquation( 2),weknowthatthenumberofspecies
S(n)weexpectanon-deterministicblackboxfuzzertodiscoverafter
generating ninputsisthetotalnumberofspeciesminusthesum
for each species iof the expected probability that ihasnotbeen
discoveredaftergenerating ninputs.With2xtimesmoremachines,
we can generate 2xtimes more inputsper minute,i.e.,
S−S/summationdisplay.1
i=1/parenleftBig
(1−pi)2x/parenrightBign
=S−S/summationdisplay.1
i=1(1−pi)2xn(3)
=S(2xn) (4)
So,givenatimebudget,suchthatthefuzzerrunningononema-
chinecangenerateexactly ntestinputs,if2xtimesmoremachines
were available, S(2xn)−S(n)more species wouldbe discovered.
Secondly,weexplore howthenumberofspeciesdiscoveredona
single machine increases as the available time budget increases . If
the non-deterministic fuzzer generated 2xmore test inputs on the
same machine, S(2xn)−S(n)more species wouldbe discovered.
4.2 Probabilityto DiscoveraGivenSpecies
Ourfirstempiricalobservationisthatanon-deterministicfuzzer
that generates exponentially more inputs per minute discovers
only linearly more new species (or less). Let us begin with an in-
vestigationofthespecialcasewhere weassumethatonlyasingle
(interesting) species exists ,S=1. How does the probability to dis-
coverthisspeciesincreasewithinagiventimebudgetasthenumber
ofmachines(i.e.,#inputsperminute)increases?Weinvestigated
thisquestionempiricallyin Section3.RQ3andourobservationsfor
this specialcaseare counterintuitive.
⋆Wesuggestthatanon-deterministicfuzzerthatgeneratesex-
ponentiallymoreinputsperminutealsodiscoversaspecificspecies
withaprobability that is exponentially higherÐup to somelimit.
Inotherwords,theprobabilitytofindaspecificspecieswithin
agiventimeincreasesapproximatelylinearlywiththenumberof
machines(uptosomelimit).Weconductaprobabilisticanalysisfor
the special case where the fuzzer is blackbox, i.e., for each species,
throughout the campaign the fuzzer has the same probability to
generate an input that belongs to that species. We also identify
exactly where this łlimitž is.
InFigure8,weseeanexampleoftherelationshipbetweenthe
probabilitytodiscoverthespeciesandanexponentialincreasein
the number of available machines (solid line). We also show the
inflectionpoint x0wherethegrowthstartstodecelerate(greylines),
andanexponentialfunctionthatintersectsthediscoverprobability
curveatx∈ {0,x0},startswiththesamerateofgrowth(slope)at
x=0, and lower-bounds the species discovery curve within the
intervalx∈ [0,x0](dashedline).
Given aspecific species , letpbe the probability that the fuzzer
generates an input that discovers the species. We compute the
expectedprobability Q(n)thatthefuzzerhasdiscoveredthespecies
as the complement of the probability that the species has not been
discoveredusing ngeneratedtest inputs, Q(n)=1−(1−p)n.
755ESEC/FSE ’20, November8–13,2020,VirtualEvent, USA MarcelBöhme andBrandon Falk
Slowergrowing exponential: T(x)=abx+c
q a b c
0.51.62488×1001.15933 −1.12488×100
1−10−11.32149×10−11.64439 −3.21490×10−2
1−10−21.13899×10−21.83219 −1.38990×10−3
1−10−41.05930×10−41.92379 −5.93000×10−6
1−10−61.03722×10−61.95092 −3.72200×10−8
1−10−81.02711×10−81.96380 −2.71100×10−10
Figure 9: Examples of exponential functions T(x)=abx+c
that grow slowerin the interval x∈ [0,x0]than the proba-
bilityQexp(x)ofdiscoveringaspecificspecieswithinagiven
time budget if 2xmore machines were available where T(x)
intersects Qexp(x)atx∈ {0,x0}and starts with the same
slope at thebeginningoftheinterval.
Beforeweshowthatthediscoveryprobabilityincreasesexpo-
nentially up to a certain limit as the number of machines increases
exponentially,wewillfirstidentifymoreformallywherethisłlimitž
is. Clearly, the discovery probability cannot be larger than one. So,
theremustbeaninflectionpoint.An inflectionpoint isapointof
the curve where the curvature changes its sign. For brevity, we
definetwoquantities Qexp(x)andqas follows
q=(1−p)nsincepandnare constants (5)
Qexp(x)=1−q2x(6)
whereqis the probability that runningthe fuzzer on one machine
withinatimebudgetthatallowstogenerate ntestinputs hasnot
discoveredthespecies,andwhere Qexp(x)givestheprobabilitythat
running the fuzzer on 2xmachines within the same time budget
hasdiscoveredthe species.
Inflectionpoint .Tofindtheinflectionpoint,wesetthesecond
derivative of Qexp(x)to 0andsolve for xto findx0.
x0=log2/parenleftbigg
−1
log(q)/parenrightbigg
wherex0>0ife−1<q<1. (7)
Notethattheexpectedprobabilitythatthespecieshasbeendiscov-
eredat this inflection pointis Qexp(x0)=1−e−1.
We can demonstrate that Qexp(x)grows exponentially in the
intervalx∈ [0,x0]by showing that for all q:e−1<q<1and
x: 0≤x≤x0, there exists a,b, andc, such that the exponential
functionT(x)=abx+cintersectswith Qexp(x)atx∈ {0,x0},that
the slopes of T(x)andQexp(x)are equal at x=0, i.e.,∂
∂x(T(x)−
Qexp(x))=0atx=0, and that Qexp(x)−T(x) ≥0for0<x<x0
(i.e.,there isnothirdintersection inthe interval).
Figure9showsthevaluesfor a,b,andcthatsatisfythesecon-
straintsforsomeinterestingprobabilities qthatthespecieshasnot
been discoveredwithin the given time budget onone machine.
⋆Giventheprobability qthatanon-deterministicblackboxfuzzer
hasnotdiscovered a given species within a given time budget, an
attackerthatrunsthesamefuzzerinthesametimebudgeton 2xtimes
more machines, such that x∈ [0,log2(−1/log(q))], has a probability
Qexp(x)of discovering the species where Qexp(x)growsfasterthan
an exponential whichintersects Qexp(x)atthebeginningandend
oftheintervaland starts withthesameslope.For non-deterministic blackbox fuzzers, an example is shown in
Figure 8. Recall that q=1− (1−p)n, wherepis the probability
thatthenon-deterministicfuzzergeneratesaninputthatbelongs
tothatspeciesand nisthenumberoftestinputsthatcanbegen-
erated within the given time budget on one machine. While the
probabalisticresultsarederivedfromamodelforblackboxfuzzing,
they explain the empirical evidence for the two greybox fuzzers in
Section3.RQ3.Thegraphsgeneratedfromourprobabilisticanalysis
inFigure 8.left and as a result of our empirical analysis in Figure 6
and7are almostidentical.
Intuition&consequences .Intuitively,ifyoubuytwo,four,or
eight lottery ticketsÐinstead of oneśalso increases your chance of
drawing a winning ticket by a factor of two, four, or eight. Rolling
sixdicesimultaneouslyinstead ofone increasesthechance to roll
at least one six by a factor of four. So what does that mean for
our empirical observation that the cost of discovering the next
unknownvulnerabilityincreasesexponentially?
(1)Foranon-deterministicblackboxfuzzer,theprobabilityof
exposingaspecific knownvulnerability,reachinga specific
program statement, violating a specificprogram assertion,
or observing a specificevent of interest (i.e,. species) within
a given time budget increases approximately linearly with
the number ofavailable machinesÐupto acertainlimit.
(2)The same observation holds even if our objective is to dis-
coverallspecies in a given set of species. On the average,
the most difficult species to discover is that which has the
highestprobability qmaxnottobediscoveredaftergenerat-
ingntest inputs. By setting q=qmax, we can reduce the
problem of discovering allspecies in a given set to expos-
ing a specific species. From the second law, we also know
that the time spent finding the same number of species is
inversely proportional to the number of available machines.
(3)The same observation holds even for the discovery of the
nextunknownvulnerability ifweassume thatthereexists
onlyasingleunknownvulnerability,or ifweassumethatall
unknown vulnerabilitieshave exactlythesame probability
qi=1/Snottobediscoveredwithinthegiventimebudget
onone machine,i.e., qi=qi+1=1/Sfori: 1≤i<S.
4.3 Explaining theFirst Empirical Law
Giventheinsightsfromtheprevioussection,whydoourempirical
observationssuggestanexponentialcostforthediscoveryofthe
nextunknown vulnerability(ourfirstlaw)?Fromtheexponential
behaviorofofthediscoveryprobabilitycurve Qiexp(x)foraspecies
i,we canderive thatdiscoveryprobability iseither approximately
zero (0) or approximately one (1) with an łalmostž linear transi-
tion at around x=log2(1/(1−qi))Ðwhen discovery is expected.
Figure 8.left illustrates this behaviornicely.
Thenumberofspecies S(2xn)discoveredif 2xmoremachines
were available isthe sum of the individual discoveryprobabilities,
S(2xn)=/summationtext.1S
i=1Qiexp(x). Without making any additional assump-
tionsaboutthetotalnumber Sofspeciesortheprobabilities {qi}S
i=1,
we mostly observe the effects of the almost-linear transitions of
the individual discovery probabilities Qiexp(x)as they contribute
to the total number of discovered species S(2xn). This additive
756Fuzzing: On the ExponentialCost of VulnerabilityDiscovery ESEC/FSE ’20, November8–13,2020,VirtualEvent, USA
Total #Species:  1 Total #Species:  10 Total #Species:  100 Total #Species:  1000
20252102152202025210215220202521021522020252102152200200400600
0204060
02468
0.000.250.500.751.00
#machines#more species discovered
Figure10:Numberofadditionalspeciesdiscovered S(2xn)−S(n)asthenumberofavailablemachinesincreasesexponentially
(S∈ {1,10,100,1000}, 5 random samples of {qi}S
i=1each). We recognize the exponential increase for a single species on the left
andthelinear increase for1000 species on theright.
acummulation of the individual curves for each species explains
ourempiricalobservationofalinearincreaseinthenumberofnew
species discovered within the same time budget and as 2xmore
machines are available.1
Simulation .Weexplorethis explanationinseveralsimulation
experiments.Wevarythethetotalnumberofspecies Sandassume
apower-lawdistribution2overtheprobabilities {qi}S
i=1.Specifically,
for each species iwe sample a random floating point value Xi
uniformlyfromtheinterval [0,32]andsettheprobability qithat
ihasnotbeendiscoveredaftergenerating ninputs(i.e., x=0)as
qi=1−2−Xi.In otherwords,themostabundantspeciesis about
twice as likely to be discovered as the next most abundant species,
and so on. We let the total number of species S∈ {1,10,100,1000}
and for each value of Srepeat the sampling of {qi}S
i=1five times.
Thesimulationshouldbynomeansbeconsideredaproofofour
firstempiricallaw,butratherasanexplorationorasanexplanation.
Forthereadertotryoutotherdistributions,wemakeourscripts
available here: https://doi.org/10.6084/m9.figshare.11911287 .
Results. The simulation results for a non-deterministic black-
boxfuzzer are shown in Figure 10. Itdepicts the additional number
of species found as 2xtimes more machines are available to an
exponentially more powerful attacker, i.e., the attacker can gen-
erate 2xmore inputs per minute . On the left, we can recognize
the exponential species discovery curve Qexp(x)from the third
empirical law (cf. Fig. 8). If we assume that only a single species
exists, exponentially more machines will discover this species also
exponentiallyfaster.Ontheright,wecanseethelineardiscovery
curve which is the subject of our first law. If we assume that a
thousand species exist,exponentially more machines will increase
the number of additional species discovered only linearly. The two
charts in betweenfor S∈ {10,100}illustrate how theexponential
curvesfromtheindividualspeciesadditivelyaccumulatetoform
anapproximatelylinearcurvefortheadditionalspeciesdiscovered.
Fortwonon-deterministicgreyboxfuzzers,weprovideempirical
evidenceinfavorofthe firstempirical law in Section 3.RQ1.
Ifweassume thatthereisjustoneundiscoveredspecies,anon-
deterministicfuzzerthatgeneratesexponentiallymoreinputsper
1Wepresented ourempirical observationsin Section3.
2Wealsoexploredthe unrealistic assumption of a uniform distribution over {qi}S
i=1,
i.e., to sample qiuniformly from the interval [0,1]. It is unrealistic, because we
wouldotherwise expectdiscovery of most specieswithonly 10x moremachines.We
conductedsimulationexperimentsandobserveda sub-linear increaseinthenumberof
more species discovered as the number of available machines increases exponentially.minutealsodiscoversaspecificspecieswithaprobabilitythatis
exponentiallyhigherÐup to some limit( Section4.2 ). However, we
cannot assume to know the total number of species in advance. We
cannotassumethere isonly one species left undiscovered.
⋆Withoutmakingassumptionsonthenumberofspecies,ifspecies
probabilitiesaredistributedaccordingtothepowerlaw,wesuggest
that a non-deterministic fuzzer that generates exponentially more
inputsper minutediscoversonly linearlymore new species(orless).
Wecallthisobservationanempiricallawbecauseitiscontingent
on the fact that species are distributed roughly according to the
power law. In the special casesÐwhere (a) all species are equally
likely (pi=1/Sfor alli: 1≤i≤S) or (b) there exists just
one species ( S=1)Ðthis law does not hold. However, from our
empirical observations in Section 3 .RQ1, we can derive that the
speciesmeasured inour dependentvariables (e.g.,vulnerabilities)
are indeed distributed according to the power law. The plots for
ourempiricalobservations( Figure2Ð4)lookverysimulartoour
plots for our simulation results ( Figure 10 .right).
Apower law distribution gives a very high probability to a small
numberofeventsandaverylowprobabilitytoaverylargenumber
ofevents.The80/20Paretoprincipleisanexample.Forus,there
are very few extremely abundant species but a large number of
extremelyrarespecies.Inoursimulation,thesecondmostabundant
species isonly halfas likely as the mostabundant,andsoon.
Intuition . When collecting baseball cards, the first couple of
cards are always easy to find, but adding a new card to your col-
lection will get progressively more difficultÐeven if all baseball
cards were equally likely. This is related to the coupon collector’s
problem.Similarly,ourfirstlawsuggeststhatcoveringonemore
branch or discovering one more bug will get progressively more
difficultÐso difficult, in fact, that each new branch covered and
eachnewvulnerabilityexposedcomes at an exponential cost.
4.4 Explaining theSecondEmpirical Law
While our first empirical law implies that it is expensive to cover
newcode,thesecondlawimpliesthatitis cheaptocoverthesame
code. Similarly, it is expensive to find an unknown vulnerability,
but cheap to find the same, known vulnerabilities. Suppose for a
non-deterministicblackboxfuzzer,intheoriginalsetuponeinputis
generated per minute while in the exponential setup 2xinputs are
generatedperminute.Giventheoriginaltime n,weneedtofindthe
757ESEC/FSE ’20, November8–13,2020,VirtualEvent, USA MarcelBöhme andBrandon Falk
1 sec1 min1 hr1 day1 week1 mth1 year
2022242628210212214216218220222224226
#machinesTime to achieve same coverage
Figure 11: Second law . We observe an exponential decrease
in the time spent to discover the same number of species
with an exponential increase in available machines (i.e., in
thenumberoftestcasesthat can be generated perminute).
timem,suchthatthenumberofspeciesfoundintheexponential
setup inmunits of time is equivalent to the number of species
foundinthe originalsetupin nunitsoftime,
S−S/summationdisplay.1
i=1/parenleftBig
1−pi)1/parenrightBign
=S−S/summationdisplay.1
i=1/parenleftBig
1−pi)2x/parenrightBigm
(8)
whichistrue when we have that
m=n
2x(9)
Foranon-deterministic blackboxfuzzer, Figure 11 illustrates the
thirdempiricallawwheretheoriginalsetupspendsoneyear.For
two non-deterministic greybox fuzzers, we provided empirical evi-
denceinfavorofthe secondempirical law in Section 3.RQ2.
⋆Wesuggestthatanon-deterministicfuzzerthatgeneratesex-
ponentially more inputs per minute discovers the same number of
species also exponentially faster. More specifically, we suggest that
thetimetofind thesame numberofspeciesisinverselyproportional
to thenumber ofmachines.
5 RELATED WORK
Fuzzingisafast-growingresearchtopicwithmostrecentadvances
incoverage-guidedfuzzing ,whichseekstomaximizecoverageof
the code. The insight is that a seed corpus that does not exercise a
program element ewill also not be able to discover a vulnerability
observablein e.Coverage-guidedgreyboxfuzzers[ 4,5,11,12,18,21,
26]uselightweightinstrumentationtocollectcoverage-information
duringruntime.Foracomprehensiveoverview,werefertoarecent
survey [14]. Coverage-guided whitebox fuzzers [6ś9] use symbolic-
executionto increase coverage. For instance,Klee [ 6]has a search
strategytopriotizepathswhichareclosertouncoveredbasicblocks.
The combination and integration of both approaches have been
explored as well [ 16,22]. In this paper, we focus only on non-
deterministic fuzzers.
Non-deterministic fuzzers generate program inputs in random
fashionwithouteverexhaustingthesetofinputsthatcanbegen-
erated. In contrast to deterministic fuzzers, there is no enumeration
of finite, determined set of inputs (or of program properties like
paths). A non-deterministic generation-based fuzzergeneratesnew
inputs by sampling from a random distribution over the program’sExponential Cost
1 2 4 8 16 32300600900
#machines#Covered Branches
Blackbox
Greybox (Global Queue)
Greybox (Local Queue)Linear Cost
1 2 4 8 16 32 64 128 2561e+021e+031e+041e+05
#machinesTime to achieve same coverage
Blackbox
Greybox (Global Queue)
Greybox (Local Queue)
Figure 12: Each new branch covered requires exponentially
more machines (left). Yet, exponentially more machines al-
lowtocoverthesamebranchesexponentiallyfaster(right).
input space.3For instance, a random input file can be generated
by sampling a random number nof UTF-8 characters, ⟨c1,...,cn⟩
whereci∈ [0,255]. Anon-deterministic mutation-based fuzzer gen-
eratesinputs by randommodificationsofa seedinput. The fuzzer
chooses a random set of mutation operators to apply at random
locations in theseed input.In this paper, we conduct anempirical
analysis for two non-deterministic greybox fuzzers and provide
aprobabilisticanalysisfornon-deterministicblackboxfuzzingin
order to shedsomelight onour observations.
Deterministicfuzzers enumerateafinitenumberofobjectsand
then terminate. For instance, a symbolic execution-based whitebox
fuzzer[6,7]enumerates(interesting)paths.Itmightnotenumerate
allpaths,butideally,itwouldnevergenerateasecondinputexercis-
ingthesamepath. Adeterministicmutation-basedfuzzer[ 23,24]
enumerates a determined set of mutation operators and applies
them to a determined set of locations in the seed input. Greybox
fuzzerssuchasAFLmayfirstfuzzeachseeddeterminsticallybefore
switchingtoanon-deterministicphase. Inthelimit ,suchłhybridž
greybox fuzzersare stillprimarilynon-deterministic.
Probabilistic analysis . Arcuri et al. [ 1] analyzed the scalability of
search-based software testing and show that random testing scales
better in the number of targets than a directed testing technique
thatfocusesononetargetuntilitisłcoveredžbeforeproceeding
to the next. Böhme and Paul [ 3] argue that even the most effective
techniqueislessefficientthanblackboxfuzzingifthetimespent
generatingatestcasetakesrelativelytoolongandprovideproba-
bilistic bounds. Majumdar and Niksic [ 13] discuss the efficiency of
random testing for distributed and concurrent systems. To the best
ofourknowledge,oursisthefirstworktoinvestigatethescalability
offuzzingacrossmachinesandthecostofvulnerabilitydiscovery.
6 DISCUSSION
Our first empirical law suggests that using a non-deterministic
fuzzer(a)giventhesametimebudget,eachnewvulnerabilityre-
quiresexponentiallymoremachinesand(b)giventhesamenumber
ofmachines,eachnewvulnerabilityrequiresexponentiallymore
time.Intuitively , when collecting baseball cards, the first couple
of cards are easy to find, but collecting the next new card gets
progressivelymore difficult.
3Itispossible, of course, that thereis zeroprobabilityweightover some inputs.
758Fuzzing: On the ExponentialCost of VulnerabilityDiscovery ESEC/FSE ’20, November8–13,2020,VirtualEvent, USA
Our second empirical law suggests that a non-deterministic
fuzzer which generates exponentially more machines discovers
the same vulnerabilities also exponentially faster. This means that
findingthesamevulnerabilitiesinhalfthetimerequiresonlytwice
as many machines. Intuitively , if each day you would bought twice
asmanypacksofbaseballcards,youcouldhavecollectedthesame
cardsthat you have nowinhalfthe time.
Inourempiricalanalysis,wemakethesimplifyingassumption
that there is no synchronization overhead .Twice themachines can
generatetwicetheinputsperminute.Conceptually,thisisstilla
single fuzzing campaign where inputs are still generated sequen-
tially. Any discovered seed, added to the corpus, is immediately
available to allothermachines. Our analysisisoptimistic.
Open science and reproducibility . We derive our empirical
laws from the data that has been available to us and call upon the
communitytotestthemforotherfuzzingtools,otherdefinitions
of species (e.g., mutants killed), other programming languages, and
so on. To facilitate this extended investigation, we provide all data
andscriptstoreproduceourempiricalevaluation,oursimulation,
andallfigures inthis paper at:
•https://doi.org/10.6084/m9.figshare.11911287.v1
•https://www.kaggle.com/marcelbhme/fuzzing-on-the-exponential-
cost-of-vuln-disc
6.1 ImpactofSynchronization Overhead
Weconductedpreliminaryexperimentstoinvestigatetheimpactof
this simplifying assumption. We ran Xfuzzing campaigns simulta-
neouslyon Xmachinesinthefollowingthreesettings:(a)blackbox
fuzzers, (b) greybox fuzzers each with a local seed corpus, and
(c)greyboxfuzzersallsharingaglobalseedcorpus.Thelastsetting
corresponds to our simplifying assumption. For each setting, we
measuredtheincreaseincoverageover allsimultaneouscampaigns.
Figure12 showsthetremendousimpactofsharingaglobalqueue
amonggreyboxfuzzersandmakingseedsfoundimmediatelyavail-
able to all other fuzzing campaigns. Running 32 greybox fuzzers in
parallelwithoutsharing a global queue does not scale much bet-
terthanrunning 32 blackbox fuzzersinparallel.Without efficient
sharingofinformation acrossmachines, thecostofcoveringeach
newbranchis still linear but the slope ofthe lineismuchsmaller.
6.2 Implications in Practice
Wereachedouttosecurityresearchersandpractitioners onTwitter
to understand the practical implications of our findings. In the
following, we summarize the discussion.
łCoolpaper!Asomewhatrelatedthoughtthatcomestomind:to
find new bugs ’faster’ one would need to make a better fuzzer
insteadoftrying to scaleupexistingones.ž
ÐAndrey Konovalov (@andreyknvl)
łI think there is something else though: the difficulty of individual
bugs/coverage are not fixed. Better mutators and feedback can
reduce the cost by orders of magnitude (think: a grammar fuzzer
finds morecoverage withafractionofthecompute).ž
ÐCornelius Aschermann(@is_eqv)łThe results show that only throwing more CPU power at fuzzing
is not the way to go. In a similar vein to what @is_eqv said, we’ll
bebetteroffoptimizingtheprocess:seedselectionpolicy,structure-
aware mutations, new feedback signals, and combining it with
othertechniques.ž ÐKhaledYakdan (@khaledyakdan)
Fuzzing smarter .Wecannotsimplythrowmoremachinesat
vulnerability discovery when we stop finding vulnerabilities. In-
stead,weneedtodevelopsmarterandmoreefficientfuzzers.Similar
tocompoundinterest(i.e.,exponentialgrowth),eventhesmallest
increaseindiscoveryprobabilityprovidestremendousperformance
gainsinthelongrun.Evensmallperformancegainsononemachine
has tremendousbenefitswhen scalingto multiple machines.
łThis probably also means that just ’fuzzing everything a little’ is
pretty lucrativeto findthe low hanging fruit.ž
ÐHenk Poley (@henkpoley)
Fuzzing in CI/CD . Fuzzing everything for just a little bit, we
canalreadycoveralotofground.Inanunfuzzedtarget,themajority
ofvulnerabilitiesisfoundwithrelativelyfewresources.
łLove the last paragraph! ‘Our results suggest to compare fuzzers
intermsoftimetodiscoverthesamebug(s),orthetimetoachieve
thesamecoverage.ž’ ÐChengyuSong (@laosong)
Fuzzingevaluation . Our results suggest to compare fuzzers in
termsofthetimetodiscoverthesamebug(s),orthetimetoachieve
thesamecoverage.Reportingtheincreaseincoveragewithinthe
sametimebudgetmaybemisleadingsinceevenasmallincrease
comes at an exponential costinterms of time ormachines.
ACKNOWLEDGMENTS
We would like to thank the anonymous reviewers for the con-
structive and valuable feedback and acknowledge the kind help
of Van-Thuan Pham with producing some of the data in other
experiments. This work was fully funded by the Australian Re-
searchCouncil(ARC)throughaDiscoveryEarlyCareerResearcher
Award (DE190100046) and partially supported by use of the Nectar
ResearchCloud,acollaborativeAustralianresearchplatformsup-
portedbytheNCRIS-fundedAustralianResearchDataCommons
(ARDC).
REFERENCES
[1]Andrea Arcuri, Muhammad Zohaib Iqbal, and Lionel Briand. 2012. Random
Testing: Theoretical Results and Practical Implications. IEEE Transactions on
SoftwareEngineering 38,2 (March2012),258âĂŞ277.
[2]Marcel Böhme. 2018. STADS: Software Testing as Species Discovery. ACM
TransactionsonSoftwareEngineeringandMethodology 27,2,Article7(June2018),
52pages. https://doi.org/10.1145/3210309
[3]Marcel Böhme and Soumya Paul. 2016. A Probabilistic Analysis of the Efficiency
of Automated Software Testing. IEEE Transactions on Software Engineering 42, 4
(April2016),345ś360. https://doi.org/10.1109/TSE.2015.2487274
[4]MarcelBöhme,Van-ThuanPham,Manh-DungNguyen,andAbhikRoychoud-
hury.2017. DirectedGreyboxFuzzing.In ProceedingsoftheACM Conferenceon
Computer and Communications Security(CCS’17) . 1ś16.
[5]Marcel Böhme, Van-Thuan Pham, and Abhik Roychoudhury. 2017. Coverage-
based GreyboxFuzzing asMarkov Chain. IEEE TransactionsonSoftware Engi-
neering(2017), 1ś18.
[6]Cristian Cadar, Daniel Dunbar, and Dawson Engler. 2008. KLEE: Unassisted and
AutomaticGenerationofHigh-coverageTestsforComplexSystemsPrograms.
759ESEC/FSE ’20, November8–13,2020,VirtualEvent, USA MarcelBöhme andBrandon Falk
InProceedings of the 8th USENIX Conference on Operating Systems Design and
Implementation(OSDI ’08) . 209ś224.
[7]Vitaly Chipounov, Volodymyr Kuznetsov, and George Candea. 2011. S2E: A
PlatformforIn-vivoMulti-pathAnalysisofSoftwareSystems.In ASPLOSXVI .
265ś278.
[8]PatriceGodefroid,MichaelY.Levin,andDavidMolnar.2012. SAGE:Whitebox
Fuzzing for SecurityTesting. Queue10,1,Article20(Jan. 2012),8 pages.
[9]Patrice Godefroid, Michael Y. Levin, and David A. Molnar. 2008. Automated
WhiteboxFuzzTesting.. In NDSS ’08 (2009-06-18). The Internet Society.
[10]Rahul Gopinath and Andreas Zeller. 2019. Building Fast Fuzzers. ArXiv
abs/1911.07707 (2019).
[11]CarolineLemieuxandKoushikSen.2018. FairFuzz:ATargetedMutationStrat-
egy for Increasing Greybox Fuzz Testing Coverage. In Proceedings of the 33rd
ACM/IEEEInternationalConferenceonAutomatedSoftwareEngineering(ASE2018) .
Associationfor Computing Machinery, 475âĂŞ485.
[12]LibFuzzer. 2019. LibFuzzer: A library for coverage-guided fuzz testing. http:
//llvm.org/docs/LibFuzzer.html . (2019). Accessed:2019-02-20.
[13]RupakMajumdarandFilipNiksic.2017. WhyisRandomTestingEffectivefor
Partition Tolerance Bugs? Proceedings of the ACM on Programming Languages 2,
POPL, ArticleArticle46(Dec. 2017),24pages. https://doi.org/10.1145/3158134
[14]Valentin J. M. Manès, HyungSeok Han, Choongwoo Han, Sang Kil Cha, Manuel
Egele, Edward J. Schwartz, and Maverick Woo. 2018. Fuzzing: Art, Science, and
Engineering. CoRRabs/1812.00140 (2018). arXiv: 1812.00140 http://arxiv.org/abs/
1812.00140
[15]OSS-Fuzz.2019. ContinuousFuzzingPlatform. https://github.com/google/oss-
fuzz/tree/master/infra . (2019). Accessed:2019-02-20.
[16]BrianS.Pak.2012. HybridFuzzTesting:DiscoveringSoftwareBugsviaFuzzingand
Symbolic Execution . Ph.D. Dissertation. Carnegie Mellon University Pittsburgh.[17]Van-ThuanPham,MarcelBöhme,AndrewE.Santosa,AlexandruRazvanCaci-
ulescu, and Abhik Roychoudhury. 2018. Smart Greybox Fuzzing. CoRR
abs/1811.09447 (2018). arXiv: 1811.09447http://arxiv.org/abs/1811.09447
[18]SanjayRawat,VivekJain,AshishKumar,LucianCojocar,CristianoGiuffrida,and
HerbertBos.2017. VUzzer:Application-awareEvolutionaryFuzzing.In NDSS
’17. 1ś14.
[19]Konstantin Serebryany.2017. https://github.com/google/fuzzer-test-suite .(2017).
Accessed:2019-02-20.
[20] Konstantin Serebryany.2017. https://github.com/google/fuzzer-test-suite/blob/
master/engine-comparison/tutorial/abTestingTutorial.md . (2017). Accessed:
2019-02-20.
[21]S. Sparks, S. Embleton, R. Cunningham, and C. Zou. 2007. Automated Vulner-
ability Analysis: Leveraging Control Flow for Evolutionary Input Crafting. In
Twenty-ThirdAnnualComputerSecurityApplicationsConference(ACSAC2007) .
477ś486.
[22]NickStephens,JohnGrosen,ChristopherSalls,AndrewDutcher,RuoyuWang,
Jacopo Corbetta, YanShoshitaishvili, Christopher Kruegel, and Giovanni Vigna.
2016. Driller: Augmenting Fuzzing Through Selective Symbolic Execution. In
NDSS ’16. 1ś16.
[23]Website. 2017. BooFuzz:A fork and successor of theSulley FuzzingFramework.
https://github.com/jtpereyda/boofuzz . (2017). Accessed:2019-08-12.
[24]Website.2017. Sulley:Apure-pythonfullyautomatedandunattendedfuzzing
framework. https://github.com/OpenRCE/sulley . (2017). Accessed:2019-08-12.
[25]Website. 2020. Clusterfuzz: Trophy Case. https://github.com/google/clusterfuzz#
trophies. (2020). Accessed:2020-09-16.
[26]Michal Zalewski. 2019. AFL: American Fuzzy Lop Fuzzer. http://lcamtuf.
coredump.cx/afl/technical_details.txt . (2019). Accessed:2019-02-20.
760