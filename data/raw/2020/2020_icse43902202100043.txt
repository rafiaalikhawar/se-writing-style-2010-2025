AUTOTRAINER : An Automatic DNN Training
Problem Detection and Repair System
Xiaoyu Zhang, Juan Zhaiy, Shiqing May, Chao Shen
School of Cyber Science and Engineering, Xi‚Äôan Jiaotong University, Xi‚Äôan, China
yRutgers University, United States
Email: zxy0927@stu.xjtu.edu.cn, {juan.zhai, shiqing.ma}@rutgers.edu, chaoshen@xjtu.edu.cn
Abstract ‚ÄîWith machine learning models especially Deep Neu-
ral Network (DNN) models becoming an integral part of the
new intelligent software, new tools to support their engineering
process are in high demand. Existing DNN debugging tools are
either post-training which wastes a lot of time training a buggy
model and requires expertises, or limited on collecting training
logs without analyzing the problem not even Ô¨Åxing them. In this
paper, we propose A UTOTRAINER , a DNN training monitoring
and automatic repairing tool which supports detecting and auto-
repairing Ô¨Åve commonly seen training problems. During training,
it periodically checks the training status and detects potential
problems. Once a problem is found, A UTOTRAINER tries to Ô¨Åx
it by using built-in state-of-the-art solutions. It supports various
model structures and input data types, such as Convolutional
Neural Networks (CNNs) for image and Recurrent Neural Net-
works (RNNs) for texts. Our evaluation on 6 datasets, 495 models
show that A UTOTRAINER can effectively detect all potential
problems with 100% detection rate and no false positives. Among
all models with problems, it can Ô¨Åx 97.33% of them, increasing
the accuracy by 47.08% on average.
Index Terms ‚Äîsoftware engineering, software tools, deep learn-
ing training
I. I NTRODUCTION
In the new Software Engineering (SE) 2.0 era, software is
developed with an intelligent component which is usually pow-
ered by Machine Learning (ML) techniques. Recent advances
in Deep Learning (DL) have already made it possible for end
users to beneÔ¨Åt from the intelligence of software. For example,
Google has deployed new DL based NLP techniques to help
improve its search results [ 1]. Facebook launched Shops which
bring more businesses online during the COVID pandemic,
and made it possible to search for clothes using over tens
of thousands of image attributes. All of these are enabled by
software created in SE 2.0.
With this new trend of SE 2.0, developing the DL com-
ponent, represented by Deep Neural Network (DNN) models,
becomes an integral part of the whole process. DNN models
and other DL methods, just like other programs, also have bugs
and its own vulnerabilities, which brings many new challenges
of SE research on debugging and repairing DNN model and
its development process. New tools that can help the devel-
opment of intelligent components will greatly help developers
especially for the ones who are new to these techniques. There
are already some efforts trying to study this problem [ 2,3].
For example, MODE [ 4], proposed as a DNN debugging
technique, identiÔ¨Åes faulty neurons that lead to undesirablebehaviors and selects additional training samples to correct
these neurons behaviors to improve model accuracy. We refer
to such techniques as post-training techniques, which focuses
on Ô¨Åxing model problems whose training has been completed.
However, many existing tools are not automatic and require
expertises, which makes them difÔ¨Åcult to use for developers
new to this Ô¨Åeld. More importantly, we observe that many DNN
problems have been exposed in the training process , and post-
training techniques have a delay in detecting such problems.
As such, a lot of resources are wasted in training a problematic
model which can be saved if we can detect the problem early in
training. Thus, a runtime monitoring and detecting technique
is highly needed.
Existing DNN training frameworks have provided lim-
ited support for training monitoring and detection. Tensor-
Board [ 5], known as the default debugger of TensorFlow is a
toolkit which can record various values and provide the visu-
alization during the training process. For example, it can track
and visualize metrics like loss, and demonstrate histograms of
weights as they change over time. There are some other similar
tools, such as Visdom [ 6], TensorWatch [ 7], and Manifold [ 8].
Just like traditional debuggers (e.g., Microsoft Visual Studio
Debugger which allow programmers to track variable values
and operations as well as monitoring the changes of computing
resources, these tools can facilitate developers in inspecting
and understanding the model training status. However, they
lack the capability of analyzing the collected data and provide
meaningful Ô¨Åxes, which makes them less useful.
Through our analysis, we found that 1) a training problem
happens or not is random even for the same training script; 2) a
training problem happens randomly during the training whole.
To be more speciÔ¨Åc, because of the randomness in training
(e.g., initialization of weight values, training data sequences),
running the same training scripts may get different results. As
such, a training problem may happen in some cases but not
in other cases. And similarly, a training problem may happen
in any training iteration (if it happens). We have provided real
cases in ¬ßIII. Considering the fact that many DNN training
tasks may take days or even months, it is infeasible for
developers to watch the numbers or curves all the time to
manually detect potential problems which may occur at any
time. Unfortunately, although these runtime tools can collect
and exhibit data, they are incapable of analyzing the data to
diagnose problems, let alone leveraging solutions to alleviate
3592021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)
1558-1225/21/$31.00 ¬©2021 IEEE
DOI 10.1109/ICSE43902.2021.00043
these training problems. To address the aforementioned limita-
tions, a tool that relieves developers from manually monitoring
the training procedure is needed. In addition, the tool will have
to automatically analyze data, diagnose and resolve problems
during training, so as to increase productivity and efÔ¨Åciency
for developers as well as improve the reliability of intelligent
software systems.
In this paper, we propose A UTOTRAINER , a dynamic
approach that detects and repairs potential DNN training
problems. The training problems that A UTOTRAINER focuses
on are vanishing gradient, exploding gradient, dying ReLU,
oscillating loss and slow convergence, and A UTOTRAINER
is capable of handling various model structures including
convolutional neural networks (CNNs) and Recurrent Neural
Networks (RNNs). And these can be easily extended as
long as a problem deÔ¨Ånition is provided. Given a model
with its training conÔ¨Åguration (e.g., hyper-parameter, opti-
mizers), A UTOTRAINER will start training the model and
record relevant data like loss values. During the moni-
toring, A UTOTRAINER conducts regular analysis to recog-
nize potential training problems. If a problem is detected,
AUTOTRAINER will try to Ô¨Åx it with built-in solutions. These
solutions are constructed based on the state-of-the-art work,
which have been demonstrated to work well in solving the
corresponding problems [ 9‚Äì12]. During the repair (retraining)
procedure, if another problem is detected, A UTOTRAINER will
regard the old problem as resolved and attempt to repair the
new problem. If no more problems are detected, it means all
the problems have been addressed by A UTOTRAINER and the
trained model with its conÔ¨Åguration is delivered to the user. If
AUTOTRAINER fails to solve this problem, it will notify the
user with complete training log. Our contributions are:
We summarize and formalize deÔ¨Ånitions for the symp-
toms of 5 common training problems.
We propose the Ô¨Årst automatic approach to detect and
repair 5 different training problems during model training.
We develop a prototype A UTOTRAINER based on the
proposed idea, and evaluate it with 6 public datasets
and 495 models. The evaluation results demonstrate that
AUTOTRAINER can effectively detect all 316 problems
for 262 models and repair 309 problems of them with
a ratio of 97.78%. On average, the test accuracy can be
improved from 32.46% to 79.55% (1.5x higher).
Our implementation, collected datasets, conÔ¨Ågurations,
and problem solutions are publicly available at [ 13].
Threat to Validity. We have tried our best to obtain as many
models as possible. A UTOTRAINER is currently evaluated
on 6 datasets and 495 models, which may still be limited.
Similarly, there are many conÔ¨Ågurable parameters used in
AUTOTRAINER , and even though our experiments show that
they are good enough to achieve high detection and repair
results, this may not hold when the number of models is
signiÔ¨Åcantly larger. To mitigate these threats, all the original
and repaired training scripts, model architecture and training
conÔ¨Åguration details, implementation including dependencies,and evaluation data (e.g., training logs) are publicly available
at [13] for reproduction.
II. B ACKGROUND
A. DNN Model Training
A DNN model is a parameterized function F:X7!Y,
wherex2Xis anm dimensional input (i.e., x2Rm) and
y2Yis the corresponding output label. It usually composes
of several connected layers. Formally, an n-layered DNN can
be written as F=l1l2ln, wherelrepresent a
layer. Each lcan be expressed as a function whose output is
Fl=(lFl 1+bl)wherelandbare the weight and
bias values of layer l.is known as the activation function
(¬ßII-C ). The input layer l1takes raw inputs and passes them
on to the subsequent layer. Hidden layers extract the features
of the input, and the output layer lnis trained to predict
the output based on the extracted features. The links between
consecutive layers are represented using a set of matrices. The
numerical values in such matrices are referred to as weight
parameters. Given a large set of input-output pairs ( xi;yi),
training a DNN model is to update all weight parameters 
to minimize the differences between a predicted result F(x)
and the corresponding ground truth label y. Such differences
are measured by a loss function L(F(x);y). Thus, training a
DNN essentially is to minimize the value of L.
SpeciÔ¨Åcally, training a DNN model consists of the following
phrases. The Ô¨Årst step is initialization which initializes the
weight matrices. Then starting from the input layer, the for-
ward propagation step uses existing weight values to predict
output labels for the training samples, and calculates the
value ofLbased on predicted output and ground truth labels.
Afterwards, the backward propagation step tweaks the weight
values from the output layer all the way back to the input
layer, trying to minimize the difference using an optimization
method which is usually a gradient descent algorithm or its
variants. The forward propagation and backward propagation
steps will be repeated until the difference converges to a
minimum value meaning reaching the stopping criteria, or has
reached the maximal number of training iterations allowed.
B. Gradient Descent
In DNN model training, a loss function evaluates the
prediction ability of a DNN model, and a smaller value of the
loss function means a better model. Thus, the training goal is
to obtain weight values which result in a minimum loss value.
Gradient descent algorithm and its variants are commonly used
to solve this optimization problem. It works by tweaking the
weights in the opposite direction to the gradient of the loss
function. SpeciÔ¨Åcally, each weight has an update proportional
to the partial derivative of the loss function with respect to the
current weight. The gradients are usually calculated by auto
differentiation (AD) techniques leveraging the chain rule. As
such, computing the gradient for a weight has an effect of
multiplying many numbers (from subsequent layers).
Normally, a neural network is designed to have many layers
to improve its capacity. Increasing the number of layers can
360enable a neural network to train on a large-scale training
dataset and efÔ¨Åciently learn more complex mapping functions
from inputs to outputs. However, the addition of layers can
have negative impacts on training. The common problems are
vanishing gradient andexploding gradient .
Problem 1 (Vanishing Gradient Problem) .In backward prop-
agation, when the gradient is computed by multiplying many
small number, the gradient can be vanishingly small, espe-
cially for layers that are close to the input layer. Consequently,
the weights can hardly be changed and the loss function can
end up with a very large value, meaning the trained model
would have a low accuracy. Such a problem is referred to as
vanishing gradient (VG).
Symptoms of VG. The gradient decreases exponentially from
layer to layer and is close to zero in the layers close to the
input layer, and the training accuracy remain low.
Problem 2 (Exploding Gradient Problem) .In contrast to
VG, the gradient can grow exponentially as it is propagated
backwards. This also leads to NaN or unexpected large values,
which results in bad model accuracy. Such a problem is
referred to as exploding gradient (EG).
Symptoms of EG. The gradient increases exponentially from
(output) layer to (input) layer during backward propagation
and can become large or even NaN value in the layers close
to the input layer, and the training accuracy is low.
C. Activation Function
Intuitively, each neuron in a DNN can be regarded as one
special feature to differentiate between the given inputs. Given
a set of inputs, each neuron computes the weighted sum and
then adds a bias to the sum. After that, an activation function
takes the computed sum as input and produces an output for
the neuron. SpeciÔ¨Åcally, the activation function determines
how much the input is relevant for the following stage, guiding
the neural network to leverage important features and suppress
irrelevant features.
ReLU (RectiÔ¨Åed Linear Unit) is a widely-used activation
function in a neural network [ 14‚Äì16], which outputs the
same value if the input is positive and outputs zero if the
input is non-positive (i.e., ReLU (x) =maxfx;0g). Existing
work [ 17] has demonstrated its excellent training effect. It
effectively improves the sparsity of the model, achieving better
training convergence and accuracy. However, using ReLU has
its own limitations, among which dying ReLU is the most
common and serious one.
Problem 3 (Dying ReLU) .When a ReLU neuron receives a
non-positive input, it will output zero, making the neuron inac-
tive. In such cases, the neuron is very likely to remain inactive
forever since a gradient-based optimization algorithm will not
tweak the weights for an inactive neuron. Consequently, such
neurons cannot be leveraged to distinguish between the inputs
and ground truth, and if there are many such neurons, we may
end up with a large part of the neural network contributingnothing to the prediction task. This is known as the dying
ReLU (DR) problem.
Symptoms of Dying ReLU. When training a DNN with ReLU
as the activation function, the gradients of a large percentage
of the neurons are zero and the training accuracy is low.
D. Convergence
The training goal is to reduce the loss value converge to
a minimum. To determine the point of convergence, there
are usually two conditions. One is that the training time has
reached the maximal allowed iteration ( deÔ¨Åned by the user).
And the other one is that the training accuracy has reached
desired values. In some training cases, we may end up with a
set of low accuracy models even after the maximal number
of training iterations, and they are usually caused by two
problems: oscillating loss and slow convergence.
Problem 4 (Oscillating Loss) .It is inevitable for the loss value
to go up and down during the training procedure. But if there
are large changes without decreasing trend, the training may
not converge in a very long time which should be enough for
training the model. We refer to such a problem as oscillating
loss (OL).
Symptoms of OL. The training accuracy keeps Ô¨Çuctuating in
a large range for a long time.
Problem 5 (Slow Convergence) .The loss value has a high
value and decrease so slow that no signiÔ¨Åcant accuracy
improvement has been made, and it may end up with low
accuracy even when the maximal number of training iteration
is Ô¨Ånished. We refer to such a problem slow convergence (SC).
Symptoms of SC. The training accuracy holds a low value
for a long time even though the loss is decreasing slowly.
III. I DENTIFYING DNN P ROBLEMS DURING TRAINING
As far as we know, there is no existing tool that can
help users identify the aforementioned DNN problems during
training. TensorFlow provides a TensorBoard Debugger [ 5]
tool to help users inspect program variables (e.g., loss value)
and inserting assertions. PyTorch also allows users to do the
same thing by using PyTorch Hooks [ 18]. However, it requires
expertises to perform the required analysis and patching to
solve this problem. While many of these problems are common
problems in DNN training, their symptoms and solutions
have been studied and analyzed. In this paper, we propose
AUTOTRAINER , a DNN training tool that can automatically
monitor DNN internal values (i.e., neuron activations and
gradients), loss values and training accuracy values during the
training procedure and inspect possible problems. If a problem
is identiÔ¨Åed, A UTOTRAINER will try to automatically Ô¨Åx it.
AUTOTRAINER is designed to be a training time monitoring
and Ô¨Åxing tool because of the following:
Training problem occurrence is highly random. When
training a model using the same conÔ¨Åguration and training
dataset for multiple times, whether a problem occurs or not
36120% 
80% 20 cases     Avg ACC: 85.34%  Dying ReLU  Not Happened:  
80 cases     Avg ACC: 11.35%  
Repaired ACC: 93.23%  Dying ReLU  Happened:  (a)Occurrence
50% 
9%8% 4% 29% 0~9: 50 cases Avg Acc: 90.36% 
10~19:  9 cases Avg Acc: 89.82%  
20~29:  8 cases Avg Acc: 86.89%  
30~49:  4 cases Avg Acc: 85.99%  
No 29 case Avg Acc: 90.47%  
Repaired Acc: 97.65%  (b)Time of Occurrence
Figure 1. Problems Occurrence and Time of Occurrence are Random
in a training procedure is random. This is because there are
many random values used in DNN training. For example, the
weight values are usually initialized with random values. In
some cases, one problem will occur because of these random
values while it will not happen in some other cases.
We train a DNN model with 34 layers (650,000 parameters)
on the MNIST [ 19] handwritten digit dataset (50,000 training
and 10,000 testing samples). In this model, we also use ReLU
as the activation function, Adam as our optimizer, and set our
learning rate to be 0.001 and the maximal number of epoch to
50 (see [ 13]). We train the model for 100 times. Figure 1(a)
shows the distribution of the appearance of the dying ReLU
problem. We can see that the dying ReLU problem occurs in
80% of the training processes but not in the remaining 20%,
which demonstrates that whether a problem occurs or not is
random. The average training accuracy when the DR problem
happens is only 11.35% while the value reaches 85.34% when
there is no DR problem. With A UTOTRAINER , we are able
to detect all these DR problems and Ô¨Åx them, improving the
accuracy to 93.23%.
The time when a training problem occurs is random.
Similar to the randomness of problem occurrence challenge,
the time when the problem actually happens is also random
during training. We use a model which has the oscillating loss
problem as an example. It is a DNN model with 20 layers and
uses ReLU as activation function, Adam as optimizer, and we
set the learning rate to be 0.001 and the maximal number of
iterations is 50. Details of the training scripts is also available
in our repository [ 13]. The distribution of the stages (epoch
number) when the problem occurs is shown in Figure 1(b) . In
29% of the cases, the oscillating loss problem is not triggered.
In half cases, the problem is detected in the Ô¨Årst 10 epochs,
and the percentages of detecting the problem in other stages
are separately 9%, 8% and 4%. It demonstrates at which stage
a particular problem occurs is random.
Since our system enforces real-time surveillance, it is
able to perform timely detection and repair. For this model,
AUTOTRAINER can detect the problem at early stage (i.e.,
before 20 epochs out of 50) in the wide majority of cases (i.e.,
more than 80% of the cases where the problem occurs). After
the detection, our system attempts to resolve the problem
by leveraging four solutions (i.e., substituting initializer, in-
creasing batch size, decreasing learning rate and substituting
optimizer. See ¬ßIV). Based on our experiments, the problem is
successfully alleviated in all cases, and improves the accuracy
to 97.65%. In contrast, existing post-training methods do not
collect real-time data, making them unable to detect problems
during the training.
Problem Detection Automatic Repair 
New Solution / No  
More  Solution Signal  
Problem Recognizer Problem  
Problem 
Report  Training Monitor 
Repaired 
Failed 
Solution Scheduler Recorded Data 
Model  Well-
trained 
Model  Figure 2. Overarching Design of A UTOTRAINER
IV. S YSTEM DESIGN
Figure 2 gives the overarching design of our system, which
consists of the problem detection module (left) and the au-
tomatic repair module (right). The whole system starts by
training a model with an initial training conÔ¨Åguration and
using the problem recognizer to monitor the training. When
a problem is detected, the system will launch the automatic
repair module trying to retrain the model with new settings
until the training can Ô¨Ånish without any problem (repaired) or
a detected problem cannot be solved (failed). Notice that if
there exist several problems, our system will attempt to solve
the detected problems one by one in the order of exposure.
AUTOTRAINER takes a training conÔ¨Ågurations (i.e., the
original training scripts including model architecture, loss
function, optimizer etc.), and user preferences as in-
puts. The user preferences are conÔ¨Ågurable parameters for
AUTOTRAINER , which includes preferred repair solutions and
so on. A UTOTRAINER has a set of default values for them, and
user can replace them. Details will be presented in ¬ßIV-B . The
problem detector monitors training information like loss value.
During this, the problem recognizer is triggered on a timely
basis to analyze the recorded data to recognize symptoms and
determine whether a training problem exists. If a problem is
detected, the automatic repair module will be leveraged to
address it. Otherwise, the training monitor will output the
trained model with its training conÔ¨Ågurations to the user.
For each problem, A UTOTRAINER has a few built-in so-
lutions to Ô¨Åx them. However, one solution may or may not
work. If the detected problem is the same as before (if any), it
means the applied solution cannot solve the problem for this
particular case. Hence, the solution scheduler will retrieve the
next one, apply it and restart training. If a new problem is
detected, the solution generator will select the corresponding
solutions to it. The order of solutions can be reorganized by
users. If none of the solutions can Ô¨Åx the problem, the solution
scheduler will report a failed case with the whole training log.
A. Training Monitor
The training monitor starts a training procedure and records
data which is used to recognize symptoms and retrain the
model when a problem is detected. The recorded data includes:
362Model deÔ¨Ånition including layers and their conÔ¨Ågurations
(e.g., kernel sizes in convolutional layers).
Optimization method deÔ¨Ånition and its parameters.
Training accuracy and loss values.
Calculated gradients for each neuron.
Hyper-parameters and other necessary variables used in
training, such as the batch size and learning rate.
Note that the data of each training procedure will be
recorded separately and can be queried by the user.
B. Problem Recognizer
The problem recognizer regularly conducts analysis on the
recorded data to recognize training problems. The symptoms
leveraged to detect problems are formalized and shown in
Table I . The Ô¨Årst column lists the training problems and the
second column speciÔ¨Åes the symptoms involving gradient and
training accuracy. If the depicted condition is met, our system
regards the corresponding symptom as observed. The last
column presents the built-in solutions in A UTOTRAINER .
VG. We formalize the symptom of the VG problem as
two conditions. Firstly, there has not been a trained model
whose accuracy is good enough to terminate the training
(max(Acc)). This check is by default enabled and
checked by all existing DNN training platforms already. If
there is such a model, the training should have terminated.
Secondly, in the recent 1training iterations, the gradient has
been drop from layer to layer in the backward propagation and
the gradient becomes to be very small (smaller than a threshold
value2). To measure the change and value of gradients, we
use thel2-norm, which is borrowed from existing literature in
the AI research community [ 20‚Äì22].
EG. The deÔ¨Ånition of EG symptoms are very similar to that
of VG except that the gradient is growing from layer to layer
in backward propagation or it has already become NaN values
in some layer (meaning that it cannot propagate back to the
input layer already).
DR. Dying ReLU means that there has been a set of neurons
whose gradients have been 0in the recent a few iterations
([k 3;k]) and this set is large forms a large portion of
the whole DNN (more than a threshold value ) while the
accuracy of the neuron net work is still low.
OL. Intuitively, the symptom of an OL problem is that there
has been a lot of oscillating loss values from the start till
now. To measure if there are oscillating loss values, we Ô¨Årst
extract two lists of loss values, AandBrepresenting the
maximum optimal and minimal optimum loss values (in time
order) respectively. Then, we calculate the degree of oscillation
by computing the differences of a consecutive pair of elements
inAandB. If the oscillation is larger than , we think this is
a signiÔ¨Åcant oscillation, and if such oscillation happens very
frequently, we think there is an OL problem.
SC. By deÔ¨Ånition, SC means the accuracy of trained models
is growing slowly. To check this problem, A UTOTRAINER
checks the training accuracy change for the past iterations.
If the change has been small, it indicates that the traininghas been trapped into a local optimal point, and the training
process has failed to improve it. Based on this, A UTOTRAINER
determines that the SC problem happens.
C. Solution Scheduler
The main role of the solution scheduler is to pick one
solution to Ô¨Åx the problem and restart the training procedure.
For the same problem, it will try each possible solution one by
one based on the default order if users do not specify preferred
orders. If one solution can Ô¨Åx the problem, the scheduler will
not be triggered by the same problem. Otherwise, it will try
a new solution. And if none of these solutions can Ô¨Åx it,
AUTOTRAINER fails to resolve this problem and will report
this to the user to determine what to do next.
D. Existing Solutions
There has been some study on how to solve training prob-
lems. Unfortunately, there is no silver bullet and one solution
cannot be guaranteed to work for all cases. For each problem,
AUTOTRAINER collects a few possible solutions which have
been shown to be effective in prior study and uses them to Ô¨Åx
detected training problems, and these solutions include:
S1: Adding Batch Normalization Layers. Batch normal-
ization is a method used to normalize the neuron values
of a layer by re-centering and re-scaling them. This helps
remove the unexpected gradient and neuron activation values.
SpeciÔ¨Åcally, the normalization will squeeze the values into a
speciÔ¨Åc range, and as such, small gradient updates will not
diminish or explode during the backward propagation, mean-
ing that the vanishing and exploding gradient problem can be
alleviated [ 9,26]. In addition, such value range enforcement
reduces the possibility of getting an inactive neuron and help
resolve the Dying ReLU problem.
Regarding to the problem of where to add batch nor-
malization layers, authors of this method [ 9] has performed
analysis and demonstrated that adding batch normalization
before activation function layers gives the best result. We
follow this guidance and implemented our solution.
S2: Substituting Activation Functions. As aforementioned,
ReLU is a commonly adopted activation function. The gradient
of ReLU activation is 1 when the input is greater than 0,
meaning the gradient will remain the same without decreasing
or increasing dramatically (if used with the proper optimizer
and learning rate). Hence, substituting the current activa-
tion function with ReLU and its variants (e.g., SELU [ 10],
LeakyReLU [ 27]) can mitigate both the vanishing gradient
problem and the exploding gradient problem.
S3: Adding Gradient Clipping. Gradient clipping clips
gradient values that exceed a speciÔ¨Åed range, which essentially
limits the update of a weight value to a limited region. Unlike
batch normalization and other normalization methods, this
method clips the gradient values based on a threshold. By
removing obviously large gradient values, it can be used to
alleviate the exploding gradient problem [ 28‚Äì30].
Bengio et al. [ 30] and many others [ 29] have studied and
evaluated the concrete values to use in gradient clipping, and
363TABLE I: Problem Symptoms and Repair Solution Candidates
Training Problem Symptom Solution
Vanishing Gradient
[20‚Äì22]Gradient:8i2[k 1;k],Gi
l2
Gi
l3:::Gi
ln 1
Gi
ln1VGi
l22S1: Adding Batch Normalization Layers
S2: Substituting Activation Functions
Accuracy:max(Acc)
Exploding Gradient
[20‚Äì22]Gradient:8i2[k 2;k],Gi
l2
Gi
l3:::Gi
ln 1
Gi
ln3W9j2N;Gi
j=NaNS1: Adding Batch Normalization Layers
S2: Substituting Activation Functions
S3: Adding Gradient Clip
Accuracy:max(Acc)
Dying ReLU
[23]Gradient:8i2[k 3;k],jfj2Nj;Gi
j=0gj
jNjS1: Adding Batch Normalization Layers
S2: Substituting Activation Functions
Accuracy:max(Acc) S4: Substituting Initializer
Oscillating Loss
[24]Accuracy:jfi2[1;min (jAj;jBj)]jA[i] B[i]gj
kS4: Substituting Initializer
S5: Adjusting Batch Sizes
S6: Adjusting Learning Rate
S7: Substituting Optimizer
Slow Convergence
[25]Accuracy:8i2[1;k];jAcc[i] Acc[i 1]jS4: Substituting Initializer
S6: Adjusting Learning Rate
S7: Substituting Optimizer
1Gb
a, the gradient of layer ain iterationb
2n, the number of layers of a DNN
3N, all neurons of a DNN
4k, the current training iteration
51=2=3, thresholds for iterations61=2=3, thresholds for gradients
7, the training accuracy threshold
8, the threshold for the percentage of neu-
rons with 0 gradients
9, the threshold for accuracy difference10, the threshold for the difference of max-
imum and minimum optimal
11, the threshold for the percentage of times
of large loss Ô¨Çuctuation12Acc , accuracy arry for each iteration
13max , the maximum function
14A=B , arraies of maximum/minimum op-
timal
recommend to clip the gradient of each layer to [ 10;10]
which is adopted by A UTOTRAINER .
S4: Substituting Initializers. Initializers set a starting point
for the optimizers during model training. Thus, inappropri-
ate initialization can cause disasters in training deep neural
networks. Xavier initialization [ 31] was proposed solve the
oscillating loss and slow convergence problem by initiating the
weight values to a proper range. Lu et al. [ 11] have shown that
the popular initialization schemes like He Initialization [ 32]
suffers from the Dying ReLU problem. In ¬ßIII, we also showed
a case where the initialization values can affect the model
training. Thus, we also try to substitute the used initializers
when a model encounters the Dying ReLU, slow convergence
or oscillating loss problems.
S5: Adjusting Batch Sizes. Batch size is the number of
training samples used in one iteration to estimate the error
gradient, which is an important hyper-parameter. A too large
batch size might make the loss value trap into a poor local
minimum, leading to low accuracy, while a too small batch
size might make the loss bounce around a lot, leading to
oscillating loss [ 12,33]. In practice, increasing the batch size
appropriately has the potential to improve the stability of the
training and solve the oscillating loss problem.
Setting the proper batch size is not easy for DNN training,
and various researchers have performed analysis and evalu-
ation and this [ 12,29,30]. Based on our study, LeCun et
al. and Bengio et al. suggest using 32 as the starting point.
Following this, we try to initialize the batch size to be 32.
If the accuracy is too low, we try to descries the batch size
by a factor of 2 until it reaches 8. If the OL occurs, we will
increase the batch size also by doubling until it reaches 256
(according to Masters et al. [ 12]).
S6: Adjusting Learning Rates. Learning rate is a hyper-
parameter that determines the amount of change to the modelin each update (i.e., each backward propagation). If the learn-
ing rate is too large, the weights are likely to have Ô¨Çuctuating
update and the loss value will oscillate and even increase over
training epochs [ 28]. Given this, decreasing the learning rate
can be helpful to tackle the oscillating loss problem.
Generally, a small learning rate makes it possible for the
model to learn more optimal or even globally optimal weights
with the risk of taking a very long time to Ô¨Ånish the training.
At one extreme, the training may never converge to a low loss
value even after the maximal number of training epochs. As
such, the slow convergence problem might be resolved if the
learning rate is increased [ 28].
The values we set for learning rates depend on different
optimizers they use. We follow the suggestions made by
their original authors (e.g., Adam [ 34]) and existing empirical
evidence [ 35,36]. SpeciÔ¨Åcally, we choose 0.01 for SGD based
optimizers,and 0.001 for Adam and other adaptive optimizers.
If the slow convergence problem still exists, A UTOTRAINER
increases it 10 times; and if the oscillating loss problem still
exists, A UTOTRAINER decreases it by a factor of 10.
S7: Substituting Optimizers. Optimizers are algorithms
used to update weights to reduce the loss value. An optimizer
can have different performance in different scenarios. Practi-
cally, a substitution of an optimizer can help address various
training problems. Stochastic Gradient Descent (SGD) [ 37]
is a variant of the basic gradient decent algorithm, which
computes an estimated gradient on a randomly selected small
subset of data samples instead of computing an actual gradient
on the entire dataset. Based on the rationale, the weights are
updated more frequently in SGD which can speed up the
convergence. However, the high variance in weights may result
in Ô¨Çuctuations in the loss value.
Momentum [ 38] is a method introduced to speed up SGD
and dampen loss oscillations. It works by adding a fraction
of the update in the past time step to the current update.
364Usually the value of momentum is set as 0.9 or a similar
value. The value 0.9 means the weights will update based on
90% of the previous gradient and 10% of the new gradient.
Such a mechanism achieves a faster convergence and fewer
oscillations compared with SGD. However, if the momentum
is too much, we may swing back and forth near the local
minimum without hitting the minimum. Adaptive Moment Es-
timation (Adam) [ 34] is a widely adopted optimizer that uses
momentum and adaptive learning rates. The adaptive learning
rate allows us to start with large learning rate and Ô¨Ånish with
small learning rate. As the learning rate is decreasing, we will
take smaller and smaller steps, which can prevent us from
missing the local minimum and accelerate the convergence.
In a nutshell, we can use algorithms with momentum like
SGD+Momentum or Adam to alleviate the oscillating loss
problem, and randomly use a different optimizer to alleviate
the slow convergence problem.
V. E VALUATION
The prototype of A UTOTRAINER is implemented on top of
Keras 2.3.1 [ 39] and TensorFlow 2.1.0 [ 40]. In the evaluation,
we aim to answer the following research questions:
RQ1: How effective is A UTOTRAINER in detecting and Ô¨Åxing
training problems?
RQ2: How efÔ¨Åcient is A UTOTRAINER in detecting and Ô¨Åxing
training problems?
RQ3: What is the impact of different conÔ¨Ågurable parameters
in A UTOTRAINER ?
A. Setup
We performed our experiments on six popular datasets: Cir-
cle [41], Blob [ 42], MNIST [ 19], CIFAR-10 [ 43], IMDB [ 44]
and Reuters [ 45]. Circle and Blob are two datasets from
SKLearn [ 46] for classiÔ¨Åcation tasks. MNIST is a gray-scale
image dataset used for handwritten digits recognition. CIFAR-
10 is a colored image dataset used for object recognition.
IMDB is a movie review dataset for sentiment analysis.
Reuters is a newswire dataset for document classiÔ¨Åcation.
In total, we collected 495 models and their training scripts
with various DNN models structures (CNN, RNN and fully
connected layers only) for these six datasets. Among them,
262 of them have training problems and the rest are normal
models, which have been conÔ¨Årmed by model authors. Most
models are collected from reported buggy models on GitHub,
StackOverÔ¨Çow, existing papers and personal blogs, and some
of them are gathered from machine learning experts within
our organization. The training scripts of these models and all
experiment results are all public at our repository [ 13].
If not speciÔ¨Åed, all experiments in this section are conducted
on a server with Intel(R) Xeon E5-2620 2.1GHz 8-core
processors, 130 GB of RAM and a NVIDIA TITAN V GPU
running Ubuntu 18.04 as the operating system.B. Effectiveness of AUTOTRAINER
Experiment Design: To evaluate the effectiveness of
AUTOTRAINER , we run our collected 495 model training
scripts to test the effectiveness of A UTOTRAINER . Due to
the randomness in performing these experiments, we run the
training multiple times to ensure that the problem have been
exposed, and collect the experiment results of such cases. To
measure the effectiveness of A UTOTRAINER , we start two
parallel trainings for the same model. To reduce the effects
of randomness, we enforce them to share the usage of the
same random number including the initialization weights.
They also share the same set of training hyper-parameters and
optimization methods. During training, we collected training
logs including gradient, loss values, etc., to help us verify
the whole process. At the end, we manually verify them
and conÔ¨Årm them with the details provided by buggy model
providers (i.e., online posts and machine learning experts).
Results: For all 262 buggy trainings, we detect 316 training
problems as some models have more than one. Table II
demonstrates partial results. The Ô¨Årst column lists the six
datasets. The second column shows the model status and the
corresponding number of models. ‚ÄúRepaired‚Äù status indicates a
model is successfully repaired if any target problem is detected
and ‚ÄúFailed‚Äù indicates that the problem still exists even after
AUTOTRAINER has tried all built-in solutions. Lastly, we
use the ‚ÄúNormal‚Äù status to denote models without training
problems. The third column lists model identiÔ¨Åcation numbers,
and the fourth column shows the number of detected problems
of each model. The following columns denote the accuracy,
the training time and the memory consumption (efÔ¨Åciency
results, see ¬ßV-C ). Column ‚ÄúOriginal‚Äù shows the information
for the original model training (without A UTOTRAINER ) while
column ‚ÄúAT‚Äù (short for A UTOTRAINER ) shows that of the re-
paired models. Column ‚ÄúRatio‚Äù gives the ratio between the val-
ues of a repaired model and the corresponding original model.
Column ‚ÄúImprove‚Äù shows the absolute accuracy improvement
that our system achieves. The cells in purple separately corre-
spond to the models with the highest accuracy improvement,
maximum training overhead and maximum memory overhead
while the cells in grey separately correspond to the ones
with least accuracy improvement, minimum training overhead
and the minimum memory overhead. All detailed experiment
results can be found at our repository [ 13].
Notice that the same problem may get repaired using differ-
ent solutions, and after A UTOTRAINER repairs the model, its
accuracy may not be improved. To evaluate the repair effects,
we also calculated the number of problems that are Ô¨Åxed
by individual solutions and the change ranges in accuracy.
The results are separately shown in Table III ,Table IV and
Figure 3 . InTable III , the Ô¨Årst column shows the datasets, and
the following columns present the problem and corresponding
solutions. The solutions are (from left to right) ordered by their
default priority used for repairing in A UTOTRAINER . Each
number in the top half of the table denotes the number of
problems that are repaired successfully by the corresponding
365TABLE II: Overall Results of A UTOTRAINER
Accuracy Train Time Average MemoryDataset Status Model #ProblemOriginal (%) AT (%) Improve (%) Ratio Original (s) AT (s) Ratio Original (MB) AT (MB) Ratio
1 1 20.33 86.00 65.67 4.23 18.53 44.35 2.39 1580.68 1571.75 0.99
2 1 85.33 84.67 -0.67 0.99 31.06 65.06 2.09 1554.12 1552.32 1.00
3 3 30.67 85.00 54.33 2.77 15.86 586.63 36.98 1564.95 1565.12 1.00
4 1 40.33 83.67 43.33 2.07 17.99 24.03 1.34 1550.91 1554.17 1.00
5 1 53.00 84.67 31.67 1.60 21.00 33.04 1.57 1575.69 1582.19 1.00
6 1 50.33 83.67 33.33 1.66 12.99 30.99 2.39 1282.06 1258.63 0.98Repaired: 46
Ave 1.13 43.31 81.04 37.73 1.87 13.67 51.78 3.79 1505.91 1505.24 1.00
47 1 33.67 33.67 0.00 1.00 16.03 109.56 6.84 1576.94 1574.19 1.00
48 1 33.67 33.67 0.00 1.00 6.89 86.64 12.57 1574.70 1573.95 1.00 Failed: 2
Ave 1 33.67 33.67 0.00 1.00 11.46 98.10 8.56 1575.82 1574.07 1.00
49 - 67.67 - - - 15.61 17.74 1.14 1505.91 1486.04 0.99
50 - 70.67 - - - 15.71 16.94 1.08 1514.26 1509.71 1.00Blob
Normal: 39
Ave - 76.27 - - - 16.36 17.68 1.08 1562.39 1561.12 1.00
88 1 n.a 88.33 88.33 n.a 18.00 28.44 1.58 1320.03 1321.28 1.00
89 1 87.33 86.33 -1.00 0.99 22.98 71.85 3.13 1325.53 1326.22 1.00
90 2 49.67 78.00 28.33 1.57 3.50 57.18 16.35 1332.55 1332.32 1.00
91 1 54.33 87.67 33.33 1.61 60.88 74.27 1.22 1358.89 1358.89 1.00Repaired: 71
Ave 1.10 46.97 83.56 36.60 1.78 28.05 67.60 2.41 1336.85 1336.12 1.00
159 - 76.67 - - - 16.20 16.94 1.05 1305.43 1302.58 1.00
160 - 68.00 - - - 29.14 30.53 1.05 1313.31 1306.58 0.99Circle
Normal: 36
Ave - 81.43 - - - 28.01 29.29 1.05 1342.73 1342.25 1.00
195 2 10.00 71.73 61.73 7.17 73.48 1180.53 16.07 4477.29 3774.16 0.84
196 1 57.72 69.46 11.74 1.20 73.80 139.98 1.90 4359.05 3655.91 0.84
197 2 10.00 65.67 55.67 6.57 409.89 431.13 1.05 3021.97 3004.28 0.99
198 1 8.12 65.44 57.32 8.06 93.24 129.31 1.39 3744.07 5034.64 1.34
199 1 10.00 67.82 57.82 6.78 214.44 295.44 1.38 3589.40 2817.81 0.79Repaired: 45
Ave 1.02 13.11 66.80 53.69 5.10 248.96 522.22 2.10 3679.23 3513.32 0.95
Failed: 1 240 1 10.00 10.00 0.00 1.00 382.79 492.60 1.29 3777.13 3777.13 1.00
241 - 65.37 - - - 342.88 319.32 0.93 4452.32 3749.12 0.84
242 - 56.56 - - - 236.45 244.89 1.04 3749.78 3753.79 1.00CIFAR-10
Normal: 35
Ave - 63.48 - - - 145.63 146.39 1.01 3946.77 3826.03 0.97
276 1 9.33 99.17 89.84 10.63 148.82 212.36 1.43 3084.37 3083.77 1.00
277 1 88.44 99.12 10.68 1.12 267.11 401.37 1.50 3226.07 3188.81 0.99
278 2 9.80 99.20 89.40 10.12 365.55 2294.69 6.28 3283.42 3283.67 1.00
279 1 35.08 98.89 63.81 2.82 331.44 365.42 1.10 3475.25 3286.04 0.95
280 1 9.50 99.21 89.71 10.44 123.55 225.97 1.83 3143.98 3356.33 1.07
281 1 16.14 99.11 82.97 6.14 65.40 123.88 1.89 3347.91 3138.69 0.94Repaired: 38
Ave 1.13 16.22 98.88 82.66 6.10 220.74 493.14 2.23 3085.09 3026.66 0.98
314 - 98.79 - - - 173.85 173.47 1.00 3203.96 3198.19 1.00
315 - 86.54 - - - 135.93 136.42 1.00 3168.69 2925.68 0.92MNIST
Normal: 78
Ave - 96.89 - - - 228.43 228.79 1.00 3251.75 3203.40 0.99
392 1 4.19 66.74 62.56 15.93 645.01 1023.98 1.59 2247.90 2361.28 1.05
393 1 56.86 57.30 0.45 1.01 855.34 2844.38 3.33 2413.77 2481.97 1.03
394 1 47.91 52.45 4.54 1.09 1278.41 4778.25 3.74 2312.99 2360.14 1.02
395 1 n.a. 62.91 62.91 n.a. 1316.38 1321.00 1.00 1859.90 1869.22 1.01
396 1 n.a. 58.46 58.46 n.a. 2591.11 4363.19 1.68 1823.66 1758.23 0.96Repaired: 31
Ave 1 21.37 59.23 37.87 2.77 1411.38 2894.73 2.05 2214.09 2250.93 1.02
Failed: 1 423 1 36.02 36.02 0.00 1.00 1484.00 1460.37 0.98 1881.61 1820.14 0.97
424 - 47.13 - - - 1466.05 1510.32 1.03 1912.03 1927.08 1.01
425 - 46.15 - - - 1400.59 1471.97 1.05 1901.38 1930.53 1.02Reuters
Normal: 32
Ave - 51.75 - - - 1222.65 1249.35 1.02 2307.96 2347.96 1.02
456 1 n.a 87.08 87.08 n.a 3982.20 8876.97 2.23 1998.46 2069.23 1.04
457 1 82.04 80.53 -1.51 0.98 2078.05 5961.56 2.87 2251.86 2285.11 1.01
458 1 49.33 86.03 36.70 1.74 670.69 6925.99 10.33 2256.18 2342.93 1.04
459 1 49.12 85.95 36.83 1.75 1069.43 1307.58 1.22 2258.64 2345.51 1.04
460 1 49.78 86.68 36.90 1.74 1306.62 5478.55 4.19 2138.05 2317.73 1.08
461 1 50.00 86.11 36.11 1.72 3703.41 9246.12 2.50 2057.98 1854.65 0.90Repaired: 24
Ave 1 45.29 84.39 39.10 1.86 2871.01 6499.83 2.26 2153.72 2195.81 1.02
480 1 50.00 50.00 0.00 1.00 1062.77 1480.36 1.39 2182.29 2349.58 1.08
481 1 n.a n.a 0.00 n.a 2089.21 1451.98 0.69 2184.26 2044.23 0.94
482 1 n.a n.a 0.00 n.a 1300.46 2257.56 1.74 2261.88 2348.53 1.04Failed: 3
Ave 1 16.67 16.67 0.00 1.00 1484.15 1729.97 1.17 2209.47 2247.45 1.02
483 - 87.38 - - - 1951.87 1984.37 1.02 2260.38 2347.84 1.04
484 - 83.14 - - - 2022.07 2036.59 1.01 2191.92 2088.60 0.95IMDB
Normal: 13
Ave - 84.54 - - - 1828.85 1844.67 1.01 2224.19 2280.91 1.03
Normal Ave - 79.14 - - - 375.37 380.57 1.01 2591.48 2565.53 0.99
Repaired Ave 1.07 32.46 79.55 47.08 2.45 515.66 1141.79 2.21 2224.98 2195.30 0.99
Failed Ave 1 23.34 23.34 0.00 1.00 906.02 1048.44 1.16 2205.54 2212.54 1.00
366TABLE III: The Problem Repaired Results
DatasetVG EG DR SC OLTotalS2 S1 S2 S1 S3 S2 S1 S4 S7 S6 S4 S7 S6 S5 S4
Blob 10 2 10 0 0 4 3 1 29 0 0 4 0 0 0 63
Circle 9 1 9 1 0 6 3 0 43 1 0 7 1 0 0 81
CIFAR-10 5 0 7 1 0 2 1 0 27 1 0 2 0 0 0 46
MNIST 6 2 10 0 0 4 0 0 20 1 0 7 1 0 0 51
Reuters 0 3 6 0 0 - - - 19 7 0 0 4 0 0 39
IMDB 5 2 5 0 1 - - - 9 3 0 0 4 0 0 29
Total 35 10 47 2 1 16 7 1 147 13 0 20 10 0 0 309
Repaired 45 50 24 160 30 309
Failed 3 4 0 0 0 7
Total 48 54 24 160 30 316
TABLE IV: The Accuracy Improvement of Problems
#Repaired Avg Improve(%)DatasetVG EG DR SC OL VG EG DR SC OL
Blob 12 10 8 29 4 38.78 30.40 24.78 43.01 -0.50
Circle 10 10 9 44 8 30.08 82.92 28.10 33.64 10.20
CIFAR-10 5 8 3 28 2 56.17 58.50 59.81 52.72 11.74
MNIST 8 10 4 21 8 87.72 87.68 86.74 82.93 56.97
Reuters 3 6 - 26 4 20.12 50.30 - 37.58 20.77
IMDB 7 6 - 12 4 36.43 85.94 - 33.43 -0.55
Total/Average 45 50 24 160 30 45.04 66.87 46.91 46.05 16.00
solution (i.e., column name). The bottom half summaries the
number of problems of different status. The pie chart in
Figure 3 demonstrates the distrubution of change ranges in
accuracy with corresponding numbers of models.
Analysis. The experiment results demonstrate the effectiveness
of our system. Firstly, A UTOTRAINER can effectively detect
the deÔ¨Åned training problems with a 100% success rate on
all 495 model trainings, and none of the normal trainings are
mis-classiÔ¨Åed as problematic. Secondly, A UTOTRAINER can
effectively repair the buggy training procedures. After success-
ful repairing, it can improve the accuracy by 47.08% with the
maximum improvement as 89.84%. Overall, A UTOTRAINER
achieves around 46% accuracy improvement which is 2.43
times that of training without A UTOTRAINER . Notice that
when EG happens, it may result in NaN values in the model,
leading to NaN output results for all inputs. In such cases,
we do not measure the prediction accuracy and directly report
them as ‚Äún.a.‚Äù in Table II
From Table III , we observe that A UTOTRAINER is able to
respectively repair 93.75%, 92.6%, 100%, 100% and 100%
of VG, EG, DR, SC and OL in buggy trainings. And Ta-
ble IV shows the detailed average accuracy improvement
of A UTOTRAINER on different problems, which is 45.04%,
66.87%, 46.91%, 46.05% and 16.00% of VG, EG, DR, SC and
OL in repairing, respectively. Table III andTable IV demon-
strate that A UTOTRAINER is capable of handling different
types of datasets, model problems and model architectures.
Regarding SC and OL, we Ô¨Ånd that only two solutions can
effectively address all the problems we encountered in our
evaluation.
Figure 3 shows that model accuracy increase distrubution.
SpeciÔ¨Åcally, over 40.78% of the models get an increase of
50% and over 50% has an increase between 10% and 30%.
It demonstrates that A UTOTRAINER has the advantage of
effectively increasing accuracy by repairing training problems.
We also notice that there are 6 models (out of all 255 models)
17.65%  
39.22%  40.78%  [-1.51%, 0%):  6 models 
[0%, 30%):  45 models 
[30%, 50%):  100 models 
‚â• 50%:  104 models 2.35%  Figure 3. Accuracy Change After Model Training Repair.
051015202530354045501
q0%5%10%15%20%25%30%Runtime Overheadq√ót2
t1
Experiment Results
(a)Circle Dataset
051015202530354045501
q0%1%2%3%4%5%Runtime Overheadq√ót2
t1
Experiment Results (b)MNIST Dataset
Figure 4. Runtime Overhead vs. Problem Check Frequency.
whose accuracy has slight reduction after repaired. For the
worst case, the model accuracy decreases from 82.04% to
80.53%. We manually analyzed them, and found that it is
mainly because they have other problems that are not covered
by A UTOTRAINER , such as Ô¨Çoating point bugs. How to detect
and repair such problems will be one of our future directions.
C. EfÔ¨Åciency of AUTOTRAINER
Experiment Design and Results: To evaluate the efÔ¨Åciency
of A UTOTRAINER , we run all 495 model trainings with and
without A UTOTRAINER enabled. During training, we collected
the time used to train the model and the memory usage
for both the original training and A UTOTRAINER . Notice
that experiments for run-time overhead and memory overhead
are conducted individually to avoid inÔ¨Çuencing each other.
The experiments are conducted 5 times, and the overhead is
calculated as the average of these 5 runs. The results are shown
inTable II . Results and analysis are presented below.
Runtime Overhead Analysis: For normal training, the run-
time overhead is purely from problem checker, which is about
1%. From Table II , we observe that the runtime overhead on
smaller datasets is usually larger (e.g., Blob 8% vs. almost
0% for MNIST). This is because the total time for training on
small datasets is relatively short, making the runtime overhead
ratio larger. For buggy trainings, A UTOTRAINER takes 1.19
more training time on average. We performed a deeper analysis
to understand the overhead of individual components, and
found that retraining takes over 99% and the rest two parts
(i.e., problem checker and repair) takes less than 1%. It
means that A UTOTRAINER only costs little time ( 1%total
overhead) in automatically searching a suitable solution for
the problems, which requires lots of manual operations and
time-consuming in existing strategies. As discussed in ¬ßIV,
to repair a problem, it may try several times, which leads
AUTOTRAINER training several models.
Checking Frequency v.s. Runtime Overhead. More frequent
problem checking causes higher runtime overhead. Suppose
that one training iteration and one checking separately take t1
andt2time, then the overhead of A UTOTRAINER is roughly
367TABLE V: Check Frequency vs. Delay in Problem Detection
ProblemDetection Delay
1/q=2 1/q=3 1/q=4 1/q=5 1/q=9 1/q=15
VG 0.33 1.12 1.48 1.78 3.22 6.22
EG 0.38 1.38 2.38 3.38 7.38 13.38
DY 0.43 1.15 2.15 2.29 8.01 8.01
OL 0.40 1.60 1.60 2.40 3.40 6.40
SC 0.32 1.06 1.25 2.13 2.74 6.09
qt2=t1, whereqis the checking frequency. Figure 4 presents
the corelations between checking frequency and runtime over-
head on Circle and MNIST. The X-axis is the number of
iterations between two checks ( 1=q), and Y-axis is the runtime
overhead. The solid line represents the collected data and the
dashed curve is the theoretical results (i.e., qt2=t1). As we
can see, shapes of experiment data conform to our theoretical
analysis. By comparing the two Ô¨Ågures, we observe the smaller
dataset has the higher runtime overhead, which is consistent
with our data in Table II . By default, A UTOTRAINER checks
the problem every 3 iterations, which causes less than 5%
overhead even for small datasets like Circle.
Lower frequency checking can reduce the overhead, but may
cause longer delay in detection. Table V shows the effects of
different check frequencies. Each row represents one problem
type, and each column denotes a different check frequency.
Numbers in cells show the delayed iterations between the
occurrence of the problem and the detection of the problem.
Considering VG, if A UTOTRAINER performs the checking
every 15 iterations, it needs 6 extra iterations to detect it
compared with checking problems every the other iteration.
In a nutshell, a lower checking frequency may result in the
delay in problem detection, which further leads to wasting
time on a buggy training.
Memory Overhead Analysis. AUTOTRAINER has very lim-
ited memory overhead (-1% to 1%) since A UTOTRAINER
reuses data which has been collected. To detect problems,
AUTOTRAINER requires the current gradient values, and his-
torical loss and training accuracy values. The gradient infor-
mation is stored as part of the tensor data for training purpose
(used in backward propagation), and the historical loss and
training accuracy values are automatically collected by all
major frameworks. The overhead caused by A UTOTRAINER
are mostly due to program variables, which are negligible
compared with neuron and gradient values and even the
overhead introduced by the memory proÔ¨Åling tool itself.
D. Effects of ConÔ¨Ågurable Parameters
AUTOTRAINER leverages conÔ¨Ågurable parameters to deter-
mine if a problem is happening or not. We classify them into
three categories and evaluated each of them in this section.
Type-A : Type-A parameters include 1,2and3inTable I ,
which are used to determine the time window used to detect
the occurrence of VG, EG and DR problems. For these
problems, the same symptoms will also be observed in the
rest iterations once they happen in one iteration. We comÔ¨Årmed
this with 50 models and 3 runs on each model. This is also
supported by others [ 20]. Thus, we set 1,2and3to 0.Type-B : A UTOTRAINER has only one Type-B parameter,
the expected accuracy threshold , which is a training task
dependent parameter. If not, we will adopt the value which is
used to determine if the training should be early stopped, and
it is provided by Keras and TensorFlow.
Type-C : Parameters in this category include 1,2, and3for
VG and EG; for DR;andfor OL; and for SC (deÔ¨Åned
inTable I ). The values of these parameters determine whether
AUTOTRAINER can successfully capture the real problem or
not. To measure their effects on A UTOTRAINER , for each
problem, we use different values (or value pairs if a problem
involves multiple such parameters) to investigate how they
can affect the detection effectiveness. All experiments are
performed on 100 models, and they are repeated 5 times.
Figure 5 reports the Ô¨Ånal averaged results.
VG: The values of 1and2affect the detection results
of VG. If1or2is too large, it will introduce a lot of
false positives (i.e., normal trainings are identiÔ¨Åed as VG). If
they are too small, it will reduce the detection accuracy (i.e.,
true positives). Figure 5(a) demonstrates how precision and
recall are changed as the parameter values change. It conÔ¨Årms
the aforementioned analysis and suggests the default values
in A UTOTRAINER (i.e.,1:1e 3,2:1e 4) can achieve high
precision and recall.
EG:Figure 5(b) presents the relationship between precision/
recall and the value of 3. Larger3implies that EG becomes
more obvious, but it also means many EG cases which are
less serious will be missed. Hence, precision gets higher but
recall becomes very low. Luckily, when 3is between 40
and 100, A UTOTRAINER can get 100% precision and recall
simultaneously. By default, A UTOTRAINER sets3to 70.
DR: The detection results of DR is highly affected by the
value of(see Figure 5(c) ). With larger , AUTOTRAINER is
able to remove obvious False Positive (FP) cases (i.e., detected
as DR, but is not DR) increasing the precision, but also may
ignore not so serious DR problem causing low recall. When 
is set in range [60%;90%] , AUTOTRAINER achieves the best
result in precision (100%) and recall (100%). By default, is
set as 70% in A UTOTRAINER .
OL: Detecting OL requires two parameters, and, and its
relationships with precision and recall in detection are shown
inFigure 5(d) . It is consistent with our intuition that larger 
andvalues will lead to higher precision and lower recall. In
AUTOTRAINER , the default values for andare0:03and
20%, which results in 100% precision and 100% recall.
SC: The only threshold in detecting SC is . Very small 
results in very low precision and recall. On one hand, such
low accuracy change are not common during training (hence,
low recall), and on the other hand, many of them with such
low accuracy change are due to randomly initialized weights
(hence, low precision). With no-so-large values, the detection
precision and recall can grow sharply. However, larger values
may result in the ignorance of many buggy training cases,
leading to low precision. Figure 5(e) shows such a change
3680.10.0011e-051e-070.010.00011e-061e-080.00.20.40.60.81.0Precision
Recall
Œ≤1Œ≤2(a)Vanishing Gradient
0 60 120 1803
 0.00.20.40.60.81.0
Precision
Recall (b)Exploding Gradient
0%20% 40% 60% 80%100%
0.00.20.40.60.81.0
Precision
Recall (c)Dying ReLU
12%20%28%36%0.0120.020.0280.0360.00.20.40.60.81.0Precision
Recall
Œ∑Œ∂ (d)Oscillating Loss
0.0 0.008 0.016 0.024
0.00.20.40.60.81.0
Precision
Recall (e)Slow Convergence
Figure 5. AUTOTRAINER Detection Precision and Recall vs. ConÔ¨Ågurable Parameters.
curve. Based on our sampling, to achieve the best in precision
(100%) and recall(100%), should be from 0.004 to 0.014.
In A UTOTRAINER , we set the default value of as 0.01.
VI. R ELATED WORK
Machine learning techniques are widely adopted in various
SE tasks [ 47‚Äì61]. A UTOTRAINER can facilitate software en-
gineering researchers in repairing their buggy DNN models
automatically. It is highly related with DNN model debugging
and testing, and automatic program repair.
DNN Model Debugging and Testing. In addition to what we
have discussed in ¬ßI, there are some other efforts devoted on
debugging DNN models [ 62‚Äì66]. Ribeiro et al. [ 62] produced
adversarial examples as training data to debug natural language
processing models. Others [ 63,64] cleaned up training data
that are wrongly labeled to debug RNN models. LAMP [ 67]
utilizes gradient information as data provenance to help debug
graph based machine learning algorithms. Ma et al. [ 4] pro-
posed differential analysis on inputs to Ô¨Åx model overÔ¨Åtting
and under Ô¨Åtting problems. TRADER [ 65] analyzed how
problematic word embeddings affect the model accuracy by
comparing the model execution traces of correctly-classiÔ¨Åed
samples and incorrectly-classiÔ¨Åed samples.
A great number of testing methods have been proposed
to test machine learning models, such as fuzzing [ 68‚Äì75],
symbolic execution [ 76‚Äì79], runtime validation [ 80,81], fair-
ness testing [ 74,78,82], etc. DeepXplore [ 83] introduced
the neuron coverage metric to measures the percentage of
activated neurons or a given test suite and DNN model,
and generates new test inputs that can maximize the metric
to test DL systems. Many others [ 70,84‚Äì88] extended the
coverage concept and proposed to use them on many different
scenarios. Model testing has also been leveraged for many
other domains such as image classiÔ¨Åcation [ 79,89], automatic
speech recognition [ 90], text classiÔ¨Åcation [ 74], and machine
translation [ 91,92]. Recently, Yan et al. [ 93] have studied
many coverage criteria and measured their correlations with
model quality (i.e., model robustness against adversarial at-
tacks), and empirical results show that existing criteria can
not faithfully reÔ¨Çect model quality.
Automatic Program Repair. The aim of automatic program
repair is to automatically derive patches to correct bugs in
programs, which normally includes fault localization, patch
candidates generation and patch candidates validation. Many
different kinds of methods have been employed in automated
program repair. The researchers in [ 94‚Äì99,99] proposed
search-based approaches to generate patches. There are someother semantics-based methods which construct patches using
synthesis techniques [ 100,100‚Äì104]. SpeciÔ¨Åcations were also
utilized to guide the repair process [ 105‚Äì109]. More program
repair work can be found in the survey [ 110]. Different from
these research efforts, our work is to repair DNN models which
are not uninterpretable rather than the interpretable code.
Automated Machine Learning (AutoML). AutoML focuses
on automatically design models for given training tasks. Var-
ious kinds of neural architecture search (NAS) algorithms
have been design to Ô¨Ånd efÔ¨Åcient models, such as Bayesian
optimization [ 111,112], deep reinforcement learning [ 113,
114], evolutionary algorithms [ 115,116], and gradient based
methods [ 117,118]. These methods acquire impressive results
in their experiments. Additionally, open-source AutoML tools,
such as AutoSKLearn [ 119‚Äì121], Microsoft NNI [ 122], and
AutoKeras [ 123], also show remarkable model searching re-
sults in actual application.
Although AutoML can automatically generate models
from the training tasks, these models may still face train-
ing problems when training. Comparing with AutoML,
AUTOTRAINER focuses on improving the training process. It
can provide timely monitoring facing the training process and
facilitates SE researchers in repairing buggy models automat-
ically. In summary, the goal of AutoML and A UTOTRAINER
are different, and these two are complementary solutions
which can be intergraded with each other.
VII. C ONCLUSION
This paper presents A UTOTRAINER , a DNN monitoring and
auto-repairing system. It monitors the model training status
and automatically Ô¨Åx them once a problem is detected. By
doing so, it can prevent problems from happening at the ear-
liest convention which saves a lot of time and resources. Our
evaluation results show that A UTOTRAINER can effectively
and efÔ¨Åciently detecting and repairing our targeted Ô¨Åve training
problems (i.e., vanishing gradient, exploding gradient, dying
ReLU, oscillating loss and slow convergence).
ACKNOWLEDGEMENT
The authors thank the anonymous reviewers for their in-
sightful feedback and constructive comments. We also thank
Jiong Li for his efforts and feedbacks on this project. This
work is, in part supported by the National Science Foundation
of China (No. 61802166, 61822309, 61773310, U1736205)
and National Key R&D Program of China under Grand No.
2020AAA0107700. Chao Shen is the corresponding author.
The views, opinions and/or Ô¨Åndings expressed are only those
of the authors.
369REFERENCES
[1] Z. Lan, M. Chen, S. Goodman, K. Gimpel, P. Sharma, and R. Soricut, ‚ÄúAlbert: A
lite bert for self-supervised learning of language representations,‚Äù arXiv preprint
arXiv:1909.11942 , 2019.
[2] G. Cadamuro, R. Gilad-Bachrach, and X. Zhu, ‚ÄúDebugging machine learning
models,‚Äù in ICML Workshop on Reliable Machine Learning in the Wild , 2016.
[3] A. Chakarov, A. Nori, S. Rajamani, S. Sen, and D. Vijaykeerthy, ‚ÄúDebugging
machine learning tasks,‚Äù arXiv preprint arXiv:1603.07292 , 2016.
[4] S. Ma, Y . Liu, W.-C. Lee, X. Zhang, and A. Grama, ‚ÄúMode: automated neural
network model debugging via state differential analysis and input selection,‚Äù in
Proceedings of the 2018 26th ACM Joint Meeting on European Software Engi-
neering Conference and Symposium on the Foundations of Software Engineering
(ESEC/FSE) . ACM, 2018, pp. 175‚Äì186.
[5] D. Man√© et al. , ‚ÄúTensorboard: TensorÔ¨Çow‚Äôs visualization toolkit, 2015.‚Äù
[6] ‚ÄúVisdom,‚Äù 2020, https://github.com/facebookresearch/visdom .
[7] ‚ÄúTensorwatch,‚Äù 2020, https://github.com/microsoft/tensorwatch .
[8] ‚ÄúManifold,‚Äù 2020, https://github.com/uber/manifold .
[9] S. Ioffe and C. Szegedy, ‚ÄúBatch normalization: Accelerating deep network training
by reducing internal covariate shift,‚Äù arXiv preprint arXiv:1502.03167 , 2015.
[10] G. Klambauer, T. Unterthiner, A. Mayr, and S. Hochreiter, ‚ÄúSelf-normalizing
neural networks,‚Äù in Advances in neural information processing systems , 2017,
pp. 971‚Äì980.
[11] L. Lu, Y . Shin, Y . Su, and G. E. Karniadakis, ‚ÄúDying relu and initialization:
Theory and numerical examples,‚Äù arXiv preprint arXiv:1903.06733 , 2019.
[12] D. Masters and C. Luschi, ‚ÄúRevisiting small batch training for deep neural
networks,‚Äù arXiv preprint arXiv:1804.07612 , 2018.
[13] ‚ÄúAutotrainer repository,‚Äù 2020, https://github.com/shiningrain/AUTOTRAINER .
[14] Y . LeCun, Y . Bengio, and G. Hinton, ‚ÄúDeep learning,‚Äù nature , vol. 521, no. 7553,
pp. 436‚Äì444, 2015.
[15] P. Ramachandran, B. Zoph, and Q. V . Le, ‚ÄúSearching for activation functions,‚Äù
arXiv preprint arXiv:1710.05941 , 2017.
[16] V . Nair and G. E. Hinton, ‚ÄúRectiÔ¨Åed linear units improve restricted boltzmann
machines,‚Äù in ICML , 2010.
[17] Y . Sun, X. Wang, and X. Tang, ‚ÄúDeeply learned face representations are sparse,
selective, and robust,‚Äù in Proceedings of the IEEE conference on computer vision
and pattern recognition , 2015, pp. 2892‚Äì2900.
[18] ‚ÄúPytorch documentations,‚Äù 2020, https://pytorch.org/docs/stable/index.html .
[19] Y . LeCun, ‚ÄúThe mnist database of handwritten digits,‚Äù
http://yann.lecun.com/exdb/mnist/ , 1998.
[20] S. Hochreiter, ‚ÄúUntersuchungen zu dynamischen neuronalen netzen,‚Äù Diploma,
Technische Universit√§t M√ºnchen , vol. 91, no. 1, 1991.
[21] D. Sussillo and L. Abbott, ‚ÄúRandom walk initialization for training very deep
feedforward networks,‚Äù arXiv preprint arXiv:1412.6558 , 2014.
[22] J. Miller and M. Hardt, ‚ÄúStable recurrent models,‚Äù arXiv preprint
arXiv:1805.10369 , 2018.
[23] I. Arnekvist, J. F. Carvalho, D. Kragic, and J. A. Stork, ‚ÄúThe effect of target
normalization and momentum on dying relu,‚Äù arXiv preprint arXiv:2005.06195 ,
2020.
[24] C. Xing, D. Arpit, C. Tsirigotis, and Y . Bengio, ‚ÄúA walk with sgd,‚Äù arXiv preprint
arXiv:1802.08770 , 2018.
[25] ‚ÄúConvolutional neural networks for visual recognition,‚Äù 2020, https://cs231n.git
hub.io/neural-networks-3/ .
[26] N. Bjorck, C. P. Gomes, B. Selman, and K. Q. Weinberger, ‚ÄúUnderstanding batch
normalization,‚Äù in Advances in Neural Information Processing Systems , 2018, pp.
7694‚Äì7705.
[27] A. L. Maas, A. Y . Hannun, and A. Y . Ng, ‚ÄúRectiÔ¨Åer nonlinearities improve neural
network acoustic models,‚Äù in Proc. icml , vol. 30, no. 1, 2013, p. 3.
[28] I. Goodfellow, Y . Bengio, and A. Courville, Deep learning . MIT press, 2016.
[29] A. Graves, ‚ÄúGenerating sequences with recurrent neural networks,‚Äù arXiv preprint
arXiv:1308.0850 , 2013.
[30] R. Pascanu, T. Mikolov, and Y . Bengio, ‚ÄúOn the difÔ¨Åculty of training recurrent
neural networks,‚Äù in International conference on machine learning , 2013, pp.
1310‚Äì1318.
[31] X. Glorot and Y . Bengio, ‚ÄúUnderstanding the difÔ¨Åculty of training deep feedfor-
ward neural networks,‚Äù in Proceedings of the thirteenth international conference
on artiÔ¨Åcial intelligence and statistics , 2010, pp. 249‚Äì256.
[32] K. He, X. Zhang, S. Ren, and J. Sun, ‚ÄúDelving deep into rectiÔ¨Åers: Surpassing
human-level performance on imagenet classiÔ¨Åcation,‚Äù in Proceedings of the IEEE
international conference on computer vision , 2015, pp. 1026‚Äì1034.
[33] ‚ÄúHow to control the stability of training neural networks with the batch size,‚Äù
2019, https://machinelearningmastery.com/how-to-control-the-speed-and-stabili
ty-of-training-neural-networks-with-gradient-descent-batch-size .
[34] D. P. Kingma and J. Ba, ‚ÄúAdam: A method for stochastic optimization,‚Äù arXiv
preprint arXiv:1412.6980 , 2014.
[35] Y . Bengio, ‚ÄúPractical recommendations for gradient-based training of deep archi-
tectures,‚Äù in Neural networks: Tricks of the trade . Springer, 2012, pp. 437‚Äì478.
[36] I. Sutskever, J. Martens, G. Dahl, and G. Hinton, ‚ÄúOn the importance of
initialization and momentum in deep learning,‚Äù in International conference on
machine learning , 2013, pp. 1139‚Äì1147.
[37] S. Ruder, ‚ÄúAn overview of gradient descent optimization algorithms,‚Äù arXiv
preprint arXiv:1609.04747 , 2016.
[38] N. Qian, ‚ÄúOn the momentum term in gradient descent learning algorithms,‚Äù Neural
networks , vol. 12, no. 1, pp. 145‚Äì151, 1999.[39] ‚ÄúKeras: The python deep learning library,‚Äù 2020, https://keras.io .
[40] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean, M. Devin,
S. Ghemawat, G. Irving, M. Isard et al. , ‚ÄúTensorÔ¨Çow: A system for large-scale
machine learning,‚Äù in 12thfUSENIXgsymposium on operating systems design
and implementation ( fOSDIg16), 2016, pp. 265‚Äì283.
[41] ‚ÄúSklearn, make circles dataset,‚Äù 2020, https://scikit-learn.org/stable/modules/ge
nerated/sklearn.datasets.make_circles.html .
[42] ‚ÄúSklearn, make blobs dataset,‚Äù 2020, https://scikit-learn.org/stable/modules/gene
rated/sklearn.datasets.make_blobs.html .
[43] ‚ÄúCifar-10 datasets,‚Äù 2020, https://www.cs.toronto.edu/~kriz/cifar.html .
[44] ‚ÄúImdb datasets,‚Äù 2020, https://www.imdb.com/interfaces/ .
[45] ‚ÄúReuters-21578 dataset,‚Äù 2020, http://www.daviddlewis.com/resources/testcollec
tions/reuters21578/ .
[46] ‚Äúscikit-learn, machine learning in python,‚Äù 2020, https://scikit-learn.org/stable/ .
[47] D. Di Nucci, F. Palomba, D. A. Tamburri, A. Serebrenik, and A. De Lucia,
‚ÄúDetecting code smells using machine learning techniques: are we there yet?‚Äù
in2018 IEEE 25th International Conference on Software Analysis, Evolution and
Reengineering (SANER) . IEEE, 2018, pp. 612‚Äì621.
[48] D. Alrajeh and A. Russo, ‚ÄúLogic-based learning: Theory and application,‚Äù in
Machine Learning for Dynamic Software Analysis: Potentials and Limits , 2018.
[49] M. Tufano, J. Pantiuchina, C. Watson, G. Bavota, and D. Poshyvanyk, ‚ÄúOn
learning meaningful code changes via neural machine translation,‚Äù arXiv preprint
arXiv:1901.09102 , 2019.
[50] C. S. P ÀòasÀòareanu, D. Gopinath, and H. Yu, ‚ÄúCompositional veriÔ¨Åcation for
autonomous systems with deep learning components,‚Äù in Safe, Autonomous and
Intelligent Vehicles . Springer, 2019, pp. 187‚Äì197.
[51] R. Ben Abdessalem, S. Nejati, L. C. Briand, and T. Stifter, ‚ÄúTesting advanced
driver assistance systems using multi-objective search and neural networks,‚Äù
inProceedings of the 31st IEEE/ACM International Conference on Automated
Software Engineering . ACM, 2016, pp. 63‚Äì74.
[52] X. Gu, H. Zhang, and S. Kim, ‚ÄúDeep code search,‚Äù in 2018 IEEE/ACM 40th
International Conference on Software Engineering , 2018.
[53] Z. Liu, X. Xia, A. E. Hassan, D. Lo, Z. Xing, and X. Wang, ‚ÄúNeural-machine-
translation-based commit message generation: how far are we?‚Äù in Proceedings
of the 33rd ACM/IEEE International Conference on Automated Software Engi-
neering . ACM, 2018, pp. 373‚Äì384.
[54] C. Chen, Z. Xing, and Y . Liu, ‚ÄúBy the community & for the community: a deep
learning approach to assist collaborative editing in q&a sites,‚Äù Proceedings of the
ACM on Human-Computer Interaction , 2017.
[55] B. Lin, F. Zampetti, G. Bavota, M. Di Penta, M. Lanza, and R. Oliveto, ‚ÄúSentiment
analysis for software engineering: How far can we go?‚Äù in Proceedings of 40th
International Conference on Software Engineering (ICSE) , 2018.
[56] Z. Li, D. Zou, S. Xu, X. Ou, H. Jin, S. Wang, Z. Deng, and Y . Zhong,
‚ÄúVuldeepecker: A deep learning-based system for vulnerability detection,‚Äù arXiv
preprint arXiv:1801.01681 , 2018.
[57] J. Henkel, S. K. Lahiri, B. Liblit, and T. Reps, ‚ÄúCode vectors: understanding
programs through embedded abstracted symbolic traces,‚Äù in Proceedings of the
2018 26th ACM Joint Meeting on European Software Engineering Conference
and Symposium on the Foundations of Software Engineering , 2018.
[58] K. Wang, R. Singh, and Z. Su, ‚ÄúDynamic neural program embedding for program
repair,‚Äù arXiv preprint arXiv:1711.07163 , 2017.
[59] S. Bhatia, P. Kohli, and R. Singh, ‚ÄúNeuro-symbolic program corrector for
introductory programming assignments,‚Äù in 2018 IEEE/ACM 40th International
Conference on Software Engineering (ICSE) . IEEE, 2018, pp. 60‚Äì70.
[60] S. Iyer, I. Konstas, A. Cheung, and L. Zettlemoyer, ‚ÄúSummarizing source code
using a neural attention model,‚Äù in Proceedings of the 54th Annual Meeting of
the Association for Computational Linguistics , 2016.
[61] S. Jiang, A. Armaly, and C. McMillan, ‚ÄúAutomatically generating commit mes-
sages from diffs using neural machine translation,‚Äù in Proceedings of IEEE/ACM
International Conference on Automated Software Engineering , 2017.
[62] M. T. Ribeiro, S. Singh, and C. Guestrin, ‚ÄúSemantically equivalent adversarial
rules for debugging nlp models,‚Äù in Association for Computational Linguistics
(ACL) , 2018.
[63] X. Zhang, X. Zhu, and S. Wright, ‚ÄúTraining set debugging using trusted items,‚Äù
inThirty-Second AAAI Conference on ArtiÔ¨Åcial Intelligence , 2018.
[64] Y . Jiang and Z.-H. Zhou, ‚ÄúEditing training data for knn classiÔ¨Åers with neural
network ensemble,‚Äù in International symposium on neural networks , 2004.
[65] G. Tao, S. Ma, Y . Liu, Q. Xu, and X. Zhang, ‚ÄúTrader: Trace divergence analysis
and embedding regulation for debugging recurrent neural networks,‚Äù in 2020
IEEE/ACM 42nd International Conference on Software Engineering (ICSE) .
IEEE, 2020.
[66] Y . Tian, S. Ma, M. Wen, Y . Liu, S. Cheung, and X. Zhang, ‚ÄúTesting deep learning
models for image analysis using object-relevant metamorphic relations,‚Äù CoRR ,
vol. abs/1909.03824, 2019. [Online]. Available: http://arxiv.org/abs/1909.03824
[67] S. Ma, Y . Aafer, Z. Xu, W. Lee, J. Zhai, Y . Liu, and X. Zhang, ‚ÄúLAMP:
data provenance for graph based machine learning algorithms through derivative
computation,‚Äù in Proceedings of the 2017 11th Joint Meeting on Foundations
of Software Engineering, ESEC/FSE 2017, Paderborn, Germany, September 4-8,
2017 , E. Bodden, W. Sch√§fer, A. van Deursen, and A. Zisman, Eds. ACM, 2017,
pp. 786‚Äì797. [Online]. Available: https://doi.org/10.1145/3106237.3106291
[68] A. Odena, C. Olsson, D. Andersen, and I. Goodfellow, ‚ÄúTensorfuzz: Debugging
neural networks with coverage-guided fuzzing,‚Äù in International Conference on
Machine Learning , 2019, pp. 4901‚Äì4911.
370[69] J. Guo, Y . Jiang, Y . Zhao, Q. Chen, and J. Sun, ‚ÄúDlfuzz: Differential fuzzing
testing of deep learning systems,‚Äù in Proceedings of the 2018 26th ACM Joint
Meeting on European Software Engineering Conference and Symposium on the
Foundations of Software Engineering , 2018, pp. 739‚Äì743.
[70] X. Xie, L. Ma, F. Juefei-Xu, M. Xue, H. Chen, Y . Liu, J. Zhao, B. Li, J. Yin, and
S. See, ‚ÄúDeephunter: A coverage-guided fuzz testing framework for deep neural
networks,‚Äù in Proceedings of the 28th ACM SIGSOFT International Symposium
on Software Testing and Analysis , 2019, pp. 146‚Äì157.
[71] M. Wicker, X. Huang, and M. Kwiatkowska, ‚ÄúFeature-guided black-box safety
testing of deep neural networks,‚Äù in International Conference on Tools and
Algorithms for the Construction and Analysis of Systems . Springer, 2018.
[72] J. Uesato, A. Kumar, C. Szepesvari, T. Erez, A. Ruderman, K. Anderson, N. Heess,
P. Kohli et al. , ‚ÄúRigorous agent evaluation: An adversarial approach to uncover
catastrophic failures,‚Äù arXiv preprint arXiv:1812.01647 , 2018.
[73] Z. Q. Zhou and L. Sun, ‚ÄúMetamorphic testing of driverless cars,‚Äù Communications
of the ACM , vol. 62, no. 3, pp. 61‚Äì67, 2019.
[74] S. Udeshi, P. Arora, and S. Chattopadhyay, ‚ÄúAutomated directed fairness testing,‚Äù
inProceedings of the 33rd ACM/IEEE International Conference on Automated
Software Engineering , 2018, pp. 98‚Äì108.
[75] X. Gao, R. Saha, M. Prasad, and R. Abhik, ‚ÄúFuzz testing based data augmentation
to improve robustness of deep neural networks,‚Äù in 2020 IEEE/ACM 42nd
International Conference on Software Engineering (ICSE) . IEEE, 2020.
[76] A. Ramanathan, L. L. Pullum, F. Hussain, D. Chakrabarty, and S. K. Jha, ‚ÄúIntegrat-
ing symbolic and statistical methods for testing intelligent systems: Applications
to machine learning and computer vision,‚Äù in 2016 Design, Automation & Test in
Europe Conference & Exhibition (DATE) . IEEE, 2016, pp. 786‚Äì791.
[77] D. Gopinath, C. S. Pasareanu, K. Wang, M. Zhang, and S. Khurshid, ‚ÄúSymbolic
execution for attribution and attack synthesis in neural networks,‚Äù in 2019
IEEE/ACM 41st International Conference on Software Engineering: Companion
Proceedings (ICSE-Companion) . IEEE, 2019, pp. 282‚Äì283.
[78] A. Aggarwal, P. Lohia, S. Nagar, K. Dey, and D. Saha, ‚ÄúBlack box fairness
testing of machine learning models,‚Äù in Proceedings of the 2019 27th ACM Joint
Meeting on European Software Engineering Conference and Symposium on the
Foundations of Software Engineering , 2019, pp. 625‚Äì635.
[79] Y . Sun, M. Wu, W. Ruan, X. Huang, M. Kwiatkowska, and D. Kroening, ‚ÄúCon-
colic testing for deep neural networks,‚Äù in Proceedings of the 33rd ACM/IEEE
International Conference on Automated Software Engineering , 2018, pp. 109‚Äì119.
[80] A. Stocco, M. Weiss, M. Calzana, and P. Tonella, ‚ÄúMisbehaviour prediction for
autonomous driving systems,‚Äù in 2020 IEEE/ACM 42nd International Conference
on Software Engineering (ICSE) . IEEE, 2020.
[81] H. Wang, J. Xu, C. Xu, X. Ma, and J. Lu, ‚ÄúDissector: Input validation for
deep learning applications by crossing-layer dissection,‚Äù in 2020 IEEE/ACM 42nd
International Conference on Software Engineering (ICSE) . IEEE, 2020.
[82] P. Zhang, J. Wang, J. Sun, G. Dong, X. Wang, X. Wang, J. S. Dong, and D. Ting,
‚ÄúWhite-box fairness testing through adversarial sampling,‚Äù in 2020 IEEE/ACM
42nd International Conference on Software Engineering (ICSE) . IEEE, 2020.
[83] K. Pei, Y . Cao, J. Yang, and S. Jana, ‚ÄúDeepxplore: Automated whitebox testing
of deep learning systems,‚Äù in proceedings of the 26th Symposium on Operating
Systems Principles , 2017, pp. 1‚Äì18.
[84] L. Ma, F. Juefei-Xu, F. Zhang, J. Sun, M. Xue, B. Li, C. Chen, T. Su, L. Li, Y . Liu
et al. , ‚ÄúDeepgauge: Multi-granularity testing criteria for deep learning systems,‚Äù
inProceedings of the 33rd ACM/IEEE International Conference on Automated
Software Engineering , 2018, pp. 120‚Äì131.
[85] Y . Tian, K. Pei, S. Jana, and B. Ray, ‚ÄúDeeptest: Automated testing of deep-
neural-network-driven autonomous cars,‚Äù in Proceedings of the 40th international
conference on software engineering , 2018, pp. 303‚Äì314.
[86] M. Zhang, Y . Zhang, L. Zhang, C. Liu, and S. Khurshid, ‚ÄúDeeproad: Gan-based
metamorphic testing and input validation framework for autonomous driving
systems,‚Äù in Proceedings of the 33rd ACM/IEEE International Conference on
Automated Software Engineering , 2018, pp. 132‚Äì142.
[87] H. Zhou, W. Li, Z. Kong, J. Guo, Y . Zhang, L. Zhang, B. Yu, and C. Liu, ‚ÄúDeep-
billboard: Systematic physical-world testing of autonomous driving systems,‚Äù in
2020 IEEE/ACM 41st International Conference on Software Engineering (ICSE) .
IEEE, 2020.
[88] S. Gerasimou, H. F. Eniser, A. Sen, and A. Cakan, ‚ÄúImportance-driven deep
learning system testing,‚Äù in 2020 IEEE/ACM 42nd International Conference on
Software Engineering (ICSE) . IEEE, 2020.
[89] Y . Tian, Z. Zhong, V . Ordonez, G. Kaiser, and B. Ray, ‚ÄúTesting dnn image
classiÔ¨Åer for confusion & bias errors,‚Äù in 2020 IEEE/ACM 42nd International
Conference on Software Engineering (ICSE) . IEEE, 2020.
[90] X. Du, X. Xie, Y . Li, L. Ma, Y . Liu, and J. Zhao, ‚ÄúDeepstellar: Model-based
quantitative analysis of stateful deep learning systems,‚Äù in Proceedings of the
2019 27th ACM Joint Meeting on European Software Engineering Conference
and Symposium on the Foundations of Software Engineering , 2019, pp. 477‚Äì487.
[91] P. He, C. Meister, and Z. Su, ‚ÄúStructure-invariant testing for machine translation,‚Äù
in2020 IEEE/ACM 42nd International Conference on Software Engineering
(ICSE) . IEEE, 2020.
[92] Z. Sun, J. M. Zhang, M. Harman, M. Papadakis, and L. Zhang, ‚ÄúAutomatic testing
and improvement of machine translation,‚Äù in 2020 IEEE/ACM 42nd International
Conference on Software Engineering (ICSE) . IEEE, 2020.
[93] S. Yan, G. Tao, X. Liu, J. Zhai, S. Ma, L. Xu, and X. Zhang, ‚ÄúCorrelations between
deep neural network model coverage criteria and model quality,‚Äù in ESEC/FSE
‚Äô20: 28th ACM Joint European Software Engineering Conference and Symposiumon the Foundations of Software Engineering, Virtual Event, USA, November
8-13, 2020 , P. Devanbu, M. B. Cohen, and T. Zimmermann, Eds. ACM, 2020,
pp. 775‚Äì787. [Online]. Available: https://doi.org/10.1145/3368089.3409671
[94] W. Weimer, T. Nguyen, C. Le Goues, and S. Forrest, ‚ÄúAutomatically Ô¨Ånding
patches using genetic programming,‚Äù in Proceedings of the 31st International
Conference on Software Engineering . IEEE Computer Society, 2009, pp. 364‚Äì
374.
[95] W. Weimer, S. Forrest, C. L. Goues, and T. V . Nguyen, ‚ÄúAutomatic program repair
with evolutionary computation,‚Äù Communications of the Acm , vol. 53, no. 5, pp.
109‚Äì116, 2010.
[96] C. Le Goues, M. Dewey-V ogt, S. Forrest, and W. Weimer, ‚ÄúA systematic study of
automated program repair: Fixing 55 out of 105 bugs for $8 each,‚Äù in Software
Engineering (ICSE), 2012 34th International Conference on . IEEE, 2012, pp.
3‚Äì13.
[97] C. L. Goues, T. V . Nguyen, S. Forrest, and W. Weimer, ‚ÄúGenprog: A generic
method for automatic software repair,‚Äù IEEE Transactions on Software Engineer-
ing, vol. 38, no. 1, pp. 54‚Äì72, 2012.
[98] A. Arcuri, ‚ÄúEvolutionary repair of faulty software,‚Äù Applied Soft Computing ,
vol. 11, no. 4, pp. 3494‚Äì3514, 2011.
[99] Y . Qi, X. Mao, Y . Lei, Z. Dai, and C. Wang, ‚ÄúThe strength of random search on
automated program repair,‚Äù in Proceedings of the 36th International Conference
on Software Engineering . ACM, 2014, pp. 254‚Äì265.
[100] S. Jha, S. Gulwani, S. A. Seshia, and A. Tiwari, ‚ÄúOracle-guided component-
based program synthesis,‚Äù in Proceedings of the 32rd International Conference
on Software Engineering . ACM, 2010, pp. 215‚Äì224.
[101] H. D. T. Nguyen, D. Qi, A. Roychoudhury, and S. Chandra, ‚ÄúSemÔ¨Åx: program
repair via semantic analysis,‚Äù in Proceedings of the 2013 International Conference
on Software Engineering . IEEE Press, 2013, pp. 772‚Äì781.
[102] S. Mechtaev, J. Yi, and A. Roychoudhury, ‚ÄúDirectÔ¨Åx: Looking for simple program
repairs,‚Äù in Ieee/acm IEEE International Conference on Software Engineering ,
2015, pp. 448‚Äì458.
[103] J. Hua, M. Zhang, K. Wang, and S. Khurshid, ‚ÄúTowards practical program repair
with on-demand candidate generation,‚Äù in Proceedings of the 40th international
conference on software engineering , 2018, pp. 12‚Äì23.
[104] F. Long and M. Rinard, ‚ÄúStaged program repair with condition synthesis,‚Äù
inProceedings of the 2015 10th Joint Meeting on Foundations of Software
Engineering . ACM, 2015, pp. 166‚Äì178.
[105] B. Demsky and M. Rinard, ‚ÄúData structure repair using goal-directed reasoning,‚Äù
inInternational Conference on Software Engineering, 2005. ICSE 2005. Proceed-
ings, 2005, pp. 176‚Äì185.
[106] B. Demsky, M. D. Ernst, P. J. Guo, S. McCamant, J. H. Perkins, and M. Rinard,
‚ÄúInference and enforcement of data structure consistency speciÔ¨Åcations,‚Äù in Pro-
ceedings of the 2006 international symposium on Software testing and analysis .
ACM, 2006, pp. 233‚Äì244.
[107] D. Gopinath, M. Z. Malik, and S. Khurshid, ‚ÄúSpeciÔ¨Åcation-based program
repair using sat,‚Äù in International Conference on TOOLS & Algorithms for the
Construction & Analysis of Systems , 2011, pp. 173‚Äì188.
[108] Y . Pei, C. A. Furia, M. Nordio, Y . Wei, B. Meyer, and A. Zeller, ‚ÄúAutomated
Ô¨Åxing of programs with contracts,‚Äù IEEE Transactions on Software Engineering ,
vol. 40, no. 5, pp. 427‚Äì449, 2014.
[109] L. Chen, Y . Pei, and C. A. Furia, ‚ÄúContract-based program repair without the
contracts,‚Äù in 2017 32nd IEEE/ACM International Conference on Automated
Software Engineering (ASE) . IEEE, 2017, pp. 637‚Äì647.
[110] L. Gazzola, D. Micucci, and L. Mariani, ‚ÄúAutomatic software repair: A survey,‚Äù
IEEE Transactions on Software Engineering , vol. 45, no. 1, pp. 34‚Äì67, 2017.
[111] J. Snoek, H. Larochelle, and R. P. Adams, ‚ÄúPractical bayesian optimization of
machine learning algorithms,‚Äù Advances in neural information processing systems ,
vol. 25, pp. 2951‚Äì2959, 2012.
[112] H. Jin, Q. Song, and X. Hu, ‚ÄúAuto-keras: An efÔ¨Åcient neural architecture search
system,‚Äù in Proceedings of the 25th ACM SIGKDD International Conference on
Knowledge Discovery & Data Mining , 2019, pp. 1946‚Äì1956.
[113] B. Zoph and Q. V . Le, ‚ÄúNeural architecture search with reinforcement learning,‚Äù
arXiv preprint arXiv:1611.01578 , 2016.
[114] B. Baker, O. Gupta, N. Naik, and R. Raskar, ‚ÄúDesigning neural network archi-
tectures using reinforcement learning,‚Äù arXiv preprint arXiv:1611.02167 , 2016.
[115] Z. Guo, X. Zhang, H. Mu, W. Heng, Z. Liu, Y . Wei, and J. Sun, ‚ÄúSingle path one-
shot neural architecture search with uniform sampling,‚Äù in European Conference
on Computer Vision . Springer, 2020, pp. 544‚Äì560.
[116] E. Real, S. Moore, A. Selle, S. Saxena, Y . L. Suematsu, J. Tan, Q. Le,
and A. Kurakin, ‚ÄúLarge-scale evolution of image classiÔ¨Åers,‚Äù arXiv preprint
arXiv:1703.01041 , 2017.
[117] R. Luo, F. Tian, T. Qin, E. Chen, and T.-Y . Liu, ‚ÄúNeural architecture optimization,‚Äù
inAdvances in neural information processing systems , 2018, pp. 7816‚Äì7827.
[118] H. Cai, L. Zhu, and S. Han, ‚ÄúProxylessnas: Direct neural architecture search on
target task and hardware,‚Äù arXiv preprint arXiv:1812.00332 , 2018.
[119] ‚ÄúAuto-sklearn,‚Äù 2020, https://github.com/automl/auto-sklearn .
[120] M. Feurer, A. Klein, K. Eggensperger, J. T. Springenberg, M. Blum, and F. Hutter,
‚ÄúAuto-sklearn: efÔ¨Åcient and robust automated machine learning,‚Äù in Automated
Machine Learning . Springer, Cham, 2019, pp. 113‚Äì134.
[121] M. Feurer, K. Eggensperger, S. Falkner, M. Lindauer, and F. Hutter, ‚ÄúAuto-sklearn
2.0: The next generation,‚Äù arXiv preprint arXiv:2007.04074 , 2020.
[122] ‚ÄúMicrosoft nni,‚Äù 2020, https://github.com/microsoft/nni .
[123] ‚ÄúAutokeras,‚Äù 2020, https://github.com/keras-team/autokeras .
371