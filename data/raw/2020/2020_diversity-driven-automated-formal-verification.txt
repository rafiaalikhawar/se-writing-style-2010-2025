Diversity-Driven Automated Formal Verification
Emily First
University of Massachusetts Amherst
Amherst, MA, USA
efirst@cs.umass.eduYuriy Brun
University of Massachusetts Amherst
Amherst, MA, USA
brun@cs.umass.edu
ABSTRACT
Formallyverifiedcorrectnessisoneofthemostdesirableproperties
ofsoftwaresystems.Butdespitegreatprogressmadeviainteractivetheorem provers, such as Coq, writing proof scripts for verification
remainsoneofthemosteffort-intensive(andoftenprohibitivelydifficult) software development activities. Recent work has cre-ated tools that automatically synthesize proofs or proof scripts.
For example, CoqHammer can prove 26.6% of theorems completelyautomatically by reasoning using precomputed facts, while TacTok
andASTactic,whichusemachinelearningtomodelproofscripts
and then perform biased search through the proof-script space,
canprove12.9%and12.3%ofthetheorems,respectively.Further,
these three tools are highly complementary; together, they can
prove 30.4% of the theorems fully automatically. Our key insight is
that control over the learning process can produce a diverse set of
models, and that, due to the unique nature of proof synthesis (the
existenceofthetheoremprover,anoraclethatinfalliblyjudgesa
proof‚Äôs correctness),this diversitycan significantlyimprove these
tools‚Äô proving power. Accordingly, we develop Diva, which uses a
diversesetofmodelswithTacTok‚ÄôsandASTactic‚Äôssearchmech-
anism to prove 21.7% of the theorems. That is, Diva proves 68%more theorems than TacTok and 77% more than ASTactic. Com-
plementary to CoqHammer, Diva proves 781 theorems (27% added
value) that CoqHammer does not, and 364 theorems no existing
tool has proved automatically. Together with CoqHammer, Divaproves 33.8% of thetheorems, the largest fractionto date. Weex-plore nine dimensions for learning diverse models, and identify
which dimensions lead to the most useful diversity. Further, we
develop an optimization tospeedup Diva‚Äôs execution by 40 √ó. Our
studyintroducesacompletelynewideaforusingdiversityinma-
chinelearningtoimprovethepowerofstate-of-the-artproof-script
synthesis techniques, and empirically demonstrates that the im-provement is significant on a dataset of 68K theorems from 122
open-source software projects.
CCS CONCEPTS
‚Ä¢Software and its engineering ‚ÜíSoftware verification; For-
mal software verification;‚Ä¢Theory of computation ‚ÜíAuto-
mated reasoning.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthe firstpage.Copyrights forcomponentsof thisworkowned byothersthan the
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or
republish,topostonserversortoredistributetolists,requirespriorspecificpermission
and/or a fee. Request permissions from permissions@acm.org.
ICSE ‚Äô22, May 21‚Äì29, 2022, Pittsburgh, PA, USA
¬© 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-9221-1/22/05...$15.00
https://doi.org/10.1145/3510003.3510138KEYWORDS
Automated formal verification,language models,Coq, interactive
proof assistants, proof synthesis
ACM Reference Format:
Emily First and Yuriy Brun. 2022. Diversity-Driven Automated Formal Veri-
fication. In 44th International Conference on Software Engineering (ICSE ‚Äô22),
May 21‚Äì29, 2022, Pittsburgh, PA, USA. ACM, New York, NY, USA, 13pages.
https://doi.org/10.1145/3510003.3510138
1 INTRODUCTION
Buildingprovablycorrectsystemsiscriticalinhigh-stakesdomains,
such as aerospace engineering and software for medical devices.
However,mostindustrialverificationtoolseitheraimtosimplify
the verification process by sacrificing soundness [ 11] or signifi-
cantlyrestricttheprogramminglanguageinwhichthesystemis
written[53].Apromisingmethodforbuildingcorrectsoftwarehas
beentouseprogramminglanguagesthataredesignedtoinherently
support program verification, such as interactive theorem provers
(ITPs), including Coq [ 79], Agda [84], and Isabelle/HOL [ 61]. ITPs
havehadsignificantimpactonindustry.Forexample,AirbusFrance
usestheCoq-verifiedCompCertCcompiler[ 50]toensuresafety
and improve performance of its aircraft [ 75]. Chrome and Android
both use cryptographic code formally verified in Coq to secure
communication [ 25], while Mozilla has its own verified crypto-
graphiclibraryforFirefox,improvingperformance[ 44].Multiple
companies have been successful in using proof assistants to pro-
vide formal verification services, including BedRock Systems, who
builds formally verified solutions for the healthcare, infrastructure,
and financial domains [ 9], Certora, who formally verifies smart
contracts[ 17],andGalois,Inc.,whoverifiescompilercorrectness
and hardware design [ 29]. Meanwhile Amazon successfully ap-
plies formal verification to cloud security problems in Amazon
WebServices,providingtoolsforuserstodetectentireclassesof
misconfigurationsthat can potentially expose vulnerable data [ 6].
WithITPs,theuser(aprogrammer)specifiesatheoremabout
a property of the software and writes a proof script, a series of
annotated prooftactics, that theinteractive theorem prover uses
to attempt to construct a proof of the theorem. Still, even with the
help of an ITP, the effort required to write proof scripts is oftenprohibitive. The Coq proof of the C compiler is more than three
timesthatofthecompilercodeitselfandtookthreepersonyears
ofwork[50].Meanwhile,ittook11personyearstowritetheproof
script to verify a microkernel [ 59]. As a general rule, because of
theexpenseofverification,nearlyallsoftwarecompaniesshipis
unverified.
However,someformalverificationcanbefullyautomatedbysyn-
thesizing either the underlying proofs or the guiding proof scripts.
Aseries oftools called hammers (e.g., CoqHammer [ 21])use aset
of precomputed mathematical facts to attempt to ‚Äúhammer‚Äù out
7492022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:18:33 UTC from IEEE Xplore.  Restrictions apply. ICSE ‚Äô22, May 21‚Äì29, 2022, Pittsburgh, PA, USA Emily First and Yuriy Brun
aproof.EvaluatedontheCoqGymbenchmark[ 90],CoqHammer
canautomaticallyprove26.6%oftheoremsfoundinopen-source
Coq projects. But hammers are restricted by their precomputed
facts and cannot reason about proof approaches such as induc-tion,greatlylimitingtheirpower.Toovercometheselimitations,researchers have used machine learning to model existing proof
scripts,andthen,givenanewtheorem,appliedthatmodeltoguide
metaheuristic search [ 35] to attempt to synthesize a new proof
script [28,69,90]. While these tools tend to prove fewer theorems,
e.g.,ASTacticproves12.3%[ 90]andTacTokproves12.9%[ 28],they
are capable of applying higher-order proof approaches learnt from
existing proofs, including induction, and so are complementary to
hammers. Together with CoqHammer, they prove 30.4% of the the-
orems. The central goal of this paper is to improve on this fraction,
particularly focusing on the tools that model existing proofs.
We make two key observations that enable us to improve the
proving powerofproof-script-synthesis techniques.First, thefor-
malverificationdomainisauniqueapplicationofmachinelearningbecauseithasacorrectnessoracle.Inmostmachinelearningappli-cations,itisnotknownwhenthemodeliscorrect.Thisiswhymod-
els are typically evaluated for precision or accuracy. In the formal
verificationdomain,however,theinteractivetheoremprovercan
use a synthesized proof script to determine whether it truly proves
the underlying theorem. If the prover can get to Qed, then the syn-
thesized proof script must be correct. Thus, proof-script-synthesis
systemsalwayshaveaprecisionof100%:theyneverreturnafailed
script, instead continuing the search or timing out. While recall
maybelow,precisionisalwaysperfect.Second,variationsinthe
modelscanalterthesearch-basedsynthesisofaproofscriptenough
that two models can potentially produce different scripts for the
sametheorem.This,inturn,can,hypothetically,leadtomodelsthat
prove complementary sets of theorems. And because of our first
observation, they can be combined without sacrificing their power.
The combined system can synthesize successful proof scripts for
all theorems each one of the models can prove individually; if one
model fails to synthesize a successful script, the theorem prover
unequivocallytellsusso,andweinsteadusetheothermodel‚Äôssuc-
cessful script. Thus, if one can learn models that differ in a way to
producedifferentscripts,potentially,thissetofmodelsmaybeable
to prove far more theorems than a single model. The central ques-
tion this paper answers is whether model diversity can be created
to improve the proving power of proof-script-synthesis techniques,and whether such an approach improves on the state-of-the-art au-
tomated formal verification techniques. We find that the answer to
both questions is ‚Äúyes.‚Äù As we will demonstrate on a benchmark of
68,501theoremsfrom122open-sourcesoftwareprojectsinCoq,weareabletocreateasetof62modelsbyvaryinglearningparameters
and learning data that, together, prove 68% more theorems than
TacTokand77%morethanASTactic,despiteusingthesamesearch
method. Combining our approach, Diva, with CoqHammer [ 21],
wecanprove33.8%ofallthetheorems,thehighestsuchresultto
date. Diva proves 364 theorems that none of the prior tools have
been able to prove. The difficulty of manually writing proof scripts
for formal verification is so great, that even small improvements in
proving power can be significant, and the savings in human effort
that our approach represents are quite substantial.Ourinsightsenableforacompletelynewwaytocombinema-
chine learning models. Of course,the idea of combining models is
notnew.Ensemblelearningallowsweightingtheresultsofmultiple
models to improve the precision or recall of a single model [ 68].
And stacking uses a classifier to decide which model to apply to
eachinput[ 24].Whileboththesemethodscanimproveprecision
andrecallinpractice,theycanalso,hypothetically,reducethem,and often cannot properly amplify the correct results of a smallminority of models. By contrast, in our domain, our method for
combining models can never produce a wrong result or ignore the
correctresultproducedbyevenasinglemodel.Thisrepresentsa
killer app for ensemble learning and stacking. We are the first to
combinetheideaofensemblelearningwithanoracletoproduce
optimal stacking.
Thispaperexploresninedimensionsforlearningdiversemodels,
andidentifieswhichdimensionsleadtothemostusefuldiversity.
Altering the types of information (the proof script, state, and term)
themodellearnsfromresultedinthegreatestdiversity,whilevary-
ing the depth of the proof script and the learning rate provided the
secondmostdiversity.Asrunningalargenumberofmodelscanbe
inefficient, we develop a model interrupts optimization that speeds
up Diva‚Äôs execution by 40√ó.
The main contributions of our work are:
‚Ä¢A novel approach for combining varied machine learning
models to formally verify software properties.
‚Ä¢A systematic exploration of which learning dimensions pro-
vide usable model diversity.
‚Ä¢An implementationof our approach, Diva,that proves 68%
moretheoremsthanTacTokand77%morethanASTactic,the
prior work most closely related to ours. Diva is open-source
and is available at https://github.com/LASER-UMASS/Diva/.
‚Ä¢An optimization for improving Diva‚Äôs performance.
‚Ä¢Aplatformforevaluatingmodelsandrerunningexperiments,
and all data and source code used in our experiments for
replications [27].
Therestofthispaperisstructuredasfollows.Section 2explains
verificationinCoq.Section 3presentsDiva,andSection 4evaluates
ouruseofdiversitytoincreasetheprovingpowerofautomatedfor-
mal verification tools. Section 5places our research in the context
of related work, and Section 6summarizes our contributions.
2 THEOREM PROVING IN COQ
Coq is a dependently-typed language with a small kernel, whichprovides a high assurance that Coq-verified programs are truly
correct. However, program verification in Coq is not automatic. To
proveatheoreminCoq,aprogrammermustwriteaproofscript(in
Ltac), which, when executed, helps automatically generate a proof
(in Gallina) of the theorem. Alternatively, metaheuristic search
techniques [ 35] can automatically search for a proof script, thus
alleviating the burden for the programmer [ 28,69,90]. However,
metaheuristicsearchisonlyasgoodasthepredictivemodelthat
is used to bias the search. In this section, we will discuss how a
programmer interactively writes proof scripts in Coq (Section 2.1),
how metaheuristic search can be used to automatically generate a
proof script (Section 2.2), and design considerations for building a
predictive model to generate proof scripts (Section 2.3).
750
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:18:33 UTC from IEEE Xplore.  Restrictions apply. Diversity-Driven Automated Formal Verification ICSE ‚Äô22, May 21‚Äì29, 2022, Pittsburgh, PA, USA
2.1 Interactively writing proof scripts
WhenatheoremisproveninCoq,thismeansthatinGallina(Coq‚Äôs
internallanguage),a proofterm ofthedesiredtypehasbeencon-
structed. The type of this term is the theorem itself. A programmer
could write the Gallina proof term themselves, but this can be a
long, unforgiving process [ 65]. To simplify this task, Coq has a
meta-programming language called Ltac in which programmers
canwrite proofscripts,whichwhencompletedandrun,generate
the Gallina proof term automatically.
Programmersusean interactiveproofassistant (e.g.,CoqIDEor
ProofGeneral)towriteproofscripts,whichconsistofasequence
ofproof tactics. The proof assistant executes aproof script, even a
partialone,andprovidesimmediatehuman-readablefeedbackafter
each tactic‚Äôs execution. This feedback is Coq‚Äôs internal proof state,
which includes the goalsto prove, the local context of assumptions,
and theenvironment of proven-so-far set of facts. The programmer
can even ask to see the intermediate Gallina proof term by writ-
ingandexecutingthe Show Proof commandintheirproofscript.
When starting to prove a theorem, Coq‚Äôs proof state is a single
goal,whichisthetheoremitself(thecorrespondingprooftermis
?Goal).Theaimistomanipulatetheproofstatethroughtheuseof
tactics until the goal is proven and thus removed from the proofstate. Since the search space of goal manipulation is too large, aprogrammer helps manage the exploration by using the current
proof state to select a sequence of proof tactics to try.
The interactive proof assistant checks that a partially-written
proofscriptisvalidandupdatesthecurrentproofstate,allowingthe
programmer to incrementally develop a proof script. The program-
mercanchooseatactic,examinetheoutputfromtheproofassistant,
andthenchoosethenexttactic.Iftheprogrammerchoosesanin-
validtactic,theproofassistantdisplaysanerror.Iftheprogrammer
choosestacticsthatarevalid,butdonotmakeprogress,theycan
usetheproofassistanttobacktracktoanearlierproofstateandtry
adifferentapproach.Theprogrammercontinuesselectingtactics
until the proof assistant prints no more subgoals , and then uses Qed
to complete the proof script.
2.2 Proof script synthesis via metaheuristic search
Ininteractiveproofscriptgeneration,theburdenisontheprogram-
mer to choose the sequence of tactics. To remove this burden from
theprogrammer,metaheuristicsearchtechniquescansometimes
automatically generate a proof script.
The space of possible proof scripts is infinite and quite complex.
Becauseofthissizeandcomplexity,automaticallysearchingblindly
through this space for a proof script that might prove a theoremis unlikely to succeed. Metaheuristic search [
35] can help guide
the search to improve the chances of success, and, in fact, is often
successful [ 28,69,90]. Such search starts with an empty proof
script, and predicts a first most likely proof step. This prediction
can be made based, for example, on the theorem being proven and
examples of past, successful proof scripts. The search executes the
partial proof script and determines, using some heuristic-basedfitness function, whether adequate progress has been made. If it
has not, the proof search can try another likely proof step. If it has,
the search can iteratively augment the partial proof script, adding
subsequent predicted proof steps, making progress toward provingsearch and 
predict
Proof Script Model Next Step 2
New 
Proof Script 1input
If compiles, proof state is not 
duplicate, and subgoals still exist, update Proof ScriptIf doesn't compile or proof state is duplicate, predict another tactic
Final Proof
If no more subgoals, apply Qedintros  n;
induction  n;
intros  n;
induction  n;
apply h;simpl;
intros  n;
induction  n;
simpl ;
qed;Next Step 1apply h;
Next Step 3trivial;
(beam size 3)
New 
Proof Script 2
intros  n;
induction  n;
simpl ;New 
Proof Script 3
intros  n;
induction  n;
trivial;apply
Figure 1: The process of synthesizing a proof script using
metaheuristicsearch,biasedbyablackboxpredictivemodel.
Given an incomplete proof script, a model can predict thenext proof step. Here, using a beam search of width 3, the
model predicts 3 likely next steps. If using the step satisfies
certain criteria (here, the proof script must compile and the
resulting proof state must not have been previously seen
within this proof script) the process iterates until, either,
theproofstatehasnosubgoalsandtheproofscriptcanbe
completed using Qed, or the search reaches a timeout.
the theorem. Making reasonably accurate predictions is, of course,
a critical part of successful metaheuristic search, and Section 2.3
will describe possible ways to do that.
Figure1shows how beamsearch can use a predictive model to
biasametaheuristicsearchforaproofscript.Inthisexample,the
modelpredicts3likelynextproofscriptsteps(thebeamwidthis3).
Thesearchthenusesaheuristic-basedfitnessfunctiontodetermine
criteriaforapplyingthecandidateproofsteps.Here,thecriteriaarethatthepartialproofscriptcompilesandresultsinaproofstatethat
hasnotbeenpreviouslyseenwithinthissearch.Ifsuccessful,the
searchappendstheproofsteptothescriptanditerates,growingthe
script. Once the proof state has no more subgoals, the proof script
can be completed by using Qed. The search fails if it times out.
2.3 Proof script modeling
Priorproofscriptsynthesistools,suchasASTacticandTacTok,use
the predictions from learnt proof script models to bias the meta-
heuristicsearchforaproofscript.Suchamodelislearntfromaset
ofexisting,successfulproofscriptstopredictthenextproofstep
(tacticandarguments)ofanincompleteproofscript.Recallfrom
Section2.1that there are three relevant aspects of proof scripts we
may want to encode to serve as input to such a model: the proof
state,theproofscript,andtheGallinaproofterm.ASTacticonlyen-codestheproofstate,whileTacTokencodesboththeproofstateandtheproofscript.TherehasyettobeaproofscriptsynthesistoolthatencodestheGallinaproofterm.Next,Sections 2.3.1,2.3.2,and 2.3.3
describe how to encode the proof state, proof script, and Gallina
proof term, respectively.
2.3.1 Encoding the proof state. Theproofstateconsistsofthegoals
to be proven, local context, and the environment. While the pro-
grammerseestheminahuman-readableformat,eachtermofthe
proof state has an underlying abstract syntax tree (AST) represen-
tation. ASTactic and TacTok serialize these ASTs and encode them
using a neural model, specifically a TreeLSTM [ 78]. Prior work has
751
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:18:33 UTC from IEEE Xplore.  Restrictions apply. ICSE ‚Äô22, May 21‚Äì29, 2022, Pittsburgh, PA, USA Emily First and Yuriy Brun
Environment
Local Context
Goal
Proof Script
Proof TermASTs
SeqsProof
State
Encoder
Proof 
Script 
Encoder
Proof 
Term
EncoderEmbeddings
Tactic and 
arguments
(next step)AST
Tactic
Decoder
Figure2:Modelofproofscript,whichDivausesinternally
to drive search.
empiricallyarguedthatneuralmodelsaremuchmoreeffectivethan
other architectures [10, 56,76].
2.3.2 Encoding proof script features. The proof script is comprised
of a sequence of tokens in Ltac. For the model to encode these
tokens, each proof script needs to be preprocessed to remove high-
frequency low-signal tokens, such as punctuation. Then, encoding
suchasequenceistraditionallydoneusingalanguagemodel[ 10,
56,76]. Language models are widely used in natural language pro-
cessing tasks [ 7,74]. The primary function of a language model
is to predict the next token in a sequence of tokens. While prior
work has used n-grams to model Coq [ 37], TacTok found neural
language models work better to encode the sequence of tokens
because it can generate a representative vector (embedding) forthe sequence, that can then be combined with other types of in-
puts.Amongthemostextensivelyusedneurallanguagemodelsaretransformers[
23]andRNNs[ 62].TacTokusesanRNN(specifically
aBidirectionalLSTM[ 62])becausetransformersrequiremassive
amountsofdatatotrain[ 23],whichistypicallynotavailableinthe
formal verification domain.
2.3.3 Encoding the proof term. Prior tools have not encoded proof
terms,but,conceptually,theGallinasequenceissimilartotheproof
script Ltac sequence, and we encode it in a similar way using a
BidirectionalLSTM[ 62].Thisallowsallthree,theproofstate,proof
script, and proof term, to be encoded with a single model.
3 DIVA: DIVERSITY-DRIVEN SYNTHESIS
Machinelearningmodelscanbesensitivetonoiseinthetraining
data [60,82] and to parameters applied during the learning pro-
cess[31].Thissensitivitycancausegreatvariabilityintheaccuracy
of models. Of course, this can hurt the generalizability of machine
learningresults,butwepositthatintherightdomain,thissensi-
tivity, and the diversity of models it can produce, can provide a
significant benefit.
In the formal verification domain, tools such as ASTactic [ 90],
Proverbot9001 [ 69], and TacTok [ 28] use a learnt model of a proof
script to guide metaheuristic search toward synthesizing a proof
script for a theorem. Variations in the models can alter the search,
resultinginpotentiallydifferentattemptedsynthesizedscripts.Thekeyuniquenessofthisdomainisthataninteractivetheoremprover
canactasanoracleforeachproofscript.Iftheproofscriptleads
thetheoremprovertogenerateaproofterminatingin Qed,thenthe
proofscriptis,bydefinition,correct.Thisallowsasynthesistoolto
tryapplyingmanydifferentmodelstobiasthesearchindifferentTreeLSTM
ASTParse
Embedding
(a) Proof state encoderBidirectional
LSTM
SeqParse
Embedding
(b) Proof script and term encoders
Figure3:Theneuralmodelsusedtoencodetheproofstate
AST, proof script sequence, and the proof term sequence.
ways, and then pick out just the successful synthesis attempts,
discarding the failed ones.
Thisis notthe typicalcase inapplications ofmachine learning.
Ensemblelearning[ 68]andstacking[ 24]attempttocombinethe
resultsofmultiplemachinelearningmodelstoimproveprecision
or recall. However, without an oracle, ensembles and stacks are
unlikelytoalwayspickthecorrectresult,especiallywhenrelatively
fewofthediversemodelsproduceit.Bycontrast,inourdomain,
withthetheoremproveractingasanoracle,evenasinglemodel
producing the correct proof script can establish an answer.
To demonstrate this insight, we develop Diva, a proof-script-
synthesis tool that uses the diversity in machine learning to sig-nificantly improve its proving power. Diva is open-source and is
available at https://github.com/LASER-UMASS/Diva/ .
Diva‚Äôs key contributions are the generation of a diverse set of
modelscapableofprovingcomplementarysetsoftheorems,amech-anismforcombiningthebenefitsofthemodels,andanoptimization
to make running a large number of searches using independent
models feasible.
Toautomateproofscriptsynthesis,Divausesalearntmodelofa
proofscripttoguidemetaheuristicbeamsearch.Duringthissearch,Divasamplesafixednumber(beamwidth)ofthemostlikelytactics,
predicted by the model, across all search tree nodes at the samelevel, and then uses these tactics to search for a complete proofscript.DivabacktrackswhentheCoqcompilerfailstocheckthe
attempted proof script step or detects a duplicate proof state. Diva
usesthesamebeamsearchconfiguration(widthof20,searchdepth
limit of 5, and a timeout of 10 minutes) as ASTactic and TacTok.
To intentionally produce a diverse set of models that prove com-
plementary sets of theorems, control over the learning processis key. When training a model of proof scripts, Diva varies thelearning parameters and which features of the training data to
encode.Next,Section 3.1describeswhataDivamodellookslike;
Sections3.2and3.3detailhowDivageneratesadiversesetofmod-
els by controlling learning parameters and the encoded features of
thetrainingdata,respectively;andSection 3.4explainsourDiva
efficiency optimization.
3.1 Diva‚Äôs learnt model
Figure2illustratesDiva‚Äôsproofscriptmodel,learntfromasetof
existing proof scripts. Diva uses the predictions from this model to
drive the search for a complete proof script.
Figure3detailstheencodersusedintheDivamodeltoencode
relevantaspectsofproofscripts.Figure 3(a)presentstheproofstate
encoder, which Diva uses to encode the goal, local context, andenvironment,inASTform.Toencodeatree,itusesaTreeLSTMnetwork [
20], which generates embeddings for each proof state
term. Figure 3(b)details the proof script encoder, which Diva uses
toencodetheproofscriptsequence.Weencodetheparsedsequence
752
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:18:33 UTC from IEEE Xplore.  Restrictions apply. Diversity-Driven Automated Formal Verification ICSE ‚Äô22, May 21‚Äì29, 2022, Pittsburgh, PA, USA
of previous tokens using a Bidirectional LSTM, which generates an
embeddingforthesequence.ABidirectionalLSTMimprovesontheLSTM by capturing more contextual information by processing the
input sequence in two ways, forward and backward [ 62], allowing
theoutputlayertosimultaneouslyseebothdirectionsofinforma-
tion.DivaencodestheGallinaproofterm(thefirstsynthesistoolto
do this) using the same encoder in Figure 3(b). Similar to the proof
script sequence encoding, we choose to encode the sequence of
prooftermtokensusingaBidirectionalLSTM,generatinganembed-
ding. Diva jointly learns embeddings for the sequences and ASTs.
Diva‚Äôs tactic decoder is modified from the tactic decoder first
used in ASTactic and, later, TacTok. This tactic decoder is con-ditioned on the sequence of embeddings. In Diva, however, the
embeddingsareaconcatenationofasubsetoftheembeddingsgen-
eratedfrom theproof script,proof term,and proof stateencoders.
This allows for modeling of more relevant proof script aspects and
thechoiceofwhichsubsettocombineallowsustocreatevariability
in the models (see Section 3.3). The tactic decoder then generates a
tacticbysequentiallygrowinganAST[ 91].Itchoosesaproduction
rule from the context free grammar of the tactic space at a non-
terminal node in the AST, while it synthesizes arguments based on
semantic constraints at a terminal node.A GRU [ 19,20] controls
thisprocessofgrowingthetree,asitupdatesitshiddenstateusing
the input embeddings of the partially generated AST.
Diva trains the model on a set of existing proof scripts. Each
proofscriptinthissetisbrokendownintotraininginstances,whicharetheinputstothemodel.Atraininginstanceiscomprisedofthe
proof state before the tactic execution, the proof script up to the
tactic execution, the Gallina proof term before the tactic execution,
and the next step of the proof script. The Diva model jointly learns
embeddings for the proof state ASTs, the proof script, and proofterm sequence, and then uses these embeddings to predict thenext proof script step in the form of an AST. The model sends
the predicted AST along with ground-truth nexttactic AST to the
trainer, where the trainer compares these tactic ASTs and back-
propagates the loss.
Unlike prior tools, Diva jointly trains a language model over the
tokens in the proof term. Section 3.2details further modifications
in this training process for creating Diva‚Äôs diverse models.
3.2 Diversity via varying learning parameters
Onewayinwhichwecreateadiversesetofmodelsisbyvarying
the learning parameters, which affects the model‚Äôs size and the
learningalgorithmitself.Forthis,westartwiththeTacmodelfrom
TacTok, and explore varying six dimensions: sequence tactic depth,
sequence token depth, the learning rate, the embedding size, the
number of layers, and the order of the training data.
Tacticandtokensequencedepth. Thesequencedepthdenotesthe
size of the input the learning algorithm considers. When training,
themodelcanconsidertheentireproofscriptwrittensofar,orpartofit,suchasonlythemostrecenttacticanditsarguments,orseveral
most recent tactics with arguments, or only several most recent
tokens. The proof script encoder considers only that portion of the
proofscript(and,symmetrically,thedecoderwillconsiderthesamedepthwhendecodingthenextproofstep).Divavariesthesequence
depth along both tactics and tokens, from a depth of 0, which doesnot consider the proof script at all (it considers only proof state,making the model equivalent to ASTactic‚Äôs model), to the entireproof script. Diva considers sequence depth sizes (excluding the
start token) of 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 29 and 30.
Learningrate. Duringtraining,thealgorithmupdatesthemodel‚Äôs
weightsineveryiteration.Thelearningrateisahyperparameter
that determines how much the weights can be changed in each
iteration.Alargerlearningrateislesslikelytoresultinthetrain-
inggettingstuckinalocaloptimum,butmayalsotakelongerto
converge or fail to explore a region long enough to find an optimal
solution. Accordingly, the models produced by varying the rate
canbequitedifferent.Divaconsiderslearningratesof 3 √ó10ùëòfor
ùëò‚àà{ ‚àí2,‚àí3,‚àí4,‚àí5,‚àí6,‚àí7,‚àí8}.
Modelsize(embeddingandlayers). Themodel‚Äôssizeisdefinedby
two hyperparameters, the number of model layers and embedding
size,whichisthesizethevectorspaceinwhichaproofaspectis
embedded. Diva varies the proof script encoder size by trying 1, 2,
3, 4, and 5 layers and embedding sizes of 64, 128, 256, and 512.
Training data order. The order of the training data can affect
the model [ 31]. We vary the order in which Diva sees the training
instances by creating ten random orders.
3.3 Diversity via varying training data
The second way in which we create a diverse set of models is
by varying aspects of the training data available to the learning
algorithm.Therearethreetypesofdatainthetrainingproofscripts:
the proof state, the proof script tactics and tokens, and the proof
term that the proof assistant generates when it executes the proof
script(recallSection 2.3).Whentrainingamodel,weeitherinclude
each of these three types of data or we exclude them. For the proofscript,weincludeeitherthetacticsorthetokens,sincetheyencode
fundamentally the same information. This leads us to a total of 11
models. For the models that do not include proof state, when we
encodethetraininginstancethatrepresentstheverystartofproof-
scriptsynthesis,weincludethetheorembeingproven(otherwise
the model would not know what it is trying to prove). Similarly, at
test time, when synthesizing the first proof script step, we include
the theorem being proven.
3.4 Efficiently combining model executions
ExecutingalargesetofmodelsinsequenceisslowsinceDivahasto
waitforamodeltofinishitsproofscriptsynthesisattemptbeforeit
cantrythenextone.WedevelopmodelinterruptstoimproveDiva‚Äôs
efficiency. In model interrupts, given a set of models, Diva assigns
anarbitraryorderofmodelapplication.Inorder,eachmodelwillbe
given a specified amount of time to try to synthesize a proof script.
Once the time runs out, the next model attempts to synthesize a
proof script from scratch. Figure 4illustrates this concept. The first
model attempts synthesis from scratch for ùëãseconds, at which
point, if a complete proof script is not generated, the partial proof
scriptisstoredandthesecondmodelattemptstosynthesizeaproof
scriptfromscratchfor ùëãseconds.Andsoon.Onceeachmodelis
given an opportunity to try for ùëãseconds and a complete proof
scriptisnotfound,themodelswillbegivenmoretimetosynthesize
753
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:18:33 UTC from IEEE Xplore.  Restrictions apply. ICSE ‚Äô22, May 21‚Äì29, 2022, Pittsburgh, PA, USA Emily First and Yuriy Brun
 Model1                          Model2               
timetactic 1Model
Prediction
tactic1. ... 
tactic k....
... tactic 1. tactic k tactic k+1
Proof
Script...
......
...
X s 2X s...
tactick+1 
Figure 4: Model interrupts allows Diva to let models take
turns synthesizing proof scripts from scratch.
aproofscriptstartingfromthestoredpartialproofscriptassociated
with the model.
4 EVALUATION
WeevaluateDivatomeasurehowmuchdiversityofmodelsofproof
scripts can increase the effectiveness of proof script generation.
Wefollowthemethodologiesofpriorevaluationsofproof-script
synthesistools[ 28,90],intermsofthedataset(Section 4.1.1)and
metrics (Section 4.1.2) used; we compare to two state-of-the-art
proof-script-synthesis tools, ASTactic [ 90] and TacTok [ 28], which
usethesamemetaheuristicsearchforproof-scriptsynthesisasDiva.
We further compare Diva to the state-of-the-art proof-synthesis
tool CoqHammer [21].
Our evaluation answers four research questions:
RQ1:Does diverse-modeling significantly improve proof-
script synthesis over state-of-the-art approaches
CoqHammer, ASTactic, and TacTok?
RQ2:Howmuchmodeldiversityresultsfromvaryingthe
modellearningparameterssequencedepth,learn-
ing rate, number of layers, size of embeddings, and
training order, and how does this model diversity
affect proof script synthesis effectiveness?
RQ3:How much model diversity results from varying
which aspects of the training proofs‚Äîtactics, to-
kens,proofstate,Gallinaproofterms‚Äîareavailable
to the learning process and how does this model
diversity affect proof script synthesis effectiveness?
RQ4:Howeffectiveisourinterruptsmechanismforim-
proving Diva efficiency?
All of our evaluation data and the source code to reproduce our
results are available [27].
4.1 Evaluation methodology
We first describe the dataset and metrics we use to evaluate Diva.
4.1.1 Dataset. Inourevaluation,weuseCoqGym[ 90],thestate-of-
the-art benchmark used in prior evaluations of formal verification
tools [28,51,90]. The benchmark consists of 70,856 theorems from
123open-sourcesoftwareprojectsinCoq.TheCoqGymbenchmarkcomes with a preselected training set of 96 projects with 57,719
human-writtenproofscripts,andtestsetoftheremaining13,137
theorems from 27 projects.
Our earlier TacTok evaluation [ 28] was unable to reproduce
prior results for ASTactic‚Äôs performance[ 90] for oneproject, coq-
library-undecidability, due to internal Coq errors when processing
the proof scripts. Accordingly, we exclude this project from our
evaluation.Wewereabletoreproducetheresultsfortheremaining
26projectsof10,782theorems.Intotal,ourtrainingandtestsets
have 68,501 theorems from 122 projects.
4.1.2 Metrics. We measure four quantities in answering our re-
search questions: success rate, added value, diversity, and mean
time to prove a theorem.
Success Rate. The success rate of a tool, widely used in prior
evaluations [ 28,41,90], is the fraction of all theorems for which
the tool generates a succesful proof script.
Added Value. The added value of tool A over tool B is the
numberofnewtheoremstoolAprovesthattoolBdoesnot,divided
by the number of theorems tool B proves.
Diversity. Givenasetofmodels,wewishtoknowhowmuch
diversity they yield with respect to their ability to prove theorems.
And so, we think of the diversity of a set of models as the diversity
ofthecorrespondingsetsoftheoremsthatthemodelsprove.Our
goalwiththediversitymeasureistobeabletocomparehowmuch
diversity results from various methods for creating models, so that
we can compare the different methods.
Informally, given a set of sets of objects (theorems) we define a
familyofdiversityfunctions,suchthatthe ùëòthdiversityfunction,
ùëëùëò, measures the relative increase in objects contained in ùëòsets,
as compared to ùëò‚àí1 sets. So, for example, for a set of models,
ùëë5denotes the fraction of the additional theorems (out of all the
theoremsprovedbyat leastonemodel)thatareableto be proved
by adding a fifth model to a set of four models, on average.
Moreformally,let ùëábeasetofobjectsandlet ùëÄbeasetofsubsets
ofùëásuch that the union of all sets in ùëÄis equal to ùëá. Then, for
eachùëò‚àà{1,2,3,...,|ùëÄ|}, theùëòthdiversity function ùëëùëò:2ùëá‚ÜíR
isthe averageincrease,in termsof thefraction of ùëá,that theunion
ofùëòelements of ùëÄcontains over the union of ùëò‚àí1 elements of ùëÄ.
Thus, for all ùëÄùëò‚äÜùëÄ, such that |ùëÄùëò|=ùëò, and for all ùëÄùëò‚àí1‚äÜùëÄ,
such that |ùëÄùëò‚àí1|=ùëò‚àí1,ùëëùëò(ùëÄ)is the average value of|ùëÄùëò\ùëÄùëò‚àí1|
|ùëá|.
Givenasetofmodels,wecomputethediversityfunctionsem-
pirically. We use each model to attempt to synthesize proof scripts
to prove theorems. We then compute ùëá, the set of all theorems
that can be proven by at least one model. Then, to compute ùëëùëò,w e ,
for each model, compute how many additional theorems it proves
comparedtoeachsetof ùëò‚àí1models.Wethencomputetheaverage
ofthosenumbers,anddivideitby |ùëá|fornormalization.Intheend,
ùëëùëò(ùëÄ)istheaverage fractionoftheoremsproven byaddinga ùëòth
modelto asetof ùëò‚àí1models.Notethat thesumof ùëëùëòforallùëòis
1, and that diversity is monotonically non-increasing with respect
toùëò(that is,ùëëùëò‚àí1‚â§ùëëùëò.)
MeanTimetoProveaTheorem. Tomeasureefficiency,we
compute the mean time it takes to generate a proof script for a
theorem,averagedoverallthetheoremsforwhichweproducea
successful proof script, and over all the possible orderings of the
models used in the metaheuristic search.
754
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:18:33 UTC from IEEE Xplore.  Restrictions apply. Diversity-Driven Automated Formal Verification ICSE ‚Äô22, May 21‚Äì29, 2022, Pittsburgh, PA, USA
tool theorems proven Diva‚Äôs value added
ASTactic 1,322(12.3%) 908(76.9%)
TacTok 1,388(12.9%) 842(68.4%)
CoqHammer 2,865(26.6%) 781(27.3%)
all 3 prior tools 3,282(30.4%) 364 (11.1%)
Diva 2,338(21.7%) ‚Äî
Diva & CoqHammer 3,646(33.8%) ‚Äî
Figure5:TheoremsprovenbyandthesuccessrateofDiva,
ASTactic,TacTok,CoqHammer,andthecombinationofthese
tools out of the 10,782 theorems in CoqGym‚Äôs test dataset.
Divaprovidesvalueaddedovereachofthesetools,and11.1%
value added over the combination of all three.
4.2 RQ1: Does diversity help Diva outperform
the state-of-the-art?
We created models by varying learning parameters and aspects
of proof scripts to encode (recall the models described in Sec-
tions3.2and3.3).Overall,wegeneratedthese62modelsforDiva
to use.
We compare Diva to the state-of-the-art synthesis tools, ASTac-
tic [90], TacTok [ 28], and CoqHammer [ 21]. ASTactic and TacTok,
like Diva, learn from existing proof scripts to predict the next step
of the proof script. CoqHammer uses a fundamentally different
approach. Whereas CoqHammer produces proofs in Coq‚Äôs logic
(Gallina), Diva searches the proof-script space. When the Coq com-
piler executes a proof script, it generates a proof. Proofs cannot
bewrong,whileproofscriptscanbe(e.g.,aproofscriptthatcon-
cludes with Proof completed, may not lead to a valid proof when it
is checked by the Coq compiler). Thus, it is reasonable to compare
proof script synthesis tools, such as Diva, to CoqHammer with
respecttothetheoremstheyareabletoprove.However,sincetheirapproaches are so fundamentally different, it is expected that these
tools are likely to be complementary, performing well for different
theorems. While CoqHammer and Diva are likely to perform simi-
larly well for some simpler classes of theorems, CoqHammer is at
a fundamental disadvantage, though, for other classes of theorems,
such as ones that require induction to prove.
On our evaluation set of 10,782 theorems, ASTactic proves 1,322
(12.3%) and TacTok proves 1,388 (12.9%) theorems. CoqHammer
proves 2,865 (26.6%) theorems. Prior to performing our evaluation,
weexpectedthatDivawouldprovestrictlymoretheoremsthanAS-
TacticandTacTok(thoughhowmanymoreremainedanimportant
question),thatitwouldnotprovemoretheoremsthanCoqHam-
mer, but that itwould prove some complementary theorems,thus
providingsignificantaddedvaluecomparedtoCoqHammer,aswas
the case in ASTactic and TacTok evaluations [28, 90].
Figure5showsthesuccessrates,aswellastherawnumberof
theorems proven by the four tools, and the value Diva adds over
eachtool,aswellastheircombination.Divaproves2,338(21.7%)
of the theorems. This means Diva proves2,338‚àí1,322
1,322=76.9% more
theorems than ASTactic and2,338‚àí1,388
1,388=68.4% more theorems
than TacTok. Since these tools use the same search mechanism,364
(3.4%)
TacTokASTactic
7,136 (66.2%) unproven theoremsDiva
388
(3.6%)88
(0.8%)0
(0.0%)
1,308
(12.1%)
0
(0.0%)0
(0.0%)
0
(0.0%) 910
(8.4%)
149
(1.4%)214
(2.0%)110
(1.0%)
0
(0.0%)CoqHammer115
(1.1%)0
(0.0%)
Figure 6: The breakdown of how many theorems are proven
byeachcombinationoftools.Divaproves364theoremsno
other tool proves.
thesesignificantimprovementsaredueentirelytotheuseofmodel
diversity.
WhileCoqHammerprovesmoretheoremsthanDiva,Divaproves
781 theorems that CoqHammer does not, an added value of781
2,865=
27.3%. Figure 6shows a Venn diagram of the theorems Diva, AS-
Tactic,TacTok,andCoqHammerprove.Together,thesefourtools
prove 3,646 theorems, for a success rate of 33.8%, whereas without
Diva,theotherthreeto olsprove 3,282theorems.(BecauseASTactic
and TacTok have an added value of 0% over Diva, CoqHammer
andDivaprovethe3,282theoremsontheirown,withouttheother
tools‚Äô help.) Diva adds a value of 11.1% over the combined state of
the art, and proves 364 theorems no tool has previously proven.
RA1: Our Diva diversity mechanisms are successful in
creatingmodeldiversitysufficienttosignificantlyimprove
the proving power of metaheuristic-search-based tools
(68%‚Äì77%addedvalue).Divaalsogenerates27.3%added
valueoverCoqHammer,andp roves364 theoremsnoprior
tool has proven. Together with CoqHammer, Diva reaches
a new milestone, proving over one third of all theorems
completely automatically.
4.3 RQ2: Learning-parameter diversity
To investigate the effectiveness of varying learning parameters on
generating diverse models, we conduct a series of experiments by
generatingmodelsvaryingthoseparameters,usingtheresulting
modelstosynthesizeproofscripts,andthenmeasuringthe diversity
of the sets of theorems the models prove. As Section 3.2described,
thefactorsweinvestigatearesequencedepth,learningrate,number
of layers, embedding size, and training order. Figure 7details how
muchdiversityDivaproducesbyvaryinglearningparametersin
training its models.
Tactic depth diversity. We vary the tactic sequence depth,
consideringdepthsof0,1,2,3,4,5,6,7,8,9,10,15,20,25,29and
30; a total of 16 models. (Note that the depth 0 model is equivalent
to ASTactic,and the depth3 model isequivalent to the Tacmodel
inTacTok.)Overallthese16modelsprove1,858theorems,whereas
755
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:18:33 UTC from IEEE Xplore.  Restrictions apply. ICSE ‚Äô22, May 21‚Äì29, 2022, Pittsburgh, PA, USA Emily First and Yuriy Brun
12345678910111213141516
kth model added0.00.10.20.30.40.50.60.7average diversity of adding kth model
12345678910111213141516
k050010001500average theorems proven by k models
(a) Tactic sequence depth (total 1,858 theorems)12345678910111213141516
kth model added0.00.10.20.30.40.50.60.7average diversity of adding kth model
12345678910111213141516
k050010001500average theorems proven by k models
(b) Token sequence depth (total 1,810 theorems)
1 2 3 4 5 6 7
kth model added0.00.10.20.30.40.50.60.7average diversity of adding kth model
1 2 3 4 5 6 7
k02004006008001000120014001600average theorems proven by k models
(c) Learning rate (total 1,730 theorems)1 2 3 4
kth model added0.00.10.20.30.40.50.60.70.8average diversity of adding kth model
1 2 3 4
k0200400600800100012001400average theorems proven by k models
(d) Embedding size (total 1,496 theorems)
1 2 3 4 5
kth model added0.00.10.20.30.40.50.60.70.80.9average diversity of adding kth model
1 2 3 4 5
k0200400600800100012001400average theorems proven by k models
(e) Number of layers (total 1,476 theorems)1 2 3 4 5 6 7 8 9 10
kth model added0.00.20.40.60.81.0average diversity of adding kth model
1 2 3 4 5 6 7 8 910
k020040060080010001200average theorems proven by k models
(f) Training data order (total 1,232 theorems)
Figure 7: The diversity exhibited by altering learning parameters tactic sequence depth (a), token sequence depth (b), learning
rate(c),embeddingsize(d),numberoflayers(e),andtrainingdataorder(f).Theleftgraphineachpairshowsthediversity
measure, as a function of the number of models (e.g., the ùëò=5bar is the mean fraction of additional theorems proven by
pickingarandom5thmodelthatarandomdisjointsetof4modelshasnotproven).Therightgraphineachpairshowsthe
meannumberoftheoremsprovenby ùëòmodels.Thebox-and-whiskersindicatethemaximum,75%-,50%-,and25%-tiles,and
minimum values.
on average, a single mo del proves 1,064 theorems. Diva‚Äôs diversity
isresponsiblefora74.6%increaseinprovingpower!Theleftgraph
inFigure 7(a)showsthediversityofthesetoftacticsequencedepth
models (recall the diversity metric from Section 4.1.2). The ùëòthbar
showsùëëùëòfor the 16 models. That is, the ùëòthbar states the fraction
ofextratheoremsprovenby ùëòrandommodels,thatarandomsetof
ùëò‚àí1modelsdoesnotprove.Forexample,the ùëò=1barissimply
theeffectiveness ofusinga singlemodel,0.573 (onaverage, 57.3%
of the theorems proven by all models together are proven by using
one random model). The remaining 42.7% need Diva‚Äôs diversity
mechanism.For ùëò=2,thediversityis0.138,meaningthatadding
the second model, on average, adds an additional 13.8% of the totaltheorems proven. Two randomly chosen models prove, on average,
57.3%+13.8%=71.1% of all the theorems proven by at least one
model.TherightgraphinFigure 7(a)showstheaveragenumberoftheoremsthat ùëòofthetacticsequencedepthmodelsprove.Thebox-
and-whiskers indicate the variability in the choice: how important
is it to select specific ùëòmodels, or can they simply be selected at
random. For example, a single model can prove between 957 (8.9%)
and1,322(12.3%)theoremsfromthetestset.Weleavedeveloping
mechanisms for selecting models to future work.
Token depth diversity. Similar to tactic depth, we considered
tokendepthsof0,1,2,3,4,5,6,7,8,9,10,15,20,25,29and30;a
totalof16models.(Notethatthedepth0modelis,again,equivalenttoASTactic,andthedepth30modelisequivalenttotheTokmodel
in TacTok.) Overall these 16 models prove 1,810 theorems (slightly
fewerthantacticdepthdiversitymodelsdid),whereasonaverage,a
single model proves 1,080 theorems. Diva‚Äôs diversity is responsible
for a 67.6% increase in proving power. The left graph in Figure 7(b)
shows the diversity of the token depth models. A single randommodel proves a slightly larger fraction, 59.7%, of all the proven
756
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:18:33 UTC from IEEE Xplore.  Restrictions apply. Diversity-Driven Automated Formal Verification ICSE ‚Äô22, May 21‚Äì29, 2022, Pittsburgh, PA, USA
theorems than was the case for tactic depth models, indicating
again that token depth provides slightly less useful diversity. Still,
the remaining 40.3% of the theorems require Diva‚Äôs diversity to
beproven.TherightgraphinFigure 7(a)showsthevariabilityin
aselected ùëòmodels.Here,a singlemodelcanprovebetween992
(9.2%)and 1,322(12.3%) theoremsfrom thetest set.Overall, token
depth provides significant diversity, but less than tactic depth did.
Learning rate. We explore 7 different learning rates: 3 √ó10ùëò
forùëò‚àà{ ‚àí2,‚àí3,‚àí4,‚àí5,‚àí6,‚àí7,‚àí8}. Overall these 7 models prove
1,730theorems(slightlyfewerthanthedepthdiversitymodelsdid),
whereas on average, a single model proves 945 theorems. Diva‚Äôs
diversity is responsible for a 83.1% increase in proving power. The
left graph in Figure 7(c)shows the diversity of the learning rate
models. A single random model proves 54.6% of all the proven
theorems. The remaining 45.4% of the theorems require Diva‚Äôsdiversity to be proven. The right graph in Figure 7(c)shows the
variabilityinaselected ùëòmodels.Here,asinglemodelcanprove
between 505 (4.7%) and 1,115 (10.3%) theorems from the test set.
Overall,learningrateprovidessignificantdiversity,andthemodelsaremorediversefromoneanotherthanthesequencedepthmodels,
but, overall, result in slightly less proving power.
Embedding size. We explore 4 different embedding sizes: 64,
128,256,512.Overallthese4modelsprove1,496theorems(fewer
thanthealreadydiscussedmodels),whereasonaverage,asingle
modelproves1,100theorems.Diva‚Äôsdiversityisresponsiblefora
36.0%increaseinprovingpower.TheleftgraphinFigure 7(d)shows
thediversityoftheembeddingsizemodels.Asinglerandommodel
proves 73.5% ofall the proven theorems. Theremaining 26.5% of
thetheoremsrequireDiva‚Äôsdiversitytobeproven.Therightgraph
in Figure 7(d)shows the variability in a selected ùëòmodels. Here,
a single model can prove between 1,056 (9.8%) and 1,134 (10.5%)
theorems from the test set. Overall, embedding size provides some
diversity, though less than sequence depth and learning rate.
Number of layers. We explore 5 different numbers of layers: 1,
2, 3, 4, and 5. Overall these 5 models prove 1,476 theorems (similar
to the embedding size), whereas on average, a single model proves
1,109 theorems. Diva‚Äôs diversity is responsible for a 33.1% increase
inprovingpower.TheleftgraphinFigure 7(e)showsthediversityof
the number of layers models. A single random model proves 75.2%
ofalltheproventheorems.Theremaining24.8%ofthetheorems
requireDiva‚Äôsdiversitytobeproven.TherightgraphinFigure 7(e)
showsthevariabilityinaselected ùëòmodels.Here,asinglemodel
canprovebetween1,063(9.9%)and1,158(10.5%)theoremsfromthe
test set. Overall, varying the number of layers provides a similar
amount of diversity as embedding size. Both parameters effect the
size of the learnt model.
Trainingdataorder. Weexplore10randomlychosenorderings
of the training data. Overall these 10 models prove 1,232 theorems,
the smallest number of all the learning parameters, whereas on
average,asinglemodelproves1,073theorems.Diva‚Äôsdiversityis
responsiblefora14.8%increaseinprovingpower.Theleftgraph
in Figure 7(f)shows the diversity of the training data order models.
A single random model proves 87.1% of all the proven theorems.
The remaining 12.9% of the theorems require Diva‚Äôs diversity to
be proven. The right graph in Figure 7(f)shows the variability in a
selectedùëòmodels. Here, a single model can prove between 1,058(9.8%)and1,098(10.2%)theoremsfromthetestset.Overall,even
just varying the training data order provided some useful diversity
and enabled proving more theorems, though the diversity benefits
were much smaller than those of the other parameters.
RA2:Varyinglearningparametersresultedinsignificant
diversity, which, in turn, led to significant improvementin proving power. Varying the depth of the tactics and
tokensthemodellearntfromandthelearning rateledto
the greatest diversity, while varying the size of the model
ledtomoderatediversity.Varyingtheorderofthetraining
data marginally increased the proving power.
4.4 RQ3: Training-data diversity
Recall from Section 3.3that there are three types of data in the
trainingproofscripts:theproofstate,theproofscripttacticsand
tokens,andtheGallinaproofterm.Wetrainmodelsforallpossible
combinationsofthesedatatypes,exceptnomodelincludesbothtactics and tokens, and we exclude the model that is the empty
combination. In total, we learn 11 models.
We first measure the value added by adding each of the three
types of information. The value of adding proof script tactics toa model already encoding the proof state and the Gallina proof
termis 134.2%,proving anadditional345 theorems.(Thevalue of
adding proof script tokens instead of tactics is similar, 136.6%, 351
theorems). The value of adding Gallina proof term to a model al-
readyencodingtheproofscriptandtheproofstateismuchsmaller,8.0%, proving an additional 89 theorems. (If using tokens instead oftactics,theaddedvalueis10.6%,124theorems.)Finally,thevalueofaddingproofstatetoamodelalreadyencodingtheproofscriptandtheGallinaprooftermis21.8%,provinganadditional135theorems.
(If using tokens instead of tactics, the added value is 53.5%, 281
theorems. We observe that while in previous scenarios, tactics and
tokens behaved similarly, here, tokens exhibit much more diversity
thantactics.)Inallthreecases,tokensexhibitedgreaterdiversity
than tactics in encoding the proof script, suggesting that tokens
areamoredifferentrepresentationthantacticsoftheothertypes
of information. The Gallina proof term contained theleast diver-
sitycompared totheother typesof data,whereasthe proofscript
contained the most.
Overall, these 11 models prove 2,053 theorems, which is sig-
nificantly more than any of the learning parameter models from
Section4.3.Asinglemodel,onaverage,proves785theorems.Diva‚Äôs
diversityisresponsiblefora161.5%increaseinprovingpower!TheleftgraphinFigure 8showsthediversityofthetraining-data-types
models.Asinglerandommodelproves38.3%ofalltheproventheo-rems.Theremaining61.7%ofthetheoremsrequireDiva‚Äôsdiversity
to be proven. The right graph in Figure 8shows the variability
in a selected ùëòmodels. Here, a single model can prove between
257 (2.4%) and 1,322 (12.3%) theorems from the test set. Overall,
trainingdatatypesprovidethemostdiversityofallthedimensions
we explored, leading to the greatest proving power.
757
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:18:33 UTC from IEEE Xplore.  Restrictions apply. ICSE ‚Äô22, May 21‚Äì29, 2022, Pittsburgh, PA, USA Emily First and Yuriy Brun
1 2 3 4 5 6 7 8 910 11
kth model added0.00.10.20.30.40.50.60.7average diversity of adding kth model
1 2 3 4 5 6 7 8 910 11
k0500100015002000average theorems proven by k models
Figure 8: Training data aspects (total 2,053 theorems)
RA3: Including different data types in training resulted in
the most diversity of all the dimensions we considered,
leading to the greatest proving power increase. Adding
proofscripttacticsortokensprovidedthemostdiversity,
followed by the proof state.
4.5 RQ4: Synthesis efficiency
To explore improving Diva‚Äôs efficiency, we implement model inter-
rupts described in Section 3.4. We evaluate the efficiency improve-
mentofmodelinterruptsbymeasuringthemeantimetoprovea
theoremwithandwithoutinterrupts.Ofcourse,theorderinwhichDivaconsidersthemodelsmatters.Withoutinterrupts,intheworst
case, the last model produces the successful proof script, and Diva
wastes 10 minutes on each of the other models, before they time
out. For our evaluation, we measure the mean time over a random
sample of 20 possible model orderings.
Withoutinterrupts,themeantimetoproveatheoremis685.5
seconds. However, we observe that most models either synthesize
theproofscriptrelativelyquickly,ordon‚Äôtatall,thoughwithsomenotableexceptions.Usingmodelinterruptsallowsustobenefitfromprovingtheoremsquicklyintheinitialburstofeachmodel,without
spending the long time in the tail of each model‚Äôs distribution,
unlessitisnecessary.Withmodelinterrupts,weexplore15differentswitchingtimes:1,2,3,4,5,6,7,8,9,10,15,20,25,30,and60seconds.
We explore two different interrupt schemes. First, we attempt
to synthesize a proof script using each model for ùëãseconds. If
noneofthemodelsfindaproofscriptinthattime,wereturnand
giveeachmodelanother ùëãseconds.Andsoon,untileachmodel
has attempted its search for 10 minutes. The left graph in Figure 9
shows the mean time to prove a theorem for this interrupt scheme.
Forùëã=1 second, this interrupt scheme achieves the minimal
mean time to prove a theorem of 17.2 seconds, and the provingtime increases monotonically for larger
ùëã. Forùëã=1, the speed
upcomparedtonotusinginterruptsis97%,or40 √ó.Thissuggests
that many theorems are proven very early in the synthesis process,
andwhilesometheoremsdogetprovenafteralengthysynthesis
search, prioritizing the first seconds of synthesis using the diverse
models greatly improves synthesis efficiency.
Second,weallow eachmodeltoattempttosynthesizeaproof
script for ùëãseconds, and then give each model the remainder of
its 600‚àíùëãseconds, thus switching only once per model. The right
graph in Figure 9shows the mean time to prove a theorem for
this interrupt scheme. For ùëã=5 seconds, this interrupt scheme123456789101520253060
switching time0200400600800100012001400mean time to prove theorem
123456789101520253060
switching time0200400600800100012001400mean time to prove theorem
Figure 9: Mean time to prove a theorem using the model
interrupts optimization for different switching times (in sec-
onds).Executingeachmodel‚Äôssearchfor ùëãseconds,andthen
again each model‚Äôs search for ùëãseconds, and so on until
eachmodel‚Äôssearchhasbeenexecutedfor600seconds(left
graph), achieves the minimal mean time to prove a theorem
of17.2secondswhen ùëã=1second.Interruptingeachmodel‚Äôs
search once, first executing each model for ùëãseconds, and
then each model for 600‚àíùëãseconds, (right graph), achieves
theminimalmeantimetoproveatheoremof44.7seconds
whenùëã=5seconds.Thebox-and-whiskersindicatethemax-
imum,75%-,50%-,and25%-tiles,andminimumvaluesover
20 different model orderings.
achievestheminimalmeantimetoproveatheoremof44.7seconds,
aspeedupof 93%, or 15√ó, compared to not using interrupts.
RA4:Modelinterruptsisincrediblyeffective,cuttingdown
the mean time to prove a theorem by up to 97%.
4.6 Threats to validity
TheCoqGymbenchmarkweevaluateourworkonhasbeenused
by prior evaluations of proof-script synthesis [ 28,90] and uses the-
oremsfrom122open-sourceprojects,improvingthelikelihoodthat
our results generalize. Our analysis focuses on the Coq interactive
proof assistant and may not extend to other assistants, such as
HOL4[72]andHOLLight[ 36].Transformershaveoutperformed
BidirectionalLSTMinsomenaturallanguagetasks[ 23],andmaybe
able to improve Diva‚Äôs performance beyond what we find here, buttheyrequiresignificantlylargertrainingsetsthanwhatisavailable
today in projects written in Coq. Accordingly, future work should
explore other neural modeling architectures.
5 RELATED WORK
We now place our research in the context of related work.
Interactive Theorem Provers (ITPs). ITPs, such as Coq [ 79],
Agda [84], Dafny [ 49], F* [77], Liquid Haskel [ 83], Mizar [ 80], Is-
abelle [61], HOL4 [ 72], and HOL Light [ 36] are semi-automated
systemsforformallyprovingtheorems.WefocusonCoq,butour
approach is applicable to other ITPs. Coq has been used to build
andverifyaCcompiler[ 50],anoperatingsystemkernel[ 32],an
x86 model [ 57], a file system [ 42], distributed protocols [ 71] and
systems [88], a browser [45], and network controllers [33].
Automation for Proof Systems. Heuristic-based search can par-
tially automate ITPs [ 5,12,14,15].Hammers use external ATPs
758
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:18:33 UTC from IEEE Xplore.  Restrictions apply. Diversity-Driven Automated Formal Verification ICSE ‚Äô22, May 21‚Äì29, 2022, Pittsburgh, PA, USA
to automatically find proofs for ITPs [ 21]. Classical search algo-
rithms, such as A*, can also search for proofs in HOL4 [ 30], as can
reinforcement-learning-basedmethods[ 89].Bycontrast,Divamod-
elsexistingproofscripts,usesnativetactics,andprovestheorems
within the ITP framework.
Software Engineering for Interactive Proof Assistants. Pump-
kinPatchgeneratesproofpatcheswhensoftwareevolves[ 67]by
learning from a template of a human-written fix to a similar evolu-
tion.UnlikePumpkinPatch,Divadoesnotrequireanearly-working
proofscriptandgeneratesproofscriptsfromscratch.PumpkinPi
repairstheprooftermofabrokenproofandthenusesadecompiler
togenerateaproofscript[ 66].PumpkinPi‚Äôsproofscriptconsists
of predefined tactics, whereas Diva predicts tactics from a learnt
model.
iCoq[16]findsfailingproofscriptsinevolvingprojectsbyprior-
itizing proof scripts affected by a revision. iCoq tracks fine-grained
dependencies between Coq definitions, propositions, and proof
scripts to narrow down the potentially affected proof scripts. Diva
does not require a failing proof script, but our ideas could poten-
tially be used to repair proof scripts. QuickChick [ 48], a random
Coqtestingtool,searchesforcounterexamplestoexecutablethe-
oremsandhelpsaprogrammergainconfidencethatatheoremis
correct.
LanguageModelsforCode. Languagemodelingofsourcecode
can detect bugs and generate tests [1, 26,64]. Modeling code with
ùëõ-gramscan helpcode completion[ 39,40].Modified ùëõ-gramscan
beusedasacachetocapturelocaldependenciesincode[ 81].How-
ever, such applications have not been applied to ITPs. Applyinglanguage models to Coq and HOL4 proof scripts showed that
ùëõ-
gram models outperform recurrent neural networks [ 37]. Unlike
Diva, thisapproach didnot considerthe proofstate orproof term
and does not synthesize complete proof scripts.
Machine Learning in Formal Verification. Machine learning
can simplify formal verification: ML4PG helps Coq users construct
proof scripts by showing proof scripts of similar theorems [ 38,47].
Machinelearningcansimilarlyhelpwithpremiseselection,thetaskof selecting lemmas that are relevant to a given theorem [
3,43,86].
NeuroTactic representstheorems andpremises withgraph neural
networksforprediction[ 51].GamePad[ 41]andProverbot9001[ 69]
modeltheproofstateinCoqusingRNNs.Divasimilarlycaptures
theproofstate,butunlikeGamePad andProverbot 9001,alsomodels
theproofscriptandGallinaprooftermforscriptsynthesis.Divais a generalization of ASTactic [
90] and TacTok [ 28]. These tools
use the CoqGym [ 90] benchmark for evaluation, which is also a
learning environment. Large transformer models can be applied to
theorem proving in the MetaMath formalization language and the
Leaninteractiveproofassistant[ 34,63].However,thesepowerful
models require much larger training sets than what is available
today in Coq projects.
MetaheuristicSearch. Metaheuristic-search-basedsoftwareen-
gineering [ 35] has been used for developing test suites [ 55,85],
finding safety violations [ 4], refactoring [ 70], project management
and effort estimation [ 8], and automated program repair [ 2,46,87].
Insearch, low-qualityfitness functionscanlead tolow-qualityre-
sults, such as, for example, incorrect bug patches [ 58,73]. With
Diva,theinteractivetheoremproverprovidesastrongassurancethatthefinalproducedproofscriptleadstoacorrectproof,andthus,
proof script synthesis is particularly well suited for metaheuristic-
search-based methods.
Ensemble Learning. Ensemble learning is the generation and
combinationofmultiplemodelstomakeadecision.Thisistypically
used in supervised machine learning tasks [ 68]. The idea is that
weighing and combining several opinions is better than simply
choosingasingleone.Whengeneratingamodeltobeusedinan
ensemblelearningmethod,themodelshouldbesufficientlydiverse
for the ensemble to achieve a desired predictive performance [ 22],
and the individual model‚Äôs predictive performance should be as
highaspossible.Thereareseveralapproachestogeneratingdiverse
models, including input manipulation [ 18], manipulation of the
learning algorithm [13, 52,54], and combinations of strategies.
Ensemblelearningmethodseitherhavedependentmodels,where
theoutputofeachmodelaffectsthegenerationofthenext,orin-
dependentmodels,whereeachmodelisconstructedindependentlyfromtheothers[
68].Anotherwaytocombineclassifiersisthrough
stacking[ 24],whichusesaclassifiertodecidewhichmodeltoapply
toeachinput.Divadiffersfromthesemethodsbyusingindepen-
dentmodelsinseparatesearchesoftheproofscriptspacesincethe
Coqproofassistantservesasanoracleforwhethertheresulting
proof scripts are valid.
6 CONTRIBUTIONS
We have identified a method for using diversity to significantly im-
prove the proving power of proof-script-synthesis tools. We create
Diva, implementing our diversity-based approach, which proves
68% more theorems than TacTok and 77% more than ASTactic, two
state-of-the-art proof-script-synthesis tools. Diva automaticallyproves 364 theorems no existing tool has proved. Together with
CoqHammer, Diva proves more than a third of all the theorems in
our benchmark of 122 open-source projects, the largest fraction to
date.OurmodelinterruptsoptimizationimprovesDiva‚Äôsrunning
timeby40 √ó.Alongthewayweidentifyakillerappforensemble
learning, by using the theorem prover as an oracle for optimallyaggregating learnt model results. Our findings strongly suggest
that using diversity for improving automated formal verification is
fruitful and warrants further research.
ACKNOWLEDGMENTS
Thiswork issupported bythe NationalScience Foundationunder
grant no. CCF-1763423, and by Amazon. This work was performed
in part using high performance computing equipment obtained
underagrantfromtheCollaborativeR&DFundmanagedbythe
Massachusetts Technology Collaborative.
DATA AVAILABILITY
Allofourdataandsourcecodetoreproduceourresultsareavail-
able[27].Divaisopen-sourceandisavailableat https://github.com/
LASER-UMASS/Diva/.
REFERENCES
[1]TonyAbou-Assaleh,NickCercone,VladoKeselj,andRaySweidan.2004. N-gram-
baseddetectionofnewmaliciouscode.In AnnualInternationalIEEEComputer
Software and Applications Conference, Vol. 2. 41‚Äì42. https://doi.org/10.1109/
CMPSAC.2004.1342667
759
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:18:33 UTC from IEEE Xplore.  Restrictions apply. ICSE ‚Äô22, May 21‚Äì29, 2022, Pittsburgh, PA, USA Emily First and Yuriy Brun
[2]Afsoon Afzal, Manish Motwani, Kathryn T. Stolee, Yuriy Brun, and Claire Le
Goues.2021. SOSRepair:ExpressiveSemanticSearchforReal-WorldProgramRepair.IEEE Transactions on Software Engineering (TSE) 47, 10 (October 2021),
2162‚Äì2181. https://doi.org/10.1109/TSE.2019.2944914
[3]JesseAlama,TomHeskes,DanielK√ºhlwein,EvgeniTsivtsivadze,andJosefUrban.
2014. Premise selection for mathematics by corpus analysis and kernel methods.
JournalofAutomatedReasoning 52,2(2014),191‚Äì213. https://doi.org/10.1007/
s10817-013-9286-5
[4]EnriqueAlbaandFranciscoChicano.2007. FindingsafetyerrorswithACO.In
Conference on Genetic and Evolutionary Computation (GECCO). London, England,
UK, 1066‚Äì1073. https://doi.org/10.1145/1276958.1277171
[5]Peter B Andrews and Chad E Brown. 2006. TPS: A hybrid automatic-interactive
system for developing proofs. Journal of Applied Logic 4, 4 (2006), 367‚Äì395.
https://doi.org/10.1016/j.jal.2005.10.002
[6]AWS [n.d.]. AWS Provable Security. https://aws.amazon.com/security/provable-
security.
[7]Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015. Neural Machine
TranslationbyJointlyLearningtoAlignandTranslate.In InternationalConference
onLearningRepresentations(ICLR).SanDiego,CA,USA. https://arxiv.org/abs/
1409.0473
[8]AhiltonBarreto,M√°rcioBarros,andCl√°udiaWerner.2008. Staffingasoftware
project: A constraint satisfaction approach. Computers and Operations Research
35, 10 (2008), 3073‚Äì3089.
[9] BedRock [n.d.]. BedRock Systems Inc. https://bedrocksystems.com.
[10]Yoshua Bengio, R√©jean Ducharme, Pascal Vincent, and Christian Jauvin. 2003. A
NeuralProbabilisticLanguageModel. JournalofMachineLearningResearch 3,
Feb. (2003), 1137‚Äì1155.
[11]AlBessey,KenBlock,BenChelf,AndyChou,BryanFulton,SethHallem,Charles
Henri-Gros, Asya Kamsky, Scott McPeak, and Dawson Engler. 2010. A Few
BillionLines ofCode Later:UsingStatic AnalysistoFind Bugsinthe RealWorld.Commun.ACM 53,2(Feb.2010),66‚Äì75. https://doi.org/10.1145/1646353.1646374
[12]JasminChristianBlanchette,LukasBulwahn,andTobiasNipkow.2011. Auto-
maticproofanddisproofinIsabelle/HOL.In InternationalSymposiumonFrontiers
ofCombiningSystems.Springer,12‚Äì27. https://doi.org/10.1007/978-3-642-24364-
6_2
[13]Gavin Brown, Jeremy L Wyatt,PeterTino, and Yoshua Bengio. 2005. Managing
diversityinregressionensembles. Journalofmachinelearningresearch(JMLR) 6,
9 (2005).
[14]AlanBundy.1998. Ascienceofreasoning.In InternationalConferenceonAuto-
matedReasoningwithAnalyticTableauxandRelatedMethods .Springer,10‚Äì17.
https://doi.org/10.1007/3-540-69778-0_2
[15]AlanBundy,FrankVanHarmelen,ChristianHorn,andAlanSmaill.1990. The
OYSTER-CLAM system. In International Conference on Automated Deduction
(CADE). Springer, 647‚Äì648. https://doi.org/10.1007/3-540-52885-7_123
[16]AhmetCelik,KarlPalmskog,andMilosGligoric.2017. ICoq:Regressionproofse-lectionforlarge-scaleverificationprojects.In IEEE/ACMInternationalConference
on Automated Software Engineering (ASE). Urbana-Champaign, IL, USA, 171‚Äì182.
https://doi.org/10.1109/ASE.2017.8115630
[17] Certora [n.d.]. Certora. https://www.certora.com.
[18]PhilipKChanandSalvatoreJStolfo.1995. Acomparativeevaluationofvoting
andmeta-learningonpartitioneddata. In MachineLearningProceedings.Elsevier,
90‚Äì98.
[19]Kyunghyun Cho, Bart van Merri√´nboer, Caglar Gulcehre, Dzmitry Bahdanau,Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning Phrase
RepresentationsusingRNNEncoder-DecoderforStatisticalMachineTranslation.
InConference on Empirical Methods in Natural Language Processing (EMNLP).
Doha, Qatar, 1724‚Äì1734. https://doi.org/10.3115/v1/D14-1179
[20]JunyoungChung,CaglarGulcehre,KyungHyunCho,andYoshuaBengio.2014.
Empirical evaluation of gated recurrent neural networks on sequence modeling.
InDeepLearningandRepresentationLearningWorkshop(DL&RL). http://arxiv.
org/abs/1412.3555
[21]≈Åukasz Czajka and Cezary Kaliszyk. 2018. Hammer for Coq: Automation for
DependentTypeTheory. JournalofAutomatedReasoning 61,1-4(2018),423‚Äì453.
https://doi.org/10.1007/s10817-018-9458-4
[22]Houtao Deng, George Runger, Eugene Tuv, and Martyanov Vladimir. 2013. A
timeseriesforestforclassificationandfeatureextraction. InformationSciences
239 (2013), 142‚Äì153.
[23]Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. Bert:
Pre-trainingofdeepbidirectionaltransformersforlanguageunderstanding.In
ConferenceoftheNorthAmericanChapteroftheAssociationforComputational
Linguistics:HumanLanguageTechnologies(NAACL-HLT) .Minneapolis,MN,USA,
4171‚Äì4186. https://doi.org/10.18653/v1/N19-1423
[24]SasoD≈æeroskiandBernard≈Ωenko.2004. Iscombiningclassifierswithstacking
better than selecting the best one? Machine learning 54, 3 (2004), 255‚Äì273.
[25]AndresErbsen,JadePhilipoom,JasonGross,RobertSloan,andAdamChlipala.
2019. Simple High-Level Code for Cryptographic Arithmetic ‚Äî With Proofs,
Without Compromises. In IEEE Symposium on Security and Privacy (S&P). 1202‚Äì
1219.https://doi.org/10.1109/SP.2019.00005[26]MichaelD.Ernst.2017. NaturalLanguageisaProgrammingLanguage:Applying
Natural Language Processing to Software Development. In Summit on Advances
inProgrammingLanguages(SNAPL),Vol.71.Dagstuhl,Germany,4:1‚Äì4:14. https:
//doi.org/10.4230/LIPIcs.SNAPL.2017.4
[27]Emily First and Yuriy Brun. 2022. Replication package for ‚ÄúDiversity-Driven
Automated Verification‚Äù. https://doi.org/10.5281/zenodo.5903318 .
[28]Emily First, Yuriy Brun, and Arjun Guha. 2020. TacTok: Semantics-Aware Proof
Synthesis. Proceedings of the ACM on Programming Languages (PACMPL) Object-
OrientedProgramming,Systems,Languages,andApplications(OOPSLA)issue 4
(November 2020), 231:1‚Äì231:31. https://doi.org/10.1145/3428299
[29] Galois [n.d.]. Galois, Inc. https://galois.com.
[30]ThibaultGauthier,CezaryKaliszyk,andJosefUrban.2017. TacticToe:Learningto
reason with HOL4 tactics. In International Conference on Logic for Programming,
Artificial Intelligence, and Reasoning (LPAR), Vol. 46. 125‚Äì143.
[31]Ian Goodfellow, Yoshua Bengio, and Aaron Courville. 2016. Deep Learning.M I T
Press.http://www.deeplearningbook.org.
[32]RonghuiGu,ZhongShao,HaoChen,XiongnanWu,JieungKim,VilhelmSj√∂berg,
andDavidCostanzo.2016. CertiKOS:AnExtensibleArchitectureforBuilding
CertifiedConcurrentOSKernels.In Proceedingsofthe12thUSENIXConference
on Operating Systems Design and Implementation. https://www.usenix.org/
conference/osdi16/technical-sessions/presentation/gu
[33]ArjunGuha,MarkReitblatt,andNateFoster.2013. MachineVerifiedNetwork
Controllers. In ACM SIGPLAN Conference on Programming Language Design
andImplementation(PLDI) .Seattle,WA,USA. https://doi.org/10.1145/2491956.
2462178
[34]Jesse Michael Han, Jason Rute, Yuhuai Wu, Edward W Ayers, and Stanislas Polu.
2021. Proof Artifact Co-training for Theorem Proving with Language Models.
CoRR(2021).https://arxiv.org/abs/2102.06203
[35]Mark Harman. 2007. The Current State and Future of Search Based Software
Engineering.In ACM/IEEEInternationalConferenceonSoftwareEngineering(ICSE).
342‚Äì357. https://doi.org/10.1109/FOSE.2007.29
[36]John Harrison. 1996. HOL Light: A tutorial introduction. In International Confer-
ence on Formal Methods in Computer-Aided Design (FMCAD). Palo Alto, CA, USA,
265‚Äì269. https://doi.org/10.1007/BFb0031814
[37]Vincent J. Hellendoorn, Premkumar T. Devanbu, and Mohammad Amin Alipour.
2018. On thenaturalness ofproofs. In ACMJoint Meetingon European Software
EngineeringConferenceandSymposiumontheFoundationsofSoftwareEngineering
(ESEC/FSE) New Ideas and Emerging Results track. Orlando, FL, USA, 724‚Äì728.
[38]J√≥nathan Heras and Ekaterina Komendantskaya. 2014. Recycling proof patterns
in Coq: Case studies. Mathematics in Computer Science 8, 1 (2014), 99‚Äì116.
https://doi.org/10.1007/s11786-014-0173-1
[39]AbramHindle,EarlT.Barr,MarkGabel,ZhendongSu,andPremkumarDevanbu.
2016. OntheNaturalnessofSoftware. Communicationsofthe ACM(CACM) 59,
5 (April 2016), 122‚Äì131. https://doi.org/10.1145/2902362
[40]AbramHindle,EarlTBarr,ZhendongSu,MarkGabel,andPremkumarDevanbu.
2012. On the naturalness of software. In Proceedings of the 34th International
Conference on Software Engineering (ICSE). 837‚Äì847. https://doi.org/10.1109/
ICSE.2012.6227135
[41]DanielHuang,PrafullaDhariwal,DawnSong,andIlyaSutskever.2018. GamePad:
A Learning Environment for Theorem Proving. CoRR(2018).https://arxiv.org/
abs/1806.00608
[42]Atalay ƒ∞leri, Tej Chajed, Adam Chlipala, M. Frans Kaashoek, and Nickolai Zel-
dovich.2018. ProvingConfidentialityinaFileSystemUsingDiskSec.In USENIX
SymposiumonOperatingSystemsDesignandImplementation(OSDI).Carlsbad,
CA, 323‚Äì338. https://www.usenix.org/conference/osdi18/presentation/ileri
[43]Geoffrey Irving, Christian Szegedy, Alexander A Alemi, Niklas E√©n, Fran√ßois
Chollet, and Josef Urban. 2016. Deepmath-deep sequence models for premise se-
lection.In AdvancesinNeuralInformationProcessingSystems(NeurIPS).Barcelona,
Spain, 2235‚Äì2243. https://papers.nips.cc/paper/6280-deepmath-deep-sequence-
models-for-premise-selection
[44]Kevin Jacobs and Benjamin Beurdouche. 2020. Performance Im-provements via Formally-Verified Cryptography in Firefox. https:
//blog.mozilla.org/security/2020/07/06/performance-improvements-via-
formally-verified-cryptography-in-firefox/.
[45]DongseokJang,ZacharyTatlock,andSorinLerner.2012. EstablishingBrowser
Security Guarantees Through Formal Shim Verification. In USENIX Security
Symposium(USENIXSecurity).Bellevue,WA,USA,113‚Äì128. https://www.usenix.
org/conference/usenixsecurity12/technical-sessions/presentation/jang
[46]Yalin Ke, Kathryn T. Stolee, Claire Le Goues, and Yuriy Brun. 2015. RepairingPrograms with Semantic Code Search. In Proceedings of the 30th IEEE/ACM
InternationalConferenceonAutomatedSoftwareEngineering(ASE) (9‚Äì13).Lincoln,
NE, USA, 295‚Äì306. https://doi.org/10.1109/ASE.2015.60
[47]EkaterinaKomendantskaya,J√≥nathanHeras,andGudmundGrov.2012. Machine
learning in proof general: Interfacing interfaces. In International Workshop on
User Interfaces for Theorem Provers (UITP), Vol. 118. Bremen, Germany. https:
//doi.org/10.4204/EPTCS.118.2
[48]Leonidas Lampropoulos, Zoe Paraskevopoulou, and Benjamin C. Pierce. 2017.Generating Good Generators for Inductive Relations. Proceedings of the ACM
760
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:18:33 UTC from IEEE Xplore.  Restrictions apply. Diversity-Driven Automated Formal Verification ICSE ‚Äô22, May 21‚Äì29, 2022, Pittsburgh, PA, USA
on Programming Languages (PACMPL) 2, POPL (Dec. 2017), 45:1‚Äì45:30. https:
//doi.org/10.1145/3158133
[49]K.RustanM.Leino.2010. Dafny:Anautomaticprogramverifierforfunctional
correctness. In International Conference on Logic for Programming Artificial Intel-
ligenceandReasoning(LPAR) .Dakar,Senegal. https://doi.org/10.1007/978-3-642-
17511-4_20
[50]XavierLeroy.2009. Formalverificationofarealisticcompiler. Communicationsof
the ACM (CACM) 52, 7 (2009), 107‚Äì115. https://doi.org/10.1145/1538788.1538814
[51]Zhaoyu Li, Binghong Chen,and Xujie Si. 2021. Graph Contrastive Pre-training
forEffectiveTheoremReasoning.In InternationalConferenceonMachineLearning
(ICML), Vol. PLMR 139. http://arxiv.org/abs/2108.10821
[52]Shih-Wei Lin and Shih-Chieh Chen. 2012. Parameter determination and feature
selection for C4.5 algorithm using scatter search approach. Soft Computing 16, 1
(2012), 63‚Äì75.
[53] Laurent Mauborgne.2004. Astr√âe:Verificationof AbsenceofRuntime Error.In
BuildingtheInformationSociety .385‚Äì392. https://doi.org/10.1007/978-1-4020-
8157-6_30
[54]Jes√∫sMaudes,JuanJRodr√≠guez,andC√©sarGarc√≠a-Osorio.2009. Disturbingneigh-
bors diversity for decision forests. In Applications of supervised and unsupervised
ensemble methods. Springer, 113‚Äì133.
[55]ChristophC.Michael,GaryMcGraw,andMichaelA.Schatz.2001. Generating
SoftwareTestDatabyEvolution. IEEETransactionsonSoftwareEngineering(TSE)
27, 12 (Dec. 2001), 1085‚Äì1110. https://doi.org/10.1109/32.988709
[56]Tom√°≈° Mikolov, Martin Karafi√°t, Luk√°≈° Burget, Jan ƒåernock `y, and Sanjeev Khu-
danpur. 2010. Recurrent Neural Network Based Language Model. In Annual Con-
ferenceoftheInternational SpeechCommunicationAssociation(INTERSPEECH).
Makuhari, Chiba, Japan. https://doi.org/10.1109/IALP.2016.7875937
[57]Greg Morrisett, Gang Tan, Joseph Tassarotti, Jean-Baptiste Tristan, and Edward
Gan.2012. RockSalt:Better,Faster,StrongerSFIforthex86.In ACMSIGPLAN
ConferenceonProgrammingLanguageDesignandImplementation(PLDI).Beijing,
China.https://doi.org/10.1145/2345156.2254111
[58]ManishMotwani,MauricioSoto,YuriyBrun,Ren√©Just,andClaireLeGoues.2021.
Quality of Automated Program Repair on Real-World Defects. IEEE Transactions
on Software Engineering (TSE) (2021).https://doi.org/10.1109/TSE.2020.2998785
DOI: 10.1109/TSE.2020.2998785.
[59]TobyMurray,DanielMatichuk,MatthewBrassil,PeterGammie,TimothyBourke,
SeanSeefried,CoreyLewis,XinGao,andGerwinKlein.2013. seL4:Fromgeneral
purpose to a proof of information flow enforcement. In IEEE Symposium on
Security and Privacy (S&P). San Francisco, CA, USA, 415‚Äì429.
[60]David F. Nettleton, Albert Orriols-Puig, and Albert Fornells. 2010. A study ofthe effect of different types of noise on the precision of supervised learning
techniques. Artificial IntelligenceReview 33(2010), 275‚Äì306. https://doi.org/10.
1007/s10462-010-9156-z
[61]TobiasNipkow,LawrenceCPaulson,andMarkusWenzel.2002. Isabelle/HOL:
A proof assistant for higher-order logic. Vol. 2283. Springer Science & Business
Media.
[62]Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, ChristopherClark, Kenton Lee, and Luke Zettlemoyer. 2018. Deep Contextualized Word
Representations. In Conference ofthe North AmericanChapter ofthe Association
forComputationalLinguistics:HumanLanguageTechnologies(NAACL-HLT) ,Vol.1.
AssociationforComputationalLinguistics,NewOrleans,LA,USA,2227‚Äì2237.
https://doi.org/10.18653/v1/N18-1202
[63]Stanislas Polu and Ilya Sutskever. 2020. Generative language modeling for auto-
mated theorem proving. CoRR(2020).https://arxiv.org/abs/2009.03393
[64]Baishakhi Ray, Vincent Hellendoorn, Saheel Godhane, Zhaopeng Tu, Alberto
Bacchelli, and Premkumar Devanbu. 2016. On the naturalness of buggy code. In
IEEE/ACM 38th International Conference on Software Engineering (ICSE). Austin,
TX, USA, 428‚Äì439. https://doi.org/10.1145/2884781.2884848
[65] Talia Ringer. 2021. Proof Repair. Ph.D. Dissertation. University of Washington.
[66]TaliaRinger,RanDairPorter,NathanielYazdani,JohnLeo,andDanGrossman.
2021. Proof Repair Across Type Equivalences. In ACM SIGPLAN International
Conference on Programming Language Design and Implementation (PLDI) (20‚Äì26).
112‚Äì127. https://doi.org/10.1145/3453483.3454033
[67]TaliaRinger,NathanielYazdani,JohnLeo,andDanGrossman.2018. Adapting
proof automation to adapt proofs. In ACM SIGPLAN International Conference
onCertifiedProgramsandProofs(CPP).LosAngeles,CA,USA,115‚Äì129. https:
//doi.org/10.1145/3167094
[68]Omer Sagi and Lior Rokach. 2018. Ensemble learning: A survey. Wiley Interdisci-
plinary Reviews: Data Mining and Knowledge Discovery 8, 4 (2018), e1249.
[69]Alex Sanchez-Stern, Yousef Alhessi, Lawrence Saul, and Sorin Lerner. 2020. Gen-
erating correctness proofs with neural networks. In ACM SIGPLAN International
Workshop on Machine Learning and Programming Languages (MAPL). 1‚Äì10.
[70]OlafSeng,JohannesStammel,andDavidBurkhart.2006. Search-baseddetermina-
tion of refactorings for improving the class structure of object-oriented systems.
InConferenceonGeneticandEvolutionaryComputation(GECCO).Seattle,WA,
USA, 1909‚Äì1916. https://doi.org/10.1145/1143997.1144315
[71]Ilya Sergey, James R. Wilcox, and Zachary Tatlock. 2017. Programming andProving with Distributed Protocols. Proceedings of the ACM on ProgrammingLanguages(PACMPL) 2,POPL(Dec.2017),28:1‚Äì28:30. https://doi.org/10.1145/
3158116
[72]KonradSlindandMichaelNorrish.2008. AbriefoverviewofHOL4.In Interna-
tional Conference on Theorem Proving in Higher Order Logics (TPHOLs). Montreal,
QC, Canada, 28‚Äì32. https://doi.org/10.1007/978-3-540-71067-7_6
[73]Edward K. Smith, Earl Barr, Claire Le Goues, and Yuriy Brun. 2015. Is theCure Worse than the Disease? Overfitting in Automated Program Repair. In
JointMeetingoftheEuropeanSoftwareEngineeringConferenceandACMSIGSOFTSymposiumontheFoundationsofSoftwareEngineering(ESEC/FSE) (2‚Äì4).Bergamo,
Italy, 532‚Äì543. https://doi.org/10.1145/2786805.2786825
[74]RichardSocher,AlexPerelygin,JeanWu,JasonChuang,ChristopherDManning,
AndrewNg,andChristopherPotts.2013. Recursivedeepmodelsforsemantic
compositionality over a sentiment treebank. In Conference on Empirical Methods
inNaturalLanguageProcessing(EMNLP).1631‚Äì1642. https://www.aclweb.org/
anthology/D13-1170
[75]Jean Souyris. 2014. Industrial Use of CompCert on a Safety-Critical Software
Product. http://projects.laas.fr/IFSE/FMF/J3/slides/P05_Jean_Souyiris.pdf .
[76]Martin Sundermeyer, Ralf Schl√ºter, and Hermann Ney. 2012. LSTM NeuralNetworks for Language Modeling. In Annual Conference of the International
SpeechCommunicationAssociation(INTERSPEECH).Portland,OR,USA. https:
//doi.org/10.21437/Interspeech.2012-65
[77]Nikhil Swamy, CƒÉtƒÉlin Hri≈£cu, Chantal Keller, Aseem Rastogi, Antoine Delignat-
Lavaud,SimonForest,KarthikeyanBhargavan,C√©dricFournet,Pierre-YvesStrub,
MarkulfKohlweiss,Jean-KarimZinzindohoue,andSantiagoZanella-B√©guelin.
2016. Dependent types and multi-monadic effects in F*.I nACM SIGPLAN-
SIGACTSymposiumonPrinciples ofProgrammingLanguages(POPL),Vol. 51.St.
Petersburg, FL, USA, 256‚Äì270. https://doi.org/10.1145/2914770.2837655
[78]Kai Sheng Tai, Richard Socher, and Christopher D. Manning. 2015. Improved
Semantic Representations From Tree-Structured Long Short-Term Memory Net-
works. In Annual Meeting of the Association for Computational Linguistics (ACL),
Vol. 1. Beijing, China, 1556‚Äì1566. https://doi.org/10.3115/v1/P15-1150
[79] The Coq Development Team. 2017. Coq, v.8.7. https://coq.inria.fr.
[80]Andrzej Trybulec and Howard A Blair. 1985. Computer Assisted Reasoning
withMIZAR.In InternationalJointConferencesonArtificialIntelligence(IJCAI),
Vol. 85. Los Angeles, CA, USA, 26‚Äì28. https://www.ijcai.org/Proceedings/85-
1/Papers/006.pdf
[81]ZhaopengTu,ZhendongSu,andPremkumarDevanbu.2014. OntheLocalnessof
Software.In ACMSIGSOFTInternationalSymposiumonFoundations ofSoftware
Engineering (FSE). Hong Kong, China, 269‚Äì280. https://doi.org/10.1145/2635868.
2635875
[82]Brendan van Rooyen, Aditya Menon, and Robert C Williamson. 2015.Learning with Symmetric Label Noise: The Importance of Being Un-hinged. In Advances in Neural Information Processing Systems, Vol. 28.
Curran Associates, Inc. https://proceedings.neurips.cc/paper/2015/file/
45c48cce2e2d7fbdea1afc51c7c6ad26-Paper.pdf
[83]Niki Vazou. 2016. Liquid Haskell: Haskell as a theorem prover. Ph.D. Dissertation.
University of California, San Diego.
[84]Philip Wadler, Wen Kokke, and Jeremy G. Siek. 2020. Programming Language
Foundations in Agda. http://plfa.inf.ed.ac.uk/20.07/
[85]KristenR.Walcott,MaryLouSoffa,GregoryM.Kapfhammer,andRobertS.Roos.2006. Time-awaretestsuiteprioritization.In InternationalSymposiumonSoftware
Testing and Analysis (ISSTA). Portland, ME, USA, 1‚Äì12. https://doi.org/10.1145/
1146238.1146240
[86]Mingzhe Wang, Yihe Tang, Jian Wang, and Jia Deng. 2017. Premise se-lection for theorem proving by deep graph embedding. In Advances in
Neural Information Processing Systems (NeurIPS) . Long Beach, CA, USA,
2786‚Äì2796. https://papers.nips.cc/paper/6871-premise-selection-for-theorem-
proving-by-deep-graph-embedding
[87]Westley Weimer, ThanhVu Nguyen, Claire Le Goues, and Stephanie Forrest.
2009. Automaticallyfindingpatchesusinggeneticprogramming.In ACM/IEEE
International Conference on Software Engineering (ICSE) . Vancouver, BC, Canada,
364‚Äì374. https://doi.org/10.1109/ICSE.2009.5070536
[88]James R. Wilcox, Doug Woos, Pavel Panchekha, Zachary Tatlock, Xi Wang,
MichaelD.Ernst,andThomasAnderson.2015. Verdi:Aframeworkforimple-
mentingandformallyverifyingdistributedsystems.In ACMSIGPLANConference
onProgrammingLanguageDesignandImplementation(PLDI).Portland,OR,USA,
357‚Äì368.
[89]Minchao Wu, Michael Norrish, Christian Walder, and Amir Dezfouli. 2021. Tac-
ticZero: Learning to Prove Theorems from Scratch with Deep Reinforcement
Learning. CoRRabs/2102.09756(2021). http://arxiv.org/abs/2102.09756
[90]Kaiyu Yang and Jia Deng. 2019. Learning to prove theorems via interacting with
proofassistants.In InternationalConferenceonMachineLearning(ICML).Long
Beach, CA, USA. http://proceedings.mlr.press/v97/yang19a/yang19a.pdf
[91]PengchengYinandGrahamNeubig.2017. ASyntacticNeuralModelforGeneral-PurposeCodeGeneration.In AnnualMeetingoftheAssociationforComputational
Linguistics (ACL) , Vol. 1. Vancouver, BC, Canada, 440‚Äì450. https://doi.org/10.
18653/v1/P17-1041
761
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:18:33 UTC from IEEE Xplore.  Restrictions apply. 