RoPGen: Towards Robust Code Authorship Attribution via
Automatic Coding Style Transformation
Zhen Li∗†, Guenevere (Qian) Chen∗, Chen Chen/sharp, Yayi Zou§, Shouhuai Xu‡
∗University of Texas at San Antonio, USA
†Huazhong University of Science and Technology, China
/sharpCenter for Research in Computer Vision, University of Central Florida, USA
§Northeastern University, China
‡University of Colorado Colorado Springs, USA
zh_li@hust.edu.cn,guenevereqian.chen@utsa.edu,chen.chen@crcv.ucf.edu
20185258@stu.neu.edu.cn,sxu@uccs.edu
ABSTRACT
Sourcecodeauthorshipattributionisanimportantproblemoften
encountered in applications such as software forensics, bug fixing,
and software quality analysis. Recent studies show that current
sourcecodeauthorshipattributionmethodscanbecompromised
by attackers exploiting adversarial examples and coding style ma-
nipulation. This calls for robustsolutions to the problem of code
authorship attribution. In this paper, we initiate the study on mak-
ing Deep Learning (DL)-based code authorship attribution robust.
We propose an innovative framework called Robust coding style
PatternsGeneration(RoPGen), which essentially learns authors’
uniquecodingstylepatternsthatarehardforattackerstomanip-
ulate or imitate. The key idea is to combine data augmentation
andgradientaugmentation attheadversarialtrainingphase.This
effectivelyincreasesthediversityoftrainingexamples,generates
meaningfulperturbationstogradientsofdeepneuralnetworks,and
learns diversified representations of coding styles. We evaluate the
effectivenessof RoPGenusingfour datasetsofprograms written
inC,C++,andJava.ExperimentalresultsshowthatRoPGencan
significantly improve the robustness of DL-based code authorship
attribution,byrespectivelyreducing22.8%and41.0%ofthesuccess
rate of targeted and untargeted attacks on average.
CCS CONCEPTS
•Security and privacy →Software security engineering.
KEYWORDS
Authorship attribution, source code, coding style, robustness, deep
learning
ACM Reference Format:
ZhenLi∗†,Guenevere(Qian)Chen∗,ChenChen/sharp,YayiZou§,ShouhuaiXu‡.
2022.RoPGen:TowardsRobustCodeAuthorshipAttributionviaAutomatic
Coding Style Transformation. In 44th International Conference on Software
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
© 2022 Association for Computing Machinery.
ACM ISBN 978-1-4503-9221-1/22/05...$15.00
https://doi.org/10.1145/3510003.3510181Engineering (ICSE ’22), May 21–29, 2022, Pittsburgh, PA, USA. ACM, New
York, NY, USA, 13 pages. https://doi.org/10.1145/3510003.3510181
1 INTRODUCTION
Softwareforensicsanalysisaimstodeterminewhetherornotthere
issoftwareintellectualpropertyinfringementortheftassociated
with some given software code. One useful technique for this pur-
poseissourcecodeauthorshipattribution[ 13,27],whichaimsto
identify the author(s) of a given software program [ 14,25]. This
techniquehasbeenusedformanyapplications,suchascodepla-
giarismdetection,criminalprosecution(e.g.,identifyingtheauthor
of a piece of malicious code), corporate litigation (e.g., determining
whether a piece of code is written by a former employee who vio-
latesanynon-competeclauseofcontract),bugfixing[ 8,38],and
software quality analysis [46].
Therearemultipleapproachestosourcecodeauthorshipattribu-
tion, including statistical analysis [ 18,26], similarity measurement
[12,21,27],and machinelearning[ 1,4,7,11,14,24,36,47,51].Re-
centstudiesshowthatcurrentsourcecodeauthorshipidentification
methodscanbecompromisedbytwoclassesofattacks:theones
exploiting adversarial examples [31,37] and the ones exploiting
codingstyleimitation/hiding [34,35,42].Forinstance,leveraging
adversarial examples [ 1,24] can cause misattribution of more than
99% software programs in the GoogleCodeJam competition dataset
[37]; whereas leveraging the coding style hiding [ 12,18,24] can
cause misattribution of all of the software programs in a GitHubdataset [
34]. The state-of-the-art is that current code authorship
attributionmethodsarevulnerabletotheseattacks.Thiscallsforre-
search on enhancing the robustness of code authorship attribution
methods against attacks.
Ourcontributions .Inthispaper,weinitiatethestudyonenhanc-
ingtherobustnessofDeepLearning(DL)-basedcodeauthorship
attribution methods. We choose to focus on this family of methods
because they can automatically learn coding style patterns (i.e.,
avoiding laborious involvement of domain experts) and are verypromising for real-world adoption [
1,4,7,11,47,51]. Effectively,
wetacklethefollowingproblem: Howcanweenhancetherobustness
of DL-based code authorship attribution against attacks? For this
purpose, we need to address two challenges.
Thefirstchallengeistoconsidermoreattacksthanwhathave
beeninvestigatedintheliterature;otherwise,theresultingdefenses
19062022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:52:10 UTC from IEEE Xplore.  Restrictions apply. ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Zhen Li∗†, Guenevere (Qian) Chen∗, Chen Chen/sharp, Yayi Zou§, Shouhuai Xu‡
wouldbespecifictotheknownattacksandwillsoonbecomeob-
solete when new attacks are introduced. This is especially true be-
causetheknownattacksaregearedtowardsdomainexpert-defined
features[ 34],whichmaynotbesustainableandwouldsooneror
later need to be replaced by automatic feature learning. This in-
spiresustoexplorenew/unknownattackssothatwecandesign
defensesthatcanenhancerobustnessagainstbothknownandnew
attacks. For this purpose, we introduce two new attacks which ex-
ploitautomaticcodingstyleimitationandhiding;theseattackscan
be applied againstboth DL-based codeauthorship attribution and
other methods. The new attacks leverage our systematization of
semantics-preservingcodingstyleattributesandtransformations,
whichmaybeofindependentvalue.Theattacksareofblack-box
type because they do not need to know the target code authorship
attributionmethods;instead,theyimitatethetargetauthor’scoding
style or hide the true author’s.
The second challenge is to design effective defenses against the
known and new attacks mentioned above, while accommodating a
range of neural network structures (rather than a specific one). To
addressthischallenge,itwouldbenaturaltoleveragetheideaof
adversarial training because it has been widely used in other set-
tings [9,33,40]. However, our experimental results show that such
adversarial training approaches applied in these settings [ 9,33,40]
cannot effectively mitigate the known and new attacks mentioned
above (as what will be described in Table 11 of Section 5.4). Thisprompts us to propose an innovative framework, called
Robust
coding style PatternsGeneration(RoPGen). The key idea is to incor-
poratedataaugmentation andgradientaugmentation tolearnrobust
codingstylepatternswhicharedifficultforattackerstomanipulate
or imitate. The role of data augmentation is to increase the amount
anddiversityofsoftwareprogramsfortrainingpurposes.Thisis
achievedbyaugmentingprogramsintwoways:(i)imitatingcoding
styles of other authors; and (ii) perturbing programs’ coding styles
to a small degree without changing their authorship. The role of
gradientaugmentation istolearnrobustDLmodelswithdiversified
representations by incurring perturbations to gradients of deep
neural networks. This is achieved as follows: at each training itera-
tion,wesamplemultiplesub-networkswithacertainfractionof
thenodesateachlayerofthenetwork;then,weusethesampled
sub-networkstoconstructthenetworkwithdiversifiedrepresen-
tations during the weights-sharing training process. The resulting
model learns robust coding style patterns which would be difficult
toexploit.Itisworthmentioningthatgradientaugmentationhas
been used as a regularization method to alleviate over-fitting of
deepneuralnetworksinimageclassification[ 50];wearethefirst
to use it for robustauthorship attribution.
To evaluate the effectiveness of RoPGen, we use four datasets
of programs written in C, C++, and Java, namely GCJ-C++ [ 37],
GitHub-Java[ 51],GitHub-C,and GCJ-Java.Amongthem, GCJ-C++
and GCJ-Java are two sets of programs written by authors whoparticipate in programming competitions for solving a given set
of problems; GitHub-Java and GitHub-C are two sets of real-world
programs written by different programmers for varying purposes;
GitHub-C and GCJ-Java are created for the purpose of the present
paper. Experimental results show that RoPGen can significantlyimprovetherobustnessofDL-basedcodeauthorshipattribution,
respectivelyreducingthesuccessrateoftargetedanduntargetedattacks by 22.8% and 41.0% on average. We have made the datasets
available at https://github.com/RoPGen/RoPGen . We will pub-
lish the source code of RoPGen on the same website.
Paper organization . We discuss the notion of coding styles in
Section2,introducetwonewattacksinSection3,describeRoPGen
in Section 4, present experimental results in Section 5, discuss
limitationsinSection6andrelatedpriorstudiesinSection7,and
conclude this paper in Section 8.
2 THE NOTION OF CODING STYLES
Theproblemofsourcecodeauthorshipattributionhastwovariants:
single-authorship attribution [ 1,2,4,7,11,12,14,18,21,24,26,27,
36,47,51] vs. multi-authorship attribution [ 3,17]. Since most stud-
ies focus on the former variant while the latter is little understood,
we focus on addressing the former variant.
Coding style attributes . The premise for achieving authorship
attribution is that each author has a unique coding style, which can
bedefinedbasedonfourtypesofattributesrelatedtoprograms’lay-
out, lexical, syntactic, and semantic information. Layout attributes
includecodeindentation,emptylines,brackets,andcomments[ 24].
Lexicalattributesdescribetokens(e.g.,identifier,keyword,operator,
and constant), the average length of variable names, the number
of variables, and the number of forloop statements [ 1,24]. Syn-
tacticattributesdescribeaprogram’s AbstractSyntaxTree (AST),
includingsyntacticconstructs(e.g.,unaryandternaryoperators)
andtreestructures(e.g.,frequencyofadjacentnodesandaverage
depthofASTnodetypes)[ 1,11,34].Semanticattributesdescribea
program’scontrolflowsanddataflows(e.g.,“ for”, “while”, “if,
else if”, “switch,case”, and execution order of statements) [ 34].
Sincecodingstylesandtheirattributesarerelatedtoprogram-
minglanguages,wefocusonC,C++,andJavaprogramsbecause
they are widely used, while leaving the treatment of other lan-
guages to future studies. Even for these specific programming lan-
guages,theircodingstyleattributesarescatteredintheliterature
[31,34,37,42].Thispromptsustosystematizeattributesaccording
to the following observations: (i) layout attributes can be easily
manipulatedbycodeformattingtools[ 37](e.g.,CodeBeautify[ 16]
andEditor Config[ 20]);(ii) thoseattributes,whosevalues cannot
beautomaticallymodifiedwithoutchangingaprogram’ssemantics,
wouldnotbeexploitedbyanattackerbecausetheymakeimitation
attacks hard to succeed; and (iii) those attributes, whose values
are rarely used (e.g., making programs unnecessarily complicated),
would not be exploited by animitation attacker. As highlighted in
Table1,theseobservationsleadto23codingstyleattributes,which
span across lexical, syntactic, and semantic information.
Leveraging coding style attributes as a starting point for ro-
bust authorship attribution . For this purpose, we need to con-
sidertwoissues.First,weconsider granularity ofcodingstyleat-
tributes, namely token vs. statement vs. basic block vs. function.
This is important because code transformations on coarse-grained
attributesmaydemandlargerdegreesofperturbationstoprograms.
•Token-levelattributes(#1-#5inTable1):Theydescribetheele-
ments in a program’s statements: identifier naming method (#1),
usageoftemporaryvariablenames(#2),usageofnon-temporary
local identifier names (#3), usage of global declarations (#4), and
1907
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:52:10 UTC from IEEE Xplore.  Restrictions apply. RoPGen: Towards Robust Code Authorship Attribution via Automatic Coding Style Transformation ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
Table 1: C, C++, and Java coding style attributes serving as a starting point for robust code authorship attribution
Granularity Attribute # Description Value Type Exhaustive? Language
Token1 Identifier naming methodCamelcase(e.g., myCount),Pascalcase(e.g., MyCount),wordsseparatedbyunderscores,
or identifiers starting with underscores.Lexical Yes C, C++, Java
2 Usage of temporary variable names Variable names defined in a compound statement of a function. Lexical No C, C++, Java
3Usage of non-temporary local identi-
fier namesVariable names defined in functions but not defined in compound statements, or user-defined function calls.Lexical No C, C++, Java
4 Usage of global declarations Global constants declared outside of functions. Lexical No C, C++
5 Access of array/pointer elements Use the form of array indexes or pointers, e.g., arr[i]and*(arr+i). Lexical Yes C, C++
Statement6 Location of defining local variablesLocalvariablesaredefinedatthebeginningofthevariablescope,oreachlocalvariableis defined when used for the first time.Syntactic Yes C, C++, Java
7 Locationofinitializinglocalvariables Localvariablesareinitializedanddefinedinsamestatements,orindifferentstatements. Syntactic Yes C, C++, Java
8Definition (and initialization) of mul-tiple variables with same types Multiple variables with same types are defined (and initialized) in a statement or inmultiple statements.Syntactic Yes C, C++, Java
9 Variable assignmentMultiplevariableassignmentsareinastatement(e.g., tmp=++i;)ormultiplestatements
(e.g., ++i; tmp=i;).Syntactic Yes C, C++, Java
10 Increment/decrement operationUse increment (or decrement) operator with different locations, e.g., (i) i++;(ii)++i;
(iii)i=i+1;(iv)i+=1;.Syntactic Yes C, C++, Java
11 User-defined data types Usetypedefto rename a data type or not. Syntactic No C, C++
12 Macros Use macros to replace constants and expressions or not. Syntactic No C, C++
13Included header files or importedclasses Header files included in C/C++ programs and classes imported in Java programs.Semantic No C, C++, Java
14 Usage of return statements Usereturn 0; to explicitly return success in mainfunction or not. Semantic Yes C, C++
15 Usage of namespaces Use namespace stdor not. Semantic Yes C++
16 Synchronization with stdio Enable or remove the synchronization of C++ streams and C streams. Semantic Yes C++
17 Stream redirection Usefreopento redirect predefined streams to specific files or not. Semantic Yes C, C++
18 Library function callsC++ library function calls (e.g., cin, cout) or corresponding C library function calls
with the same functionalities (e.g., scanf, printf).Semantic Yes C++
19 Memory allocationStatic array allocation (e.g., int arr[100];) or dynamic memory allocation (e.g., int
*arr=malloc(100*sizeof(int));).Semantic Yes C, C++
Basic block20 Loop structures Useforstructure or whilestructure. Semantic Yes C, C++, Java
21 Conditional structures Use conditional operator, if-else,o rswitch-case structure. Semantic Yes C, C++, Java
22 Compound ifstatementsUsealogicaloperatorinan ifcondition(e.g., if(a && b))orusemultiple ifconditions
(e.g., if(a){if(b){...}}).Semantic Yes C, C++, Java
Function 23 Usage of functionsThe maximum layer number of control statements and loops that are nested withineach other, or the number of lines of code in the function.Semantic No C, C++, Java
access of array/pointerelements (#5). For instance, attribute #2
oftheprogramshowninFigure1(a)isdescribedbytemporary
variable names case_it, st,ss,ans, pos, and i.
•Statement-level attributes (#6-#19 in Table 1): They describe the
locationofdefininglocalvariable(#6),thelocationofinitializing
local variables (#7), the definition (and initialization) of multiple
varialbles with same types (#8), variable assignment (#9), incre-
ment/decrementoperation(#10),user-defineddatatypes(#11),
macros (#12), included header files or imported classes (#13),
Usageofreturnstatements(#14),usageofnamespaces(#15),syn-
chronization with stdio (#16), stream redirection (#17), library
functioncalls(#18),andmemoryallocation(#19).Forinstance,
attribute #18 of the program shown in Figure 1(a) is described
by library functions cin(Line 7) and cout(Line 20).
•Basic block-level attributes (#20-#22 in Table 1): They describe
loopstructures(#20),conditionalstructures(#21),andcompound
ifstatements(#22).Forinstance,attribute#20oftheprogram
showninFigure1(a)isdescribedbytwo forstructures(Line4
and Line 13) and a whilestructure (Line 11).
•Function-level attribute (#23 in Table 1): At this granularity, cod-
ing styles describe the usage of functions, namely (i) the max-
imum number of layers of nested compound statements (e.g.,
control statements and loops) or (ii) the number of lines of code
inafunction.Forinstance,attribute#23oftheprogramshowninFigure1(a)isthemaximumnumberoflayersofnestedcompound
statements, which is 3 in this case (i.e., for-while-for).
Second, we propose distinguishing those coding style attributes
whose domains are exhaustive from those that are not; the term
“exhaustive” means that an attribute’s domain contains few values
(e.g., the kinds ofloop structures), and a domain is treatedas non-
exhaustive if its domain contains many values (e.g., the numberof possible variable names can be very large). This is importantbecause a non-exhaustive attribute would naturally demand more
perturbed examples for adversarial training purposes. As shownin Table 1, exhaustive attributes include attributes #1 and #5 atthe token-level granularity, #6-#10 and #14-#19 at the statement-
levelgranularity,and#20-#22atthebasicblock-levelgranularity.
For instance, #20 (i.e., loop structures) has only two values in C,
C++,andJavaprograms: forandwhile.Non-exhaustiveattributes
include attributes #2-#4 at the token level, #11-#13 at the statement
level,and#23atthefunctionlevel.Forinstance,#2(i.e.,usageof
temporaryvariablenames)isnon-exhaustivebecausetemporary
variablescanhavearbitrarynames.Fortheprogramdescribedin
Figure 1(a), the value of attribute #2 includes case_it,st,ss,ans,
pos, and i.
3 TWO NEW ATTACKS
Weinvestigatetwonewattacksagainstcodeauthorshipattribution,
one is coding style imitation attack and the other is coding style
hidingattack. These attacks are new and can make our defense
widely applicable because they are waged automatically and are
wagedagainstbothDL-basedcodeauthorshipattributionandother
methods.Incontrast,attackspresentedintheliteraturearemanual
[42], semi-automatic [ 35], or automatic but not applicable to DL-
based code authorship attribution [34].
Denote by A={A1,...,Aδ}a finite set of authors and by M
thecodeauthorshipattributionmethodinquestion.Theattacker
has black-box access to M, meaning: (i) the attacker can query any
programptoMwhichreturnstheauthorof porM(p);and(ii)how
Mis obtained is unknown to the attacker. In the threat model, the
attacker manipulates pwritten by As(e.g., Alice) into a variant
programp/primevia semantics-preserving code transformations, where
p/prime/nequalp. The attacker’s goal is:
1908
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:52:10 UTC from IEEE Xplore.  Restrictions apply. ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Zhen Li∗†, Guenevere (Qian) Chen∗, Chen Chen/sharp, Yayi Zou§, Shouhuai Xu‡
    
     …
1   void split_main(int *test, String *tmp) {
2            auto proxmsk = test + 1; 
3            while (proxmsk < tmp.length()) {
4                  tmp[proxmsk] = '9';
5                  ++proxmsk;
6            }
7  }
8  int main() {
9    int case_num;
10  cin >> case_num;
11  int ps = 0;
12  while (ps < case_num) {
13      ++ ps;
14      String tmp;
15      scanf(“%s”, &tmp);
16      stringstream spd;
17      long long ls;
18      int test  = get_wrong_pos(tmp );
19      while (test  != -1) {
20            tmp[test] = tmp[test] - 1;
21            split_main(&test, &tmp);
22            test = get_wrong_pos( tmp);
23      }
24      spd << tmp;
25      spd >> ls;
26      printf(“Case #%d:%lld\n ”, ps, ans);
27    }28  }
(a) Input (e) IA.Step IV: Conducting code 
transformations to imitate 
target author At    …
1  int main() {2    int case_num;
3    cin >> case_num;
4    for (int case_it = 0; case_it < case_num;) {
5        ++case_it;
6        String st;7        cin >> st;
8        stringstream ss;
9        long long ans;
10      int pos = get_wrong_pos(st);
11      while (pos != -1) {12            st[pos] = st[pos] - 1;
13            for (auto i = pos + 1; i < st.length(); ++i) {
14                  st[i] = '9';15            }
16            pos = get_wrong_pos(st);
17      }
18      ss << st;
19      ss >> ans;20      cout << "Case #" << case_it << ": " << ans
              << endl;
21   } 
22 }A set R of programs 
authored by target 
author At
(b) IA.Step I: Extracting 
coding style attribute 
values from programs #1:   {words separated by
           underscores}
#2:   {case_it, st, ss, ans, pos, i}#3:   {case_num}
#5:   {use the form of array 
          indexes}
#6:   {local variables are defined 
          when they are used for the           first time}
#10: {increment operation is used
          before the variable}
#18: {cin, cout}
#20: {for, while}#23: {the maximum layer number: 
          3}#1:   ...#2:   ...
#3:   ...
 ...
(c) IA.Step II: Synthesizing 
coding style attribute 
values extracted from the 
programs in R#1:   {words separated by underscores, 
          camel case}
#2:   {ps, tmp, spd, ls, test, proxmsk, ...}#3:   {totalTest, case_num, my_count,
          ...} 
#5:   {use the form of array indexes}
#6:   {local variables are defined when
          they are used for the first  time}#9:   {multiple variable assignments are
          in a statement}
#18: {scanf, printf}#20: {while}
#21: {use the conditional operator}
#23: {the maximum layer number: 2}
(d) IA.Step III: 
Identifying coding style 
attributes in p for code 
transformation#2:   {case_it, st, ss, ans, pos, i}
#18: {cin, cout}
#20: {for}
#23: {the maximum layer
          number: 3}Program p Program p’ 
Figure1:AnexampleshowinggenerationofC++program p/primefortargetedattack(modifiedcodeishighlightedinredanditalics)
•In atargetedattack with target author At(e.g., Bob) where t/nequals,
the attacker’s goal is to make Mmisattribute p/primetoAt, namely
M(p/prime)=Atwhilenotingthat Mwouldcorrectlyattribute ptoAs,
namelyM(p)=As.Thatis,theattackerattemptstomanipulatea
programwrittenbyAliceintoasemantically-equivalentprogram
which will be misattributed to Bob.
•Inanuntargeted attack,theattacker’sgoalistomake Mmisat-
tributep/primetoanyotherauthor AuthanAs,namely M(p/prime)=Au
whereAu∈A−{As}.
3.1 Automatic Coding Style Imitation Attack
In this attack, the attacker, As∈Ain typical use cases, takes as
input: (i) the set Aof authors; (ii) a program pauthored by As;
and (iii) a set Rof programs authored by target author At∈A
wheret/nequals. The goal of Asis toautomatically transform program
pto program p/primesuch that p/primepreserves p’s functionality and M
misattributes p/primetoAt. The attack proceeds as follows.
•IA.StepI: Extractingcodingstyleattributevaluesfrompro-
gram pand the programs in R(authored by target author
At).Attacker Asgeneratesthecodingstylesofprogram pand
all programs in Rby leveraging the 23 attributes mentioned
above (Table 1). As a running example, Figure 1(a) shows As’s
programpandFigure1(b)showsthevaluesofthe9applicable
attributes of p. For instance, in order to obtain the value of at-
tribute #1 (i.e., identifier naming method), Ascan identify all of
the user-defined variable and function call names used in p(i.e.,
case_num ,case_it,st,ss,ans,pos,get_wrong_pos , and iin
this case). Then, Ascan obtain the identifier naming method for
eachuser-definedvariableandfunctioncallname.Specifically,
the value of attribute #1 corresponding to case_num ,case_it,
andget_wrong_pos is “words separated by underscores”; the
othervariableandfunctioncallnames(i.e., st,ss,ans,pos,and
i)cannotberepresentedbyattribute#1becausetheseidentifiers
have no naming rules. Therefore, the value of attribute #1 of
programpis “words separated by underscores”.•IA.StepII: Synthesizingcodingstyleattributevaluesextracted
fromtheprogramsin R.Havingextractedattributevaluesfrom
individual programs in R, we need to synthesize them into a sin-
glevalueforeachattributetoobtaintargetauthor At’scoding
style.Inthecaseanattributeisnumeric,weproposeusingthe
average of an attribute’s values (as observed from the programs
inR) to represent At’s coding style with respect to the attribute.
Inthecaseanattributeisnon-numeric,weproposeusingtheor-
deredsetofanattribute’sdistinctvaluesinthedescendingorder
of their frequency to represent At’s coding style with respect
to the attribute. As a running example, Figure 1(c) illustrates
At’s coding style attributes synthesized from the programs in
R.Forinstance,thesynthesizedvalueofnumericattribute#23
(usage of function) is 2, which is the average of values observed
from the programs in R. Non-numeric attribute #1 (identifier
naming method) takes two distinct values: “words separated by
underscores” (as observed from most programs in R) and “camel
case” (as observed from the other programs in R); the synthe-
sizedvalueofattribute#1istheorderedset“{wordsseparatedby
underscores, camel case}” as the former has a higher frequency.
•IA.StepIII: Identifyingcodingstyleattributesin pforcode
transformation. Having obtained attacker As’s coding style at-
tributesfromprogram p(IA.StepI)andtargetauthor At’scoding
style attributes from R(IA.Step II), we identify the discrepant
attributes,namelytheattributesthattakedifferentvalueswith
respectto AsandAt,ascandidatesforcodetransformationto
makepimitateAt’scodingstyle.Foranumericattribute,discrep-
ancy means that the difference between its value derived from p
anditsvaluederivedfrom Risaboveagiventhreshold τ.Fora
non-numeric attribute, discrepancy means that its value derived
frompisnotasubsetofitsvaluederivedfrom R.Asarunning
example, Figure 1 (b) and (c) show that the value of numeric
attribute #23 derived from pis discrepant with the value derived
fromRbecause their difference, 1, is larger than the threshold
τ=0;thevaluesofnon-numericattributes#2,#18,and#20de-
rivedfrom parediscrepantwiththeircounterpartsderivedfrom
Rbecause the former is not a subset of the latter, respectively.
1909
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:52:10 UTC from IEEE Xplore.  Restrictions apply. RoPGen: Towards Robust Code Authorship Attribution via Automatic Coding Style Transformation ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
As shown in Figure 1 (d), these four discrepant attributes are
candidates for code transformations to imitate At’s coding style.
•IA.StepIV: Conductingcodetransformationstoimitatetar-
getauthor At.Thisstepistochangethevaluesofthediscrepant
attributes identified in IA.Step III to imitate target author At,
leading to a transformed (or manipulated) program p/primewhich
preserves p’s functionality. We conduct code transformations on
individualprogramfilesbasedon srcML[44],whichcanpreserve
programfunctionalitieswhilesupportingmultipleprogramming
languages. As a running example, Figure 1 (e) shows the ma-
nipulated program p/primeobtained by sequentially transforming the
valuesofattributes#2,#18,#20,and#23derivedfromprogram p,
whileassuringthateachtransformationpreserves thefunction-
ality of the program in question. Take attribute #23 for example.
Themainfunction(Line1inFigure1(a))issplitintotwofunc-
tions main(Line 8 in Figure 1 (e)) and split_main (Line 1 in
Figure 1 (e)).
3.2 Automatic Coding Style Hiding Attack
In this attack, attacker As∈Atakes as input the set Aof authors
andaprogram pauthoredby As.Asmentionedabove,thegoalof As
istomanipulateprogram ptoanotherprogram p/prime,whichpreserves
p’s functionality but will not be attributed to As. To achieve this,
we propose leveraging the preceding imitation attacks by choosing
a target author with the highest misattribution probability. Details
follow.
•HA.Step I: Extracting coding style attribute values from
program p.This is the same as IA.Step I.
•HA.Step II: Obtaining the coding style of each author Ad.
ForeachAd∈A− {As},wegenerate Ad’scodingstyleasIA.Step
II by treating Adas the target author.
•HA.StepIII: Identifyingthecodingstyleattributesin pfor
each Ad.Foreachauthor Ad∈A−{As},weidentifythecoding
style attributes extracted from pthat are discrepant with Ad’s.
ThisisthesameasIA.StepIIIbytreating Adasthetargetauthor.
•HA.Step IV: Selecting author Aufor transformation. For
eachAd∈A−{As}, we compute the number of lines of code
that need to be changed to make p/primeimitateAd’s coding style.
Changingmorelinesofcodein p(e.g.,involvingattributes#11,
#12, and #13) may make pretain fewer original coding styles
and thus make an untargeted attack successful with a higher
misattributionprobability.Weselectauthor Au∈A−{As}with
the highest misattribution probability as the target author.
•HA.StepV: Conductingcodetransformationstoimitateau-
thorAu.This is the same as IA.Step IV with target author Au.
4 THE ROPGEN FRAMEWORK
InDL-basedauthorshipattribution,theinputatthetrainingphaseis
asetofηtrainingprogramswithlabels,denotedby P={pk,qk}η
k=1,
wherepkis a training program and qkis its label (i.e., author).
The output is a DL model M. Given a finite set of authors A=
{A1,...,Aδ}andaprogram pkauthoredby As∈A,letPr(M,pk,As)
denotetheprobabilitythat Mpredictsthat pkisauthoredby As.The
attacker manipulates pkto a different program, denoted by p/prime
k.A s
discussedabove,an imitation attackersucceedswhen Pr(M,p/prime
k,At)=max1≤z≤δPr(M,p/prime
k,Az)for a given t/nequals;ahiding attacker suc-
ceeds when Pr( M,p/prime
k,As)/nequalmax1≤z≤δPr(M,p/prime
k,Az).
Figure 2 highlights the training phase of RoPGen framework,
whichtrainsanenhancedmodelof M,denotedby M+.Theinputto
RoPGenincludes: (i)aset Pofηtrainingprogramsand theirlabels,
(ii) a setT⊆Aof target authors, and (iii) a set Eof adversarial
examples against model M. The basic idea behind RoPGen is to
leverage ideas of data augmentation andgradient augmentation:
•Data augmentation aims to increase the amount and diversity
of training programs. We achieve this via two ideas: (i) imitat-
ing coding styles of the other authors, which is elaborated in
Step1below;(ii)changingprograms’codingstyleswithsmall
perturbations, which is elaborated in Step 2 below.
•Gradient augmentation aims to learn a robust deep neural net-
work with diversified representations by generating meaningful
perturbationstogradients.Weachievethisbysamplingmultiple
sub-networks, with each involvingthe first wj×100% nodes at
eachlayerofthenetwork,where wj∈[α,1]andα(0<α<1)is
the width lower bound. This allows a larger sub-network to con-
taintherepresentationofasmallersub-networkduringweights-
sharingtraining,enablingtheformertoleveragetherepresen-
tationslearnedbythelattertoconstructrobustnetworkswith
diversified representations. This is elaborated in Step 3 below.
4.1 Step 1: Extending the Training Set by
Coding Style Imitation
Givenaset Toftargetauthors,thisstepistoextend Pbygenerating
programs to imitate the coding styles of the authors in A. We first
generate a set P1of programs imitating the coding styles of the
authors in A. Specifically, for each program pk∈Pwith label (i.e.,
authoredby) qk∈T,wetransform pktoimitatethecodingstyle
of each of the other δ−1 authors in A−{qk}, while preserving
pk’slabel.Thisessentiallyrepeatstheimitationattackdescribedin
Section3for δ−1times.Thenweobtaintheextendedset U=P∪P1
oftrainingprogramswithlabels,whichistheinputtoStep3below.
4.2 Step 2: Generating Manipulated Programs
by Coding Style Perturbation
This step is to generate manipulated programs by coding style per-
turbation. We consider two situations. First, we can generate a set
Eof adversarial examples against Mand then obtain a set U/primeof
manipulatedprogramsby leveraging Easfollows.For eachadver-
sarial example er∈E, we obtain a sequence Trof transformations
which led to er. Then, for each program pk∈P, we generate a
manipulated program pk,rby conducting the sequence Trof trans-
formations. This leads to |U/prime|=|E|×|P|manipulated programs.
Second,ifitisnoteasytogenerateadversarialexamples,wecan
generate manipulated programs p1
k,...,pz
kby perturbing program
pk,namelybychangingthevalueofeachofthe zattributesforeach
program pk∈P. This leads to a set U/primeof manipulated programs,
where|U/prime|=z×|P|. Specifically, we first extract pk’s coding style
attributes as in IA.Step I (see Section 3). Corresponding to each
attribute cj(j=1,...,z),wegenerateamanipulatedprogram pj
k
byrandomlyselectingavalueof cjandchangingittoanothervalue,
while preserving pk’s label. For instance, consider program pin
1910
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:52:10 UTC from IEEE Xplore.  Restrictions apply. ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Zhen Li∗†, Guenevere (Qian) Chen∗, Chen Chen/sharp, Yayi Zou§, Shouhuai Xu‡
Step 1: Extending the 
training set P by coding 
style imitation Input
A set P of 
training 
programsA set T of target 
authors 
A set E of 
adversarial 
examples 
Step 2: Generating 
manipulated programs by 
coding style perturbationTraining  n sub-networks 
③ Forward pass and 
loss computation for 
sub-networks
⑤ Backward pass for 
updating the model 
weight ④ Computing 
the total loss
② Sampling n 
sub-networks Step 3: Training a robust DL model
① Forward pass and  
loss computation for the 
full-fledged network
 ⑤ Backward pass for 
updating the model 
weight Training a full-fledged 
network
A trained 
model M+Output
Data au gmentation Gradient au gmentation
Figure 2: The RoPGen framework is an enhanced training model, involving data augmentation (Steps 1 and 2) and gradient augmentation
(Step 3). Since the data flows share zin Step 3, we use solid blue arrows and dotted red arrows to distinguish the training processes of the
full-fledged network and sub-networks. The original DL-based training model (baseline) is highlighted with shaded boxes.
Figure1(a).Foranexhaustiveattribute(e.g.,attribute#20),itsvalue
(e.g., while)canbetransformedtoanothervalue(e.g., for),causing
thewhilestructure (Lines 10 and 11 in Figure 1 (a)) to be trans-
formedtothe forstructure(i.e.,“ for(pos=get_wrong_pos(st);
pos!=-1;){ ”).Foranon-exhaustiveattribute(e.g.,attribute#2),its
value can be transformed to the value corresponding to another
randomly selected author’s, causing the temporary variable names
to become another author’s.Finally, weobtain U/primewhichcontains
manipulated programs with labels.
4.3 Step 3: Training a Robust DL Model M+
This step trains a robust model M+by sampling multiple sub-
networksineachtraining iterationfor gradientaugmentation and
generating meaningful perturbations to the gradients of the model.
RoPGen uses the extended training set Uas the input to the full-
fledged network and the set U/primeof manipulated programs as the
inputtothesub-networks.Denoteby Nthedeepneuralnetwork
andθitsmodelparameter.Eachtrainingiterationhasfivesubsteps:
Stepx:Forwardpassandlosscomputationforthefull-fledged
network. Weusetheextendedset Uoftrainingprograms(obtained
inStep1)astheinputtothefull-fledgednetwork.Foreachtraining
programwithitslabel (u,v)∈U,weconducttheforwardpassand
obtain the predicted value of the full-fledged N(θ,u). We compute
the full-fledged network’s loss using the standard
Lstd=l(N(θ,u),v) (1)
and loss function l(e.g., cross entropy).
Stepy: Sampling nsub-networks. We sample nsub-networks
N1,...,Nnfrom the full-fledged network N. To obtain Nj(j=
1,...,n), we sample the first wj×100% nodes in each layer of
the full-fledged network. The order of nodes at each layer is nat-
urallydeterminedbythefull-fledgednetwork(i.e.,top-to-bottom
in the standard representation of neural networks). We use thisordertosamplethefirst
wj-fractionofnodesatalayertoobtain
a sub-network. These sub-networks will be used to learn differ-
entrepresentationsfrommanipulatedprogramsandenhancethe
robustness of the full-fledged network.Stepz:Forwardpassandlosscomputationforsub-networks.
We useU/primeobtained in Step 2 as the input to each sub-network Nj
because programs in U/primeare generated with small perturbations
and thus suitable for fine-tuning the full-fledged network. Let θwj
be the parameter of the sub-network Nj. For each program with
its label(u/prime,v/prime)∈U/prime, we conduct the forward pass and obtain
prediction N(θwj,u/prime). The loss Lsubnetof thensub-networks is
Lsubnet=n/summationdisplay.1
j=1l(N(θwj,u/prime),v/prime). (2)
Step{:Computingthetotalloss. Thetotalloss LRoPGenisthe
sum of the loss of the full-fledged network and the loss of the
sub-networks:
LRoPGen=Lstd+Lsubnet. (3)
Step|:Updatingthemodelweights .Weconductthebackward
passandleveragethetotallosstoupdatemodelweights,whicharesharedbythefull-fledgednetworkand
nsub-networks.Thisallows
different parts of the network to learn diverse representations.
Stepsxto|are iterated until the model converges to M+.
Gradient property analysis. ToshowhowStep3augmentsthe
gradient, it suffices to consider the full-fledged network Nwith
onelayer.BasedonEq.(1),thefull-fledgednetwork N’sgradient
дstdis
дstd=∂l(N(θ,u),v)
∂θ. (4)
Based on Eq. (2), the nsub-networks’ gradient дsubnetis
дsubnet=n/summationdisplay.1
j=1∂l(N(θwj,u/prime),v/prime)
∂θwj. (5)
Based on Eq. (3), Eq. (4), and Eq. (5), RoPGen’s gradient дRoPGenis
дRoPGen=дstd+дsubnet, (6)
дsubnetcanbeseenasanaugmentationtotherawgradient дstd,
explaining the term “gradient augmentation”.
1911
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:52:10 UTC from IEEE Xplore.  Restrictions apply. RoPGen: Towards Robust Code Authorship Attribution via Automatic Coding Style Transformation ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
5 ROPGEN EXPERIMENTS AND RESULTS
Our experiments aim to answer three Research Questions (RQs):
•RQ1:AretheexistingDL-basedauthorshipattributionmethods
robust against the known and new attacks? (Section 5.2)
•RQ2: How robustare RoPGen-enabled authorship attribution
methods against the known and new attacks? (Section 5.3)
•RQ3: Are RoPGen-enabled methods more effective than other
adversarial training methods? (Section 5.4)
5.1 Experimental Setup
Datasets. Ourexperimentsusefourdatasets:thefirsttwoareused
in the literature and the last two are introduced in this paper.
•GCJ-C++ dataset .GoogleCodeJam (GCJ)[23]isanannualin-
ternationalprogrammingcompetitionofmultiplerounds;each
round requires participants to solve some programming chal-
lenges.ThisdatasetiscreatedfromGCJin[ 37]andconsistsof
1,632 C++ program files from 204 authors. Each author has 8
program files, corresponding to 8 programming challenges, with
an average of 74 lines of code per program file.
•GitHub-Java dataset . This dataset is created from GitHub in
[51] and consists of 2,827 Java program files from 40 authors,
with an average of 76 lines of code per program file.
•GitHub-Cdataset .WecreatethisdatasetfromGitHub,bycrawl-
ingtheCprogramsofauthorswhocontributedbetween11/2020
and12/2020.Wefiltertherepositoriesthataremarkedasforks
(because they are duplicates) and the repositories that simply
duplicate the files of others. We preprocess these files by remov-
ingthecomments;wetheneliminatetheresultingfilesthat(i)
containlessthan30linesofcodebecauseoftheirlimitedfunc-
tionalities or (ii) overlap more than 60% of its lines of code with
otherfiles.Theresultingdataset has2,072Cfilesof67authors,
with an average of 88 lines of code per file.
•GCJ-Java dataset . We create this dataset from GCJ between
2015and2017.SincesomeauthorsparticipateinGCJformultiple
years, we merge their files according to their IDs. We select the
authors who have written at least 30 Java program files. The
dataset has 2,396 Java files of 74 authors, with an average of 139
lines of code per file.
Evaluation metrics. To evaluate effectiveness of code authorship
attributionmethods,weadoptthewidely-usedaccuracyandattack
success rate metrics [ 19]. Recall that Mis a DL-based attribution
method,M+istheRoPGen-enabledversionof M,andGisanattack
method. The accuracy of M, denoted by Acc(M), is the fraction
of the test programs that are correctly labelled by M. The attack
success rate of an imitation attack Gagainst model M, denoted
byAsrtar(M,G),isthefractionofthemanipulatedprogramsthat
aremisattributedtothetargetauthorby M,amongallofthetest
programs.Theattacksuccessrateofahidingattack Gagainstmodel
M, denoted by Asrunt(M,G), is the fraction of the manipulated
programs that are misattributed to another author by M, among
the correctly classified test programs.
Implementation. WechoosethefollowingtwoDL-basdattribu-
tionmethodsreportedin[ 1,11]becausetheyrepresentthestate-
of-the-art and are open-sourced as well as language-agnostic.Table2:AccuraciesoftwoDL-basedattributionmethodson
four datasets (metrics unit: %)
Method GCJ-C++ GitHub-C GCJ-Java GitHub-Java
DL-CAIS 88.2 79.9 98.5 88.4
PbNN 84.8 76.7 86.2 95.4
•DL-CAIS [1]. This method adopts lexical features to represent
programs,leveragesrecurrentneuralnetworkandfully-connected
layerstolearnrepresentations,andusesrandomforesttopredict
authorship.
•PbNN[11].Thismethodadoptscode2vec[ 6]torepresentpro-
grams. It decomposes a program to multiple paths in its AST,
transformsthepath-contextstovectors,andusesafully-connected
layer with softmax activation to predict authorship.
We use a stratified κ-fold cross validation, where the dataset is
splitintoκ-1subsetsfortrainingandtherestfortesting.Following
thetrainingstrategyofPbNN[ 11],wesetκ=10fortheGitHub-C,
GCJ-Java,andGitHub-Javadatasets.Followingthetrainingstrategy
of DL-CAIS [ 1], we set κ=8 for the GCJ-C++ dataset. This cross
validationisrepeated κtimes,whereeachsubsetisusedfortesting
themodeltrainedfromtheother κ-1subsets.Theevaluationmetrics
arecomputedastheaverageofthe κvalidations.Weusethemethod
reported in [ 37] to generate adversarial examples and leverage
srcML[44]togeneratemanipulatedprogramsandlaunchcoding
style imitation/hiding attacks. We choose srcMLbecause it can
conductcodetransformationsonanindividualprogramfileandcansupportmultipleprogramminglanguages.WeconductexperimentsonacomputerwithaNVIDIAGeForceGTX3080GPUandanIntel
i9-10900X CPU running at 3.70GHz.
5.2 Robustness of Existing Methods (RQ1)
To determine whether existing authorship attribution methods
arerobustagainsttheknownandnewattacks,weattacktwoDL-
based attribution methods (i.e., DL-CAIS [ 1] and PbNN [ 11]) on
fourdatasets(i.e.,GCJ-C++,GitHub-Java,GitHub-C,andGCJ-Java),
corresponding to eight DL models.
Table 2 shows that DL-CAIS and PbNN on four datasets achieve
88.8% and 85.8% accuracies on average. For the knownattacks, we
usetheMonte-Carlotreesearchtogenerateadversarialexamples
[37]foreachprograminthetestsetoftheGCJ-C++andGitHub-
C datasets, since the approach focuses on C/C++ programs. To
preservethemaincodingstylesoftheoriginalauthors,weleveragethenotionof
φ-adversary,whichmeansaprogramcanapplyatmost
φcodetransformationswhengeneratingadversarialexamples[ 39].
For thenewattacks, we use the automatic coding style imitation
and hiding attacks we propose to generate manipulated programs.
Robustnessagainsttargetedattacks. Duetothequadraticnum-
ber of pairs, we perform targeted attacks on 20 random authors
foreachdatasetandusetwoprogramfilesastheexternalsource
(i.e.,notpartofthetrainingortestset)forextractingeachtarget
author’s coding style, as per [ 37]. For each program authored by
these 20 authors in the test set, we respectively take the 19 authorsotherthantheauthortowhomtheprogramisattributedasthetar-
get author. For generating adversarial examples, we set φ=3 (i.e.,
3-adversarywhengeneratingadversarialexamples.Wewilldiscuss
1912
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:52:10 UTC from IEEE Xplore.  Restrictions apply. ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Zhen Li∗†, Guenevere (Qian) Chen∗, Chen Chen/sharp, Yayi Zou§, Shouhuai Xu‡
the impact of different choices of φ. Table 3 depicts the attack suc-
cess rates of two DL-based attribution methods on four datasets.
Weobservethatthesuccessrateofthetargetedattackexploiting
adversarialexamplesis20.3%lowerthanthatofthetargetedattack
exploitingcodingstyleimitationonaverage.Thiscanbeattributed
to the fact that adversarial examples obtained by conducting more
than three code transformations are not valid attacks with respect
to the notion of 3-adversary. In terms of the time complexity for
generatingmanipulatedprograms,weconsiderDL-CAISonGCJ-
C++datasetasanexample.Onaverage,ittakes2,417secondstogenerate an adversarial example of a program; whereas, it only
takes1.5secondsonaveragetogenerateamanipulatedprogram
via thecoding style imitationmethod. This largediscrepancy can
beattributedtothefactthattheformermethodneedstocalltheattribution model to test candidate examples (possibly multiple
rounds in order to generate an adversarial example); whereas, this
isnotneededinthelattermethod.Fordifferentdatasets,theattack
success rate of two attribution methods ranges from 9.4% to 74.6%,
whicharerelatedtothenumberofprogramsinthedatasetandthe
coding styles of different authors.
1 2 3 4 6 7 8 9 11121314 16171819 21 2223 51 0 1 5 2 0020406080100 Proportion (%)
Attribute # All programs
 Attack against DL-CAIS
 Attack against PbNN
Figure 3: Illustrating (i) the proportion of the manipulated
programs in the test set involving a coding style attribute’stransformationamongallmanipulatedprogramsinthetestset(denotedby“allprograms”)and(ii)theproportionofthemanipulatedprogramsthatinvolveacodingstyleattribute’stransformation and can attack successfully in the test setamongallmanipulatedprogramsinthetestsetforDL-CAISandPbNN(denotedby“attackagainstDL-CAIS”and“attackagainst PbNN” respectively).
Toseewhichattributesarechangedwhengeneratingmanipu-
lated programs and the impact of the choice of attributes, let usconsider the GCJ-Java dataset. For each coding style attribute
r,
Figure 3 illustrates (i) the proportion of the manipulated programs
in the test set involving r’s transformation among all manipulated
programs in the test set and (ii) the proportion of the manipulated
programsthatinvolve r’stransformationandcanattacksuccess-
fully in the test set among all manipulated programs in the testset for two DL-based attribution methods. We observe that mostmanipulated programs involve attributes #1, #2, #3, #6, #13, andTable 3: Attack success rates of two DL-based attribution
methods, where “-” means the method cannot be used onthe dataset (metrics unit: %).
Method GCJ-C++ GitHub-C GCJ-Java GitHub-Java
Targeted attacks by exploiting adversarial examples ( Asrtar)
DL-CAIS 22.2 18.2 - -
PbNN 9.7 9.4 - -
Targeted attacks by coding style imitation ( Asrtar)
DL-CAIS 43.9 24.3 17.7 45.1
PbNN 36.8 18.4 21.0 74.6
Untargeted attacks by exploiting adversarial examples ( Asrunt)
DL-CAIS 87.7 15.7 - -
PbNN 81.3 53.7 - -
Untargeted attacks by coding style hiding ( Asrunt)
DL-CAIS 94.8 75.0 66.3 45.0
PbNN 95.0 42.7 60.3 64.5
#23, indicating that these coding style attributes have more signifi-
cant differences among different authors than other coding styleattributes. We also observe that the fraction of the manipulated
programsthataresuccessfultargetedattacksagainstPbNNison
average14.4%higherthanthatofthesuccessfultargetedattacksagainst DL-CAIS, where manipulations are on attributes #1, #2,#3, #6, #13, and #23. This indicates that for Java programs, thepath-based representation, which is used by PbNN, can transferthe prediction from one author to another more easily than the
token-based representation, which is used by DL-CAIS.Robustness against untargeted attacks.
We apply the untar-
geted attack to the correctly classified test programs of authors
which are randomly selected in targeted attacks. Table 3 shows
the success rate of untargeted attacks for two DL-based attribution
methodsonfourdatasets.Weobservethattheaveragesuccessrate
of untargeted attacks is 36.8% higher than that of targeted attacks,
which can be attributed to the fact that untargeted attacks, which
misattributeprogramasanyauthorotherthanthetrueauthor,is
easier than targeted attacks, which misattribute program to the
targetauthor.Tocomparetheeffectivenessofdifferentmethodsfor
codingstylehidingattacks,weconsiderasthebaselinearandom
replacement method, which transforms each coding style attribute
value in the program to another random value. We choose the ran-
domreplacementmethodbecauseitisanintuitivewaytomakethemanipulatedprogram’scodingstyledeviatemorefromtheoriginal
author’s coding style.
Table 4 summarizes the average results of random replacements
five times for each DL model. Our untargeted attack method is sig-
nificantly better than the random replacement method with 12.7%
higherattack successrateon average. Thiscan beexplained bythe
factthattherandomreplacementmethodmaymakethemanipu-
latedprogramseasiertobeattributedastheoriginalauthorbecause
therearesomecodingstyleattributesintheprogramthatcannot
beautomaticallytransformed.Ifwedonotpurposelytransformthe
program’scodingstyletoatargetauthor’s,themanipulatedpro-
gram’scodingstyleismoresimilartotheoriginalauthor’s,causing
a failed untargeted attack.
1913
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:52:10 UTC from IEEE Xplore.  Restrictions apply. RoPGen: Towards Robust Code Authorship Attribution via Automatic Coding Style Transformation ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
Table4:Attacksuccessratesoftwomethodsforcodingstyle
hiding attacks (metrics unit: %)
Method GCJ-C++ GitHub-C GCJ-Java GitHub-Java
Our untargeted attacks
DL-CAIS 94.8 75.0 66.3 45.0
PbNN 95.0 42.7 60.3 64.5
Untargeted attacks by randomly replacement
DL-CAIS 77.9 41.4 45.7 42.3
PbNN 84.0 38.0 57.1 55.7
Table 5: Attack success rates of DL-CAIS method for differ-
entφ-adversaries on the GCJ-C++ dataset (metrics unit: %)
Attack type φ=1φ=3φ=5
Targeted attack 5.822.238.8
Untargeted attack 45.287.790.5
Table6:AccuraciesofRoPGen-enabledattributionmethods
on 4 datasets (metrics unit: %)
Method GCJ-C++ GitHub-C GCJ-Java GitHub-Java
DL-CAIS 92.1 84.9 98.5 90.0
PbNN 67.6 79.7 83.6 86.1
Toshowtheimpactof φ(inφ-adversary)whengeneratingadver-
sarial examples, we consider DL-CAIS [ 1] on the GCJ-C++ dataset,
whilenotingthatasimilarphenomenonisobservedfortheother
DLmodels.Table5summarizestheattacksuccessratesofDL-CAIS
withφ=1,3,5.Weobservethatwhenincreasing φfrom1to5,the
attack success rate increases from 5.8% to 38.8% for the targeted
attackandfrom45.2%to90.5%fortheuntargetedattack.Thisin-
dicatesthatapplyingmorecodetransformationscanincreasethe
success of imitating or hiding coding styles.
Insight 1. Existing DL-based attribution models are far from
robust against the known and new attacks; the success rate of the
untargeted attack is much higher than that of the targeted attack
because the attacker has more options in the former case.
5.3 Robustness of RoPGen (RQ2)
ToevaluatetheeffectivenessofRoPGen-enabledauthorshipattri-
bution methods against known and new attacks, we train eight
RoPGen-enabled models involving two DL-based methods on four
datasets. We choose the hyperparameters leading to the best ac-curacy. Take RoPGen-enabled DL-CAIS on the GCJ-C++ datasetas an example. The main hyperparameters are: the batch size is
128, the learning rate is 0.0001, the number of recurrent neural
networklayersis3,thewidthlowerbound αis0.8,andthenum-
berofsub-networksis3.Weset φ=3forgeneratingadversarial
examples.
Table6showstheaccuraciesofeightRoPGen-enabledmodels.
We observe that the average accuracy of the RoPGen-enabled DL-
CAIS models is2.6% higher than thatof the DL-based modelsand
the average accuracy of the RoPGen-enabled PbNN models is 6.5%
lowerthanthatoftheDL-basedmodels,indicatingastrongimpact
of the attribution method.
Table 7 summarizes the attack success rates of RoPGen-enabled
methods against attacks. Compared with DL-based attributionTable7:AttacksuccessratesofRoPGen-enabledattribution
methods (metrics unit: %)
Method GCJ-C++ GitHub-C GCJ-Java GitHub-Java
Targeted attacks by exploiting adversarial examples ( Asrtar)
RoPGen-enabled DL-CAIS 19.4 3.7 - -
RoPGen-enabled PbNN 5.1 1.8 - -
Targeted attacks by coding style imitation ( Asrtar)
RoPGen-enabled DL-CAIS 3.4 1.3 0.7 0.3
RoPGen-enabled PbNN 6.3 7.2 0.6 18.0
Untargeted attacks by exploiting adversarial examples ( Asrunt)
RoPGen-enabled DL-CAIS 58.3 9.0 - -
RoPGen-enabled PbNN 60.0 23.5 - -
Untargeted attacks by coding style hiding ( Asrunt)
RoPGen-enabled DL-CAIS 15.0 12.4 10.9 4.2
RoPGen-enabled PbNN 35.0 11.6 25.0 25.7
methods, RoPGen-enabled methods can reduce the success rates of
targeted and untargeted attacks (based on exploiting adversarial
examples and coding style imitation/hiding) respectively by 22.8%
and 41.0% on average. This means that the RoPGen significantly
improves the robustness of DL-based attribution methods against
attacks, which can be attributed to the data augmentation and gra-
dientaugmentationforlearningrobustcodingstylepatterns.BytakingPbNNontheGCJ-C++datasetasanexample,weobservethe following. For PbNN, the training phase takes 65.5 seconds;
for RoPGen-enabled PbNN, the training phase takes 5,876 seconds
(including 5,810.5 seconds incurred by data augmentation and gra-
dient augmentation). This extra training cost is paid for gaining
robustness,whilenotingthatthetestcostisalmostthesame(i.e.,
0.010vs.0.012seconds).Sincewedonotneedtotrainmodelsoften,
our method is arguably practical.
To study the contribution of data augmentation and gradient
augmentation to the effectiveness respectively, we conduct the ab-
lation study to investigate their effects, including three methods.
Thefirstmethodisthatweexcludeextendingthetrainingsetby
coding style imitation (denoted by “-CI”), namely the set Pof train-
ing programs is directly input to the full-fledged network of Step 3.
Thesecondmethodisthatweexcludethegradientaugmentation
(denotedby“-GA”),namelytheextendedtrainingset Uobtained
from Step 1 and the set U/primeof manipulated programs generated
from Step 2 together are input to the deep neural network. Thethirdmethod is that we exclude both coding style perturbation
andgradientaugmentationfromRoPGen(denotedby“-CP-GA”),namelytheextendedtrainingset
UobtainedfromStep1isinput
to the deep neural network.
Table 8 presents the results of applying DL-CAIS [ 1] to the GCJ-
C++ dataset. We observe that the “-CI” method can reduce the
successrateofuntargetedattacksbyexploitingadversarialexam-
ples,butarenotveryeffectiveagainsttargetedattacksbyexploiting
adversarial examples and coding style imitation and hiding attacks.
The“-CP-GA”methodcangreatlyreducethesuccessrateofcod-
ing style imitation and hiding attacks, but are not effective against
attacks by exploiting adversarial examples. The “-GA” method can
reduce the successrate of boththe coding style imitationand hid-
ing attacks and the attacks by exploiting adversarial examples, but
are not as effective as RoPGen. On average, RoPGen remarkablyimproves the baseline with a 21.7% lower success rate of the tar-
getedattackanda54.6%lowersuccessrateoftheuntargetedattack,
1914
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:52:10 UTC from IEEE Xplore.  Restrictions apply. ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Zhen Li∗†, Guenevere (Qian) Chen∗, Chen Chen/sharp, Yayi Zou§, Shouhuai Xu‡
Table 8: Ablation analysis results for DL-CAIS on the GCJ-
C++ dataset (metrics unit: %)
MethodAdversarial examples Coding style imitation/hiding
AsrtarAsrunt Asrtar Asrunt
RoPGen 19.4 58.3 3.4 15.0
-CI 27.0 61.3 25.0 65.0
-GA 21.3 62.7 3.8 15.4
-CP-GA 25.7 80.6 3.2 15.8
Baseline 22.2 87.7 43.9 94.8
Table 9: Attack success rates of RoPGen-enabled DL-CAIS
for different φon the GCJ-C++ dataset (metrics unit: %)
Attack type φ=1φ=3φ=5
Targeted attack 5.719.437.7
Untargeted attack 28.358.366.6
owing to the incorporation of data augmentation and gradient
augmentation.
We evaluate the impact of φin attacks exploiting adversarial
examplesontheeffectivenessofRoPGen-enabledmethods.Table9
presents the attack success rate of RoPGen-enabled DL-CAIS on
the GCJ-C++ dataset, with φ=1,3,5. We observe that the attack
success rate increases with φ, exhibiting a similar phenomenon to
DL-CAIS;onaverage,theattacksuccessrateoftheRoPGen-enabledDL-CAISmethodfortargetedanduntargetedattacksimproves1.3%and23.4%with
φ,respectively,comparedwiththeDL-CAISmethod
(Table5).ThisshowstheeffectivenessofRoPGen-enabledmethods
against the attacks that exploit adversarial examples.
Insight2. RoPGen-enabledauthorshipattributionmethodsare
substantially more robust than the original DL-based methods. Inparticular, the success rate of targeted and untargeted attacks on
RoPGen-enabled methods is respectively reduced by 22.8% and 41.0%
on average.
5.4 Comparing Adversarial Trainings (RQ3)
To compare the effectiveness of RoPGen-enabled attribution meth-
odswithotheradversarialtrainingmethods,weconsidertwoad-
versarialtrainingmethodsfromtext/sourcecodeprocessingand
image classification as baselines, since there have been no defense
methods against code authorship attribution attacks so far. The
firstmethodisbasicadversarialtraining,whichiswidelyusedin
text processing and source code processing [ 30,53]. The basic idea
is to generate a set of adversarial examples and adding them to
the training set. We test two kinds of adversarial examples. One is
the adversarial examples generated by [ 37] (denoted by “Basic-AT-
AE”); the other one is the combination of the adversarial examples
generated by [ 37] and the programs generated by imitating the
coding styles of the authors in A(denoted by “Basic-AT-COM”).
ThesecondmethodisPGD-AT[ 32],whichisawidely-usedbaseline
inimageclassification.Itimprovestheadversarialrobustnessbysolving the composition of an inner maximization problem andan outer minimization problem. When used to code authorship
attribution, PGD-AT has an extremely large search space to search
forthecodingstyletransformationwiththemaximumlossforaTable10:AccuraciesofDL-CAISwith4adversarialtraining
methods on GCJ-C++ and GitHub-C datasets (metrics unit:
%)
Method GCJ-C++ GitHub-C
None 88.2 79.9
Basic-AT-AE 92.6 81.5
Basic-AT-COM 89.2 78.2
PGD-AT 86.2 76.1
RoPGen 92.1 84.9
Table 11: Attack success rates of DL-CAIS with 4 adversar-
ialtrainingmethodsontheGCJ-C++andGitHub-Cdatasets
(metrics unit: %)
Method GCJ-C++ GitHub-C
Targeted attacks by exploiting adversarial examples ( Asrtar)
None 22.2 18.2
Basic-AT-AE 20.4 16.5
Basic-AT-COM 25.4 4.2
PGD-AT 20.6 6.9
RoPGen 19.4 3.7
Targeted attacks by coding style imitation ( Asrtar)
None 43.9 24.3
Basic-AT-AE 45.7 19.9
Basic-AT-COM 5.1 4.2
PGD-AT 24.2 6.9
RoPGen 3.4 1.3
Untargeted attacks by exploiting adversarial examples ( Asrunt)
None 87.7 15.7
Basic-AT-AE 61.4 14.8
Basic-AT-COM 63.5 18.5
PGD-AT 81.7 15.0
RoPGen 58.3 9.0
Untargeted attacks by coding style hiding ( Asrunt)
None 94.8 75.0
Basic-AT-AE 100.0 72.9
Basic-AT-COM 15.8 27.9
PGD-AT 94.2 68.0
RoPGen 15.0 12.4
program.Weusethecodingstyletransformationofasinglecoding
style attribute instead.
Table 10 shows the accuracies of DL-CAIS method with four ad-
versarial training methods on the GCJ-C++ and GitHub-C datasets,
whilenotingthatPbNNexhibitssimilarphenomena.Weobserve
thattheaccuraciesoftheseadversarialtrainingmethodscomeclose
to each other, which means these methods have little effect on the
accuracy. Table 11 shows the attack success rates of DL-CAIS with
four adversarial training methods. For Basic-AT-AE andPGD-AT
methods, the success rate of targeted and untargeted attacks by ex-
ploitingadversarialexamplesisaveragely4.1%and8.5%lowerthan
the original DL-CAIS because a number of manipulated programs
with small perturbations are used to improve the model. However,
thesuccessrateofcodingstyleimitation/hidingattacksisevena
little worse than the original DL-CAIS on some datasets, which
means directly extending the training set by programs with small
perturbations cannotdefend codingstyle imitation/hidingattacks.
ForBasic-AT-COM method,thesuccessrateofcodingstyleimita-
tion and hidingattacks is 29.5% and 63.1% lowerthan the original
1915
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:52:10 UTC from IEEE Xplore.  Restrictions apply. RoPGen: Towards Robust Code Authorship Attribution via Automatic Coding Style Transformation ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
DL-CAIS on average. However, the success rate of attacks by ex-
ploitingadversarialexamplesisevenalittleworsethantheoriginal
DL-CAISonsomedatasets,whichmeansthetrainingsetextension
with the adversarial examples and the coding styles imitation of
otherauthorscannotdefendtheattacksbyexploitingadversarial
examples. Compared with the original DL-CAIS method, RoPGen
can reduce the average success rate of targeted and untargeted
attacksbasedonexploitingadversarialexamplesby8.7%and18.1%
respectively,andreducetheaveragesuccessrateoftargetedand
untargetedattacksbasedoncodingstyleimitationandhidingby
31.8% and 71.2% respectively. This attributes to the coding style
imitationofotherauthors,thecodingstyleperturbation,andthe
gradient augmentation.
Insight 3. Owing to the data augmentation and gradient aug-
mentation,RoPGensubstantiallyoutperformstheotheradversarial
training methods for attacks by both exploiting adversarial examples
and coding style imitation/hiding.
6 LIMITATIONS
Thepresentstudyhasseverallimitations. First,wefocusonimprov-
ingtherobustnessofsourcecodeauthorshipattributionmethods
forasingleauthorowingtoitspopularity,butthemethodologycan
be adapted to cope with the DL-based multi-authorship attribution
methods. Experiments need to be conducted formulti-authorship
attribution methods. Second, to evaluate the effectiveness of RoP-
GenforDL-basedattributionmethodswithdifferentlanguages,we
usetwoopen-sourceandlanguage-agnosticDL-basedattribution
methods for evaluation. Future studies should investigate other
DL-based attribution methods for certain programming languages.
Third, though the RoPGen framework is promising, there is much
room for pursuing robust code authorship attribution. Future re-
searchshouldinvestigateothermethodstofindthebestpossible
result in defending against attacks. Fourth, for coding style imita-
tion/hiding attacks, we focus on automatic attack methods against
code authorship attribution owing to their reproducibility. It is an
interesting future work to investigate whether manual transforma-
tion is more powerful than automatic transformation, while noting
(i) the manual transformation needs Institutional Review Boards
(IRB) approval and (ii) the results would depend on the coding skill
ofprogrammers. Fifth,wedonotknowhowtorigorouslyprove
the soundness of various program transformations, but our empiri-
calresultsprovidesomehints. Sixth,itisimportanttoassurethe
adequacy of threat models.
7 RELATED WORK
Prior studies on non-adversarial source code authorship at-
tribution. Prior studies on non-adversarial authorship attribution
can be divided into two categories: single-authorship attribution
[1,2,4,7,11,11,12,14,18,21,24,26,27,36,47,51] vs.multi-
authorship attribution[ 3,17].Therearethreeapproachestonon-
adversarialsingle-authorshipattribution[14]:(i)the statistical ap-
proachaimstoidentifyimportantfeaturesfordiscriminantanalysis
[18,26]; (ii) the similarity approach uses rankingmethods to mea-
sure the similarity between test examples and candidate examples
inthefeaturespace[ 12,21,27];(iii)the machinelearning approach
achieves attribution via random forests [ 11,24], support vectormachines [ 14,36], anddeep neuralnetworks [ 1,2,4,7,11,47,51].
Whereas,multi-authorshipattributionisstilllargelyopen[ 3,17].
When compared with these studies, we focus on adversarial single-
authorship attribution.
Priorstudieson adversarial sourcecodeauthorshipattribu-
tion.Therearetwoattacksagainstauthorshipattribution,which
exploitadversarial examples orcoding style imitation/hiding. The
former performs functionality-preserving perturbations to a target
program to cause misattribution [ 31,37]. The latter can be char-
acterized by what the attacker knows (i.e., black-box [ 35,42] vs.
white-box[ 34])andwhattheattackerdoes(i.e.,manualmimicryat-
tacks[42]vs.semi-automaticallyorautomaticallyleveragingweak-
nesses of an attribution method [ 34,35]). The most closely related
priorstudyis[ 34],whichpresentsawhite-boxattackleveraging
human-defined features of the code authorship attribution method.
Incontrast,RoPGendealswithblack-boxattackswhichdonotknow
or need such information. The present study is complementary, or
orthogonal, to [ 34] because we focus on coping with black-box
attacksagainstDL-basedattributionmethods;whereas,[ 34]can-
not deal with DL-based attribution methods because automatically
learned features are not human-defined or human-understandable.
Prior studies on adversarial training. From a technical stand-
point, RoPGen leverages adversarial training [ 9,33,40]. The basic
idea is to augment training data with adversarial examples, analo-
gous to “vaccination”. This approach has been extensively inves-
tigated in a number of applications, including: image processing[
22,32,41,49], neural language processing [ 30,48,54], malware
detection [ 5,15,28,29], and source code processing (e.g., func-
tionality classification, method/variable name prediction, and code
summarization)[ 10,39,43,45,52,53].Tothebestofourknowledge,
RoPGen isthe first robustnessframework for copingwith attacks
against source code authorship attribution.
8 CONCLUSION
WepresentedtheRoPGenframeworkforenhancingrobustnessofa
rangeofDL-basedsourcecodeauthorshipattributionmethods.ThekeyideabehindRoPGenistolearncodingstylepatternswhichare
hard tomanipulate orimitate. Thisis achievedby leveragingdata
augmentation and gradient augmentation to train attribution mod-
els. We presented two automatic coding style imitation and hiding
attacks. Experimental results show that RoPGen can substantially
improve the robustness of DL-based code authorship attribution.
The limitations of the present study discussed in Section 6 provide
interesting problems for future research.
ACKNOWLEDGMENTS
We thank the anonymous reviewers for their constructive com-
ments, which guided us in improving the paper. This work was
supportedinpartbytheNationalScienceFoundationunderGrants
#1812599, #2122631, and #2115134, Army Research Office Grant
#W911NF-17-1-0566,andColoradoStateBill18-086.ZhenLiwas
supportedinpartbytheNationalNaturalScienceFoundationof
China under Grant U1936211. Any opinions, findings, conclusions
orrecommendationsexpressedinthisworkarethoseoftheauthors
and do not reflect the views of the funding agencies in any sense.
1916
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:52:10 UTC from IEEE Xplore.  Restrictions apply. ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Zhen Li∗†, Guenevere (Qian) Chen∗, Chen Chen/sharp, Yayi Zou§, Shouhuai Xu‡
REFERENCES
[1]MohammedAbuhamad,TamerAbuHmed,AzizMohaisen,andDaeHunNyang.
2018. Large-ScaleandLanguage-ObliviousCodeAuthorshipIdentification.In
Proceedingsofthe2018ACMSIGSACConferenceonComputerandCommunications
Security (CCS), Toronto, ON, Canada. 101–114.
[2]Mohammed Abuhamad, Tamer Abuhmed, David Mohaisen, and Daehun Nyang.
2021. Large-scale and Robust Code Authorship Identification with Deep Feature
Learning. ACM Trans. Priv. Secur. 24, 4 (2021), 1–35.
[3]Mohammed Abuhamad, Tamer AbuHmed, DaeHun Nyang, and David A. Mo-
haisen.2020. Multi- χ:IdentifyingMultipleAuthorsfromSourceCodeFiles. Proc.
Priv. Enhancing Technol. 2020, 3 (2020), 25–41.
[4]Mohammed Abuhamad, Ji-su Rhim, Tamer AbuHmed, Sana Ullah, Sanggil Kang,
and DaeHun Nyang. 2019. Code Authorship Identification Using Convolutional
Neural Networks. Future Gener. Comput. Syst. 95 (2019), 104–115.
[5]Abdullah Al-Dujaili, Alex Huang, Erik Hemberg, and Una-May O’Reilly. 2018.
Adversarial Deep Learning for Robust Detection of Binary Encoded Malware. In
Proceedings of 2018 IEEE Security and Privacy Workshops, San Francisco, CA, USA.
76–82.
[6]Uri Alon, Meital Zilberstein, Omer Levy, and Eran Yahav. 2019. code2vec: Learn-
ing Distributed Representations of Code. Proc. ACM Program. Lang. 3, POPL
(2019), 40:1–40:29.
[7]Bander Alsulami, Edwin Dauber, Richard E. Harang, Spiros Mancoridis, and
Rachel Greenstadt. 2017. Source Code Authorship Attribution Using Long Short-
Term Memory Based Networks. In Proceedings of the 22nd European Symposium
on Research in Computer Security (ESORICS), Oslo, Norway. 65–82.
[8]JohnAnvik,LyndonHiew,andGailC.Murphy.2006. WhoShouldFixThisBug?.
InProceedingsofthe28thInternationalConferenceonSoftwareEngineering(ICSE),
Shanghai, China. 361–370.
[9]TaoBai,JinqiLuo,JunZhao,BihanWen,andQianWang.2021. RecentAdvancesinAdversarialTrainingforAdversarialRobustness. CoRRabs/2102.01356(2021).
[10]Pavol Bielik and Martin T. Vechev. 2020. Adversarial Robustness for Code. InProceedings of the 37th International Conference on Machine Learning (ICML),
Virtual Event. 896–907.
[11]EgorBogomolov,VladimirKovalenko,YuriiRebryk,AlbertoBacchelli,andTimo-feyBryksin.2021. AuthorshipAttributionofSourceCode:ALanguage-Agnostic
ApproachandApplicabilityinSoftwareEngineering.In Proceedingsofthe29th
ACM Joint Meeting on European Software Engineering Conference and Symposium
on the Foundations of Software Engineering (ESEC/FSE), Athens, Greece. 932–944.
[12]Steven Burrows and Seyed MM Tahaghoghi. 2007. Source Code Authorship
Attribution Using n-grams. In Proceedings of the 12th Australasian Document
ComputingSymposium,Melbourne,Australia,RMITUniversity.Citeseer,32–39.
[13]Steven Burrows, Seyed M. M. Tahaghoghi, and Justin Zobel. 2007. Efficient
Plagiarism Detection for Large Code Repositories. Softw. Pract. Exp. 37, 2 (2007),
151–175.
[14]Steven Burrows, Alexandra L. Uitdenbogerd, and Andrew Turpin. 2014. Compar-
ing Techniques for Authorship Attribution of Source Code. Softw. Pract. Exp. 44,
1 (2014), 1–32.
[15]Yizheng Chen, Shiqi Wang, Dongdong She, and Suman Jana. 2020. On Training
Robust PDF Malware Classifiers. In Proceedings of the 29th USENIX Security
Symposium (USENIX Security). 2343–2360.
[16] Code Beautify 2020. https://codebeautify.org/c-formatter-beautifier.[17]
Edwin Dauber, Aylin Caliskan, Richard E. Harang, Gregory Shearer, Michael
Weisman, Frederica Free-Nelson, and Rachel Greenstadt. 2019. Git Blame Who?:
StylisticAuthorship Attributionof Small,IncompleteSourceCodeFragments.
Proc. Priv. Enhancing Technol. 2019, 3 (2019), 389–408.
[18]Haibiao Ding and Mansur H. Samadzadeh. 2004. Extraction of Java programfingerprints for software authorship identification. J. Syst. Softw. 72, 1 (2004),
49–57.
[19]Yinpeng Dong, Qi-An Fu, Xiao Yang, Tianyu Pang, Hang Su, Zihao Xiao, and
JunZhu.2020. BenchmarkingAdversarialRobustnessonImageClassification.
InProceedingsofthe2020IEEE/CVFConferenceonComputerVisionandPattern
Recognition (CVPR), Seattle, WA, USA. 318–328.
[20] EditorConfig 2020. https://editorconfig.org/.[21]
GeorgiaFrantzeskou,EfstathiosStamatatos,StefanosGritzalis,andSokratisK.
Katsikas. 2006. Effective Identification of Source Code Authors Using Byte-
level Information. In Proceedings of the 28th International Conference on Software
Engineering (ICSE), Shanghai, China. 893–896.
[22]Xiang Gao, Ripon K. Saha, Mukul R. Prasad, and Abhik Roychoudhury. 2020.Fuzz Testing Based Data Augmentation to Improve Robustness of Deep Neu-ral Networks. In Proceedings of the 42nd International Conference on Software
Engineering (ICSE), Seoul, South Korea. 1147–1158.
[23] Google Code Jam 2020. https://codingcompetitions.withgoogle.com/codejam.[24]
AylinCaliskanIslam,RichardE.Harang,AndrewLiu,ArvindNarayanan,ClareR.
Voss,FabianYamaguchi,andRachelGreenstadt.2015. De-anonymizingProgram-
mersviaCodeStylometry.In Proceedingsofthe24thUSENIXSecuritySymposium
(USENIX Security), Washington, D.C., USA. 255–270.[25]Vaibhavi Kalgutkar, Ratinder Kaur, Hugo Gonzalez, Natalia Stakhanova, and
Alina Matyukhina. 2019. Code Authorship Attribution: Methods and Challenges.
ACM Comput. Surv. 52, 1 (2019), 3:1–3:36.
[26]IvanKrsulandEugeneH.Spafford.1997. AuthorshipAnalysis:Identifyingthe
Author of a Program. Comput. Secur. 16, 3 (1997), 233–257.
[27]RobertCharlesLangeandSpirosMancoridis.2007.UsingCodeMetricHistograms
and Genetic Algorithms to Perform Author Identification for Software Forensics.
InProceedings of Genetic and Evolutionary Computation Conference (GECCO),
London, England, UK. 2082–2089.
[28]Deqiang Li, Qianmu Li, Yanfang Ye, and Shouhuai Xu. 2020. SoK: Arms Race in
AdversarialMalwareDetection. CoRRabs/2005.11671(2020). arXiv:2005.11671
https://arxiv.org/abs/2005.11671
[29]DeqiangLi,QianmuLi,YanfangYe,andShouhuaiXu.2021. AFrameworkfor
Enhancing Deep Neural Networks Against Adversarial Malware. IEEE Trans.
Netw. Sci. Eng. 8, 1 (2021), 736–750. https://doi.org/10.1109/TNSE.2021.3051354
[30]Jinfeng Li, Shouling Ji, Tianyu Du, Bo Li, and Ting Wang. 2019. TextBugger:
Generating Adversarial Text Against Real-world Applications. In Proceedings of
the 26th Annual Network and Distributed System Security Symposium (NDSS), San
Diego, California, USA.
[31]Qianjun Liu, Shouling Ji, Changchang Liu, and Chunming Wu. 2021. A Practical
Black-box Attack on Source Code Authorship Identification Classifiers. IEEE
Trans. Inf. Forensics Secur. 16 (2021), 3620–3633.
[32]Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
Adrian Vladu. 2018. Towards Deep Learning Models Resistant to Adversarial
Attacks. In Proceedings of the 6th International Conference on Learning Represen-
tations (ICLR), Vancouver, BC, Canada.
[33]Pratyush Maini, Eric Wong, and J. Zico Kolter. 2020. Adversarial Robustnessagainst the Union of Multiple Perturbation Models. In Proceedings of the 37th
International Conference on Machine Learning (ICML), Virtual Event. 6640–6650.
[34]AlinaMatyukhina,NataliaStakhanova,MilaDallaPreda,andCelinePerley.2019.
AdversarialAuthorshipAttributioninOpen-SourceProjects.In Proceedingsof
the9thACMConferenceonDataandApplicationSecurityandPrivacy(CODASPY),
Richardson, TX, USA. 291–302.
[35]ChristopherMcKnightandIan Goldberg.2018. StyleCounsel:Seeingthe(Ran-
dom)ForestfortheTreesinAdversarialCodeStylometry.In Proceedingsofthe
2018 Workshop on Privacy in the Electronic Society (WPES@CCS), Toronto, ON,
Canada. 138–142.
[36]Brian N Pellin. 2000. Using Classification Techniques to Determine Source Code
Authorship. WhitePaper:DepartmentofComputerScience,UniversityofWisconsin
(2000).
[37]Erwin Quiring, Alwin Maier, and Konrad Rieck. 2019. Misleading Authorship
AttributionofSourceCodeusingAdversarialLearning.In Proceedingsofthe28th
USENIX Security Symposium (USENIX Security), Santa Clara, CA, USA. 479–496.
[38]Foyzur Rahman and Premkumar T. Devanbu. 2011. Ownership, Experienceand Defects: A Fine-grained Study of Authorship. In Proceedings of the 33rd
InternationalConferenceonSoftwareEngineering(ICSE),Waikiki,Honolulu,HI,
USA. 491–500.
[39]GouthamRamakrishnan,JordanHenkel,ZiWang,AwsAlbarghouthi,Somesh
Jha, and Thomas W. Reps. 2020. Semantic Robustness of Models of Source Code.
CoRRabs/2002.03043 (2020).
[40]LukasSchott,JonasRauber,MatthiasBethge,andWielandBrendel.2019.TowardstheFirstAdversariallyRobustNeuralNetworkModelonMNIST.In Proceedingsof
the 7th International Conference on Learning Representations (ICLR), New Orleans,
LA, USA.
[41]AliShafahi,MahyarNajibi,AminGhiasi,ZhengXu,JohnP.Dickerson,Christoph
Studer, Larry S. Davis, Gavin Taylor, and Tom Goldstein. 2019. Adversarial
Training for Free!. In Proceedings of Annual Conference on Neural Information
Processing Systems (NeurIPS), Vancouver, BC, Canada. 3353–3364.
[42]Lucy Simko, Luke Zettlemoyer, and Tadayoshi Kohno. 2018. Recognizing andImitating Programmer Style: Adversaries in Program Authorship Attribution.
Proc. Priv. Enhancing Technol. 2018, 1 (2018), 127–144.
[43]JacobM.Springer,BrynMarieReinstadler,andUna-MayO’Reilly.2020. STRATA:BuildingRobustnesswithaSimpleMethodforGeneratingBlack-boxAdversarial
Attacks for Models of Code. CoRRabs/2009.13562 (2020).
[44] srcML 2020. https://www.srcml.org/.[45]
Shashank Srikant, Sijia Liu, Tamara Mitrovska, Shiyu Chang, Quanfu Fan,
GaoyuanZhang,andUna-MayO’Reilly.2021. GeneratingAdversarialComputer
Programs Using Optimized Obfuscations. In Proceedings of the 9th International
Conference on Learning Representations (ICLR), Virtual Event, Austria.
[46]PatanamonThongtanunam,ShaneMcIntosh,AhmedE.Hassan,andHajimuIida.
2016. Revisiting Code Ownership and Its Relationship with Software Qualityin the Scope of Modern Code Review. In Proceedings of the 38th International
Conference on Software Engineering (ICSE), Austin, TX, USA. 1039–1050.
[47]FarhanUllah,JunfengWang,SohailJabbar,FadiAl-Turjman,andMamounAlazab.
2019. Source Code Authorship Attribution Using Hybrid Approach of Program
Dependence Graph and Deep Learning Model. IEEE Access 7 (2019), 141987–
141999.
1917
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:52:10 UTC from IEEE Xplore.  Restrictions apply. RoPGen: Towards Robust Code Authorship Attribution via Automatic Coding Style Transformation ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
[48]Wenqi Wang, Lina Wang, Run Wang, Zhibo Wang, and Aoshuang Ye. 2019.
TowardsaRobustDeepNeuralNetworkinTexts:ASurvey. CoRRabs/1902.07285
(2019).
[49]EricWong,LeslieRice,andJ.ZicoKolter.2020. FastisBetterthanFree:Revisiting
AdversarialTraining.In Proceedingsofthe8thInternationalConferenceonLearning
Representations (ICLR), Addis Ababa, Ethiopia.
[50]Taojiannan Yang, Sijie Zhu, and Chen Chen. 2020. GradAug: A New Regulariza-
tion Method for Deep Neural Networks. In Proceedings of Annual Conference on
Neural Information Processing Systems (NeurIPS), virtual.
[51]XinyuYang,GuoaiXu,QiLi,YanhuiGuo,andMiaoZhang.2017. Authorship
AttributionofSourceCodebyUsingBackPropagationNeuralNetworkBasedon Particle Swarm Optimization. PloS one12, 11 (2017), e0187204.
[52]NoamYefet,UriAlon,andEranYahav.2020. AdversarialExamplesforModels
of Code.Proc. ACM Program. Lang. 4, OOPSLA (2020), 162:1–162:30.
[53]HuangzhaoZhang,ZhuoLi,GeLi,LeiMa,YangLiu,andZhiJin.2020. Generating
AdversarialExamplesforHoldingRobustnessofSourceCodeProcessingModels.
InProceedings of the 34th AAAI Conference on Artificial Intelligence (AAAI), New
York, NY, USA. 1169–1176.
[54]Yuhao Zhang, Aws Albarghouthi, and Loris D’Antoni. 2020. Robustness to
Programmable String Transformations via Augmented Abstract Training. InProceedings of the 37th International Conference on Machine Learning (ICML),
Virtual Event. 11023–11032.
1918
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:52:10 UTC from IEEE Xplore.  Restrictions apply. 