NPEX: Repairing Java Null Pointer Exceptions without Tests
Junhee Lee
Korea University
Republic of Korea
junhee_lee@korea.ac.krSeongjoon Hongâˆ—
Korea University
Republic of Korea
seongjoon@korea.ac.krHakjoo Ohâ€ 
Korea University
Republic of Korea
hakjoo_oh@korea.ac.kr
ABSTRACT
We present NPEX, a new technique for repairing Java null pointer
exceptions (NPEs)without tests. State-of-the-artNPE repair tech-
niquesrelyontestsuiteswrittenbydevelopersforpatchvalidation.
Unfortunately,however,thosearetypicallyfuturetestcasesthatare
unavailable at the time bugs are reported or insufficient to identify
correct patches. Unlike existing techniques, NPEXdoes notrequire
test cases; instead, NPEX automatically infers the repair specifica-
tion of the buggy program and uses the inferred specification to
validatepatches.Thekeyideaistolearnastatisticalmodelthatpre-
dicts how developers would handle NPEs by mining null-handling
patterns from existingcodebases, and to usea variant of symbolic
execution that can infer the repair specification from the buggy
program using the model. We evaluated NPEX on real-world NPEs
collected from diverse open-source projects. The results show that
NPEX significantly outperforms the current state-of-the-art.
ACM Reference Format:
Junhee Lee, Seongjoon Hong, and Hakjoo Oh. 2022. NPEX: Repairing Java
Null Pointer Exceptions without Tests. In 44th International Conference on
Software Engineering (ICSE â€™22), May 21â€“29, 2022, Pittsburgh, PA, USA. ACM,
New York, NY, USA, 13 pages. https://doi.org/10.1145/3510003.3510186
1 INTRODUCTION
Null pointer exceptions (NPEs) are perhaps the most infamousbug in Java. NPEs represent a serious flaw of a program becausedereferencing a null pointer always causes the program to crash.Furthermore,NPEsarehighlyprevalentinreal-worldJavaappli-cations [
2,8,9,32,55,72]. For example, NPEs take up 37.2% and
40.2% of crashes in open-source projects [ 32] and Android appli-
cations [55], respectively, and recent studies show that NPEs are
the most prevailing uncaught exception in production environ-
ments [2,72]. Yet, fixing NPEs remains challenging because simply
avoidingcrashesisoftenincorrectandfindingacorrectfixoutofa
wide range of candidates is nontrivial.
âˆ—The first and second authors contributed equally to this work.
â€ Corresponding author
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Â© 2022 Association for Computing Machinery.
ACM ISBN 978-1-4503-9221-1/22/05...$15.00
https://doi.org/10.1145/3510003.3510186Generate-and-ValidateAPRApproaches .Overthelastdecade,
automated program repair (APR) techniques have shown promise
inaddressingthechallengeofbugfixing[ 21,24,29,37,38,43,53,
59,60,66,68]. Most existing APR techniques follow the conven-
tionalgenerate-and-validate approach, which alternates the two
phases:(1) patchgenerationand (2)patchvalidation.In thepatch
generation phase, a candidate patch is selected from a pre-defined
search space, and in the patch validation phase, the correctness of
thecandidatepatch ischeckedbyrunningthe patchedprogramon
asetoftestcases.Thisprocessisrepeateduntilaplausiblepatch
that passes all test cases is found.
VFix[67]isthecurrentstate-of-the-artforrepairingNPEs.Its
novel feature is to use value-flow information of programs to accu-
ratelylocalizesuspiciousstatementsandreducethesearchspaceof
candidatepatchesappropriatelyforNPEs.Thereducedpatchspace
improvestheefficiencyofthegenerate-and-validateprocessand
also increases the chances of finding correct patches. As a result,
VFix has been shown to outperform existing APR techniques such
asGenProg[ 59],ACS[66],CapGen[ 60],Nopol[ 68],SimFix[ 21],
and NPEfix [13] when evaluated for NPEs [67].
OurApproach .Inthispaper,wepresentanewapproach,called
NPEX,forrepairingNPEs.LikeexistingAPRtechniques,NPEXfol-
lowsthestandardgenerate-and-validateapproach.Thedifference,
though,isthatNPEXreplacesthetest-basedpatchvalidationphase
of the existing approach by a novel technique that can validate
patches without relying on test cases.
We avoid using test cases as a validation oracle for two reasons.
First, because test cases are typically unavailable at the time a bug
is reported [ 25], they cannot be effectively used by a repair tool
thataimstofixthebugassoonasitisdetected.Furthermore,using
a test suite as a repair specification is likely to produce incorrectpatches fitted only to the given tests [
28,54,69]. For example, as
wedemonstrateinthispaper,eventhe-state-of-the-artVFix,which
reduces incorrect patches using a customized patch space, often
fails to fix diverse NPEs due to overfitting.
WeusetwokeyideastovalidateNPEpatcheswithouttests.First,
we use a statistical model that predicts how developers would han-
dleNPEs.Tolearnsuchamodel,wecollectvariousnull-handling
patterns available in existing codebases. For example, from null-handling code
(x != null)? x.m() : 0 , we extract the knowl-
edgethattheexpectedreturnvalueof x.m()is0whenxisnull
and therefore an NPE occurs at x.m(). We then generalize this
patternusingprogram-independentfeaturesforexpressionsand
surrounding contexts. Second, we use the model to infer the ex-
pected behavior of a buggy program. To this end, we use a variant
ofsymbolicexecutionthatinterpretsNPE-triggeringexpressionsin
the buggy program using the modelâ€™s prediction. The result of this
symbolic execution is used as the repair specification of the buggy
15322022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:30:33 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Junhee Lee, Seongjoon Hong, and Hakjoo Oh
(a) Buggy program
1boolean compare(int row, Column<?> temp, Column<?> org) {
2Object o1 = org.get(row);
3Object o2 = temp.get(temp.size() - 1);
4returno1.equals(o2); // NPE
5}
(b) NPE-triggering input
intmissing = IntColumnType.missingValueIndicator();
Table t1 = Table.create("T1",
IntColumn.create("Id", 0, 0),
IntColumn.create("ChildId", missing, missing));
t1.dropDuplicateRows(); // compare is invoked inside
(c) NPEX-generated patch (= developerâ€™s patch)
(-)returno1.equals(o2);
(+)returno1 ==null?o 2= =null : o1.equals(o2);
Figure 1: An NPE bug (line 4) and developer patch
program; given a candidate patch during the generate-and-validate
process, we analyze the behavior of the patched program to check
if it satisfies the inferred specification.
The evaluation results show that our approach substantially
improvesuponthecurrentstate-of-the-art.Weimplementedour
approach as a tool, NPEX, using existing methods for fault localiza-
tionandpatchgeneration[ 13,67].Weused119NPEbugscollected
from prior work [ 36,41,67] as well as open-source projects, and
comparedtheperformanceof NPEXwithtwostate-of-the-arttech-niques,VFix[
67]andGenesis[ 36],forrepairingNPEs.Theresults
show that NPEX can correctly fix 51% of those bugs even without
test cases while Genesis and VFix fixed 22% and 42%, respectively,
with test cases.
Contributions. We summarize our contributions below:
â€¢WepresentanewtechniqueforvalidatingNPEpatcheswith-out test cases. The key idea is to infer the expected behavior
of a buggy program by combining statistical learning and
symbolic execution.
â€¢WepresentNPEX,anend-to-endpatchgenerationsystemfor
Java NPEs. NPEX is able to fix NPEs given a buggy program
and crashing input only.
â€¢Wedemonstratetheeffectiveness of NPEXincomparison
withcurrentstate-of-the-arts.Ourresultsarereproducible;
thesourcecodeof NPEXandthebenchmarksarepublicly
available.1
2 OVERVIEW
This section motivates and illustrates NPEX with examples.
2.1 Motivating Example
Figure1describesanNPEbug2foundinproject tablesaw .Method
compareinFigure 1(a)checksif twoobjectsassociated with temp
andorgareequivalent.TheNPEoccurswhendereferencing o1,i.e.,
1https://github.com/kupl/npex
2https://github.com/jtablesaw/tablesaw/commit/65596d81String m(Object obj, String valueIfNull) {
2// if (obj==null) return valueIfNull; // developer patch
3Class cls = obj.getClass(); // NPE
4String name = cls.getCanonName();
5if(name == null){return valueIfNull; }
6else{returnname; }
7}
Figure 2: A buggy program (simplified from Apache Com-mons Lang) and the developer patch (commented out).
1if(obj == null)
2return null;
3Class cls = ...;
4String name = ...;1if(obj == null)
2returnvalueIfNull;
3Class cls = ...;
4String name = ...;
P1(incorrect) P2(correct)
Figure 3: Candidate patches
o1.equals(o2) ,atline4,where o1isnullifelementsaremissing
atposition rowoforg.Inpractice,NPEsaretypicallyreportedwith
bug-triggeringinputonly;inthiscase,thebugreportwasgiven3
with the single NPE-triggering input shown in Figure 1(b).
Giventhebuggyprogram(Figure1(a))andNPE-triggeringinput
(Figure 1(b)), NPEX generates the patch in Figure 1(c), which is
exactly the same as the developerâ€™s patch. Note that producingthe correct patch is nontrivial because there are various ways of
avoiding the NPE. For example, all the following candidate patches
eliminatetheNPEwheninsertedrightbeforeline4,buttheirse-
mantics differs from that of the developer patch:
â€¢if (o1 == null) return false;
â€¢if (o1 == null) return true;
â€¢if (o1 == null) o1 = new Object();
Toexcludetheseincorrectpatches,NPEXautomaticallyinfers
the expected specification of the buggy program and validates
candidatepatchesagainst it.Inthiscase, NPEXinfersthatâ€œwhen
o1isnull,compare should return true if o2isnulland false
otherwiseâ€. None of the incorrect patches satisfy this specification
and are therefore rejected by NPEX.
Existing test-based techniques, e.g., VFix [ 67] and Genesis [ 36],
do not work well when the test suite only includes the crashinginput. VFix would generate the first incorrect patch,
if(o1 ==
null) return false ,sinceitsrankingheuristicprioritizespatches
that skip statements containing NPEs and return default values.Genesisgeneratedapatchthatimplementsalogictoremoveall
Columns with a missing value, which is obviously incorrect.
2.2 How NPEX Works
The distinctive feature of NPEX is in the patch validation phase.
We explain how NPEX validates patches with the buggy program
in Figure 2, where method invocation obj.getClass() at line 3
3https://github.com/jtablesaw/tablesaw/issues/798
1533
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:30:33 UTC from IEEE Xplore.  Restrictions apply. NPEX: Repairing Java Null Pointer Exceptions without Tests ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
raisesanNPEwhenvariable objisnotinitialized.Themethod m
is supposed to return the canonical name of the objâ€™s class. When
objoritscanonicalname( name)isnull, however, misexpectedto
return the default value (valueIfNull).
Assume that we are given the variable objat line 3 as the fault
expression.Assumefurther thattwocandidate patches, P1andP2,
in Figure 3 are generated during the repair process. While both
patchessucceedtoeliminatethegivenNPE, P1isincorrectbecause
it returns null, instead of valueIfNull , whenobjisnull, which
violates the intended behavior of the method. The goal of NPEX is
to invalidate ğ‘ƒ1while validating the correctness of ğ‘ƒ2.
LearningaNull-HandlingModel .NPEXusesastatisticalnull-
handling model to validate patches, which is learned from existing
codebases and used to repair new, unseen buggy programs. The
null-handling model, denoted M, predicts how developers would
handle an NPE by inferring an alternative expression to replace
the NPE-triggering expression. For example, it infers that, when
objisnull,theentireNPE-triggeringexpression obj.getClass()
at line 3 should be interpreted as if it were the expression null.
Also,when clsisnull,themodelinfersthattheNPE-triggering
expression cls.getCanonName() atline4shouldbeinterpretedas
null.Insummary,wheninstantiatedfortheexampleprogramin
Figure 2, the model Mcan be treated as the following function:
M=/braceleftbiggnull.getClass() â†¦â†’null
null.getCanonName() â†¦â†’null/bracerightbigg
.(1)
NPEX learns such a model by mining various null-handling
patterns available incodebases. The intuition is that existingnull-
handlingpatternswrittenbydevelopersaregoodreferencesforhan-dlingNPEs(andinferringalternativeexpressions).Forinstance,con-siderthenull-handlingcodesnippetavailableinproject
rapidoid4:
(args[i] != null) ? args[i].getClass() : null
from which we find that expression nullcan be alternatively used
for the NPE-triggering expression, args[i].getClass() , when
args[i] isnull. Generalizing this, we learn the first replacement
null.getClass() â†¦â†’null (2)
ofthemodel Min(1).Thecodebasemayhavedifferentpatterns
forthesamemethod getClass .Forexample,thefollowingpattern
is also available in rapidoid:
obj != null ? obj.getClass() : Object.class
from which we infer the following:
null.getClass() â†¦â†’Object.class .
When applying the model, we resolve the conflict by choosing
themostappropriateonebasedonthesurroundingcodecontext
(Section3.1);forourexample,weassumedthepatternin(2)was
chosen.Theknowledgeforhandling getCanonName canbeinferred
from the following code snippet in project dozer5:
destCls != null ? destCls.getCanonName() : null
from which we obtain the second replacement in (1).
4https://github.com/rapidoid/rapidoid
5https://github.com/DozerMapper/dozerSpecification Inference .Once a model is learned, we can use
it to infer the expected behavior of a buggy program. To do so,
we run a variant of symbolic execution on the buggy program
that interprets NPE-triggering expressions using the null-handling
model. The result of this symbolic execution will be used as the
repair specification against which we validate candidate patches.
Consider the buggy method min Figure 2. Our symbolic exe-
cution beginswith the initial state (ğœ‹init,ğœinit), whereğœ‹initis the
initial path condition, i.e., ğœ‹init=âˆ…, andğœinitis the initial symbolic
store, i.e., ğœinit=[objâ†¦â†’ğ›¼,valueIfNull â†¦â†’ğ›½], that maps formal
parameters to fresh symbols ğ›¼andğ›½.
Atline3,weencounterthemethodinvocation, obj.getClass() ,
whosebasevariable objisthefaultexpressionthatcausestheNPE.
The key difference between normal symbolic execution and our
variant is that we interpret such an NPE-triggering expression
(obj.getClass() ) using the alternative expression inferred by the
null-handlingmodel.Forexample,themodelin(1)infers nullas
thealternativeexpressionfor obj.getClass() whenobjisnull.
Thus, our symbolic execution produces the following two states as
output of line 3:
ğ‘ 1=(ğœ‹1,ğœ1)=(ğ›¼=null,ğœinit[clsâ†¦â†’null])
ğ‘ 2=(ğœ‹2,ğœ2)=(ğ›¼â‰ null,ğœinit[clsâ†¦â†’f(ğ›¼)])
States1represents the output of the NPE-triggering execution
whereobjisnull(denoted by path condition ğ›¼=null). In this
case, store ğœ1is obtained using the null-handling model as follows:
ğœ1=ğœinit[clsâ†¦â†’M(null.getClass())] =ğœinit[clsâ†¦â†’null]
where we inferred the expected meaning of the method invocation
usingM. States2represents the normal execution where no NPE
occurs. We use an uninterpreted function symbol to represent the
return value of the external method; f(ğ›¼)denotes the symbolic
value that obj.getClass() evaluates to.
Withs1ands2asinputstates,symbolicexecutionofline4results
in the following output states:
s3=(ğœ‹3,ğœ3)=(ğ›¼=null,ğœ1[nameâ†¦â†’null])
s4=(ğœ‹4,ğœ4)=(ğ›¼â‰ null,ğœ2[nameâ†¦â†’g(f(ğ›¼))])
Notethattheexecutionwith s1encountersanewNPEbecause cls
holdsnullins1andmethod getCanonName iscalledonit.Thus,we
usethenull-handlingmodelagaintoinfertheexpectedbehavior
ofnull.getCanonName and obatin store ğœ3as follows:
ğœ3=ğœ1[nameâ†¦â†’M(null.getCannonName)] =ğœ1[nameâ†¦â†’null].
States4istheresultofexecutingline4withinputstate s2,where
g(f(ğ›¼))is the symbolic value representing cls.getCanonName().
Wecompletesymbolicexecutionbyanalyzingtheifstatementat
line 5 with states s3ands4as input, which produces the following
three states as output:
s5=(ğ›¼=null,ğœ3[retâ†¦â†’ğ›½])
s6=(ğ›¼â‰ nullâˆ§g(f(ğ›¼))=null,ğœ4[retâ†¦â†’ğ›½])
s7=(ğ›¼â‰ nullâˆ§g(f(ğ›¼))â‰ null,ğœ4[retâ†¦â†’g(f(ğ›¼))])
Theinputstate s3resultsin s5takingonlythetruebranchasthe
valueofnameisnullins3.Withs4,weconsiderbothtrueandfalse
branches,producing s6ands7,respectively.Finally,weobtainthe
1534
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:30:33 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Junhee Lee, Seongjoon Hong, and Hakjoo Oh
symbolic summary ğ‘†mof method mby removing information about
local variables in those states:
ğ‘†m=â§âªâª â¨
âªâªâ©(ğ›¼=null,ğœinit[retâ†¦â†’ğ›½]),
(ğ›¼â‰ nullâˆ§g(f(ğ›¼))=null,ğœinit[retâ†¦â†’ğ›½]),
(ğ›¼â‰ nullâˆ§g(f(ğ›¼))â‰ null,ğœinit[retâ†¦â†’g(f(ğ›¼))])â«âªâª â¬
âªâªâ­
Weconsiderthesymbolicsummary ğ‘†mastherepairspecificationof
thebuggymethod m.Thatis,ourrepairspecificationisthesummary
of theinstrumented semanticsof the buggymethod mwhere each
NPE-triggering expression is replaced by an alternative expression
using the null-handling model.
Patch Validation .Now we validate candidate patches against
theinferredspecification ğ‘†m.Weconcludethatacandidatepatch
iscorrectiffrunninganormalsymbolicexecutiononitproduces
asummaryequivalentto ğ‘†m.Forexample,thesummary ğ‘†1ofthe
incorrect patch ğ‘ƒ1in Figure 3 is computed as follows:
ğ‘†1=â§âªâª â¨
âªâªâ©(ğ›¼=null,ğœinit[retâ†¦â†’null])
(ğ›¼â‰ nullâˆ§g(f(ğ›¼))=null,ğœinit[retâ†¦â†’ğ›½]),
(ğ›¼â‰ nullâˆ§g(f(ğ›¼))â‰ null,ğœinit[retâ†¦â†’g(f(ğ›¼))])â«âªâª â¬
âªâªâ­
Note that ğ‘†1andğ‘†mdo not agree with the return value, (ret ) when
ğ›¼isnull, i.e.,ğœinit[retâ†¦â†’null]â‰ ğœinit[retâ†¦â†’ğ›½], concluding that
patchğ‘ƒ1does not satisfy the repair specification. By contrast, sym-
bolicexecutionofthecorrectpatch P2producesasummaryexactly
equivalentto ğ‘†ğ‘š.Wecanchecktheequivalenceofsummariesusing
an off-the-shelf SMT solver.
3 OUR PATCH VALIDATION TECHNIQUE
Inthissection,wedescribehowNPEXvalidatespatchesindetail.
Ourapproachconsistsoftwophases:(1)learninganullhandling
model(Section3.1)fromacodebase,and(2)validatingcandidate
patches using the model (Section 3.2).
Programs .A Java program ğ‘ƒâˆˆPgmis a sequence of class dec-
larations,whereaclassdeclarationisapairofaclassnameanda
sequence of method declarations. A method declaration consistsofareturntype,amethodname,aformalparameter,andabody
statement.Wewrite ğ‘ğ‘šandbody(ğ‘š)fortheparameterandbody
statement of method ğ‘š, respectively. A type ğ‘‡is either a primi-
tive type (we only consider intfor simplicity) or a reference type
for custom classes ( ğ¶). We consider the usual statements ( ğ‘†) and
expressions ( ğ¸) in Java:
ğ‘†â†’ğ‘¥=ğ‘’|returnğ‘’|ifğ¸ğ‘†1ğ‘†2|whileğ¸ğ‘†|ğ‘†1;ğ‘†2|ğœ–
ğ¸â†’ğ‘›|null|ğ‘¥|ğ‘¥.ğ‘š(ğ‘¦)|newğ¶() |ğ¸1?ğ¸2:ğ¸3|ğ¸1==ğ¸2
We do not consider field access ( ğ‘¥.ğ‘¦) because it is very rare to
directly access public fields in real-world Java programs; fields are
typicallyaccessedviagettermethodsthatourlanguagesupports.
Weassumetheprogramisstaticallytypedandwrite type(ğ‘’)forthe
typeofexpression ğ‘’.Weassumethatmethodnamesareunique.The
bodyofa whilestatementmayincludecontrolstatements breakor
continue . A variable is either a local or this. We write ğ¸NPEfor
thesetofexpressionswhereNPEsmayoccur;inourlanguage, ğ¸NPE
represents the set of method invocations, i.e., ğ‘¥.ğ‘š(ğ‘¦), where NPEs
occur when ğ‘¥is a null pointer.3.1 Learning a Null-Handling Model
The goal of the learning phase is to learn a null-handling model
MâˆˆPgmÃ—ğ¸NPEâ†’ğ¸
fromadatasetofprograms.Givenaprogram ğ‘ƒâˆˆPgmanditsNPE-
triggeringexpression ğ‘’NPEâˆˆğ¸NPE,Mğ‘ƒ(ğ‘’NPE)predictsanalternative
expression that can be used as a substitute for ğ‘’NPEto correctly
handle the NPE. We construct the model in the following steps.
CollectingNull-HandlingPatterns .Thefirststepistocollect
a dataset Dof null-handling patterns from a codebase. Let P=
{ğ‘ƒ1,ğ‘ƒ2,...,ğ‘ƒğ‘š}beacollectionofprograms.Thedataset Disofthe
type DâŠ†PgmÃ—ğ¸NPEÃ—ğ¸. That is, Dis a set of tuples (ğ‘ƒ,ğ‘’NPE,ğ‘’)
whereğ‘ƒâˆˆPisaprograminthecodebase, ğ‘’NPEisanNPEexpression
inğ‘ƒ, andğ‘’is an expression that is alternatively used in ğ‘ƒwhen
ğ‘’NPEcauses an NPE.
To collect thedataset D, we traversethe abstract syntax tree of
each program ğ‘ƒâˆˆPand observe how NPEs are handled. For exam-
ple,fromternaryexpressionoftheform ğ‘¥==null?ğ‘’:ğ‘¥.ğ‘š(ğ‘¦),
we collect tuple (ğ‘ƒ,ğ‘¥.ğ‘š(ğ‘¦),ğ‘’), meaning that, when ğ‘¥is a null
pointer and hence an NPE occurs at expression ğ‘¥.ğ‘š(ğ‘¦),w ec a n
alternativelyuseexpression ğ‘’insteadof ğ‘¥.ğ‘š(ğ‘¦).Whencollecting
null-handling patterns, we mainly consider such ternary expres-
sionsastheNPE-triggeringexpression( ğ‘¥.ğ‘š(ğ‘¦))andthecorrespond-
ing alternative expression ( ğ‘’) are clearly identifiable. Note that
other several null-handling patterns can be translated to ternary
expressions. For example, boolean expression ğ‘¥==null||ğ‘¥.ğ‘š(ğ‘¦)
istranslatedinto ğ‘¥==null?true:ğ‘¥.ğ‘š(ğ‘¦)andrepresentedby
tuple(ğ‘ƒ,ğ‘¥.ğ‘š(ğ‘¦),true).
Generalization .Once we collect null-handling patterns, we
generalizethembyabstractingalternativeexpressions.Themain
purposeofthisstepistodiscardprogram-dependentinformation
such as local variable and user-defined class names. We also make
thedatasetmoreamenabletolearningbyconsideringafinitesubset
of alternative expressions. The output of this step is the following:
/hatwideDâŠ†PgmÃ—ğ¸NPEÃ—/hatwideğ¸
where /hatwideğ¸denotes abstract expressions defined as follows:
/hatwideğ¸=NDâˆª{null,ARG,NEW}âˆª{ARG==/hatwideğ‘’|/hatwideğ‘’âˆˆNDâˆª{null}}âˆª{/latticetop}
Here,NDdenotes a finite set of integers that frequently appear in
the dataset D. NPEX uses ND={âˆ’1,0,1}because they were the
top-3 most popular integers in D. We do not distinguish names
ofmethodargumentsandrepresentthembyanabstractelement,
denotedARG.Anewexpression( newğ¶())isabstractedto NEWwhere
its type information ( ğ¶) is discarded. An equality test ( ğ¸1==ğ¸2)i s
abstractedinto ARG==/hatwideğ‘’whenğ¸1isanargumentvariableand ğ¸2
isgeneralizedtoaliteralin NDâˆª{null}.Wediscardothercases
andsimplyrepresentthemby /latticetop.Specifically,wedefinefunction
ğ›¼âˆˆğ¸NPEÃ—ğ¸â†’/hatwideğ¸for generalization as follows:
ğ›¼(ğ‘’NPE,ğ‘’)=
â§âªâªâªâªâªâª â¨
âªâªâªâªâªâªâ©ğ‘’ Â·Â·Â·ğ‘’âˆˆN
Dâˆª{null}
NEW Â·Â·Â·ğ‘’=newğ¶()
ARG Â·Â·Â·ğ‘’NPE=ğ‘¥.ğ‘š(ğ‘¦)âˆ§ğ‘’=ğ‘¦
ARG==ğ‘›Â·Â·Â·ğ‘’NPE=ğ‘¥.ğ‘š(ğ‘¦)âˆ§ğ‘’=(ğ‘¦==ğ‘›)âˆ§ğ‘›âˆˆNDâˆª{null}
/latticetop Â·Â·Â· otherwise
1535
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:30:33 UTC from IEEE Xplore.  Restrictions apply. NPEX: Repairing Java Null Pointer Exceptions without Tests ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Withğ›¼, the generalized dataset /hatwideDis obtained as follows:
/hatwideD={(ğ‘ƒ,ğ‘’NPE,ğ›¼(ğ‘’NPE,ğ‘’) )|(ğ‘ƒ,ğ‘’NPE,ğ‘’)âˆˆD}.
Feature Representation .Next,werepresentNPEexpressions
as feature vectors to generate the training data D:
DâŠ†{0,1}ğ‘›Ã—/hatwideğ¸.
To do so, we assume ğ‘›boolean features: Î¦={ğœ™1,ğœ™2,...,ğœ™ğ‘›},
where each feature ğœ™ğ‘–:PgmÃ—ğ¸NPEâ†’{0,1}is a predicate on
program and NPE expression pairs and describes characteristics
of an NPE expression and its surrounding code context. For in-
stance, a feature may describe whether an NPE expression belongs
to atry/catch block. We write Î¦(ğ‘ƒ,ğ‘’NPE)for the feature vector
of(ğ‘ƒ,ğ‘’NPE):Î¦(ğ‘ƒ,ğ‘’NPE)=/angbracketleftğœ™1(ğ‘ƒ,ğ‘’NPE),ğœ™2(ğ‘ƒ,ğ‘’NPE),...,ğœ™ğ‘›(ğ‘ƒ,ğ‘’NPE)/angbracketright.
With Î¦, we can generate the training data Das follows:
D={(Î¦(ğ‘ƒ,ğ‘’NPE),/hatwideğ‘’)|(ğ‘ƒ,ğ‘’NPE,/hatwideğ‘’)âˆˆ/hatwideD}.
Weuse31featuresinTable1.Here,eachfeatureisapredicate
onmethodcalls, ğ‘¥.ğ‘š(ğ‘¦),sinceğ¸NPEdenotesthesetofmethodinvo-
cations in our language. The features are divided into three classes:method name features, method body features, and context features.
The method name features describe which keywords appear in the
name (ğ‘“) ofthe called method.Weused 20 keywords asthe name
features. To select these keywords, we collected all the method
namesfromourcodebase,splitthemintokeywordsbythecamel
case,andrankedthetop20bytheirfrequency.ThemethodbodyfeaturescheckwhetherabodystatementcontainsaspecificAST
component.Wedesignedthosetwoclassesoffeaturestoidentify
what kind of methods is invoked. For example, features #8 and
#27 are strong indicators for getter methods. Thecontext features
capture the syntactic code contexts around an NPE expression.
TrainingaModel .From the training data D, we train a proba-
bilistic multi-label classifier to learn a probability distribution over
/hatwideğ¸for a given feature vector.Let Prbe the learned probabilitydistri-
bution; given a program ğ‘ƒ, an NPE expression ğ‘’NPE, and abstract
expression /hatwideğ‘’âˆˆ/hatwideğ¸,Pr(/hatwideğ‘’|Î¦(ğ‘ƒ,ğ‘’NPE))denotestheprobabilityofthe
alternative expression of ğ‘’NPEbeing /hatwideğ‘’. We computed Prusing an
off-the-shelf learning algorithm for Random Forest Classifier.
Wecanconstructthenull-handlingmodel MfromPr,withan
additional process that concretizes an abstract expression into a
type-compatible concrete expression. We define ğ›¾:ğ¸NPEÃ—/hatwideğ¸â†’
ğ¸âˆª{âŠ¥}for concretization, which converts an abstract expression
into a concrete expression as follows:
ğ›¾(ğ‘¥.ğ‘š(ğ‘¦),/hatwideğ‘’)=â§âªâªâªâªâªâªâªâª â¨
âªâªâªâªâªâªâªâªâ©ğ‘› Â·Â·Â·/hatwideğ‘’=ğ‘›âˆ§ğ‘‡=int
null Â·Â·Â·/hatwideğ‘’=nullâˆ§ğ‘‡â‰ int
newğ¶() Â·Â·Â· /hatwideğ‘’=NEWâˆ§ğ‘‡=ğ¶
ğ‘¦ Â·Â·Â·/hatwideğ‘’=ARGâˆ§type(ğ‘¦)=ğ‘‡
ğ‘¦==ğ‘’Â·Â·Â·/hatwideğ‘’=ARG==ğ‘’âˆ§ğ‘‡=int
âŠ¥ Â·Â·Â· otherwise
whereğ‘‡denotes the type of expression ğ‘¥.ğ‘š(ğ‘¦). Withğ›¾, our null-
handling model M:PgmÃ—ğ¸NPEâ†’ğ¸is defined as follows:
Mğ‘ƒ(ğ‘’NPE)=ğ›¾(ğ‘’NPE,argmax
/hatwideğ‘’âˆˆCPr(/hatwideğ‘’|Î¦(ğ‘ƒ,ğ‘’NPE)))
whereC={/hatwideğ‘’âˆˆ/hatwideğ¸|ğ›¾(ğ‘’NPE,/hatwideğ‘’)â‰ âŠ¥}is the set of concretizable
expressions and we pick one with the highest probability.Table 1: Features for method invocations
Class #Description
Name
Features1
-
201."Code", 2."hash", 3."append", 4."equals", 5."on",
6."Error", 7."Success", 8."get", 9."set", 10."is",
11."add". 12."close", 13."Empty", 14."Value",
15."put" 16."String", 17."to", 18."remove",
19."write", 20."contains"
Body
Features21return type is void
22method returns a literal
23thrown exceptions are annotated
24null check expression exists
25method returns a constructor call
26method is the base of another invocation
27method returns a field
Context
Features28caller method is private
29null pointer is assigned to an array
30null pointer is assigned to a field
31null pointer is assigned to a public field
3.2 Validating Patches using the Model
Next we use the model to validate the correctness of a candidatepatch. To this end, we first infer the correctness specification ofa buggy program using the learnt null-handling model and then
check if the patch candidate satisfies the inferred specification.
Specification Inference .We use the null-handling model to
infer the correct behavior of a buggy program. Suppose a buggyprogram
ğ‘ƒNPEâˆˆPgmisgivenandthebuggy(NPE-triggering)ex-
pressionin ğ‘ƒNPEisğ‘¥NPE.ğ‘š(ğ‘¦),whereğ‘¥NPEisthefaultvariablewhose
valueisnullalongthebuggytrace.Forsimplicity,weassumethere
isonlyasingleNPEinthebuggyprogram.Supposealsothatanull-handlingmodel
Mlearnedfromanexistingcodebaseisgiven.The
goal of specification inference is then to infer the desired behavior
of the buggy program when the NPE is correctly fixed.
We infer the correctness specification by running a variant of
symbolicexecutiononthebuggyprogramandinterpretingtheNPE-
triggering expression ( ğ‘¥NPE.ğ‘š(ğ‘¦)) using the null-handling model.
To this end, we first define a normal symbolic execution procedure
and explain how to extend it to use the null-handling model.
Weconsidertheoutputofsymbolicexecutionasthespecification
of the input program. The output of our symbolic execution is a
tableÎ£from methods to summaries:
Î£âˆˆSumTable =Methodâ†’Summary
where a summary is defined as follows:
ğ‘†âˆˆSummary =P(State)
sâˆˆState =PCÃ—Store
ğœ‹âˆˆPC=P(SymValÃ—{=,â‰ }Ã—SymVal)
ğœâˆˆStore =Varâ†’SymVal
ğ‘£âˆˆSymVal =Z+Class+{null}+Symbol
Asummary(Summary )isasetofprogramstates( State)andastate
consistsofapathcondition( PC)andastore(Store ).Apathcondition
isacollectionofbranchconditions,whereabranchconditionisan
equalityofsymbolicvaluesoritsnegation.Astoreisamapfrom
1536
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:30:33 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Junhee Lee, Seongjoon Hong, and Hakjoo Oh
variablestosymbolicvalues.Symbolicvaluesincludeintegers,class
types,null, and symbols representing method parameters.
For scalability, we have designed our symbolic execution, de-
notedSymExec :Pgmâ†’SumTable , to be compositional and
bounded [ 11]. It analyzes each method of a program only once
by calculating its summary in isolation using summaries of callee
methods.Loopsandrecursivecallcyclesareunrolledfinitetimes
priortotheanalysis.Forpresentationsimplicity,weassumethat
methodnamesareunique(i.e.,nomethodoverridingandoverload-
ing) and ternary expressions are converted to ifstatements. With
these assumptions, it is enough to define symbolic execution for
the following subset of statements and expressions:
ğ‘†â†’ğ‘¥:=ğ‘’|returnğ‘¥|if(ğ‘¥==ğ‘¦)ğ‘†1ğ‘†2|ğ‘†1;ğ‘†2
ğ¸â†’ğ‘›|null|ğ‘¥|ğ‘¥.ğ‘“(ğ‘¦)|newğ¶()
Theprocedure SymExec isdefinedasfollows,whichcomputes
method summaries in a bottom-up manner:
SymExec(P)=[miâ†¦â†’F(body(mi),Î£i,si
init)]n
i=1
whereğ‘š1,...,ğ‘šğ‘›are a sequence of methods sorted according to
the reverse topological order of the call-graph, Î£ğ‘–is the partial
summary table for methods ğ‘š1,...,ğ‘šğ‘–âˆ’1, and the initial state sğ‘–
init
is defined by (âˆ…,[ğ‘ğ‘šğ‘–â†¦â†’ğ›¼ğ‘šğ‘–])which indicates that the formal
parameter ğ‘ğ‘šğ‘–of method ğ‘šğ‘–is bound to a fresh symbolic value
ğ›¼ğ‘šğ‘–.Thesemanticfunction F:StmtÃ—SumTable Ã—Stateâ†’P(State)
is defined in a standard manner as follows:
F(x:=n,Î£,(ğœ‹,ğœ))={(ğœ‹,ğœ[xâ†¦â†’n])}
F(x:=null,Î£,(ğœ‹,ğœ))={(ğœ‹,ğœ[xâ†¦â†’null])}
F(x:=y,Î£,(ğœ‹,ğœ))={(ğœ‹,ğœ[xâ†¦â†’ğœ(y)])}
F(x:=newC(),Î£,(ğœ‹,ğœ))={(ğœ‹,ğœ[xâ†¦â†’C])}
F(x:=y.m(z),Î£,(ğœ‹,ğœ))={(ğœ‹âˆªğœ‹im,ğœ[xâ†¦â†’ğœim(retm]))}i
F(S1;S2,Î£,s)=/uniontext.1{F(S2,Î£,s/prime)|s/primeâˆˆF(S1,Î£,s)}
F(if(x==y)S1S2,Î£,(ğœ‹,ğœ))=F(S1,Î£,s1)âˆªF(S2,Î£,s2)
whereğ‘ 1,ğ‘ 2=(ğœ‹âˆª{ğœ(ğ‘¥)=ğœ(ğ‘¦)},ğœ),(ğœ‹âˆª{ğœ(ğ‘¥)â‰ ğœ(ğ‘¦)},ğœ)and
(ğœ‹ğ‘–ğ‘š,ğœğ‘–ğ‘š)âˆˆÎ£(ğ‘š)[ğ›¼ğ‘šâ†¦â†’ğœ(ğ‘§)].
Now we describe how we infer the repair specification of a
buggy program ğ‘ƒNPE. We do so by analyzing ğ‘ƒNPEwith a variant of
symbolic execution, denoted SymExecxNPE
M, whereğ‘¥NPErefers to the
localizedfaultvariablethatcausestheNPEweaimetofixand Mis
the null-handling model. The overall procedure remains the same:
SymExecxNPE
M(P)=[miâ†¦â†’FxNPE
M(body(mi),Î£i,si
init)]ni=1.
The extended semantic function FxNPE
M(S,Î£,(ğœ‹,ğœ))is defined in the
same way as Fexcept for the following two cases. The first case is
whenğ‘†isanNPE-triggeringstatement,i.e., ğ‘¥:=ğ‘¦.ğ‘š(ğ‘§),whereğ‘¦
is the fault variable ğ‘¥NPE. In this case, FxNPE
M(S,Î£,(ğœ‹,ğœ))produces
F(S,Î£,(ğœ‹nonnull,ğœ))âˆªF(x:=MP(y.m(z)),Î£,(ğœ‹NPE,ğœ))
whereğœ‹nonnull=ğœ‹âˆª{ğœ(ğ‘¥NPE)â‰ null}andğœ‹NPE=ğœ‹âˆª{ğœ(ğ‘¥NPE)==
null}.Theformerdescribesstateswherethefaultvariableisnot
null, hence they normally execute the invocation. The latter de-
scribes states where the fault variable is null. In this case, we
interpret the NPE-triggering expression using the output of the
modelM. The second case is when ğ‘†isğ‘¥:=ğ‘¦.ğ‘š(ğ‘§)and the
basevariable yisnotthefaultvariablebutevaluatesto null,i.e.,
(ğœ(ğ‘¦)==null)âˆˆ ğœ‹. This happens when the prediction of themodel in the former case returns null, i.e.,Mğ‘ƒNPE(ğ‘¦.ğ‘š(ğ‘§))=null.
IfanewNPEisintroducedbythemodel,weapplythemodelagain:
FxNPE
M(S,Î£,(ğœ‹,ğœ))=F(x:=MPNPE(y.m(z)),Î£,(ğœ‹,ğœ)).
Example 3.1. Note that we infer procedural summaries not only
for the faulty method, but also for its callers. Let us consider the
followingcodethatusesnullpointersacrossprocedureboundaries.
1A foo(p) { returnp.hoo(0); // NPE }
2intgoo(z) {
3Ax=this.foo(z);
4returnx.goo(); }
SupposethatNPEoccursatline1because pisnullandthealterna-
tiveexpressioninferredbythemodelis nullfortheNPE-triggering
expression p.hoo(0) . Then, the inferred procedural summary of
foois{(ğ›¼foo=null,[retfooâ†¦â†’null])}, whereğ›¼fooandretfoo
denote the symbolic parameter and return variable, respectively.
Then, the return value nullpropagates to callerâ€™s variable x.S o
the model Mis applied again at line 4, and we get the summary
ofgooas{(ğ›¼goo=null,[retgooâ†¦â†’v])}where we assume ğ‘£is the
alternative value for x.goo() obtained by the model M.
Specification Validation .The next step is to validate candi-
date patches against the inferred specification. Let ğ‘ƒNPEbe a buggy
programand ğ‘ƒcandbeapatchcandidate.Wewouldliketodetermine
whetherğ‘ƒcandis a correct patch of ğ‘ƒNPE. We do this by checking
the equivalence: SymExecxNPE
M(PNPE)â‰¡SymExec(Pcand), wherethe
left-handsidedenotestheinferredrepairspecificationofthebuggyprogram.Wesaythattwosummarytables
Î£1andÎ£2areequivalent,
denoted Î£1â‰¡Î£2, if the following holds for all methods ğ‘š:
/logicalanddisplay.1
(ğœ‹1,ğœ1)âˆˆÎ£1(ğ‘š)/logicalanddisplay.1
(ğœ‹2,ğœ2)âˆˆÎ£2(ğ‘š)ğœ‹1âˆ§ğœ‹2=â‡’ğœ1=ğœ2
whereweassumethesymbolicvaluefortheformalparameterof
methodğ‘šis consistently named (e.g., ğ›¼ğ‘š). Intuitively, the formula
checksifalloutputstatesareequalintheinferredspecificationand
the summary of the candidate patch.
Note that we check the equivalence not only for the patched
method but also for its callers. A patch could implement correct
semanticsforthepatchedmethod,butincorrectsemanticsforits
callers. For example, consider the program in Example 3.1. A patch
that modifies p.hoo(0) top == null ? null : p.hoo() is
correct for method foo, but it introduces a new NPE in goo. In this
case,wecansuccessfullyrejectthispatchbycheckingthesemantic
equivalence for gooas well.
4 NPEX
NPEXisanend-to-endrepairtoolbasedonourideainSection3.
In this section, we describe other details of NPEX.
Implementation .We implemented NPEX in 4,200 lines of Java
and7,400linesofOCamlcodes.OurfaultlocalizationalgorithmandsymbolicexecutionareimplementedontopoftheInfer[
20]frame-
work.Wealsoused theSpoon[ 49]librarytoparseJava programs
and transform source codes.
Overall Algorithm .Algorithm 1 describes the overall algo-
rithmof NPEX.Givenabuggyprogram ğ‘ƒNPE,anNPEstacktrace
1537
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:30:33 UTC from IEEE Xplore.  Restrictions apply. NPEX: Repairing Java Null Pointer Exceptions without Tests ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
(ğ‘¥NPE,ğœ), and a null-handling model Mas input, the algorithm pro-
ducesasetofvalidatedpatchestofixthebug.Atline1,itfirstruns
thebuggyprogramwiththecrashinginputtogetthefaultvariable
ğ‘¥NPEandstacktrace ğœ.Atline2,thebuggyprogram ğ‘ƒNPEisanalyzed
by our variant of symbolic execution, SymExecxNPE
M, which returns
therepairspecification, Î£inferred,ofthebuggyprogram.Atline3,
we compute a set ğ‘‹of candidate faults. We iterate each candidate
faultğ‘¥/prime
NPEinğ‘‹, and accumulate validated patches in Patches.A t
line 6, we enumerate patches with given fault ğ‘¥/prime
NPE, and for each
patchğ‘ƒpatched,wecomputeitssummarytable Î£patchedbynormal
symbolicexecution.Ifthesummarytableof ğ‘ƒpatchedisequivalent
to the inferred specification Î£inferred, we add it to Patches.
FaultLocalization .Ourfaultlocalizationissimilartothatof
VFix[67]inthatittracksthedataflowofagivennullpointer.Given
thefaultexpression ğ‘¥NPEandstacktrace ğœonly,FaultLocalization
computesasetofnullpointerexpressionsthatmaybealiasto ğ‘¥NPE
foreachmethodinthestacktrace ğœ.Wedonotrankeachfaultand
returns the set of all the computed faults, as we validate patchesbyinferredspecificationsrather thanrelyingona patchranking
heuristic.Weimplementedalight-weightpointeranalysisontop
of Infer to compute alias information.
PatchEnumeration .Giventhelocalizedfaultexpression ğ‘¥NPE,
PatchEnumeration enumerates patches based on pre-defined tem-
plates. We used the following templates from prior work [13, 67]:
â€¢SKIP: (i)if(ğ‘¥NPE!=null)ğ‘†, or (ii)if(ğ‘¥NPE==null)fb
â€¢REPLACE: ğ‘¥NPE== null? ğ‘’:ğ‘’NPE
â€¢INIT:if(ğ‘¥NPE==null)ğ‘¥NPE=ğ‘’
SKIPskips a statement or a block ( ğ‘†) containing an NPE (SKIP-
(i)),orinsertsacontrolflowbreak(fb ):break,continue ,return
ğ‘’,o rthrowğ¸ğ‘¥ğ‘›(SKIP-(ii)). REPLACE substitutes an expression
involving the fault expression ( ğ‘’NPE) with a ternary with an al-
ternative expression ( ğ‘’).INITinitializes a null pointer to a fresh
object obtained by calling a constructor ( ğ‘’). For expressions ( ğ‘’),
weusedfrequentexpressionsinnull-handlingpatternscollected
from our training database. We collected the top-3 frequent ex-
pressions for each of primitive types and common class types (e.g.,
java.util.ArrayList ). We synthesize exceptions ( ğ¸ğ‘¥ğ‘›)f r o me x -
ceptions thrown around the fault expression within its class. We
implemented PatchEnumeration using the Spoon libraryâ€™s source
code transformation.
Scalable Symbolic Execution .We implemented symbolic ex-
ecutionontopoftheInferâ€™sbottom-upanalysisframework.We
tookadvantageofthebottom-upanalysistoanalyzeonlythepartsofprogramsrelatedtoeachpatchinthevalidationphase.Althoughtheanalysisisbottom-up,itwasnontrivialtoimplementascalable
symbolic executor that works for real-world applications while
supportingthefullJavalanguageincludingdynamicdispatch,ex-
ception handling, field accesses, etc., Thus, we designed a pathmerging heuristic to further accelerate the analysis; we only dis-
tinguished error states where an NPE occurs while merging other
NPE-irrelevant states. We treated results of an invocation for an
externalfunctionasanuninterpretedsymbolassumingithasno
side-effect.FortheJavaLibraryClassmethods(e.g,theStringmeth-ods), we modeled the effect of each method. We unrolled each loop
of programs twice.Algorithm 1 The NPEX Algorithm
Input:Buggy program ğ‘ƒNPE, NPE stack trace (ğ‘¥NPE,ğœ), modelM
Output: A setPatchesof validated patches
1:ğ‘¥NPE,ğœâ†RunProgram (ğ‘ƒNPE,ğ¼) âŠ²Fault variable and stack
trace
2:Patchesâ†âˆ…
3:Î£inferredâ†SymExecxNPE
M(PNPE) âŠ²Spec inference
4:Xâ†FaultLocalization (ğ‘ƒNPE,ğœ)
5:forğ‘¥/prime
NPEâˆˆXdo
6:forPpatchedâˆˆPatchEnumeration (PNPE,x/prime
NPE)do
7: Î£patchedâ†SymExec(Ppatched)
8: if(Î£patchedâ‰¡Î£inferred)then âŠ²Spec validation
9: Patchesâ†Patchesâˆª{Ppatched}
10: end if
11:end for
12:end for
13:returnPatches
Null-handling Model .We implemented null-handling code
mining and feature extraction using Spoon. We collected null-handling patterns of more various syntactic forms than ternarydescribed in Section 3.1. For example, we additionally collected
null-handles of the following form:
y=ğ‘’;...if (ğ‘¥NPE!= null){y= ğ‘¥NPE.foo(); }
where we interpreted ğ‘’as an alternative value for foo.
Use Cases of NPEX .NPEX can be used in many application
scenarios. First of all, Note that NPEX does not require a failing
â€œtestâ€;instead,NPEXonlyrequiresastacktrace(oracrashinginput
to obtain the stack trace). In the context of NPEs, a failing â€œtestâ€ is
apairofacrashing,NPE-triggeringinputandthecorresponding
expected output. What NPEX requires is the crashing input, which
isavailablewhenNPEsaredetectedandconfirmed.Ontheother
hand, we do not require the expected output, which is typically un-availableatthetimeNPEsarereported;itisprovidedbyadeveloper
later when the reported NPE is fixed.
Because NPEX only requires a stack trace (crashing input), it
can be used in many practical scenarios to automatically fix NPEs
as soon as they are detected. For example, we can use NPEX to fix
NPEsdetectedbyautomatictestingtoolsorstaticbug-finders.Also,
NPEX can be used to fix NPEs reported in issue tracking systems.
StacktracesareusuallyavailablewhenNPEsaredetectedand
reported.Forexample,whenNPEsarefoundbytestingtools,stack
traces are immediately available from the crashes. Also, static bug-
finders usually provide error traces (stack traces) for reported bugs.
WhenNPEbugsarereportedinissuetrackingsystems,itistypical
that users include a crashing input or stack trace in the bug report.
5 EVALUATION
In this section, we evaluate NPEX in comparison with state-of-the-
art techniques for repairing NPEs.
5.1 Setup
Benchmark Selection .We used four different benchmark sets:
â€¢VFixBM: 30 NPE bugs from [67].
1538
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:30:33 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Junhee Lee, Seongjoon Hong, and Hakjoo Oh
â€¢GenBM: 16 NPE bugs from [36].
â€¢BearsBM: 14 NPE bugs from Bears [41].
â€¢OurBM: 59 NPE bugs from open-source repositories.
VFixBM,GenBM,andBearsBMcamefrompriorwork.VFixBMcon-
sistsof30NPEbugs,ofwhich15isfromDefects4J[ 23]andanother
15 from open-source repositories collected by the authors of VFix.
We note that the structures of the projects in VFixBM are mod-
ified by the authors of VFix to easily run VFix. They removed
the build system in the original projects, and wrote a compilable
Main.javathatactsasatestsuite.WeusedVFixBMastheyarepro-
vided without any modification.We alsocollected NPE bugs used
forevaluatingGenesis[ 36]andcontainedinBears[ 41].Bothof
these benchmarks consist of NPE bugs collected from open-source
projects in GitHub and use the apache maven project management
system6.F r o m[36,41], we only collected benchmarks that can be
built in our environment and parsed by Spoon [ 49] and Infer [ 20].
Finally, we excluded benchmarks that already exist in differentbenchmark sets, leading to 16 and 14 NPE bugs in GenBM and
BearsBM, respectively.
In addition, we tried to collect more diverse NPE bugs from
open-source projects and constructed OurBM as the result. We
usedtwosources:(1)thetop-200JavarepositoriesinGitHubsortedbythenumberofstarsand(2)repositoriesundertheApacheproject
page7. Among them, we only considered projects that can be built
bythemavensystem.Fromthoserepositories,wecollected4472
commitswhosemessagescontainkeywords"NPE"or"NullPointerException",whereweonlyconsideredrecentcommitsupto5years
ago. We then searched for reproducible NPE bugs in a similar way
as Bears was collected [ 41]; we only ran NPE-triggering test cases
to check whether an NPE is reproducible in the buggy version
(i.e., the parent revision of the collected commit) and the error is
removedinthefixedversion.Also,weexcludedbenchmarksthat
SpoonorInferfailtohandle.Finally,weexcludedbenchmarksthatarealreadycontainedinthethreebenchmarksetsabove,whichled
to a total of 59 NPE bugs in OurBM.
Intotal,weused119uniqueNPEbugsandallofthemcomewith
test suites written by developers to check patch correctness. All
experimentsweredoneonamachinerunningUbuntu18.04with
20 CPUs and 128GB memory, powered by Intel Xeon Gold 6230
processor.
Tool Selection andSetup .WeevaluatedNPEXincomparison
withVFix[ 67]andGenesis[ 36],twostate-of-the-arttechniquesfor
repairingNPEs.VFixisthemostrecenttechnique,whichisNPE-
specific and known to be significantly more effective than existing
APR techniques such as NPEFix [ 13], Nopol [ 68], CapGen [ 60],
and ACS [ 66]. Genesis is a data-driven technique that can effec-
tively fix NPEs using an NPE-specific patch space learned fromhuman patches. We included Genesis as it was not evaluated in
priorwork[ 67].Wealsoconsider NPEXbase,whichisthebaselineof
NPEXthatusestheconventionaltest-basedpatchvalidationinstead
ofournewapproach; NPEXbaseusesexactlythesametechniques
for fault localization and patch generation as NPEX (Section 4). We
included NPEXbaseto see the net effect of our key contribution
6https://maven.apache.org/
7https://github.com/apache/(automatic specification inference and validation). In the evalua-
tion, we excluded NPEFix [ 13], another recent technique to fix
NPEs, because it was reported that VFix significantly outperforms
NPEFixonVFixBM[ 67].Also, theresultsof NPEXbasehintat the
performance of NPEFix for otherbenchmarks, as theyuse similar
patch templates and the same patch validation method (i.e., test
cases). In summary, we used the following tools in evaluation:
â€¢NPEX: our technique (without test cases)
â€¢NPEXbase: the baseline of NPEX (with test cases)
â€¢VFix: a state-of-the-art for fixing NPEs (with test cases)
â€¢Genesis: a data-driven technique for NPEs (with test cases)
For NPEX, we only used the single NPE-triggering test con-
tained ineachbenchmark,and didnotuse othertest cases.Instead,
NPEXusedanull-handlingmodellearnedfrom571Javaprojects.
Wecollectedtheseprojectsstartingfromthetop-1000Javaprojects
based on the number of stars and excluding ones that are not built
withmavenorSpoon.Wealsoexcludedprojectscontainedinthe
fourbenchmarksetsinordertoensurethatthetrainingandtestsets do not overlap. For
NPEXbase, we used the same setting as
NPEX except that NPEX baseuses test cases.
WeobtainedGenesisfromthereplicationpackagereleasedby
the authors8. When running Genesis, we used the search space
learned for NPE, which is also provided in the replication package.
Specifically,weusedthespacenamed npe-space-vo becauseithas
beenreportedasthebestamongothers[ 35].Genesistakesasinput
a list of passing and failing test cases, which is used for fault local-
ization andpatch validation. Because severalbenchmarks contain
multiplefailingtestsotherthantheNPE-triggeringtest,weonly
used tests in the NPE-triggering test caseâ€™s class as input so that
the Genesis can precisely localize the target NPE. Although Gene-
sisusedbugswithmorethan50testcasesin[ 36],weobservedthat
noperformancedegradationoccurredduetothissetting,compared
to the original numbers reported in [36].
Weobtainedtheexecutablebinary(JAR)of VFixviapersonal
communication with the authors. Running VFix was nontrivial as
it requires notonly a stack trace and nullpointer(fault) expression
but also a runnable main class with an entry point which actsas a test suite. Therefore, running VFix on GenBM, BearsBM,and OurBM was particularly challenging. We had to manually
writetheMainclassforeachbug,hadtoresolvetheclasspathfor
dependencies and set up testing environments by hand without
aidsofbuildsystemsandtestingframeworks.Wealsoencountered
severalinternalerrorsof VFixrunningonthosebenchmarksbut
we could not debug them as source code is unavailable. As a result,
thoughwedidourbest,weendedupwith27outof89benchmarks
inGenBM,BearsBM,andOurBM.Forthose27benchmarks,we
preparedstacktracesandnullpointerexpressionsbyrunningNPE-
triggering test cases.
Correctness Criteria .We say a patch is correct if it is semanti-
callyequivalenttothedeveloperâ€™spatch.Wemanuallyinvestigated
each of the generated patches to check the correctness. Follow-ing Genesis [
36], we ignored log messages and error messages
of exceptions in the judgement. VFix often failed to convert anIR (intermediate representation) to source code. In this case, we
8http://www.cs.toronto.edu/~fanl/program_repair/genesis-rep/index.html
1539
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:30:33 UTC from IEEE Xplore.  Restrictions apply. NPEX: Repairing Java Null Pointer Exceptions without Tests ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Table 2: Evaluation results. #R: the number of bugs for which each tool was successfully ran. #G: the number of patchess
successfully generated and validated by each tool. #C: the number of correct patches. Prec: precision (#ğ¶
#ğº). FixR: fix rate (#ğ¶
#ğ‘…).
Benchmarks NPEX NPEXbase Genesis [36] VFix [67]
Name #Bug#R#G#CPrecFixR#R#G#CPrecFixR#R#G#CPrecFixR#R#G#CPrecFixR
VFixBM 3030281968 %63 %3030620 %20 %0n/an/an/an/a30262077 %67 %
GenBM 1616161063 %63 %1614321 %19 %1611873 %50 %22150 %50 %
BearsBM 141411655 %43 %1410330 %21 %149333 %21 %2100%0%
OurBM 5959442659 %44 %59471634 %27 %5933927 %15 %2315320 %13 %
Total 119119996162%51%1191012828%24%89532038%22%57442455%42%
manuallytranslatedthegeneratedIRtothesourcecodewiththe
samesemantics,andthencheckedthecorrectness.Were-evaluated
the patches labeled by existing works with the same criteria above.
We found that 4 of VFix-generated patches labeled as correct by
the authors are actually incorrect under the criteria (i.e., patches
werenot semanticallyequivalent tothe developerâ€™sfix). Thus,we
labeled them as incorrect in our evaluation.9
5.2 Results
Table 2 shows the evaluation results. Out of 119 bugs, NPEX gener-
ated and validated patches for 99 bugs (#G), and among them 61
were correct, leading to a fix rate of 51% (61
119) and a precision (i.e.,
howpreciselygeneratedpatchesturnedouttobecorrect)of62%
(61
99).Ontheotherhand, NPEXbase,whichdoesnotuseourpatch
validation but relies on a test suite, resulted in a fix rate of 24% and
a precision of 28%, which shows that our patch validation is much
more effective than conventional test-based validation.
Meanwhile, Genesis generated 53 patches out of 89 bugs and
20werecorrectamongthose,leadingtoafixrateof22%(20
89)anda
precisionof38%(20
53).WecouldnotrunGenesisonVFixBMbecause
ithasnobuildsystemandtestingframeworkwhicharerequired
to run Genesis.
WecouldsuccessfullyrunVFixfor57benchmarksandVFixgen-
erated 44 patches in total. The number of correct patches out of
44 were 24, leading to a fix rate of 42% (24
57) and a precision of
55% (24
44). Most of the correct patches produced by VFix were from
VFixBM (20 outof24). Forother benchmarks(GenBM, BearsBM,
OurBM),VFixgenerated18patchesand4amongthemwerecor-
rect,leadingtoafixrateof15%andaprecisionof22%,whichare
substantially lower than the fix rate of 67% and the precision of
77% for VFixBM. This is because, most of the correct patches in
VFixBMaresimilarinthattheysimplyskipstatementsorblocks
that contain NPEs, for which the VFixâ€™s ranking heuristic works
well.However,otherbenchmarksetscontainNPEbugsthatrequire
more diverse fix strategies (e.g., returning a non-default value or
replacinganexisting expression).Bycontrast, NPEXconsistently
shows good performance over the four benchmark sets.
Scalability .The sizes of programs in our benchmarks range
from 2K to 340KLoC (75KLoC on average). Excluding the build
time by Infer, NPEX took 173.8 seconds to fix a bug on average.
Specifically,ittook65secondsforfaultlocalization,25.8seconds
for specification inference, and 84.0 seconds for validating patchcandidates on average. Note that the time cost for running tests,
9We made these cases publicly available for verification.(a) Buggy Program
1publicList getJpaAnnotated(Class c, ...) {
2finalList jpaAnnotated = newArrayList<>();
3while(c != Object.class){
4 for(Field f: c.getDeclaredFields()) { // NPE
5 jpaAnnotated.add(...);
6 }
7 c = c.getSuperclass()
8...
9returnjpaAnnoated;
10}
(b) Developerâ€™s test case
1List members = ...getJpaAnnotated(TestInterface.class, ...);
2Assert.assertEquals(0, members.size());
Figure 4: A simplified code snippet containing an NPE (line
4) from the project Apache aries-jpaâ€™s revision 7712046
a frequent performance bottleneck in generate-and-validate ap-proaches, is zero for NPEX because it does not use test cases at
all.Runningtestcaseswasveryexpensiveforsomebenchmarks.
For example, project commons-pool_41f4e41 took 3 minutes for
asinglerunofthetestsuite,whichmustberepeatedmanytimes
during the repair process and hence caused timeout (1 hour) for
Genesis.
Case Study .We observed that test cases written by develop-
ersareoftenincompleteinpractice,andVFixandGenesiseasily
produce incorrect patches in such cases. For example, consider Fig-
ure4,whichdescribesanNPEfoundinproject aries-jpa10and
thetestcasewrittenbythedeveloper.Method getJpaAnnotated
(Figure 4(a)) collects all the declared fields of the input class ob-
jectcretrieving its super classes. An NPE occurs at line 4 because
c.getSuperclass() at line 7 may return nullin case the super
class is an interface.In this case, the developer wrote a singletest
case(theassertioninFigure4(b))forthepurposeofpatchvalida-
tion,whichfirstexposestheNPEandthenchecksifthelengthof
the returned list equals to 0. This test case is incomplete as it only
checkstheexecutionwheretheloopiteratesonlyonce,whilethe
fully expected behavior of the method is that it retrieves all the
superclassesuntil c.getSuperclass() returnsObject.class or
null. With this incomplete specification, Genesis and VFix gener-
atedthefollowingpatchesthatpassthetestcasebutareincorrect:
10https://github.com/apache/aries-jpa/commit/771204
1540
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:30:33 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Junhee Lee, Seongjoon Hong, and Hakjoo Oh
if(c.getSuper...() != null)
while(c != ...) { ... }while(c != ...) {
if(c ==null)
return new ArrayList();
Fix by Genesis Fix by VFix
Bycontrast,NPEXgeneratedthefollowingpatchthatissemanti-
cally equivalent to the developerâ€™s fix, which was possible because
NPEXcanautomaticallyinfertheexpectedspecificationfromthe
buggy code rather than relying on test cases.
while(c != ...) {
if(c ==null)break;while(c != Object.class
& &c! =null){
Fix by NPEX Fix by developer
LimitationsofNPEX .Nextwediscusslimitationsof NPEXiden-
tified from the evaluation. First, NPEX failed because of unsup-
ported fix patterns. In Figure 5, for example, the developer fixed an
NPEbychangingthetypeofalocalvariablefrom inttodouble.
ThisisbecausethefaultofthisNPEisduetounsafetypeconver-
sion from doubletoint. Because of this unsafe conversion, the
methoddistance returnsNaNvalue,whichcausestheconditionat
line 9 to produce false, and therefore clusterisnullat line 11.
Wealsoidentifiedalimitationofourspecificationinference.This
happened when another fault exists in the buggy program other
than the NPE to be fixed. For example, the program in Figure 6 has
an NPE at line 4 since iterable can benullNPEX inferred the
incorrectspecificationforthisprogram:â€œif iterable isnull,then,
throwNullPointerException â€,whichwascomputedbyinterpret-
ingtheNPEexpression iterable.iterator() asnullusingthe
learned model and symbolically executing the constructor at line 6,
which is through this(...) at line 4. However, there was another
bug in the constructor at line 6. On the other hand, NPEX could
infer a correct specification if IllegalArgumentException were
thrown at line 8.
Validated Patches .We observed that NPEX can successfully
validatevariouspatchesbeyondsimpleternaryforms.Interestingly,
all 21 patches fixed and validated correctly by NPEX were in theformsofSKIPorINIT.Inotherwords,NPEXrejectedallternary
patcheseventhoughweusedternarynullhandlingcodeforspecifi-cationmining.Thesebugsrequire SKIPorINITpatchestofixNPEs,
since simply replacingan NPEexpression toa ternaryexpression
introducedanewNPE.NPEXinferredcorrectspecificationwhichis
semantically equivalent to SKIPorINITpatches (e.g., Section 2.2).
Falsely Validated Patches .We manually investigated 38 (99-
61, Table 2) false positive cases (i.e., incorrect patches accepted by
the patch validator) during manual assesment of validated patches.
Those cases were classified into the following cases:
â€¢(26 cases) Inference of correct specification failed due to the
existence of faults other than the target NPE (as decribed in
Limitations of NPEX).
â€¢(2 cases) Correct specification is inferred, but an incorrect
patchisvalidatedduetotheimprecisionofstaticsymbolic
execution.
â€¢(10 cases) The learnt null-handling model returns wrong
alternative expressions.1doubledistance(int[] p1, int[] p2) {
2(-)ints u m=0 ;
3(+)doubles u m=0 ;
4 for(inti = 0; i < p1.length; i++) { sum += ...; }
5 returnMath.sqrt(sum); // return NaN
6}
7voidassignPointsToClusters(T point) {
8 Cluster cluster = null;
9 if(point.distance(...) < Double.MAX_VALUE) // false
10 cluster = ...;
11 cluster.addPoint(p) // NPE
12}
Figure5:AnNPEbug(line11)andthedeveloperpatch(sim-plified code snippet Math-79 in Defects4J)
1publicIteratorReader(Iterable<String> iterable) {
2(+)if(iterable == null)
3(+) throw new IllegalArgumentException("...");
4 this(iterable.iterator()); // NPE
5}
6publicIteratorReader(Iterator<String> iterator) {
7 if(iterator == null)
8(-) throw new NullPointerException();
9(+) throw new IllegalArgumentException("...");
10 this.iterator = iterator;
11}
Figure 6: An NPE bug (line 4) and the developer patch (sim-plified from opengrok-6a95adb)
Whilethefirstcaseisthelimitationof NPEX,weexpectthatthe
other cases can be resolved. The second case could be resolved by
standard techniques to improve symbolic executionsuch as more
advancedstatemergingheuristics.Thethirdcasecouldberesolvedbyrefiningthenull-handlingmodelwithmorefeaturesandtraining
dataset.
6 RELATED WORK
We discuss prior work closely related to ours. We focus on auto-
mated program repair (APR) approaches [ 16,45], rather than tech-
niques for detecting and mitigating NPEs (e.g., [6, 12, 39, 42, 47]).
APR techniques are broadly classified into general-purpose and
special-purposetechniques.Special-purposetechniquesareapplica-bletoparticularkindsofbugs.Forexample,FootPatch[
58]canfix
heap-relatedbugssuchasresourceleaks,memoryleaks,andnull
dereferences. SAVER [ 18], MemFix [ 30], and LeakFix [ 14] are tech-
niquesforfixingmemoryleaks,use-after-frees,anddouble-freesinCprograms.Otherspecial-purposetechniqueshavebeenproposed
to fix common and important classes of bugs, e.g., concurrencybugs [
1,22,33,34], buffer/integer overflows [ 7,19,46,52], error-
handling bugs [ 57], and performance bugs [ 5,51]. VFix [67] and
1541
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:30:33 UTC from IEEE Xplore.  Restrictions apply. NPEX: Repairing Java Null Pointer Exceptions without Tests ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
NPEFix [13] are NPE-specific techniques. NPEX is also specialized
for fixing NPEs with its novel patch validation approach.
General-purpose approaches [ 21,24,26,27,29,37,38,43,44,
48,53,59,60,66]areapplicabletoanykindsofbugs,wheremost
techniquesrelyontest cases tovalidatepatches.General-purpose
approaches are further classified into generate-and-validate [ 21,
24,37,38,59]andsemantics-basedapproaches[ 26,27,43,44,48].
Generate-and-validatetechniquesusesearchalgorithms(e.g.,ge-
netic programming [ 59]) to iteratively generate candidate patches
fromapatchspaceuntilplausiblepatchesthatpassthegiventest
suite are found. Semantics-based approaches explore the search
spaceimplicitlybygeneratingconstraintsoncorrectpatchesand
usingSMTsolverstosynthesizesatisfyingpatches.Althoughthese
techniques are general, they are less effective for fixing specific
types of bugs such as NPEs as demonstrated by Xu et al. [67].
To mitigate overfitting [ 28,54,69], existing APR techniques
are often combined with patch prioritization [ 3,21,38,50,60,63,
64]. For example, CapGen [ 60] uses context information of code
(ASTnodes)torankcorrectpatchesbeforemerelyplausibleones.
Prophet [ 38] learns a probabilistic model of correct code from a
dataset of human-written patches collected from open-source soft-
ware repositories, and uses the model to rank candidate patches
based on the probability of being correct. VFix uses a heuristic
that ranks NPE patches by solving a graph congestion problem.
We believe these ranking techniques can be combined with our
approach to better identify correct NPE patches.
Recently, various data-driven techniques have emerged to en-
hanceprogramrepair[ 10,17,31,40,61].NPEXliesinthislineof
research,whereweusedatatolearnanull-handlingmodel.Notable
existing data-driven techniques related to fixing NPEs are Gene-
sis and Getafix. Genesis [ 36] uses data, a set of human patches, for
searchspaceinference.Inparticular,GenesiscanfixNPEsusing
aspecializedsearchspacelearnedfromexistingdata.Getafix[ 4]
aims to quickly generate human-like fixes for bugs detected bystatic analyzers. To do so, Getafix uses repair templates learned
from past human patches and suggests the most appropriate fix for
a given bug. Compared to NPEX, Getafix is more focused on the
patchgenerationphasewhilerelyingonasimplerankingheuristictoselectcorrectpatches.Asaresult,onelimitationofGetafixisthat
itcannotpreciselyinfertheexpectedbehaviorofbuggycode[ 4],
which is particularly important for repairing NPEs. Our patch vali-
dation technique could be used with Getafix to better suggest NPE
fixes.
Ourworkalsoliesinthelineofworkonidentifyingtest-overfitted
patches[15,56,62,65,70,71].T anetal .[56]proposedasetofcom-
mon syntactic patterns for incorrect patches, which can be used to
prevent specific classes of patches that are likely to be incorrect.ODS [
71] trains a statistical model to predict overfitted patches
based on featuresthat describe syntacticcharacteristics of correct
patches.Fix2Fit[ 15]focusedonavoidingpatchesthatcausecrashes
beyondthegiveninput,bygeneratingnewtestinputsusingagrey-
box fuzzing technique. Xiong et al . [65]proposed a technique to
validatepatchesbymeasuringsimilarityordissimilaritybetweena
buggy program and a patched program for newly generated testinputs.Comparedtothesework,thegoalof NPEXisfocusedon
NPEsandpresentsanewapproachbasedonlearningandsymbolic
execution.7 CONCLUSION
While NPEs are recurring and critical bugs in Java applications,
automaticallyrepairingNPEsstillremains asignificantchallenge.
Themaindifficultyisinidentifyingcorrectfixesoutofawiderange
of plausible patches that pass but overfitted to test cases, a central
open problem in automated program repair.
In this paper, we presented a new approach to address this chal-
lenge. Instead of relying on test cases, our approach infers the
expected behavior of a buggy program by combining learning and
symbolic execution, and validates candidate patches against theinferred repair specification. We implemented our approach in a
tool,NPEX,andshowedthatNPEXcanfixdiversereal-worldNPEs
more effectively than state-of-the-art test-based techniques.
Future Work .Although we focused on NPEs in this paper, our
approach couldbegeneralizedto otherfaults.Note thatthe core
ideaofNPEXconsistsoftwogeneralcomponents:(1)learningof
error-handling model from codebases, and (2) validating patches
using symbolic execution. The second component (symbolic execu-
tion)is alreadyreusable forother typesoffaults onceappropriate
â€œerror-handling modelâ€ is given. Instantiating the first component
(learning of error-handling model) for each different fault is less
obvious and will be interesting future work.
A good starting point for generalization would be the class of
faults whose alternative semantics can be easily captured fromerror-handling code. For example, Class Cast Exceptions (CCEs),
yet another common runtime error in Java, are such a case. In Java
projects, developers handle CCEs in a way similar to NPEs, i.e.,
usingternaryexpressionswithtypecheckingguardandalternative
expression. In this case, the idea of NPEX can be reused without
significant changes.
ACKNOWLEDGMENTS
This work was partly supported by Institute of Information &
communicationsTechnologyPlanning&Evaluation(IITP)grant
funded by the Korea government(MSIT) (No.2020-0-01337,(SW
STAR LAB) Research on Highly-Practical Automated Software Re-
pair and No.2021-0-00758, Development of Automated Program
Repair Technology by Combining Code Analysis and Mining) and
the MSIT(Ministry of Science and ICT), Korea, under the ICT Cre-
ative Consilience program (IITP-2022-2020-0-01819) supervised by
theIITP(Institute forInformation& communicationsTechnology
Planning & Evaluation), and the National Research Foundationof Korea (NRF) grant funded by the Korea government (MSIT)
(No.2021R1A5A1021944).
REFERENCES
[1]Christoffer Quist Adamsen, Anders MÃ¸ller, Rezwana Karim, Manu Sridharan,
FrankTip,andKoushikSen.2017. RepairingEventRaceErrorsbyControlling
Nondeterminism. In Proceedings of the 39th International Conference on Software
Engineering (Buenos Aires, Argentina) (ICSE â€™17). IEEE Press, Piscataway, NJ,
USA, 289â€“299. https://doi.org/10.1109/ICSE.2017.34
[2]Nick Andrews. [n.d.]. We Crunched 1 Billion Java Logged Errors â€“ Hereâ€™s What
Causes97%ofThem. https://www.overops.com/blog/we-crunched-1-billion-
java-logged-errors-heres-what-causes-97-of-them-2/.
[3]MoumitaAsad,KishanKumarGanguly,andKaziSakib.2019. ImpactAnalysis
of Syntactic and Semantic Similarities on Patch Prioritization in Automated
ProgramRepair.In 2019IEEEInternationalConferenceonSoftwareMaintenance
and Evolution (ICSME). 328â€“332. https://doi.org/10.1109/ICSME.2019.00050
1542
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:30:33 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Junhee Lee, Seongjoon Hong, and Hakjoo Oh
[4]JohannesBader,AndrewScott,MichaelPradel,andSatishChandra.2019. Getafix:
LearningtoFixBugsAutomatically. Proc.ACMProgram.Lang. 3,OOPSLA,Article
159 (Oct. 2019), 27 pages. https://doi.org/10.1145/3360585
[5]A.Banerjee,L.K.Chong,C.Ballabriga,andA.Roychoudhury.2018. EnergyPatch:
Repairing ResourceLeaks to ImproveEnergy-Efficiency of AndroidApps. IEEE
Transactions on Software Engineering 44, 5 (May 2018), 470â€“490. https://doi.org/
10.1109/TSE.2017.2689012
[6]SubarnoBanerjee,LazaroClapp,andManuSridharan.2019. NullAway:Practical
Type-basedNullSafetyforJava.In Proceedingsofthe201927thACMJointMeeting
on European Software Engineering Conference and Symposium on the Foundations
of Software Engineering (Tallinn, Estonia) (ESEC/FSE 2019). ACM, New York, NY,
USA, 740â€“750. https://doi.org/10.1145/3338906.3338919
[7]Xi Cheng, Min Zhou, Xiaoyu Song, Ming Gu, and Jiaguang Sun. 2017. IntPTI:
Automatic Integer Error Repair with Proper-type Inference. In Proceedings of
the 32Nd IEEE/ACM International Conference on Automated Software Engineering
(Urbana-Champaign, IL, USA) (ASE 2017). IEEE Press, Piscataway, NJ, USA, 996â€“
1001. http://dl.acm.org/citation.cfm?id=3155562.3155693
[8]Maciej Cielecki, Jundefineddrzej Fulara, Krzysztof Jakubczyk, and Åukasz
Jancewicz.2006. PropagationofJMLNon-NullAnnotationsinJavaPrograms.
InProceedings of the 4th International Symposium on Principles and Practice of
Programming in Java (Mannheim, Germany) (PPPJ â€™06). Association for Comput-
ingMachinery,NewYork,NY,USA,135â€“140. https://doi.org/10.1145/1168054.
1168073
[9]Roberta Coelho, Lucas Almeida, Georgios Gousios, and Arie van Deursen. 2015.
Unveiling Exception Handling Bug Hazards in Android Based on GitHub and
GoogleCode Issues.In 2015IEEE/ACM12th WorkingConferenceonMiningSoft-
ware Repositories. 134â€“145. https://doi.org/10.1109/MSR.2015.20
[10]ElizabethDinella,HanjunDai,ZiyangLi,MayurNaik,LeSong,andKeWang.
2020. Hoppity: Learning Graph Transformations to Detect and Fix Bugs in
Programs. In 8th International Conference on Learning Representations, ICLR 2020,
AddisAbaba,Ethiopia,April26-30,2020.OpenReview.net. https://openreview.
net/forum?id=SJeqs6EFvB
[11]DinoDistefano,ManuelFÃ¤hndrich,FrancescoLogozzo,andPeterW.Oâ€™Hearn.
2019. Scaling Static Analyses at Facebook. Commun. ACM 62, 8 (July 2019),
62â€“70. https://doi.org/10.1145/3338112
[12]KingaDobolyiandWestleyWeimer.2008. ChangingJavaâ€™sSemanticsforHan-
dling Null Pointer Exceptions. In 2008 19th International Symposium on Software
Reliability Engineering (ISSRE). 47â€“56. https://doi.org/10.1109/ISSRE.2008.59
[13]T. Durieux, B. Cornu, L. Seinturier, and M. Monperrus. 2017. Dynamic patchgeneration for null pointer exceptions using metaprogramming. In 2017 IEEE
24thInternationalConferenceonSoftwareAnalysis,EvolutionandReengineering
(SANER). 349â€“358. https://doi.org/10.1109/SANER.2017.7884635
[14]QingGao,YingfeiXiong,YaqingMi,LuZhang,WeikunYang,ZhaopingZhou,
Bing Xie, and Hong Mei. 2015. Safe Memory-leak Fixing for C Programs. In
Proceedings of the 37th International Conference on Software Engineering - Volume
1(Florence, Italy) (ICSE â€™15). IEEE Press, Piscataway, NJ, USA, 459â€“470. http:
//dl.acm.org/citation.cfm?id=2818754.2818812
[15]XiangGao,SergeyMechtaev,andAbhikRoychoudhury.2019. Crash-avoiding
programrepair.In Proceedingsofthe28thACMSIGSOFTInternationalSymposium
on Software Testing and Analysis. 8â€“18.
[16]L. Gazzola, D. Micucci, and L. Mariani. 2019. Automatic Software Repair: A
Survey.IEEE Transactions on Software Engineering 45, 1 (Jan 2019), 34â€“67. https:
//doi.org/10.1109/TSE.2017.2755013
[17]Jacob Harer, Onur Ozdemir, Tomo Lazovich, Christopher P. Reale, Rebecca L.
Russell,LouisY.Kim,andSangPeterChin.2018. LearningtoRepairSoftware
Vulnerabilities with Generative Adversarial Networks. In Advances in Neural
Information Processing Systems 31: Annual Conference on Neural InformationProcessing Systems 2018, NeurIPS 2018, December 3-8, 2018, MontrÃ©al, Canada,Samy Bengio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, NicolÃ²
Cesa-Bianchi,andRomanGarnett(Eds.).7944â€“7954. https://proceedings.neurips.
cc/paper/2018/hash/68abef8ee1ac9b664a90b0bbaff4f770-Abstract.html
[18]Seongjoon Hong, Junhee Lee, Jeongsoo Lee, and Hakjoo Oh. 2020. SAVER: Scal-
able,Precise,andSafeMemory-ErrorRepair.In 2020IEEE/ACM42ndInternational
Conference on Software Engineering (ICSE). 271â€“283. https://doi.org/10.1145/
3377811.3380323
[19]ZhenHuang,DavidLie,GangTan,andTrentJaeger.2019.UsingSafetyPropertiestoGenerateVulnerabilityPatches.In 2019IEEESymposiumonSecurityandPrivacy
(SP). 539â€“554. https://doi.org/10.1109/SP.2019.00071
[20]Facebook Inc. 2018. A tool to detect bugs in Java and C/C+++/Objective-C code
before it ships. Available: https://fbinfer.com.
[21]Jiajun Jiang, Yingfei Xiong, Hongyu Zhang, Qing Gao, and Xiangqun Chen.2018. Shaping Program Repair Space with Existing Patches and Similar Code.InProceedings of the 27th ACM SIGSOFT International Symposium on Software
Testing and Analysis (Amsterdam, Netherlands) (ISSTA 2018). Association for
ComputingMachinery,NewYork,NY,USA,298â€“309. https://doi.org/10.1145/
3213846.3213871
[22]Guoliang Jin, Linhai Song, Wei Zhang, Shan Lu, and Ben Liblit. 2011. Automated
Atomicity-violation Fixing. In Proceedings of the 32Nd ACM SIGPLAN ConferenceonProgrammingLanguageDesignandImplementation (SanJose,California,USA)
(PLDI â€™11). ACM, New York, NY, USA, 389â€“400. https://doi.org/10.1145/1993498.
1993544
[23]RenÃ© Just, Darioush Jalali, and Michael D. Ernst. 2014. Defects4J: A Databaseof Existing Faults to Enable Controlled Testing Studies for Java Programs. In
Proceedings of the 2014 International Symposium on Software Testing and Analysis
(San Jose, CA, USA) (ISSTA 2014). ACM, New York, NY, USA, 437â€“440. https:
//doi.org/10.1145/2610384.2628055
[24]Dongsun Kim, Jaechang Nam, Jaewoo Song, and Sunghun Kim. 2013. Automatic
Patch Generation Learned from Human-written Patches. In Proceedings of the
2013InternationalConferenceonSoftwareEngineering (SanFrancisco,CA,USA)
(ICSE â€™13). IEEE Press, Piscataway, NJ, USA, 802â€“811. http://dl.acm.org/citation.
cfm?id=2486788.2486893
[25]Anil Koyuncu, Kui Liu, TegawendÃ© F. BissyandÃ©, Dongsun Kim, Martin Monper-
rus, Jacques Klein, and Yves Le Traon. 2019. IFixR: Bug Report Driven Program
Repair. In Proceedings ofthe 201927th ACM Joint Meetingon EuropeanSoftware
Engineering Conference and Symposium on the Foundations of Software Engineer-
ing(Tallinn, Estonia) (ESEC/FSE 2019). Association for Computing Machinery,
New York, NY, USA, 314â€“325. https://doi.org/10.1145/3338906.3338935
[26]Xuan-Bach D. Le, Duc-Hiep Chu, David Lo, Claire Le Goues, and Willem Visser.
2017. JFIX:Semantics-basedRepairofJavaProgramsviaSymbolicPathFinder.
InProceedings of the 26th ACM SIGSOFT International Symposium on Software
TestingandAnalysis (SantaBarbara,CA,USA) (ISSTA2017).ACM,NewYork,NY,
USA, 376â€“379. https://doi.org/10.1145/3092703.3098225
[27]Xuan-Bach D. Le, Duc-Hiep Chu, David Lo, Claire Le Goues, and Willem Visser.
2017. S3: Syntax- and Semantic-guided Repair Synthesis via Programming by
Examples.In Proceedingsofthe201711thJointMeetingonFoundationsofSoftware
Engineering (Paderborn,Germany) (ESEC/FSE2017).ACM, NewYork,NY, USA,
593â€“604. https://doi.org/10.1145/3106237.3106309
[28]Xuan-Bach D. Le, Ferdian Thung, David Lo, and Claire Le Goues. 2018. Over-fitting in Semantics-Based Automated Program Repair. In Proceedings of the
40th International Conference on Software Engineering (Gothenburg, Sweden)
(ICSE â€™18). Association for Computing Machinery, New York, NY, USA, 163.
https://doi.org/10.1145/3180155.3182536
[29]ClaireLeGoues,ThanhVuNguyen,StephanieForrest,andWestleyWeimer.2012.
GenProg:AGenericMethodforAutomaticSoftwareRepair. IEEETransactions
onSoftwareEngineering 38,1(2012),54â€“72. https://doi.org/10.1109/TSE.2011.104
[30]Junhee Lee, Seongjoon Hong, and Hakjoo Oh. 2018. MemFix: Static Analysis-based Repair of Memory Deallocation Errors for C. In Proceedings of the 2018
26thACM JointMeetingonEuropean SoftwareEngineeringConferenceand Sym-
posium onthe Foundationsof Software Engineering (Lake BuenaVista, FL,USA)
(ESEC/FSE 2018). ACM, New York, NY, USA, 95â€“106. https://doi.org/10.1145/
3236024.3236079
[31]Yi Li, Shaohua Wang, and Tien N. Nguyen. 2020. DLFix: Context-Based Code
TransformationLearningforAutomatedProgramRepair.In Proceedingsofthe
ACM/IEEE42ndInternationalConferenceonSoftwareEngineering (Seoul,South
Korea)(ICSEâ€™20).AssociationforComputingMachinery,NewYork,NY,USA,
602â€“614. https://doi.org/10.1145/3377811.3380345
[32]ZhenminLi,LinTan,XuanhuiWang,ShanLu,YuanyuanZhou,andChengxiang
Zhai. 2006. Have Things Changed Now? An Empirical Study of Bug Charac-teristics in Modern Open Source Software. In Proceedings of the 1st Workshop
onArchitecturalandSystemSupportforImprovingSoftwareDependability (San
Jose, California) (ASID â€™06). Associationfor ComputingMachinery, New York,
NY, USA, 25â€“33. https://doi.org/10.1145/1181309.1181314
[33]Huarui Lin, Zan Wang, Shuang Liu, Jun Sun, Dongdi Zhang, and Guangning
Wei. 2018. PFix: Fixing Concurrency Bugs Based on Memory Access Patterns. In
Proceedingsofthe33rdACM/IEEEInternationalConferenceonAutomatedSoftwareEngineering (Montpellier,France) (ASE2018).ACM,NewYork,NY,USA,589â€“600.
https://doi.org/10.1145/3238147.3238198
[34]Haopeng Liu, Yuxi Chen, and Shan Lu. 2016. Understanding and Generating
HighQualityPatchesforConcurrencyBugs.In Proceedingsofthe201624thACM
SIGSOFTInternationalSymposiumonFoundationsofSoftwareEngineering (Seattle,
WA,USA) (FSE2016).AssociationforComputingMachinery,NewYork,NY,USA,
715â€“726. https://doi.org/10.1145/2950290.2950309
[35]Fan Long, Peter Amidon, and Martin Rinard. 2016. Automatic inference of code
transforms and search spaces for automatic patch generation systems. (2016).
[36]Fan Long, Peter Amidon, and Martin Rinard. 2017. Automatic inference of code
transforms for patch generation. In Proceedings of the 2017 11th Joint Meeting
on Foundations of Software Engineering, ESEC/FSE 2017, Paderborn, Germany,
September 4-8, 2017. ACM, 727â€“739.
[37]Fan Long and Martin Rinard. 2015. Staged Program Repair with Condition
Synthesis.In Proceedingsofthe201510thJointMeetingonFoundationsofSoftware
Engineering (Bergamo,Italy) (ESEC/FSE2015).ACM,NewYork,NY,USA,166â€“178.
https://doi.org/10.1145/2786805.2786811
[38]Fan Long and Martin Rinard. 2016. Automatic Patch Generation by Learning
CorrectCode.In Proceedingsofthe43rd AnnualACMSIGPLAN-SIGACTSympo-
siumonPrinciplesofProgrammingLanguages (St.Petersburg,FL,USA) (POPLâ€™16).
ACM, New York, NY, USA, 298â€“312. https://doi.org/10.1145/2837614.2837617
1543
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:30:33 UTC from IEEE Xplore.  Restrictions apply. NPEX: Repairing Java Null Pointer Exceptions without Tests ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
[39]Fan Long, Stelios Sidiroglou-Douskos, and Martin Rinard. 2014. Automatic Run-
timeErrorRepairandContainmentviaRecoveryShepherding.In Proceedings
of the 35th ACM SIGPLAN Conference on Programming Language Design and
Implementation (Edinburgh,UnitedKingdom) (PLDIâ€™14).AssociationforCom-
putingMachinery,NewYork,NY,USA,227â€“238. https://doi.org/10.1145/2594291.
2594337
[40]ThibaudLutellier,HungVietPham,LawrencePang,YitongLi,MoshiWei,and
Lin Tan. 2020. CoCoNuT: Combining Context-Aware Neural Translation Models
Using Ensemble for Program Repair. In Proceedings of the 29th ACM SIGSOFT
InternationalSymposiumonSoftwareTestingandAnalysis (VirtualEvent,USA)
(ISSTA2020).AssociationforComputingMachinery,NewYork,NY,USA,101â€“114.
https://doi.org/10.1145/3395363.3397369
[41]Fernanda Madeiral, Simon Urli, Marcelo Maia, and Martin Monperrus. 2019.
BEARS: An Extensible Java Bug Benchmark for Automatic Program Repair Stud-
ies.In2019IEEE26thInternationalConferenceonSoftwareAnalysis,Evolutionand
Reengineering (SANER). 468â€“478. https://doi.org/10.1109/SANER.2019.8667991
[42]RavichandhranMadhavanandRaghavanKomondoor.2011. NullDereference
VerificationviaOver-ApproximatedWeakestPre-ConditionsAnalysis.In Pro-
ceedingsofthe2011ACMInternationalConferenceonObjectOrientedProgram-
ming Systems Languages and Applications (Portland, Oregon, USA) (OOPSLA
â€™11). Association for Computing Machinery, New York, NY, USA, 1033â€“1052.
https://doi.org/10.1145/2048066.2048144
[43]SergeyMechtaev,JooyongYi,andAbhikRoychoudhury.2015. DirectFix:Looking
forSimpleProgramRepairs.In Proceedingsofthe37thInternationalConferenceon
SoftwareEngineering-Volume1 (Florence,Italy) (ICSEâ€™15).IEEEPress,Piscataway,
NJ, USA, 448â€“458. http://dl.acm.org/citation.cfm?id=2818754.2818811
[44]Sergey Mechtaev, Jooyong Yi, and Abhik Roychoudhury. 2016. Angelix: Scalable
MultilineProgramPatchSynthesisviaSymbolicAnalysis.In Proceedingsofthe
38thInternationalConferenceonSoftwareEngineering (Austin,Texas) (ICSEâ€™16).
ACM, New York, NY, USA, 691â€“701. https://doi.org/10.1145/2884781.2884807
[45]Martin Monperrus. 2018. Automatic Software Repair: A Bibliography. ACM
Comput. Surv. 51, 1, Article 17 (Jan. 2018), 24 pages. https://doi.org/10.1145/
3105906
[46]PaulMuntean,MartinMonperrus,HaoSun,JensGrossklags,andClaudiaEckert.
2019. IntRepair: Informed Repairing of Integer Overflows. IEEE Transactions on
Software Engineering (2019), 1â€“1. https://doi.org/10.1109/TSE.2019.2946148
[47]Mangala Gowri Nanda and Saurabh Sinha. 2009. Accurate Interprocedural Null-
Dereference Analysis for Java. In 2009 IEEE 31st International Conference on
Software Engineering. 133â€“143. https://doi.org/10.1109/ICSE.2009.5070515
[48]Hoang Duong Thien Nguyen, Dawei Qi, Abhik Roychoudhury, and SatishChandra. 2013. SemFix: Program Repair via Semantic Analysis. In Proceed-
ings of the 2013 International Conference on Software Engineering (San Fran-
cisco, CA, USA) (ICSE â€™13). IEEE Press, Piscataway, NJ, USA, 772â€“781. http:
//dl.acm.org/citation.cfm?id=2486788.2486890
[49]RenaudPawlak,MartinMonperrus,NicolasPetitprez,CarlosNoguera,andLionelSeinturier.2016. Spoon:Alibraryforimplementinganalysesandtransformations
of java source code. Software: Practice and Experience 46, 9 (2016), 1155â€“1179.
[50]Ripon K. Saha, Yingjun Lyu, Hiroaki Yoshida, and Mukul R. Prasad. 2017. Elixir:
Effectiveobject-orientedprogramrepair.In 201732ndIEEE/ACMInternational
ConferenceonAutomatedSoftwareEngineering(ASE).648â€“659. https://doi.org/
10.1109/ASE.2017.8115675
[51]Marija Selakovic and Michael Pradel. 2015. Poster: Automatically Fixing Real-
WorldJavaScriptPerformanceBugs.In 2015IEEE/ACM37thIEEEInternational
Conference on Software Engineering, Vol. 2. 811â€“812. https://doi.org/10.1109/
ICSE.2015.260
[52]AlexShaw,DustenDoggett,andMunawarHafiz.2014. AutomaticallyFixingC
BufferOverflowsUsingProgramTransformations.In Proceedingsofthe201444th
AnnualIEEE/IFIPInternationalConferenceonDependableSystemsandNetworks
(DSN â€™14). IEEE Computer Society, Washington, DC, USA, 124â€“135. https://doi.
org/10.1109/DSN.2014.25
[53]SteliosSidiroglou-Douskos,EricLahtinen,FanLong,andMartinRinard.2015.
AutomaticErrorEliminationbyHorizontalCodeTransferAcrossMultipleAp-
plications. In Proceedings of the 36th ACM SIGPLAN Conference on Programming
Language Design and Implementation (Portland, OR, USA) (PLDI â€™15). ACM, New
York, NY, USA, 43â€“54. https://doi.org/10.1145/2737924.2737988
[54]Edward K. Smith, Earl T. Barr, Claire Le Goues, and Yuriy Brun. 2015. Is theCure Worse Than the Disease? Overfitting in Automated Program Repair. In
Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering
(Bergamo, Italy) (ESEC/FSE 2015). ACM, New York, NY, USA, 532â€“543. https:
//doi.org/10.1145/2786805.2786825
[55]Shin Hwei Tan, Zhen Dong, Xiang Gao, and Abhik Roychoudhury. 2018. Repair-
ing Crashes in Android Apps. In Proceedings of the 40th International Conferenceon Software Engineering (Gothenburg, Sweden) (ICSE â€™18). Association for Com-
putingMachinery,NewYork,NY,USA,187â€“198. https://doi.org/10.1145/3180155.
3180243
[56]ShinHweiTan,HiroakiYoshida,MukulRPrasad,andAbhikRoychoudhury.2016.
Anti-patterns in search-based program repair. In Proceedings of the 2016 24th
ACM SIGSOFT International Symposium on Foundations of Software Engineering.
727â€“738.
[57]YuchiTianandBaishakhiRay.2017. AutomaticallyDiagnosingandRepairing
Error Handling Bugs in C. In Proceedings of the 2017 11th Joint Meeting on Foun-
dations of Software Engineering (Paderborn, Germany) (ESEC/FSE 2017). ACM,
New York, NY, USA, 752â€“762. https://doi.org/10.1145/3106237.3106300
[58]RijnardvanTonderandClaireLeGoues.2018. StaticAutomatedProgramRepairforHeapProperties.In Proceedingsofthe40thInternationalConferenceonSoftware
Engineering (Gothenburg,Sweden) (ICSEâ€™18).ACM,NewYork,NY,USA,151â€“162.
https://doi.org/10.1145/3180155.3180250
[59]WestleyWeimer,ThanhVuNguyen,ClaireLeGoues,andStephanieForrest.2009.
AutomaticallyFindingPatchesUsingGeneticProgramming.In Proceedingsofthe
31st International Conference on Software Engineering (ICSE â€™09). IEEE Computer
Society, Washington, DC, USA, 364â€“374. https://doi.org/10.1109/ICSE.2009.
5070536
[60]Ming Wen, Junjie Chen, Rongxin Wu, Dan Hao, and Shing-Chi Cheung. 2018.
Context-Aware Patch Generation for Better Automated Program Repair. In Pro-
ceedingsofthe40thInternationalConferenceonSoftwareEngineering (Gothenburg,
Sweden)(ICSE â€™18). Association for Computing Machinery, New York, NY, USA,
1â€“11. https://doi.org/10.1145/3180155.3180233
[61]Martin White, Michele Tufano, MatÃ­as MartÃ­nez, Martin Monperrus, and Denys
Poshyvanyk. 2019. Sorting and Transforming Program Repair Ingredients viaDeep Learning Code Similarities. In 2019 IEEE 26th International Conference
on Software Analysis, Evolution and Reengineering (SANER). 479â€“490. https:
//doi.org/10.1109/SANER.2019.8668043
[62]QiXinandStevenPReiss.2017. Identifyingtest-suite-overfittedpatchesthrough
test case generation. In Proceedings of the 26th ACM SIGSOFT International Sym-
posium on Software Testing and Analysis. 226â€“236.
[63]Qi Xin and Steven P. Reiss. 2017. Leveraging syntax-related code for automated
programrepair.In 201732ndIEEE/ACMInternationalConferenceonAutomated
Software Engineering (ASE). 660â€“670. https://doi.org/10.1109/ASE.2017.8115676
[64]Yingfei Xiong, Xinyuan Liu, Muhan Zeng, Lu Zhang, and Gang Huang. 2018.
IdentifyingPatchCorrectnessinTest-BasedProgramRepair.In Proceedingsof
the 40th International Conference on Software Engineering (Gothenburg, Sweden)
(ICSE â€™18). Association for Computing Machinery, New York, NY, USA, 789â€“799.
https://doi.org/10.1145/3180155.3180182
[65]Yingfei Xiong, Xinyuan Liu, Muhan Zeng, Lu Zhang, and Gang Huang. 2018.
Identifying patch correctness in test-based program repair. In Proceedings of the
40th international conference on software engineering. 789â€“799.
[66]YingfeiXiong,JieWang,RunfaYan,JiachenZhang,ShiHan,GangHuang,andLuZhang.2017.PreciseConditionSynthesisforProgramRepair.In Proceedingsofthe
39th International Conference on Software Engineering (Buenos Aires, Argentina)
(ICSEâ€™17).IEEEPress,Piscataway,NJ,USA,416â€“426. https://doi.org/10.1109/
ICSE.2017.45
[67]Xuezheng Xu, Yulei Sui, Hua Yan, and Jingling Xue. 2019. VFix: Value-flow-guided Precise Program Repair for Null Pointer Dereferences. In Proceedings
ofthe41stInternationalConferenceonSoftwareEngineering (Montreal,Quebec,
Canada)(ICSEâ€™19).IEEEPress,Piscataway,NJ,USA,512â€“523. https://doi.org/10.
1109/ICSE.2019.00063
[68]JifengXuan,MatiasMartinez,FavioDeMarco,MaximeClÃ©ment,SebastianLame-
las Marcote, Thomas Durieux, Daniel Le Berre, and Martin Monperrus. 2017.
Nopol: Automatic Repair of Conditional Statement Bugs in Java Programs. IEEE
TransactionsonSoftwareEngineering 43,1(2017),34â€“55. https://doi.org/10.1109/
TSE.2016.2560811
[69]JinqiuYang,AlexeyZhikhartsev,YuefeiLiu,andLinTan.2017. BetterTestCasesforBetterAutomatedProgramRepair.In Proceedingsofthe201711thJointMeeting
onFoundationsofSoftwareEngineering (Paderborn,Germany) (ESEC/FSE2017).
ACM, New York, NY, USA, 831â€“841. https://doi.org/10.1145/3106237.3106274
[70]Jinqiu Yang, Alexey Zhikhartsev, Yuefei Liu, and Lin Tan. 2017. Better test cases
forbetterautomatedprogramrepair.In Proceedingsofthe201711thJointMeeting
on Foundations of Software Engineering. 831â€“841.
[71]He Ye, Jian Gu, Matias Martinez, Thomas Durieux, and Martin Monperrus. 2021.
Automated classification of overfitting patches with statically extracted code
features. IEEE Transactions on Software Engineering (2021).
[72]Alex Zhitnitsky. [n.d.]. The Top 10 Exception Types in Production Java Ap-plications â€“ Based on 1B Events. https://www.overops.com/blog/the-top-10-
exceptions-types-in-production-java-applications-based-on-1b-events/.
1544
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:30:33 UTC from IEEE Xplore.  Restrictions apply. 