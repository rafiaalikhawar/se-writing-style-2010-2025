DeepTraLog: Trace-Log Combined Microservice Anomaly
Detection through Graph-based Deep Learning
Chenxi Zhangâˆ—
Fudan University
ChinaXin Pengâˆ—â€ 
Fudan University
ChinaChaofeng Shaâˆ—
Fudan University
China
Ke Zhangâˆ—
Fudan University
ChinaZhenqing Fuâˆ—
Fudan University
ChinaXiya Wuâˆ—
Fudan University
China
Qingwei Lin
Microsoft Research
ChinaDongmei Zhang
Microsoft Research
China
ABSTRACT
A microservice system in industry is usually a large-scale dis-
tributed system consisting of dozens to thousands of services run-
ning in different machines. An anomaly of the system often can be
reflected in traces and logs, which record inter-service interactions
and intra-service behaviors respectively. Existing trace anomaly
detection approachestreat a trace asa sequence of serviceinvoca-
tions. Theyignore the complex structureof a tracebrought by its
invocationhierarchyandparallel/asynchronousinvocations.On
the otherhand,existing loganomaly detectionapproaches treata
log as a sequence of events and cannot handle microservice logs
that are distributed in a large number of services with complex
interactions.Inthispaper,weproposeDeepTraLog,adeeplearning
based microservice anomaly detection approach. DeepTraLog uses
a unified graph representation to describe the complex structure of
a trace together with log events embedded in the structure. Based
on the graph representation, DeepTraLog trains a GGNNs based
deepSVDDmodelbycombingtracesandlogsanddetectsanom-
alies in new traces and the corresponding logs. Evaluation on a
microservicebenchmarkshowsthatDeepTraLogachievesahigh
precision (0.93) and recall (0.97), outperforming state-of-the-art
trace/log anomaly detection approaches with an average increase
of0.37inF1-score.ItalsovalidatestheefficiencyofDeepTraLog,
thecontributionoftheunifiedgraphrepresentation,andtheimpact
of the configurations of some key parameters.
âˆ—C.Zhang,X.Peng,C.Sha,K.Zhang,Z.FuandX.WuarewiththeSchoolofComputer
ScienceandShanghaiKeyLaboratoryofDataScience,FudanUniversity,Chinaand
the Shanghai Collaborative Innovation Center of Intelligent Visual Computing, China
â€ X. Peng is the corresponding author (pengxin@fudan.edu.cn).
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Â© 2022 Association for Computing Machinery.
ACM ISBN 978-1-4503-9221-1/22/05...$15.00
https://doi.org/10.1145/3510003.3510180CCS CONCEPTS
â€¢Softwareanditsengineering;â€¢ Computersystemsorganiza-
tionâ†’Reliability; Maintainability and maintenance; Cloud
computing;
KEYWORDS
Microservice, Anomaly Detection, Log Analysis, Tracing, Graph
Neural Network, Deep Learning
ACM Reference Format:
Chenxi Zhang, Xin Peng, Chaofeng Sha, Ke Zhang, Zhenqing Fu, Xiya Wu,
QingweiLin,andDongmeiZhang.2022.DeepTraLog:Trace-LogCombined
Microservice Anomaly Detection through Graph-based Deep Learning. In
44thInternationalConferenceonSoftwareEngineering(ICSEâ€™22),May21â€“
29, 2022, Pittsburgh, PA, USA. ACM, New York, NY, USA, 12 pages. https:
//doi.org/10.1145/3510003.3510180
1 INTRODUCTION
Microservice architecture is an approach to developing a single
application as a suite of small services, each running in its own
process and communicating with lightweight mechanisms [ 15]. A
microservice system in industry is usually a large-scale distributed
systemhavingdozenstothousandsofservicesrunningindifferent
machines. Running in a highly uncertain and dynamic environ-
ment,amicroservicesystemoftenfailsduetovariousinfrastructure
problems or application faults such as hardware failures, improper
configurations,implementationfaults,andincorrectcoordination
inserviceinteractions[ 42,43].Toallowengineerstotimelyreactto
potentialfailures,itisdesirablethattheanomaliesofamicroservice
system can be automatically detected at runtime.
Powered by specifications like OpenTracing [ 27] and related in-
frastructureslikeSkyWalking[ 33],distributedtracing[ 32]hasbeen
widely adopted in industrial microservice systems. Each produced
trace describes the execution process (i.e., invocation chain) of a
request through service instances and each operation (i.e., service
invocation)initiscalledaspan.Atthesametime,logginghasalsobeenwidelyusedbythedeveloperstorecordthebehaviorsofeachservice.Alogrecordssignificantmessagesatvariouscriticalpoints
forthepurposeofdebuggingandrootcauseanalysis[ 7].Atrace
canincludeseveraltohundredsofserviceinvocations(i.e.,spans)
6232022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:58:31 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Chenxi Zhang, Xin Peng, Chaofeng Sha, Ke Zhang, Zhenqing Fu, Xiya Wu, Qingwei Lin, and Dongmei Zhang
andduringeachinvocationaseriesoflogmessagesareproducedby
the invoked service instance. Industrial distributed tracing systemscanlinkthelogmessagesofthesametracebyinjectingthetraceID
andspanIDsintothelogmessagesproducedbydifferentservice
instances.
Recentresearches[ 20,26]usedeeplearningbasedtraceanaly-
sismethodstodetectruntimeanomaliesofmicroservicesystems.
These approaches treat a trace as a sequence of service invoca-
tions. However, a trace can have a complex structure formed by
the hierarchy of service invocations and parallel/asynchronous in-
vocations. Existing trace anomaly detection approaches ignore the
complexstructuresoftraces.Moreover,theydonotconsiderthelog messages which describe the behaviors of individual service
instancesinvolvedinatrace.Therefore,theseapproachescannot
well capture microservice anomalies.
Ontheotherhand,logshavebeenwidelyusedinanomalyde-
tection for distributed systems. Existing log anomaly detectionapproaches [
7,24,40] learn log patterns from normal execution
anddetectanomalieswhenlogpatternsdeviatefromthetrained
model. These approaches treat a log as a sequence of log events,
whicharetheabstractionofagroupofsimilarlogmessages[ 12].
For a distributed system, a log is produced for each request by
sortinglogmessagesfromdifferentnodesinvolvedintherequest
bytimestamp.Foramicroservicesystem,however,arequestcor-
responds to an invocation chain that may involve many service
instancesandcomplexinvocationsamongthem.Ifweproducea
logforarequestinasimilarway,itcannotwellcapturethecomplex
structure of its invocation chain.
Inthispaper,weproposeDeepTraLog,adeeplearningbasedmi-
croservice anomaly detection approach. DeepTraLog uses a unified
graphrepresentation,whichiscalledtraceeventgraph(TEG),to
describe the complex structure of a trace together with log events
embedded in the structure. It takes traces and logs as input andtrains a graph-based deep learning model for trace anomaly de-
tection. First,it parsesthe inputtraces and logsand extractsspan
relationshipsandlogeventsfromthemrespectively.Second,itgen-
erates vector representations for span events and log events and
at the same time constructs a TEG for each trace. Third, it trains a
gated graph neural networks (GGNNs) based deep SVDD (Support
VectorDataDescription)model,whichlearnsalatentrepresenta-
tion for each TEG and a minimized data-enclosing hypersphere.
When used for anomaly detection, DeepTraLog analyzes a trace
and the related logs in a similar way and uses the trained model to
generate a latent representation for the trace. It then determines
whetherthetraceisanomalousbasedonitsanomalyscore,i.e.,the
shortest distance from the latent representation of the trace to the
hypersphere.NotethatDeepTraLogdoesnotrelyontracelabelling
and just requires that the majority of traces in the training set are
produced in normal execution of the system. Moreover, it is able to
capture different types of anomalies.
ToevaluatetheeffectivenessandefficiencyofDeepTraLogwe
conduct a series of experimental studies on a microservice bench-
marksystem.TheresultsshowthatDeepTraLogoutperformsexist-
ing trace- and log-based anomaly detection approaches by 64.94%
and101.59%onaverageintermsofprecisionandrecallrespectively.
The unified graph representation significantly contributes to the
improvement of DeepTraLog, making it outperform the variant of
Figure 1: Trace, Span, and Log
Figure 2: Timeline of Spans in Figure 1
DeepTraLogusingsequencerepresentationby7.64%and26.03%on
averageintermsofprecisionandrecallrespectively.DeepTraLog
isefficientinmodeltrainingandtestinganditsresponsetimein
anomaly detection increases linearly with the size of the trace.
In summary, this paper makes the following contributions:
â€¢a unified graph representation of traces and logs that facili-tates the combined analysis of them;
â€¢
aGGNNsbaseddeepSVDDmodelformicroserviceanomaly
detection;
â€¢a series of experimental studies validating the effectiveness
andefficiencyofDeepTraLogtogetherwiththecontribution
of the unified graph representation and the impact of the
configurationsof some key parameters.
Significance. Our work provides a new and effective way for
combining traces and logs for microservice anomaly detection
whichoutperformsexistinglog/traceanomalydetectionapproaches.
It defines a unified graph-based representation for inter-serviceinteractions and intra-service behaviors. The representation can
facilitate avariety of differentmicroservice analysis taskssuch as
anomalydetection,rootcauseanalysis,andarchitecturecompre-
hension.
2 BACKGROUND AND MOTIVATION
In this section, we first introduce the background about traces and
logs, then motivate our work with an example.
2.1 Background
As a kindof large-scale distributedsystems, microservice systems
widely use distributed tracing [ 27,32] to profile and monitor their
executions.Atraceisthedescriptionoftheexecutionprocessof
624
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:58:31 UTC from IEEE Xplore.  Restrictions apply. DeepTraLog: Trace-Log Combined Microservice Anomaly Detection through Graph-based Deep Learning ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
arequestasitmovesthroughadistributedsystem[ 27].Forami-
croservice system, a trace describes the execution process of a
requestthroughserviceinstances,i.e.,aserviceinvocationchain.
The service invocations in a trace are initially recorded by indi-
vidual service instances and then collected and restored to a trace.
As shown in Figure 1, a trace consists of a set of spans in a tree
structure and each spancorresponds to a service invocation. Each
trace has a unique trace ID and each span has a unique span ID. A
span records the invoker and the invoked service instance and has
anoperationnameindicatingtheoperationtobeperformed.For
example, the operationname of a spanof REST invocation canbe
POST /api/v1/foodservice/orders. Each span (except the root span)
has a parent span which initiates the current span. For example, in
Figure 1 Span A is a synchronous invocation and during its exe-
cutionitinitiatestwosynchronousinvocationscorrespondingto
Span B and Span D respectively. Therefore, Span A is the parent of
Span B and Span D. Distributed tracing has been an important part
of microservice infrastructures and supported by open-source solu-tions(e.g.,Zipkin[
35],Jeager[ 13],andSkyWalking[ 33])andcloud
service providers (e.g., Amazonâ€™s X-Ray [ 3] and Alibaba Cloudâ€™s
ARMS [1]).
Asynchronousinvocationsandparallelinvocationsarewidely
used in microservice systems for better performance and availabil-
ity.Atracecanincludeseveraltohundredsofspans(i.e.,serviceinvocations). Therefore, synchronous invocations are often con-
sideredharmfulduetothemultiplicativeeffectofdowntime[ 15].
Asynchronousinvocationsareusuallyimplementedbymessage-
based communication and are thought to be a way for achieving
high-availability systems as the invoker does not block while wait-
ing. Parallel invocations mean to invoke multiple services at thesame time to reduce the overall response time. They are usually
implemented by making service invocations in multiple threads.
As shown in Figure 1, log messages are produced during each
serviceinvocation.Theselogmessagesareproducedbythelogging
statements written by service developers. They record the internal
statesandbehaviorsoftheinvokedserviceinstance.Alogmessage
is an unstructured sentence which contains a constant part (log
event)andseveralvariableparts(logparameters).Forexample,a
log message â€œ[assignSeat] Requested seat type is T1 and number is
2â€containsalogeventâ€œ[assignSeat]Requestedseattypeis<*>and
number is <*>â€ and two log parameters SeatType andSeatNumber.
Log event extraction has been a standard step in log parsing. After
log parsing, a log is converted into a sequence of log events.
Traces and logs can be combined for analyzing the runtime
behaviors of microservice systems. A trace describes the service
interactions for a request, while the logs record the internal states
and behaviors in individual service instances. As a service instance
mayserveformultiplerequestsatthesametime,itslogfileinter-
leaveslogmessagesfordifferentrequests.Tosupportthecombined
analysis,somedistributedtracingsystems(e.g.,SkyWalking[ 33],
Alibaba ARMS [ 1]) inject trace IDs and span IDs into log messages
andthusthelogmessagesofaserviceinstancecanbeassociated
with different requests. For example, SkyWalking uses the Mapped
DiagnosticContextmechanismofJavaloggingframeworks(e.g.,
Log4j [2], Logback [ 21]) to inject trace IDs and span IDs to log
messages.2.2 Motivation
Figure2showsthetimelineofthespansinFigure1.SpanBandSpan
Daretwoparallel invocationsgeneratedbySpanA,sotheyhave
someoverlapinthetimeline.SpanFisanasynchronousinvocation
generated by Span D, so it ends after Span D.
Existingtraceanomalydetectionapproaches[ 20,26]treatatrace
asasequenceofserviceinvocations,whileexistingloganomalyde-tectionapproaches[
7,24,40]treatalogasasequenceoflogevents.
These approaches cannot well support the anomaly detection of
microservice systems due to the following two reasons.
First, the logs of different service instances need to be combined
foranomalydetection.Existingtraceanomalydetectionapproaches
do not consider logs, thus can only detect anomalies that are re-
flected intrace structures.Figure1 showsan example oflog-level
anomalies.ThelogmessagesinSpanD showthatthetrainticket
order does not need food, but those in Span F show that a food
orderiscreatedforthistrainticketorder.Thisanomalycanonly
be detected by combing the log messages of Span D and F.
Second, a trace may have a complex structure involving invo-
cation hierarchy and parallel/asynchronous invocations. A trace
hasatreestructure.Ifallthespansaresynchronousinvocations,
thetracecanberepresentedbyasequenceofserviceinvocations
orderedbytheirstarttime.Evenso,sequence-basedrepresentationcannotreflectthecausalrelationshipsbetweenparentandchildren
spansandtemporalrelationshipsbetweenlogeventsofthesame
spans.Forexample,twoadjacentlogeventsinSpanAmaybefarin
the sequence-based representation, as the log events of the descen-
dantspansofSpanAareinsertedintothem.Moreover,atracemay
include parallel or asynchronous invocations. The trace shown in
Figure1andFigure2includestwoparallelinvocations(SpanBand
SpanD)and anasynchronousinvocation(SpanF). Therefore,the
log events in Span B and Span D (and their descendant spans) can
interleave in any order; Similarly, the log events in Span F and a
partlogeventsinSpanDcaninterleaveinanyorder.Ifwecombinethelogeventsofdifferentspansintoasequence(e.g.,bystarttime),
the characteristics of parallel or asynchronous invocations will be
lost.
Basedontheanalysis,wecanseethatthelogeventsofdifferent
spans of a trace need to be combined in a way that the structureof the trace can be kept. Therefore, we propose a unified graphrepresentationthatcandescribethestructureofatracetogether
withthelogeventsembeddedinthestructuretofacilitateanomaly
detection.
3 APPROACH
The objective of DeepTraLog is to automatically and accurately
detectanomaloustracesofmicroservicesystems.Ittakestracesand
logs as input and trains a graph-based deep learning model. When
usedforanomalydetection,itanalyzesatraceandtheassociated
logsinasimilarwayandusesthemodeltogeneratearepresentation
for the trace to calculate its anomaly score.
An overview ofDeepTraLogis presented in Figure3, which in-
cludessixsteps. LogParsing parsestheinputlogsandextractslog
eventsfromthelogmessages. TraceParsing parsestheinputtraces
andconvertstheirspansintospanevents,whichwillbeanalyzed
625
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:58:31 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Chenxi Zhang, Xin Peng, Chaofeng Sha, Ke Zhang, Zhenqing Fu, Xiya Wu, Qingwei Lin, and Dongmei Zhang
Figure 3: DeepTraLog Overview
together with log events. Event Embedding generates vector rep-
resentations for span events and log events. Graph Construction
constructsatraceeventgraph(TEG)foreachtracetorepresentvar-
ious relationships between the span/log events of the trace. Model
Training trains a gated graph neural networks (GGNNs) based
deepSVDD(SupportVectorDataDescription)model,whichlearns
a latent representation for each TEG and a minimized hypersphere
that encloses the representations of the TEGs. Anomaly Detec-
tiondetermineswhetheratraceisanomalousbasedonitsanomaly
score(i.e.,theshortestdistancefromthelatentrepresentationof
its TEG to the hypersphere).
3.1 Log Parsing
Following existing researches on log anomaly detection [ 24,40],
we adopt a state-of-the-art log parsing approach Drain [ 11]. It can
parse logs in a streaming and timely manner with high parsing
accuracy and efficiency. To support the combined analysis with
traces, weextract and recordthe trace IDand spanID of eachlog
messagebeforelogparsing.Afterlogparsing,atraceIDandaspan
ID are attached with each of the extracted log events for further
analysis.
3.2 Trace Parsing
Thelogeventsofaserviceinstanceconstituteaneventsequence.To
combine traces and logs for anomaly detection, we need to convert
the spans of a trace into span events. Span events are a special
kindofeventsthatrepresenttherequestandresponseofservice
invocations. When analyzed together with log events, span events
can indicate the starts and ends of service invocations.
For each span of a trace, we convert it into multiple span events
ofrelatedspansaccordingtoitstype(Client/Server orProducer/Con-
sumer). AClient/Server span represents a synchronous invocation,
while aProducer/Consumer span represents an asynchronous invo-
cation. For a Client/Server span we generate a request event and
aresponseeventforthecurrentspan(server)anditsparentspan
(client)respectively.Therequesteventandtheresponseeventof
the client (server) represents the sending (receiving) of the service
invocationandthereceiving(sending)oftheinvocationresponse
respectively.Fora Producer/Consumer spanwegenerateaconsumer
event for the current span (consumer) and a producer event for the
parent span of the current span (producer). The producer eventand the consumer event represent the sending and receiving of the
message respectively.
Thecontentofaspaneventincludestwoparts,aneventtypeand
anoperationname.Forexample,fora Client/Server spanwiththe
operationname POST/api/v1/foodservice/orders,wegeneratetwo
span events â€œServer Request POST /api/v1/foodservice/ordersâ€ and
â€œServer Response POST /api/v1/foodservice/ordersâ€ for the current
spanandtwospaneventsâ€œClientRequestPOST/api/v1/foodservice/ordersâ€ and â€œClient Response POST /api/v1/foodservice/ordersâ€ for
the parent span of the current span; for a Producer/Consumer span
withtheoperationname RabbitMQ/Topic/Queue/email/sendEmail,
we generate a span event â€œConsumer RabbitMQ/Topic/Queue/e-
mail/sendEmailâ€forthecurrentspanandaspaneventâ€œProducer
RabbitMQ/Topic/Queue/email/sendEmailâ€fortheparentspanof
thecurrentspan.Eachspaneventhasatimestampobtainedfrom
the span record. For example, the timestamp of a client request
event is the time when the client service instance sends the service
invocation.
3.3 Event Embedding
Logeventembeddingiswidelyusedinloganomalydetection.Itgenerates a vector representation for each log event. The vector
representationcanidentifysemanticallysimilarlogeventsandalsodistinguishdifferentlogevents[
40].InDeepTraLog,spaneventsare
analyzedtogetherwithlogeventsforanomalydetection.Therefore,
our event embedding generates vector representations for both log
events and span events. Each log event or span event is a sequence
of English words, thus can be treated as a sentence. Following the
commonpracticeoflogeventembedding,DeepTraLogimplements
event embedding in three steps.
Step 1. Preprocessing. Log events and span events contain
non-character tokens (e.g., separators such as â€œ/â€ and â€œ,â€, IP ad-dresses), stop words (e.g., â€œaâ€, â€œtheâ€, â€œisâ€), and compound words
(e.g., â€œverifycodeâ€, â€œtripidâ€). Following previous works [ 24,40], we
preprocess log events and span events by removing non-verbalsymbols and stop words, and splitting compound words into in-dividual words. For example, a span event â€œClient Request POST
/api/v1/foodservice/ordersâ€ispreprocessedintoâ€œclientrequestpost
api v1 food service ordersâ€.
Step 2. Word Embedding. We use the widely used pre-trained
GloVemodel[ 29]togenerateavectorrepresentationforeachword
626
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:58:31 UTC from IEEE Xplore.  Restrictions apply. DeepTraLog: Trace-Log Combined Microservice Anomaly Detection through Graph-based Deep Learning ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Figure 4: An Example of Trace Event Graph (TEG)
inlogeventsandspanevents.Particularly,weusetheGloVe300-
dimensional word vectors trained on Wikipedia and Gigaword 5
data[9].Thusforeachwordwecanobtaina300-dimensionalvector
as its representation.
Step3. SentenceEmbedding.Sentence embeddinggenerates
a vector representation for each log event and span event based
on word embedding. The words in these events are not equally
important.Somewords(e.g.,â€œapiâ€,â€œgetâ€)aremorecommon,thus
arelessimportantthanothers(e.g.,â€œfoodâ€,â€œsubmitâ€)insentence
embedding. Therefore, we follow previous works [40] and use TF-
IDF[31]tomeasuretheweightofeachwordinsentenceembedding.
TF (Term Frequency) of a word ğ‘¤in an event ğ‘’, which measures
its importance in ğ‘’, is calculated by ğ‘‡ğ¹ğ‘¤,ğ‘’=ğ¿ğ‘¤,ğ‘’
ğ¿ğ‘’, where ğ¿ğ‘¤,ğ‘’is
theoccurrencesof ğ‘¤inğ‘’andğ¿ğ‘’isthenumberofwordsin ğ‘’.IDF
(Inverse Document Frequency) of a word ğ‘¤, which measures its
frequency in all events, is calculated by ğ¼ğ·ğ¹ğ‘¤=logğ¿
ğ¿ğ‘¤, where
ğ¿is the total number of events and ğ¿ğ‘¤is the number of events
containing ğ‘¤. Then the weight of a word ğ‘¤in an event ğ‘’can be
measuredbyitsTF-IDFscoreas ğ‘Šğ‘¤,ğ‘’=ğ‘‡ğ¹ğ‘¤,ğ‘’Ã—ğ¼ğ·ğ¹ğ‘¤.Thus,the
vectorrepresentationofanevent ğ‘’canbecalculatedastheweighted
sum of the vector representations of all its words as following,
whereğ‘ğ‘’isthenumberofdifferentwordsin ğ‘’andğ‘‰ğ‘¤isthevector
representation of a word ğ‘¤.
ğ‘‰ğ‘’=1
ğ‘ğ‘’ğ‘ğ‘’/summationdisplay.1
ğ‘¤=1ğ‘Šğ‘¤,ğ‘’Â·ğ‘‰ğ‘¤ (1)
Notethatlogeventsandspaneventshavequitedifferentchar-
acteristics, so we calculate the TF-IDF scores and word weights for
log events and span events separately.
3.4 Graph Construction
Atraceeventgraph(TEG)consistsofthelogeventsandspanevents
ofatraceandtheirrelationships.ArelationshipinaTEGcanbe
one of the following four types.
â€¢Sequence: A sequence relationship represents the predeces-
sor/successor relationship between two sequential span/log
events of the same span.â€¢SynchronousRequest:Asynchronousrequestrelationship
representsasynchronousrequestfromaparentspantoits
child span.
â€¢SynchronousResponse:Asynchronousresponserelation-
ship represents the response of a synchronous request from
a span to its parent span.
â€¢Asynchronous Request: An asynchronous request rela-
tionship represents an asynchronous request from a parent
span to its child span.
Given a trace, we construct a TEG in three steps.
Step 1: Connection of Log Events. For each span of the trace,
obtainallthelogeventsthatbelongtothespan.Thenorderthelog
eventsbytheirtimestampsandaddasequencerelationshipfrom
each log event to the one next to it.
Step2:InsertionofSpanEvents.Foreachspanofthetrace,
obtain all the span events that belong to the span. Then for eachobtained span event, insert it into the log event sequence of the
currentspanbasedonitstimestampandaddasequencerelationship
between it and its predecessor/successor event.
Step3:ConnectionofSpans.Foreachspanconnectitwithits
parentspaninthefollowingway.Ifthespanisa Client/Server span,
add a synchronous request relationship from the corresponding
client request event of its parent span to the corresponding server
request event of the current span, and a synchronous response
relationshipfromthecorrespondingserverresponseeventofthe
currentspantothecorrespondingclientresponseeventofitsparentspan.Ifthespanisa Producer/Consumer )span,addanasynchronous
requestrelationshipfromthecorrespondingproducereventofits
parent span to the corresponding consumer event of the current
span.
Figure 4 shows an example of TEG, which corresponds to the
trace shown in Figure 1 and Figure 2. In the graph, colored rect-angles and uncolored rectangles represent span events and log
events respectively. Span events of different colors are of different
types,includingclient/serverrequest,client/serverresponse,and
producer/consumer.Notethatthedottedroundedrectangleswhich
represent spans in Figure 4 are not the nodes of the TEG but arejust used for illustration. The spans are implicitly represented in
theTEGbytheeventsequencesstartingfromserverrequestevents.
627
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:58:31 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Chenxi Zhang, Xin Peng, Chaofeng Sha, Ke Zhang, Zhenqing Fu, Xiya Wu, Qingwei Lin, and Dongmei Zhang
Arrowsofdifferentcolorsrepresentdifferenttypesofrelationships.
The graphcan well describe thestructure of thetrace and various
relationships in it. The log events and span events in the same
spanformasequencebytheirtimestamps.Therefore,thetemporal
relationshipsbetween inter-serviceinteractions (spanevents) and
intra-servicebehaviors(logevents)canbedescribedandconsidered
inanomalydetection.Theeventsofdifferentspansareseparated
and only connected via request/response relationships between
span events. The structure of the trace is embodied in these re-
quest/response relationships: a synchronous invocation is reflected
byapairofrequestandresponserelationships;anasynchronous
invocation is reflected by a request relationship without the corre-
sponding response relationship. For example, it can be seen that
SpanBandSpanDareparallelsynchronousinvocationsastheir
request/response ranges in Span A overlap; Span F is an asynchro-
nousinvocationinitiatedbySpanDasthereisnoresponsefrom
Span F to Span D.
3.5 Model Training
We frame the task of trace-log combined microservice anomaly
detection asan one-classclassificationproblem. One-classclassifi-
cation problem aims to learn a model that can accurately describe
the train data which is considered belong to the same class. Foranomalydetectiontask,mostofthetrainingsamplesarenormal
oneswhichcanberegardedasthesameclassandtheotherscan
identified as outliers (e.g., anomalous traces in our work).
DeepTraLog uses deep SVDD [ 30] to train a one-class classifi-
cation model for detecting anomalous traces. Deep SVDD learnsuseful feature representations of the training data together with
aminimizedhyperspherethatenclosesthelatentrepresentations
of the data. Thus the data that is distant from the center of the
hypersphere can be considered anomalous. Existing deep learning
basedanomalydetectionapproaches[ 20,26]usuallyusedeepau-
toencoder to detect anomalies based on the reconstruction errorof the data. Thus the anomaly detection relies on an empiricallydetermined threshold of the reconstruction error, which is often
challenging.Incontrast,deepSVDDjointlylearnsthelatentrep-
resentations of the data and a classification boundary without a
threshold. Standard deep SVDD uses multi-layer perception (MLP)or convolutional neural networks (CNN) to learns the latent repre-
sentations of the data. However, in our work a trace is represented
byagraph(TEG)whichcannotbewellhandledbyMLPorCNN.
Therefore,weusegatedgraphneuralnetworks(GGNNs)tolearn
thetracerepresentationsandjointlytraintheGGNNswithdeep
SVDD.GGNNsisimplementedbasedontheneuralmessagepass-
ingmechanismandcanworkwellwithavarietytypesofgraphs,
such as directed graph, bipartite graph, and undirected graph.
In DeepTraLog, a trace is represented by a TEG, which is a
directedattributedgraph ğ‘”={ğ‘‰,ğ´,ğ‘‹}where: ğ‘‰isasetofnodes
(i.e., events); ğ´is adjacency matrix of the graph; and ğ‘‹âˆˆR|ğ‘‰|Ã—ğ‘‘is
thenode attributematrix, whereeachrow ğ‘¥ğ‘£ofğ‘‹isthe attribute
(i.e., event vector) of a node ğ‘£âˆˆğ‘‰,ğ‘‘is the dimension of the event
vector. GGNNs represents the nodes in a graph as units of a neural
network and the units are linked to each other according to the
adjacencymatrixofthegraph.GGNNspassesthenodeattributesasthemessagesbetweentheunitsineveryiterationandusesGRU[
4]to determine which messages to remember or forget during the
messagepassing. Thefinal representationofa nodeis determined
by a combination of its own state and the state of neighbouring
nodes.Therepresentationofanodeafterthe ğ‘¡-thiterationisdefined
by the following equations:
â„(0)
ğ‘£=ğ‘¥ğ‘£ (2)
ğ‘š(ğ‘¡)
ğ‘£=ğ´T
ğ‘£[â„(ğ‘¡âˆ’1)T
1...â„(ğ‘¡âˆ’1)T
|ğ‘‰|]T+ğ‘ (3)
â„(ğ‘¡)
ğ‘£=GRU(ğ‘š(ğ‘¡)
ğ‘£,â„(ğ‘¡âˆ’1)
ğ‘£) (4)
whereâ„(ğ‘–)
ğ‘£is the representation of a node ğ‘£after the ğ‘–-th itera-
tion;ğ‘¥ğ‘£istheinitialeventvectorofnode ğ‘£;ğ´ğ‘£=[ğ‘Tğ‘£,:,ğ‘:,ğ‘£]isthe
row and column in the adjacency matrix ğ´, which represent the
incoming edges and outgoing edges of ğ‘£;ğºğ‘…ğ‘ˆis the GRU function.
Finallyafter ğ‘‡iterationseachnodeinaTEGcanhave avectoras
the latent representation. GGNNs calculates the vector represen-
tationoftheTEGbasedonthenodevectorrepresentationsusing
asoft-attentionmechanism.Thesoft-attentionmechanismtakes
the vector representations of the nodes as input and calculates the
weight(attentionscore)ofeachnodethroughanattentionfunction
to give higher weights to the nodes that contribute more to the
graphclassification.ThegraphrepresentationofTEG ğ‘”iscalculated
by the following equation:
â„ğ‘”=tanh/parenleftBigg/summationdisplay.1
ğ‘£âˆˆğ‘‰ğœ™/parenleftBig
ğ‘“ğ‘–(â„(ğ‘‡)
ğ‘£,ğ‘¥ğ‘£)/parenrightBig
âŠ™tanh/parenleftBig
ğ‘“ğ‘—(â„(ğ‘‡)
ğ‘£,ğ‘¥ğ‘£)/parenrightBig/parenrightBigg
(5)
whereâ„ğ‘”isthevector representationofaTEG ğ‘”;ğœ™(ğ‘“ğ‘–(â„ğ‘£(ğ‘¡),ğ‘¥ğ‘£))
isthesoft-attentionmechanism; ğ‘“ğ‘–andğ‘“ğ‘—areneuralnetworks; ğ‘‡is
the number of layers of GGNNs; âŠ™is element-wise multiplication.
Readers can refer to [17] for more details about GGNNs.
DeepTraLogtrainstheGGNNsusingthefollowinglossfunction,
whichexpressestheobjectiveoflearningaminimizedhypersphere
to enclose the vector representations of TEGs:
ğ¿ğ‘œğ‘ ğ‘ =ğ‘…2+1
ğœ‡ğ‘ğ‘”ğ‘ğ‘”/summationdisplay.1
ğ‘”=1max{0,||â„ğ‘”âˆ’ğ‘||2âˆ’ğ‘…2}+ğœ†
2ğ‘ğ‘™/summationdisplay.1
ğ‘™=1||ğœƒ(ğ‘™)||2
ğ¹(6)
whereğ‘is the center of the hypersphere; ğ‘…is the radius of the
hypersphere; ||â„ğ‘”âˆ’ğ‘||2is the distance fromthe latent representa-
tionofaTEG ğ‘”toğ‘;ğ‘ğ‘”isthenumberofTEGs; ğ‘ğ‘™isthenumber
of network layers in GGNNs; the hyperparameter ğœ‡controls the
trade-off between the hypersphere volume and the violations of
the boundary, which allows some training data mapped outside
thehypersphere(i.e.,allowingsomeanomalydatainthetraining
set);ğœ†
2/summationtext.1ğ‘ğ‘™
ğ‘™=1||ğœƒ(ğ‘™)||2
ğ¹isaweightdecayregularizerontheGGNNs
parameters ğœƒwith hyperparameter ğœ†.
Inthetrainingphase,wejointlyoptimizetheGGNNsparameters
ğœƒandthehypersphereradius ğ‘…inEquation6.WeuseAdam[ 14]to
optimizetheGGNNsparameters ğœƒineachepoch.Astheradius ğ‘…is
not an inner parameter of GGNNs, we optimize it using a different
method as follows. We optimize ğœƒwith a fixed ğ‘…in the first few
epochsandafterevery ğ‘˜epochswecalculateanoptimizedvalue
forğ‘…by linear search. Each time when ğ‘…is updated its value is
628
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:58:31 UTC from IEEE Xplore.  Restrictions apply. DeepTraLog: Trace-Log Combined Microservice Anomaly Detection through Graph-based Deep Learning ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Figure 5: Visualization of An Anomalous TEG
calculated as the (1âˆ’ğœ‡)percentile of the distances of all the TEGs
inthecurrentepoch.Thehyperspherecenter ğ‘issettothemeanof
thevectorrepresentationsofalltheTEGsafteraninitialforward
pass.
3.6 Anomaly Detection
DeepTraLog trains a GGNNs based deep SVDD model for anom-
aly detection. Given a new trace and the corresponding log foranomaly detection, DeepTraLog follows the same process as thetraining phase (i.e., log parsing, trace parsing, event embedding,
andgraphconstruction)toproduceaTEGtogetherwithitsevent
embedding for the trace. Then DeepTraLog feeds the TEG into the
trainedmodeltogeneratealatentrepresentationoftheTEGand
usesthelatentrepresentationtocalculateananomalyscore.The
anomaly score is defined as the shortest distance from the latentrepresentation of the TEG to the learned hypersphere, which is
calculated by the following equation:
ğ‘ğ‘›ğ‘ (â„ğ‘”)=||â„ğ‘”âˆ’ğ‘||2âˆ’Ë†ğ‘…2(7)
whereâ„ğ‘”is the vector representation of a TEG ğ‘”;ğ‘is the center
of the learned hypersphere; Ë†ğ‘…is the final radius of the learned
hypersphere.
ForaTEG ğ‘”ofatrace,ifitsanomalyscore(i.e., ğ‘ğ‘›ğ‘ (â„ğ‘”))isgreater
than 0 it is treated as anomalous.
Tohelptheuserstounderstandtheresultsofanomalydetection,
DeepTraLog provides a visualization of the TEGs of anomaloustraces. Figure 5 presents an example of the visualization of an
anomalousTEG.Specifically,DeepTraLoghighlightsthenodesin
theTEGthathavehighattentionscorescalculatedusingEquation5,
which helps the users to quickly locate the anomalous parts of the
trace.
4 EVALUATION
WeimplementDeepTraLogusingPython3.8.8,PyTorch1.8.0,and
PyTorchGeometric1.7.2(forGGNNslearning).Toevaluateitwe
conduct aseries ofexperimentalstudies toanswerthe following
research questions:Table 1: Fault Types in the TrainTicket Dataset
FaultType FaultCases Example
Asynchronous
InteractionF1,F2, F13 F1:asynchronousmessagedeliv-
ery without sequence control
Multi-Instance F8,F11, F12 F12: service states not synchro-nized among different instances
of the service
Configuration F3,F4, F5, F7 F4: improper configurations of
SSL
Monolithic F6, F9, F10,
F14F14: wrong calculating process of
train ticket price
â€¢RQ1: How effective is DeepTraLog in microservice anomaly
detectioncomparedwithbaselineapproaches?Howmuch
does theunified graph representation contribute to the ef-
fectiveness of DeepTraLog?
â€¢RQ2: How efficient is DeepTraLog in model training and
anomalydetectioncomparedwithbaselineapproaches?How
doesDeepTraLogscalewiththesizeoftraceinonlinepre-
diction?
â€¢RQ3: How do different configurations of the GGNNs-baseddeep SVDD model impact the effectiveness of DeepTraLog?
4.1 Experimental Design
4.1.1 BenchmarkSystemandDataset. Ourstudiesareconducted
on the latest release V0.2.0 of TrainTicket1[42,44]. It is a medium-
scale open-source microservice system for train ticket bookingand has been widely used in researches on microservice archi-tecture, infrastructure, and AIOps (Artificial Intelligence for IT
Operation)[ 20,41,43].Ithas45serviceswrittenbydifferentlan-
guages (e.g., Java, JavaScript, Python) and communicating with
synchronous REST invocations and asynchronous messaging.
TrainTicketreplicates avarietyofdifferent typesoffaultcases
fromindustrialmicroservicesystemsandprovidesthefaultcasesin
different fault branches. The latest release of TrainTicket provides
14 compatible fault cases of different types as shown in Table 1.
Each fault case may include multiple fault instances in different
services. The fault types include [43]:
â€¢AsynchronousInteraction -faultscausedbymissingor
improper coordination of asynchronous service invocations;
â€¢Multi-Instance - faults related to the existence of multiple
instances of the same service at runtime;
â€¢Configuration - faultscaused byimproper orinconsistent
configurations of services and/or environments (e.g., con-
tainers and virtual machines);
â€¢Monolithic - faults caused by internal implementations of
individual services, which can cause failures even when the
application is deployed in a monolithic mode.
Thus we can have a normal version of TrainTicket and 14 faulty
versionseachcorrespondingtothebranchofafaultcase.Wedeploy
different versions of TrainTicket on a Kubernetes cluster with 8
virtualmachines,eachofwhichhasa16-core3.0GHzCPUand32GB
RAM.WeusePythontoimplementanexecutioncontrollerthatcanexecuteautomatedtestcases.Foreachversionweusetheexecution
1TrainTicket Project: https://github.com/FudanSELab/train-ticket
629
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:58:31 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Chenxi Zhang, Xin Peng, Chaofeng Sha, Ke Zhang, Zhenqing Fu, Xiya Wu, Qingwei Lin, and Dongmei Zhang
controller to simulate user requests by executing automated test
cases.WeuseApacheSkyWalking[ 33]asthedistributedtracing
frameworktocollecttracesandlogsanduseElasticSearch[ 8]to
store the collected traces and logs.
The resulted dataset includes 132,485 traces and 7,705,050 log
messages. Among the traces 23,334 (17.6%) are anomalous ones
causedby73faultsofthe14faultcaseswhicharelocatedindifferent
services.Thisdatasetisusedthroughoutthewholeexperimental
studies. It is available in our replication package [5].
4.1.2 Baselines. We use the following four state-of-the-art log-
basedortrace-basedanomalydetectionapproachesasthebaselines.
â€¢TraceAnomaly [20] is a trace anomaly detection approach
that only considers service-level traces (operations not con-
sidered). It adopts posterior flow based variational auto-
encoders (VAE) to detect anomalous traces.
â€¢MultimodalTrace [26] is a trace anomaly detection ap-
proach that treats a trace as a span sequence and a response
timesequence.Itadoptsamulti-modalLSTM(LongShort-
Term Memory) model to learn the sequential patterns of
normal traces.
â€¢DeepLog [7]isaloganomalydetectionapproachthattreats
a log as an event sequence. It adopts an LSTM model to pre-
dict the next log event in the sequence and identify possible
anomalies.
â€¢LogAnomaly [24]isaloganomalydetectionapproachthat
treatsalogasaneventsequenceandconsidersthecounts
ofdifferent logeventsasan additionalfeature.It adoptsan
LSTMmodeltolearnsequentialandquantitativepatterns.
SimilartoDeepLog,itdetectsanomaliesbypredictingthe
next log event.
As TraceAnomaly and MultimodalTrace only consider traces,
we feed them with only the traces when using them. LogAnomaly
andDeepLogonlyconsiderlogsandtreatthemaseventsequences.
Therefore, we combine all the events (including span events and
logevents)ofdifferentspansofatraceintoasingleeventsequence
orderedbytimestampandprovidetheeventsequencesofallthetraces as the input for these two approaches. TraceAnomaly and
DeepLogprovideopen-sourceimplementations[ 22,34]andweuse
themdirectly.Theothertwoapproacheshavenopubliclyavailable
implementations,sowedevelopourownimplementationsbased
on their papers.
To evaluate the contribution of the unified graph representation
of traces and logs (i.e., TEG), we derive a variant of DeepTraLog
calledGRU-based Deep SVDD which represents all the events of
atrace asan eventsequenceordered bytimestamp andusesGRU
instead of GGNNs.
For all these baseline approaches we experimentally choose the
best parameters and use their optimal results for comparison.
4.1.3 Metrics. Weusetheprecision,recall,andF1-scoretomeasure
the effectiveness of anomaly detection based on ğ‘‡ğ‘ƒ(True Positive),
ğ¹ğ‘ƒ(False Positive), and ğ¹ğ‘(False Negative).
â€¢Precision: the percentage of anomalous traces out of alltraces detected as anomalies, represented as
ğ‘ğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘› =
ğ‘‡ğ‘ƒ
ğ‘‡ğ‘ƒ+ğ¹ğ‘ƒ.Table 2: Effectiveness of Different Approaches
Approach Precision Recall F1-Score
TraceAnomaly 0.742 0.205 0.321
MultimodalTrace 0.591 0.776 0.671
DeepLog 0.608 0.948 0.741
LogAnomaly 0.415 0.977 0.582
GRU-base d Deep SVDD 0.864 0.776 0.818
DeepTraLog 0.930 0.978 0.954
(a) DeepTraLog
 (b) GRU-based Deep SVDD
Figure 6: Distribution of Latent Representations of Traces
â€¢Recall:thepercentageofallanomaloustracesthatarede-
tected as anomalies, represented as ğ‘Ÿğ‘’ğ‘ğ‘ğ‘™ğ‘™ =ğ‘‡ğ‘ƒ
ğ‘‡ğ‘ƒ+ğ¹ğ‘.
â€¢F1-Score: the harmonic mean of precision and recall, repre-
sented as ğ¹1=2Â·ğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘› Â·ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™
ğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘› +ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™.
4.1.4 Settings. AlltheexperimentsareconductedonaLinuxserver
withIntelCorei9-10900X3.70GHzCPU,128GBRAM,RTX3090
with 24GB GPU memory and running Ubuntu 18.04.5. The setting
of DeepTraLog are the following: the embedding size of each event
set to 300, the hidden layer of GGNNs set to 3, the hidden sizeof each hidden layer set to 300, the
ğœ†andğœ‡in Equation 6 set to
0.001 and 0.05 respectively, and the batch size set to 32. Following
thepracticein[ 30],weemployasimpletwo-phaselearningrate
schedulewithaninitiallearningrate0.0001inthefirst60epochs
and subsequently 0.00001 in the last 40 epochs. For each approach
we leverage 60% of the normal traces as the training set, 10% of
the normal traces as the validation set, and the rest of the traces
(include the rest 30% of the normal traces and all the anomalous
traces) as the test set.
4.2 RQ1: Effectiveness
Table2showstheeffectivenessevaluationresultsofdifferentap-
proaches.DeepTraLogoutperformsallthebaselineapproachesandachievesahighprecision(0.930),recall(0.978),andF1-score(0.954).
The two trace-based approaches (i.e., TraceAnomaly and Mul-
timodalTrace) achieve low precision and recall. These two ap-proaches do not consider logs, thus cannot detect anomalies inlog events. As they use sequence-based trace representation and
haveaspecialfocusonresponsetime,theycanonlydetectanom-
aliesthathavesignificantimpactonspansequencesordistribution
of response time.
630
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:58:31 UTC from IEEE Xplore.  Restrictions apply. DeepTraLog: Trace-Log Combined Microservice Anomaly Detection through Graph-based Deep Learning ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Table 3: Training and Testing Time of Different Approaches
Methods Training Time Testing Time
TraceAnomaly 30m 137s
MultimodalTrace 30.4m 148s
DeepLog 77.6m 278s
LogAnomaly 816m 3,136s
GRU-base d Deep SVDD 138.8m 105s
DeepTraLog 67.1m 77s
The two log-based approaches (i.e.,DeepLog and LogAnomaly)
achievehighrecallandlowprecision.Thesetwoapproachescon-
sider events within spans (we provide both span events and log
events for them), thus can detect anomalies in span sequences and
log event sequences. However, they rely on the prediction of the
next event in a sliding window of the event sequence, thus haveno global view of the trace and its structure. Therefore, they arelikely to falsely report unseen event subsequences as anomalies.
Actually, this kind of log anomaly detection approaches usually
work on a single log event sequence such as the HDFS dataset [ 38].
Thus,theycannotwellworkformicroserviceanomalydetection
whichinvolvesmanyserviceinstancesanddistributedlogevents
in parallel and asynchronous service invocations.
GRU-basedDeepSVDDachievesbetterprecisionandrecallthan
thefourbaselineapproaches.Itconsidersallthespaneventsand
log events of a trace, thus performs better than log anomaly detec-
tion approacheswhich relyon slidingwindow based loganalysis.
However, its sequence-based representation of span events andlog events ignores the complex structures of traces brought by
theirinvocationhierarchiesandparallel/asynchronousinvocations.
Therefore, it does not perform as well as DeepTraLog.
Figure 6 shows the comparison of the results produced by Deep-
TraLog and GRU-based deep SVDD. We use t-SNE [ 36] to visualize
the latent representations of the traces in the test set by project-
ingthemto2Dspace.ItcanbeseenthatDeepTraLogcanlearna
hypersphere that can better enclose normal traces and distinguish
anomaloustracesfromnormalones.Webelievethattheimprove-
ment is broughtby the unified graph representationof traces and
logs.
In conclusion, DeepTraLog is effective in microservice anomaly
detectionandoutperformsexistingtrace-andlog-basedanomaly
detectionapproachesby64.94%and101.59%onaverageinterms
of precision and recall respectively. The unified graph representa-
tionsignificantlycontributestotheimprovementofDeepTraLog,
makingitoutperformthevariantofDeepTraLogusingsequence
representation by 7.64% and 26.03% in terms of precision and recall
respectively.
4.3 RQ2: Efficiency
Usingeachoftheapproaches,wetrainananomalydetectionmodel
with the training set (including 65,490 traces) and test the model
withthetestset(including56,080traces).Table3showsthetraining
time and testing time of each approach. These approaches take 30-
816 minutes to train the models and 77-3,136 seconds to finishthe test. In general, all the approaches except LogAnomaly are
efficient,forexampletrainingamodelinabout30-138minutesandfinishingthetest(thewholetestset)in77-278seconds.DeepTraLog
is slower than the two trace-based approaches (i.e., TraceAnomaly
and MultimodalTrace) but much faster than the others in model
training. It is much faster than all the other approaches in testing.
Thetwotrace-basedapproaches (i.e., TraceAnomalyandMulti-
modalTrace) are much faster than DeepTraLog in training, as they
onlyconsidertraces.DeepTraLogconsidersbothtracesandlogs,
thus uses more time in training. However, DeepTraLog is much
faster than them in testing. The reason is that the network param-
etersğœƒcompletelycharacterizetheanomalydetectionmodeland
no data has to be stored for anomaly detection [30].
Thetwo log-based approaches (i.e.,DeepLog and LogAnomaly)
useslidingwindowstosegmenteventsequences,thusproducea
largenumberofsubsequencesfortrainingandtesting.Moreover,
LogAnomaly uses an additional count vector sequence for each
subsequence and the dimension of the count vectors is determined
by the number of log events. Public log datasets usually have a
smallnumberoflogevents.Forexample,theHDFSlogdataset[ 38]
contains only about 40 log events. In contrast, our dataset has
morethan800log/spanevents,causingthecurseofdimensionality
forLogAnomaly.Thelargenumberoflog/spaneventsispopular
in microservice systems, thus traditional log anomaly detection
approaches cannot work well for microservice systems.
GRU-basedDeepSVDDusesmuchsimplersequencerepresen-
tationfortracesandlogs,butisslowerthanDeepTraLoginboth
trainingandtesting.ThereasonisthatGGNNstreatsnodes(events)
in the graph as network units and conducts message passing inparallel, while GRU serially processes every event in a very long
sequence.
Theresponsetimeofonlinepredictionisimportantforachieving
timelyanomalydetection.Ithighlydependsonthesizeofthetrace,
i.e., the number of span/log events in it. To evaluate the scalability
ofDeepTraLogwithtracesize,weconductanexperimentonthe
changesofresponsetimewiththeincreaseofeventnumber.Wedivide the event number 0-900 into nine ranges, e.g., 0-100, 100-
200,andforeachrangerandomlysample100traceswhoseevent
numbers are within the range. For each trace we run the anom-
alydetectionmodel300timesandcalculatetheaverageresponse
timeofprediction.WecomparetheaverageresponsetimeofDeep-
TraLog and GRU-based Deep SVDD for traces of different sizes.
Figure 7 shows the results. It can be seen that the response time of
both approaches increases linearly with the size of the trace and
DeepTraLog is always faster than GRU-based Deep SVDD.
Inconclusion,DeepTraLogisslowerthantrace-basedapproaches
by122.19%andfasterthanlog-basedapproachesby52.65%intrain-
ing; it is faster than trace-based approaches by 45.88% and faster
thanlog-basedapproachesby84.92%intesting.Moreover,there-
sponsetimeofDeepTraLogincreaseslinearlywiththesizeofthe
trace and it costs DeepTraLog around 4 milliseconds to make a
prediction when the trace includes 800-900 events.
4.4 RQ3: Impact of Configurations
The hyperparameter ğœ‡in the loss function (see Equation 6) and
the hidden layer number of GGNNs are two important parameters
of the GGNNs based deep SVDD model. As stated in Section 3.5,
ğœ‡controlsthetrade-offbetweenthehyperspherevolumeandthe
631
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:58:31 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Chenxi Zhang, Xin Peng, Chaofeng Sha, Ke Zhang, Zhenqing Fu, Xiya Wu, Qingwei Lin, and Dongmei Zhang
Figure 7: Changes of Response Time with the Increase of
Event Number
(a) hyperparameter ğœ‡in Equation 6
(b) hidden layer number of GGNNs
Figure 8: Impact of Different Configurations
violations of the boundary. The hidden layer number of GGNNs
determines the iterations of message passing between the nodes
in a TEG, thus has great impact on the latent representation the
TEG. The regularization parameter ğœ†in Equation 6 usually can
be empirically set (e.g., 0.001 in our implementation) as previous
work [30].
Figure 8(a) shows the impact of ğœ‡on the precision, recall, and
F1-score of DeepTraLog. In deep SVDD, ğœ‡usually can take a value
between0.01and0.1[ 30].Bigger ğœ‡usuallyleadstolowerprecisionand higher recall as it makes a smaller hypersphere enclosing less
normal traces andanomalous traces. According to theresults, ğœ‡=
0.07achievesthebesttrade-offin termsofF1-score.Notethatthe
bestconfigurationof ğœ‡highlydependsonthecharacteristicsofthe
dataset. It usually can be determined based on the preference on
precision and recall.
Figure 8(b) shows the impact of the hidden layer number of
GGNNs.Itisusuallysettotwotofour.Itcanbeseenthatbothrecall
and F1-score decrease with the increase of hidden layer number. It
is usuallybecause thatmore hiddenlayers are morelikely tolead
toover-smoothing,whichmakesthefeaturesindistinguishableand
thus hurts the classification accuracy [16].
4.5 Threats to Validity
Thethreatstotheinternalvaliditymainlylieintheimplementation
andconfigurationofbaselineapproachesandtheprocessofdataset
generation.WeimplementMultimodalTrace andLogAnomalyby
ourselvesastheyhavenopubliclyavailableimplementations.These
twoapproachesarebasedonstandarddeeplearning(e.g.,LSTM)
andlogeventextraction(e.g.,FT-Tree)components.Wefollowtheir
papers and assemble the components in the same way. Regarding
the impact of configuration, we experimentally choose the best
configurations for all the baseline approaches. For DeepTraLog we
experimentallyinvestigatethe impactofsomekeyparameterson
its effectiveness and report the results. The normal and anomalous
traces in our dataset are generated by automatically executing the
normalandfaultyversionsofthebenchmarksystemrespectively.Itisthuspossiblethatthenormaltracesmayincludelatentanomalies.
Toalleviatethethreat,wecarefullytesttheinvolvedscenariosof
thenormalversionbeforeexecutionandmanuallycheckthequality
of a set of sampled traces after execution.
The threats to the external validity mainly lie in the bench-
mark system and fault cases. Our approach is only evaluated on
TrainTicket and its fault cases. It is unclear whether it can be effec-
tively used formore complex industrial microservicesystems and
fault cases. These threats are alleviated from two aspects. First, the
dataset we construct includes complex traces including about 900
eventsandinvolvingparallelandasynchronousserviceinvocations.
Typicallyatraceinindustrialmicroservicesystemsinvolvesdozens
ofserviceinvocationsandhundredsoflogevents.Therefore,the
sizeoftraceiscomparable.Second,thefaultcasesofTrainTicket
arereplicatedfromrealfaultsinindustrialsystemsandcoverdif-
ferent types of typical faults [ 42]. Therefore, the fault cases used in
the evaluation are representative.
5 RELATED WORK
Traditional software anomaly detection approaches are mainly
based on logs [ 7,12,18,23,24,37,39,40]. Typically log anomaly
detectionconsistsoftwostages.First,itextractslogeventsfrom
log messages via log parsing. Widely used log parsing approaches
includeDrain[ 11]andSpell[ 6].Second,itconductsanomalydetec-
tiononlogeventsequences.Earlystudiesusenumericvectorsto
representlogsequences, whichareusuallygenerated bycounting
thenumbersofvariouslogeventinlogsequences.Louetal.[ 23]
propose an approach that mines the invariant relationships among
632
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:58:31 UTC from IEEE Xplore.  Restrictions apply. DeepTraLog: Trace-Log Combined Microservice Anomaly Detection through Graph-based Deep Learning ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
log events for anomaly detection. Xu et al. [ 37] use Principal Com-
ponentAnalysis(PCA)todetectloganomalies.Linetal.[ 18]use
the hierarchical clustering technique to identify log anomalies and
He et al. [ 12] extend their work by identifying the correlations
between logs and system metrics.
Recently,therearesomeapproachesusingdeeplearningtode-
tect log anomalies. Du et al.[ 7] propose a log anomaly detection
approachcalledDeepLog,whichdetectsanomaliesbypredicting
the next log event using LSTM. Similarily, Meng et al. [ 24] propose
a log anomaly detection approach called LogAnomaly. It combines
semanticvectorsproducedbywordembeddingandnumericvec-
tors for the prediction of the next log event using LSTM. Zhang et
al.[40]alsousesemanticvectorstorepresentlogeventsanduse
BiLSTM to detect anomalies of the whole log sequence in an su-
pervised manner. Yang et al. [ 39] extend [ 40] to a semi-supervised
approach which estimates the labels of log sequences using PU
learning. These log anomaly detection approaches are based onsequence representations of log events, thus cannot well detect
anomalous traces that involve complex structures.
Inmicroservicesystems,tracesarewidelyusedinanomalyde-
tectionandrootcauseanalysis[ 10,19,20,25,26,28].Traditional
approaches [ 10,42] rely on the visualization of traces to support
manual trace analysis. Zhou et al. [ 42] conduct an empirical study
onindustrialpracticesofmicroservicefaultanalysisanddebuggingandproposeanimprovedtracevisualizationmethod.Guoetal.[
10]
presentan approachthatuses traceaggregationandvisualization
to help the analysis of error propagation chains.
Recently,someresearchersproposeautomatedapproachesfor
trace anomaly detection. Zhou et al. [ 43] propose a supervised
approach to detect anomalous traces based on a set of featuresextracted from traces. It relies on fault injection to produce alarge number of normal and anomalous traces for training and
asetofpredefinedtracefeaturesextractedfromdifferentaspects.
Other approaches detect various types of anomalies by learning
patterns from the traces produced by normal execution [ 20,25,26].
Nedelkoskietal.[ 25]detectresponsetimeanomaliesinmicroser-
vicesystemsbytraininganAuto-EncodingVariationalBayesmodel.
Nedelkoski et al. [ 26] represent each trace as a span sequence and
a response time sequence and design a multimodal LSTM modelto detect anomalous traces. Liu et al. [
20] use a service trace vec-
tor to represent each trace, which treats each possible path as a
dimensioninthevector.Thesetraceanomalydetectionapproaches
do not consider logs. Moreover, they usually represent a trace as a
sequence and do not consider the complex structures of traces.
6 CONCLUSION
Inthispaper,wehaveproposedDeepTraLog,adeeplearningbased
microserviceanomalydetectionapproach.Itusesaunifiedgraphrepresentationtodepictthecomplexstructureofatracetogether
withlogeventsembeddedinthestructure.Basedontherepresenta-
tionwedesignaGGNNsbaseddeepSVDDmodelwhichcanlearnalatentrepresentationforeachtraceandaminimizeddata-enclosing
hypersphere.Weusethemodeltodetectanomaloustracesbycal-
culating their distancesto the center of thehypersphere. We have
evaluatedDeepTraLogonamicroservicebenchmark.Theresults
showthatDeepTraLogsignificantlyoutperformsstate-of-the-arttrace/loganomalydetectionapproaches.Ourfutureworkwillex-
tendDeepTraLogtosupportmoredifferentkindsofanomaliesof
microservice systems such as response time anomalies, and on the
otherhandevaluateDeepTraLogwithdifferentkindsofmicroser-
vice systems.
7 DATA AVAILABILITY
All the data and results of the work can be found in our replication
package [5].
REFERENCES
[1]Alibaba. 2021. ARMS. Retrieved August 15, 2021 from https://www.aliyun.com/
product/arms
[2]Apache. 2021. Log4j. Retrieved August 15, 2021 from https://logging.apache.
org/log4j/2.x/
[3]AWS.2021. X-Ray. RetrievedAugust15,2021fromhttps://aws.amazon.com/xray
[4]Kyunghyun Cho, Bart van Merrienboer, Ã‡aglar GÃ¼lÃ§ehre, Dzmitry Bahdanau,
Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning Phrase
RepresentationsusingRNNEncoder-DecoderforStatisticalMachineTranslation.
In2014 Conference on Empirical Methods in Natural Language Processing, EMNLP
2014. ACL, 1724â€“1734. https://doi.org/10.3115/v1/d14-1179
[5]DeepTraLog. 2021. DeepTraLog. Retrieved August 25, 2021 from https://
fudanselab.github.io/DeepTraLog/
[6]MinDuandFeifeiLi.2016. Spell:StreamingParsingofSystemEventLogs.In
IEEE16thInternationalConferenceonDataMining,ICDM2016 .IEEEComputer
Society, 859â€“864. https://doi.org/10.1109/ICDM.2016.0103
[7]MinDu,FeifeiLi,GuinengZheng,andVivekSrikumar.2017. DeepLog:AnomalyDetectionandDiagnosisfromSystemLogsthroughDeepLearning.In 2017ACM
SIGSACConferenceonComputerandCommunicationsSecurity,CCS2017.ACM,
1285â€“1298. https://doi.org/10.1145/3133956.3134015
[8]elastic. 2021. Elasticsearch. Retrieved August 15, 2021 from https://www.elastic.
co/elasticsearch/
[9]GloVe. 2021. GloVe. Retrieved August 15, 2021 from https://nlp.stanford.edu/
projects/glove/
[10]Xiaofeng Guo, Xin Peng, Hanzhang Wang, Wanxue Li, Huai Jiang, Dan Ding,
Tao Xie, and Liangfei Su. 2020. Graph-based trace analysis for microservice
architecture understanding and problemdiagnosis. In 28th ACM JointEuropean
SoftwareEngineeringConferenceandSymposiumontheFoundationsofSoftware
Engineering,ESEC/FSE2016.ACM,1387â€“1397. https://doi.org/10.1145/3368089.
3417066
[11]Pinjia He, Jieming Zhu, Zibin Zheng, and Michael R. Lyu. 2017. Drain: An
Online Log Parsing Approach with Fixed Depth Tree. In 2017 IEEE International
Conference on Web Services, ICWS 2017. IEEE, 33â€“40. https://doi.org/10.1109/
ICWS.2017.13
[12]Shilin He, Qingwei Lin, Jian-Guang Lou, Hongyu Zhang, Michael R. Lyu, andDongmei Zhang. 2018. Identifying impactful service system problems via log
analysis.In 2018ACMJointMeetingonEuropeanSoftwareEngineeringConference
andSymposiumontheFoundationsofSoftwareEngineering,ESEC/SIGSOFTFSE
2018. ACM, 60â€“70. https://doi.org/10.1145/3236024.3236083
[13]Jaegertracing.Io. 2021. Jaeger. Retrieved August 15, 2021 from https://www.
jaegertracing.io/
[14]DiederikP.KingmaandJimmyBa.2015. Adam:AMethodforStochasticOpti-
mization. In 3rd International Conference on Learning Representations, ICLR 2015.
http://arxiv.org/abs/1412.6980
[15]James Lewis and Martin Fowler. 2014. Microservices a definition of this new
architectural term. Retrieved August 25, 2021 from https://www.martinfowler.
com/articles/microservices.html
[16]QimaiLi,ZhichaoHan,andXiao-MingWu.2018. DeeperInsightsIntoGraph
ConvolutionalNetworksforSemi-SupervisedLearning.In Thirty-SecondAAAI
Conference on Artificial Intelligence, (AAAI-18), Sheila A. McIlraith and Kilian Q.
Weinberger(Eds.).AAAIPress,3538â€“3545. https://www.aaai.org/ocs/index.php/
AAAI/AAAI18/paper/view/16098
[17]Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard S. Zemel. 2016. Gated
GraphSequenceNeuralNetworks.In 4thInternationalConferenceonLearning
Representations, ICLR 2016. http://arxiv.org/abs/1511.05493
[18]QingweiLin,HongyuZhang,Jian-GuangLou,YuZhang,andXueweiChen.2016.
Logclusteringbasedproblemidentificationforonlineservicesystems.In 38th
IEEE/ACM International Conference on Software Engineering, ICSE 2016. ACM,
102â€“111. https://doi.org/10.1145/2889160.2889232
[19]DeweiLiu,ChuanHe,XinPeng,FanLin,ChenxiZhang,ShengfangGong,Ziang
Li, Jiayu Ou, and Zheshun Wu. 2021. MicroHECL: High-Efficient Root Cause
LocalizationinLarge-ScaleMicroserviceSystems.In 43rdIEEE/ACMInternational
633
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:58:31 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Chenxi Zhang, Xin Peng, Chaofeng Sha, Ke Zhang, Zhenqing Fu, Xiya Wu, Qingwei Lin, and Dongmei Zhang
Conference on Software Engineering: Software Engineering in Practice, ICSE (SEIP)
2021. IEEE, 338â€“347. https://doi.org/10.1109/ICSE-SEIP52600.2021.00043
[20]PingLiu,HaowenXu,QianyuOuyang,RuiJiao,ZhekangChen,ShenglinZhang,
JiahaiYang,LinlinMo,JiceZeng,WenmanXue,andDanPei.2020. Unsupervised
DetectionofMicroserviceTraceAnomaliesthroughService-LevelDeepBayesian
Networks. In 31st IEEE International Symposium on Software Reliability Engineer-
ing, ISSRE 2020. IEEE, 48â€“58. https://doi.org/10.1109/ISSRE5003.2020.00014
[21]Logback. 2021. Logback. Retrieved August 15, 2021 from http://logback.qos.ch/
[22]LogPAI. 2021. Loglizer. Retrieved August 15, 2021 from https://github.com/
logpai/loglizer
[23]Jian-GuangLou,QiangFu,ShengqiYang,YeXu,andJiangLi.2010. MiningInvari-
antsfromConsoleLogsforSystemProblemDetection.In 2010USENIXAnnual
Technical Conference. USENIX Association. https://www.usenix.org/conference/
usenix-atc-10/mining-invariants-console-logs-system-problem-detection
[24]WeibinMeng,YingLiu,YichenZhu,ShenglinZhang,DanPei,YuqingLiu,Yihao
Chen,RuizhiZhang,ShiminTao,PeiSun,andRongZhou.2019.LogAnomaly:Un-
supervised Detection of Sequential and Quantitative Anomalies in Unstructured
Logs. InTwenty-Eighth International Joint Conference on Artificial Intelligence,
IJCAI 2019. ijcai.org, 4739â€“4745. https://doi.org/10.24963/ijcai.2019/658
[25]SashoNedelkoski,JorgeS.Cardoso,andOdejKao.2019. AnomalyDetectionand
ClassificationusingDistributedTracingandDeepLearning.In 19thIEEE/ACM
International Symposium on Cluster, Cloud and Grid Computing, CCGRID 2019.
IEEE, 241â€“250. https://doi.org/10.1109/CCGRID.2019.00038
[26]SashoNedelkoski,JorgeS.Cardoso,andOdejKao.2019. AnomalyDetectionfromSystemTracingDataUsingMultimodalDeepLearning.In 12thIEEEInternational
Conference on Cloud Computing, CLOUD 2019. IEEE, 179â€“186. https://doi.org/10.
1109/CLOUD.2019.00038
[27]Opentracing.io. 2021. OpenTracing. Retrieved August 15, 2021 from https:
//opentracing.io/
[28]YichengPan,MengMa,XinruiJiang,andPingWang.2021. Faster,deeper,easier:crowdsourcingdiagnosisofmicroservicekernelfailurefromuserspace.In ISSTA
â€™21:30thACMSIGSOFTInternationalSymposiumonSoftwareTestingandAnalysis.
ACM, 646â€“657. https://doi.org/10.1145/3460319.3464805
[29]JeffreyPennington,RichardSocher,andChristopherD.Manning.2014. Glove:
GlobalVectorsforWordRepresentation.In 2014ConferenceonEmpiricalMethods
inNaturalLanguageProcessing,EMNLP2014.ACL,1532â€“1543. https://doi.org/
10.3115/v1/d14-1162
[30]Lukas Ruff, Nico GÃ¶rnitz, Lucas Deecke, Shoaib Ahmed Siddiqui, Robert A. Van-
dermeulen,AlexanderBinder,EmmanuelMÃ¼ller,andMariusKloft.2018. Deep
One-ClassClassification.In 35thInternationalConferenceonMachineLearning,
ICML 2018 (Proceedings of Machine Learning Research, Vol. 80). PMLR, 4390â€“4399.
http://proceedings.mlr.press/v80/ruff18a.html
[31]GerardSaltonandChrisBuckley.1988.Term-WeightingApproachesinAutomatic
TextRetrieval. Inf.Process.Manag. 24,5(1988),513â€“523. https://doi.org/10.1016/
0306-4573(88)90021-0
[32]BenjaminHSigelman,LuizAndreBarroso,MikeBurrows,PatStephenson,Manoj
Plakal, Donald Beaver, Saul Jaspan, and Chandan Shanbhag. 2010. Dapper, a
large-scale distributed systems tracing infrastructure.
[33]skywalking.apache.org.2021. ApacheSkyWalking. RetrievedAugust15,2021
from http://skywalking.apache.org/
[34]TraceAnomaly. 2021. TraceAnomaly. Retrieved August 15, 2021 from https:
//github.com/NetManAIOps/TraceAnomaly
[35] Twitter. 2021. Zipkin. Retrieved August 15, 2021 from https://zipkin.io/[36]
Laurens van der Maaten and Geoffrey Hinton. 2008. Visualizing Data usingt-SNE.Journal of Machine Learning Research 9, 86 (2008), 2579â€“2605. http:
//jmlr.org/papers/v9/vandermaaten08a.html
[37]Wei Xu, Ling Huang, Armando Fox, David Patterson, and Michael Jordan. 2009.
Largescale system problem detection by mining console logs. Proceedings of
SOSPâ€™09(2009).
[38]WeiXu,LingHuang,ArmandoFox,DavidA.Patterson,andMichaelI.Jordan.
2009. Detecting large-scale system problems by mining console logs. In 22nd
ACM Symposium on Operating Systems Principles, SOSP 2009. ACM, 117â€“132.
https://doi.org/10.1145/1629575.1629587
[39]LinYang,JunjieChen,ZanWang,WeijingWang,JiajunJiang,XuyuanDong,and
WenbinZhang.2021. PLELog:Semi-SupervisedLog-BasedAnomalyDetection
via Probabilistic Label Estimation. In 43rd IEEE/ACM International Conference on
SoftwareEngineering,ICSE2021.IEEE,230â€“231. https://doi.org/10.1109/ICSE-
Companion52605.2021.00106
[40]Xu Zhang, Yong Xu, Qingwei Lin, Bo Qiao, Hongyu Zhang, Yingnong Dang,
Chunyu Xie, Xinsheng Yang, Qian Cheng, Ze Li, Junjie Chen, Xiaoting He, Ran-
dolphYao,Jian-GuangLou,MuraliChintalapati,FuraoShen,andDongmeiZhang.
2019. Robust log-based anomaly detection on unstable log data. In 2019 ACM
JointMeetingonEuropeanSoftwareEngineeringConferenceandSymposiumon
the Foundations of Software Engineering, ESEC/SIGSOFT FSE 2019. ACM, 807â€“817.
https://doi.org/10.1145/3338906.3338931
[41]NengwenZhao,JunjieChen,ZhaoyangYu,HonglinWang,JiesongLi,BinQiu,
Hongyu Xu, Wenchi Zhang, Kaixin Sui, and Dan Pei. 2021. Identifying bad
software changes via multimodal anomaly detection for online service systems.InESEC/FSEâ€™21: 29thACM JointEuropean SoftwareEngineeringConference and
SymposiumontheFoundationsofSoftwareEngineering,Athens,Greece,August
23-28, 2021. ACM, 527â€“539. https://doi.org/10.1145/3468264.3468543
[42]Xiang Zhou, Xin Peng, Tao Xie, Jun Sun, Chao Ji, Wenhai Li, and Dan Ding.
2021. Fault Analysis and Debugging of Microservice Systems: Industrial Survey,
Benchmark System, and Empirical Study. IEEE Trans. Software Eng. 47, 2 (2021),
243â€“260. https://doi.org/10.1109/TSE.2018.2887384
[43]XiangZhou,XinPeng,TaoXie,JunSun,ChaoJi,DeweiLiu,QilinXiang,and
ChuanHe.2019. Latenterrorpredictionandfaultlocalizationformicroservice
applicationsbylearningfromsystemtracelogs.In 2019ACMJointMeetingon
European Software Engineering Conference and Symposium on the Foundations of
SoftwareEngineering,ESEC/SIGSOFTFSE2019.ACM,683â€“694. https://doi.org/10.
1145/3338906.3338961
[44]XiangZhou,XinPeng,TaoXie,JunSun,ChenjieXu,ChaoJi,andWenyunZhao.
2018. Benchmarking microservice systems for software engineering research. In
40th International Conference on Software Engineering, ICSE 2018 . ACM, 323â€“324.
https://doi.org/10.1145/3183440.3194991
634
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 07:58:31 UTC from IEEE Xplore.  Restrictions apply. 