Fast and Precise Application Code Analysis using a Partial
Library
Akshay Utture
University of California, Los Angeles
U.S.A.
akshayutture@ucla.eduJens Palsberg
University of California, Los Angeles
U.S.A.
palsberg@ucla.edu
ABSTRACT
Long analysis times are a key bottleneck for the widespread adop-
tionofwhole-programstaticanalysistools.Fortunately,however,
auserisoftenonlyinterestedinfindingerrorsintheapplication
code,whichconstitutesasmallfractionofthewholeprogram.Cur-
rent application-focused analysis tools overapproximate the effect
ofthelibraryandhencereducetheprecisionoftheanalysisresults.
However, empirical studies have shown that users have high ex-
pectations on precision and will ignore tool results that don’t meet
these expectations.
Inthispaper,weintroducethefirsttool QueryMax thatsignifi-
cantlyspeed supanapplicationcodeanalysiswithoutdroppingany
precision. QueryMax acts as a pre-processor to an existing analysis
tooltoselectapartiallibrarythatismostrelevanttotheanalysis
queries in the application code. The selected partial library plus
the application is given as input to the existing static analysis tool,
with the remaining library pointers treated as the bottom element
in the abstract domain. This achieves a significant speedup over a
whole-programanalysis,atthecostofafewlosterrors,andwithno
lossinprecision.Weinstantiateandrunexperimentson QueryMax
foracast-checkanalysisandanull-pointeranalysis.Foraparticular
configuration, QueryMax enables these two analyses to achieve,
relative to a whole-program analysis, an average recall of 87%, a
precisionof100%andageometricmeanspeedupof10x.
CCS CONCEPTS
•Softwareanditsengineering →Automatedstaticanalysis .
ACM Reference Format:
Akshay Utture and Jens Palsberg. 2022. Fast and Precise Application Code
AnalysisusingaPartialLibrary.In 44thInternationalConferenceonSoftware
Engineering (ICSE ’22), May 21–29, 2022, Pittsburgh, PA, USA. ACM, New
York, NY, USA, 12 pages. https://doi.org/10.1145/3510003.3510046
1 INTRODUCTION
Motivation. Long analysis times are a key bottleneck for the
widespreadadoptionofwhole-programstaticanalysistools.Several
recent papers for both Java [ 3,10,15] and C/C++ [ 8,22,23] report
that a whole-program analysis on their largest benchmarks can
takeseveralhours.Analyzingalargecollectionofbenchmarkslike
This work is licensed under a Creative Commons Attribution International 4.0 
License.
ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
© 2022 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-9221-1/22/05.
https://doi.org/10.1145/3510003.3510046an app-store takes even longer, with a total compute time of many
years for the largest app-stores. Hence, a speedup in analysis time
cansave significantcomputetime andenergy,and enableus touse
more precise and expensive algorithms.
Whole-programanalysesmaybeslow,butauserisoftenonly
interested in finding errors in the application code [ 34], which
constitutes a small fraction of the whole program. In the NJR-1
dataset [31], application code (excluding third-party libraries) con-
stituteslessthan1%ofthewholeprogramonaverage.Hence,an
application-focusedanalysishasthepotential foralargespeedup.
Ideally,anapplication-focusedanalysisshouldcomputethesame
set of errors for the application-code as a whole-program analysis.
However, this is hard to achieve because errors can both originate
in or propagate through the library. We use the singular libraryto
refer to the aggregate of the third-party libraries and the standard
library.Thequalityofanapplication-focusedanalysistool’sresults
can be quantified using precisionandrecall.Precisionis the ratio of
true-positivesinthetool’sresults,withthewhole-programanalysis
results serving as the ground-truth. Recallis the ratio of whole-
program analysis errors caught by the tool. Thus, any application-
focusedanalysistoolcanbejudgedbyitsperformanceonthethree
metricsofprecision,recallandspeedup.
Thecurrentbesttoolforanapplication-focusedanalysisisAver-
roes [1]. Averroes overapproximates the effect of the library with a
compact summary. The overapproximation ensures high recall and
the small size of the summary compared to the whole library gives
a large speedup. However, this summary is created by merging the
analysis information from all the library pointers into a single set,
resulting in significantly worseprecision than the whole program
analysis. In our experiments, Averroes gets an average precision of
59% relative to the whole-program analysis. This precision drop is
problematic because empirical studies show that users have a very
high bar for precision.
For example, Christakis and Bird [ 6] find that, in practice, static
analysis users care much more about precision than recall. They
concludethatpracticalanalysistoolsmustaimforaminimumof
80%user-perceived precision. Failing to meet this value results in
users ignoringthe tooloutput entirely.Other empirical studies[4,
13] also arrive at similar conclusions. Whole-program analyses
themselves often get much less than 80% user-perceived precision
[3,5,18].Hence,anapplication-focusedanalysisthatgetslessthan
100% precision relative to a whole-program analysis will almost
certainlyfailtomeetthe80% user-perceivedprecision target.This
defines the goal of our paper.
Ourgoalinthispaperistocapturethespeeduppotentialofan
application-focused analysis, while maintaining 100% precision
relative to the whole-program analysis.
9342022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)
ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Akshay Utture and Jens Palsberg
Partial LibraryApplication code
Analysis queries
ErrorsQueryMaxExisting static
analysis toolApplication code
Analysis queriesLibrary
87% recall  
10x speedup
Figure 1: Overview of the QueryMax workflow
Our technique. In this paper, we introduce a new application-
focused analysis tool called QueryMax , that achieves our goal of
100% precision and gets both good speedup and good recall. Fig-
ure1givesanoverviewoftheworkflow. QueryMax actsasapre-
processor to an existing static analysis by selecting a small subset
ofthelibrary(i.e.partiallibrary)whichisrelevanttothesetofanal-
ysis queries in the application. To decide which part of the library
is most relevant, QueryMax uses a new static analysis called the
externalsourceanalysis.Once QueryMax picksthepartiallibrary,
the existing static analysis tool is run on the application code plus
thepartiallibrary,withallexternallibrarypointerstreatedasthe
bottom element in the abstract domain.
TheanalysisqueriesusedinFigure1areexactlylikethequeries
in a demand-driven analysis [ 28] and they represent all the in-
structions of interest in the application code. For example, in a
cast-checkanalysis,theanalysisquerieswouldbeallthedown-cast
instructions in the application code.
The complexity of QueryMax isO(a3+p2)whereais the size
ofthe application-codeand pisthe sizeofthe(application-code +
partial-library).Thisismuchlessthanthecomplexityofawhole-
program analysis like 0CFA, which has complexity O(n3)where
nis the size of the whole program. Here we assume (n>p)and
(n>>a), both of which are true for our benchmarks.
OurexperimentsfocusonJavabytecodeprogramsfromtheNJR-
1 dataset [ 31], but our approach applies to other object-oriented
languages as well. We implemented QueryMax in Wala [ 33] and
ran experiments on it with an existing cast-check analysis and null
pointer analysis.
Our contributions.
•We introduce a new static analysis, the external source anal-
ysis, which computes the set of external library pointers
affecting each pointer in the application code.
•We describe the QueryMax tool which uses the external
source analysisand picks a partial library which issmall yet
sufficient to yield a good recall.
•Weshowexperimentallythat QueryMax successfullyspeeds
uptwodifferentanalyses.Inaparticularconfiguration, Query-
Maxachievesa97%recall(onaverage,relativetoawhole-
program) and an 8.7x geometric-mean speedup for a cast-
checkanalysis,anda(79%recall,11.2xspeedup)foranull
pointer analysis. Both analyses get 100% precision.Whole Program
A(2)B(3)
C(1)(0.2) (0.2) (0.2)
(0.2)(0.2)
(0.2)
(0.2)
(0.2)
(0.2) (0.2)(Cast 1)
(Cast 2)(Cast 3)
(Cast 5)(Cast 4)
(Cast 6)
(Cast 9)(Cast 10)(Cast 8) (Cast 7)Application-codeD(1.5)
E(1.5)
Figure 2: Schematic of a cast-check analysis on application-
code
Significance. The impact of this research contribution is that the
10x analysis speedup without any loss in precision will help us
meet user expectations on both speedup and precision. Further,
the speedup will enable us to use expensive and precise analysis
algorithmsaswellasanalyzelargeprogramsorlargecollectionsof
programs(likeanapp-store)thatpreviouslycouldn’tbeanalyzed
in a reasonable amount of time.
2 EXAMPLE
In this section, we show an example of how QueryMax picks a par-
tiallibrarytoanalyze,andcomparethiswithAverroes’approach.
Wealsodiscusstwootherbaselineswhichcanbeadaptedtopro-
videaspeedupoverawhole-programanalysis:ademand-driven
analysis [24, 28] and an application-only analysis.
Figure2showstheschematicofaprogramwewishtoanalyze
forcast-errors.Theapplicationcode,representedbythecircle,is
the part in which we wish to catch the cast errors, and everything
outsideisthelibrary.Thegreyboxes(labeled A,B,C)ontheedge
of the circle show library methods with pointers that influence the
valueofcastinstructionsintheapplicationcode.Theaccompanying
number in the grey box tells us how many cast instructions are
affected by that method. The application code has a total of 10 cast
instructions and each cast instruction is considered an analysis
query. We say that an application-focused analysis coversa cast-
queryifitoverapproximatestheresultofthatquery.Inotherwords,a query
coveredby a tool is guaranteed to mark it as a cast-error if
the whole-program analysis does.
The first baseline technique is to run a demand-driven analy-
sis for every analysis query in the application. The demand-driven
analysisexhaustivelytracesthebackwardsliceofall10castinstruc-
tions.Castsnumbered7-10atthebottomoftheapplicationcircle
gettheirvaluefrominsidetheapplication,andhenceareansweredquickly.Thecastsaffectedby
BandC(castsnumbered3-6)arealso
answeredquicklybecausethebackwardsliceshaveonly2and0
caller-methods respectively. However, the demand-driven analysis
faces a significant slowdown when answering the two cast queries
influencedby A(Cast1andCast2).Theirbackwardtraceinvolves
the10callersofA,eachofwhichcouldresultinalongtrail,making
935Fast and Precise Application Code Analysis using a Partial Library ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
this approach expensive because of these two queries. In total, the
demand-driven analysis analyzes all the 15 library methods in the
figure. It gets 100% precision and covers all 10 cast instructions
since its output is identical to the whole-program analysis. Note
thatthedemand-drivenanalysisistheonlyonewhichrequiresa
newdemand-drivendesignofanexistinginter-proceduralanalysis;
the others use the existing interprocedural analysis as is.
The second baseline is an application-only analysis. Such an
analysis analyzes the code inside the application circle in isolation
and assumes the bottom element of the abstract domain for alllibrary pointers outside. Hence it analyzes zero library methodsand only
coversthe 4 casts that get their values from inside the
application (that is, the casts numbered 7-10). The application-onlyanalysisgets100%precisionbecauseitserrorsarethesubsetofthe
whole-program errors that do not involve the library.
Averroes [ 1] improves upon the application-only analysis by
modeling the whole library with a small summary. In Figure 2,
everythingoutsidethe applicationcircleisrepresented usingthis
summary. The summary primarily consists of a single summary-
pointertorepresentalllibrarypointers,andasinglesummary-nodetoperformalltheobjectinitializationsandapplicationcall-backs.Ausualinter-proceduralcast-analysisisperformedontheapplication-
code plus this summary. Averroes’s summary is sound for someanalyses, the cast check being one them. Hence, it covers all 10
cast instructions while only analyzing the summary. However, the
analysis information merged in the common summary-pointer
and summary-node drops precision relative to the whole-program
analysis.
QueryMax’s approach differs from Averroes primarily in that
it selects a small part of the library to fully analyze instead of
modelingthelibraryusingasummary. QueryMax keepsexpanding
thepartiallibrarytobeuseduntilitreachessomestoppingcriterion.
Let usassume thatwe use QueryMax with astopping criterionof
80%querycoverage.Thismeansthatwewillhavetopicka fragment
consistingoftheapplication-codeplusapartiallibrary,suchthatat
least 8 of the 10 queries (i.e. casts) are coveredwithin this fragment.
QueryMax startsoutbyperformingan externalsourceanalysis
on the application code to find out which library pointers affect
the 10 cast instructions. This information is marked by the arrows
insidetheapplicationcircle. QueryMax thenassignsprioritiesto
eachexternallibrarymethodbasedonthenumberofcastsitaffects.
In Figure 2, this is denoted by the numbers in the grey boxes. Next,
QueryMax expandsonthemethodwiththehighestpriority(method
B) to look at its callers, callees and field-reads. Method Bhas 2
callers,DandE. We estimate that each of DandEaffects half as
many casts as B, and hence each of them get half its priority (i.e.
1.5 each). Now, the method with the highest priority is A, which
on expansion leads to 10 different caller methods, and we assign
a priority of (2 / 10) to each of them. The next methods with the
highest priorityare DandE, followedby method C. Eachof these
methods are expanded in turn.
At this point, our fragment consists of the application code plus
a partial library consisting of methods ( A,B,C,D,E). Performing
anotherexternal source analysis on this fragment shows that now 8
ofthecasts(castsnumbered3-10)arecoveredwithinthisfragment.
Recallthatwestarted QueryMax withastoppingcriterionof80%
querycoverage,orinotherwords,wewouldliketoterminatewhenAnalysis Tool Casts
coveredLib MethodsanalyzedPrecision
Application-only 4 0 100%
QueryMax 8 5 100%
Demand-driven 10 15 100%
Averroes 10 Summary Low
Figure3:Numberofcastscovered,librarymethodsanalyzed,and Precision (relative to the whole program analysis) foreach of the competing tools
8 of the 10 casts (i.e. queries) are covered. Hence, QueryMax stops
expandingatthispoint,andanexistinginter-proceduralcast-check
analysis is now performed on this fragment. By terminating the ex-
pansionearly, QueryMax avoidedexploringthe10callersofmethod
A,andtheirsubsequentcallerswhichcouldpotentiallyexpandlarge
sectionsoftheprogram,whileonlyansweringthequeriesfor Cast1
andCast2. In total, by using QueryMax , we analyzed only 5 library
methodsandcovered8casts. QueryMax ,justlikeanapplication-
onlyanalysis,reportsasubsetofthewhole-programerrors,thereby
getting 100% precision.
Figure 3 summarizes the number of library methods analyzed
(lessisbetter),thecast-instructionscovered(moreisbetter),and
precision(moreisbetter)foreachofthefourtechniques. QueryMax ,
the demand-driven analysis and the application-only analysis each
get100%precision.Fortheothertwometrics, QueryMax obtains
a useful trade-off point in between the application-only analysisand the demand-driven analysis. Note that the differences in li-brary methods analyzed is rather small for this example, but the
differencesaremuchlargerinrealprograms.Averroescoversall
casts and analyzes just the small summary, but gets low precision,
thereby falling short of our 100% precision goal.
This example illustrates the core insight underlying QueryMax’s
speedup: few queries in the application code require large sections
of the library for their analysis (like Cast1andCast2), whereas
the remaining queries need a much smaller subset of the library.
Byidentifyingtheseexpensivequeriesandassigningthemalow
priority,QueryMax can pick a small partial library that is sufficient
to cover all the remaining queries. The downstream client can nowuse this partial library in its analysis, which is a fraction of the sizeofthewholelibrary.Thetrade-offisthatthefewexpensivequeries
(likeCast1andCast2intheexample)arenotfullycoveredbythe
partial library, resulting in a few missed errors.
3 APPROACH
In this section, we describe in detail how QueryMax works to pick
the partial library to analyze.
3.1 Overview
QueryMax picks its partial library by finding the library classes
mostlylikelyrelevanttothequeriesintheapplicationcode. Query-
Maxaccomplishes this by using a new static analysis called an
external source analysis. QueryMax expands its partial library in
agreedyfashiontomaximizethenumberofqueriesansweredin
theapplicationcodeuntilsomestoppingcriterionisreached.We
936ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Akshay Utture and Jens Palsberg
No Stmt Condition Constraint
1 x = y x is not an array ext(y) ⊆ext(x)
2 x = y x is an array ext(y)⊆ext(x) and
ext(x)⊆ext(y)
3 x = y.f field f is internal ext(f) ⊆ext(x)
4 y.f = x field f is internal ext(x) ⊆ext(f)
5 x = foo(z) target foo(p){.. ret q}
is internalext(q)⊆ext(x) and
ext(z)⊆set(p)
6 x = y.f field f is external {f} ⊆ext(x)
7 y.f = x field f is external (No constraint)
8 x = foo(z) target foo(p){.. ret q}
is external{q}⊆ext(x)
9 N/A foo(x)hasanexternal
caller y.foo(z){z}⊆ext(x)
Figure 4: Constraints for the External Source Analysis
discusstwostoppingcriteria:a class-budget iftheuserwantstoset
a limit on the number of classes analyzed (proxy for analysis time),
and aquery-coverage if the user wants to set a goal for the number
of queries covered (proxy for recall).
3.2 External Source Analysis (ESA)
Theexternalsourceanalysis,or ESAforshort,takesaprogramand
a subset of its classes called the fragment, and computes, for every
pointerinthefragment,thesetofexternalpointersthatpassvalues
to it. For example, defining the application code as the fragment
would make the library pointers the external pointers, and an ESA
would tell us which library pointers directly pass values to each
pointerintheapplicationcode.AnexampleofapplyingtheESA
was illustrated in the example in Figure 2, where we computed the
library methods affecting cast-instructions in the application code.
TheESAisdesignedtobecontext-,flow-andfield-insensitive
because it’s primary application is partial-program analysis, which
istime-sensitive.AnyoverheadofperforminganESAduringpartial
program analysis eats into the speedup that we may get over a
whole-program analysis.
Figure 4 outlines the core constraints used for ESA. The second
columnlistsastatement,thethirdcolumnlistsanaccompanying
condition, and the fourth column gives the corresponding con-
straint. The third column in the figure uses the words internaland
external.Apointerisconsideredinternalifitiswithinthefragment,andexternalotherwise.TheabstractdomainfortheESAconsistsofall possible subsets of external pointers. Hence, the notation
ext(y)
inthefourthcolumnrepresentsthesetofexternalpointerspassing
valuestothefragmentpointer y.Thisisdifferentfromthenotation
{z}which is a singleton set consisting of the external pointer z.
Rows1-5inFigure4areidenticaltoastandardcontext,flowand
field-insensitive pointer analysis such as [ 29], and we assume that
the reader understands them well. Rows 6-9 deal with the different
types of external pointers: external fields, external return values,
andexternalfunction-arguments.Theconstraintsfortheserows
are similar to what one would expect for a newstatement in a
pointer analysis. Row 6 says that for the read of an external field f,
theexternalfield fshouldbeaddedtothe extsetoftheassigned
variablex. Row 7 says that writes to external fields produce noconstraint.Row8saysthatforeveryexternaltargetofamethod
call,thereturnpointerofthetargetshouldbeaddedtothe extsetof
theassignedvariable x.Therearenoconstraintsforthearguments
inthiscase.Row9saysthatifamethodinthefragmenthasacaller
outside the fragment,then the external caller’s argument should
be added to the extset of the method’s parameter.
Thegeneratedconstraintscanbesolvedusingstandardstatic-
analysis constraint solving techniques. The complexity of solving
theESAconstraintsonafragmentofsize pisO(p3).Thecomplexity
calculationsareverysimilartothatofacontext-insensitivepointer
analysis.
In addition to the ESA, we define a faster version of it called the
fast-ESA, with the primary change being to the abstract domain.
Insteadofmaintainingthesetofexternalsourcesforeveryfragment
pointer,fast-ESA only maintains whether or not the set is non-
empty. Hence there are only two elements in the fast-ESAabstract-
domain:thetopelementisusedwhenthefragmentpointermaybepassedavaluebyanexternalsource,andthebottomelementisused
whenthepointerisguaranteedtonotgetanyvaluesfromexternal
sources.TheconstraintsarethesameasinFigure4,exceptforRows
6-9 using the Top element instead of the external pointer names.
Duetothesmallersizeoftheabstractdomain,thecomplexityof
fast-ESAonafragmentofsize pisO(p2),whichislesserthanthe
cubic complexity of ESA. Hence, fast-ESA allows us to compute
whetherafragmentpointerisaffectedbyexternalsourcesmuch
quicker than an ESA.
3.3 QueryMax Algorithm
TheQueryMax algorithm is used to pick a fragment to analyze,
consisting of the application and the partial library, with a best
efforttocatchasmanyofthewhole-programerrorsaspossible.TheexampleinSection2showedhow QueryMax runsforoneparticular
case.Here, wedescribethealgorithm (giveninFigure. 5)indetail.
The figure has three main procedures: the main algorithm, the
class-budgetstoppingcriterionandthequery-coveragestopping
criterion.
Themainalgorithm(line1)takesasinputtheapplicationclasses,
setofallclasses,andthequeriestobeanswered.Forinternalbook-
keeping, QueryMax uses the set fraдment to mark the classes
that are to be analyzed finally, a visitedset for the methods, and a
priority-queue pQueuetokeeptrackoftheprioritiesoftheexternal
(library) methods to be explored. The intuition behind the priority
valuesisthattheyrepresenttheestimatednumberofqueriesan-
sweredby thatmethod, and QueryMax will explore methodswith
a higher priority earlier.
The main algorithm starts off by performing an ESA (line 5),
withtheapplicationclassesasthe fraдment .TheESAcomputes
the set of external library pointers affecting each pointer in the
applicationclasses.UsingtheESAresult,wecomputeitsinverse
information:thenumberofqueriesaffectedbyeachoftheexternal
librarypointers(line6).Now,themethodofeachoftheexternallibrary pointers is added to
pQueuewith a priority equal to the
number of queries it affects. For external field pointers, we add the
methodswhichwritetothatfield.Eachoftheexternallibrarypoint-
ers’methodsareaddedtothe visitedset.Afterthisinitialization
phase, we move into the main algorithm loop.
937Fast and Precise Application Code Analysis using a Partial Library ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
1:procedure QueryMax(appClasses, allClasses, queries)
2:fragment ←appClasses
3:visited←new Set()
4:pQueue←new PriorityQueue()
5:esa←ESA(allClasses, appClasses)
6:extLibPtrs ←computeAffectedQueries(esa, queries)
7:forExternalLibraryPointer e in extLibPtrs do
8: pQueue.setPriority(e.method, e.affectedQueries)
9: visited.add(e.method)
10:end for
11:whilenot (pQueue.empty() ∨Criterion) do
12: Method m ←pQueue.poll()
13: analysisFragment.add(m.declaringClass)
14: methodSlice ←getmethodSlice(m)
15: newPriority ←m.priority / methodSlice.size
16: forMethod n in methodSlice do
17: ifvisited.contains(n) then
18: pQueue.addToOldPriority(n,newPriority)
19: else
20: pQueue.setPriority(n, newPriority)
21: visited.add(e)
22: end if
23: end for
24:end while
25:returnfragment
26:end procedure
27:
28:procedure BudgetCriterion(fragment)
29:percentAnalyzed ←(fragment.size / allClasses.size)
30:return(percentAnalyzed ≥budget)
31:end procedure
32:33:
procedure CoverageCriterion(fragment, queries)
34:coveredQueries ←fastESA(allClasses, fragment, queries)
35:coverageRatio ←coveredQueries / fragment.totalQueries
36:return(coverageRatio ≥goal)
37:end procedure
Figure 5: QueryMax algorithm
The main algorithm loop starts at line 11. It keeps looping until
eitherpQueueis empty or we satisfy the stopping criterion (de-
scribed below). Inside the loop, we remove the method mwith the
maximum priority in pQueue, and add its class to the fraдment .
Thisstepisagreedymovetoexpandtheclassthatisexpectedto
affect the largest number of queries. The next step is to find the
method-slice ofm(line 14). This is similar to computing one step in
the backward slice of a pointer, but is performed at the granularity
ofmethodsinsteadofpointerstoreducetheoverhead.The method-
sliceconsists of callersand callees of m, as wellas methods which
write to fields that are read in m. Each method in the method-slice
gets a new priority which is the priority of mdivided by the size
ofitsmethod-slice.Theintuitionbehindthispriorityassignment
is that if maffectskqueries and has tcallers/callees, then each
caller/callee is expected to affect k/tqueries. If a method from the
method-sliceisalreadyin pQueueweaddthenewprioritytoitsoldpriority,elseweaddthemethodto pQueuewiththenewpriority.Fi-
nally,oncetheloophasterminated,the fraдment ,whichhastheset
of classes to be analyzed, is returned. An existing inter-procedural
static analysis is performed on the set of classes returned, with all
external pointers assumed to be the bottom element.
QueryMax uses a stopping criterion to know when to stop ex-
panding the fragment and return, and we experiment with two
such criteria: class-budget andquery-coverage goal.
Class budget. The class budget stopping criterion (line 28) is
used when the user wants a handle on the analysis time. The class
budgetisaproxyforatimebudget,andweprefertousethenumber
of classes instead of analysis time because it can be accurately
computed in advance without running the actual analysis. Thiscriterion simply checks if the percentage of classes used in the
fragmentisgreaterthanacertainbudget.Thebudgetisassumedto
bespecifiedasaglobalvariableforreadability.Forthispaper,we
experimentwitha3%,10%and30%class-budget.Abudgetofunder2% will have no space for library methods in some programs, and a
budget of over 40% will analyze a large partial library, resulting in
onlyasmallspeedup.
Query-coverage goal. The query-coverage criterion (line 33) is
usedwhentheuserwantsahandleontherecall.Query-coverageis
a proxy for recall, because the number of errors found is expected
to be proportional to the number of queries covered. The query-
coveragecriterionusesa fast-ESA(line34)tofindthenumberof
queries covered by the fragment classes, and computes a coverage-
Ratiowhich is the percentage of queries covered. Finally, if the
coverage-Ratio exceeds the query-coverage goal, then we return
true. The goal is assumed to be specified as a global variable forreadability. The coverage criterion is not used at every iterationof the main loop because the fast-ESAadds significant overhead.
Instead,weonlyevaluatethiscriterionatsomesetcheckpoints.For
this paper, we experiment with 70% and 90% query-coverage goals.
A goal of less than 60% gives recall close to that of a application-
only analysis, and a goal of greater than 95% requires too many
classestobeaddedtothepartiallibrary,therebyresultingintoo
small a speedup.
Theoverallcomplexityfor QueryMax isO(a3+p2)whereaisthe
sizeoftheapplication-codeand pisthesizeofthe(application-code
+partial-library).The O(a3)termcomesfromtheESAperformed
onthe application-codeon line5,and the O(p2)termcomes from
thefast-ESAperformed for the coverage-criterion on line 34.
3.4 Applicability of QueryMax to Client Static
Analyses
Nowthatweunderstandhow QueryMax worksasapreprocessorto
select a partial library, we can discuss what kind of client analyses
QueryMax can be applied to.
Firstly, since QueryMax trades off recall for analysis speedup,
itsclientanalysisshouldbeabletoaffordtolosesomerecall.For
example,compileroptimizationclientsthatpreferthestaticanal-
ysisbesound(orsoundy[ 16]),willnotuse QueryMax .Secondly,
QueryMax isrestrictedtoclientanalysesthatonlycareabouterrors
938ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Akshay Utture and Jens Palsberg
Client Analysis Analysis Queries
Cast-check analysis [29] Cast instructions
Null-pointer analysis [12] Method calls and field accessesTaint Analysis [17] Taint sink instructions
Type-state analysis [9] State-change instructionsPointer analysis [14] Client analysis queries
Figure 6: Analaysis Queries for different Client Analyses
manifestingintheapplicationcode.Itcannotspeedupaclientanal-
ysisthataimstocatcherrorsmanifestinginboththeapplication
code and the library.
On the plus side, QueryMax makes no assumptions about the
flow-,context-andfield-sensitivityoftheclientanalysisthatitispreprocessingfor.Henceitcanbeappliedregardlessoftheclient
analysis’ sensitivities. Further, unlike [ 1], it makes no assumptions
aboutthedemarkationbetweenapplicationandlibrarycode.Hence,
theusercanchooseanysubsetofclassesastheapplicationcodeto focus on and get everything outside the subset treated as the
library.
Figure 6 lists some analysis clients that QueryMax could be
appliedtoandshowsthecorrespondinganalysisqueriesforsucha
client analysis. This is not an exhaustive list of client analyses, and
itsmainpurposeistogiveexamplesofwhattheanalysisqueries
wouldbefordifferentkindsofclientanalyses.Typically,ananalysis
query would be any instruction in the application code where aparticular kind of error could potentially manifest. For example,
for a cast-check analysis the queries are cast instructions. For a
null-pointeranalysistheyarealldereferenceinstructions,including
methodcallsandfieldaccesses.Forataint-analysiswhichisdefinedintermsofvulnerablesource-sinkpairs,theanalysisquerieswould
beallthesinks.Foratype-stateanalysis,likeonethatchecksfor
thecorrectnessoffile-operations,allthestate-changeoperations
(likefile-open,file-close,etc.)willbetheanalysisqueries.Apointer
analysisitselfdoesnothaveanystatementsorvariablesofinterest,
and hence cannot define analysis queries for itself. Ho wever,if the
pointer analysis is used by a particular client (like cast-check or
taint analysis),we can defineits analysisqueries as thequeries of
that client.
4 IMPLEMENTATION
The WALA [ 33] framework for Java bytecode analysis is used to
implement QueryMax and the ESA analysis. The actual analysis is
performed on the WALA IR, which is in SSA form and hence auto-
maticallygrantspartialflow-sensitivity.WeusetheCHA-callgraph
for all the analyses, since computing a whole-program 0-CFA call-
graph would defeat the purpose of doing a partial library analysis.
Weignorecall-graphedgesinvolvingasinglecall-sitewithmore
than 10 targets, since the likely root cause of this is severe impreci-
sion, and it results in mostly false-positives. We also exclude the
java/utilpackage since it is well known for introducing too many
false-positives unless one uses high context-sensitivity [30].
Client Analyses. QueryMax accepts any inter-procedural anal-
ysis to run with as long as the analysis can be run on a subset of
the classes in the program. We experiment with two such analyses:a cast-check analysis and a null-pointer analysis. The cast-checkanalysis is based on the VTA algorithm [
29] for pointer analysis.
The null-pointer analysis (based on [ 12]), focuses on catching null-
pointer exceptions resulting from uninitialized instance fields. The
two analyses vary significantly in their constraints, abstract do-
mains,designdecisions,numberofanalysisqueries,andnumber
of errors per program. Hence, the two analyses offer considerable
diversityforexperimentation.Weleavetofutureworktoexperi-
mentwithotherclientanalysis,includingotherimplementations
of cast-check and null-pointer analysis, such as NullAway [2].
For the analysis sensitivities, we choose to be context-, flow-
andfield-insensitiveasfaraspossible.Thecast-checkanalysisis
insensitiveonallthreeaxes.Thenull-pointeranalysisiscontext-
and field-insensitive but flow-sensitive because a flow-insensitive
version of the analysis trivially marks all fields as null. Our choice
of sensitivities are different from other papers such as [ 24–26], be-
causetheirtaskistoimprovepre cision,whereasoursis toimprove
analysisspeed .Forthetaskofimprovingprecision,aflow-,context-
and field-sensitive analysis is the hardest baseline because it is the
mostprecise.Incontrast,forourtaskofimprovinganalysisspeed,acontext-, field- and flow-insensitive analysis is the hardest baseline
because it is the fastest.
Demand-drivenanalysis. Wechoosetowriteourowndemand-
driven cast-check instead of using an existing tool like [ 24]o r[28].
This ensures that thewhole-program analysis and demand-driven
analysis are identical in their various sensitivities, analysis design
decisions, constraint solvers and errors generated. This normaliza-
tion helps to make a fair timing comparison between the demand-
drivenanalysis,andothertechniqueslike QueryMax ,Averroesand
the application-only analysis. For the demand-driven cast check,
we implement caching across queries to reuse computations done
for a previous query.
Mostpriorresearchondemand-drivenanalysisdealswithpointer
analysis which can be used to implement the cast-check. However,
a design of the demand-driven version of the null-pointer analy-sis[
12]isnotpubliclyavailableandisnon-trivialtodesignfrom
scratch. Hence, for the demand-driven analysis, we only report
experiments for the cast-check analysis.
Averroes. Averroes takes as input the original Jar file and the
setofapplicationclasses,andproducesmodifiedJarfilesconsist-
ing of the application classes and the librarysummary. Wedo not
count the time taken to produce the modified Jar files since it is
aone-timecostwhichisamortizedacrossallclientanalyses.The
Averroes library summary also has the java/utilpackage excluded
from it.Finally, thesame null-pointerand cast-checkanalyses de-
scribedabovearerunonthemodifiedJarfiles,therebymakinga
fair comparison between Averroes and the other techniques.
Reflection. We do not use WALA’s inbuilt reflection support for
the client analyses because this would worsen the analysis time of
the baseline, thereby making QueryMax look better. Further, we
also do not use reflection support for the ESA. While reflection
support may help the ESA find external sources reachable through
reflection, its overhead is too high and this reduces the effective
speedup provided by QueryMax .
939Fast and Precise Application Code Analysis using a Partial Library ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
Statistic Mean Std-dev
Lines of application code 9911 12689
Number of application classes 97 91
Number of 3rd party library classes 2608 5220Percentage of application classes 0.33% 0.33%
Figure 7: Statistics about the benchmark programs
Statistic Cast-check Null-pointer
Total number of programs 221 221
Mean Errors per program 4.4 37
Std-dev Errors per program 27 56
Programs with non-zero errors 58 177
Mean Analysis time 27 sec 293 sec
Std-dev Analysis time 41 sec 142 sec
Figure8:Statisticsaboutthewhole-programcast-checkandnull-pointer analysis on the benchmark set
Precision,RecallandSpeedup. Tomeasurethequalityofananaly-
sisusingQueryMax oranyofthebaselinetechniqueslikeAverroes,
demand-driven analysis, etc., we evaluate it on the three axes of
speedup,precision,andrecall.Herearethestandardformulaefor
computing these metrics:
Speedup =Whole-program analysis time
Application-focused analysis time
Precision =|A∩W|
|A|Recall=|A∩W|
|W|
whereAis the set of errors given by QueryMax andWis the set of
errors given by the whole-program analysis (which we consider as
the ground-truth).
5 DATASET DESCRIPTION
WeusetheNJR-1dataset(availablehere[ 31]),asourbenchmark-
set. We chose NJR-1 because its 293 Java bytecode programs run
successfullywithWALA,andeachprogramexplicitlylistsitssetofapplicationandthird-partylibraryclasses.Outofthe293programs
we remove 68 programs that crash the Averroes tool. The crash
reportshavebeenfiledwiththedevelopers.Another4programs
whichrunoutofmemoryforthewhole-programnull-pointeranal-
ysis are removed, leaving us with a total of 221 programs.
Figure 7 lists some statistics about the benchmark programs.
On average, each benchmark program has almost 10k lines of Java
sourcecodeintheapplication,withanaverageofalmost100classes
each.Thethird-partylibraryclassesaremuchlarger,withanav-
erageof2608classesperbenchmark,andthesecorrespondtoan
estimated 250,000 lines of Java source code. The application classes
constitute just 0.33% of the program, with the remaining being
the Java standardlibrary and third partylibrary classes. The large
standard deviation for all these metrics implies that they vary sig-
nificantly acrossbenchmarks. Amongthe 221 benchmarks,63 use
reflectionintheapplicationcodeand130usereflectioninthethird-
party libraries.Figure 8 lists some statistics about the benchmarks when an-
alyzed with a whole-program null-pointer analysis and the cast-
check analysis. The cast check analysis gets 4.4 errors per program
on average, whereas the null pointer analysis gets 37. This large
difference is expected, since down-casting is rare, whereas method
calls and field accesses are common.
The table also shows thatonly 58 of the 221 programs have non-
zerocasterrorsandonly177ofthemhavenon-zeronull-pointer
errors.Theprogramswithzeroerrorsinthewholeprogramanalysisareaproblemfortheevaluationbecausetheirrecallisundefinedfor
all of the techniques. Hence, the experimental results are reported
intwoparts:thosewithzeroerrorsandthosewithnon-zeroerrors.
Wereporttherecallandspeedupforthenon-zeroerrorcasesand
onlyspeedupforthezeroerrorcases.
Theanalysistimesforthetwoanalysesalsovarywidely,with
the cast-check taking 27 seconds per program and the null-pointer
analysistaking293secondsperprogram.Thestandarddeviation
for analysis times is large, especially for the cast-check analysis,
implying that a few outliers have large analysis times.
6 EXPERIMENTAL RESULTS
In this section, we discuss our experimental results which validate
the following claims.
(1)C1:QueryMax gets a significant speedup, full precision and
reasonablerecallascomparedtothewhole-programanalysis,
with trade-off points that none of the existing techniques
can achieve.
(2)C2:Thedistributionofspeedupsandrecall-scoresareuni-
form across the benchmarks.
The experiments were carried out on a machine with 24 Intel(R)
Xeon(R)Silver4116CPUcoresat2.10GHzand188GBRAM.For
the JVM, the default heap size of 32GB, and default stack size of
1MB, was used. The artifact for the paper is available here [32].
Thefirsttwosub-sectionsvalidatetheclaimsmade,andthese
experimentsfocusontheprogramswithnon-zeroerrors.Thethird
subsection evaluates the programs with zero errors, the fourth
examines the QueryMax analysis time split-up, the fifth compares
the correlation between class-budget and analysis time, and the
sixth subsection outlines the threats to validity.
6.1 C1: Main Result
Figures 9 and 10 show the various recall and speedup trade-off
points for the cast-check analysis and null-pointer analysis respec-
tively. The X-axis gives the recall plotted on a linear scale and the
Y-axis gives the speedup plotted on a logarithmic scale. There is
actuallyathirdaxisforprecision,butwedonotshowitbecauseall
the techniques except for Averroes, get a 100% precision. We mark
Averroes’ precision directly in the figure.
Whole-programanalysis. Thewhole-programanalysis(marked
by the black circle) is considered as the ground-truth and the refer-
ence for all speedup calculations. Hence it trivially gets 100% recall
and 1x speedup.
Demand-drivenanalysis. Thedemand-drivenanalysis(marked
bythegreentriangle)computesthesameresultasawhole-program
analysisandhencegets100%recall,butitmanagesa5.1xgeometric
940ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Akshay Utture and Jens Palsberg
Figure9:RecallandSpeedupforthevarioustechniquesfor
the cast-check analysisFigure 10: Recall and Speedup for the various techniquesfor the null-pointer analysis
mean speedup for the cast-check analysis because it avoids analyz-
ingthewholeprogram.Thismeanspeedupisnotrepresentativeof
theaveragebenchmark.Oneportionofthebenchmarksgetalarge
speedupbecausetheyanalyzeasmallpartoftheprogram,while
othersexperienceaslowdownbecausetheyanalyzealargesection
oftheprogramandthedemand-drivenanalysisaddssomeoverhead.
Thereasonforthisdifferenceinspeedupsisthatsomeprograms
either have expensive queries like the example in Section 2, or a
largernumberofqueries,andothersdon’t.Thisobservationisin
line with previous experiments on demand-driven analyses [ 11]. A
demand-drivenversionofthenull-pointeranalysisdoesnotexist
(seewhyinSection4),butweexpectittoperformworsethanin
thecast-checkanalysisbecausetherearesignificantlymorequeries
in the null-pointer analysis and the demand-driven analysis works
on a per-query basis.
Application-onlyanalysis. Attheotherendofthespectrumisthe
application-onlyanalysis(markedbyagreystar),whichisorders
of magnitude faster, but gets a significantly lower recall. For the
cast-checkanalysisitgetsa254xspeedupanda56%recall,whereas
forthenull-pointeranalysisitgets1222xspeedupand58%recall.
The large speed-up is attributed to the fact that the application
constitutes only 0.33% of the whole program on average (Figure 7 ).
An application-onlyanalysis isa goodoption for use-caseswhere
analysisspeed issignificantlymoreimportantthanrecall,butwhen
bothareimportant,it doesn’tstrikeasgoodofa balancebetween
the two.
Averroes. The point closest to this is Averroes (marked by a red
plus),whichgetsa(179xspeedup,60%recall,71%precision)forthe
cast check analysis, and a (913x speedup, 53% recall, 47% precision)
for the null-pointer analysis. This is the only tool for which we
report the precision because the other tools get 100% precision.ThemassivespeedupofAverroesisattributedtothefactthatits
summaryis tinycompared tothesize ofthelibrary. However,the
tinysizeisalsowhatcausesanalysisinformationtobemergedandprecisiontodrop.The47%and71%precisionvaluesaresignificantly
lower than our target of 100% precision.
Averroes should theoretically get 100% recall for the cast-check,
butnotforthenull-pointeranalysisbecauseitslibrarysummary
includes information about object-initialization but not about field-
initialization.Theobservedrecallislowerthanexpectedbecause
of a bug in its dealing of inner-classes which causes any error
propagating through a Java inner-class to be dropped. The bug has
been reported to the developers.
QueryMax. Finally,QueryMax gives some points in between
these two extremes. The points marked with crosses are for the
class-budgets and the points marked with with squares are for the
query-coverage goals.
For the cast-check analysis (Figure9) QueryMax performs very
well.The3%budget(purplecross)getsa24xspeedupand92%recall,
and this strikes a really useful balance between the two metrics.
The10% budget (blue cross) gets an 8.7x speedup and a 97% recall,
thereby favoring therecall alittle more than the speedup, but still
a great trade-off between the two metrics. The 30% budget (pink
cross)gets3.9xspeedupanda99.6%recall.
Thequery-coveragestoppingcriterion(representedbythesquares)
forthecast-checkanalysisgetssimilarlygoodresults.The70%goal
(brown square) gets (12x speedup, 94% recall) and the 90% goal(yellow square) gets (6.7x speedup, 97% recall). The speedups for
the coverage goals are slightly lower than the class budgets. Forexample, the yellow square in Figure 9 is directly below the bluecross. This happens because calculating the query-coverage in-
volvestheoverheadofatleastone fast-ESA,whichtheclass-budget
versionavoids.However,thecoverage-goalgivesaguaranteeon
941Fast and Precise Application Code Analysis using a Partial Library ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
the number of queries covered, which could be more valuable than
a guarantee on the number of classes analyzed.
Forthenull-pointeranalysis(Figure10),weseeasimilarspeedup
vsrecalltrade-offfor QueryMax .The3%class-budget,markedby
thepurplecrossgets(34xspeedup,69%recall),the10%classbudget
marked by the blue cross gets (11x speedup, 77% recall), and the
30% class-budget, marked by the pink cross gets (5.2x speedup,
91%recall).Thequery-coveragepoints(markedbysquares)liein
between these three points. Unlike the cast-check analysis, the
coverage-goalvariantsarenotmuchworsethantheclass-budget
variantsforthenullpointeranalysis.Wediscussthereasonforthis
observation in Section 6.4
Comparing figures 9 and 10 shows that QueryMax gets much
better recall for the cast-check than the null-pointer analysis. The
main reason for this is that some dereference instructions get ahigh-priority from QueryMax , but are often never null-pointer
exceptions. For example, in any given program, the println()call
occurs many times, and in all cases gets its value from the fieldjava/lang/System.out. Since this field affects several dereferenceinstructions, it ends up getting a high-priority and that part of
thelibrarygetsaddedtoourpartiallibraryfirst,eventhoughthe
println()callsnevercausenull-pointerexceptions.Asimilarcase
happens to some other common dereference instructions.
To sum up, QueryMax with either stopping criterion provides a
useful analysis design point in-between the application-only analy-
sisandthedemand-drivenanalysis,justlikeintheexamplefrom
Section2.Further,unlikeAverroes,itachievesthisspeedupwithoutsacrificingprecision,andthuscontinuestomeetthehigh-precision
expectation of its users.
6.2 C2:DistributionofRecallandSpeedup
We now understand the recall and speedup trade-off points for
QueryMax ,butwewouldalsoliketoknowtheirdistributionacross
thebenchmarkprograms.Figures11and12useahistogramtoshowthedistributionoftherecallandspeedupfor QueryMax witha70%
query coverage. The X-axis gives the speedup or recall, with the
values split into bins, and the Y-axis gives the number of programs
in each bin. Just like figures 9 and 10, we use a logarithmic scaling
for speedup here. The recall is still plotted on a linear scale.
Therecallfor QueryMax withthecast-checkanalysis(Figure11)
is close to 100% for most of the programs, with only a couple of
programs getting lower scores. Two programs geta0r e call. These
programs had just 1 and 2 errors each and missing those errorsmeant a recall of 0. The null-pointer analysis (Figure 12) has a
similarstoryforrecall,butithasalargernumberofprogramswith
0 recall. In most of these cases, the null-errors are very few and
highly related, and hence missing one library method could cause
all the null-errors to be missed.
The speedups for both analyses are consistent, with most pro-
grams getting closeto the mean speedup value.The cast-check has
2programsthatgetlessthana1xspeedup.Thishappensbecause
ifQueryMax cannot guaranteethat 70% coverage has been reached
by thetime its chosenfragment expands to30% of theprogram, it
simply falls back to picking the whole program, thereby resulting
in no speedup.6.3 Zero-Error Benchmarks
Theresultssofarfocusedontheprogramswithnon-zeroerrors.Fig-
ure13liststhespeedupforprogramswithzeroerrorsinthewhole-programanalysis.Thespeedupsfor QueryMax areonaveragetwice
as much as the non-zero error benchmarks. The demand-drivencast-check however, gets a 42x speedup here as compared to the
5.1xspeeduponthenon-zeroerrorbenchmarks.Thishighspeedup
forthedemand-drivenanalysisonthesebenchmarksstemsfrom
thefactthattheseprogramshavemuchfewerdown-castinstruc-
tionsthanthenon-zeroerrorbenchmarks.Thus,whenthereare
very few analysis queries, a demand-driven analysis gets a higher
speedup.
6.4 Split-up of Analysis Time
Recalltheworkflowof QueryMax fromFigure1.Wefirstrun Query-
Maxwitheitheraquery-coveragegoaloraclass-budget.Forquery-
coverage, QueryMax includestheadditionaloverheadofthe fast-
ESA.Finally,weruntheexistinganalysis.Figure14givesasplit-up
of the time between QueryMax (minus the fast-ESA), the fast-ESA,
and the existing static analysis, for the query coverage goal.
Forthecast-check,the fast-ESAtakes51%of thetime,whereas
the other QueryMax part takes just 4%. This explains why the
query-coverage criterion from Figure. 9 is slower than the class-
budget one; computing the query-coverage needs the fast-ESA, but
computing the class-budget does not.
For the null-pointer analysis, both the fast-ESA and the other
partofQueryMax takeupasmallpercentageofthetime(8%totally).
The contribution of QueryMax andfast-ESAto the total analysis
time is larger for the cast-check than the null-pointer analysis. The
reason for this is that existing null-pointer analysis has a longer
absoluteanalysistimethanthecast-check,buttheabsolute fast-ESA
time is similar in both cases.
6.5 Analysis-time vs Number of Classes
As a minor result, we show the relationship between the class-
budget and the analysis time, to justify our use of the former asa proxy for the latter. Figure 15 compares the number of classes
analyzed on the X-axis with the analysis time on the Y-axis for
both analyses. Each point represents one analysis of QueryMax
with a class-budget. Forboth analyses, the analysis time isalmost
linear, but the cast check has more outliers, which explains thehigh-standard deviation for its analysis time (see Figure 8). The
figure also plots a regression line, and the equation of this line can
be used to convert time-budgets into class-budgets.
6.6 Threats to Validity
Therearetwomainthreatstovalidity.Thefirstisthatoutofthe
application, third party libraries and standard library, the standard
library forms the largest part. Even though different programs
interactwithdifferentpartsofthestandardlibrary,itstillmeansthat
the benchmarks are not perfectly independent for a static analysis.
However, this issue occurs with any static-analysis benchmark-set
where the programs access the standard library.
Thesecondisthatanalysistimemeasurementsforallthepro-
gramswereperformedusingasinglerun,eventhoughexecution
times can vary across runs. However, since the speedups are large
942ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Akshay Utture and Jens Palsberg
Figure 11: Speedup and Recall histograms for QueryMax
(70% query coverage) on the cast-check analysisFigure 12: Speedup and Recall histograms for QueryMax
(70% query coverage) on the null-pointer analysis
Analysis Cast-check Null-pointer
Application-only 395x 2196x
Averroes 230x 1744x
QueryMax 3% class-budget 30x 84x
QueryMax 10% class-budget 13x 33x
QueryMax 30% class-budget 6.4x 18x
QueryMax 70% query coverage 16x 20x
QueryMax 90% query coverage 12x 10x
Demand-driven 42x N/A
Figure 13: Speedup for the various analysis techniques for
the Zero-error benchmarks
RIWRWDOWLPH&DVW&KHFN
1XOO3RLQWHU
      4XHU\0D[PLQXV)DVW(6$ )DVW(6$ ([LVWLQJ$QDO\VLV
Figure14:Splitupofthetimetakenbyeachcomponentfor
an analysis using QueryMax with the query-coverage goal
(anorderofmagnitude)andthebenchmarksarenumerous,these
variationsmatterless.Further,sincethetotalexperiment-timeis
already ten days, performing multiple runs is infeasible.Figure 15: Class-budget and analysis time relationship.
7 RELATED WORK
The three research directions that focus on speeding up static anal-
ysis by avoiding the analysis of the entire program are library-
summary based analysis, demand-driven analysis, and the analysis
of program fragments. We discuss each of these in turn.
Library-summarybasedanalysis. Themainideabehindthere-
search in this area is to create an analysis summary for the library
andusethislibrarysummaryinsteadoftheactuallibrarycodeto
analyze the application.
943Fast and Precise Application Code Analysis using a Partial Library ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
Averroes [ 1] heavily compresses the library into a small sum-
mary.Thissummaryconsistsofasinglesummary-pointertorep-
resentalllibrarypointers,stubsformethodscalleddirectlyfrom
theapplication,andasinglesummary-methodtoperformallthe
objectinitializationsandapplicationcall-backs.Sincethissummary
is quite small compared to the library, using it in place of the li-
braryresultsinamassivespeedup.However,thesmallsizeofthe
summary has two downsides: precision drops because information
is merged in the single summary-pointer, and some kinds of in-
formation (like field initialization information for the null-pointer
analysis)getleftoutoutofthesummary. QueryMax ,incontrast,
leaves out no information in the partial library that it chooses, and
more importantly, preserves the precision.
Thecomponent-level analysis by Rountev et. al [ 19,21] differs
from Averroes in that its library summary contains all the informa-
tion necessary to get the same result as a whole program analysis.
The first time an analysis is run, the library is separately analyzed
andsummarized,andthesummaryisintegratedwiththeapplica-
tion analysis. This saves no time in the initial run (the overhead
causes a slowdown). However, it saves time in subsequent runs
when the same library summary is reused across different pro-
gramsorfutureversionsoftheprogram. QueryMax ontheother
hand never uses the whole library and itspeedsu p the analysis of
each program independently. Further, unlike the component-level
analysis which needs a separate design for each type of analysis,
QueryMax can be used off-the-shelf with any analysis.
Demand-drivenanalysis. Demand-drivenanalyses[ 11,24,27,28]
are well-accepted as the most efficient option for single analysis
queries, and work best for resource-constrained environments like
IDEsandJITcompilers.Theyalsoperformwellwhenthenumberof
queries is small [ 28]. However, when analyzing entire applications
inwhichthenumberofqueriesislarge,thedemand-drivenanalysiscouldendupanalyzinglargepartsoftheprogramandcauseaslow-
down because of their overhead [ 11]. We also see this observation
in our benchmarks, where some programs get huge speedups over
a whole-program analysis, but some experience slowdowns.
Unlikethedemand-drivenapproach, QueryMax avoidsexpensive
queries by assigning them a low priority, like in the example from
Section2.Italsoavoidsthedemand-drivenoverheadsinceitstill
runs a batch analysis, thereby performing better when there aremany queries to be answered. Further, since QueryMax is only
a preprocessor to an existing whole-program analysis, it can beused with an existing analysis, without requiring a design of a
demand-driven version of it.
Analysis of Program Fragments. There has been past research
onanalyzingprogramfragmentsinisolation.Inouruse-case,the
programfragmentistheapplication-code.CousotandCousot[ 7]
describe four techniques for this general approach. The first is a
simplification-based separate analysis, which analyzes the various
fragments of a program separately and then combines their infor-
mation. This idea is similar to the library-summary based analysis
by[19],andhasthedrawbacksasdiscussedabove.Thesecondtech-
niqueisaworst-caseanalysis,whichmeansrunninganapplication-
only analysis, but using the top element of the abstract domain
for library pointers. This introduces additional false-positives. Ourexperimentsonthistechniqueshowthatitgetsaprecision(aver-
agedoverboth analyses)of22%whichisfarbelow our100%target
precision. The third technique is to ask a user to provide stubsfor the library (i.e. information about the library interface) and
thenperformanapplication-onlyanalysisthatincorporatesthese
stubs instead of the library. This can give high recall, precision and
speedup, but it requires a static-analysis expert to manually write
and update the stubs for each library. The fourth technique uses
arelationalabstractdomainandanalyzesaprogramfragmentby
givingsymbolicnamestoexternalpointersandlazilyevaluating
the values they pass. To the best of our knowledge, there are norecent implementations or experimental results to compare the
effectiveness of this technique in practice.
Rountev et. al [ 20] introduce a technique to improve the perfor-
manceofawhole-programflow-sensitiveanalysis.Theyperform
a flow-sensitive analysis for the application code and then use a
whole-programflow-insensitiveanalysistooverapproximatethe
effect of the library pointers. The two limitations of this technique
arethatitdropsprecisionascomparedtotheoriginalflow-sensitive
analysis, and it cannot be used to s peedupaflo w-insensitive anal-
ysis.QueryMax on the other hand maintains the same precision
astheoriginalanalysistoolandworkswithanylevelofcontext-,
flow- or field-sensitivity.
8 CONCLUSION AND FUTURE WORK
In this paper, we introduce a new application-focused analysis tool
QueryMax , which achieves alarge speedup over a whole-program
analysis, without losing any precision. QueryMax acts as a prepro-
cessor to an existing static analysis to select a partial library that is
smallbutsufficienttoanswermostoftheanalysisqueries. Query-
Maxprovidestheuserwithtwostoppingcriteria:aclass-budget
or aquery-coverage goal, dependingon whether the userwants a
handleontheanalysistimeortherecall.Ourexperimentsonthe
NJR-1 dataset show that QueryMax provides a significant speedup
atthecostofasmallandcontrolleddropinrecall,andwithnoloss
in precision.
A possible future research direction could be to evaluate Query-
Maxandtheotherbaselinetechniqueswithotherclientanalyses
suchastaintanalysisortype-stateanalysis.Additionally,onecould
also extend the approach to the Android platform, with the help of
frameworks suchas WALAthat support Android analysis.Finally,
a third direction could be to study how the QueryMax approach
translatestobenchmarksinotherpopularlanguagessuchasC/C++
and Javascript.
ACKNOWLEDGMENTS
This work was supported by the U.S. NSF Award 1823360, and the
ONRAwardN00014-18-1-2037.WealsothanktheICSE’22reviewers
and Aishwarya Sivaraman for their constructive comments that
helped improve the paper.
REFERENCES
[1]Karim Ali and Ondřej Lhoták. 2013. Averroes: Whole-Program Analysis without
the Whole Program. In Proceedings of the 27th European Conference on Object-
OrientedProgramming (Montpellier,France) (ECOOP’13) .Springer-Verlag,Berlin,
Heidelberg, 378–400. https://doi.org/10.1007/978-3-642-39038-8_16
[2]Subarno Banerjee, Lazaro Clapp, and Manu Sridharan. 2019. NullAway: Prac-
tical Type-Based Null Safety for Java. In Proceedings of the 2019 27th ACM
944ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Akshay Utture and Jens Palsberg
Joint Meeting on European Software Engineering Conference and Symposium
on the Foundations of Software Engineering (Tallinn, Estonia) (ESEC/FSE 2019) .
Association for Computing Machinery, New York, NY, USA, 740–750. https:
//doi.org/10.1145/3338906.3338919
[3]Manuel Benz, Erik Krogh Kristensen, Linghui Luo, Nataniel P. Borges, EricBodden, and Andreas Zeller. 2020. Heaps’n Leaks: How Heap Snapshots Im-
prove Android Taint Analysis. In Proceedings of the ACM/IEEE 42nd Interna-
tional Conference on Software Engineering (Seoul, South Korea) (ICSE ’20).A s -
sociation for Computing Machinery, New York, NY, USA, 1061–1072. https:
//doi.org/10.1145/3377811.3380438
[4]AlBessey,KenBlock,BenChelf,AndyChou,BryanFulton,SethHallem,Charles
Henri-Gros, Asya Kamsky, Scott McPeak, and Dawson Engler. 2010. A Few
BillionLines ofCode Later:UsingStatic AnalysistoFind Bugsinthe RealWorld.
Commun.ACM 53,2(Feb.2010),66–75. https://doi.org/10.1145/1646353.1646374
[5]Sam Blackshear, Bor-Yuh Evan Chang, and Manu Sridharan. 2013. Thresher:
PreciseRefutationsforHeapReachability.In Proceedingsofthe34thACMSIG-
PLAN Conference on Programming Language Design and Implementation (Seattle,
Washington, USA) (PLDI ’13) . Association for Computing Machinery, New York,
NY, USA, 275–286. https://doi.org/10.1145/2491956.2462186
[6]Maria Christakis and Christian Bird. 2016. What Developers Want and Need
from Program Analysis: An Empirical Study. In Proceedings of the 31st IEEE/ACM
InternationalConferenceonAutomatedSoftwareEngineering (Singapore,Singa-
pore)(ASE 2016). Association for Computing Machinery, New York, NY, USA,
332–343. https://doi.org/10.1145/2970276.2970347
[7]PatrickCousotandRadhiaCousot.2002. ModularStaticProgramAnalysis.In
Proceedingsofthe11thInternationalConferenceonCompilerConstruction(CC’02) .
Springer-Verlag, Berlin, Heidelberg, 159–178.
[8]GangFan,RongxinWu,QingkaiShi,XiaoXiao,JinguoZhou,andCharlesZhang.
2019. Smoke: Scalable Path-Sensitive Memory Leak Detection for Millions ofLines of Code. In Proceedings of the 41st International Conference on Software
Engineering (Montreal, Quebec, Canada) (ICSE ’19). IEEE Press, 72–82. https:
//doi.org/10.1109/ICSE.2019.00025
[9]Stephen J. Fink, Eran Yahav, Nurit Dor, G. Ramalingam, and Emmanuel Geay.
2008. EffectiveTypestate VerificationinthePresence ofAliasing. ACMTrans.
Softw. Eng. Methodol. 17, 2, Article 9 (may 2008), 34 pages. https://doi.org/10.
1145/1348250.1348255
[10]Neville Grech, George Fourtounis, Adrian Francalanza, and Yannis Smaragdakis.
2018.ShootingfromtheHeap:Ultra-ScalableStaticAnalysiswithHeapSnapshots.
InProceedings of the 27th ACM SIGSOFT International Symposium on Software
Testing and Analysis (Amsterdam, Netherlands) (ISSTA 2018). Association for
ComputingMachinery,NewYork,NY,USA,198–208. https://doi.org/10.1145/
3213846.3213860
[11]NevinHeintzeandOlivierTardieu.2001. Demand-DrivenPointerAnalysis.In
Proceedings of the ACM SIGPLAN 2001 Conference on Programming Language
Design and Implementation (Snowbird, Utah, USA) (PLDI ’01). Association for
Computing Machinery, New York, NY, USA, 24–34. https://doi.org/10.1145/
378795.378802
[12]LaurentHubert,ThomasJensen,andDavidPichardie.2008. SemanticFounda-
tionsandInferenceofNon-NullAnnotations.In Proceedingsofthe10thIFIPWG6.1
InternationalConferenceonFormalMethodsforOpenObject-BasedDistributedSys-tems(Oslo,Norway) (FMOODS’08) .Springer-Verlag,Berlin,Heidelberg,132–149.
https://doi.org/10.1007/978-3-540-68863-1_9
[13]Brittany Johnson, Yoonki Song, Emerson Murphy-Hill, and Robert Bowdidge.
2013. WhyDon’tSoftwareDevelopersUseStaticAnalysisToolstoFindBugs?.
InProceedings of the 2013 International Conference on Software Engineering (San
Francisco, CA, USA) (ICSE ’13). IEEE Press, 672–681.
[14]Ondrej Lhoták and Laurie Hendren. 2003. Scaling Java points-to analysis using
SPARK.International Conference on Compiler Construction 2622, 153–169. https:
//doi.org/10.1007/3-540-36579-6_12
[15]Yue Li, Tian Tan, Anders Møller, and Yannis Smaragdakis. 2018. Scalability-
First Pointer Analysis with Self-Tuning Context-Sensitivity. In Proceedings of the
201826thACMJointMeetingonEuropeanSoftwareEngineeringConferenceand
Symposium on the Foundations of Software Engineering (Lake Buena Vista, FL,
USA)(ESEC/FSE 2018). Association for Computing Machinery, New York, NY,
USA, 129–140. https://doi.org/10.1145/3236024.3236041
[16]BenjaminLivshits,ManuSridharan,YannisSmaragdakis,OndřejLhoták,J.Nelson
Amaral,Bor-YuhEvanChang,SamuelZ.Guyer,UdayP.Khedker,AndersMøller,
andDimitriosVardoulakis.2015.InDefenseofSoundiness:AManifesto. Commun.
ACM58, 2 (jan 2015), 44–46. https://doi.org/10.1145/2644805
[17]V. Benjamin Livshits and Monica S. Lam. 2005. Finding Security Vulnerabilities
inJavaApplicationswithStaticAnalysis.In Proceedingsofthe14thConference
on USENIX Security Symposium - Volume 14 (Baltimore, MD) (SSYM’05). USENIX
Association, USA, 18.
[18]MukundRaghothaman,SulekhaKulkarni,KihongHeo,andMayurNaik.2018.
User-Guided Program Reasoning Using Bayesian Inference. In Proceedings of the
39th ACM SIGPLAN Conference on Programming Language Design and Implemen-
tation(Philadelphia,PA,USA) (PLDI2018) .AssociationforComputingMachinery,
New York, NY, USA, 722–735. https://doi.org/10.1145/3192366.3192417[19]Atanas Rountev, Scott Kagan, and Thomas Marlowe. 2006. Interprocedural
DataflowAnalysisinthePresenceofLargeLibraries.In Proceedingsofthe15th
International Conference on Compiler Construction (Vienna, Austria) (CC’06).
Springer-Verlag, Berlin, Heidelberg, 2–16. https://doi.org/10.1007/11688839_2
[20]Atanas Rountev,Barbara G. Ryder,and William Landi. 1999. Data-FlowAnalysis
ofProgram Fragments.In Proceedingsofthe 7thEuropeanSoftwareEngineering
ConferenceHeldJointlywiththe7thACMSIGSOFTInternationalSymposiumon
FoundationsofSoftwareEngineering (Toulouse,France) (ESEC/FSE-7).Springer-
Verlag, Berlin, Heidelberg, 235–252.
[21]Atanas Rountev, Mariana Sharp, and Guoqing Xu. 2008. IDE Dataflow Analysis
inthePresenceofLargeObject-OrientedLibraries.In CompilerConstruction,17th
International Conference, CC 2008, Held as Part of the Joint European Conferences
onTheoryandPracticeofSoftware,ETAPS2008,Budapest,Hungary,March29-
April 6, 2008. Proceedings (Lecture Notes in Computer Science, Vol. 4959), Laurie J.
Hendren (Ed.). Springer, 53–68. https://doi.org/10.1007/978-3-540-78791-4_4
[22]Qingkai Shi, Rongxin Wu, Gang Fan, and Charles Zhang. 2020. Conquering the
Extensional Scalability Problem for Value-Flow Analysis Frameworks. In Pro-
ceedings ofthe ACM/IEEE42nd International Conferenceon SoftwareEngineering
(Seoul,SouthKorea) (ICSE’20) .AssociationforComputingMachinery,NewYork,
NY, USA, 812–823. https://doi.org/10.1145/3377811.3380346
[23]Qingkai Shi and Charles Zhang. 2020. Pipelining Bottom-up Data Flow Analysis.
InProceedingsoftheACM/IEEE42ndInternationalConferenceonSoftwareEngi-
neering(Seoul,SouthKorea) (ICSE’20).AssociationforComputingMachinery,
New York, NY, USA, 835–847. https://doi.org/10.1145/3377811.3380425
[24]Johannes Späth, Lisa Nguyen Quang Do, Karim Ali, and Eric Bodden. 2016.
Boomerang:Demand-DrivenFlow-and Context-SensitivePointerAnalysisfor
Java. In30th European Conference on Object-Oriented Programming (ECOOP 2016)
(Leibniz International Proceedings in Informatics (LIPIcs), Vol. 56) , Shriram Kr-
ishnamurthiandBenjamin S.Lerner(Eds.).SchlossDagstuhl–Leibniz-Zentrum
fuer Informatik, Dagstuhl, Germany, 22:1–22:26. https://doi.org/10.4230/LIPIcs.
ECOOP.2016.22
[25]Fausto Spoto. 2011. Precise Null-Pointer Analysis. Softw. Syst. Model. 10, 2 (may
2011), 219–252. https://doi.org/10.1007/s10270-009-0132-5
[26]Manu Sridharan and Rastislav Bodík. 2006. Refinement-Based Context-Sensitive
Points-to Analysis for Java. In Proceedings of the 27th ACM SIGPLAN Conference
onProgrammingLanguageDesignandImplementation (Ottawa,Ontario,Canada)
(PLDI ’06). Association for Computing Machinery, New York, NY, USA, 387–400.
https://doi.org/10.1145/1133981.1134027
[27]Manu Sridharan and Rastislav Bodík. 2006. Refinement-Based Context-Sensitive
Points-to Analysis for Java. In Proceedings of the 27th ACM SIGPLAN Conference
onProgrammingLanguageDesignandImplementation (Ottawa,Ontario,Canada)
(PLDI ’06). Association for Computing Machinery, New York, NY, USA, 387–400.
https://doi.org/10.1145/1133981.1134027
[28]Manu Sridharan, Denis Gopan, Lexin Shan, and Rastislav Bodík. 2005. Demand-
DrivenPoints-toAnalysisforJava.In Proceedingsofthe20thAnnualACMSIG-
PLAN Conference on Object-Oriented Programming, Systems, Languages, and Ap-
plications (SanDiego,CA,USA) (OOPSLA’05).AssociationforComputingMa-
chinery, New York, NY, USA, 59–76. https://doi.org/10.1145/1094811.1094817
[29]Vijay Sundaresan, Laurie Hendren, Chrislain Razafimahefa, Raja Vallée-Rai,
PatrickLam,EtienneGagnon,andCharlesGodin.2000. PracticalVirtualMethod
Call Resolution for Java. In Proceedings of the 15th ACM SIGPLAN Conference on
Object-Oriented Programming, Systems, Languages, and Applications (Minneapo-
lis, Minnesota, USA) (OOPSLA ’00). Association for Computing Machinery, New
York, NY, USA, 264–280. https://doi.org/10.1145/353171.353189
[30]OmerTripp,MarcoPistoia,StephenJ.Fink,ManuSridharan,andOmriWeisman.2009. TAJ:EffectiveTaintAnalysisofWebApplications.In Proceedingsofthe30th
ACMSIGPLANConferenceonProgrammingLanguageDesignandImplementation
(Dublin,Ireland) (PLDI’09).AssociationforComputingMachinery,NewYork,
NY, USA, 87–97. https://doi.org/10.1145/1542476.1542486
[31]Akshay Utture, Christian Gram Kalhauge, Shuyang Liu, and Jens Palsberg. 2020.
NJR-1 Dataset. https://doi.org/10.5281/zenodo.4839913
[32]Akshay Utture and Jens Palsberg. 2021. Artifact for ICSE-22 submission "Fast and
PreciseApplicationCodeAnalysisusingaPartialLibrary". https://doi.org/10.5281/
zenodo.5551128
[33]WALA. 2015. IBM, “T.J. Watson Libraries for Analysis (WALA),”. http://wala.
sourceforge.net.
[34]Weilei Zhang and Barbara G. Ryder. 2007. Automatic Construction of Accurate
Application Call Graph with Library Call Abstraction for Java: Research Articles.
J. Softw. Maint. Evol. 19, 4 (July 2007), 231–252.
945