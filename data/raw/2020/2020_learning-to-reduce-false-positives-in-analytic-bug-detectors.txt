Learning to Reduce False Positives in Analytic Bug Detectors
Anant Kharkar
Microsoft
Redmond, Washington, USARoshanak Zilouchian
Moghaddam
Microsoft
Redmond, Washington, USAMatthew Jin
Microsoft
Redmond, Washington, USA
Xiaoyu Liu
Microsoft
Redmond, Washington, USAXin Shi
Microsoft
Redmond, Washington, USAColin Clement
Microsoft
Redmond, Washington, USA
Neel Sundaresan
Microsoft
Redmond, Washington, USA
ABSTRACT
Due to increasingly complex software design and rapid iterative
development,codedefectsandsecurityvulnerabilitiesarepreva-
lentinmodernsoftware.Inresponse,programmersrelyonstatic
analysistools toregularlyscantheir codebasesandfindpotential
bugs.Inordertomaximizecoverage,however,thesetoolsgenerally
tend to report a significant number of false positives, requiring
developers to manually verify each warning. To address this prob-
lem,weproposeaTransformer-basedlearningapproachtoidentify
falsepositivebugwarnings.Wedemonstratethatourmodelscan
improvetheprecisionofstaticanalysisby17.5%.Inaddition,we
validated the generalizability of this approach across two major
bug types: null dereference and resource leak.
CCS CONCEPTS
•Software and its engineering →Software defect analysis ;•
Computing methodologies →Natural language generation ;
Neural networks.
KEYWORDS
datasets, neural networks, gaze detection, text tagging
ACM Reference Format:
Anant Kharkar, Roshanak Zilouchian Moghaddam, Matthew Jin, Xiaoyu
Liu,XinShi,ColinClement,andNeelSundaresan.2022.LearningtoReduce
FalsePositivesinAnalyticBugDetectors.In 44thInternationalConferenceon
Software Engineering (ICSE ’22), May 21–29, 2022, Pittsburgh, PA, USA. ACM,
New York, NY, USA, 10 pages. https://doi.org/10.1145/3510003.3510153
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthe firstpage.Copyrights forcomponentsof thisworkowned byothersthan the
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or
republish,topostonserversortoredistributetolists,requirespriorspecificpermission
and/or a fee. Request permissions from permissions@acm.org.
ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
© 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-9221-1/22/05...$15.00
https://doi.org/10.1145/3510003.35101531 INTRODUCTION
Softwaredefects(bugs)thatgoundetectedduringthedevelopment
processcancausesoftwarefailure,resultinginfinancialandrep-
utational harm to companies and a host of problems for users of
buggy software. Developers often rely on static analysis tools to
scan their codebases and find potential bugs. Despite their benefits,
static analysis tools are not consistently used in many software
projects [ 3]. Previous work has attributed their inconsistent usage
tohighfalsepositiveratesandineffectivepresentationofwarnings
[11].
Developing any static analyzer is a non-trivial task due to the
trade-offbetweenprecisionandrecall;itischallengingtoreport
only correct bugs (precision) while covering all bugs with a similar
pattern (coverage/recall). Balancing these two objectives manually
is difficult and can result in analyzers with high false positive rate
(lowprecision).Analyzerswithhighinitialprecisioncanalsode-
gradeinpredictiveperformanceasthenatureofbugschangesover
time.Continuouslyupdatingandmaintainingstaticanalyzersto
handle concept drift can be costly [5].
Previous research has investigated various methods to improve
staticanalysisfalsepositiverates.Inparticular,researchershaveexplored eliminating bugs along infeasible paths using syntacticmodel-checking [
12]; eliminating all the bugs that are similar to
a false positive based on similarity of modification points [ 16];
and using a two-staged error ranking strategy where false positive
patterns are learned after manual labeling in the first stage [ 22,
24]. Our work uniquely contributes to this line of prior work by
leveraging state-of-the-art neural models to automatically refine
the output of static analyzers.
Beyondtraditionalrule-basedtools,therehasbeensignificant
recent work leveraging machine learning for software bug and
vulnerability detection in various languages, including C/C++ [ 13,
21], Java[18], andJavaScript [ 19]. However,much likerule-based
analyzers, these machine learning models often suffer from low
precisionwhenappliedinrealworldsettings.Anotherchallenge
with some machine learning approaches is the need to develop
newmodelstocapturenewtypesofvulnerabilities.Unlikethisline
of work, we do not use machine learning to detect bugs directly.
Instead,weleveragemachinelearningtoaugmentexistingstatic
analyzers.Webelievethisstrategyyieldsthebestofbothworlds,
13072022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:26:40 UTC from IEEE Xplore.  Restrictions apply. ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Anant Kharkar, Roshanak Zilouchian Moghaddam, Matthew Jin, Xiaoyu Liu, Xin Shi, Colin Clement, and Neel Sundaresan
where machine learning complements the capabilities of current
static analyzers.
Toaugmentstaticanalyzers,weexploredseveralmodels,includ-
ingafeaturebasedmodelandtwoneuralmodels.Ourfeature-based
model includes a set of carefully handcrafted features extracted
fromsourcecode.Ourneuralmodelswereinspiredbytherecent
successes of transformer models in code search and document gen-
eration [9] as well as code completion [ 23]. One of our neural
models learns from labeled data (DeepInferEnhance), while the
other is applied in a zero-shot setting without the need for further
training or finetuning (GPT-C [ 23]). We conducted an experiment
with allthe modelson bugs identifiedby Infer,an interprocedural
staticanalyzerthatdetectsbugsinJava,C++,andC#.Ourresults
showthatwecanimprovetheprecisionofInfer’sanalysisbyupto
17%.
2 RELATED WORK
Wedescribethepriorworkonstaticanalyzersandtheuseofma-
chine learning for bug detection.
2.1 Static Analysis-Based Bug Detection
Rule-based systems and static analyzers have been widely adopted
fordetectingsoftwarebugs[ 1,2,27,31].However,oneofthebarri-
erstoconsistentusageofstaticanalyzersistheirhighfalsepositive
rate [11]. Previous work has explored various ways of reducing
this false positive rate. For instance, Junker et al. [ 12] leveraged
syntactic model-checking to eliminate infeasible paths (program
slices). An implementation of their approach on Goanna, an static
analyzerforC/C++programsshowedthattheycouldexcludethe
majority of false positives. Muske, et al. [ 16] implemented a par-
titioning mechanism to partition similar warnings based on the
modified variables and modification points. A whole partition is
then considered false positive once its leader is determined as false
positive.Shenetal.[ 22]developedEFindBugs,whichusesatwo-
staged error ranking strategy to deal with the false positives issue
in FindBugs [ 4]. EFindBugs first reports warnings on a sample pro-
gram.Oncethewarningsaremanuallylabeled,thetoollearnswhat
bug patterns to eliminate on the second run against the user appli-
cation. Similarly, ALETHEIA learns users preferences from manuallabelingonasmallerset[
24].Ourworkuniquelycontributestothis
line of prior work by exploring the use of state-of-the-art neuralmodels to automatically refine the output of static analyzers by
removing false positives.
2.2 Learning-Based Bug Detection
Beyond rule-based tools, there has been significant recent work on
data-driven and machine learning approaches to detect software
bugsandvulnerabilities.Forinstance,Russelletal.[ 21]proposeda
machine learning method for detecting software vulnerabilities in
C/C++codebases.Similarly,Choietal.[ 7]trainedamemoryneural
network to detect a variety of buffer overruns in C-style code. Li etal.[
13]trainedarecurrentneuralnetwork(RNN)todetecttwospe-
cific types of vulnerabilities related to improper use of library/API
functions. Bugram [ 28] leveraged n-gram language models to iden-
tifylowprobabilitytokensequencesincodeasbugs.Pangetal.[ 18]
trainedamachinelearningmodeltopredictstaticanalyzerlabelsforJavasourcecode.Finally,DeepBugs[ 19]trainedaclassifierthat
distinguishes correct from incorrect code for three classes of bugs
(swapped function arguments, wrong binary operator, and wrong
operandinabinaryoperation)inJavaScript.However,themajority
ofmachinelearningsolutionssufferfromlowprecisionwhenap-
pliedonrealworldsettings.Anotherchallengewithsomemachine
learning approaches is the need to develop new models to capture
new types of vulnerabilities. By leveraging machine learning to
augmentexistingstaticanalyzers,ourworkcreatesthebestofboth
worlds,wheremachinelearningwillcomplementthecapabilities
of current static analyzers to generate more precise results.
8 static void Main(string[] args)
9{
10 varreturnNull = ReturnNull();
11 _ = returnNull.Value;
12}
13
14 private static NullObj ReturnNull()
15{
16 return null;
17}
1819
internal class NullObj
20{
21 internal stringValue { get; set;}
22}
/Examples/NullDeref/Program.cs:11
error: NULL_DEREFERENCE pointer’returnNull’couldbenulland
is dereferenced at line 11, column 13.
Figure1:AnexampleofaNullDereferencedetectedbyInfer
3 INFER
Our false positive reduction approach can work with any static
analyzerforwhichlabeleddataisavailable.Ourexperimentsspecif-
ically targeted Infer, an interprocedural static analyzer that is used
todetectavarietyofbugsinJavaandC++.Therecentreleaseof
Infer# also added support for bug detection in C# projects. Infer
uses separation logic, a program logic for reasoning about memory
manipulations, to prove certain memory safety conditions and cre-
ateprogramstatesummariesforeachmethodinacodebase.Infer’s
analysis examines multiple methods in order to identify bugs in
code.Whenanalyzingeachmethod,Inferformulatespre-andpost-
conditions thatdescribe the impactof the method onthe memory
stateoftheprogram.Whenanalyzingamethodinvocation,Infer
usestheconditionsofthecalleetoformlogicalpredicatesforthe
caller. Thus, Infer analyzes the entire call stack of a program by
composinglogicalpredicatesfromallnestedcalleemethods.Figure
1 shows an example of a null dereference bug identified by Infer.
We decidedto focus onInfer for threereasons. First, unlikethe
majorityofcommonanalyzersthatonlyconsiderthecontextofa
singlemethod(i.e.intraprocedural),Infer’sanalysisis interproce-
duralanditscontextcanstretchacrossseveralmethods.Second,as
opposedtomanyanalyzersthatrelyondeveloperannotationsto
detect certain bugs, Infer’s analysis is automated and does not rely
onannotations.Finally,duetoincrementalchangeanalysis,Infer
can scale well on large production codebases.
Like other static analyzers, Infer is also prone to false positives.
Figure2showsanexample,inwhichInferreportsthatthevariable
1308
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:26:40 UTC from IEEE Xplore.  Restrictions apply. Learning to Reduce False Positives in Analytic Bug Detectors ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
136 private voiddumpLog(File logFile, longstartOffset, longendOffset, ArrayList<String> blobs) throwsIOException {
137 Map<String, LogBlobStatus> blobIdToLogRecord =newHashMap<>();
138 finalTimer.Context context =metrics.dumpLogTimeMs.time();
139 try{
140 dumpLog(logFile, startOffset, endOffset, blobs,blobIdToLogRecord);
141 longtotalInConsistentBlobs =0 ;
142 for(String blobId :blobIdToLogRecord.keySet()) {
143 LogBlobStatus logBlobStatus =blobIdToLogRecord.get(blobId);
144 if(!logBlobStatus.isConsistent){
145 totalInConsistentBlobs++;
146 logger.error("Inconsistent blob " +blobId+""+logBlobStatus);
147 }
ambry-tools/src/main/java/com.github.ambry/store/DumpLogTool.java:144
error: NULL_DEREFERENCE object ‘logBlobStatus‘ last assigned on line 143 could be null and is dereferenced at line 144.
Figure2:AnexampleofafalsepositivewarningfromInfer.Inferwarnsthat logBlobStatus canbenull.Thisoccursif blobId
is not a valid key of blobIdToLogRecord. The warning is incorrect, since blobIdcomes from blobIdToLogRecord’s key set.
logBlobStatus can be null, since it is assigned by calling get()
on a map; if the key is not present in the map, get()will return
null.However,thekey blobIdcomesfromthe keySetofthesame
map,meaningthevaluemustexistinthemapand logBlobStatus
cannot be null. Infer is not able to recognize the coding conven-
tion of iterating over a map’s key set and incorrectly triggers a
nulldereferencewarning.Languagemodels,whicharetrainedto
identify patterns across a large corpus of code, can recognize such
idioms. This motivated us to turn to machine learning to detect
falsepositivesreportedbyInfer.Indeed,ourmodelidentifiesthis
specific warning as a false positive.
4 FALSE POSITIVE REDUCTION
False positive Infer warnings share common characteristics and
follow patterns in coding conventions, as described in the example
above.Thismotivatedustoturntomachinelearningasameans
of capturing these patterns and identifying false positive warnings.
Weexperimentedwithseveralmodels,includingafeature-based
modelandtwotransformer-basedneuralmodels.Below,wepresent
thedata setwe usedfor training andtesting thesemodels, aswell
as the details of each model.
4.1 Data Collection
Our data set consists of 539 null dereference warnings generated
by running Infer on seven Java repositories. Null dereference bugs
occurwhenapointerthatcanpotentiallybenullisdereferenced.
To create a diverse dataset, we chose several open source projects
andtwoproprietaryprojects.Theprojectsincludeback-endservice
components(Ambry, AzureSDK,and Nacos),buildplugins(Azure
MavenPlugins ),andbrowserautomation(Playwright ).Table1sum-
marizestheprojectsinourdataset,includingthenumberoftotal
warningsandtruepositivesreportedbyvanillaInfer.ProjectAand
Project B denote the proprietary projects.
Eachwarningwasinvestigatedandlabeledasvalid(truepositive)
orinvalid (falsepositive) byexperienced developers.Theneed for
manuallabelingpresentsabottlenecktoscalinguptolargerdata
sets. In the end, the developers identified 392 of the warnings as
true positives (72.7% precision) and 147 as false positives. Precision
for individual repositories varied between 16% to 90%; the lower
endofthisrangecancorrespondtopoorexperiencefordevelopersTable 1: Summary statistics of null dereference warnings.Total warnings and true positives are as reported by vanilla
Infer.
Name Lines of Total True Precision
Code Warnings Positives
Project A 35,527 57 47 82.4%
Project B 66,346 33 30 90.9%
Ambry 138,947 25 17 68.0%
Azure SDK 3,555,286 343 272 79.3%
Playwright 21,094 18 3 16.7%
Nacos 62,443 37 13 35.1%
Azure Maven 23,995 26 10 38.5%
Plugins
Total 3,903,638 539 392 72.7%
of those projects. There is significant opportunity for machine
learning to benefit the experience by improving precision.
For each warning, we record the following information:
•thelabel: whether the warning was legitimate or not
•thelocationofthewarning:includesthefilenameandline
number where the warning occurred
•thecode: this is the code snippet on the line of warning
•the error message: the error message produced by Infer
•thelocal context around the warning: consists of all lines of
code from beginning of the surrounding function to the line
of the warning.
•thenon-local context : includes the content of functions that
were called in the current context.
Thenon-localcontext enablesustoaccountfortheinterproce-
dural nature of Infer. To obtain interprocedural information, we
collect and use the content of certain methods invoked in the local
context that can impact the value of the null pointer. For example,
forsomenulldereferencewarnings,thenullpointeroriginatesas
the return value of a method; we retrieve the body of this methodas non-local context.
Figure3demonstratestheimportanceofnon-localcontext.Infer
reports that the variable datacenterToAdd assigned on line 461
(top) can be null. To investigate this, a developer must look into
thefindDatacenter methodin adifferentfile (bottom).Here,we
1309
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:26:40 UTC from IEEE Xplore.  Restrictions apply. ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Anant Kharkar, Roshanak Zilouchian Moghaddam, Matthew Jin, Xiaoyu Liu, Xin Shi, Colin Clement, and Neel Sundaresan
461Datacenter datacenterToAdd =hardwareLayout.findDatacenter(dataCenterName);
462List<Disk> disksForReplicas =
463 allocateDisksForPartition(numberOfReplicasPerDatacenter, capacityOfReplicasInBytes, datacenterToAdd,
464 attemptNonRackAwareOnFailure);
465partitionLayout.addNewReplicas((Partition) partitionId, disksForReplicas);
466System.out.println("Added partition " +partitionId +" to datacenter " +dataCenterName);
198 publicDatacenter findDatacenter(String datacenterName){
199 for(Datacenter datacenter :datacenters){
200 if(datacenter.getName().compareToIgnoreCase(datacenterName)= =0 ){
201 returndatacenter;
202 }
203 }
204 return null;
205}
ambry-clustermap/src/main/java/com.github.ambry.clustermap/StaticClusterManager.java:463
error: NULL_DEREFERENCE object ‘datacenterToAdd’ last assigned on line 461 could be null and is dereferenced by call to
‘allocateDisksForPartition(...)’ at line 463.
Figure3:AnexampleofaninterproceduralbugdetectedbyInfer.Inferreportsthat datacenterToAdd (top,line461)canbenull.
Todetermineifthisisthecase,aninvestigatormustfindtheimplementationof findDataCenter() (bottom),whichisusedto
assignthevalueof datacenterToAdd.Since findDataCenter() explicitlycontainstheline return null, datacenterToAdd canbe
null and the warning is reasonable.
canseethat findDatacenter canreturnnullonline204ifnoneof
thedatacenters match the argument, meaning it is possible for
datacenterToAdd to be null when it is dereferenced. Therefore, in
order to determine whether this warning is correct, the content of
the callee method ( findDatacenter ) is necessary. Although it is
possibleforanullpointertooriginatefrommultiplenestedmethod
calls, we found that in most cases, collecting the immediate callee
was sufficient.
4.2 Feature-Based False Positive Reduction
Asabaseline,weextractedfeaturevectorsfromourdataandtrained
a classifier to predict whether a warning is a false positive. Our
features included:
•whether the non-local context explicitly contains the line
return null; .Ifthislineexistsinnon-localcontext,then
it is possible for the callee to return null, and the variable
that holds the return value in the caller can be null.
•whetheranull-checkmethodappearsinthecontextofthe
warning.ForsomeInferwarnings,thedereferencedvariable
is verified to be non-null earlier in the method using spe-
cial null-check methods (e.g. Objects.requireNonNull() ).
Since these null-check methods belong to external libraries,
Inferisunabletounderstandtheirbehavior,resultinginfalse
positive warnings.
•whetheradereferencedvariableisaclassfield.Inpractice,
Infer’s logic makes errors when tracking the state of class
fields and often incorrectly treats them as nullable.
•whetheranimplicitcastofawrapperclasstoaprimitivetype
occurs on the warning line. In our analysis, we realized that
implicitcastscanbethecauseofmanynullpointerissues.
For example, when the code includes a map object with
primitive-typevalues(e.g.HashMapwithdoublevalues),the
map’svaluesmustinsteadbewrapperclassobjects(Double)insteadofprimitives(double),sincemapsinJavacannottakeprimitives.Valuesretrievedfromthemapareoftenstoredinprimitive-type variables, causing an implicit cast (see Figure
4). If the wrapper object is null, this cast operation causes a
null dereference.
Wetrainedalogisticregressionclassifieronthesefeatures.Since
thelimitedsizeofourdatapreventsusfromusingasimpletrain-testsplit,weinsteadused5-foldcross-validationfortrainingand
evaluation. In a realistic scenario, the model would not have access
totrainingdatafromthesameprojectforwhichitismakingpre-
dictions. However, as shown in Table 1, the projects that comprise
ourdatasetvarywidelyinthenumberofwarnings,andattempting
to separate repos across different folds would result in insufficient
training data in several folds. To partially mitigate this issue, we
ensurethatallwarningsfromthesamefileappearinthesamefold.
1HashMap<String, Double> m=newHashMap<String, Double>();
2m.put("Bla", newDouble(1.0));
3//below line will cause an implicit cast operation
4 doublev=m.get("Bla");
Figure4:Exampleofanimplicitcastofawrapperclass(Dou-ble)toprimitivetype(double)inline4.Calling get()onthe
map mreturnsaDouble,whichisimplicitlycasttodoubleto
comply with the type of v.
4.3 Neural False Positive Reduction
Engineeredfeatures,whileeasytounderstand,areinflexibleand
cannot automatically learn new patterns from data. Deep learning
models, particularly transformers, are able to better capture the
complexities of modern source code. Transformers are deep neural
networksthatleverageattentionmechanismstolearnpatternsin
sequential data, such as language. They contain billions of parame-
tersandcan leveragemassivedatasetstolearn representationsof
languagepatterns.Theyhaveachievedstate-of-the-artresultsfor
applications in natural language processing (NLP) such as machinetranslation,questionanswering,anddocumentsummarization[
26].
1310
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:26:40 UTC from IEEE Xplore.  Restrictions apply. Learning to Reduce False Positives in Analytic Bug Detectors ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
Transformers are usually pretrained on a large unlabeled corpus
and further finetuned on task-specific labeled data to perform clas-
sification or language generation.
ThewealthofopensourcecodeavailableonGitHubhasinspired
researchers to train a variety of transformers on open source code
andfinetunethemtosupportmanydownstreamtaskssuchascode
completion[ 23], documentation generation[ 9], automated code re-
view [25], software traceability [ 14], and code search using natural
language.
Twomajorcategoriesoftransformersareauto-generativemodels
and auto-regressive models. Auto-generative models such as BERT
[8] are trained to reproduce their inputs, while auto-regressive
model produce the next token in the sequence. In this work, we
leverage two transformers to help reduce Infer’s false positive rate.
Thefirstmodel,DeepInferEnhance,isacustomizedversionofCode-
BERTa:anauto-generativeencodermodelsimilartoRoBERTa[ 15].
The second model is GPT-C, an auto-regressive model with only
decoder layers (similar to GPT-2 [ 20] and GPT-3 [ 6]). Both models
require only source code as input, rather than any intermediate
code structure such as syntax trees or control flow graphs.
4.3.1 DeepInferEnhance. CodeBERTais a pre-trainedtransformer
based on the RoBERTa [ 15] architecture and developed by Hug-
gingFace [ 30]. The model was pre-trained on CodeSearchNet [ 10]:
a multilingual source code corpus of 2 million functions (with com-
ments and docstrings) from GitHub. CodeSearchNet consists of
functions from Go, Java, JavaScript, PHP, Python, and Ruby. Code-
BERTawasinspiredbythesuccessofCodeBERT[ 9],anapplication
oftheBERTarchitecturetosourcecode.CodeBERTwasalsotrained
onCodeSearchNetandyieldedstate-of-the-artresultsfortaskssuch
as code search and documentation generation. Furthermore, Code-
BERT’s promisingresults in zero-shotsettings showed thepower
of its representations.
WedecidedtousethemorelightweightandefficientCodeBERTa
architecture.However,wewereinterestedinapplyingInfertoboth
JavaandC#code,andC#wasnotablyabsentfromCodeBERTa’s
training dataset. Therefore, we pretrained an identical CodeBERTa
model on a corpus of 2 million Java and C# functions that we
collected from GitHub. Like the original CodeBERTa, our model is
pretrained using a masked language modeling (MLM) objective.
Encoder-based transformers like CodeBERTa, which incorpo-
rate information from both sides of the current position, can learn
to create efficient representations of their entire input. Through
transferlearning,theserepresentationscanthenbeusedtosolve
morespecifictasks.Wesoughttotransferourpretrainedmodel’s
learnedrepresentationstothetaskofidentifyingfalsepositiveInfer
warnings. Therefore, we added a sequence classification head to
this model in order to classify warnings as true positive or false
positive. We finetuned the model on our dataset of Infer warnings
by freezing all layers except for the classification head. The inputs
forfinetuningarestringsofcodecontext,andthelabelsareboolean
indicators of valid or invalid warnings. Our final model consists of
a 6-layer encoder and 2-layer classification head, with a total of 83
million parameters. We call this model DeepInferEnhance.4.3.2 GPT-C. Unlikeauto-generativemodels,whichlearnrepre-
sentations to reproduce their input, auto-regressive (generative)
modelslearntocreatenewtext.GPT-3isoneexampleofsuchagen-erative model [
6]. Because of the scarcity of labeled Infer warnings
for supervised learning, we turned to generative models and used
code completion recommendations as a signal of the legitimacy of
Inferwarnings. Manynulldereferencewarnings canberesolved-
evenifsub-optimally-byintroducinganullcheckbeforethederef-erence.Similarly,manyresourceleakbugscanbefixedbyexplicitly
releasingtheleakedresource.Ifagenerativemodelrecommends
anull checkorresourcerelease, thismayindicate thatthecorre-sponding warning is indeed legitimate, since the model deemedthat such a fix is necessary. Our intuition is that the model may
have a fuzzy understanding that a null check or resource release is
required.
To generate these code recommendations, we use GPT-C [ 23], a
generative transformer based on the well-known GPT-2 [ 20]. This
model was designed and trained for code line completion and rep-
resents the state of the art in this field; it was implemented as part
oftheIntelliCodeComposewebservice.Thismodelisalsomulti-
lingual and was pretrained on C#, Python, C++, Java, JavaScript,
TypeScript,Go,PHP,Ruby,andC.GPT-Ctakesinapartiallywritten
method body and uses multi-headed self-attention to predict the
nextline.Weuseitinazero-shotsetting:unlikeDeepInferEnhance,
we do not train GPT-C ourselves, but instead rely on its pretrained
parameters.Wedonotverifythesyntacticcorrectnessofthegener-atedcode,butratheruseitasa“fuzzy”signalonlytodetermineifa
warningisvalidornot.Fornulldereferencewarnings,ifthemodel
generates a null check statement at a line before a null pointer
warning occurs, we consider that warning valid.
GPT-C is trained specifically for line completion, rather than
wholelinegeneration.Thismeansthat,ratherthangeneratinga
full line of code from previous lines, GPT-C expects an incomplete
line of code at the end of its input and generates code to complete
thisline.Thisincompletetrailinglineisa promptandconsistsof
severaltokensatthebeginningofthefinalline.Forourobjective
ofpredictingInferwarningvalidity,weprovidespecificprompts
toGPT-Cforeachwarningtype.Fornulldereferences,theinput
promptsaretheprefixesof7differentnullcheckstatements(e.g.
iforDebug.Assert ).Foreach prompt,weuseGPT-C withbeam
search to generate line completion recommendations. With a beam
size of 5, this results in 35 recommendations per warning. We also
prepend non-local context to the input where possible. Figure 5
shows an example input.
Each Inferwarning hasan associatedfile pathand linenumber
thatcorrespondtothemethodwherethewarningoccurs;wecall
thisthetargetmethod.Forbothtransformermodels,theinputto
the neural network includes the source code of the target method
up to (but not including) the line of the warning. For GPT-C, we
include two additional components: the non-local context method
body preceding the target method and a line completion prompt
immediately following the target method.
1311
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:26:40 UTC from IEEE Xplore.  Restrictions apply. ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Anant Kharkar, Roshanak Zilouchian Moghaddam, Matthew Jin, Xiaoyu Liu, Xin Shi, Colin Clement, and Neel Sundaresan
201 for(Node dataNode :nodes){
202 if(allocatedDisks.size() == numberOfReplicas){
203 break;
204 }
205 Disk disk =dataNode.getDiskWithMostCapacity(replicaSize);
206 allocatedDisks.add(disk);
207 disk.freeCapacity =disk.freeCapacity -replicaSize;
publicDiskgetDiskWithMostCapacity(long replicaSize){
Disk minDisk =null;
for(Disk disk :disks){
if((minDisk ==null||minDisk.freeCapacity <disk.freeCapacity)& &disk.freeCapacity >=replicaSize){
minDisk =disk;
}
}
returnminDisk;
}
public static voidStrategy3(Datacenter dc, List<Partition> partitions, intnumberOfPartitions, intnumberOfReplicas,
longreplicaSize){
for(inti=0 ;i<numberOfPartitions; i++) {
List<Node> nodes=dc.nodes;
Collections.shuffle(nodes);
List<Disk> allocatedDisks =newArrayList<Disk>();
for(NodedataNode :nodes){
if(allocatedDisks.size() == numberOfReplicas){
break;
}Disk disk =dataNode.getDiskWithMostCapacity(replicaSize);
allocatedDisks.add(disk);if(
Figure 5: An example of a legitimate Infer warning (top) and the corresponding input to GPT-C (bottom). Infer reports that
disk,whichisassignedby getDiskWithMostCapacity() (bottom)canbenullandisdereferencedonline207.TheGPT-Cinput
is constructed by appending a prompt to the method body preceding this line, as well as prepending the non-local contextmethod getDiskWithMostCapacity(). Here GPT-C correctly predicts a null check and therefore this warning is regarded as
legitimate by the GPT-C based model.
5 EXPERIMENTS
We performed two experiments to better understand how these
models perform in a real-world setting. The first experiment, sum-
marized in Table 2, was focused on comparing effectiveness of our
feature-based and neural models. The second experiment focused
on verifying the generalizability of our neural approaches when
appliedtoadifferentbugtype.Sinceourobjectiveistoeliminate
falsepositivesreportedbyInfer,ourprimarymetrictoevaluateourmodelsistherelativeprecisionimprovementovervanillaInfer.We
alsomeasurerecallwithrespecttoInfer’struepositivewarnings:
arecallof100%meansthatallofthetruepositivewarningsfrom
vanillaInferwerereported.Byconstruction,noneoftheapproaches
inthisworkreportnewwarningsbeyondthoseoriginallyreported
by Infer.
Table 2: Performance of machine learning for removing
false positive null dereference warnings
Approach Precision ΔPrecision Recall
Baseline 72.7% - 100%
Feature-Based 78.7% +8.26% 65.1%
DeepInferEnhance 83.7% +15.13% 88.3%
GPT-C 85.4% +17.47% 83.7%5.1 Experiment 1: Comparing feature-based
and neural models
5.1.1 Feature-Based Model. The simplest data-driven approach
toidentifyfalsepositiveInferwarningsistomanuallysearchfor
patternsinthewarnings.Thehandcraftedfeatureswecollectedfor
ourlogisticregressionmodelcapturethepatternsthatwediscov-
ered from manual review of our dataset. This feature-based model
was able to improve Infer’s precision by 8%, but with significant
reduction in recall. Since source code can be inherently complex, it
is unsurprising that simple handcrafted features are insufficient to
identify false positive warnings.
5.1.2 DeepInferEnhance. Sincehandcraftedfeaturescannotade-
quately represent source code, we turned to deep learning to au-tomatically learn patterns in code that indicate the legitimacy of
Infer warnings. We took a traditional supervised transfer learning
approach, using our dataset of labeled warnings to finetune our
DeepInferEnhance model. The results show that this model greatlyimprovedprecisionandrecallcomparedtothefeature-basedmodel.
Transformersaregenerallyfinetunedonmuchlargerdatasets
thantheseveralhundredwarningsweused.However,DeepInfer-
Enhance was still able to learn patterns that provided a significant
improvementinprecision.Onesuchpatternoccurswhen nullis
explicitlypassedasanargumenttoamethod.Evenifthemethod
1312
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:26:40 UTC from IEEE Xplore.  Restrictions apply. Learning to Reduce False Positives in Analytic Bug Detectors ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
handles null arguments, Infer still reports a null dereference warn-
ing, which is often a false positive. DeepInferEnhance is able to
learn this pattern purely from the code itself.
5.1.3 GPT-C. DeepInferEnhance is able to boost vanilla Infer’s
precision, but requires labeled data. Since this data is expensive to
collect, we sought a solution that could forego supervised learning
altogether. Transformer models such as CodeBERT have shown
promisingperformanceinzero-shot settingsforsourcecode.Our
approach is novel due to our interpretation of code completion
recommendations by self-supervised generative models: recom-mendations for null checks are a signal that the null dereference
warning is legitimate. With this approach, GPT-C had the highest
precision of our models, improving on Infer by relative 17.5%, with
slightly lower recall than DeepInferEnhance.
WhileanalyzingtheresultsfromGPT-C,weidentifiedseveral
patterns in the warnings that GPT-C predicts incorrectly. These
patterns included:
Insufficientornonexistentnon-localcontext Ourinvestiga-
tionrevealedthat whennon-localcontextisunavailableorcontains
insufficientinformation,GPT-Cdoesnotperformwell.Forexample,methodcallsbelongingtoaninterfacetypecannotberesolveduntil
runtime. Therefore, we cannot retrieve such methods as non-local
context.Similarly,non-localcontextcanincludegettermethodsthat
return a class field; however, these methods do not provide any in-
formationaboutthevaluetheclassfieldmayhold.IntheexampleinFigure6,Inferwarnsthat
handlerMethod ,whichisassignedusing
getHandlerMethod() ,canbenull. getHandlerMethod() (middle)
simply returns the handlerMethod class field (bottom). In order
to correctly determine if the local variable handlerMethod can be
null, we would need to collect not only the bodies of the methods
getHandlerMethod() andcreateMessagingErrorMessage() ,but
also the constructors and fields of DefaultAzureMessageHandler .
No reference to the target object Nulldereferencewarnings
generally fall into two categories with respect to the target pointer.
For some warnings, the null pointer is represented by a variable in
thesourcecode;forotherwarnings,thepointerisreturnedfrom
a method with no explicit variable to hold its value. The latter
case presents a problem for GPT-C recommendations: the nullable
pointer has no reference in the code before the line where the
warning occurs, which is not included in the input to the model.
Therefore, this pointer does not appear in the input to GPT-C,
reducing the chance that GPT-C recommends a null-check.
Excessive sensitivity to the input Several Infer warnings in
asingleprojectcanrefertosimilarcode,oftenwiththesametarget
variable or method. In such cases, if the instances are truly similar
and legitimate, all of the instances should be reported as bugs to
theenduser.However,becauseGPT-Cisverysensitivetominor
differencesintheinputsequence,itmayreportonlyasubsetofthe
warnings as legitimate. To enforce consistency, we group together
warningswiththesametargetvariableandlabelthemallaccording
to a logical OR, where all warnings are predicted as legitimate if
GPT-Cpredictsanywarninginthegroupaslegitimate.Theresults
inTable2includethisconsistencypostprocessing.Alternatively,
warnings could be grouped according to code similarity metrics
such as edit distance.5.1.4 Overall Result. DeepInferEnhanceandGPT-Cofferatradeoff.
Ourobjectiveistoincreaseprecision,forwhichGPT-Cisbest.How-
ever, DeepInferEnhance has significantly better recall, capturing
88%oflegitimatebugswhilestillprovidinga15%boostinprecision
over vanilla Infer. Because of its superior recall, we would be more
likelytorecommendDeepInferEnhancetodeveloperswhovalue
coverage in addition to precision. H owever, this model requires
finetuning, whereas GPT-C offers the best precision and moderate
recall without the need for additional data or further training.
5.2 Experiment 2: Verifying the
generalizability of neural approaches
Toverifythegeneralizabilityofourneuralapproachesbeyond
thenull pointer bug, we evaluated our GPT-C model on Infer’s
resourceleak warnings.Aresourceleakhappenswhenaprogram
does not release resources it has acquired. The below code snippet
shows an example of a resource leak warning, where an excep-
tion inf.write(7) will cause the program to skip the f.close()
statement and leak the stream resource.
56public static voidfoo()throwsIOException {
57FileOutputStream f =newFileOutputStream(new File("w"));
58f.write(7); //an exception here will cause a leak
59f.close();
60}
In our target Java projects, Infer detected a total of 108 resource
leak warnings. Table 3 shows the summary statistics of the iden-tified resource leaks (Infer did not detect any resource leaks in
Ambry).
Table 3: Summary statistics of resource leak warnings.Total
warnings and true positives are as reported by vanillaInfer.
Name Lines of Total True Precision
Code Warnings Positives
Project A 35,527 6 2 33.3%
Project B 66,346 49 33 67.3%
Azure SDK 3,555,286 33 16 48.5%
Playwright 21,094 2 2 100 %
Nacos 62,443 7 2 28.6%
Azure Maven 23,995 11 7 63.6%
Plugins
Total 3,764,691 108 62 57.4%
Sincethisdatasetwasnotlargeenoughtomeaningfullyfinetune
DeepInferEnhance, we decided to only focus on our GPT-C model,
wherenofurthertrainingorfinetuningisrequired.Weonlyhadto
adjustourpromptinglogic.Forresourceleaks,weuseprefixes(first
three characters) of the method names close() andrelease() as
theprompts.Iftheleakedresourceisassignedtoavariable,wealso
use this variable name as a prompt. Table 4 shows the results of
using GPT-C to remove false positives in resource leak warnings.
As shown in the table, GPT-C can improve Infer’s precision
by 5.5%. However, it fails to identify over a third of legitimate
bugs. One pattern in the missed bugs is that some leaked resources
have names or types, such as EntityNotFoundHttpResponse or
ChangeFeedProcessorBuilderImpl , that do not clearly indicate
1313
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:26:40 UTC from IEEE Xplore.  Restrictions apply. ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Anant Kharkar, Roshanak Zilouchian Moghaddam, Matthew Jin, Xiaoyu Liu, Xin Shi, Colin Clement, and Neel Sundaresan
17 public class DefaultAzureMessageHandler implements AzureMessageHandler {
18
19 @Nullable
20 private InvocableHandlerMethod handlerMethod;
2122
private Class<?> messagePayloadType;
2324
private StringcreateMessagingErrorMessage(String description){
25 InvocableHandlerMethod handlerMethod =getHandlerMethod();
26 StringBuilder sb =
27 newStringBuilder(description).append("\n").append("Endpoint handler details:\n").append("Method [")
28 .append(handlerMethod.getMethod()).append("]\n").append("Bean [")
29 .append(handlerMethod.getBean()).append("]\n");
30 returnsb.toString();
31 }
56 publicInvocableHandlerMethod getHandlerMethod() {
57 returnhandlerMethod;
58}
Figure6:AnexampleofanInferwarningwherenon-localcontextdoesnotprovideenoughinformationaboutthevalueofa
class field. Infer warns that handlerMethod can be null (top). getHandlerMethod() simply returns the handlerMethod class field
(bottom). But this is not enough to determine the legitimacy of this warning.
that they are in fact resources, and therefore should be released.
Types that clearly indicate resources, such as those that contain
FileorStreamin the name, are recognized more often by GPT-C.
Table 4: Performance of machine learning for removing
false positive resource leak warnings
Approach Precision ΔPrecision Recall
GPT-C 60.6% 5.56% 64.5%
6 DISCUSSION
Our GPT-C model improved Infer’s precision by 17.5% for null
dereferences and by 5.5% for resource leaks. However, it missed
someofthecorrectwarningsthatInferdetected,witharecallof
84%fornulldereferences and65%for resourceleaks.Weidentified
several patterns of false negative predictions, which resulted in the
reducedrecall.Onepatternoccurredwhenthenon-localcontext
wasaclassfieldgettermethod.Thesemethodsareoftenasingle
return statement, which is not sufficient information for GPT-C
tomakethecorrectprediction.Onewaytomitigatethisproblem
couldbetoincludeclassfieldsandconstructorsaspartofnon-localcontext. However, the current GPT-C model is only trained for linecompletionusingsinglemethodbodies.Newertransformermodelsforcode,whichusesupplementarycontextinadditiontoindividual
method bodies, can better leverage this context to create morecomplete representations of the program state. Therefore, future
work should explore training an extended-context model for code
completion,asanevolutionoftheGPT-Cmodelweused.Weexpectthatsuchamodelwouldperformbetterinmanydownstreamtasks,
including for verifying true positive warning from static analyzers.
AnotherclassofwarningsforwhichGPT-Cdidnotperformwell
were chained method calls (e.g. foo.bar().baz() ). If a warning is
triggered on a method call in the middle of a chain, GPT-C cannot
reasonably predict a null check. Since the intermediate method
call is not stored in a variable, we cannot prompt GPT-C to predicta null check for the return value of that method call. One wayto mitigate this problem is to modify the source code to insert a
variable assignment for each method call in the chain. However,
a developer would only break the method chain for a null check
wherenecessary.Therefore,breakingthechainmaycreateanab-
normal codepattern thatGPT-Cwill notrecognize. Alternatively,
thevariableassignmentcouldbeinsertedforonlyonemethodin
the chain. For each method call in the chain, we could insert anassignment, generate recommendations using GPT-C, and selectthe recommendation with the highest confidence. However, we
decidedonamuchsimplerapproachtomitigatechainedmethod
calls: simply trust Infer’s decision and predict such warnings as
legitimate bugs.
Foranybugdetectionsystem,precisionandrecall havesignifi-
cantly different downstream impacts for developers. Low precision
means that developers waste time analyzing many false positive
warnings, while low recall means that some legitimate bugs are
not identified. Static analyzers have typically favored coverage and
recall over precision, with the objective of maximizing the number
of reported legitimate bugs. However, in practice, low precision
reducesdeveloperadoptionofanalysistools[ 11]duetothetime
developerswasteoninvestigatingfalsepositives.Priorworkhas
found that developers mostly use analysis tools in their spare time
andtendtofixwarningsinshortworkingsessions.Therefore,they
are primarily driven by time constraints when addressing bugs
identifiedbystaticanalyzers[ 17].Asaresult,wechosetofocuson
precision rather than recall; we believe presenting developers with
higher quality warnings will lead to bugs actually being addressed,
rather than ignored due to a lack of confidence or time constraints.
Howeverincertaincases,whererecallismoreimportant,ourmod-
els can be used to re-rank the warnings so that developers are
presented withmore true positivesfirst. Thisallows us topresent
all warnings to developers while prioritizing likely legitimate bugs.
We demonstrated the effectiveness of transformer models for
two bug types and one tool, but we believe this approach should
generalizetootherlanguagesandtools.Ourexperimentonresource
1314
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:26:40 UTC from IEEE Xplore.  Restrictions apply. Learning to Reduce False Positives in Analytic Bug Detectors ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
leaksprovidesevidenceofthis.Inaddition,ourGPT-Capproach
isnottiedtoaparticularprogramminglanguage,staticanalyzer,
or warning type. Because we use GPT-C in a zero-shot setting, no
furthertrainingisrequired.Customizationmayinsteadberequired
throughuniquewaysofpromptingGPT-Candspecificsignalsto
seekinitsoutputs;adjustingpromptsshouldbetheonlychange
necessary to apply GPT-C to new bug types. For example, one way
to apply this technique to buffer overflow bugs in C/C++ couldbe to search for bounds checking recommendations. Even Deep-InferEnhance, which requires labeled data for finetuning, can be
expanded to additional programming languages by pretraining on
a larger and more diverse corpus.
Inthisworkweappliedlarge-scaletransformerstofurtherverify
bugs that have already been localized by static analyzers. Whilethismeansthatourapproachwillnotfindbugsbeyondthosere-
ported by the static analyzers, it is a cost-effective way to leverage
transformers for this problem. Large-scale transformer models are
expensive to train and evaluate, and using them to scan everymethod or every line of a project can be prohibitively expensive.By applying these models to resolve warnings that have alreadybeen localized by a static analyzer, we ensure that transformersare utilized in a cost-effective way . However, there may be other
waystolocalizebugsandusetransformers.Forexample,onecan
leverage prior work on bug localization to determine buggy files
[29]andonlyexaminethosefilesasopposedtotheentireprogram.
6.1 Threats to Validity
6.1.1 Dataset Size. Static analysis warnings are time-intensive to
triage, since each warning requires a detailed review of the source
code involved in the warning. It is expensive to collect a large
datasetoflabeledwarnings,whichispreferredwhentrainingtrans-formermodels.ThisisparticularlyimpactfulforDeepInferEnhance,
which requires labeled data for both finetuning and evaluation. Al-
though we used cross validation to compensate for the limiteddataset size, all of our approaches would benefit from a largerdataset. In order to scale the dataset, we must present warningsto project owners for review. Through developer engagements,
wefoundthatthisraisesacold-startproblem:inordertoreceive
appropriate attention and high-quality feedback, warnings must
havesufficientlyhighprecision,orelsedevelopersmaynotengage
with warnings shared for labeling purposes. We believe that the
precision improvements of the approaches discussed here serve
asasolution tothiscold-startproblem, andwillallowus toshare
warnings with a wider set of projects to scale our dataset.
6.1.2 Evidence of Generalizability. Ourapproachofusingmachine
learning to augment and complement static analysis is designed
genericallytobenefitanyanalyzer.However,inthisstudy,wefocus
on one analyzer (Infer) and two categories of bugs (null derefer-ence and resource leak) for one language (Java). To gain wider
adoption among developers of diverse projects, our approach must
demonstrate benefits across additional languages and bug types.
Ourexperimentswithresourceleaksareourfirstattempttodemon-
stratethis.WeplantoapplyandevaluateourapproachtoC#,as
well as additional languages, as the next step for expanding our
approach.6.2 Data Release
OurdatasetconsistsofwarningsfromInferforvariousopensource
and proprietary software projects. Source code from proprietary
projectswasmadeavailabletoussolelyforresearchpurposes.Since
wedonotownthisdata,wecannotreleaseitpublicly.Weintendto
release data from open source projects after we have worked with
eachprojectownerto resolvetheissues,orotherwiseverifywith
the owners the safety of releasing bug or vulnerability data.
7 CONCLUSION
Rule-based bug detectors and static analyzers have been widely
adopted for detecting security vulnerabilities, functional bugs, and
even performance issues. However, building an analyzer is non-
trivialbecauseofthedifficultyofbalancingprecisionandcoverage:
reportingonlycorrectbugsandensuringthatallsimilarbugsare
reported.
Themajorityofexistinganalyzersfavorhighercoveragetoen-
sure completeness, and therefore they produce more false positive
warnings.However,frequentfalsepositivewarningsareoneofthe
main barriers to wider adoption of static analyzers in the software
industry; this problem cannot be solved by the analyzers them-selves. To close this gap, we augmented static analyzers with a
varietyofmachinelearningmodels.Weexperimentedwithboth
feature-basedandneuralmodelsforfalsepositivereduction.Our
experimentsonInfer,awell-knowninterproceduralstaticanalyzer,
showed that leveraging GPT-C in a zero-shot setting can improve
theprecisionofnullpointerwarningsby17.5%andresourceleak
warnings by 6%.
One immediate direction for future work is to experiment with
more warning types and languages to further verify the gener-alizability of our approach. Another direction involves training
transformers with broader context. For instance, one may include
the imports, constructors, class fields, and superclasses (in cases of
inheritance)aspartofthecontextwhiletraining.Weexpectthis
broader context to increase transformer effectiveness in general,
and especially in zero-shot settings to augment other code analyz-
ers.Athirddirectionistoexplorewhetheragenerativetransformer
similar to GPT-C can be used in conjunction with a static analyzer
to suggest fixes for some or all the bugs.
REFERENCES
[1] [n.d.]. Coverity. https://scan.coverity.com/
[2] [n.d.]. SonarQube. https://www.sonarqube.org/[3]
N. Ayewah, W. Pugh, D. Hovemeyer, J. D. Morgenthaler, and J. Penix. 2008.Using Static Analysis to Find Bugs. IEEE Software 25, 5 (2008), 22–29. https:
//doi.org/10.1109/MS.2008.130
[4]Nathaniel Ayewah, William Pugh, J. David Morgenthaler, John Penix, and
YuQian Zhou. 2007. Using FindBugs on Production Software. In Companion
to the 22nd ACM SIGPLAN Conference on Object-Oriented Programming Sys-tems and Applications Companion (Montreal, Quebec, Canada) (OOPSLA ’07).
Association for Computing Machinery, New York, NY, USA, 805–806. https:
//doi.org/10.1145/1297846.1297897
[5]PavolBielik,VeselinRaychev,andMartinVechev.2017. Learningastaticanalyzer
from data. In International Conference on Computer AidedVerification. Springer,
233–253.
[6]Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,
Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell,SandhiniAgarwal,ArielHerbert-Voss,GretchenKrueger,TomHenighan,
Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter,
ChristopherHesse,MarkChen,EricSigler,MateuszLitwin,ScottGray,Benjamin
Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya
1315
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:26:40 UTC from IEEE Xplore.  Restrictions apply. ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Anant Kharkar, Roshanak Zilouchian Moghaddam, Matthew Jin, Xiaoyu Liu, Xin Shi, Colin Clement, and Neel Sundaresan
Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners.
CoRRabs/2005.14165 (2020). arXiv:2005.14165 https://arxiv.org/abs/2005.14165
[7]Min-JeChoi,SehunJeong,HakjooOh,andJaegulChoo.2017. End-to-EndPre-
dictionofBufferOverrunsfromRawSourceCodeviaNeuralMemoryNetworks.
CoRRabs/1703.02458 (2017). arXiv:1703.02458 http://arxiv.org/abs/1703.02458
[8]JacobDevlin,Ming-WeiChang,KentonLee,andKristinaToutanova.2018. BERT:
Pre-trainingofDeepBidirectionalTransformersforLanguageUnderstanding.
CoRRabs/1810.04805 (2018). arXiv:1810.04805 http://arxiv.org/abs/1810.04805
[9]Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming
Gong (YIMING), Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, and Ming Zhou.
2020. CodeBERT:APre-TrainedModelforProgrammingandNaturalLanguages.
InFindings of EMNLP 2020.
[10]Hamel Husain, Ho-Hsiang Wu, Tiferet Gazit, Miltiadis Allamanis, and Marc
Brockschmidt.2020. CodeSearchNetChallenge:EvaluatingtheStateofSemantic
Code Search. (June 2020).
[11]Brittany Johnson, Yoonki Song, Emerson Murphy-Hill, and Robert Bowdidge.
2013. WhyDon’tSoftwareDevelopersUseStaticAnalysisToolstoFindBugs?.
InProceedings of the 2013 International Conference on Software Engineering (San
Francisco, CA, USA) (ICSE ’13). IEEE Press, 672–681.
[12]Maximilian Junker, Ralf Huuck, Ansgar Fehnker, and Alexander Knapp. 2012.
SMT-based false positive elimination in static program analysis. In International
Conference on Formal Engineering Methods. Springer, 316–331.
[13]Zhen Li, Deqing Zou, Shouhuai Xu, Xinyu Ou, Hai Jin, Sujuan Wang, Zhijun
Deng,andYuyiZhong.2018. Vuldeepecker:Adeeplearning-basedsystemfor
vulnerability detection. arXiv preprint arXiv:1801.01681 (2018).
[14]Jinfeng Lin, Yalin Liu, Qingkai Zeng, Meng Jiang, and Jane Cleland-Huang. 2021.
Traceability Transformed: Generating more Accurate Links with Pre-Trained
BERT Models. CoRRabs/2102.04411 (2021). arXiv:2102.04411 https://arxiv.org/
abs/2102.04411
[15]YinhanLiu,MyleOtt,NamanGoyal,JingfeiDu,MandarJoshi,DanqiChen,Omer
Levy,MikeLewis,LukeZettlemoyer,andVeselinStoyanov.2019. RoBERTa:A
Robustly Optimized BERT Pretraining Approach. arXiv:1907.11692 [cs.CL]
[16]TukaramBMuske,AnkitBaid,andTusharSanas.2013. Revieweffortsreduction
bypartitioningofstaticanalysiswarnings.In 2013IEEE13thInternationalWorking
Conference on Source Code Analysis and Manipulation (SCAM). IEEE, 106–115.
[17]LisaNguyenQuangDo, JamesWright, andKarim Ali.2020. Why DoSoftware
Developers Use Static Analysis Tools? A User-Centered Study of Developer
NeedsandMotivations. IEEETransactionsonSoftwareEngineering (2020),1–1.
https://doi.org/10.1109/TSE.2020.3004525
[18]Yulei Pang, Xiaozhen Xue, and Akbar Siami Namin. 2015. Predicting vulnerable
softwarecomponentsthroughn-gramanalysisandstatisticalfeatureselection.
In2015 IEEE 14th International Conference on Machine Learning and Applications
(ICMLA). IEEE, 543–548.
[19]Michael Pradel and Koushik Sen. 2018. DeepBugs: A Learning Approach to
Name-Based Bug Detection. Proc. ACM Program. Lang. 2, OOPSLA,Article 147
(Oct. 2018), 25 pages. https://doi.org/10.1145/3276517
[20]Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
Sutskever. 2019. Language models are unsupervised multitask learners. OpenAI
blog1, 8 (2019), 9.
[21]Rebecca Russell, Louis Kim, Lei Hamilton, Tomo Lazovich, Jacob Harer, Onur
Ozdemir, Paul Ellingwood, and Marc McConley. 2018. Automated vulnerability
detectioninsourcecodeusingdeeprepresentationlearning.In 201817thIEEE
InternationalConferenceonMachineLearningandApplications(ICMLA).IEEE,
757–762.
[22]H. Shen, J. Fang, and J. Zhao. 2011. EFindBugs: Effective Error Ranking for Find-
Bugs.In2011FourthIEEEInternationalConferenceonSoftwareTesting,Verification
and Validation. 299–308. https://doi.org/10.1109/ICST.2011.51
[23]AlexeySvyatkovskiy,ShaoKunDeng,ShengyuFu,andNeelSundaresan.2020.
IntelliCodeCompose:CodeGenerationUsingTransformer. CoRRabs/2005.08025
(2020). arXiv:2005.08025 https://arxiv.org/abs/2005.08025
[24]OmerTripp,SalvatoreGuarnieri,MarcoPistoia,andAleksandrAravkin.2014.
ALETHEIA: Improvingthe Usabilityof StaticSecurityAnalysis. In Proceedings
ofthe2014ACMSIGSACConferenceonComputerandCommunicationsSecurity
(Scottsdale,Arizona,USA) (CCS’14).AssociationforComputingMachinery,New
York, NY, USA, 762–774. https://doi.org/10.1145/2660267.2660339
[25]Rosalia Tufano, Luca Pascarella, Michele Tufano, Denys Poshyvanyk, andGabriele Bavota. 2021. Towards Automating Code Review Activities. CoRR
abs/2101.02518 (2021). arXiv:2101.02518 https://arxiv.org/abs/2101.02518
[26]Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
AidanNGomez,ŁukaszKaiser,andIlliaPolosukhin.2017. Attentionisallyou
need.InProceedings of the 31st International Conference on Neural Information
Processing Systems. 6000–6010.
[27]John Viega, Jon-Thomas Bloch, Yoshi Kohno, and Gary McGraw. 2000. ITS4:
A static vulnerability scanner for C and C++ code. In Proceedings 16th Annual
Computer Security Applications Conference (ACSAC’00). IEEE, 257–267.
[28]SongWang,DevinChollak,DanaMovshovitz-Attias,andLinTan.2016. Bugram:bugdetectionwithn-gramlanguagemodels.In Proceedingsofthe31stIEEE/ACM
International Conference on Automated Software Engineering. 708–719.[29]Song Wang, Taiyue Liu, and Lin Tan. 2016. Automatically learning semantic
features for defect prediction. In 2016 IEEE/ACM 38th International Conference on
Software Engineering (ICSE). IEEE, 297–308.
[30]ThomasWolf,LysandreDebut,VictorSanh,JulienChaumond,ClementDelangue,
Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe
Davison,SamShleifer,PatrickvonPlaten,ClaraMa,YacineJernite,JulienPlu,
CanwenXu,TevenLeScao,SylvainGugger,MariamaDrame,QuentinLhoest,
and Alexander M. Rush. 2020. HuggingFace’s Transformers: State-of-the-art
Natural Language Processing. arXiv:1910.03771 [cs.CL]
[31]ZhongxingXu,TedKremenek,andJianZhang.2010. Amemorymodelforstatic
analysis of C programs. In International Symposium On Leveraging Applications
of Formal Methods, Verification and Validation. Springer, 535–548.
1316
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:26:40 UTC from IEEE Xplore.  Restrictions apply. 