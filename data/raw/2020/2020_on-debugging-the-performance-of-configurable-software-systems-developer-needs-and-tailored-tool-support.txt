On Debugging the Performance of Configurable Software
Systems: Developer Needs and Tailored Tool Support
Miguel Velez
Carnegie Mellon UniversityPooyan Jamshidi
University of South CarolinaNorbert Siegmund
Leipzig University
Sven Apel
Saarland Informatics Campus -
Saarland UniversityChristian Kästner
Carnegie Mellon University
ABSTRACT
Determining whether a configurable software system has a per-
formance bugor itwas misconfiguredis oftenchallenging. While
there arenumerous debugging techniquesthat can supportdevel-
opers in this task, there is limited empirical evidence of how useful
thetechniquesaretoaddresstheactualneedsthatdevelopershave
whendebuggingtheperformanceofconfigurablesoftwaresystems;
most techniques are often evaluated in terms of technical accuracy
instead of their usability. In this paper, we take a human-centered
approach to identify, design, implement, and evaluate a solution to
supportdevelopersintheprocessofdebuggingtheperformance
of configurable software systems. We first conduct an exploratory
study with 19 developers to identify the information needs that
developershaveduringthis process.Subsequently,wedesignand
implement a tailored tool, adapting techniques from prior work, to
supportthoseneeds.Twouserstudies,withatotalof20developers,
validateandconfirmthattheinformationthatweprovidehelpsde-
velopers debug the performance of configurable software systems.
ACM Reference Format:
MiguelVelez,PooyanJamshidi,NorbertSiegmund,SvenApel,andChristian
Kästner.2022.OnDebuggingthePerformanceofConfigurableSoftwareSys-tems:DeveloperNeedsandTailoredToolSupport.In 44thInternationalCon-
ferenceonSoftwareEngineering(ICSE’22),May21–29,2022,Pittsburgh,PA,USA.ACM,NewYork,NY,USA,13pages.https://doi.org/10.1145/3510003.
3510043
1 INTRODUCTION
Developers often spend a substantial amount of time diagnosing a
configurablesoftwaresystemtolocalizeandfixaperformancebug,
or to determine that the system was misconfigured [ 8,11,26,30,
32,33,55,58,59,86]. This struggle is quite common when main-
taining configurable software systems. Some empirical studies find
that59percentofperformanceissuesarerelatedtoconfiguration
errors, 88 percent of these issues require fixing the code [ 26,27],
ofwhich61percenttakeanaverageof5weekstofix[ 41],andthat
50 percent of patches in open-source cloud systems and 30 percent
This work is licensed under a Creative Commons Attribution International 4.0 
License.
ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
© 2022 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-9221-1/22/05.
https://doi.org/10.1145/3510003.3510043class Main 
  boolean commit; boolean sync; 
  def main()     trans = getOpt("TRANSACTIONS" );  
    dups = getOpt("DUPLICATES" ); 
    Database db = new Database (trans, dups); 
    init(db);     new Cursor().put(this.commit, this.sync);  
  def init(Database db) {     ....     this.commit = db.trans ? true : false; 
    this.sync = db.dups ? true : false; 
    .... 
class Database  
  boolean trans; boolean dups; 
  def Database (boolean  trans, boolean dups) 
    this.trans = trans;     this.dups = dups; 
class Cursor { 
  def put(boolean  commit, boolean sync) 
    if(commit) 
if(sync) 
synchronized (...) 
....What is the issue? (Effect)
Executing one configuration 
results in a 20x slowdown in this 50-option configurable system
Why this issue occurs? (Cause)
Setting the options Transactions  and Duplicates  
to true, drastically increases the 
execution time of the method Cursor.put . 
Transactions  sets the value of 
commit  and Duplicates  sets 
the value of sync. When the 
variables are true, the system 
synchronizes, which is not 
required when inserting duplicate 
data using transactions. The variables are initialized in Main.init , using the values of 
the options. Note that the options are passed through the Database  
object created in Main.main .
Figure 1: Artificial example contrasting effects and causes when
debugging the performance of configurable software systems.
ofquestionsinforumsarerelatedtoconfigurations[ 75].Regard-
less of how developers find the root cause of the issue or mis-
configuration,performanceissuesimpairuserexperience,which
often result in long execution times or increased energy consump-
tion [26, 29, 30, 32, 44, 68, 78].
When performance issues occur, developers typically use profil-
ers to identify the locations of performance bottlenecks [ 10,12,13,
21,84].Unfortunately,locationswhereasystemspendsthemost
time executing are not necessarily the sign of a performance issue.
Additionally, traditional profilers only indicate the locations of the
effectofperformanceissues(i.e.,whereasystemspendsthemost
time executing) for one configuration at a time. Developers are left
to inspect the code to analyze the root cause of the performance
issues and to determine how the issues relate to configurations.
WithanexamplescenarioinFigure1,weillustratethekindof
performance challenge that developers may face in configurable
software systems and that we seek to support: A user executes a
configurationofthissystemwith50configurationoptions,whichre-sultsinan unexpected 20
×slowdown.The onlyvisibleeffect istheex-
cessiveexecutiontime.While,insomesituations,developersmight
be able to change some options to work around the problem, users
mightnotknowwhichoptionscausetheproblem,andmaywantto
select certain options to satisfy specific needs (e.g., enable encryp-
tion,useaspecifictransformationalgorithm,orsetaspecificcachesize).Inthesesituations,developersneedtodeterminewhetherthesystemhasapotential bug,ismisconfigured,orworksasintended To
15712022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)
ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Miguel Velez, Pooyan Jamshidi, Norbert Siegmund, Sven Apel, and Christian Kästner
determinethecauseofthepotentiallyproblematicperformancebe-
havior,developerswouldneedtodebugthesystemand,mostlikely,
theimplementation toidentifywhichoptionsorinteractionsinthis
configuration of 50 options are the root cause of theunexpected
performancebehavior (e.g.,thesystemworksasexpected,setting
a specific Cache_Size results in a misconfiguration, or setting the
options Transactions and Duplicates to trueresults in a bug).
Whenperformanceissuessuchasinourexampleoccur,there
arenumeroustechniquesthatdeveloperscouldusetodetermine
whetherthereisaperformancebugorthesystemwasmisconfig-
ured.Inadditiontooff-the-shelfprofilers[ 15,53,74],developers
could use more targeted profiling techniques [ 4,10,13,83,84],
visualizeperformancebehavior[ 2,6,12,21,62,70],searchforinef-
ficientcodingpatterns[ 7,46,54,56,68],useinformation-flowanal-
yses[43,45,48,69,79,81,88],ormodeltheperformanceofthesys-
tems in terms of its options and interactions [ 24,38,64,71,72,76].
Likewise,developerscoulduseestablishedprogramdebuggingtech-
niques,suchasdeltadebugging[ 85],programslicing[ 3,39,77],and
statisticaldebugging[ 5,67]forsomepartofthedebuggingprocess.
One reason why we cannot reliably suggest developers to use any
oftheabovetechniquesisthatthereislimitedempiricalevidenceof
how useful the techniques are to help developers debug the perfor-
manceofconfigurablesoftwaresystems;thetechniquestypically
solveaspecifictechnicalchallengethatisusuallyevaluatedinterms
ofaccuracy,notusability[ 59].Hence,wecouldonly,atbest,specu-
latewhichtechniquesmightsupportdevelopers’needstodebugun-
expected performance behaviors in configurable software systems.
In this paper, we take a human-centered approach [ 16,51]t o
identify,design,implement ,andevaluateasolutiontosupportdevel-
opers in the process of debugging the performance of configurable
softwaresystems;particularly,insituationssuchasourexample
in Figure 1. Our human-centered research design consists of three
steps, summarized in Figure 2: We first conduct an exploratory user
studytoidentifythe informationneeds thatdevelopers havewhen
debugging the performance of configurable software systems. Our
study reveals that developers struggleto find relevant informa-
tion to (a) identify influencingoptions; the options or interactions
causingan unexpected performance behavior, (b) locate option
hotspots; the methods whereoptions affect the performance of the
system,and(c)tracethe cause-effectchain;howinfluencingoptions
are used in the implementation to directly and indirectly affect the
performanceofoptionhotspots.Subsequently,we designandimple-
ment information providers to support developers’ needs, adapting
and tailoring global and local performance-influence models, CPU
profiling,andprogramslicing,inatoolcalled GLIMPS.Finally,we
conduct two user studies to validateandconfirmthat the designed
informationprovidersareusefultodeveloperswhendebuggingthe
performanceofcomplexconfigurablesoftwaresystems,interms
of supporting their information needs and speeding up the process.
In summary, we make the following contributions:
•Theinformationneeds–influencingoptions,optionhotspots,
andcause-effectchain–thatdevelopershavewhendebug-
ging the performance of configurable software systems;
•The design of information providers, adapted from global
and local performance-influence models, CPU profiling, and
program slicing, to support the above needs;Identify Information Needs† Exploratory study 
(19 developers, medium-sized system)
Design Information Providers† Tailor information sources to 
support information needs
Validation study 
(8 developers, medium-sized system)
Confirmatory study 
(12 developers, complex system)
† for debugging the performance of configurable software systemsEvaluate usefulness of  
Information Providers†
Figure 2: Overview of our human-centered approach to support
the information needs that developers have when debugging the
performance of configurable software systems.
•Two empirical evaluations to demonstrate the usefulness of
the designed information providers;
•A prototype tool, GLIMPS, that implements the designed
informationproviderstohelpdevelopersdebugtheperfor-
mance of configurable software systems.
2 PERFORMANCE DEBUGGING IN
CONFIGURABLE SOFTWARE SYSTEMS
There is substantial literature on debugging the performance of
software systems [e.g., 25,29,46,56,67]. Our goal is to support
developers in the process of debugging the performance of config-
urablesoftwaresystems;inparticular,whendevelopersdonoteven
know which options or interactions in their current configuration
cause an unexpected performance behavior.
Whenperformanceissuesoccurinsoftwaresystems,developers
need to identify relevant information to debug the unexpected per-
formancebehaviors[ 8,11,27,55].Forthistask,inadditiontousing
off-the-shelf profilers[ 15,53,74], someresearchers suggest using
more targeted profiling techniques [ 10,12,13,21,84] and visual-
izations[2,6,12,21,62,70]toidentifyandanalyzethelocationsof
performancebottlenecks.Alternatively,someresearcherssuggest
using techniques to search for inefficient coding patterns [ 7,13,46,
54,56,68]. While these techniques are quite useful, there is lim-
ited evidence of their usefulness when debugging the performance
ofconfigurablesoftwaresystems;particularly,todeterminehow
performance issues are related to options and their interactions.
In addition to performance debugging techniques, there are
several established program debugging techniques , such as delta
debugging [ 85], program slicing [ 3,39,77], and statistical debug-
ging [5,67], that can help developers isolate relevant parts of a
systemtofocustheirdebuggingefforts.Forthisreason,thetech-
niques have been implemented in the backend of tools to help
developers debug [ 9,37,42,60]. For example, Whyline [ 37] com-
binesstaticanddynamicprogramslicingtoallowdeveloperstoask
questionsaboutasystem’soutput.Whilethesetoolshavebeeneval-
uatedintermsoftheirtechnicalaccuracyandsomealsointermsof
usabilitywithuserstudies,thereislimitedevidenceofwhichand
how these program debuggingtechniques canbe usedoradopted
for debugging the performance of configurable software systems.
1572On Debugging the Performance of Configurable Software Systems: Developer Needs and Tailored Tool Support ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
Performanceissuesinconfigurablesoftwaresystems: Performance
issuesareoftencausedbymisconfigurationsorsoftwarebugs,both
ofwhichimpairuserexperience.Misconfigurationsareerrorsin
which the system and the input are correct, but the system does
not behave as desired, because the user-selected configuration is
inconsistentordoesnotmatchtheintendedbehavior[ 82,87,89].
By contrast, a software bug is a programming error by a devel-
operthat degrades a system’s behavior or functionality [ 5,85,86].
Regardlessoftherootcauseoftheunexpectedbehavior(misconfig-
urationsorsoftwarebugs),systemsoftenmisbehavewithsimilar
symptoms, such as crashes, incorrect results [ 5,47,85,86], and, in
terms of performance, long execution times or increased energy
consumption [26, 29, 30, 32, 44, 68, 78].
Research has repeatedly found that configuration-related per-
formance issues are common and complex to fix in software sys-
tems[26,27,29,41,75].Forexample,HanandYu [26]foundthat
59percentofperformance issuesconcernconfigurations, 72per-
cent of which involved one option, and 88 percent require fixing
the code. Similarly, Krishna et al . [41]found that 61 percent of per-
formanceissues takean averageof 5weeksto fix,and Wanget al .
[75]foundthat50percentofpatchesinopen-sourcecloudsystems
and 30 percent of questions in forums are related to configurations
and performance issues. Performance issues were primarily caused
by incorrect implementation of configurations, synchronization
issues, and misconfigurations.
Debugging performance in configurable software systems: Similar
todebuggingperformanceingeneral,identifyingrelevantinforma-
tion is key when debugging unexpected performance behaviors in
configurablesoftwaresystems.Ideally,developerswouldhaverel-
evant information to debug how performance issues are related to
specific options and their interactions. Unfortunately, there are sit-
uations in which developers only know the effectof an unexpected
performancebehavior(e.g.,alongexecutiontimeasinFigure1).
Inthesesituations,developersneedtodebugthesystemtodeter-
minewhetherthesystemhasapotential bug,ismisconfigured ,or
works correctly , but the user has a different expectation about the
performance behavior of the system. For these reasons, our goal is
tosupportdevelopersin findingrelevantinformation todebugun-
expected performance behaviors in configurable software systems.
Therearesomeresearchareasthataimtohelpdevelopersunder-
standhowoptionsaffectasystem’sbehavior.Forinstance,somere-
searchersarguethatinformation-flowanalysescanhelpdevelopers
understandhowoptionsaffectasystem’sbehavior[ 43,45,48,69,79,
81,88]. For example, Lotrack [ 45] used static taint analysis to iden-
tify under which configurations particular code fragments are exe-
cuted.Whilethesetechniquescansolvespecificchallenges,thereis
limited evidence of the usefulness of these techniques, particularly,
for debugging the performance of configurable software systems.
Intermsofunderstandingperformance,someresearcherssug-
gest that performance-influence models can help developers debug
unexpected performance behaviors [ 24,38,64,71,72,76], as the
modelsdescribeasystem’sperformanceintermsofitsoptionsand
their interactions. For example, the model 8 ·A·B+5·Cexplains
theinfluenceoftheoptionsA,B,andC,andtheirinteractionson
the performance of a system; in this example, enabling C increases
the execution time by 5 seconds, and enabling A and B, together,further increase the execution time by 8 seconds. Some approaches
alsomodeltheperformanceofindividualmethods[ 28,71,72,76],
whichcanbeusefultolocate whereoptionsaffectasystem’sperfor-
mance. However,while performance-influence models have been
evaluatedintermsofaccuracy[ 36,64–66,71,72]andoptimizing
performance[ 22,52,57,90],theyhavenotbeenevaluatedinterms
of usability; in particular, to support developers’ needs when de-
bugging the performance of configurable software systems.
Contributions: Wetakeahuman-centeredapproach[ 16,51]to
identify, design, implement, and evaluate a solution to support
developers whendebugging the performance ofconfigurable soft-
waresystems.Wefirstconductanexploratoryuserstudyto identify
theinformation needs that developers have when debugging the
performance of configurable software systems. Afterwards, we de-
signandimplement information providers to support developers’
needs,adaptingtechniquesfrompriorwork.Finally,weconduct
avalidation userstudyanda confirmatory userstudytoevaluate
that the designed information providers actually support develop-
ers’ informationneeds and speedupthepr ocess of debugging the
performance of complex configurable software systems.
3 EXPLORING INFORMATION NEEDS
While there are numerous performance and program debugging
techniques,thereislimitedempiricalevidenceofhowusefulthe
techniquesaretosupportdevelopers’needswhendebuggingthe
performance of configurable software systems. Hence, we first in-
vestigatethe informationneeds thatdevelopershaveandtheprocess
thattheyfollowtodebugtheperformanceofconfigurablesoftware
systems.Specifically,weanswerthefollowingresearchquestions:
RQ1:Whatinformationdodeveloperslookforwhendebug-
ging the performance of configurable software systems?
RQ2: What is the process that developers follow and the ac-
tivities that they perform to obtain this information?
RQ3: What barriers do developers face during this process?
3.1 Method
Weconductedanexploratoryuserstudyto identifytheinformation
needsthat developers have when debugging the performance of
configurablesoftwaresystems.UsingZeller’sterminology[ 86],we
wanttounderstand howdevelopers findpossibleinfectionorigins :
where options affect performance, and analyze the infection chain :
what are the causes of an unexpected performance behavior, when
debugging the performance of configurable software systems.
Study design. We conducted the exploratory user study, combin-
ing a think-aloud protocol [ 31] and a Wizard of Oz approach [ 14],
to observe how participants debug a performance issue for 50 min-
utes:Weencourageparticipantstoverbalizewhattheyaredoingor
trying to do (i.e., think-aloud component), while the experimenter
plays the role of some tool that can provide performance behavior
information, such as performance profiles and execution time of
specific configurations, on demand (i.e., Wizard of Oz component),
thus avoiding overhead from finding or learning specific tools.
1573ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Miguel Velez, Pooyan Jamshidi, Norbert Siegmund, Sven Apel, and Christian Kästner
We decided to provide additional information to participants
halfway through the study, after we found, in a pilot study with
4graduatestudentsfromourpersonalnetwork,thatparticipants
spend an extremely long time ( ∼60 minutes in a relatively small
system) just identifying relevant options and methods. To addition-
ally explore how participants search for the cause of performance
issues once they have identified options and methods, we told par-
ticipants,after25minutes,whichoptionscausetheperformance
issue and the methods where the options influence performance.
In this way, we can both observe how participants start addressing
theproblemandanalyzehowoptionsaffecttheperformanceinthe
implementation.
Afterthetask,weconductedabriefsemi-structuredinterview
to discuss the participants’ experience in debugging the system, as
well as the information that they found useful and would like to
have when debugging the performance of configurable software
systems.
Due to the COVID-19 pandemic, we conducted the studies re-
motely over Zoom. We asked participants to download and import
thesourcecodeofthesubjectsystemtotheirfavoriteIDE,toavoid
struggles with using an unfamiliar environment. We also asked
participants to share their screen. With the participants’ permis-
sion,werecordedaudioandvideoofthesessionsforsubsequent
analysis.
Task and subject system. Based on past studies [ 47,49,50,59]
thathaveshownhowtime-consumingdebuggingevensmallcon-
figurablesoftwaresystemsis,wepreparedoneperformancedebug-
gingtaskforoneconfigurablesoftwaresystemofmoderatesizeand
complexity. We selected Density Converter as the subject system,
which transforms images to different dimensions and formats. We
selectedthisJavasystembecauseitismedium-sized,yetnon-trivial,
withover49KSLOCand22binaryandnon-binaryoptions,andhas
manyoptionsthatinfluenceitsperformancebehavior;execution
timeonthesameworkloadrangedfromfewsecondstoacouple
of minutes, depending on the configuration. The task involved
a user-defined configuration that spends an excessive amount of
time executing. We introduced a bug caused by the incorrect im-
plementationofoneoption,representativeofbugsreportedinpast
research [ 1,26,32] (the system was spending a long time to trans-
formandoutputaJPEGimage).Participantswereaskedtoidentify
and explain which and how options caused the unexpected perfor-
mance behavior. We, however, did not explicitly tell participants
that the performance problem was related to configurations.
Participants. We recruited 14 graduate students and 5 profes-
sional software engineers with extensive experience analyzing the
performanceofconfigurableJavasystems.Westoppedrecruiting
whenweobservedsimilarinformationneedsandpatternsinthe
debuggingprocess.WeusedourprofessionalnetworkandLinkedIn
for recruiting.The graduatestudents hada medianof 6 .5years of
programming experience, a median of 5 years in Java, a median of
3 years analyzing performance and a median of 4 .5 years working
with configurable software systems. The software engineers had
amedianof13yearsofprogrammingexperience,amedianof13
years in Java, a median of 5 years analyzing performance and a
median of 5 years working with configurable software systems.Analysis. We analyzed transcripts of the audio and video record-
ingsofthedebuggingtaskandinterviewsusingstandardqualitative
research methods [ 61]. The first author conducted the study and
codedthesessionsusingopenanddescriptivecoding,summarizing
observations, discussions, and trends [ 73]. All authors met weekly
todiscussthecodesandobservations.Whencodeswereupdated,
previouslyanalyzedsessionswerereanalyzedtoupdatethecoding.
ThreatstoValidityandCredibility. Weobservehowdevelopers
debugtheperformanceofasystemthattheyhadnotusedbefore.
Developers who are familiar with a system might have different
needsorfollowdifferentprocesses.Whilereadersshouldbecareful
whengeneralizingourfindings,theneedshelpusidentifytheinfor-
mation that, at the very least, developers want to find when debug-
ging the performance of unfamiliar configurable software systems.
Conductingastudywithonesysteminwhichoneoptioncausesa
performanceissuehasthepotentialtooverfitthefindingstothissce-
nario, even though the scenario mirrors common problems in prac-
tice[26].Whileourlaterstudyintentionallyvariessomeaspects
of the design to observe whether our solutions generalize to other
tasks, generalizations about our results should be done with care.
3.2 Results
We observed that participants struggle for a long time looking for
relevant information to debug the performance of the configurable
subject system. In fact, no participant was able to finish debugging
thesystemwithin50minutes!Inwhatfollows,wepresenttheinfor-
mation needs that participants had, the process that they followed,
and the barriers that they faced during the debugging process.
RQ1: Information Needs. Table 1 lists the four information needs
that we identified and the number of participants that recogniz-
ably demonstrated each need. We refer to the information needs as
influencingoptions,optionhotspots, cause-effectchain,and user
hotspots. The participants referred to these needs using varying
terms.
When participants faced a non-trivial configuration space, they
all tried to identify the influencingoptions – the option or inter-
action causing the unexpected performance behavior. More specif-
ically,theparticipantstriedtoidentify whichoptions intheprob-
lematic configuration caused the unexpected performance behavior.
Some participants tried locating optionhotspots – the meth-
ods where options affect the performance of the system. More
specifically,theparticipantstriedto locatewherethe effectofthe
problematicconfigurationcouldbeobserved;themethodswhose
execution time increased under the problematic configuration.
When we told participants (a) which options cause the unex-
pected performance behavior (i.e., the influencing options) and
(b)themethodswheretheseoptionsinfluenceperformance(i.e.,the
optionhotspots),allparticipantstriedtracingthe cause-effectchain
–howinfluencingoptionsareusedintheimplementationtodirectly
and indirectly affect the performance of option hotspots. More
specifically,astheparticipants(a)knewwhichoptionswere caus-
ingan unexpected performance behavior and (b) had observed the
effectofthoseoptionsonthesystem’sperformance,theparticipants
triedtofindthe rootcause oftheunexpectedperformancebehavior.
1574On Debugging the Performance of Configurable Software Systems: Developer Needs and Tailored Tool Support ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
Table 1: Information needs, activities, and information sources for debugging the performance of configurable software systems.
Information Need   Description   Frequency   Activities   Frequency   Information Source
Influencing Options  Which options influence the 
performance of the system?19/19 Read options’ documentation 19/19 Global performance-
influence modelsMeasure the performance of numerous configurations 10/19
User Hotspots What are the hotspots under the 
problematic configuration?9/19 Profile the system under the problematic configuration 9/19 CPU Profiling
Option Hotspots Where do options influence the 
performance of the system?10/19 Trace options in the implementation 4/10 Local performance-
influence modelsAnalyze the user hotspots’ source code 6/10
Inspect the user hotspots’ call stacks 6/10
Cause-Effect Chain How are influencing options used 
in the implementation to directly 
and indirectly influence the 
performance of option hotspots?19/19 Analyze the option hotspots source code 19/19 CPU Profiling 
Program SlicingInspect the option hotspots call stacks 12/19
Use a debugger to analyze how the influencing options 
affect the values of the variables used in the option 
hotspots10/19
Manually trace how influencing options are used in the 
implementation to directly and indirectly affect the 
performance of option hotspots19/19
Someparticipantsalsolookedfor userhotspots–themethods
thatspendalongtimeexecutingundertheuser-definedproblematic
configuration. However, as we will discuss in RQ2, these partici-
pantslooked forthis informationtrying tolocate optionhotspots
(i.e., how options might affect the execution time of the expensive
methodsunder the user-defined configuration).
RQ1:Developerslookforinformationto(1)identifyinfluencingop-
tions,(2)locateoptionhotspots,and(3)tracethecause-effectchain
of how options influence performance in the implementation.
RQ2: Process and Activities. Table 1 lists the activities that par-
ticipants performed when looking for relevant information and
thenumberofparticipantsthatperformedeachactivity.Overall,
allparticipants compared theproblematic configurationto thede-
fault configuration, to understand the causes of the unexpected
performance behavior. In particular, the participants compared the
valuesselectedforeachoptionandanalyzedhowthechangeswere
affecting the performance of the system in the implementation.
Whenlookingfortheinfluencingoptions,theparticipantsmainly
readdocumentationandexecutedthesystemundermultiplecon-
figurations,primarily comparing executiontimes.Withtheseap-
proaches, the participants tried to identify which options in the
problematic configuration were causing the unexpected behavior.
Whenlookingforoptionhotspots,theparticipantsmainly pro-
filedthesystemundertheproblematicconfiguration,andanalyzed
thecallstacks andsourcecodeofhotspots,tryingto locatethemeth-
odswhereoptionsmight be affecting the performance of hotspots.
Whenlookingforthecause-effectchain,someparticipantsan-
alyzedtheoptionhotspots’ sourcecode ,whereasothersusedade-
bugger; trying to understand howthe influencing options are used
intheimplementationtoaffecttheperformanceofoptionhotspots.
Severalparticipantsalso compared thehotspots’ callstacks under
theproblematicanddefaultconfigurations,tryingtounderstand
howtheinfluencingoptionsaffectedhowtheoptionhotspotswerecalled.Ultimately,allparticipantstriedto manuallytrace howthein-
fluencingoptionswerebeingusedintheimplementationtodirectly
and indirectly affect the performance of the option hotspots.
Whileidentifyingtheinfluencingoptionsandlocatingtheop-
tion hotspots is needed to trace the cause-effect chain, the order
inwhichthefirsttwopiecesofinformationwasacquireddidnot
affectthedebuggingprocess.Forinstance,nineparticipantsstarted
looking for influencing options, but gave up trying after a while.
Then, the participants looked for and were able to identify user
hotspots. Six of these participants subsequently started looking for
option hotspots(i.e., how options mightaffect the executiontime
of the expensive methods under the user-defined configuration).
RQ2:Overall,developerscomparetheproblematicconfigurationto
anon-problematicbaselineconfigurationtounderstandthecauses
of an unexpected performance behavior. Initially, developers com-
pareexecutiontimestoidentifyinfluencingoptions,andanalyze
call stacks and source code to locate option hotspots. These two
piecesofinformationarenecessarytotracethecause-effectchainof
howinfluencingoptionsareusedintheimplementationtodirectly
and indirectly influence the performance of option hotspots.
RQ3: Barriers. Our participants struggled for a long time trying
tofindrelevantinformationtodebughowoptionsinfluencetheper-
formanceofthesystemintheimplementation.Mostparticipants
discussedthe “tediousandmanual” processofexecutingmultiple
configurations when looking for influencing options. For instance,
only10outofthe19participantsidentifiedtheinfluencingoptions.
Whilewe toldparticipantsthe system’sexecutiontime underany
configurationthattheywanted,severalparticipantsmentionedthat
finding the problematic option would have “taken me hours.”
Mostparticipantsalsomentionedthestruggletolocateoption
hotspots. In fact, no participant found any option hotspot! Several
participants mentioned that locatingthese methods is challenging
since options are not typically directly used in expensive methods.
1575ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Miguel Velez, Pooyan Jamshidi, Norbert Siegmund, Sven Apel, and Christian Kästner
The participants struggled the most when trying to trace the
cause-effect chain. In fact, no participant could establish the cause-
effect chain, even when our task consisted of tracing a singleinflu-
encing option and we explicitly told participants the influencing
optionandtheoptionhotspotstheyneededtoanalyze.Mostpartic-
ipantsmentionedthatmanuallytracingevenoneoptionthrough
a relatively small system is “error-prone.” Additionally, some partic-
ipants discussed that identifying differences in the option hotspots’
call stacks was difficult for determining whether the influencing
optionswereaffectinghowtheoptionhotspotswerecalled.Asmen-
tioned by several participants: Variables used in option hotspots
are often a “result of several computations” involving influencing
options.Sincetheinfluencingoptionsareusedinvariouspartsof
the system, “tracing which paths to follow is very challenging.”
RQ3: Developers struggle for a substantial amount of time looking
for relevant information to identify influencing options, locate
option hotspots, and trace the cause-effect chain.
4 SUPPORTING INFORMATION NEEDS
We aim to support developers in identifying influencing options,
locatingoptionhotspots,andtracingthecause-effectchain.Tothis
end, we design information providers , adapting information sources ,
tosupporttheaboveneeds.Weimplementthedesignedinformation
providersinatailoredandcohesiveprototypecalled GLIMPS [73],
which can assist developers to debug the performance of config-
urablesoftwaresystems.Table1showswhichinformationneedsare
supportedbytheinformationsourcesglobalandlocalperformance-
influencemodels,CPUprofiling,andprogramslicingthatweadapt
for designing information providers.
4.1 Identifying Influencing Options
Tohelpdevelopersidentifytheinfluencingoptionsthatcausean
unexpectedperformancebehavior,weselectglobalperformance-
influence models [ 24,38,64,71,72,76], which describe a system’s
performanceintermsofitsoptionsandtheirinteractions.Forin-
stance, the model 4 .6+54 .7·Duplicates ·Transactions +8.9·
Evict+3.5·Temporary explains the influence of Duplicates,
Transactions, Evict, and Temporary, and their interactions on
the performance of Berkeley DB.
Weadaptthisinformationsourcetodesignan informationprovider
that shows developers influencingoptions; specifically, which and
howdifferences betweenconfigurations(e.g.,aproblematicanda
non-problematic configuration) influence a system’s performance.
In our implementation, this information provider highlights the
differences in the values of options selected between two config-
urations,andshowstheinfluencing optionsbetweentheconfigu-
rations. If changes between the configurations are not shown, then
the changes do not influence the performance of the system.1
Global performance-influence models are typically built by mea-
suringexecutiontimeunderdifferentconfigurations[ 64].Themod-
elscanbebuiltusingwhite-boxtechniques[ 71,72,76],machine-
learning approaches [ 20,22–24,35], or a brute-force approach.
1Anyperformance-influencemodelisshownrelativetooneconfiguration(e.g.,the
default configuration), which explains the impact of changes to that configuration.
In our tool, developers can select that one configuration.
Figure 3: Our tool highlights differences in the options selected
between two configurations, and shows the influencing options of
the changes from one configuration to ( /trianglerightsld) another configuration.
Details on these techniques are beyond the scope of this paper.
In our implementation, we generate the models using white-box
techniques,astheseapproachesfirstgeneratelocalperformance-
influence models (which our tool also uses) to obtain the global
model for the system [71, 72, 76].
Example. Figure3showsascreenshotofourtoolhighlightingthe
differencesoftheoptionsselectedbetweentwoconfigurations(e.g.,
anon-problematicandproblematicconfigurations).Ourtoolshows
theinfluencing optionsbetweenthesetwo configurations.Forin-
stance,changingbothoptionsDuplicatesandTransactionsfrom
falsetotrueresultsinaninteractionthatincreasedtheexecution
time by 54 .7 seconds. Based on this information, most develop-
ers would consider Duplicates and Transactions as influencing
options that are causing an unexpected performance behavior.
Note that individual changes to Duplicates and Transactions
didnotinfluencetheperformanceofthesystem;onlythe interac-
tionincreased the execution time. Additionally, any other changes
between the configurations– Replicated – do not influence the
performance of the system. Likewise, the influence of Temporary
is not shown, as both configurations selected the same value.
4.2 Locating Option Hotspots
After helping developers identify the influencing options, we help
developers locate the option hotspots where these options cause
anunexpectedperformancebehavior.Tothisend,weselectlocal
performance-influencemodels[ 71,72,76].Analogoustohowglobal
performance-influence models describe the influence of options
andinteractions ona system’sperformance, localmodels describe
the influence of options on the performance of individual methods .
Hence, local models indicate whereoptions affect the performance
in the implementation [ 71,72,76]. For instance, the local model
ofamethod0 .9+42 .9·Duplicates ·Transactions explainsthe
influenceof DuplicatesandTransactionsontheperformance
of the specific method, rather than the entire system.
We adapt this information source to design another informa-
tion provider that shows developers option hotspots; specifically,
whereandbyhow much optionsinfluence theperformanceof the
system. In our implementation, this information provider shows
(a) themethodswhose performance is influenced by changes made
1576On Debugging the Performance of Configurable Software Systems: Developer Needs and Tailored Tool Support ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
Figure 4: Our tool shows option hotspots affected by influencing
options, as well as the influence on performance in each method.
between configurations (e.g., a problematic and a non-problematic
configuration)and(b)the influence ofthechangesoneachmethod’s
performance.2
Localperformance-influencemodelsareusuallybuiltwithwhite-
box approaches as by-products of global models [ 71,72,76]. In our
implementation, we generate local models using these approaches.
Example. Figure 4 shows as screenshot of our tool indicating
the optionhotspots where the influencing options Duplicates and
Transactionsaffectthesystem’sperformance.Notethatthein-
fluence on all methods equals the influence in the entire system
(seeFigure3).Basedonthisinformation,mostdeveloperswould
consider Cursor.put as an option hotspot; the location where the
effectof the influencing options is observed.
4.3 Tracing the Cause-Effect Chain
Afterhelpingdevelopersidentifytheinfluencingoptionsandlocate
theoptionhotspots,wehelpdeveloperstracethecause-effectchain.
To this end, we select CPU profiling and program slicing.
4.3.1 CPU Profiling. WeselectCPUprofilingtocollectthehotspot
view of the problematic configuration and a non-problematic con-
figuration.Thehotspotviewistheinverseofacalltree:Alistof
allmethodssortedbytheirtotalexecutiontime,cumulatedfrom
all different call stacks, and with back traces that show how the
methods were called.
We adapt this information source to design another informa-
tion provider that helps developers trace the cause-effect chain;
specifically, comparethehotspotviewoftwoconfigurations(e.g.,
a non-problematic and a problematic configuration) to help de-
velopers determine whether the influencing options affecthow
option hotspots are called. In our implementation, this information
provider highlights differences in the option hotspots’ execution
time and call stacks.3
CPUprofilescanbecollectedwithmostoff-the-shelfprofilers.
White-box approaches that build global and local performance-
influence models collect these profiles [ 71,72,76]. In our imple-
mentation, we use the CPU profiles collected by these approaches.
Example. Figure5showsascreenshotofourtool,whichhelpsde-
velopers trace the cause-effect chain by highlighting differences in
the option hotspots’ execution time and call stacks based on the in-
fluencingoptionsDuplicatesandTransactions.Forinstance,the
changes increased Cursor.put ’s execution time, but did not affect
howthemethodwascalled.Bycontrast, FileManager.read isonly
executedundertheproblematicconfiguration.Thisinformationcan
2Our tool also allows developers to select a single configuration to analyze individual
local performance-influence models.
3Our tool also allows developers to analyze the CPU profile of one configuration.
Figure 5: Our tool helps developers trace the cause-effect chain
by highlighting the differences in the option hotspots’ execution
time and call stacks affected by influencing options. While the
call stacks of Cursor.put are the same under both configurations,
FileManager.read is only called under the second configuration.
Main.main(…)
Cursor.put(…)
Main.init(…)Database.init(…)
def init(Database db) 
  Database. checkForNullParam (db.name, "dbName" ); 
  Log.msg(Level.INFO, "db " + db.name + " open"); 
  ... 
  if(db.replicated) 
    configReplicated (...); 
  ... 
  this.cacheMode = db.cacheMode; 
  this.commit = db.trans ? true : false; 
  this.sync = db.dups ? true : false; 
  if(db.evict) 
    Evictor. init(db.evictorThreads); 
  ...
Figure 6: Our tool helps developers trace the cause-effect chain
by displaying a method-level dependence graph from the method
where the influencing options are first loaded into the system
(green box) to and option hotspot (red box). Other relevant meth-
ods are shown in brown boxes. When clicking on a box, GLIMPS
opensthefilewiththemethodandhighlightsthestatementsofthe
slice. The position of the nodes in the graph (left to right and top
to bottom) does not represent the order of execution of methods.
helpdevelopersunderstandhowtheinfluencingoptionsareused
in the implementation to affect the option hotspots’s performance.
4.3.2 Program Slicing. Weselectprogramslicing[ 40,77,80,86];
anapproachtocomputerelevantfragmentsofasystembasedon
a criterion. Several debugging tools have been implemented on
top of program slicers [ 17,37,42,80] to help developers narrow
down relevant parts of a system where developers should focus
their debugging efforts.
We adapt this information source to design another informa-
tion provider that helps developers trace the cause-effect chain;
specifically, tracking how influencing options are used in the imple-
mentation todirectlyandindirectly influence theperformanceof
option hotspots. In our implementation, this information provider
slices (chops) a system from where influencing options are first
loaded into the system to the option hotspots, and shows (a) a
method-leveldependencegraph and(b)highlightedstatements ofthe
slice in the source code.
Example. Figure6showsascreenshotofourtool,whichhelps
developers trace the cause-effect chain by showing a method-level
1577ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Miguel Velez, Pooyan Jamshidi, Norbert Siegmund, Sven Apel, and Christian Kästner
dependence graph from the mainmethod, in which the influenc-
ing options Duplicates and Transactions are first loaded into
the system, to the option hotspot Cursor.put . The graph can help
developerstrackdependencesacrossmethodsinthesystem.When
clicking on a method on the graph, our implementation opens the
file with the method and highlights the statements in the slice,
suchasinFigure6.Thehighlightedstatementscanhelpdevelopers
trace the cause-effect chain by tracking how influencing options
are used in the implementation to directly and indirectly cause an
unexpected performance behavior in option hotspots.
4.4 Implementation
WeimplementedtheinformationprovidersinaVisualStudioCode
extension called GLIMPS [73]. Our prototype adapts global and
local performance-influencemodels, CPU profiles, anda program
slicer. The first three items are collected prior to debugging, using
aninfrastructurewheredevelopersconfigureandrunthesystem.
Subsequently,developersuse GLIMPS toidentifyinfluencingop-
tions, locate option hotspots, and trace the cause-effect chain.
GLIMPS isagnostictotheinformationsourcesusedtoadaptand
implementinformationproviders.Infact, GLIMPS isentirelybuilt
on existing infrastructure of information sources for global and
localperformance-influencemodeling,CPUprofiling,andprogram
slicing. Thenovelty to GLIMPS is inthedesignandintegration of
information providers , from multiple information sources , into aco-
hesiveinfrastructure and user interface, which can help developers
debug the performance of configurable software systems.
Our implementation uses Comprex [ 72] to build the global and
localperformance-influencemodelsandusesJProfiler[ 15]tocollect
the CPU profiles.
Ideally,wewouldslicetheprogramdynamically,aswearean-
alyzing a system’s dynamic behavior and to avoid approximations
in the results. However, after exploring various dynamic and static
slicing research tools, we settled on the state-of-the-art static slicer
providedbyJOANA[ 19],asitisthemostmatureoption.Ourimple-
mentationusesJOANAtoslicethesystemfrominfluencingoptions
tooptionhotspots,usingafixed-pointchopperalgorithm,which
first computes a backward slice from the option hotspots, and then
computes a forward slice, on the backward slice, from the influenc-
ing options [ 18]. For scalability and to reduce approximations, we
modified JOANA to consider code coverage under the problematic
and a non-problematic configurations.
5 EVALUATING USEFULNESS OF
INFORMATION PROVIDERS
Weevaluatetheusefulness ofourdesignedinformationproviders
tohelpdevelopersdebugtheperformanceofconfigurablesoftware
systems. Specifically, we answer the following research question:
RQ4:Towhatextentdothedesignedinformationproviders
helpdevelopersdebugtheperformanceofconfigurablesoft-
ware systems?
Weanswerthisresearchquestionwithtwouserstudiesusingdif-
ferent designs. We first evaluate the extent that our designed infor-
mation providers support the information needs that we identified
inourexploratorystudy.Tothisend,weconducta validation study,in which we ask the participants of our exploratory study to debug
acomparable unexpected performance behavior using GLIMPS
on the same subject system (Sec 5.1). Afterwards, we replicate the
study,intentionally varyingsomeaspectsofthedesigns(theoretical
replication[ 34,63]),toevaluatetowhichextentourinformation
providersgeneralizeforamorecomplextaskwithaninteraction
in a larger system. Specifically, we conduct a confirmatory study,
in which we aska new set of participants to debug a more complex
taskon amore complex subject system (Sec 5.2). The validation and
confirmatory studies, together, provide evidence that our informa-
tion providers help developers debug the performance of complex
configurablesoftwaresystems becausetheinformationproviders
supportthe information needs that developers have in this process.
5.1 Validating Usefulness of Information
Providers
We first conducted a validation study to evaluate the extent that
the designed information providers support the information needs
that we identified in our exploratory study.
5.1.1 Method
Studydesign. Weinvitedtheparticipantsfromourexploratory
study,after5months,tosolveanotherprobleminthesamesystem,
butnowwiththehelpofourinformationproviders.Thisdesigncan
be considered as a within-subject study, where subjects perform
tasksbothinthecontrolandinthetreatmentcondition:Specifically,
weconsiderourexploratorystudyasthe controlcondition,inwhich
participantsdebuggedasystem withoutGLIMPS,andconsiderthe
new study as the treatment condition, in which participants de-
bug acomparable performance issue for 50 minutes in the same
subject system with GLIMPS. Similar to the exploratory study, we
use think-aloud protocol [ 31] to identify whether our information
providersactuallysupporttheinformationneedsthatdevelopers
have when debugging the performance of the subject system.
Prior to the task, participants worked on a warm-up task for 20
minutes using GLIMPS. We tested the time for the warm-up task,
as well as GLIMPS’s design and implementation in a pilot study
with 4 graduate students from our personal network.
Afterthetask,weconductedabriefsemi-structuredinterview
to discuss the participants’ experience in debugging the system, as
well as the usefulness of the information providers, and to contrast
their experience to debugging without the information providers.
Due to the COVID-19 pandemic, we conducted the studies re-
motely over Zoom.Participants used VisualStudio Code through
their preferred Web browser. The IDE was running on a remote
serverandwasconfiguredwith GLIMPS.Weaskedparticipantsto
share their screen. With the participants’ permission, we recorded
audio and video of the sessions for subsequent analysis.
Taskandsubjectsystem. Wepreparedacomparable, butdifferent ,
debugging task to the task in our exploratory study. Similar to the
exploratorystudy,thetaskinvolvedauser-definedconfigurationin
Density Converter that spends an excessive amount of time execut-
ing.Weintroducedabugcausedbytheincorrectimplementationof
one option (the system was using a larger scale of the input image
insteadofusingafraction).Participantswereaskedtoidentifyand
explainwhichandhowoptionscausedtheunexpectedperformance
1578On Debugging the Performance of Configurable Software Systems: Developer Needs and Tailored Tool Support ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
behavior.Incontrasttotheexploratorystudy,theuser-definedcon-
figuration, bug, and problematic option, were different.
Participants. Weinvitedtheparticipantsfromourexploratory
studytoworkonourtask.Afterconductingthestudywith 8par-
ticipants,weobserveda massiveeffectsize betweendebuggingwith
andwithoutourinformationproviders(correctlydebuggingwithin
19 minutes compared to failing after 50 minutes, see Sec. 5.1.2).
Hence, we did not invite the remaining participants.
Analysis. We analyzed and compared transcripts of the audio
andvideorecordingsoftheexploratoryandvalidationstudiesto
measure the time participants spend working on the task and their
success rates. Based on our exploratory study, participants were
required to identify influencing options, locate option hotspots,
and trace the cause-effect chain to correctly debug the system. We
also analyzed the interviews using standard qualitative research
methods[ 61].Thefirstauthorconductedthestudyandanalyzed
thesessionsindependently,summarizingobservations,discussions,
and trends during the task and interviews. All authors met weekly
to discuss the observations.
ThreatstoValidityandCredibility. Weinvitedthesamepartic-
ipants and use the same subject system as in our exploratory study.
Such a design might only validate the information needs when de-
bugging performance in the selected subject system. Additionally,
the exploratory and validation studies were conducted 5 months
apart, which might result in learning effects that help participants
in the latter study. Furthermore, there is the threat that the task in
thevalidationstudyissimpler.Whileourlaterstudyvariesthese
aspects to observe whether our solutions generalize to other tasks,
generalizations about our results should be done with care.
5.1.2 Results
RQ4: Validating Usefulness of Information Providers. Figure 7
showsthetimethateachparticipantspentlookingforeachpieceof
informationwhiledebuggingtheperformanceof DensityConverter
with(treatment)andwithout(control) GLIMPS.Overall,allpartici-
pantswhousedourinformationprovidersidentifiedtheinfluencing
options, located option hotspots, and traced the cause-effect chain,
and correctly explained the root cause of the performance issue in
less than 19 minutes. By contrast, the 8 participants could debug
theunexpected behaviorwithout ourinformationprovidersin 50
minutes, when they struggled to find relevant information.4
All8participantswhousedourinformationprovidersidentified
the influencing options and located the option hotspots in a few
minutes.Afterwards,allparticipants tracedthecause-effectchain
and explained how the influencing options caused the unexpected
performance behavior in the option hotspots.
Whenthese8participantsdidnotuseourinformationproviders,
noparticipantfoundasinglepieceofinformationinthesametime-
frame as they did when using our information providers. In fact,
4Wedidnotconductastatisticalsignificancetest,sincecomparingcompletionrates
is obvious: All participants correctly debugged with our tool, but no participants
correctly debugged without our tool; comparing completion times cannot be done
since nobody completed the task without our tool.30’ 35’ 45’ 05’ 10’ 20’ 25’ 15’ 40’ 50’Influencing Options Option Hotspots Cause-Effect Chain
       Timeout
              Found information        Did not find information
Treatment - Used GLIMPS
Control - Did not use GLIMPSSystem: Density Converter
Figure 7: Time looking for each piece of information when
debugging performance with and without GLIMPS. The first 8
participants who did not use GLIMPS are the same participants
who used our tool. The data for the other participants who did not
use GLIMPS is included for reference.
duringa25-minutewindow,only3participantsfoundtheinfluenc-
ing options, and no participant foundany option hotspots. Further-
more,asdescribedinourexploratorystudy,evenwhenwe explicitly
toldparticipants (a) the one influencing option that was causing
the unexpected performance behavior and (b) the option hotspots
whose execution times drastically increased as a result of the prob-
lematicoption,noparticipantcouldtracethecause-effectchainand
find the root cause of the unexpected behavior within 25 minutes.
After completing the task, the participants discussed how the
informationprovidershelpedthemdebugtheperformanceofthe
system, and contrasted their experience to debugging without our
tool. All participants mentioned that the information providers
helpedthemobtainrelevantinformationfordebugging.Thecon-
sensus was that the information providers “helped me focus on the
relevant parts of the system” to debug the unexpected performance
behavior.The participantscontrasted thisexperienceto thestrug-
glesthattheyfacedwhendebuggingwithoutourtool.Inparticular,
some participants remembered “being lost” on what methods to
follow or knowing “which parts of the program are relevant.”
RQ4: The validation study provides evidence that the designed
informationproviderssupporttheinformationneedsthatweidenti-
fiedinourexploratorystudy.Specifically,theinformationproviders
supportdevelopers’needsto(a)identifyinfluencingoptions,(b)lo-
cate option hotspots, and (c) trace the cause-effect chain.
5.2 Confirming Usefulness of Information
Providers
Aftervalidatingthatourinformationproviderssupporttheinfor-
mationneedsthatweidentified,weconducteda confirmatory study
to evaluate the extent that the information providers can poten-
tiallygeneralizetosupporttheinformationneedsofdebuggingthe
performance of complex configurable software systems.
1579ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Miguel Velez, Pooyan Jamshidi, Norbert Siegmund, Sven Apel, and Christian Kästner
5.2.1 Method
Studydesign. Wereplicatedthevalidationstudy,intentionally
varyingsome aspects of the designs: We used a between-subject
designwhere we ask a new set of participants to debug a more
complex task on amore complex subject system , all working on the
same task but using different tool support . With these variations,
we evaluate that the results and massive effect size in our previous
studiesarenotdueto,forexample,asimplertaskorlearningeffects,
butrather,thattheinformationprovidershelpdevelopersdebug
theperformanceofcomplexconfigurablesoftwaresystems, because
the information providers support the needs that developers have
in this process.
As in our prior study, we conducted the confirmatory study
using a think-aloud protocol [ 31], to compare how two new sets
ofparticipantsdebugtheperformanceofacomplexconfigurable
software system using different tool support in 60 minutes. The
treatment group used GLIMPS, while the control group used a
simple plugin, which profiles and provides the execution time of
thesystemunderanyconfiguration.Thisinformationisthesame
that we gave participants in our exploratory study using a Wizard
ofOzapproach.Forthisconfirmatorystudy,however,wedidnot
usea Wizardof Ozapproach,as wewanted bothgroups toaccess
information for debugging using a tool and the same IDE.
Similar to our prior study, participants worked on a warm-up
taskfor20minutesusingeither GLIMPS orthesimplepluginto
learn how to use the information providers or the components
that provided performance behavior information, respectively. We
tested the simple plugin’s design and implementation in a pilot
study with 4 graduate students from our personal network.
As in our prior study, we conducted a brief semi-structured
interview,afterthetask,todiscusstheparticipants’experiencein
debuggingthesystem.Inparticular,weaskedparticipantsinthe
treatment group about the usefulness of the information providers
and whether there was additional information that they would like
to have in the debugging process. Similarly, we asked participants
in the control group for the information that they would like to
have when debugging the performance of configurable software
systems.
Due to the COVID-19 pandemic, we conducted the studies re-
motely over Zoom.Participants used VisualStudio Code through
theirpreferredWebbrowser,whichwasrunningonaremoteserver
andwasconfiguredwith GLIMPS andthesimpleplugin.Weasked
participants to share their screen. With the participants’ permis-
sion,werecordedaudioandvideoofthesessionsforsubsequent
analysis.
Task and subject system. We prepared a more complex perfor-
mancedebuggingtaskforamorecomplexconfigurablesoftware
system than the task and subject system in our exploratory and
validationstudies.Similartotheprior studies,thetaskinvolveda
user-definedconfigurationthatspendsanexcessiveamountoftime
executing.Participantswereaskedtoidentifyandexplainwhich
and how options caused the unexpected performance behavior. In
contrasttothepreviousstudies,weintroducedabugcausedbythe
incorrect implementation of an interactionof two options (The sys-
tem spenta long timeinserting duplicate datausing transactions).
We selected Berkeley DB as the subject system for the followingreasons: (1) the system is implemented in Java, is open source, and
is more complex than Density Converter (over 150K SLOC and over
30 binary and non-binary options) and (2) the system has a com-
plexperformancebehavior(executiontimerangesfromacouple
of seconds to a few minutes, depending on the configuration).
Participants. We recruited 12 graduate students, independent of
ourexploratoryandvalidationstudies,withextensiveexperience
analyzing the performance of configurable Java systems.
When determining the number of participants for the control
group,wemadesomeethicalconsiderations,whilealsoensuring
thatweobtainreliableresults.Inourexploratorystudy,weobserved
19experienced researchersandprofessionalsoftwareengineerswho
could not debug the performance of a medium-sized system with a
performancebugcausedbya singleoption within50minutes(see
Figure 7). With Berkeley DB , we want to observe how participants
debug the performance of a more complex system ; a significantly
larger system, in terms of SLOC and configuration space size, in
whichtheunexpectedbehavioriscausedbyan interactionoftwo
options.Basedon(a)thefactthatwehave strongempiricalevidence
that debugging the performance of configurable software systems
without relevant information is frustrating and is highly likely
to not be completed under 60 minutes and (b) the massive effect
sizeinourvalidationstudybetweendebuggingwithandwithout
our information providers, we decided to minimize the number of
participantsthatweexpecttostruggleandfailtocompletethetask,
while stillhaving areasonable number participants in thecontrol
group.
Ultimately, we randomly assigned 4 out of the 12 participants to
thecontrolgroup,makingsuretobalancethegroupsintermsof
the participants’ debugging experience: The median programming
experience for both groups is 6 years, a median of 3 .5 years in Java,
a median of 2 .2 years of performance analysis experience, and a
median of 2 .7 years working with configurable software systems.
Analysis. We analyzed transcripts of the audio and video record-
ingstomeasurethetimeparticipantsspendworkingonthetaskand
theirsuccessrates.Basedonourexploratoryandvalidationstudies,
participantsneededtoidentifyinfluencingoptions,locateoption
hotspots, and trace the cause-effect chain to successfully debug the
system. Additionally, we analyzed the interviews using standard
qualitativeresearchmethods[ 61].Thefirstauthorconductedthe
studyandanalyzedthesessionsindependently,summarizingob-
servations, discussions, and trends during the debugging task and
the interviews. All authors met weekly to discuss the observations.
ThreatstoValidityandCredibility. Whileweaimedtoincrease
the complexity of the performance debugging task, readers should
be careful when generalizing our results to other complex systems.
Our control group consisted of 4 participants. As argued pre-
viously,wedidnotrecruitmoreparticipantsduetothestruggles
thatweobservedinourexploratorystudyonasimplersystemand
the massive effect size in our validation study between debugging
with and without our information providers. Nevertheless, readers
should be careful when generalizing our results.
WhilethecontrolgrouphadaccesstotheIDE’sdebuggerand
usedasimpleplugin,wemightobtaindifferentresultsifthepar-
ticipants had used other debugging tools and techniques.
1580On Debugging the Performance of Configurable Software Systems: Developer Needs and Tailored Tool Support ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
Influencing Options Option Hotspots Cause-Effect Chain
       Timeout
            Found information        Did not find information
30’ 35’ 45’ 05’ 10’ 20’ 25’ 15’ 40’ 50’ 55’ 60’Treatment - Used GLIMPS
Control - Used simple pluginSystem: Berkeley DB
Figure 8: Time looking for each piece of information when
debugging performance with different tool support.
5.2.2 Results
RQ4: Confirming Usefulness of Information Providers. Figure 8
shows the time each participant spent looking for each piece of
information while debugging the performance of Berkeley DB with
GLIMPS (treatment) and the simple plugin (control). Similar to
our validation study, all participants who used our information
providers identified the influencing options, located the option
hotspots, and traced the cause-effect chain in less than 25 min-
utes. By contrast, the participants who did not use our information
providersstruggledfor60minutesandcouldnotdebugthesystem.5
While working on the task, we observed the participants in the
treatmentgrouplookingforthesameinformationasinTable1and
using our information providers similarly to the participants in the
validationstudy tofind information todebug thesubjectsystem.
Likewise, the participants in the control group struggled while
performingthesameactivitiesasthoselistedinTable1whentrying
to identify the influencing options and locate the option hotspots.
After working on the task, all participants discussed their ex-
perience in debugging the performance of the system using tool
support.Similartothediscussioninourvalidationstudy,allpar-
ticipantsinthetreatmentgroupcommentedhowtheinformation
providershelpedthemidentifyinfluencingoptions,locateoption
hotspots,andtracethecause-effectchain.Likewise,theparticipants
whousedthesimpleplugindescribedsimilarstrugglesandbarriers
as those mentioned in our exploratory study. All participants in
this group mentioned that identifying the influencing options that
causetheexpectedbehavioris “difficult” andlocatingtheoption
hotspots is “challenging.” However, none of the participants in this
group commentedon tracingthe cause-effectchain, asthey never
got to that point in the debugging process.
RQ4: The confirmatory study provides evidence that the designed
informationprovidershelpdevelopersdebugtheperformanceof
complex configurable software systems because the information
providers support the needs that developers have in this process.
5Again, we did not conduct a statistical significance test, since comparing completion
rates is obvious: All participants in the treatment group correctly debugged the
system, but no participant in the control group did; comparing completion times
cannot be done since nobody in the control group completed the task.6 CONCLUSION
Weidentifiedtheinformationneeds– influencingoptions,option
hotspots,and cause-effectchain–thatdevelopershavewhende-
bugging the performance of configurable software systems. Sub-
sequently, we designed and implemented information providers,
adapted from global and local performance-influence models, CPU
profiling,andprogramslicing,thatsupporttheaboveneeds.Two
user studies, with a total of 20 developers, validate and confirm
that our designed information providers help developers debug the
performance of complex configurable software systems.
7 ACKNOWLEDGMENTS
We want to thank James Herbsleb, for his guidance on conduct-
ingaWizardofOzexperiment,ThomasLaToza,forhisadviceon
howtoanalyzeandcodesessions,andRohanPadhye,JanetSieg-
mund, and Bogdan Vasilescu, for their feedback on the design of
ourconfirmatoryuserstudy.Thisworkwassupportedinpartby
theNSF(Awards2007202,2038080,and2107463),NASA(Awards
80NSSC20K1720and521418-SC),theSoftwareEngineeringInsti-
tute, the German Research Foundation (SI 2171/2, SI 2171/3-1, and
AP206/11-1,andGrant389792660aspartofTRR248–CPEC),and
the German Federal Ministry of Education and Research (AgileAI:
01IS19059A and 01IS18026B) by funding the competence center for
Big Data and AI "ScaDS.AI Dresden/Leipzig".
REFERENCES
[1]Iago Abal, Jean Melo, Ştefan Stănciulescu, Claus Brabrand, Márcio Ribeiro, and
Andrzej Wąsowski. 2018. Variability Bugs in Highly Configurable Systems: A
Qualitative Analysis. ACM Trans. Softw. Eng. Methodol. (TOSEM) 26, 3, Article 10
(Jan. 2018), 34 pages.
[2]Andrea Adamoli and Matthias Hauswirth. 2010. Trevis: A Context Tree Visual-
ization and Analysis Framework and Its Use for Classifying Performance Failure
Reports. In Proc. Int’l Symposium Software Visualization (SOFTVIS) (Salt Lake
City, UT, USA). ACM, New York, NY, USA, 73–82.
[3]Hiralal Agrawal and Joseph R Horgan. 1990. Dynamic Program Slicing. ACM
SIGPlan Notices 25, 6 (1990), 246–256.
[4]Mohammad Mejbah ul Alam, Tongping Liu, Guangming Zeng, and Abdullah
Muzahid. 2017. SyncPerf: Categorizing, Detecting, and Diagnosing Synchro-
nizationPerformanceBugs.In Proc.EuropeanConferenceonComputerSystems
(EuroSys) (Belgrade, Serbia). ACM, New York, NY, USA, 298–313.
[5]DavidAndrzejewski,AnneMulhern,BenLiblit,andXiaojinZhu.2007. Statistical
DebuggingUsingLatentTopicModels.In Proc.EuropeanConf.MachineLearning
(Warsaw, Poland). Springer-Verlag, Berlin, Heidelberg, 6–17.
[6]Cor-Paul Bezemer, J.A. Pouwelse, and Brendan Gregg. 2015. Understanding
SoftwarePerformanceRegressionsUsingDifferentialFlameGraphs.In Int’lConf.
Software Analysis, Evolution, and Reengineering (SANER) (Montreal, Canada).
IEEE, Los Alamitos, CA, USA, 535–539.
[7]James Bornholt and Emina Torlak. 2018. Finding Code That Explodes Under
Symbolic Evaluation. Proc. Int’l Conf. Object-Oriented Programming, Systems,
Languages and Applications (OOPSLA) 2, Article 149 (Oct. 2018), 26 pages.
[8]Silvia Breu, Rahul Premraj, Jonathan Sillito, and Thomas Zimmermann. 2010.
Information Needs in Bug Reports: Improving Cooperation between Developers
andUsers.In Proc.Conf.ComputerSupportedCooperativeWork(CSCW) (Savannah,
GA, USA). ACM, New York, NY, USA, 301–310.
[9]BrianBurg,RichardBailey,AndrewJ.Ko,andMichaelD.Ernst.2013. Interactive
Record/ReplayforWebApplicationDebugging.In Proc.SymposiumUserInterface
Software and Technology (UIST) (St. Andrews, Scotland, United Kingdom). ACM,
New York, NY, USA, 473–484.
[10]Pablo De Oliveira Castro, Chadi Akel, Eric Petit, Mihail Popov, and William
Jalby.2015. CERE:LLVM-BasedCodeletExtractorandREplayerforPiecewise
Benchmarking and Optimization. ACM Trans. Archit. Code Optim. (TACO) 12, 1,
Article 6 (April 2015), 24 pages.
[11]OscarChaparro,JingLu,FiorellaZampetti,LauraMoreno,MassimilianoDiPenta,
AndrianMarcus,GabrieleBavota,andVincentNg.2017. DetectingMissingInfor-
mationinBugDescriptions.In Proc.Europ.SoftwareEngineeringConf.Foundations
of Software Engineering (ESEC/FSE) (Paderborn, Germany). ACM, New York, NY,
USA, 396–407.
1581ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA Miguel Velez, Pooyan Jamshidi, Norbert Siegmund, Sven Apel, and Christian Kästner
[12]Jürgen Cito, Philipp Leitner, Christian Bosshard, Markus Knecht, Genc Mazlami,
and Harald C. Gall. 2018. PerformanceHat: Augmenting Source Code with
Runtime Performance Traces in the IDE. In Proc. Int’l Conf. Software Engineering:
CompanionProceeedings (Gothenburg,Sweden). ACM, NewYork,NY,USA, 41–
44.
[13]Charlie Curtsingerand Emery D.Berger. 2016. COZ: FindingCode that Counts
with Causal Profiling. In USENIX Annual Technical Conference (ATC) . USENIX
Association, Denver, CO, USA, 184–197.
[14]Nils Dahlbäck, Arne Jönsson, and Lars Ahrenberg. 1993. Wizard of Oz Stud-
ies—Why and How. Knowledge-Based Systems 6, 4 (1993), 258–266.
[15]EJ-technologies. 2019. JProfiler 10 . EJ-technologies. Retrieved December 10,
2019 from https://www.ej-technologies.com/products/jprofiler/overview.html
[16]Tayba Farooqui, Tauseef Rana, and Fakeeha Jafari. 2019. Impact of Human-
CenteredDesignProcess(HCDP)onSoftwareDevelopmentProcess.In Int’lConf.
Communication, Computing and Digital systems (C-CODE) (Islamabad, Pakistan).
IEEE, Los Alamitos, CA, USA, 110–114.
[17]Xiaoqin Fu, Haipeng Cai,and Li Li. 2020. Dads: Dynamic Slicing Continuously-
Running Distributed Programs with Budget Constraints. In Proc. Int’l Symp.
Foundations of Software Engineering (FSE) (Virtual Event, USA). ACM, New York,
NY, USA, 1566–1570.
[18]DennisGiffhorn.2011. AdvancedChoppingofSequentialandConcurrentPro-
grams.Software Quality Journal 19, 2 (2011), 239–294.
[19]JürgenGraf,MartinHecker,andMartinMohr.2012. UsingJOANAforInformation
FlowControlinJavaPrograms-APracticalGuide . TechnicalReport24.Karlsruhe
Institute of Technology.
[20]Alexander Grebhahn, Norbert Siegmund, and Sven Apel. 2019. Predict-
ing Performance of Software Configurations: There is no Silver Bullet.
arXiv:1911.12643 [cs.SE]
[21]BrendanGregg.2016. TheFlameGraph. Commun.ACM 59,6(May2016),48–57.
[22]JianmeiGuo,KrzysztofCzarnecki,SvenApel,NorbertSiegmund,andAndrzej
Wąsowski.2013.Variability-AwarePerformancePrediction:AStatisticalLearning
Approach. In Proc. Int’l Conf. Automated Software Engineering (ASE) (Silicon
Valley, CA, USA). ACM, New York, NY, USA, 301–311.
[23]Huong Ha and Hongyu Zhang. 2019. DeepPerf: Performance Prediction for
Configurable Software with Deep Sparse Neural Network. In Proc. Int’l Conf.
SoftwareEngineering(ICSE) (Montreal,Quebec,Canada).IEEE,LosAlamitos,CA,
USA, 1095–1106.
[24]H.HaandH.Zhang.2019. Performance-InfluenceModelforHighlyConfigurable
SoftwarewithFourierLearningandLassoRegression.In Proc.Int’lConf.Software
Maintance and Evolution (ICSME) . IEEE, Los Alamitos, CA, USA, 470–480.
[25]Shi Han, Yingnong Dang, Song Ge, Dongmei Zhang, and Tao Xie. 2012. Perfor-
mance Debugging in the Large via Mining Millions of Stack Traces. In Proc. Int’l
Conf. Software Engineering (ICSE) (Zurich, Switzerland). IEEE, Piscataway, NJ,
USA, 145–155.
[26]Xue Han and Tingting Yu. 2016. An Empirical Study on Performance Bugs
for Highly Configurable Software Systems. In Proc. Int’l Symposium Empirical
Software Engineering and Measurement (ESEM) (Ciudad Real, Spain). ACM, New
York, NY, USA, Article 23, 10 pages.
[27]Xue Han, Tingting Yu, and David Lo. 2018. PerfLearner: Learning from Bug
ReportstoUnderstandandGeneratePerformanceTestFrames.In Proc.Int’lConf.
Automated Software Engineering (ASE) (Montpellier, France). ACM, New York,
NY, USA, 17–28.
[28]Xue Han, Tingting Yu, and Michael Pradel. 2021. ConfProf: White-Box Per-
formance Profiling of Configuration Options. In Proc. Int’l Conf. Performance
Engineering (ICPE) . ACM, New York, NY, USA, 1–8.
[29]Haochen He, Zhouyang Jia, Shanshan Li, Erci Xu, Tingting Yu, Yue Yu, Ji Wang,
and Xiangke Liao. 2020. CP-Detector: Using Configuration-related Performance
PropertiestoExpose PerformanceBugs.In Proc.Int’lConf. AutomatedSoftware
Engineering (ASE) . ACM, New York, NY, USA, 623–634.
[30]Md ShahriarIqbal,Rahul Krishna,Mohammad AliJavidian, BaishakhiRay, and
PooyanJamshidi.2022. Unicorn:ReasoningaboutConfigurableSystemPerfor-
mancethroughthelensofCausality.In Proc.Conf.ComputerSystems(EuroSys)
(Rennes, France). ACM, New York, NY, USA.
[31]Riitta Jääskeläinen. 2010. Think-aloud protocol . John Benjamins Publishing
Amsterdam/Philadelphia, Amsterdam. 371–374 pages.
[32]Guoliang Jin, Linhai Song, Xiaoming Shi, Joel Scherpelz, and Shan Lu. 2012.
UnderstandingandDetectingReal-worldPerformanceBugs.In Proc.Conf.Pro-
grammingLanguageDesignandImplementation(PLDI) (Beijing,China).ACM,
New York, NY, USA, 77–88.
[33]MilanJovic,AndreaAdamoli,andMatthiasHauswirth.2011. CatchMeIfYou
Can: Performance Bug Detection in the Wild. In Proc. Int’l Conf. Object-Oriented
Programming, Systems, Languages and Applications (OOPSLA) (Portland, Oregon,
USA). ACM, New York, NY, USA, 155–170.
[34]Natalia Juristo and Omar S. Gómez. 2011. Replication of Software Engineering
Experiments . Springer Berlin Heidelberg, Berlin, Heidelberg, 60–88.
[35]C. Kaltenecker, A. Grebhahn, N. Siegmund, and S. Apel. 2020. The Interplay
ofSamplingandMachineLearningforSoftwarePerformancePrediction. IEEE
Software37, 4 (2020), 58–66.[36]Christian Kaltenecker, Alexander Grebhahn, Norbert Siegmund, Jianmei Guo,
andSvenApel.2019. Distance-BasedSamplingofSoftwareConfigurationSpaces.
InProc.Int’lConf.SoftwareEngineering(ICSE) (Montreal,Quebec,Canada).IEEE,
Los Alamitos, CA, USA, 21–31.
[37]AndrewJ.KoandBradA.Myers.2004. DesigningtheWhyline:ADebugging
Interface for Asking Questions about Program Behavior. In Proc. Conf Human
Factors in Computing Systems (CHI) (Vienna, Austria). ACM, New York, NY, USA,
151–158.
[38]SergiyKolesnikov,NorbertSiegmund,ChristianKästner,AlexanderGrebhahn,
andSvenApel.2019. TradeoffsinModelingPerformanceofHighlyConfigurable
SoftwareSystems. SoftwareandSystemModeling(SoSyM) 18,3(2019),2265–2283.
[39]Bogdan Korel and Janusz Laski. 1988. Dynamic Program Slicing. Information
processing letters 29, 3 (1988), 155–163.
[40]JensKrinke.2003. BarrierSlicingandChopping.In Int’lWorkshopSourceCode
Analysis and Manipulation (SCAM) . IEEE, Amsterdam, Netherlands, 81–87.
[41]Rahul Krishna,MdShahriar Iqbal,Mohammad AliJavidian, BaishakhiRay, and
PooyanJamshidi.2020. CADET:ASystematicMethodForDebuggingMiscon-
figurations using Counterfactual Reasoning. arXiv:2010.06061 [cs.SE]
[42]T.D.LaTozaandB.A.Myers.2011. VisualizingCallGraphs.In SymposiumVisual
Languages and Human-Centric Computing (VL/HCC) . IEEE, Los Alamitos, CA,
USA, 117–124.
[43]Chi Li, Shu Wang, Henry Hoffmann, and Shan Lu. 2020. Statically Inferring
Performance Properties of Software Configurations. In Proc. European Conf.
Computer Systems (EuroSys) (Heraklion, Greece). ACM, New York, NY, USA,
Article 10, 10 pages.
[44]DingLi,YingjunLyu,JiapingGui,andWilliamG.J.Halfond.2016. Automated
Energy Optimization of HTTP Requests for Mobile Applications. In Proc. Int’l
Conf. Software Engineering (ICSE) (Austin, TX, USA). ACM, New York, NY, USA,
249–260.
[45]Max Lillack, Christian Kästner, and Eric Bodden. 2018. Tracking Load-time
Configuration Options. IEEE Transactions on Software Engineering 44, 12 (12
2018), 1269–1291.
[46]Yepang Liu, Chang Xu, and Shing-Chi Cheung. 2014. Characterizing and Detect-
ing Performance Bugs for Smartphone Applications. In Proc. Int’l Conf. Software
Engineering (ICSE) (Hyderabad, India) (ICSE 2014) . ACM, New York, NY, USA,
1013–1024.
[47]JensMeinicke,Chu-PanWong,ChristianKästner,andGunterSaake.2018. Under-
standing Differences Among Executions with Variational Traces . Technical Report
1807.03837. arXiv.
[48]Jens Meinicke, Chu-PanWong,Christian Kästner, Thomas Thüm,and Gunter
Saake. 2016. On Essential Configuration Complexity: Measuring Interactions in
Highly-configurable Systems. In Proc. Int’l Conf. Automated Software Engineering
(ASE)(Singapore, Singapore). ACM, New York, NY, USA, 483–494.
[49]Jean Melo, Claus Brabrand, and Andrzej Wąsowski. 2016. How Does the Degree
of Variability Affect Bug Finding?. In Proc. Int’l Conf. Software Engineering (ICSE)
(Austin, TX, USA). ACM, New York, NY, USA, 679–690.
[50]JeanMelo,Fabricio BatistaNarcizo,DanWitznerHansen, ClausBrabrand,and
Andrzej Wasowski. 2017. Variability through the Eyes of the Programmer. In
Proc. Int’l Conference Program Comprehension (ICPC) (Buenos Aires, Argentina).
IEEE, Los Alamitos, CA, USA, 34–44.
[51]BradA.Myers,AndrewJ.Ko,ThomasD.LaToza,andYoungSeokYoon.2016. Pro-
grammersAreUsersToo:Human-CenteredMethodsforImprovingProgramming
Tools.Computer 49, 7 (July 2016), 44–52.
[52]Vivek Nair, Tim Menzies, Norbert Siegmund, and Sven Apel. 2017. Using Bad
Learners to Find Good Configurations. In Proc. Europ. Software Engineering Conf.
FoundationsofSoftwareEngineering(ESEC/FSE) (Paderborn,Germany) (ESEC/FSE
2017). ACM, New York, NY, USA, 257–267.
[53]NicholasNethercoteandJulianSeward.2007. Valgrind:AFrameworkforHeavy-
weight Dynamic Binary Instrumentation. In Proc. Conf. Programming Language
DesignandImplementation(PLDI) (SanDiego,CA,USA).ACM,NewYork,NY,
USA, 89–100.
[54]Adrian Nistor, Po-Chun Chang, Cosmin Radoi, and Shan Lu. 2015. Caramel:
Detectingand FixingPerformance ProblemsThat HaveNon-intrusive Fixes.In
Proc.Int’lConf.SoftwareEngineering(ICSE) (Florence,Italy).IEEE,Piscataway,
NJ, USA, 902–912.
[55]Adrian Nistor, Tian Jiang, and Lin Tan. 2013. Discovering, Reporting, and Fixing
PerformanceBugs.In Proc.Int’lConf.MiningSoftwareRepositories (SanFrancisco,
CA, USA). IEEE, Piscataway, NJ, USA, 237–246.
[56]AdrianNistor,LinhaiSong,DarkoMarinov,andShanLu.2013.Toddler:Detecting
PerformanceProblemsviaSimilarMemory-accessPatterns.In Proc.Int’lConf.
SoftwareEngineering(ICSE) (SanFrancisco,CA,USA).IEEE,Piscataway,NJ,USA,
562–571.
[57]Jeho Oh, Don Batory, Margaret Myers, and Norbert Siegmund. 2017. Finding
Near-optimal Configurations in Product Lines by Random Sampling. In Proc.
Europ.SoftwareEngineeringConf.FoundationsofSoftwareEngineering(ESEC/FSE)
(Paderborn, Germany). ACM, New York, NY, USA, 61–71.
[58]J. Park, M. Kim, B. Ray, and D. Bae. 2012. An Empirical Study of Supplementary
Bug Fixes. In Proc. Int’l Conf. Mining Software Repositories (Zurich, Switzerland).
1582On Debugging the Performance of Configurable Software Systems: Developer Needs and Tailored Tool Support ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA
IEEE, Los Alamitos, CA, USA, 40–49.
[59]Chris Parnin and Alessandro Orso. 2011. Are Automated Debugging Techniques
ActuallyHelpingProgrammers?.In Proc.Int’lSymp.SoftwareTestingandAnalysis
(ISSTA)(Toronto, Canada). ACM, New York, NY, USA, 199–209.
[60]Guillaume Pothier, Éric Tanter, and José Piquer. 2007. Scalable Omniscient
Debugging. In Proc. Int’l Conf. Object-Oriented Programming, Systems, Languages
and Applications (OOPSLA) (Montreal, Quebec, Canada). ACM, New York, NY,
USA, 535–552.
[61]Johnny Saldaña. 2015. The Coding Manual for Qualitative Researchers . Sage,
London, England.
[62]J. P. Sandoval Alcocer, F. Beck, and A. Bergel. 2019. Performance Evolution
Matrix:VisualizingPerformanceVariationsAlongSoftwareVersions.In Conf.
Software Visualization (VISSOFT) . IEEE, Los Alamitos, CA, USA, 1–11.
[63]Stefan Schmidt. 2009. Shall we Really do it Again? The Powerful Concept of
Replication is Neglected in the Social Sciences. Review of General Psychology 13,
2 (2009), 90–100.
[64]NorbertSiegmund,AlexanderGrebhahn,SvenApel,andChristianKästner.2015.
Performance-influence Models for Highly Configurable Systems. In Proc. Eu-
rop.SoftwareEngineeringConf.FoundationsofSoftwareEngineering(ESEC/FSE)
(Bergamo, Italy). ACM, New York, NY, USA, 284–294.
[65]Norbert Siegmund, Sergiy S. Kolesnikov, Christian Kästner, Sven Apel, Don
Batory,MarkoRosenmüller,andGunterSaake.2012. PredictingPerformancevia
AutomatedFeature-interactionDetection.In Proc.Int’lConf.SoftwareEngineering
(ICSE)(Zurich, Switzerland). IEEE, Piscataway, NJ, USA, 167–177.
[66]NorbertSiegmund,MarkoRosenmüller,MartinKuhlemann,ChristianKästner,
Sven Apel, and Gunter Saake. 2012. SPLConqueror: Toward Optimization of
Non-functionalPropertiesinSoftwareProductLines. SoftwareQualityJournal
20, 3-4 (Sept. 2012), 487–517.
[67]LinhaiSongandShanLu.2014.StatisticalDebuggingforReal-WorldPerformance
Problems.In Proc.Int’lConf.Object-OrientedProgramming,Systems,Languages
and Applications (OOPSLA) (Portland, OR, USA). ACM, New York, NY, USA,
561–578.
[68]Linhai Song and Shan Lu. 2017. Performance Diagnosis for Inefficient Loops.
InProc. Int’l Conf. SoftwareEngineering (ICSE) (Buenos Aires, Argentina). IEEE,
Piscataway, NJ, USA, 370–380.
[69]John Toman and Dan Grossman. 2016. Staccato: A Bug Finder for Dynamic
Configuration Updates. In Proc. European Conf. Object-Oriented Programming
(ECOOP). Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik, Dagstuhl, Ger-
many, 1–23.
[70]Jonas Trümper, Jürgen Döllner, and Alexandru Telea. 2013. Multiscale Visual
Comparison of Execution Traces. In Proc. Intl Conf. Program Comprehension
(ICPC)(San Francisco, CA, USA). IEEE, Los Alamitos, CA, USA, 53–62.
[71]Miguel Velez, Pooyan Jamshidi, Florian Sattler, Norbert Siegmund, Sven Apel,
andChristianKästner.2020. ConfigCrusher:TowardsWhite-BoxPerformance
Analysis for Configurable Systems. Autom Softw Eng 27, 3 (2020), 265–300.
[72]Miguel Velez, Pooyan Jamshidi, Norbert Siegmund, Sven Apel, and Christian
Kästner. 2021. White-Box Analysis over Machine Learning: Modeling Perfor-
manceofConfigurableSystems.In Proc.Int’lConf.SoftwareEngineering(ICSE)
(Madrid, Spain). IEEE, Los Alamitos, CA, USA, 1072–1084.
[73]Miguel Velez, Pooyan Jamshidi, Norbert Siegmund, Sven Apel, and Christian
Kästner. 2022. On Debugging the Performance of Configurable Software Sys-
tems: Developer Needs and Tailored Tool Support - Supplementary Material -
https://bit.ly/35HUvl9.
[74]VisualVM. 2020. VisualVM . VisualVM. Retrieved November 24, 2020 from
https://visualvm.github.io/[75]ShuWang,ChiLi,HenryHoffmann,ShanLu,WilliamSentosa,andAchmadImam
Kistijantoro. 2018. Understanding and Auto-Adjusting Performance-Sensitive
Configurations.In Proc.Int’lConf.ArchitecturalSupportforProgrammingLan-
guages and Operating Systems (ASPLOS) (Williamsburg, VA, USA). ACM, New
York, NY, USA, 154–168.
[76]MaxWeber,SvenApel,andNorbertSiegmund.2021. White-BoxPerformance-
InfluenceModels:AProfilingandLearningApproach.In Proc.Int’lConf.Software
Engineering (ICSE) (Madrid, Spain). IEEE, Los Alamitos, CA, USA, 232–233.
[77]Mark Weiser. 1981. Program Slicing. In Proc. Int’l Conf. Software Engineering
(ICSE)(San Diego, CA, USA). IEEE, Piscataway, NJ, USA, 439–449.
[78]Claas Wilke, Sebastian Richly, Sebastian Götz, Christian Piechnick, and Uwe
Amann. 2013. Energy Consumption and Efficiency in Mobile Applications: A
User Feedback Study. In Proc. Int’l Conf. Green Computing and Communications .
IEEE, Los Alamitos, CA, USA, 134–141.
[79]Chu-PanWong,JensMeinicke,LukasLazarek,andChristianKästner.2018. Faster
VariationalExecutionwithTransparentBytecodeTransformation. Proc.Int’lConf.
Object-OrientedProgramming, Systems,LanguagesandApplications(OOPSLA) 2,
Article 117 (Oct. 2018), 30 pages.
[80]BaowenXu,JuQian,XiaofangZhang,ZhongqiangWu,andLinChen.2005. A
Brief Survey of Program Slicing. ACM SIGSOFT Software Engineering Notes 30, 2
(2005), 1–36.
[81]Tianyin Xu, Xinxin Jin, Peng Huang, Yuanyuan Zhou, Shan Lu, Long Jin, and
Shankar Pasupathy. 2016. Early Detection of Configuration Errors to Reduce
Failure Damage. In Proc. Conf.Operating Systems Design and Implementation
(OSDI)(Savannah, GA, USA). USENIX Association, Berkeley, CA, USA, 619–634.
[82]TianyinXu,JiaqiZhang,PengHuang,JingZheng,TianweiSheng,DingYuan,
Yuanyuan Zhou, and Shankar Pasupathy. 2013. Do Not Blame Users for Miscon-
figurations. In Proc. Symp. Operating Systems Principles (Farminton, PA, USA).
ACM, New York, NY, USA, 244–259.
[83]Tingting Yu and Michael Pradel. 2016. SyncProf: Detecting, Localizing, and
OptimizingSynchronizationBottlenecks.In Proc.Int’lSymp.SoftwareTestingand
Analysis (ISSTA) (Saarbrücken, Germany). ACM, New York, NY, USA, 389–400.
[84]Tingting Yu andMichael Pradel. 2018. Pinpointing andRepairing Performance
Bottlenecks in Concurrent Programs. Empirical Softw. Eng. 23, 5 (Oct. 2018),
3034–3071.
[85]Andreas Zeller. 1999. Yesterday, My Program Worked. Today, It Does Not. Why?
SIGSOFT Softw. Eng. Notes 24, 6 (Oct. 1999), 253–267.
[86]Andreas Zeller. 2009. Why Programs Fail: A Guide to Systematic Debugging .
Elsevier, Amsterdam, The Netherlands.
[87]Jiaqi Zhang,Lakshminarayanan Renganarayana,Xiaolan Zhang, NiyuGe, Vas-
anthBala,TianyinXu,andYuanyuanZhou.2014. EnCore:ExploitingSystem
Environment and Correlation Information for Misconfiguration Detection. In
Proc. Int’l Conf. Architectural Support for Programming Languages and Operating
Systems(ASPLOS) (SaltLakeCity,UT,USA).ACM,NewYork,NY,USA,687–700.
[88]Sai Zhang and Michael D. Ernst. 2014. Which Configuration Option Should I
Change?.In Proc.Int’lConf.SoftwareEngineering(ICSE) (Hyderabad,India).ACM,
New York, NY, USA, 152–163.
[89]SaiZhang andMichaelD.Ernst. 2015. Proactive Detection ofInadequateDiag-
nostic Messages for Software Configuration Errors. In Proc. Int’l Symp. Software
TestingandAnalysis(ISSTA) (Baltimore,MD,USA).ACM,NewYork,NY,USA,
12–23.
[90]Yuqing Zhu, Jianxun Liu, Mengying Guo, Yungang Bao, Wenlong Ma, Zhuoyue
Liu, Kunpeng Song, and Yingchun Yang. 2017. BestConfig: Tapping the Per-
formance Potential of Systems via Automatic Configuration Tuning. In Proc.
SymposiumCloudComputing(SoCC) (SantaClara,CA,USA).ACM,NewYork,
NY, USA, 338–350.
1583