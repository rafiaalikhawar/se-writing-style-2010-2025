PyTER : Effective Program Repair for Python Type Errors
Wonseok Oh
Korea University
Republic of Korea
marinelay@korea.ac.krHakjoo Ohâˆ—
Korea University
Republic of Korea
hakjoo_oh@korea.ac.kr
ABSTRACT
We present PyTER , an automated program repair (APR) technique
for Python type errors. Python developers struggle with type error
exceptions that are prevalent and difficult to fix. Despite the impor-
tance, however, automatically repairing type errors in dynamically
typed languages such as Python has received little attention in the
APR community and no existing techniques are readily available
for practical use. PyTER is the first technique that is carefully de-
signed to fix diverse type errors in real-world Python applications.
To this end, we present a novel APR approach that uses dynamic
and static analyses to infer correct and incorrect types of program
variables, and leverage their difference to effectively identify faulty
locations and patch candidates. We evaluated PyTER on 93 type
errors collected from open-source projects. The result shows that
PyTER is able to fix 48.4% of them with a precision of 77.6%.
CCS CONCEPTS
â€¢Software and its engineering â†’Automated static analysis ;
Software testing and debugging .
KEYWORDS
Program Repair, Program Analysis, Debugging
ACM Reference Format:
Wonseok Oh and Hakjoo Oh. 2022. PyTER : Effective Program Repair for
Python Type Errors. In Proceedings of the 30th ACM Joint European Software
Engineering Conference and Symposium on the Foundations of Software Engi-
neering (ESEC/FSE â€™22), November 14â€“18, 2022, Singapore, Singapore. ACM,
New York, NY, USA, 13 pages. https://doi.org/10.1145/3540250.3549130
1 INTRODUCTION
Python has become one of the most popular programming lan-
guages. According to the IEEE Spectrumâ€™s ranking of the top pro-
gramming languages [ 1], Python is clearly the dominant language
used in a wide variety of applications, including web, enterprise,
and embedded domains. In particular, Pythonâ€™s popularity has sky-
rocketed in recent years, driven by its use in artificial intelligence
and data science applications.
âˆ—Corresponding author
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore
Â©2022 Association for Computing Machinery.
ACM ISBN 978-1-4503-9413-0/22/11. . . $15.00
https://doi.org/10.1145/3540250.3549130Table 1: Top 5 runtime exceptions in Python. We counted
the number of StackOverflow posts and GitHub issues (in
the repositories used in Section 4) containing the keyword
â€œ*Errorâ€. Below are the top 5 built-in exceptions (i.e., TypeEr-
ror, AttributeError, ValueError, KeyError, ImportError) and
their relative proportions.
Type Attribute Value Key Import
StackOverflow 31.5% 19.4% 27.8% 8.3% 13.0%
GitHub 29.2% 19.4% 28.2% 12.9% 10.3%
in a day
31.4%more than a day,
less than a week 
19.6%
more than a week,
less than a month 19.6%
more than a month29.4%
Figure 1: Statistics on the time period between reporting
and patching a type error. For bugs in our benchmarks (Sec-
tion 4), it took 82 days on average and about 30% took more
than a month. The worst case took 1,277 days, more than
three years.
As a dynamic language, however, Python suffers from an im-
portant class of run-time errors, namely type error exceptions. In
Python, a type error occurs when an operation is performed on
a value of an unsupported type. For example, applying primitive
arithmetic operations on an integer and a string (e.g., 1+"two" ) is
undefined in Python and hence raises a run-time exception. Python
developers struggle with such type errors. Table 1 shows that they
appear most frequently among all built-in exceptions in Python.
More importantly, type errors are difficult and time-consuming to
fix: (1) Correctly fixing a type error requires not only avoiding the
given fault, but also anticipating other potential risks in advance
(see Section 4.3); (2) In practice, type errors commonly get fixed
weeks or months after they are reported (Figure 1).
PyTER .In this paper, we present PyTER1, the first technique
that can automatically fix Python type errors. Despite the impor-
tance, no techniques or tools are readily available for fixing type
1Python T ype E rror R epairESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore Wonseok Oh and Hakjoo Oh
1def main(x, y, z) :
2if z :
3 return foo(x, z, y)
4if y :
5 return foo(y, x, z)
6return y
7
8def foo(a, b, c) :
9d = b + c
10
11
12 e = a + d # TypeError
13 return a + c + e
(a) Buggy Code1def main(x, y, z) :
2if z :
3 return foo(x, z, y)
4if y :
5 return foo(y, x, z)
6return y
7
8def foo(a, b, c) :
9d = b + c
10 if isinstance(a, str) :
11 a = int(a)
12 e = a + d # Pass
13 return a + c + e
(b) Fixed Code
Figure 2: Example to illustrate how PyTER works
errors in dynamically typed languages such as Python. Instead,
existing work focused on either detecting type errors in dynamic
languages [ 4,21,28,32,50] or repairing compile-time type errors
in statically typed languages [ 8,51]. Also, as our evaluation in
Section 4 implies, domain-unaware APR (automated program re-
pair) techniques [ 33,41,43,47,56] are unlikely to be effective for
real-world type errors.
The key novelty of PyTER is its type-aware APR technique that
leverages type information to boost fault localization and patch
generation. PyTER aims to fix a type error by handling the incorrect
type of a variable with a correct type. To do so, PyTER first collects
candidate program variables from error traces and uses dynamic
and static analyses to infer the incorrect and correct types that
candidate variables may have in erroneous and successful program
executions. The difference of those types is then used to accurately
localize erroneous program locations and to prioritize candidate
patches that are likely to fix the given error correctly.
We prove the effectiveness of PyTER with various type errors
in real Python applications. Since there is no benchmark dedicated
for Python type errors, we created a new benchmark, called Type-
Bugs , that includes 93 type errors collected from 15 open-source
projects. In total, PyTER successfully fixed 48.4% of those bugs
with a precision (#correct patches
#plausible patches) of 77.6%. We also checked that
our type-aware APR technique is essential for the performance;
the baseline of PyTER , which uses a conventional generate-and-
validate approach without our type-aware enhancement, was able
to fix 24.7% of 93 bugs with a precision of 48.9%.
Contributions .Our contributions are summarized as follows:
â€¢We present PyTER , the first technique for fixing diverse type
errors in real-world Python applications. The key technical
contribution is the type-aware APR technique that lever-
ages the different of correct and incorrect types of program
variables to enhance fault localization and patch generation.
â€¢We make that the tool and benchmarks publicly available.2
In particular, we provide a new benchmark for Python type
errors, which consists of 15 programs (2.9-428.8 KLoC) and
93 type errors collected from open-source repositories.
2https://github.com/kupl/PyTER2 OVERVIEW
In this section, we illustrate how PyTER works with an example.
Figure 2(a) shows a buggy program, where a type error may occur
at line 12. Figure 2(b) shows the program fixed by PyTER , where
lines 10 and 11 are added to handle the type error.
PyTER is a test-based repair technique; it assumes that nega-
tive and positive test cases, denoted Tğ‘andTğ‘ƒ, respectively, are
given together with a buggy program. For the example program in
Figure 2(a), suppose the following test cases are given:
Tğ‘={(("0", 1, 1),3),((1, "0", 0),2)},Tğ‘ƒ={((0, 0, 0),0)}.
A negative test, e.g., (("0", 1, 1),3), consists of an error-triggering
input, ("0", 1, 1) , to the entry function ( main ) and the corresponding
expected output, 3, i.e., the return value of main . Note that when the
value of zis 1, it is considered True at line 2 in Python. Therefore,
foois called at line 3 with a string and two integer values being
passed to a,b, and c, respectively. Thus, addition at line 12 is per-
formed on unsupported values (i.e., â€œ0â€+2) and raises a type error
exception. In the second negative test, ((1, "0", 0),2), the value of y
is considered as True in the condition statement at line 4. Thus, foo
is called at line 5 and the same type error exception is raised at line
12. The positive test case, ((0, 0, 0), 0), also consists of an input and
an expected output but is used to specify the functionality of the
program when it is run successfully without any run-time errors.
Step 1: Collecting Candidate Variables .In Python, type er-
rors typically occur when a variable is used with an incorrect type.
Then, developers fix a type error, for example, by converting the
erroneous type of the variable to a proper one. In Figure 2(b), the
patch at lines 10 and 11 changes the type of variable ato integer
when it has the string type. Thus, the first step of PyTER is to collect
such candidate program variables.
We collect candidate variables from the traceback of the type
error exception. A traceback is an error-triggering a call chain that
begins with the entry function and ends with a run-time excep-
tion. Such a call chain is obtained by running the program with
negative test cases. For example, Figure 3 shows the two tracebacks
generated from the negative tests in our running example. Given
the tracebacks in Figure 3, we collect all program variables that
appear in the nodes and edges up to the error location, resulting in
CandVars ={x,y,z,a,b,c,d}for the program in Figure 2(a) (we do
not collect variable ethat is defined after the type error occurs).
1:main(x,y,z)
6:foo(a,b,c)
TypeError3:foo(x, z, y)
12:e = a + d
(a) For input ("0", 1, 1)1:main(x,y,z)
6:foo(a,b,c)
TypeError5:foo(y, x, z)
12:e = a + d
(b) For input (1, "0", 0)
Figure 3: Traceback examples
Step 2: Inferring Negative and Positive Types .The second
step of PyTER is to infer the types of candidate variables. Specif-
ically, we infer both â€œnegative typesâ€ (types that variables havePyTER : Effective Program Repair for Python Type Errors ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore
Negative types Positive types Difference Ranking
x { int, str } { int } { str } 2
y { int, str } { int } { str } 2
z { int } { int }âˆ… 3
a { str } { int } { str, int } 1
b { int } { int }âˆ… 3
c { int } { int }âˆ… 3
d { int } { int }âˆ… 3
Figure 4: Type analysis example
when type errors occur) and â€œpositive typesâ€ (types that variables
have when type errors do not occur). Figure 4 shows the result of
type inference for the program in Figure 2(a). The result shows that
variable a, for example, has the string type in the buggy execution,
but has the integer type in the normal execution.
We compute negative types using a dynamic analysis that ob-
serves variable types while running the program with negative test
inputs. For example, when we execute the example program with
the inputs (â€œ0â€, 1, 1) and (1, â€œ0â€, 0), we find out that variables have
types as shown in the second column of Table 4. To obtain positive
types, we perform both dynamic and static analyses. Running the
program with the positive test input (0, 0, 0) skips the function calls
at line 3 and 5, hence we cannot infer the types of variables a,b,c,
anddusing a dynamic analysis alone. Thus, PyTER makes predic-
tions for those variables using a static analysis specially designed to
infer positive types dominantly used in the program (Section 3.2).
Step 3: Fault Localization .PyTER â€™s fault localization is done
in two stages. We first perform a function-level fault localization
that chooses the function containing the most suspicious candidate
variable. We compute the suspicious scores of candidate variables
by defining a metric to quantify the difference between negative
and positive types. In our example, the most suspicious variable
isabecause its negative types {str}and positive types {int}are
completely different. Thus, we attempt to fix function foofirst,
where variable ais used. Once a function is selected, we identify
the most suspicious line by running an existing spectrum-based
fault localization (SBFL) technique inside the function. We assume
that line 12 is selected for our example program.
We use this two-staged method because existing SBFL is not
accurate enough to localize type errors. For example, when we
apply SBFL based onfailed
failed+passed, where failed andpassed denote
the numbers of failing and passing test cases, respectively, we have
to equally suspect functions main andfoo: lines 3 and 5 of main
and all lines of foohave the same suspicions score. However, it is
not possible to fix the bug by repairing main .
Step 4: Patch Generation .After fault localization, the follow-
ing information is available:
ğ›¿=(foo,12,a,{str},{int}))
which means that the most suspicious function, line, and candi-
date variable are foo, 12, and a, respectively, and the negative and
positive types of aare{str}and{int}, respectively. To fix line 12
of function foo,PyTER uses the standard generate-and-validateapproach with a set of predefined repair templates designed for
type errors and accelerates the procedure by ranking the templates
based on the negative and positive types of the candidate variable.
In the running example, we note that both {str}and{int}are sin-
gleton sets and first try to use a type-casting template that converts
the negative type (str) of the candidate variable ( a) to the positive
type (int), generating the conditional statement at lines 10-12 of
Figure 2(b). This patch is accepted by PyTER as it satisfies all test
cases inTğ‘andTğ‘ƒ.
3PYTER ALGORITHM
In this section, we describe each step of our approach in detail.
Programs .We consider a small language to describe PyTER ,
so that its core idea is generally applicable to other languages.
A program ğ‘ƒâˆˆPgm is a sequence of function declarations, i.e.,
ğ‘ƒ=ğ¹1,ğ¹2,...,ğ¹ğ‘›. A function declaration ğ¹âˆˆFDecl is a tuple
(ğ‘“,ğ‘¥,ğ‘†)of a function name ( ğ‘“), function parameter ( ğ‘¥), and body
statement (ğ‘†). We consider statements and expressions below:
ğ‘†â†’ğ‘¥=ğ¸|returnğ¸|ğ‘†1;ğ‘†2
ğ¸â†’ğ‘›|ğ‘ |ğ‘|ğ‘¥|ğ¸1âŠ•ğ¸2|ğ‘“(ğ¸1,...,ğ¸ğ‘›)
whereğ‘›,ğ‘ , andğ‘are constant values of integer, string, and boolean
types, respectively. We write ğ¹ğ‘’for the entry function, the starting
point ofğ‘ƒ. We assume program variables are uniquely named and
all functions explicitly return a value upon termination. Let Valbe
the set of values that programs manipulate, e.g., integers, strings.
LetâŸ¦ğ‘ƒâŸ§:Valâ†’Valbe the evaluator that takes an input value (i.e.,
an argument value of the entry function) and produces an output
value.âŸ¦ğ‘ƒâŸ§is a partial function and we write âŸ¦ğ‘ƒâŸ§(ğ‘£ğ‘–)=âŠ¥when it
is undefined for input ğ‘£ğ‘–(we treatâŠ¥as a special value not included
inVal, i.e.,âŠ¥âˆ‰Val). We assumeâŸ¦ğ‘ƒâŸ§(ğ‘£ğ‘–)producesâŠ¥only when it
causes a type error. In other words, we assume no other run-time
errors can occur for simplicity. Moreover, we assume there is only
a single type error in the buggy program.
Problem Definition .Assume a program ğ‘ƒwith a setTâŠ† ValÃ—
Valof test cases are given, where a test case is a pair (ğ‘£ğ‘–,ğ‘£ğ‘œ)âˆˆT of
input and output values of the program. We assume that for some
(ğ‘£ğ‘–,ğ‘£ğ‘œ)âˆˆT ,âŸ¦ğ‘ƒâŸ§(ğ‘£ğ‘–)=âŠ¥. We divideTinto negative tests ( Tğ‘)
and positive tests (Tğ‘ƒ):
T=Tğ‘âˆªTğ‘ƒ
whereTğ‘={(ğ‘£ğ‘–,ğ‘£ğ‘œ)âˆˆT|âŸ¦ğ‘ƒâŸ§(ğ‘£ğ‘–)=âŠ¥}andTğ‘ƒ={(ğ‘£ğ‘–,ğ‘£ğ‘œ)âˆˆT|
âŸ¦ğ‘ƒâŸ§(ğ‘£ğ‘–)=ğ‘£ğ‘œ}. Our goal is then to fix the program by transforming
ğ‘ƒintoğ‘ƒâ€²such that for all(ğ‘£ğ‘–,ğ‘£ğ‘œ)âˆˆT =Tğ‘âˆªTğ‘ƒ,âŸ¦ğ‘ƒâ€²âŸ§(ğ‘£ğ‘–)=ğ‘£ğ‘œ.
3.1 Collecting Candidate Variables
Traceback .We collect candidate variables from the traceback
(error trace) that is available in Python when a run-time exception
is raised. WhenâŸ¦ğ‘ƒâŸ§(ğ‘£ğ‘–)=âŠ¥for some error-triggering input ğ‘£ğ‘–, we
write traceback(âŸ¦ğ‘ƒâŸ§(ğ‘£ğ‘–))for the associated traceback. A traceback
ğ‘‡is a sequence of function calls made at an error location:
ğ‘‡=âŸ¨(ğ¹1,ğ‘†1),(ğ¹2,ğ‘†2),...,(ğ¹ğ‘›,ğ‘†ğ‘›)âŸ©
whereğ¹ğ‘–is a function declaration (i.e., ğ¹ğ‘–=(ğ‘“,ğ‘¥,ğ‘†)),ğ‘†ğ‘–a statement,
andğ¹1the entry function ( ğ¹ğ‘’). For 1â‰¤ğ‘–â‰¤ğ‘›âˆ’1,ğ‘†ğ‘–is a statementESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore Wonseok Oh and Hakjoo Oh
that includes a function call to ğ¹ğ‘–+1.ğ‘†ğ‘›is the statement where the
error occurs.
Candidate Variables .We collect program variables appearing
in error traces as candidate variables. We run negative test cases in
Tğ‘to generate the set Tof all tracebacks for the given type error:
T={traceback(âŸ¦ğ‘ƒâŸ§(ğ‘£ğ‘–))|(ğ‘£ğ‘–,ğ‘£ğ‘œ)âˆˆTğ‘}.
Given a traceback ğ‘‡, letVar(ğ‘‡)be the set of variables appearing in
ğ‘‡:Var(ğ‘‡)=Ã
((ğ‘“,ğ‘¥,_),ğ‘†)âˆˆğ‘‡Var(ğ‘†)âˆª{ğ‘¥}, where Var(ğ‘†)denotes the
set of variables used in statement ğ‘†. We define the set CandVars of
candidate variables as follows:
CandVars =Ã˜
ğ‘‡âˆˆTVar(ğ‘‡)
3.2 Inferring Negative and Positive Types
Next, we infer the negative and positive types of candidate variables.
We compute negative types via dynamic analysis by observing the
types of variables while running the program with negative test
inputs; for all ğ‘¥âˆˆCandVars , we compute
NegTypes(ğ‘¥)={type(ğ‘¥,ğ‘ƒ,ğ‘£ğ‘–)|(ğ‘£ğ‘–,_)âˆˆTğ‘}
where type(ğ‘¥,ğ‘ƒ,ğ‘£ğ‘–)denotes the type that variable ğ‘¥has whenğ‘ƒis
executed with input ğ‘£ğ‘–(for simplicity, we assume a variable has a
single type per program execution).
For positive types, we use both dynamic and static analyses:
PosTypes(ğ‘¥)=PosTypesdynamic(ğ‘¥)âˆªPosTypesstatic(ğ‘¥)
where PosTypesdynamic(ğ‘¥)andPosTypesstatic(ğ‘¥)denote the types
inferred by dynamic and static analyses, respectively. The former
obtained from positive test cases and is defined as follows:
PosTypesdynamic(ğ‘¥)={type(ğ‘¥,ğ‘ƒ,ğ‘£ğ‘–)|(ğ‘£ğ‘–,_)âˆˆTğ‘ƒ}.
When the given positive test cases are not enough to infer the
positive types of some candidate variables (i.e., PosTypesdynamic(ğ‘¥)
is undefined for some ğ‘¥âˆˆCandVars ),PyTER predicts those types
using static analysis. However, note that using a conventional type
inference algorithm is unlikely to produce useful information in
our case, because variables often do not have ground-truth types
in dynamic languages. For example, if we perform conventional
type inference on the program in Figure 2a, then PosTypesstatic
would include all the possible types (e.g. int, str, bool, etc) for all
candidate variables. In particular, it would contain all negative
types, i.e.,âˆ€ğ‘¥âˆˆCandVars.NegTypes(ğ‘¥)âŠ†PosTypesstatic(ğ‘¥), which
is undesirable because our aim is to leverage the difference of types
that variables have in normal and erroneous executions.
To address this issue of standard type inference, we present a
new type analysis tailored for finding the intended positive types of
the program variables. Our type analysis is based on the intuition
that, when a type error occurs, a specific buggy variable has an
incorrect type while other variables typically have correct types.
For example, when we execute program in Figure 2(a) with negative
tests, the type ( str) of the buggy variable ais incorrect but other
variables such as b,c, and dare of the correct types. Based on this
observation, our type analysis infers the intended positive type of
each candidate variable ğ‘¥âˆˆCandVars as follows:(1)We assume ğ‘¥is the buggy variable and initialize a type en-
vironment Î›ğ‘¥
init:CandVarsâ†’2Typesby assuming all vari-
ables butğ‘¥have the negative types:
Î›ğ‘¥
init=ğœ†ğ‘¦âˆˆCandVars.âˆ… Â·Â·Â· ğ‘¦=ğ‘¥
NegTypes(ğ‘¦) Â·Â·Â· otherwise
(2)Run a consistency-based type inference algorithm (denoted
infer ) w.r.t. Î›ğ‘¥
initto predict the intended positive types ğœğ‘¥âŠ†
Types ofğ‘¥:
ğœğ‘¥=infer(ğ‘¥,Î›ğ‘¥
init).
(3)When the prediction is not deterministic, i.e., |ğœğ‘¥|>1, we se-
lect one dominantly used in the program. Writing dom_type
for this procedure, we can define PosTypesstatic(ğ‘¥)as follows:
PosTypesstatic(ğ‘¥)=dom_type(ğœğ‘¥).
We apply the above steps for all variables ğ‘¥âˆˆCandVars . Now, we
explain the second and third steps ( infer anddom_type) in detail.
Consistency-based Type Inference .To infer the intended type
of a specific variable from the initial type environment, we propose
a consistency-based static type analysis.
As typical in type inference, our algorithm begins with gener-
ating type constraints. We generate a set Cof constraints from
statements in tracebacks:
C=Ã˜
ğ‘‡âˆˆTÃ˜
((_,_,ğ‘†),_)âˆˆğ‘‡ğ›¼(ğ‘†)
whereğ›¼extracts constraints from statements and expressions as
follows:3
ğ›¼(ğ‘†)=ï£±ï£´ï£´ï£´ ï£²
ï£´ï£´ï£´ï£³ğ›¼(ğ‘†1)âˆªğ›¼(ğ‘†2) Â·Â·Â· ğ‘†=ğ‘†1;ğ‘†2
ğ›¼(ğ¸)âˆª{(ğ‘¥Â¤=ğ¸)} Â·Â·Â· ğ‘†=ğ‘¥=ğ¸
ğ›¼(ğ¸) Â·Â·Â· ğ‘†=returnğ¸
ğ›¼(ğ¸)=ï£±ï£´ï£´ï£´ ï£²
ï£´ï£´ï£´ï£³ğ›¼(ğ¸1)âˆªğ›¼(ğ¸2)âˆª{(ğ¸1Â¤=ğ¸2)} Â·Â·Â·ğ¸=ğ¸1âŠ•ğ¸2Ã
ğ‘–ğ›¼(ğ¸ğ‘–) Â·Â·Â· ğ¸=ğ‘“(ğ¸1,...,ğ¸ğ‘›)
âˆ… Â·Â·Â· otherwise
where constraint(ğ¸1Â¤=ğ¸2)indicates that ğ¸1andğ¸2should have
equivalent types in order to satisfy type consistency.
Example 3.1. Let us generate constraints from the buggy program
in Figure 2a. In case of the statement (e = a + d) at line 12 , we can
extract constraints such as:
ğ›¼(e = a + d)=ğ›¼(a + d)âˆª{ eÂ¤=a + d}={aÂ¤=d,eÂ¤=a + d}.
The generated constraints for statements in fooare as follows:
9: d = b + c
12: e = a + d
13: return a + c + e(dÂ¤=b + c)
(bÂ¤=c)
(eÂ¤=a + d)
(aÂ¤=d)
(aÂ¤=c + e)
(cÂ¤=e)(1)
After collecting constraints C, we solve them to create the final
solution (type environment ) Î›:CandVarsâ†’2Types. Given a
3In practice, we distinguish constraints by their labels (program locations), which is
necessary to find dominant types when constraints are not unique.PyTER : Effective Program Repair for Python Type Errors ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore
current solution Î›, the following function Î¦updates Î›by iterating
over constraints in C:
Î¦C(Î›)=(
Î¦â€²
C(ğœ™(ğ‘,Î›)),Â·Â·Â·C=ğ‘âˆªCâ€²
Î›Â·Â·Â·C=âˆ…
where Î¦processes a single constraint of the form ğ¸1Â¤=ğ¸2:
ğœ™((ğ¸1Â¤=ğ¸2),Î›)=Ã„
ğ‘¥1âˆˆVar(ğ¸1)Î›[ğ‘¥1â†¦â†’Î›(ğ‘¥1)âˆªğœ2]
âŠ”Ã„
ğ‘¥2âˆˆVar(ğ¸2)Î›[ğ‘¥2â†¦â†’Î›(ğ‘¥2)âˆªğœ1](2)
whereğœ1andğœ2are the results of ğ¸1andğ¸2w.r.t. the current
solution, i.e., Î›âŠ¢ğ¸1:ğœ1,Î›âŠ¢ğ¸2:ğœ2. The operatorâŠ”is defined
to merge two maps in the pointwise manner. The typing rules are
fairly standard such as:
Î›âŠ¢ğ‘›:{int}Î›âŠ¢ğ‘ :{str}Î›âŠ¢ğ‘:{bool}Î›âŠ¢ğ‘¥:Î›(ğ‘¥)
ğ‘“âˆˆCastFuns
Î›âŠ¢ğ‘“(ğ¸):{ğ‘“}ğ‘“âˆ‰CastFuns
Î›âŠ¢ğ‘“(ğ¸1,...,ğ¸ğ‘›):âˆ…Î›âŠ¢ğ¸1:ğœ1Î›âŠ¢ğ¸2:ğœ2
Î›âŠ¢ğ¸1âŠ•ğ¸2:ğœ1âˆªğœ2
where CastFuns denotes the set of built-in casting functions (e.g.,
CastFuns ={int,str,...})4; our analysis is intra-procedural that
ignores return values of functions except for built-in casting func-
tions. In (2), we assume that Î›(ğ‘¥ğ‘–)andğœğ‘–are defined for ğ‘–âˆˆ{1,2}.
Otherwise, we define ğœ™((ğ¸1Â¤=ğ¸2),Î›)=âˆ….
Given Î¦, we can define infer as follows:
infer(ğ‘¥,Î›ğ‘¥
init)=(fixÎ›ğ‘¥
initÎ¦C)(ğ‘¥)
where fixÎ›ğ‘¥
initÎ¦Ccomputes the following until a fixed point is reached:
Î›ğ‘¥
0=Î›ğ‘¥
init
Î›ğ‘¥
ğ‘–=Î¦C(Î›ğ‘¥
ğ‘–âˆ’1) (ğ‘–â‰¥1)(3)
Note that the fixed point computation begins with the initial type
environment that assumes variables have positive types except for
the variable ğ‘¥currently assumed to be buggy.
Example 3.2. To infer the intended type of variable ain Figure 2a,
we begin with the following type environment:
Î›0=Î›âˆ’a={aâ†¦â†’âˆ…,bâ†¦â†’{int},câ†¦â†’{int},...}
Iterating over the constraints in (1) starting from Î›0converges to
the following:
Î›={aâ†¦â†’{int},bâ†¦â†’{int},câ†¦â†’{int},...}
from which we conclude that the desired type of aisint.
Finding Dominant Types .LetÎ›ğ‘¥be the solution of (3). When
the inferred type of ğ‘¥is not deterministic, i.e., |Î›ğ‘¥(ğ‘¥)|>1, our
algorithm goes into the next step where we select the type of ğ‘¥
dominantly used in the program.
Example 3.3. Consider the following code:
1def main(seq, to_append)
2 if isinstance(to_append, list) :
3 to_append = seq + to_append
4 elif isinstance(to_append, tuple) :
5 to_append += (1,)
6 to_append = seq + to_append # TypeError
7 else :
4In Python, type casting is done with functions whose names equal types, e.g., int().8 to_append = [seq, to_append]
9return to_append
where we assume seqhas a list value and to_append has a tuple
value. Then, a type error occurs at line 6 because addition between
list and tuple is undefined in Python. By assuming to_append is a
buggy variable, our algorithm described so far infers from lines 5
and 8 that the positive types of to_append can be both tuple and
list , respectively, resulting in a non-singleton set {list,tuple}.
In this case, however, we would like to predict the type of to_append
aslist since it is the intent of the developer and to_append is dom-
inantly used as list over the program (e.g., lines 3 and 8).
To find out the dominant type, we maintain information Î©:
CandVarsÃ—Typesâ†’N, which counts the number of times types
are associated with variables during the fixed point computation.
We update Î©whenever the type environment Î›is updated. That
is,Î©is updated to the following whenever ğœ™is applied in (2):
Ã„
ğœâˆˆğœ2Î©[(ğ‘¥1,ğœ)â†¦â†’Î©(ğ‘¥1,ğœ)+1]âŠ”Ã„
ğœâˆˆğœ1Î©[(ğ‘¥2,ğœ)â†¦â†’Î©(ğ‘¥2,ğœ)+1]
where Î©(ğ‘¥,ğœ)is initially 0 for all ğ‘¥âˆˆCandVars andğœâˆˆTypes . Let
Î©ğ‘¥be such count information generated when Î›ğ‘¥is computed.
Then, we can define dom_type as follows:
dom_type(ğœğ‘¥)=argmax
ğœâˆˆğœğ‘¥Î©ğ‘¥(ğ‘¥,ğœ).
3.3 Type-Aware Fault Localization
PyTER uses the type information to identify the program location
to be fixed. Suppose the negative and positive types of candidate
variables are given from the previous step:
NegTypes,PosTypes :CandVarsâ†’2Types
Function-Level Fault Localization .The main difference from
traditional fault localization is that our approach is staged and the
most suspicious function is identified first. To do so, we compute
the suspicious scores of candidate variables based on the difference
of the negative and positive types. We define the score of a variable
ğ‘¥as a pair of integers as follows:
score(ğ‘¥)=(Ã•
(ğœ1,ğœ2)âˆˆğ´(ğ‘¥)âˆ’1{ğœ1=ğœ2},Ã•
(ğœ1,ğœ2)âˆˆğ´(ğ‘¥)1{ğœ1â‰ ğœ2})
whereğ´(ğ‘¥)is the cartesian product of NegTypes(ğ‘¥)andPosTypes(ğ‘¥).
The first and second elements measure how similar and differ-
entNegTypes(ğ‘¥)andPosTypes(ğ‘¥)are, respectively. Here, a smaller
score is given when the types are similar, and a higher score is
given when the types are different. With score , we find out the most
suspicious candidate variable ğ‘¥âˆˆCandVars :
ğ‘¥=argmax
ğ‘¥â€²âˆˆCandVarsscore(ğ‘¥â€²)
where we use the lexicographic, total order between scores: (ğ‘,ğ‘)>
(ğ‘â€²,ğ‘â€²)â‡â‡’ğ‘>ğ‘â€²âˆ¨(ğ‘=ğ‘â€²âˆ§ğ‘>ğ‘â€²). Then we treat the function
ğ¹as most suspicious that uses the selected variable ğ‘¥.ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore Wonseok Oh and Hakjoo Oh
Line-Level Fault Localization .Once the suspicious function
ğ¹and variable ğ‘¥are chosen, we compute the suspicious scores of
program locations in ğ¹by running a traditional spectrum-based
fault localization (SBFL). We simply define the score of a program
location (line) ğ‘™as follows:
scoreğ¹(ğ‘™)=(
1 âˆƒğ‘‡âˆˆT.(ğ¹,ğ‘†ğ‘™)âˆˆğ‘‡
failed(ğ‘†ğ‘™)
failed(ğ‘†ğ‘™)+passed(ğ‘†ğ‘™)otherwise
whereğ‘†ğ‘™represents the statement at line ğ‘™,failed(ğ‘†ğ‘™)andpassed(ğ‘†ğ‘™)
denote the numbers of failing and passing test cases that execute
statementğ‘†ğ‘™, respectively. When the function ğ¹and the statement ğ‘†ğ‘™
appear in some error trace ğ‘‡, we give the highest score. Otherwise,
we run SBFL to compute a score based on the numbers of failing
and passing test cases.
3.4 Type-Aware Patch Generation
Now we explain the patch generation step of PyTER . We are cur-
rently given the suspicious function, line, and variable line as well
as the positive and negative types of ğ‘¥:
ğ›¿=(ğ¹,ğ‘™,ğ‘¥, NegTypes(ğ‘¥),PosTypes(ğ‘¥)).
Letğ‘†ğ‘™be the suspicious statement at line ğ‘™.
Repair Templates .We extensively studied developer patches
available in open-source programs5, and concluded that most of
the patches for fixing single-variable type errors can be categorized
into the 9 templates in Table 2, which are divided into three main
categories based on their strategies to fix type errors:
â€¢â€˜TypeCastingâ€™ templates insert a casting statement that con-
verts a negative type of the suspicious variable ( ğ‘¥) to a posi-
tive type.
â€¢â€˜Handlingâ€™ templates handle the type error by replacing the
suspicious statement ( ğ‘†ğ‘™) or an expression in it by new one.
â€¢â€˜Guardâ€™ templates are used when the suspicious statement
(ğ‘†ğ‘™) is a conditional statement. The guard of the statement is
strengthened by adding a type check to avoid the error.
A template contains holes ( â–¡) of five types: â–¡ğ‘indicates a neg-
ative type in NegTypes(ğ‘¥),â–¡ğ‘ƒa positive type in PosTypes(ğ‘¥),â–¡ğ¶
a casting expression, â–¡ğ‘†a statement, and â–¡ğ¸an expression. Ta-
ble 2 shows examples of buggy statement ğ‘†ğ‘™, template applied to ğ‘†ğ‘™
(denotedğ‘†â–¡
ğ‘™) , and candidate patch (denoted ğ‘†âˆ—
ğ‘™). Thus, templates
with prefix â€˜Negativeâ€™ is to check if the suspicious variable ( ğ‘¥) has
a negative type in NegTypes(ğ‘¥). Likewise, templates with prefix
â€˜Positiveâ€™ is to check whether the variable ğ‘¥has a positive type in
PosTypes(ğ‘¥).
Prioritizing Templates .To fix the bug in ğ‘†ğ‘™, we first need
to select a template. Basically, we enumerate all templates, but
PyTER prioritizes appropriate ones based on the type information,
NegTypes(ğ‘¥)andPosTypes(ğ‘¥)of the suspicious variable ( ğ‘¥).
We first decide one of the main categories. We choose the Guard
category if ğ‘†ğ‘™is a conditional statement, because it can be only
applied when the condition is satisfied. Otherwise, we prioritize
either TypeCasting or Handling categories based on the number of
positive types (i.e., |PosTypes(ğ‘¥)|). We expect|PosTypes(ğ‘¥)|to be
5For this study, we used not only our benchmarks, TypeBugs , but also others that do
not meet our benchmark selection criteria in Section 4.one for synthesizing the hole â–¡ğ¶in TypeCasting. Thus, we select
TypeCasting instead of Handling when |PosTypes(ğ‘¥)|=1.
Once a main category is chosen, we prioritize sub categories
with the number of negative types (i.e., |NegTypes(ğ‘¥)|). It is easy
to synthesize â–¡ğ‘, when|NegTypes(ğ‘¥)|=1. Hence, we first se-
lect sub templates with prefix â€˜Negativeâ€™ when |NegTypes(ğ‘¥)|=1.
Otherwise, we choose other sub templates firstly except for tem-
plates with prefix â€˜Negativeâ€™. Then, we enumerate the rest of sub
categories in increasing size.
Template Instantiation .Once a template ( ğ‘†â–¡
ğ‘™) is chosen, we
need to synthesize holes in it to produce candidate patches. This
synthesis procedure is defined by the transition system:
(Î˜,{,ğœƒğ¼,Î˜ğ¹)
where Î˜is a set of states,({)âŠ†Î˜Ã—Î˜is a transition relation, Î˜ğ¼
is a set of initial state, and Î˜ğ¹âŠ†Î˜is a set of final states. A state
ğœƒâˆˆÎ˜is a pair(ğ‘†â–¡,ğ›¿)of a partial statement with holes and the
information ğ›¿from fault localization. The initial state ğœƒğ¼âˆˆÎ˜ğ¼is
the pair(ğ‘†â–¡
ğ‘™,ğ›¿)whereğ‘†â–¡
ğ‘™denotes the selected template. The goal
of template instantiation is to find a final state (ğ‘†âˆ—
ğ‘™,_)âˆˆÎ˜ğ¹that
makes the program work correctly:
âˆ€(ğ‘£ğ‘–,ğ‘£ğ‘œ)âˆˆT,âŸ¦ğ‘ƒ[ğ‘†ğ‘™â†¦â†’ğ‘†âˆ—
ğ‘™]âŸ§(ğ‘£ğ‘–)=ğ‘£ğ‘œ.
whereğ‘ƒ[ğ‘†ğ‘™â†¦â†’ğ‘†âˆ—
ğ‘™]denotes the program ğ‘ƒwith the statement ğ‘†ğ‘™
replaced by ğ‘†âˆ—
ğ‘™.
Givenğ›¿=(ğ¹,ğ‘™,ğ‘¥, NegTypes,PosTypes), Figure 5 presents the
transition relation for synthesizing holes in partial programs. We
write dvğœfor the default value of ğœ(e.g. dvint= 0,dvstr= "", etc). In
Python, the expression (isinstance( x, (int, str, bool))) means whether
a type of xis one of (int, str, bool). We use this expression when
synthesizing â–¡ğ‘ƒ.ReturnExps(ğ¹)andReturnTypes(ğ¹)return a set of
the expression of return statements used and the output types of
the function ğ¹, respectively:
ReturnExps(ğ¹)={ğ¸|returnğ¸âˆˆReturnStmts(ğ¹)}
ReturnTypes(ğ¹)={ğœâˆˆğœ|ğ¸âˆˆReturnTypes(ğ¹),PosTypesâŠ¢ğ¸:ğœ}
where the ReturnStmts(ğ¹)denotes the set of all return statements
inğ¹and we use PosTypes as a type environment in ReturnTypes .
3.5 Final Algorithm
Putting it all together, Algorithm 1 shows the final algorithm of
PyTER . We first collect candidate variables from error traces (line
2) and perform dynamic and static type analysis (line 3). Let Î¥be
the result of type analysis phase, which contain information about
negative and positive types of candidate variables. By utilizing Î¥,
we run fault localization to rank candidate faulty locations and
iterates over the results (line 4), where ğ›¿consists of function ( ğ¹),
line (ğ‘™), variable (ğ‘¥), negative types ( NegTypes ), and positive types
(PosTypes ). We generate a ranked list of candidate patches (line 5)
and apply a patch to the original buggy program (line 6). Next,
we execute the candidate patched program on test cases ( Tğ‘ƒ,Tğ‘)
at line 7, and obtain failed test cases Tâ€²
ğ‘. IfTâ€²
ğ‘is empty, then we
return that candidate program as output. Otherwise, we check if
Tâ€²
ğ‘is a subset ofTğ‘, which means that some of Tğ‘passes. Then,
we continue to refine the current patch by invoking the algorithm
withTâ€²
ğ‘(line 11).PyTER : Effective Program Repair for Python Type Errors ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore
Table 2: Repair templates with examples. To illustrate, we assume the suspicious variable is x,NegTypes(ğ‘¥)={str}, and
PosTypes(ğ‘¥)={int}.ğ‘†ğ‘™: buggy statement. ğ‘†â–¡
ğ‘™: template for ğ‘†ğ‘™.ğ‘†âˆ—
ğ‘™: candidate patch without holes.
Main Sub ğ‘†ğ‘™(Buggy stmt) ğ‘†â–¡
ğ‘™(Template for ğ‘†ğ‘™) ğ‘†âˆ—
ğ‘™(Candidate patch)
Type
CastingNegative
TypeCastingreturn x + yif isinstance(x, â–¡ğ‘) :
x =â–¡ğ¶
return x + yif isinstance(x, str) :
x = int(x)
return x + y
Positive
TypeCastingreturn x + yif not isinstance(x, â–¡ğ‘ƒ) :
x =â–¡ğ¶
return x + yif not isinstance(x, (int)) :
x = int(x)
return x + y
TypeCasting
Expressionreturn x + y return â–¡ğ¶+ y return int(x) + y
HandlingNegative
Handling Stmtreturn x + yif isinstance(x, â–¡ğ‘) :
â–¡ğ‘†
return x + yif isinstance(x, str) :
return 0
return x + y
Negative
Handling Exprreturn x + y return ( â–¡ğ¸if isinstance(x, â–¡ğ‘) else x) + y return (0 if isinstance(x, str) else x) + y
Positive
Handlingreturn x + yif not isinstance(x, â–¡ğ‘ƒ) :
â–¡ğ‘†
return x + yif not isinstance(x, (int)) :
return 0
return x + y
Exception
Handlingreturn x + ytry :
return x + y
except :
â–¡ğ‘†try :
return x + y
except :
return 0
GuardNegative
Guardif x == 0 :
return x
else :
return 0if not isinstance(x, â–¡ğ‘) and x == 0 :
return x
else :
return 0if not isinstance(x, (int)) and x == 0 :
return x
else :
return 0
Positive
Guardif x == 0 :
return x
else :
return 0if isinstance(x, â–¡ğ‘ƒ) and x == 0 :
return x
else :
return 0if isinstance(x, int) and x == 0 :
return x
else :
return 0
ğœâˆˆPosTypes(ğ‘¥)
â–¡ğ‘†{ğ‘¥=dvğœğœâˆˆReturnTypes(ğ¹)
â–¡ğ‘†{return dvğœğ¸âˆˆReturnExps(ğ¹)
â–¡ğ‘†{returnğ¸ğœâˆˆPosTypes(ğ‘¥)
â–¡ğ¸{dvğœPosTypes(ğ‘¥)={ğœ1,ğœ2,...,ğœğ‘›}
â–¡ğ‘ƒ{(ğœ1,ğœ2,...,ğœğ‘›)ğœâˆˆNegTypes(ğ‘¥)
â–¡ğ‘{ğœ
ğœâˆˆPosTypes(ğ‘¥)
â–¡ğ¶{ğœ(ğ‘¥)âˆ€ğ‘–âˆˆ{1,...,ğ‘›}ğ¸ğ‘–{ğ¸â€²
ğ‘–
ğ‘“(ğ¸1,...,ğ¸ğ‘›){ğ‘“(ğ¸â€²
1,...,ğ¸â€²ğ‘›)ğ¸1{ğ¸â€²
1ğ¸2{ğ¸â€²
2
ğ¸1âŠ•ğ¸2{ğ¸â€²
1âŠ•ğ¸â€²
2ğ¸{ğ¸â€²
ğ‘¥=ğ¸{ğ‘¥=ğ¸â€²ğ¸{ğ¸â€²
returnğ¸{returnğ¸â€²ğ‘†1{ğ‘†â€²
1ğ‘†2{ğ‘†â€²
2
ğ‘†1;ğ‘†2{ğ‘†â€²
1;ğ‘†â€²
2
Figure 5: Transition relation for instantiating templates
4 EVALUATION
In this section, we experimentally evaluate PyTER to answer the
following research questions:
â€¢Effectiveness of PyTER : How effectively can PyTER fix
real-world Python type errors?
â€¢Impact of techniques : How important are the major tech-
niques used in PyTER ?
â€¢Limitations of PyTER : What limitations does PyTER have?
When is PyTER likely to fail to fix type errors?
4.1 Setup
We implemented PyTER in about 8,000 lines of Python code (v.3.9.1).
We implemented dynamic type analysis and fault localization on
top of PyAnnotate [ 27], a framework to instrument Python source
code. Our implementation of PyTER supports the full languageof Python 3, including object-oriented features and user-defined
types. An exception is sub-types; the current implementation of
PyTER ignores sub-types because we observed they are rarely used
in real-world programs. All experiments were done on a Linux
machine (Ubuntu 18.04) with 2 CPUs and 128GB memory, powered
by the Intel Zeon Silver 4214 processor.
Benchmarks .We used two benchmark sets: TypeBugs and
BugsInPy . We constructed a new benchmark set, TypeBugs , be-
cause there is no benchmark dedicated to repairing type errors
although datasets for type inference exist [ 3,44]. We first collected
popular open-source projects from Github that have more than
1000 stars. We then searched for pull requests with the keyword
"TypeError" in their messages over the past 5 years (since 2016
up to 2021). Among them, we considered type errors that include
both error-triggering test cases and a correct patch written by aESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore Wonseok Oh and Hakjoo Oh
Algorithm 1 ThePyTER Algorithm
Input: A buggy program ğ‘ƒ, test casesTğ‘andTğ‘ƒ, tracebacks T
Output: A correct program ğ‘ƒâ€²satisfying all test cases in Tğ‘âˆªTğ‘ƒ
1:function REPAIR (ğ‘ƒ,Tğ‘ƒ,Tğ‘,T)
2:ğ¶â†CandidateVariables (T) âŠ²Section 3.1
3: Î¥â†TypeAnalysis(ğ‘ƒ,ğ¶,Tğ‘ƒ,Tğ‘,T) âŠ²Section 3.2
4: forğ›¿âˆˆFaultLocalization(T,Î¥)do âŠ²Section 3.3
5: forğ‘†âˆ—
ğ‘™âˆˆPatchCandidates(ğ›¿)do âŠ²Section 3.4
6: ğ‘ƒâ€²â†ğ‘ƒ[ğ‘†ğ‘™â†¦â†’ğ‘†âˆ—
ğ‘™] âŠ²Apply the patch
7:Tâ€²
ğ‘â†Execute(ğ‘ƒâ€²,Tğ‘ƒ,Tğ‘) âŠ²Tâ€²
ğ‘: Failed tests
8: ifTâ€²
ğ‘=âˆ…then
9: returnğ‘ƒâ€²
10: else ifTâ€²
ğ‘âŠ‚Tğ‘then
11: ğ‘ƒâˆ—â†REPAIR (ğ‘ƒâ€²,Tğ‘ƒ,Tâ€²
ğ‘,T)
12: ifğ‘ƒâˆ—â‰ failthen
13: returnğ‘ƒâˆ—
14: return fail
developer. For each bug, TypeBugs includes the repository snap-
shot of the bug-fixing commit with the developer patch removed.
In total, we collected 93 bugs from 15 open-source projects, com-
prising of small to large scale projects (2.9-428.8 KLoC) on various
domains such as machine learning (e.g. scikit-learn), data analysis
(e.g., pandas), and scientific computing (e.g. numpy). On average,
TypeBugs includes 4.1 negative test cases per bug. We used positive
test cases in the file containing the negative test cases, resulting in
91.9 test cases per program on average. We did not use the full set
of positive tests provided by each project, because running all of
them was prohibitively expensive. For example, the pandas project
contains about 170,000 tests and running them takes more than 24
hours.
We also evaluate PyTER onBugsInPy [57], an existing bug bench-
mark for Python. BugsInPy is a Python version of Defects4J [ 31],
containing 493 bugs of diverse types. Among them, we extracted
57 bugs that raise type error exceptions.
Success Criteria .We manually checked whether the generated
patches are correct or not, where a patch is considered correct if
it is semantically identical to a developer patch ignoring I/O side
effects (e.g., printing a value). We also checked the developerâ€™s com-
ments to consider their implicit intention when checking semantic
equivalence. In all experiments, we set the time budget for tool
execution to 3,600 seconds per bug.
4.2 Results
Results on TypeBugs .Table 3 shows the performance of PyTER
onTypeBugs andBugsInPy . To see the effectiveness of PyTER , we
compare it with Baseline , the baseline of PyTER that uses a con-
ventional generate-and-validate approach without our type-aware
enhancement and static type analysis. More precisely, Baseline
uses existing SBFL without our type-aware fault localization and
patch prioritization. Baseline uses the same set of templates as
PyTER . When synthesizing holes in the templates, Baseline uses
NegTypes andPosTypesdynamic but it does not use PosTypesstatic that
requires our static analysis technique.1def foo(out, data) :
2- out = out + data # TypeError
3+ out = out.encode() + data
4return out
5
6def goo(module) :
7...
8- for obj in module.values() :
9+ for obj in module.itervalues() :
10 ...
Figure 6: A developer patch example in BugsInPy (simpli-
fied from scrpay-30)
In total, PyTER generated 58 plausible patches (which pass all
test cases) out of 93 bugs. Among those 58 plausible patches, 45
were correct (equivalent to developer patches), leading to a fix rate
of 48.4% (45
93) and a precision of 77.6% (45
58). On the other hand,
Baseline generated 47 plausible patches of which 23 were correct,
achieving a fix rate of 24.7% (23
93) and a precision of 48.9% (23
47). These
results confirm that our type-aware APR technique is essential for
fixing real-world type errors.
Results on BugsInPy .On average, PyTER fixed 31.6% (18
57) of
57 bugs with a precision of 64.3% (18
28). By contrast, Baseline was
able to fix 14.0% (8
57) with a precision of 32.0% (8
25).
PyTER is less effective on BugsInPy than TypeBugs (48.4% vs.
31.6%) because BugsInPy was not constructed with type errors in
mind. We found that many of those 57 bugs were not originally
reported as type errors (e.g., the error reports do not contain the
keyword â€œTypeErrorâ€). Therefore, although they raise type error
exceptions, their root causes often involve other kinds of bugs as
well. Figure 6 shows an example that includes a type error at line
2 but also involves another (non-type) error at line 8. In this case,
PyTER succeeds to fix the type error at line 2, but the resulting
patch does not pass test cases as the bug at line 8 still remains. This
is why we newly created TypeBugs , a collection of bugs originally
reported as type errors, to solely evaluate the ability of PyTER for
fixing type errors.
Impact of Techniques .PyTER features three new techniques:
type-aware fault localization (Section 3.3), type-aware patch pri-
oritization (Section 3.4), and static type analysis (Section 3.2). To
evaluate the impact of these techniques, we compared the perfor-
mance of the following variants of PyTER :
â€¢Baseline : the baseline of PyTER without our fault localiza-
tion, patch prioritization, and static type analysis.
â€¢Baseline+:Baseline with our patch prioritization
â€¢Baseline++:Baseline+with our fault localization
â€¢PyTER :Baseline++with our static type analysis
We evaluate these variants in terms of the number of solved bench-
marks, including both TypeBugs andBugsInPy , and the cumulative
repair time. Note that, to our knowledge, no existing APR tools are
readily available for fixing real-world Python programs (except for
those for fixing student programs, e.g., [ 13,19,25]). Thus, we tried
to indirectly compare PyTER with general APR tools by includingPyTER : Effective Program Repair for Python Type Errors ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore
Table 3: Evaluation Results. #B : the number of bugs for each projects. #G : the number of plausible patches. #C : the number
of correct patches. FixRate : (#ğ¶
#ğµ). Prec(Precision) : (#ğ¶
#ğº). Avg. Time : average running time (sec) per bug.
Program #BAvg.
KLoCNegTest PosTest Baseline PyTER
Avg.
NumAvg.
TimeAvg.
NumAvg.
Time#G #CFix
RatePrecAvg.
Time#G #CFix
RatePrecAvg.
TimeTypeBugsairflow 7 73.9 1.0 53.4 13.3 43.9 3 0 0.0% 0.0% 232.0 4 3 42.9% 75.0% 50.5
beets 1 21.4 1.0 4.0 9.0 7.0 1 0 0.0% 0.0% 8.1 1 0 0.0% 0.0% 3.6
core 9 230.5 1.4 11.6 23.7 14.7 6 4 44.4% 66.7% 303.7 6 5 55.6% 83.3% 88.7
kivy 1 44.5 1.0 6.0 4.0 26.0 1 0 0.0% 0.0% 400.57 1 0 0.0% 0.0% 54.3
luigi 1 13.2 4.0 4.0 1.0 2.0 1 0 0.0% 0.0% 20.6 1 0 0.0% 0.0% 1.5
numpy 3 53.4 2.0 6.0 72.3 4.7 1 0 0.0% 0.0% 1356.8 2 0 0.0% 0.0% 225.5
pandas 45 86.9 7.0 42.6 141.1 125.8 21 11 24.4% 52.4% 1478.2 24 19 42.2% 79.2% 1063.4
rasa 1 45.8 1.0 9.0 7.0 6.0 1 1 100.0% 100.0% 7.3 1 1 100.0% 100.0% 7.3
requests 4 9.4 1.5 8.0 184.8 33.3 3 1 25.0% 33.3% 942.4 4 4 100.0% 100.0% 167.7
rich 1 16.1 1.0 9.0 7.0 6.0 0 0 0.0% n/a 3600.0 0 0 0.0% n/a 3600.0
salt 9 364.8 1.0 31.0 12.7 165.6 3 2 22.2% 66.7% 1265.5 6 6 66.7% 100.0% 93.8
sanic 3 5.6 3.3 5.7 51.0 9.3 1 1 33.3% 50.0% 1406.6 3 3 100.0% 100.0% 43.5
scikit-learn 5 63.5 1.0 8.0 75.8 13.2 3 2 40.0% 66.7% 1561.6 3 2 40.0% 66.7% 408.7
tornado 1 12.6 1.0 8.0 171.0 20.0 1 1 100.0% 100.0% 1307.9 1 1 100.0% 100.0% 199.2
Zappa 2 4.1 1.0 7.0 46.5 748.5 1 0 0.0% 0.0% 1876.3 1 1 50.0% 100.0% 1663.9
Total 93 112.7 4.1 30.7 91.9 101.2 47 23 24.7% 48.9% 1196.0 58 45 48.4% 77.6% 651.2BugsInPyansible 1 126.5 1.0 21.0 30.0 13.0 0 0 0.0% n/a 3600.0 0 0 0.0% n/a 2549.7
fastapi 2 7.4 1.0 5.5 7.0 3.0 0 0 0.0% n/a 10.8 0 0 0.0% n/a 1.5
keras 5 26.5 1.0 23.8 14.8 50.4 1 0 0.0% 0.0% 2162.9 1 1 20.0% 100.0% 1769.8
luigi 7 12.3 1.1 9.3 54.9 23.0 4 1 14.3% 25.0% 207.1 5 3 42.9% 60.0% 15.1
matplotlib 1 94.9 1.0 8.0 214.0 41.0 0 0 0.0% n/a 0.0 0 0 0.0% n/a 0.0
pandas 25 87.9 9.2 67.4 250.8 130.5 11 4 16.0% 36.4% 2040.3 13 7 28.0% 53.8% 1636.7
scrapy 10 12.7 1.6 8.7 21.0 6.5 6 2 20.0% 33.3% 62.2 6 5 50.0% 83.3% 12.0
spacy 1 78.6 1.0 7.0 6.0 7.0 1 0 0.0% 0.0% 9.7 1 0 0.0% 0.0% 79.8
tornado 2 13.3 1.0 3.5 44.0 3.0 1 0 0.0% 0.0% 1.2 1 1 50.0% 100.0% 0.8
tqdm 1 1.9 1.0 6.0 54.0 4.0 0 0 0.0% n/a 0.0 0 0 0.0% n/a 0.0
youtube-dl 2 112.0 1.0 9.0 81.5 8.5 1 1 50.0% 100.0% 1815.2 1 1 50.0% 100.0% 1802.9
Total 57 54.6 4.7 35.7 131.7 67.3 25 8 14.0% 32.0% 1248.4 28 18 31.6% 64.3% 968.5
0 10 20 30 40 50 60
Benchmark Solved02000400060008000Repair Time (s)
PyTER
Baseline++
Baseline+
Baseline
Figure 7: Impact of Techniques
Baseline that can be considered as representing a typical APR tool
that is not specifically designed for type errors.Figure 7 shows the results. The difference between PyTER and
Baseline++shows how useful our static type analysis is. While
Baseline++fixed 51 programs, PyTER fixed 12 more bugs which
had insufficient positive test cases. The gap between Baseline++and
Baseline+shows the impact of our type-aware fault localization;
using it increased the number of correct patches from 42 to 51.
Moreover, the results show that our patch prioritization technique
is also important. Without it, Baseline was only able to repair 31
bugs as opposed to 42 that Baseline+can fix.
4.3 Discussion
Strength of PyTER over Manual Patches .Because real-world
type errors are nontrivial to fix, we found that PyTER often gen-
erates patches of higher quality compared to developer patches,
which also include all the intended behaviors of the developer patch.
Figure 8 shows an example simplified from scikit-learn. The orig-
inal code in Figure 8(a) has a type error at line 14. We assume that
function fooat line 14 only receives string values as its argument
and otherwise raises a type error exception. Suppose we are given
test cases such that when main is called, the value of sis False
andkhas a value of the bytes type. Then the program executesESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore Wonseok Oh and Hakjoo Oh
Table 4: Statistics on patch patterns PyTER failed in Type-
Bugs andBugsInPy .
TypeBugs (48) BugsInPy (39)
Group A 10 (21%) 7 (18%)
Group B 14 (29%) 10 (25%)
Group C 7 (15%) 4 (10%)
Group D 5 (10%) 8 (21%)
Others 12 (25%) 10 (26%)
function dense and the type error occurs at line 14 because kis not
a string value. Figure 8(b) shows the patch written by a developer,
where (s)he fixed the type error by inserting the conditional type-
casting statement at lines 12 and 13. The developer patch correctly
fixed the type error at line 14. However, it is overfitted to the given
test cases as a potential error still remains at line 9. When kis a
bytes value, the expression str_list.index(k) at line 9 raises an
exception (ValueError) because str_list does not contain bytes
values. Thanks to our type-aware fault localization, PyTER was able
to insert the type-casting statement at lines 3 and 4 and avoided
the future risk by always converting the bytes type of kinto str
before invoking functions sparse ordense at line 5.
Limitations of PyTER .Our evaluation also identified limita-
tions of PyTER . In experiments, PyTER failed to fix 87 bugs. We
investigated why PyTER failed and classified those 87 bugs into
four groups based on the patterns of desirable patches:
â€¢A : patches that convert incorrect type to correct
â€¢B : patches that need conversion for both types and values
â€¢C : patches that introduce new argument values
â€¢D : patches that insert statements not related to types
The frequencies of these groups are shown in Table 4, where â€˜Oth-
ersâ€™ are unclassified bugs that require more complicated repair
strategies.
Bugs in group A are within the scope of PyTER while other
groups are not. So, we further investigated bugs in the A group to
see why PyTER failed: 6 bugs needed multi-line patches, 8 bugs re-
quired more advanced type inference, 2 bugs required for complex
type conversion, and 1 bug required more effective patch prioriti-
zation. For example, PyTER failed to produce the patch in Figure 9
that fixes two type errors at lines 1 and 6 at the same time. Cur-
rently, PyTER focuses on fixing single-line bugs. Also, to fix the
type error at line 1, we need to infer the type of the user-defined
function to_bytes . Our static type analysis currently exploits types
of built-in casting functions such as intandstr.
5 RELATED WORK
APR techniques are commonly classified into special-purpose and
general-purpose approaches. Special-purpose techniques aim to fix
specific yet important classes of bugs. For example, techniques have
been proposed to fix memory errors in C programs [ 16,23,24,36,53,
54,61], null pointer exceptions in Java [ 12,37,59], error-handling
bugs [ 55], concurrency bugs [ 2,30,38,39], dependency errors [ 45],
and integer/buffer overflow [ 9,11,26,46,52]. To our knowledge,
PyTER is the first technique specialized for fixing type errors inPython programs. Furthermore, we are not aware of APR tech-
niques applicable to Python except for introductory programming
assignments [13, 19, 25].
General purpose approaches [ 18,29,33â€“35,40â€“43,47,56,58,60]
aim to fix any kinds of bugs instead of focusing on specific types
of bugs. These techniques are further classified into generate-and-
validate [ 29,33,40,41,56] and semantic-based approaches [ 34,35,
42,43,47,60]. Generate-and-validate approaches explore a pre-
defined search space to generate candidate patches until a patched
program which passes the given test cases is found. Semantics-based
techniques derive constraints on correct patches and synthesize
patches by using SMT solvers. Technically, PyTER belongs to the
generate-and-validate approach, but enhances it with techniques
specialized for type errors such as type-aware fault localization and
patch prioritization.
A number of analyses have been proposed for type inference
in dynamic languages such as Python [ 7,17,21,48,49], JavaScript
[6,10,20,22,28,50], and Ruby [ 4,5,14,15]. For example, Cannon
et al. [ 7] perform analysis to infer atomic types of local variables.
Typepete [21] and DRuby [15] are constraint-based type inference
algorithms. These approaches have a limitation; they require user
type annotations [ 7] or assume variables have single types [ 21]. Neu-
ral type inference techniques [ 48,49] were also presented, but they
need extra learning steps with a large amount of data. TypeDevil
[50] and Rubydust [5] dynamically analyze types by running test
cases. To address shortcomings of dynamic and static analyses, a
hybrid approach [ 20] has been proposed for JavaScript. Note that
our type analysis in Section 3.2 crucially differs from the works
described above; our goal is not to infer all the possible types of
program variables, which are typically useless for type-error repair,
but to predict the intended types when variables are incorrectly
used.
6 CONCLUSION
Type errors are common yet difficult-to-fix in dynamic languages
such as Python. However, no existing techniques or tools are read-
ily available for use. In this paper, we presented PyTER , the first
technique for automatically fixing real-world type errors in Python
applications. To this end, we proposed a new APR technique that
leverages the difference between negative and positive types of pro-
gram variables to perform type-aware fault localization and patch
generation. Experimental results demonstrated that PyTER can re-
pair diverse type errors effectively; it was able to fix 48.4% of type
errors from popular open-source projects with 77.6% precision.
ACKNOWLEDGMENTS
This work was partly supported by Institute of Information &
communications Technology Planning & Evaluation (IITP) grant
funded by the Korea government(MSIT) (No.2020-0-01337,(SW
STAR LAB) Research on Highly-Practical Automated Software Re-
pair and No.2021-0-00758, Development of Automated Program
Repair Technology by Combining Code Analysis and Mining) and
the MSIT(Ministry of Science and ICT), Korea, under the ICT Cre-
ative Consilience program (IITP-2022-2020-0-01819) supervised by
the IITP(Institute for Information & communications Technology
Planning & Evaluation), and the National Research FoundationPyTER : Effective Program Repair for Python Type Errors ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore
1def main(s, k) :
2
3
4fit = sparse if s else dense
5fit(k)
6
7def sparse(k)
8str_list = ["one", "two"]
9return str_list.index(k)
10
11def dense(k)
12
13
14 return foo(k) # TypeError
(a) Original code1def main(s, k) :
2
3
4fit = sparse if s else dense
5fit(k)
6
7def sparse(k)
8str_list = ["one", "two"]
9return str_list.index(k) # Future Risk
10
11def dense(k)
12+ if isinstance(k, bytes) :
13+ k = k.decode()
14 return foo(k) # Fixed
(b) Fix by a developer1def main(s, k) :
2fit = sparse if s else dense
3+ if isinstance(k, bytes) :
4+ k = k.decode()
5fit(k)
6
7def sparse(k)
8str_list = ["one", "two"]
9return str_list.index(k) # Fixed
10
11def dense(k)
12
13
14 return foo(k) # Fixed
(c) Fix by PyTER
Figure 8: (a) Original buggy code (simplified from scikit-learn-7064). (b) Developer patch. (c) Patch generated by PyTER .
1- user_pass = '%s:%s '% (user, password)
2+ user_pass = to_bytes( '%s:%s '% (user, password))
3creds = b64encode(user_pass).strip() # TypeError
4...
5if creds:
6- request = 'Basic '+ creds
7+ request = b 'Basic '+ creds
Figure 9: A TypeError bug (line 3) and developer patch (sim-
plified from scrpay-23 in BugsInPy)
of Korea (NRF) grant funded by the Korea government (MSIT)
(No.2021R1A5A1021944).
REFERENCES
[1][n.d.]. IEEE Spectrumâ€™s the Top Programming Languages 2021. https://spectrum.
ieee.org/top-programming-languages.
[2]Christoffer Quist Adamsen, Anders MÃ¸ller, Rezwana Karim, Manu Sridharan,
Frank Tip, and Koushik Sen. 2017. Repairing event race errors by controlling
nondeterminism. In Proceedings of the 39th International Conference on Software
Engineering, ICSE 2017, Buenos Aires, Argentina, May 20-28, 2017 , SebastiÃ¡n Uchitel,
Alessandro Orso, and Martin P. Robillard (Eds.). IEEE / ACM, 289â€“299. https:
//doi.org/10.1109/ICSE.2017.34
[3]Miltiadis Allamanis, Earl T. Barr, Soline Ducousso, and Zheng Gao. 2020. Typ-
ilus: Neural Type Hints. In Proceedings of the 41st ACM SIGPLAN Conference
on Programming Language Design and Implementation (London, UK) (PLDI
2020) . Association for Computing Machinery, New York, NY, USA, 91â€“105.
https://doi.org/10.1145/3385412.3385997
[4]Jong-hoon An, Avik Chaudhuri, and Jeffrey S Foster. 2009. Static typing for
Ruby on Rails. In 2009 IEEE/ACM International Conference on Automated Software
Engineering . IEEE, 590â€“594.
[5]Jong-hoon An, Avik Chaudhuri, Jeffrey S Foster, and Michael Hicks. 2011. Dy-
namic inference of static types for Ruby. ACM SIGPLAN Notices 46, 1 (2011),
459â€“472.
[6]Christopher Anderson, Paola Giannini, and Sophia Drossopoulou. 2005. To-
wards type inference for JavaScript. In European conference on Object-oriented
programming . Springer, 428â€“452.
[7]Brett Cannon. 2005. Localized type inference of atomic types in python . Ph.D.
Dissertation. Citeseer.
[8]Sheng Chen and Martin Erwig. 2014. Counter-Factual Typing for Debugging
Type Errors. SIGPLAN Not. 49, 1 (jan 2014), 583â€“594. https://doi.org/10.1145/
2578855.2535863
[9]Xi Cheng, Min Zhou, Xiaoyu Song, Ming Gu, and Jiaguang Sun. 2017. IntPTI:
automatic integer error repair with proper-type inference. In Proceedings of the
32nd IEEE/ACM International Conference on Automated Software Engineering, ASE
2017, Urbana, IL, USA, October 30 - November 03, 2017 , Grigore Rosu, Massim-
iliano Di Penta, and Tien N. Nguyen (Eds.). IEEE Computer Society, 996â€“1001.
https://doi.org/10.1109/ASE.2017.8115718[10] Wontae Choi, Satish Chandra, George Necula, and Koushik Sen. 2015. SJS: A type
system for JavaScript with fixed object layout. In International Static Analysis
Symposium . Springer, 181â€“198.
[11] Zack Coker and Munawar Hafiz. 2013. Program transformations to fix C integers.
In35th International Conference on Software Engineering, ICSE â€™13, San Francisco,
CA, USA, May 18-26, 2013 , David Notkin, Betty H. C. Cheng, and Klaus Pohl (Eds.).
IEEE Computer Society, 792â€“801. https://doi.org/10.1109/ICSE.2013.6606625
[12] Thomas Durieux, Benoit Cornu, Lionel Seinturier, and Martin Monperrus. 2017.
Dynamic patch generation for null pointer exceptions using metaprogramming.
In2017 IEEE 24th International Conference on Software Analysis, Evolution and
Reengineering (SANER) . 349â€“358. https://doi.org/10.1109/SANER.2017.7884635
[13] Madeline Endres, Georgios Sakkas, Benjamin Cosman, Ranjit Jhala, and Westley
Weimer. 2019. InFix: Automatically Repairing Novice Program Inputs. In 2019
34th IEEE/ACM International Conference on Automated Software Engineering (ASE) .
399â€“410. https://doi.org/10.1109/ASE.2019.00045
[14] Michael Furr, Jong-hoon An, and Jeffrey S Foster. 2009. Profile-guided static
typing for dynamic scripting languages. In Proceedings of the 24th ACM SIGPLAN
conference on Object oriented programming systems languages and applications .
283â€“300.
[15] Michael Furr, Jong-hoon An, Jeffrey S Foster, and Michael Hicks. 2009. Static
type inference for Ruby. In Proceedings of the 2009 ACM symposium on Applied
Computing . 1859â€“1866.
[16] Qing Gao, Yingfei Xiong, Yaqing Mi, Lu Zhang, Weikun Yang, Zhaoping Zhou,
Bing Xie, and Hong Mei. 2015. Safe Memory-Leak Fixing for C Programs. In
2015 IEEE/ACM 37th IEEE International Conference on Software Engineering , Vol. 1.
459â€“470. https://doi.org/10.1109/ICSE.2015.64
[17] Michael Gorbovitski, Yanhong A Liu, Scott D Stoller, Tom Rothamel, and Tuncay K
Tekle. 2010. Alias analysis for optimization of dynamic languages. In Proceedings
of the 6th Symposium on Dynamic Languages . 27â€“42.
[18] Claire Le Goues, ThanhVu Nguyen, Stephanie Forrest, and Westley Weimer. 2012.
GenProg: A Generic Method for Automatic Software Repair. IEEE Trans. Software
Eng. 38, 1 (2012), 54â€“72. https://doi.org/10.1109/TSE.2011.104
[19] Sumit Gulwani, Ivan RadiÄek, and Florian Zuleger. 2018. Automated Clustering
and Program Repair for Introductory Programming Assignments. In Proceedings
of the 39th ACM SIGPLAN Conference on Programming Language Design and Im-
plementation (Philadelphia, PA, USA) (PLDI 2018) . Association for Computing Ma-
chinery, New York, NY, USA, 465â€“480. https://doi.org/10.1145/3192366.3192387
[20] Brian Hackett and Shu-yu Guo. 2012. Fast and precise hybrid type inference for
JavaScript. ACM SIGPLAN Notices 47, 6 (2012), 239â€“250.
[21] Mostafa Hassan, Caterina Urban, Marco Eilers, and Peter MÃ¼ller. 2018. MaxSMT-
based type inference for Python 3. In International Conference on Computer Aided
Verification . Springer, 12â€“19.
[22] Phillip Heidegger and Peter Thiemann. 2010. Recency types for analyzing script-
ing languages. In European conference on Object-oriented programming . Springer,
200â€“224.
[23] David L Heine and Monica S Lam. 2003. A practical flow-sensitive and context-
sensitive C and C++ memory leak detector. In Proceedings of the ACM SIGPLAN
2003 conference on Programming language design and implementation . 168â€“181.
[24] Seongjoon Hong, Junhee Lee, Jeongsoo Lee, and Hakjoo Oh. 2020. SAVER:
Scalable, Precise, and Safe Memory-Error Repair. In Proceedings of the ACM/IEEE
42nd International Conference on Software Engineering (Seoul, South Korea) (ICSE
â€™20). Association for Computing Machinery, New York, NY, USA, 271â€“283. https:
//doi.org/10.1145/3377811.3380323ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore Wonseok Oh and Hakjoo Oh
[25] Yang Hu, Umair Z. Ahmed, Sergey Mechtaev, Ben Leong, and Abhik Roychoud-
hury. 2019. Re-Factoring Based Program Repair Applied to Programming Assign-
ments. In 2019 34th IEEE/ACM International Conference on Automated Software
Engineering (ASE) . 388â€“398. https://doi.org/10.1109/ASE.2019.00044
[26] Zhen Huang, David Lie, Gang Tan, and Trent Jaeger. 2019. Using Safety Properties
to Generate Vulnerability Patches. In 2019 IEEE Symposium on Security and
Privacy, SP 2019, San Francisco, CA, USA, May 19-23, 2019 . IEEE, 539â€“554. https:
//doi.org/10.1109/SP.2019.00071
[27] Dropbox Inc. 2018. PyAnnotate: Auto-generate PEP-484 annotations. https:
//github.com/dropbox/pyannotate.
[28] Simon Holm Jensen, Anders MÃ¸ller, and Peter Thiemann. 2009. Type analysis
for JavaScript. In International Static Analysis Symposium . Springer, 238â€“255.
[29] Jiajun Jiang, Yingfei Xiong, Hongyu Zhang, Qing Gao, and Xiangqun Chen.
2018. Shaping program repair space with existing patches and similar code. In
Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing
and Analysis, ISSTA 2018, Amsterdam, The Netherlands, July 16-21, 2018 , Frank Tip
and Eric Bodden (Eds.). ACM, 298â€“309. https://doi.org/10.1145/3213846.3213871
[30] Guoliang Jin, Linhai Song, Wei Zhang, Shan Lu, and Ben Liblit. 2011. Automated
atomicity-violation fixing. In Proceedings of the 32nd ACM SIGPLAN Conference
on Programming Language Design and Implementation, PLDI 2011, San Jose, CA,
USA, June 4-8, 2011 , Mary W. Hall and David A. Padua (Eds.). ACM, 389â€“400.
https://doi.org/10.1145/1993498.1993544
[31] RenÃ© Just, Darioush Jalali, and Michael D. Ernst. 2014. Defects4J: A Database
of Existing Faults to Enable Controlled Testing Studies for Java Programs. In
Proceedings of the 2014 International Symposium on Software Testing and Analysis
(San Jose, CA, USA) (ISSTA 2014) . Association for Computing Machinery, New
York, NY, USA, 437â€“440. https://doi.org/10.1145/2610384.2628055
[32] Faizan Khan, Boqi Chen, Daniel Varro, and Shane Mcintosh. 2021. An Empirical
Study of Type-Related Defects in Python Projects. IEEE Transactions on Software
Engineering (2021), 1â€“1. https://doi.org/10.1109/TSE.2021.3082068
[33] Dongsun Kim, Jaechang Nam, Jaewoo Song, and Sunghun Kim. 2013. Automatic
patch generation learned from human-written patches. In 35th International
Conference on Software Engineering, ICSE â€™13, San Francisco, CA, USA, May 18-26,
2013, David Notkin, Betty H. C. Cheng, and Klaus Pohl (Eds.). IEEE Computer
Society, 802â€“811. https://doi.org/10.1109/ICSE.2013.6606626
[34] Xuan-Bach Dinh Le, Duc-Hiep Chu, David Lo, Claire Le Goues, and Willem Visser.
2017. JFIX: semantics-based repair of Java programs via symbolic PathFinder.
InProceedings of the 26th ACM SIGSOFT International Symposium on Software
Testing and Analysis, Santa Barbara, CA, USA, July 10 - 14, 2017 , Tevfik Bultan
and Koushik Sen (Eds.). ACM, 376â€“379. https://doi.org/10.1145/3092703.3098225
[35] Xuan-Bach Dinh Le, Duc-Hiep Chu, David Lo, Claire Le Goues, and Willem
Visser. 2017. S3: syntax- and semantic-guided repair synthesis via programming
by examples. In Proceedings of the 2017 11th Joint Meeting on Foundations of
Software Engineering, ESEC/FSE 2017, Paderborn, Germany, September 4-8, 2017 ,
Eric Bodden, Wilhelm SchÃ¤fer, Arie van Deursen, and Andrea Zisman (Eds.).
ACM, 593â€“604. https://doi.org/10.1145/3106237.3106309
[36] Junhee Lee, Seongjoon Hong, and Hakjoo Oh. 2018. MemFix: Static Analysis-
Based Repair of Memory Deallocation Errors for C. In Proceedings of the 2018 26th
ACM Joint Meeting on European Software Engineering Conference and Symposium
on the Foundations of Software Engineering (Lake Buena Vista, FL, USA) (ESEC/FSE
2018) . Association for Computing Machinery, New York, NY, USA, 95â€“106. https:
//doi.org/10.1145/3236024.3236079
[37] Junhee Lee, Seongjoon Hong, and Hakjoo Oh. 2022. NPEX: Repairing Java
Null Pointer Exceptions without Tests. In International Conference on Software
Engineering .
[38] Huarui Lin, Zan Wang, Shuang Liu, Jun Sun, Dongdi Zhang, and Guangning
Wei. 2018. PFix: fixing concurrency bugs based on memory access patterns. In
Proceedings of the 33rd ACM/IEEE International Conference on Automated Software
Engineering, ASE 2018, Montpellier, France, September 3-7, 2018 , Marianne Huchard,
Christian KÃ¤stner, and Gordon Fraser (Eds.). ACM, 589â€“600. https://doi.org/10.
1145/3238147.3238198
[39] Haopeng Liu, Yuxi Chen, and Shan Lu. 2016. Understanding and generating high
quality patches for concurrency bugs. In Proceedings of the 24th ACM SIGSOFT
International Symposium on Foundations of Software Engineering, FSE 2016, Seattle,
WA, USA, November 13-18, 2016 , Thomas Zimmermann, Jane Cleland-Huang, and
Zhendong Su (Eds.). ACM, 715â€“726. https://doi.org/10.1145/2950290.2950309
[40] Fan Long and Martin Rinard. 2015. Staged program repair with condition syn-
thesis. In Proceedings of the 2015 10th Joint Meeting on Foundations of Software
Engineering, ESEC/FSE 2015, Bergamo, Italy, August 30 - September 4, 2015 , Elis-
abetta Di Nitto, Mark Harman, and Patrick Heymans (Eds.). ACM, 166â€“178.
https://doi.org/10.1145/2786805.2786811
[41] Fan Long and Martin Rinard. 2016. Automatic patch generation by learning
correct code. In Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT Symposium
on Principles of Programming Languages, POPL 2016, St. Petersburg, FL, USA,
January 20 - 22, 2016 , Rastislav BodÃ­k and Rupak Majumdar (Eds.). ACM, 298â€“312.
https://doi.org/10.1145/2837614.2837617[42] Sergey Mechtaev, Jooyong Yi, and Abhik Roychoudhury. 2015. DirectFix: Looking
for Simple Program Repairs. In 37th IEEE/ACM International Conference on Soft-
ware Engineering, ICSE 2015, Florence, Italy, May 16-24, 2015, Volume 1 , Antonia
Bertolino, Gerardo Canfora, and Sebastian G. Elbaum (Eds.). IEEE Computer
Society, 448â€“458. https://doi.org/10.1109/ICSE.2015.63
[43] Sergey Mechtaev, Jooyong Yi, and Abhik Roychoudhury. 2016. Angelix: scalable
multiline program patch synthesis via symbolic analysis. In Proceedings of the
38th International Conference on Software Engineering, ICSE 2016, Austin, TX, USA,
May 14-22, 2016 , Laura K. Dillon, Willem Visser, and Laurie A. Williams (Eds.).
ACM, 691â€“701. https://doi.org/10.1145/2884781.2884807
[44] Amir M. Mir, Evaldas LatoÅ¡kinas, and Georgios Gousios. 2021. ManyTypes4Py: A
Benchmark Python Dataset for Machine Learning-based Type Inference. In 2021
IEEE/ACM 18th International Conference on Mining Software Repositories (MSR) .
585â€“589. https://doi.org/10.1109/MSR52588.2021.00079
[45] Suchita Mukherjee, Abigail Almanza, and Cindy Rubio-GonzÃ¡lez. 2021. Fixing
Dependency Errors for Python Build Reproducibility. In Proceedings of the 30th
ACM SIGSOFT International Symposium on Software Testing and Analysis (Virtual,
Denmark) (ISSTA 2021) . Association for Computing Machinery, New York, NY,
USA, 439â€“451. https://doi.org/10.1145/3460319.3464797
[46] Paul Muntean, Martin Monperrus, Hao Sun, Jens Grossklags, and Claudia Eckert.
2021. IntRepair: Informed Repairing of Integer Overflows. IEEE Trans. Software
Eng. 47, 10 (2021), 2225â€“2241. https://doi.org/10.1109/TSE.2019.2946148
[47] Hoang Duong Thien Nguyen, Dawei Qi, Abhik Roychoudhury, and Satish Chan-
dra. 2013. SemFix: program repair via semantic analysis. In 35th International
Conference on Software Engineering, ICSE â€™13, San Francisco, CA, USA, May 18-26,
2013, David Notkin, Betty H. C. Cheng, and Klaus Pohl (Eds.). IEEE Computer
Society, 772â€“781. https://doi.org/10.1109/ICSE.2013.6606623
[48] Yun Peng, Cuiyun Gao, Zongjie Li, Bowei Gao, David Lo, Qirun Zhang, and
Michael Lyu. 2022. Static Inference Meets Deep Learning: A Hybrid Type
Inference Approach for Python. In Proceedings of the 44th International Con-
ference on Software Engineering (Pittsburgh, Pennsylvania) (ICSE â€™22) . Asso-
ciation for Computing Machinery, New York, NY, USA, 2019â€“2030. https:
//doi.org/10.1145/3510003.3510038
[49] Michael Pradel, Georgios Gousios, Jason Liu, and Satish Chandra. 2020. Type-
Writer: Neural Type Prediction with Search-Based Validation. In Proceedings
of the 28th ACM Joint Meeting on European Software Engineering Conference
and Symposium on the Foundations of Software Engineering (Virtual Event, USA)
(ESEC/FSE 2020) . Association for Computing Machinery, New York, NY, USA,
209â€“220. https://doi.org/10.1145/3368089.3409715
[50] Michael Pradel, Parker Schuh, and Koushik Sen. 2015. TypeDevil: Dynamic type
inconsistency analysis for JavaScript. In 2015 IEEE/ACM 37th IEEE International
Conference on Software Engineering , Vol. 1. IEEE, 314â€“324.
[51] Georgios Sakkas, Madeline Endres, Benjamin Cosman, Westley Weimer, and
Ranjit Jhala. 2020. Type Error Feedback via Analytic Program Repair. In Proceed-
ings of the 41st ACM SIGPLAN Conference on Programming Language Design and
Implementation (London, UK) (PLDI 2020) . Association for Computing Machinery,
New York, NY, USA, 16â€“30. https://doi.org/10.1145/3385412.3386005
[52] Alex Shaw, Dusten Doggett, and Munawar Hafiz. 2014. Automatically Fixing
C Buffer Overflows Using Program Transformations. In 44th Annual IEEE/IFIP
International Conference on Dependable Systems and Networks, DSN 2014, Atlanta,
GA, USA, June 23-26, 2014 . IEEE Computer Society, 124â€“135. https://doi.org/10.
1109/DSN.2014.25
[53] Tatsuya Sonobe, Kohei Suenaga, and Atsushi Igarashi. 2014. Automatic Memory
Management Based on Program Transformation Using Ownership. In Asian
Symposium on Programming Languages and Systems . Springer, 58â€“77.
[54] Kohei Suenaga and Naoki Kobayashi. 2009. Fractional ownerships for safe mem-
ory deallocation. In Asian Symposium on Programming Languages and Systems .
Springer, 128â€“143.
[55] Yuchi Tian and Baishakhi Ray. 2017. Automatically diagnosing and repairing error
handling bugs in C. In Proceedings of the 2017 11th Joint Meeting on Foundations
of Software Engineering, ESEC/FSE 2017, Paderborn, Germany, September 4-8, 2017 ,
Eric Bodden, Wilhelm SchÃ¤fer, Arie van Deursen, and Andrea Zisman (Eds.).
ACM, 752â€“762. https://doi.org/10.1145/3106237.3106300
[56] Westley Weimer, ThanhVu Nguyen, Claire Le Goues, and Stephanie Forrest. 2009.
Automatically finding patches using genetic programming. In 31st International
Conference on Software Engineering, ICSE 2009, May 16-24, 2009, Vancouver, Canada,
Proceedings . IEEE, 364â€“374. https://doi.org/10.1109/ICSE.2009.5070536
[57] Ratnadira Widyasari, Sheng Qin Sim, Camellia Lok, Haodi Qi, Jack Phan, Qijin
Tay, Constance Tan, Fiona Wee, Jodie Ethelda Tan, Yuheng Yieh, Brian Goh,
Ferdian Thung, Hong Jin Kang, Thong Hoang, David Lo, and Eng Lieh Ouh. 2020.
BugsInPy: A Database of Existing Bugs in Python Programs to Enable Controlled
Testing and Debugging Studies. In Proceedings of the 28th ACM Joint Meeting on
European Software Engineering Conference and Symposium on the Foundations
of Software Engineering (Virtual Event, USA) (ESEC/FSE 2020) . Association for
Computing Machinery, New York, NY, USA, 1556â€“1560. https://doi.org/10.1145/
3368089.3417943
[58] Yingfei Xiong, Jie Wang, Runfa Yan, Jiachen Zhang, Shi Han, Gang Huang, and
Lu Zhang. 2017. Precise condition synthesis for program repair. In Proceedings ofPyTER : Effective Program Repair for Python Type Errors ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore
the 39th International Conference on Software Engineering, ICSE 2017, Buenos Aires,
Argentina, May 20-28, 2017 , SebastiÃ¡n Uchitel, Alessandro Orso, and Martin P.
Robillard (Eds.). IEEE / ACM, 416â€“426. https://doi.org/10.1109/ICSE.2017.45
[59] Xuezheng Xu, Yulei Sui, Hua Yan, and Jingling Xue. 2019. VFix: Value-Flow-
Guided Precise Program Repair for Null Pointer Dereferences. In 2019 IEEE/ACM
41st International Conference on Software Engineering (ICSE) . 512â€“523. https:
//doi.org/10.1109/ICSE.2019.00063
[60] Jifeng Xuan, Matias Martinez, Favio Demarco, Maxime Clement, Sebastian
R. Lamelas Marcote, Thomas Durieux, Daniel Le Berre, and Martin Monperrus.2017. Nopol: Automatic Repair of Conditional Statement Bugs in Java Programs.
IEEE Trans. Software Eng. 43, 1 (2017), 34â€“55. https://doi.org/10.1109/TSE.2016.
2560811
[61] Hua Yan, Yulei Sui, Shiping Chen, and Jingling Xue. 2016. Automated memory leak
fixing on value-flow slices for C programs. In Proceedings of the 31st Annual ACM
Symposium on Applied Computing, Pisa, Italy, April 4-8, 2016 , Sascha Ossowski
(Ed.). ACM, 1386â€“1393. https://doi.org/10.1145/2851613.2851773