Nalin: Learning from Runtime Behavior to Find
Name-Value Inconsistencies in Jupyter Notebooks
Jibesh Patra
University of Stuttgart
Germany
jibesh.patra@gmail.comMichael Pradel
University of Stuttgart
Germany
michael@binaervarianz.de
ABSTRACT
Variable names are important to understand and maintain code. If
a variable name and the value stored in the variable do not match,
thentheprogramsuffersfroma name-valueinconsistency,whichis
duetooneoftwosituationsthatdevelopersmaywanttofix:Either
a correct value is referred to through a misleading name, which
negatively affects code understandability and maintainability, orthe correct name is bound to a wrong value, which may cause
unexpected runtime behavior. Finding name-value inconsistencies
is hard because it requires an understanding of the meaning ofnames and knowledge about the values assigned to a variable atruntime.ThispaperpresentsNalin,atechniquetoautomaticallydetect name-value inconsistencies. The approach combines ady-namic analysis that tracks assignments of values to names witha neural machine learning model that predicts whether a nameand a value fit together. To the best of our knowledge, this is thefirst work to formulate the problem of finding coding issues as aclassification problem over names and runtime values. We apply
Nalinto106,652real-worldPythonprograms,wheremeaningful
namesareparticularlyimportantduetotheabsenceofstaticallyde-claredtypes.Ourresultsshowthattheclassifierdetectsname-value
inconsistencies with high accuracy, that the warnings reported by
Nalin have a precision of 80% and a recall of 76% w.r.t. a ground
truth created in a user study, and that our approach complements
existing techniques for finding coding issues.
CCS CONCEPTS
â€¢Softwareanditsengineering â†’Softwaremaintenancetools;
Software post-development issues;
KEYWORDS
Neural software analysis, identifier names, learning-based bug de-
tection
ACM Reference Format:
Jibesh Patra and Michael Pradel. 2022. Nalin: Learning from Runtime
Behavior to Find Name-Value Inconsistencies in Jupyter Notebooks . In
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Â© 2022 Association for Computing Machinery.
ACM ISBN 978-1-4503-9221-1/22/05...$15.00
https://doi.org/10.1145/3510003.351014444thInternationalConferenceonSoftwareEngineering(ICSEâ€™22),May21â€“
29, 2022, Pittsburgh, PA, USA. ACM, New York, NY, USA, 13 pages. https:
//doi.org/10.1145/3510003.3510144
1 INTRODUCTION
Variable names are a means to convey the intended semantics of
code. Because meaningful names are crucial for the understand-
ability and maintainability of code [ 15], developers generally try
to name a variable according to the value(s) it refers to. Names are
particularly relevant in dynamically typed languages, e.g., Python
andJavaScript,wherethelackoftypesforcesdeveloperstorelyon
names, e.g., to understand what types of values a variable stores.
Unfortunately, the name and the value of a variables sometimes
donotmatch,whichwerefertoasa name-valueinconsistency.A
common reason is a misleading name that is bound to a correct
value. Because such names make code unnecessarily hard to un-
derstand and maintain, developers may want to replace them with
moremeaningfulnames.Anotherpossiblereasonisthatamean-
ingfulnamereferstoan incorrectvalue.Becausesuchvaluesmay
propagate through the program and cause unexpected behavior,
developers should fix the corresponding code.
The following illustrates the problem with two motivating ex-
amples, both found during our evaluation on real-world Python
code[49].Asanexampleofamisleadingnameconsiderthefollow-
ing code:
log_file = glob.glob('/var/www/some_file.csv')
The right-hand side of the assignment yields a list of file names,
whichisinconsistentwiththenameofthevariableitgetsassigned
to,because log_file suggestsasinglefilename.Thecodeiseven
more confusing since this specific call to globwill return a list
with at most one file name. That is, a cursory reader of the code
mayincorrectlyassumethisfilenametobestoredinthe log_file
variable, whereas it is actually wrapped into a list. To clarify the
meaning of the variable, it could be named, e.g., log_files or
log_file_list , or the developer could adapt the right-hand side
oftheassignmentbyretrievingthefirst(andonly)elementfrom
the list. We find misleading names to be the most common reason
for name-value inconsistencies.
Lesscommon,butperhapsevenworse,arename-valueinconsis-
tenciescausedbyanincorrectvalue,asinthefollowingexample:
train_size = 0.9* iris.data.shape[0]
test_size = iris.data.shape[0] - train_size
train_data = data[0:train_size]
The code tries to divide a dataset into training and test sets. Names
liketrain_size areusuallyboundtonon-negativeintegervalues.
However,theabovecodeassignsthevalue135.0tothe train_size
14692022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:28:46 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Jibesh Patra and Michael Pradel
variable,i.e.,afloatingpointvalue.Unfortunately,thisvaluecauses
thecodetocrashatthethirdline,where train_size isusedasan
indextoslicethedataset,butindicesforslicingmustbeintegers.
Whiletherootcauseandthemanifestationofthecrashareclose
toeachotherinthissimpleexample,ingeneral,incorrectvalues
maypropagatethroughaprogramandcausehardtounderstand
misbehavior.
Findingname-valueinconsistenciesisdifficultbecauseitrequires
both understanding the meaning of names and realizing that a
value that occurs at runtime does not match the usual meaning of
a name. As a result, name-value inconsistencies so far are found
mostly during some manual activity. For example, a developer may
point out a misleading name during code review, or a developer
may stumble across an incorrect value during debugging. Because
developer time is precious, tool support for finding name-value
inconsistencies is highly desirable.
Thispaperpresents Nalin,anapproachfordetecting name-value
inconsistencies automatically. The approach combines dynamic
programanalysiswithdeeplearning.Atfirst,adynamicanalysis
keeps track of assignments during an execution and gathers pairs
of names and values the names are bound to. Then, a neural model
predictswhetheranameandavaluefittogether.Whenthedynamic
analysis observes a name-value pair that the neural model predicts
to not fit together, then the approach reports a warning about a
likely name-value inconsistency.
Whilesimpleatitscore,realizingtheNalinideainvolvesfour
key challenges:
C1Understandingthesemanticsofnamesandhowdeveloperstyp-icallyusethem.Theapproachaddressesthischallengethrough
alearnedtokenembeddingthatrepresentssemanticsimilari-
ties of names in a vector space. For example, the embedding
mapsthenames train_size ,size,andlentosimilarvectors,
as they refer to similar concepts.
C2Understanding the meaning of values and how developers
typicallyusethem.Theapproachaddressesthischallengeby
recording runtimevalues andby encodingthem intoa vector
representation based on several properties of values. The prop-
erties include a string representation of the value, its type, and
type-specific features, such as the shape of multi-dimensional
numeric values.
C3Pinpointingunusualname-valuepairs.Weformulatethisprob-
lem as a binary classification task and train a neural modelthatpredictswhetheranameandavaluematch.Tothebest
of our knowledge, this work is the first to detect coding issues
through neural classification over names and runtime values.
C4Obtaining a dataset for training an effective model. The ap-
proachaddressesthischallengebyconsideringobservedname-
valuepairsascorrectexamples,andbycreatingincorrectex-
amplesbycombiningnamesandvaluesthroughastatistical,
type-guided sampling that is likely to yield an incorrect pair.
Our work relates to learning-based bug detectors [ 6,18,33,
47,57], which share the idea to classify code as correct or in-
correct. However, we are the first to focus on name-value incon-sistencies, whereas prior work targets other kinds of problems.
Nalin alsorelates to learnedmodels that predictmissing identifier
names [12,17,48]. Our work differs by analyzing code with namessupposed to be meaningful, instead of targeting obfuscated or com-
piledcode.Finally,therearestaticanalysis-basedapproachesfor
findinginconsistentmethodnames[ 26,34,38]andothernaming
issues[22].AkeydifferencetoalltheaboveworkisthatNalinis
based on dynamic instead of static analysis, allowing it to learn
fromruntimevalues,whichstaticanalysiscanonlyapproximate.
One of the few existing approaches that learn from runtime behav-
ior [56] aims at finding vector representations for larger pieces of
code, but cannot pinpoint name-value inconsistencies.
We train Nalin on 780k name-value pairs and evaluate it on 10k
previously unseen pairs from real-world Python code extracted
fromJupyternotebooks.Themodeleffectivelydistinguishescon-
sistentfrom inconsistentexamples,with anF1scoreof 0.89.Com-
paring the classifications by Nalin to a ground truth gathered in
astudywithelevendevelopersshowsthatthereportedinconsis-
tencies have a precision of 80% and a recall of 76%. Most of the
inconsistenciesdetectedinreal-worldcodeareduetomisleading
names, but there also are some inconsistencies caused by incorrect
values.Finally,weshowthattheapproachcomplementsstate-of-
the-artstaticanalysis-basedtoolsthatwarnaboutfrequentlymade
mistakes, type-related issues, and name-related bugs.
In summary, this paper contributes the following:
â—An automatic technique to detect name-value inconsistencies.
â—The first approach to find coding issues through neural machine
learning on names and runtime behavior.
â—A type-guided generation of negative examples that improves
upon a purely random approach.
â—Empirical evidence that the approach effectively identifies name-
value pairs that developers perceive as detrimental to the under-
standability and maintainability of the code.
2 OVERVIEW
Thissectiondescribestheproblemweaddressandgivesanoverview
ofourapproach.Nalinreasonsabout name-valuepairs,i.e.,pairs
of a variable name and a value that gets assigned to the variable.
The problem we address is to identify name-value pairs where
the name is not a good fit for the value, which we call inconsis-
tent name-value pairs. Identifying such pairs is an inherently fuzzy
problem: Whether a name fits a value depends on the conventions
that programmers follow when naming variables. The fuzzinessof the problem motivates a data-driven approach [
45], where we
usethevastamountsofavailableprogramsasguidanceforwhat
name-value pairs are common and what name-value pairs stand
out as inconsistent.
Broadly speaking, Nalin consists of six components and two
phases, illustrated in Figure 1. During the training phase, the ap-
proachlearnsfromacorpusofexecutableprogramsaneuralclassi-
ficationmodel,whichthenservesduringthepredictionphasefor
identifyingname-valueinconsistenciesinpreviouslyunseenpro-
grams.Thefollowingillustratesthesixcomponentsoftheapproach
with some examples. A detailed description follows in Section 3.
Given a corpus of executable programs, the first component
is a dynamic analysis of assignments of values to variables. For
each assignment during the execution of the program, the analysis
extracts the variable name, the value assigned to the variable, and
several properties of the value, e.g., the type, length, and shape. As
1470
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:28:46 UTC from IEEE Xplore.  Restrictions apply. Learning from Runtime Behavior to Find Name-Value Inconsistencies ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Name-value
pairsTraining
PredictionTrain neuralmodel4
Representationas vectors3Generation ofnegative examples2
Query neuralmodel5Previously unseenexecutable programs
...name = 2.5
file_name = compute ()
...
Name-valueinconsistencies
name = 2.5!Executable programs
...age = arr[i]probability = get_prob (data)
Xs_train = load_data()...
Name Value Type Length Shape
age 23 int null null
probability 0.83 oat null null
Xs_train [[0.5 2.3]\n [.. ndarray 600 (600, 2)
name 2.5 oat null null
file_name â€˜example.txtâ€™ str 11 nullDynamic analysisof assignments1
Heuristic ltering of
meaningless names6
Figure 1: Overview of the approach.
illustratedinFigure1,propertiesthatdonotexistforaparticular
value are represented by null. For example, the analysis extracts
thelengthoftheassignedvaluefor Xs_train ,butnotfor ageand
probability ,asthecorrespondingvaluesareprimitivesthatdo
not have a length.
Whilethename-valuepairsobtainedbythedynamicanalysis
serve as positive examples, the second component generates nega-
tive examples that combine names and values in an unusual and
likelyinconsistentway.Themotivationbehindgeneratingnegative
examples is that Nalin trains a classification model in a supervised
manner,i.e.,theapproachrequiresexamplesofbothconsistentand
inconsistent name-value pairs. Using the example pairs in Figure 1,
one negative example would be the name Xs_train paired with
the floating point value 0.83, which indeed is an unusual name-
value pair. Our approach for generating negative examples is a
probabilistic algorithmthat biasesthe selectionof unusualvalues
toward unusual types based on the types of values that are usually
observed with a name. The first and second component together
addresschallengeC4fromtheintroduction,i.e.,obtainingadataset
for training an effective model.
ThethirdcomponentofNalinaddresseschallengesC1andC2,
i.e.,â€œunderstandingâ€thesemanticsofnamesandvalues.Tothisend,
the approach represents names and values as vectors that preserve
theirmeaning.Torepresentidentifiernames,webuildonlearned
token embeddings [ 13], which map each name into a vector while
preserving the semantic similarities of names [ 54]. For example,
the vector of probability will be close to the vectors of names
probabandlikelihood ,becausethesenamesrefertosimilarcon-
cepts. To represent values, we present a neural encoding of values
based on their string representation, type, and other properties.
Giventhevectorrepresentationsofname-valuepairs,thefourth
component trains a neural model to distinguish positive from neg-
ative examples. The result is a classifier that, once trained with
sufficiently many examples, addresses challenge C3. The fifth com-
ponent of the approach queries the classifier with vector repre-
sentationsofname-valuepairsextractedfrompreviouslyunseen
programs, producing a set of pairs predicted to be inconsistent.
Thefinalcomponentheuristicallyfilterspairsthatarelikelyfalse
positives, and then reports the remaining pairs as warnings to the
developer. For the two new assignments shown in Figure 1, thetrained classifier will correctly identify the assignment name =
2.5as unusual and raises a warning.
3 APPROACH
The following presents the components of Nalin outlined in the
previous section in more detail.
3.1 Dynamic Analysis of Assignments
The goal of thiscomponent is to gather name-valuepairs from a
corpus of programs. Our analysis focuses on assignments because
theyassociateavaluewiththenameofavariable.Oneoptionwould
betostaticallyanalyzeallassignmentsinaprogram.However,a
static analysis could capture only those values where the right-
hand side of an assignment is a literal, but would miss many other
assignments,e.g.,whentheright-handsideisacomplexexpression
or function call. In the code corpus used in our evaluation, we find
that 90% of all assignments have a value other than a primitive
literal on the right-hand side, i.e., a static analysis could not gather
name-valuepairsfromthem.Instead,Nalinusesadynamicanalysis
thatobservesallassignmentsduringtheexecutionofaprogram.
Besidesthebenefitofcapturingassignmentsthatarehardtoreason
about statically, a dynamic analysis can easily extract additional
properties of values, such as the length or shape, which we find to
be useful for training an effective model.
3.1.1 Instrumentation and Data Gathering. Todynamicallyanalyze
assignments, Nalin instruments and then executes the programs in
the corpus. For instrumentation, the analysis traverses the abstract
syntaxtreeofaprogramandaugmentsallassignmentstoavariable
withacalltoafunctionthatrecordsthenameofthevariableand
the assigned value.
Asruntimevaluescanbearbitrarilycomplex,theanalysiscan
extract only limited information about a value. We extract four
properties of eachvalue, which wefound to be usefulfor training
aneffectivemodel,butextendingtheapproachtogatheradditional
propertiesofvaluesisstraightforward.Slightlyabusingtheterm
â€œpairâ€toincludethepropertiesextractedforeachvalue,theanalysis
extracts the following information:
Definition 1 (Name-value pair). A name-value pair is a tuple
(ð‘›,ð‘£,ðœ,ð‘™,ð‘ ), whereð‘›denotes the variable name on the left hand
1471
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:28:46 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Jibesh Patra and Michael Pradel
side,ð‘£is a string representation of the value, ðœrepresents the type
ofthevalue,and ð‘™andð‘ representthelengthandshapeofthevalue,
respectively.
ThestringrepresentationbuildsuponPythonâ€™sbuilt-instring
conversion,whichoftenyieldsameaningfulrepresentationbecause
developerscommonlyusethisrepresentation,e.g.,fordebugging.
The type of values is relevant because it allows Nalin to find type-
related mistakes, which otherwise remain easily unnoticed in a
dynamicallytypedlanguage.Lengthherereferstothenumberof
itemspresentinacollectionorsequencetypevalue,whichisuseful,
e.g., to enable the model to distinguish empty from non-empty
collections.Sincesomecommondatatypesaremultidimensional
theshaperefers to the number of items present in each dimension.
ThetableinFigure1showsexamplesofname-valuepairsgathered
bytheanalysis.Weshowintheevaluationhowmuchtheextracted
properties contribute to the overall effectiveness of the model.
3.1.2 Filtering and Processing of Name-Value Pairs.
Merge Types. We observe that the gathered data forms a long-
taileddistributionoftypes.Oneofthereasonsisthepresenceof
manysimilartypes,suchasPythonâ€™sdictionarytype dictandits
subclassdefaultdict. To help the model generalize across similar
types, we reduce the overall number of types by merging some of
the less frequent types. To this end, we first choose the ten most
frequent types present in the dataset. For the remaining types, we
replace any types that are in a subclass relationship with one of
the frequent types by the frequent type. For example, consider aname-value pair (stopwords,frozenset({"all", "afterwards", "eleven",
...}), frozenset, 337, null). Because type frozenset is not among the
ten most frequent types, but type setis, we change the name-value
pairinto (stopwords,frozenset({"all","afterwards","eleven",...}),set,
337, null).
FilterMeaninglessNames. AnunderlyingassumptionofNalin
isthatdevelopersusemeaningfulvariablenames.Unfortunately,
some names are rather cryptic, such as variables called aorts_pd.
Such names help neither our model nor developers in deciding
whetheranamefitsthevalueitrefersto,andhence,wefilterlikely
meaningless names. The first type of filtering considers the length
ofthevariablenamesanddiscardsanyname-valuepairswherethenameislessthanthreecharacterslong.Thesecondtypeoffiltering
is similar to the first one, except that it targets names composed of
multiplesubtokens,suchas ts_pd.Wesplitnamesatunderscores1,
and remove any name-value pairs where each subtoken has less
than three characters.
3.2 Generation of Negative Examples
The gathered name-value pairs provide numerous examples of
names and values that developers typically combine. Nalin uses su-
pervised learning to train a classification model that distinguishes
consistent, or positive, name-value pairs from inconsistent, or neg-
ative, pairs. Based on the common assumption that most code iscorrect, we consider the name-value pairs extracted from execu-
tions as positive examples. The following presents two techniques
1https://www.python.org/dev/peps/pep-0008/#function-and-variable-namesAlgorithm 1 Create a negative example
Input:Name-value pair(ð‘›,ð‘£,ðœ,ð‘™,ð‘ ), datasetð·of all pairs
Output: Negative example (ð‘›,ð‘£â€²,ðœâ€²,ð‘™â€²,ð‘ â€²)
1:ð¹globalâ†Computefrom ð·amapfromtypestotheirfrequency
2:ð¹nameâ†Compute from ð·andð‘›a map from types observed
withð‘›to their frequency
3:ð‘‡nameâ†âˆ… â–·Types seen with ð‘›
4:ð‘‡name_infreqâ†âˆ…â–·Types infrequently seen with ð‘›
5:for each (ðœâ†¦ð‘“)âˆˆð¹namedo
6:ð‘‡nameâ†ðœ
7:ifð‘“â‰¤threshold then
8: ð‘‡name_infreqâ†ðœ
9:ð‘‡allâ†dom(ð¹global) â–·All types ever seen
10:ð‘‡cand=(ð‘‡allâˆ–ð‘‡name)â‹ƒð‘‡name_infreqâ–·Types never or
infrequently seen with ð‘›
11:ðœâ€²â†weightedRandomChoice (ð‘‡cand,ð¹global)
12:ð‘£â€²,ð‘™â€²,ð‘ â€²â†randomChoice(ð·,ðœâ€²)
13:return(ð‘›,ð‘£â€²,ðœâ€²,ð‘™â€²,ð‘ â€²)
for generating negative examples. First, we explain a purely ran-
domtechnique,followedbyatype-guidedtechniquethatwefind
to yield a more effective training dataset.
3.2.1 Purely Random Generation. Ourpurelyrandomalgorithm
forgeneratingnegativeexamplesisstraightforward.Foreachname-
valuepair(ð‘›,ð‘£,ðœ,ð‘™,ð‘ ),thealgorithmrandomlyselectsanothername-
value pair(ð‘›â€²,ð‘£â€²,ðœâ€²,ð‘™â€²,ð‘ â€²)from the dataset. Then, the algorithm
creates a new negative example by combining the name of theoriginal pair and the value of the randomly selected pair, which
yields(ð‘›,ð‘£â€²,ðœâ€²,ð‘™â€²,ð‘ â€²).
Whilesimple,thepurelyrandomgenerationofnegativeexam-
plessuffersfromtheproblemofcreatingmanyname-valuepairs
that dofit welltogether. Theunderlying rootcause isthat thedis-
tributionofvaluesandtypesislong-tailed,i.e.,thedatasetcontains
manyexamplesofsimilarvaluesamongthemostcommontypes.
Forexample,considera name-valuepairgatheredfromanassign-
mentn u m=2 3 . When creating a negative example, the purely
randomalgorithmmaychooseavaluegatheredfromanotheras-
signment a g e=3. As both values are positive integers, they both
fitthename num,i.e.,thesupposedlynegativeexampleactuallyisa
legitimate name-value pair. Having many such legitimate, negative
examples in the training data makes it difficult for a classifier to
discriminatebetweenconsistentandinconsistentname-valuepairs.
3.2.2 Type-Guided Generation. Tomitigatetheproblemoflegiti-
mate,negativeexamplesthatthepurelyrandomgenerationalgo-
rithmsuffersfrom,wepresentatype-guidedalgorithmforcreating
negative examples. The basic idea is to first select a type that anameisinfrequentlyobservedwith,andtothenselectarandom
value among those observed with the selected type. Algorithm 1
showsthetype-guidedtechniqueforcreatinganegativeexample
for a given name-value pair. The inputs to the algorithm are a
name-valuepair(ð‘›,ð‘£,ðœ,ð‘™,ð‘ )andthe completedataset ð·of positive
name-value pairs.
ThefirsttwolinesofAlgorithm1createtwohelpermaps,which
map types to their frequency. The ð¹globalmap assigns each type to
1472
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:28:46 UTC from IEEE Xplore.  Restrictions apply. Learning from Runtime Behavior to Find Name-Value Inconsistencies ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
years  = [2011, 2012, 2013, 2014]
(n, v, , l, s) = (years, [2011, 2012, 2013, 2014], list, 4, null)
Fname = { list: 235, ndarray: 59, int: 33, 
    float: 7, dict: 5, tuple:4, set:1 }
Tname_infreq  = {float, dict, tuple, set}
Fglobal ={str: 89337, bool: 5385,
            float: 71244, dict: 21654,  }
 Weighted random selection of a target type:
 Random selection of a float  value from the dataset:
(n, v', ', l', s') = (years, 1.8 , oat, null, null) Infrequent types for years:   
 Global frequencies of types infrequently or never seen with years: Given name-value pair:
 All types years has been in the dataset and their frequencies:
'=float
Figure 2: Steps for creating a negative example.
itsfrequencyacrosstheentiredataset ð·,whereasthe ð¹namemap
assigns each type to how often it occurs with the name ð‘›of the
positive example. Next, lines 3 to 8 populate two sets of types. The
firstset,ð‘‡name,ispopulatedwithalltypeseverobservedwithname
ð‘›. The second set, ð‘‡name_infreq, is populated with all types that are
infrequentlyobservedwithname ð‘›.â€œInfrequentâ€heremeansthat
the frequency of the type among all name-value tuples with name
ð‘›is below some threshold, which is 3% in the evaluation. The goal
of selecting types that are infrequent for a particular name is to
createnegativeexamplesthat areunusual, andhence, likelyto be
inconsistent.
The remainder of the algorithm (lines 9 to 13) picks a type to be
usedforthe negativeexample andthencreates anegativename-
value pair by combining the name ð‘›with a value of that type.
To this end, the algorithm computes all candidates types, ð‘‡cand,
that are either never observed with name ð‘›or among the types
ð‘‡name_infreqthat infrequently occur with ð‘›. The algorithm then
randomly selects among the candidate types, using the global type
frequencyasweights fortherandomselection.The rationaleisto
chooseatypethatisunlikelyforthename ð‘›,whilefollowingthe
overall distribution of types. The latter is necessary to prevent the
modelfromsimplylearningtospotunlikelytypes,buttoinstead
learn to find unlikely combinations of names and values. Once the
targettype ðœâ€²forthenegativeexampleisselected,thealgorithm
randomly picks a value among all values (line 12) observed with
typeðœâ€²,andeventuallyreturnsanegativeexamplethatcombines
nameð‘›with the selected value.
Figure 2 illustrates the algorithm with an example from our
evaluation. The goal is to create a negative example for a name-
value pair where the name is years. In the dataset of positive
examples,thename yearsoccurswithvaluesoftypes list,ndarray,
int, etc., with the frequencies shown in the figure. For example,
yearsoccurs235timeswitha listvalue,butonlyseventimeswith
afloatvalue.Amongalltypesthatoccurinthedataset,manynever
occurtogetherwiththename years,e.g.,strandbool.Basedonthe
global frequencies of types that yearsnever or only infrequently
occurs with, the algorithm picks floatas the target type. Finally, aVari abl e 
name Val ue TypeLength of
valueShape of
value
n v  l s
Concat
Classier
Probability of being
inconsistentFastText
GRU
Convol uti on
one-hot
one-hot
one-hot
Figure 3: Architecture of the neural model.
corresponding floatvalue is selected from the dataset, which is 1.8
for the example, and the negative example shown at the bottom of
the figure is returned.
By default, Nalin uses the type-guided generation of negative
examples, and our evaluation compares it with the purely random
technique. The generated negative examples are combined with
the positive examples in the dataset, and the joint dataset serves as
trainingdatafortheneuralclassifier.Duetotheautomatedgenera-tion,ageneratednegativeexamplesmaycoincidentallybeidentical
toanexistingpositiveexample.Inpractice,thedatasetuseddur-
ingtheevaluationcontains38instancesofidenticalpositiveand
negative examples out of 490,332 negative examples.
3.3 Representation as Vectors
Givenadatasetofname-valuepairs,eachlabeledeitherasapositive
or a negative example, Nalin trains a neural classification model to
distinguishthetwokindsofexamples.Acrucialstepistorepresent
the information in a name-value pair as vectors, which we explain
inthefollowing.Theapproachfirstrepresentseachofthefivecom-ponents
(ð‘›,ð‘£,ðœ,ð‘™,ð‘ )ofaname-valuepairasavector,andthenfeeds
theconcatenationofthesevectorsintotheclassifier.Figure3showsanoverviewoftheneuralarchitecture.Thefollowingdescribesthe
vectorrepresentationinmoredetail,followedbyadescriptionof
the classifier in Section 3.4.
Representing Variable Names. To enable Nalin to reason about
the meaning of variable names, it maps each name into a vector
representationthatencodesthesemanticsofthename.Forexample,
the representation should map the names list_of_numbers and
integers to similar vectors, as both represent similar concepts,
but the vector representations of the names ageandfile_name
shoulddifferfromtheprevious vectors. Tothisend,ourapproach
builds on pre-trained word embeddings, i.e., a learned functionthat maps each name into a vector. Originally proposed in natu-ral language processing as a means to represents words [
13,36],
wordembeddingsarebecomingincreasinglypopularalsoonsource
1473
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:28:46 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Jibesh Patra and Michael Pradel
code[9,35,39,41,47],wheretheyrepresentindividualtokens,e.g.,
variable names.
WebuilduponFastText[ 13],aneuralwordembeddingknown
torepresentthesemanticsofidentifiersmoreaccuratelythanother
popularembeddings[ 54].AnadditionalkeybenefitofFastTextis
toavoidtheout-of-vocabularyproblemthatotherembeddings,e.g.,
Word2vec[ 36]sufferfrom,bysplittingeachtokeninton-gramsand
by computing a separate vector representation for each n-gram. To
obtainmeaningfulembeddingsforthePythondomain,wepre-train
a FastText model on token sequences extracted from the corpusPython programs used in our evaluation. Formally, the trainedFastText model
ð‘€, assigns to each name ð‘›a real-valued vector
ð‘€(ð‘›)âˆˆRð‘‘, whereð‘‘=100 in our evaluation.
Representing Values. The key challenge for representing the
string representations of values as vectors is that there is a widerange of different values, including sequential structures, e.g., in
values of types string,ndarray,list, and values without an obvious
sequential structure, e.g., primitives and custom objects. The string
representations of values may capture many interesting properties,
includingandbeyondtheinformationconveyedbythetypeofa
value.Forexample,thestringrepresentationofan intimplicitlyen-
codes whether the value is a positive or negative number. Our goal
whenrepresentingvaluesasvectoristopickupsuchintricacies,
without manually defining type-specific vector encoders.
To this end, Nalin represents value as a combination of two
vectorrepresentations,eachcomputedbyaneuralmodelthatwe
jointlylearnalongwiththeoverallclassificationmodel.Ontheone
hand, we use a recurrent neural network (RNN) suitable for cap-
turing sequential structures. Specifically, we apply gated recurrent
units (GRU) over the sequence of characters, where each character
is used as an input at every timestep. The vector obtained from the
hidden state of the last timestep then serves as the representation
of the complete sequence. On the other hand, we use a convolu-
tional neural network (CNN) suitable for capturing non-sequential
information about the value. Specifically, the approach applies a
one-dimensional CNN over the sequence of characters, where the
number of channels for the CNN is equal to the number of charac-
ters in the string representation of the value, the number of output
channels is set to 100, Relu is the activation function, and a one-
dimensional MaxPool layer serves as the final layer. Finally, Nalin
concatenates the vectors obtained from the RNN and the CNN into
the overall vector representation of the value.
Representing Types. To represent the type of a value as a vector,
the approach computes a one-hot vector for each type. Each vectorhasadimensionequaltothenumberoftypespresentinthedataset.
Atypeisrepresentedbysettinganelementtoonewhilekeeping
theremaining elementssetto zero.For example,ifwehaveonlythree types namely int, float, andlistin our dataset then using
one-hotencoding,eachofthemcanberepresentedas [1,0,0],[0,1,
0]and[0,0,1]respectively.Fortheevaluation,wesetthemaximum
numberoftypestoten.Moresophisticatedrepresentationsoftypes,
e.g., learned jointly with the overall model [ 5], could be integrated
into Nalin as part of future work.
Representing Length and Shape. Length and shape are similar
concepts,andhence,werepresenttheminasimilarfashion.Becausethelengthofavalueistheoreticallyunbounded,weconsiderten
rangesoflengthsandrepresenteachofthemwithaone-hotvector.
Specifically,Nalinconsidersrangesoflength100,startingfrom0
until1,000.Thatis,anylengthbetween0and100willberepresented
bythesameone-hotvector,andlikewiseanylengthgreaterthan
1,000willberepresentedbytheanothervector.Theshapeofavalue
is a tuple of discrete numbers, which we represent similarly to the
length,exceptthatwefirstmultiplytheelementsoftheshapetuple.
For example, for a value of shape ð‘¥,ð‘¦,ð‘§, we encode ð‘¥â‹…ð‘¦â‹…ð‘§using
the same approach as for the length. For values that do not have a
length or shape, we use a special one-hot vector.
3.4 Training and Prediction
OnceNalinhasobtainedavectorrepresentationforeachcompo-
nent of a name-value pair, the individual vectors are concatenated
into the combined representation of the pair. We then feed this
combinedrepresentationintoaneuralclassifierthatpredictsthe
probability ð‘ofthename-valuepairtobeinconsistent.Theclassifi-
cationmodelconsistsoftwolinearlayerswithasigmoidactivation
functionattheend.Wealsoaddadropoutwithprobabilityof0.5
before each linear layer. We train the model with a batch size of
128, using the Adam [ 28] optimizer, for 15 epochs, after which the
validationaccuracysaturates.Duringtraining,themodelistrained
toward predicting ð‘=0.0 for all positive examples and ð‘=1.0
for all negative examples. Once trained, we interpret the predicted
probability ð‘as the confidence Nalin has in flagging a name-value
pairasinconsistent,andtheapproachreportstotheuseronlypairs
withð‘above some threshold (Section 4.2).
3.5 Heuristic Filtering of Likely False Positives
Before reporting name-value pairs that the model predicts as in-
consistent to the user, Nalin applies two simple heuristics to prune
likelyfalsepositives.Theheuristicsaimatremovinggenericand
meaningless names that have passed the filtering described in Sec-
tion 3.1.2, such as dataandval_0. The rationale is that judging
whetherthosenamesmatchaspecificvalueisdifficult,butthegoal
of Nalin is to identify name-value pairs that clearly mismatch. The
first heuristic removes pairs with names that contain one of thefollowing terms, which are often found in generic names:
data,
value,result,temp,tmp,str, andsample. The second heuris-
tic removes pairs with short and cryptic names. To this end, we
tokenize names at underscores and then remove pairs with names
where at least one subtoken has less than three characters.
4 EVALUATION
Our evaluation focuses on the following research questions:
â—RQ1: How effective is the neural model of Nalin in detecting
name-value inconsistencies?
â—RQ2:AretheinconsistenciesthatNalinreportsperceivedashard
to understand by software developers?
â—RQ3: What kinds of inconsistencies does the approach find in
real-world code?
â—RQ4: How does our approach compare to popular static code
analysis tools?
â—RQ5: How does Nalin compare to simpler variants of the ap-
proach?
1474
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:28:46 UTC from IEEE Xplore.  Restrictions apply. Learning from Runtime Behavior to Find Name-Value Inconsistencies ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
4.1 Experimental Setup
WeimplementourapproachforPythonasitisoneofthemostpopu-
lar dynamically typed programming languages[ 1]. All experiments
arerunonamachinewithIntelXeonE5-2650CPUhaving48cores,
64GB of memory and an NVIDIA Tesla P100 GPU. The machine
runs Ubuntu 18.04, and we use Python 3.8 forthe implementation.
Theevaluationrequiresalarge-scale,diverse,andrealisticdataset
of closed (i.e., include all inputs) programs. We choose one million
computational notebooks in an existing dataset of Jupyter note-
books scrapped from GitHub [ 49]. The dataset is (i) large-scale
because there are many notebooks available, (ii) diverse becausethey are written by various developers and cover various appli-cation domains, (iii) realistic because Jupyter notebooks are one
ofthemostpopularwaysofwrittenPythoncodethesedays,and
(iv)closedbecausenotebooksdonotrelyonuserinput.Another
option would be to apply Nalin to executions of test suites, which
oftenfocusonunusualinputsthoughand,bydefinition,exercise
well-tested and hence likely correct behavior.
Excluding some malformed notebooks, we convert 985,865 note-
booksintoPythonscriptsusing nbconvert.Someofthesenotebooks
containonlytextandnocode,whileforothers,thecodehassyntax
errors,orthecodeisveryshortanddoesnotperformanyassign-
ments.All ofthis decreasesthe numberof Pythonfilesthat Nalin
can instrument, and we finally obtain 598,321 instrumented files.
The instrumentation takes approximately two hours.
Whengatheringname-valuepairs,wefacegeneralchallenges
related to reproducing Jupyter notebooks [ 55]. First, even with the
installationofthe100mostpopularPythonpackages,unresolved
dependencies result in crashes during some executions. Second,
some Python scripts read inputs from files, e.g., a dataset for train-
ing a machine learning model, which may not be locally available.
Considering all notebooks that we can successfully execute de-
spitetheseobstacles,Nalingathersatotalof947,702name-value
pairs,ofwhich500,332remainafterthefilteringdescribedinSec-
tion 3.1.2. The extracted pairs come from 106,652 Python files with
a total of 7,231,218 lines of non-comment, non-blank Python code.
Runningtheinstrumentedfilestoextractname-valuepairstakes
approximately 48 hours.
Before running any experiments with the model, we sample
10,000 name-value pairs as a held-out test dataset. Unless men-
tionedotherwise,allreportedresultsareonthistestdataset.Ontheremaining490,332name-valuepairs,weperforman80-20splitinto
trainingandvalidation data.Foreachname-valuepairpresentin
thetraining,validation,andtestdatasets,wecreateacorrespond-
ing negative example, which takes two hours in total. The total
numberofdatapointsusedtotraintheNalinmodelhenceisabout
780k. Training takes an average of 190 seconds per epoch and once
trained,predictionontheentiretestdatasettakesabout15seconds.
Wefindthename-valuepairstoconsistofadiversesetofvalues
andtypes.Thereare99.8kuniquenames,i.e.,eachnameappears,on
average, about 10 times. The top-5 frequent types are list,ndarray,
str,int,float. The presence of a large number of collection types,
suchaslistandndarray,whichusuallyarenotfullyinitializedas
literals shows that extracting values at run-time is worthwhile.Figure4:Precision,recall,andF1scorewithdifferentthresh-
olds for reporting warnings.
4.2 RQ1: Effectiveness of the Trained Model
We measure the effectiveness of Nalinâ€™s model by applying the
trained model to the held-out test dataset. The output of the model
canbeinterpretedasaconfidencescorethatindicateshowlikely
the model believes a given name-value pair to be inconsistent. We
consider all name-value pairs ð‘ƒwarningwith a score above some
thresholdasawarning,andthenmeasureprecisionandrecallof
themodelw.r.t.theinconsistencylabelsinthedataset( ð‘ƒð‘–ð‘›ð‘ð‘œð‘›ð‘ ð‘–ð‘ ð‘¡ð‘’ð‘›ð‘¡
are pairs labeled as inconsistent):
precision=âˆ£ð‘ƒwarning âˆ©ð‘ƒinconsistent âˆ£
âˆ£ð‘ƒwarning âˆ£
recall=âˆ£ð‘ƒwarning âˆ©ð‘ƒinconsistent âˆ£
âˆ£ð‘ƒinconsistent âˆ£
We also compute the F1 score, which is the harmonic mean of
precision and recall.
Figure 4 shows the results for different thresholds for reporting
apredictionasawarning.Theresultsillustratetheusualprecision-
recall tradeoff, where a user can reduce the risk of false positive
warningsatthecostoffindingfewerinconsistencies.Themodel
achieves the highest F1 score of 89% at a threshold of 0.4, with a
precisionof 88%andarecall of91%.Unless otherwise mentioned,
weuseathresholdof0.5asthedefault,whichgives87%F1score.
Out of 8,858 files in the held-out test set, 336 (3.8%) have at least
one warning reported by Nalin.
Finding1: Themodeleffectivelyidentifiesinconsistentname-
value pairs, with a maximum F1 score of 89%.
4.3 RQ2: Study with Developers
To answer the question how well Nalinâ€™s warnings match name-
value pairs that developers perceive as hard to understand, we
perform a study with eleven software developers. The participants
arefourPhDstudentsandsevenmaster-levelstudents,allofwhich
regularlydevelopsoftware,andnoneofwhichoverlapswiththe
authors of thispaper.During the study, each participant isshown
40 name-value pairs and asked to assess each pair regarding its
understandability.Theparticipantsprovidetheirassessmentona
five-point Likert scale ranging from â€œhardâ€ (1) to â€œeasyâ€ (5), where
1475
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:28:46 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Jibesh Patra and Michael Pradel
Nalinâ€™s prediction
Developer Consistent Inconsistent
assessment (ð‘ƒnoWarning)(ð‘ƒwarning)
Easy to understand ( ð‘ƒeasy) 15 4
Hard to understand ( ð‘ƒhard) 51 6
(a) Nalinpredictions of inconsistenciesvs. developer-perceived un-
derstandability.


	

(b)Understandabilityratingsforname-valuepairswithandwithout
warnings by Nalin.
Figure 5: Results from user study.
â€œhardâ€meansthatthenameandthevalueareinconsistent,makingit
hardtounderstandandmaintainthecode.The40name-valuepairs
consist of 20 pairs that are randomly selected from all warnings
Nalinreportsasinconsistentwithaconfidenceabove80%andof20
randomlyselectedpairsthattheapproachdoesnotwarnabout.For
each pair, the participants are shown the name of the variable, the
valuethatNalindeemsinconsistentwiththisname,andthetypeof
the value. In total, the study hence involves 440 developer ratings.
Because what is a meaningful variable names is, to some extent,
subjective, we expect some variance in the ratings provided by the
participants. To quantify this variance, we compute the inter-rater
agreement using Krippendorffâ€™s alpha, which yields an agreement
of 56%. That is, developers agree with a medium to high degree on
whether a name-value pair is easy to understand.
Before providing quantitative results, we discuss a few represen-
tativeexamples.Amongthename-valuepairswithoutawarning
isavariablecalled DATA_URL thatstoresastringcontainingaURL.
Thispairis consistentlyratedaseasyto understand,withamean
rankingof5.0.AmongthepairsthatNalinreportsasinconsistent
are a variable password_text storing an integer value 0, which
most participants consider as hard to understand (mean rating:
1.54). Another pair that the approach warns about is a variable
calledpaththat stores an empty list. The study participants are
rather undecided about this example, with a mean rating of 2.72.
The main question of the user study is to what extent Nalin
pinpoints name-value pairs that developers also consider to be
hard to understand. We address this question in two ways, first bycomputingprecisionandrecallofNalinw.r.t.thedeveloperratings,andthenbycomparingtheratingsforwarningsandnon-warnings.
PrecisionandRecallw.r.t.DeveloperRatings. Weassigneachof
the 40 name-value pairs into two sets: On the one hand, a pair is
inð‘ƒhardifthemeanratingassignedbythedevelopersislessthan
threeandin ð‘ƒeasyotherwise.Ontheotherhand,apairisin ð‘ƒwarning
if Nalin flags it as an inconsistency and in ð‘ƒnoWarning otherwise.
Table5ashowstheintersectionsbetweenthesesets.Forexample,
weseethat16ofthepairsthatNalinwarnsabout,butonly5ofthe
pairswithoutawarning,areconsideredtobehardtounderstand.
We compute precision and recall as follows:
precision=âˆ£ð‘ƒwarning âˆ©ð‘ƒhardâˆ£
âˆ£ð‘ƒwarning âˆ£=16
20=80%
recall=âˆ£ð‘ƒwarning âˆ©ð‘ƒhardâˆ£
âˆ£ð‘ƒhardâˆ£=16
21=76%
RatingsforWarningsvs.Non-Warnings. Inadditiontothepair-
based metrics above, we also globally compare the ratings for pairs
with and without warnings. The goal is to understand whether
Nalin is effective at distinguishing between name-value pairs that
developers perceive as easy and hard to understand. To this end,
consider two sets of ratings: ratings ð‘…warningfor name-value pairs
that Nalin reports as inconsistent, and ratings ð‘…noWarning for other
name-value pairs. Figure 5b compares the two sets of ratings with
each other, showing how many ratings there are for each point
on the 5-point Likert scale. The results show a clear difference be-
tweenthetwosets:â€œeasyâ€isthemostcommonratingin ð‘…noWarning,
whereasthemajorityofratingsin ð‘…warningiseitherâ€relativelyhardâ€
or â€œhardâ€. We also statistically compare ð‘…warningandð‘…noWarning us-
ing a Mann-Whitney U-test, which shows the two sets of rankings
to be extremely likely to be sampled from different populations
(with a p-value of less than 0.1%).
Finding 2: Developers mostly agree with the (in)consistency
predictionsbyNalin.Inparticular,theyassess80%ofthename-
value pairs that the approach warns about as hard to maintain
and understand.
4.4RQ3: Kinds of Inconsistencies in Real-World
Code
Tobetterunderstandthekindsofname-valueinconsistenciesde-
tectedinreal-worldcode,weinspectname-valuepairsinthetest
datasetsthatappearassuchinthecode,butthatareclassifiedas
inconsistentbythemodel.WhenusingNalintosearchforprevi-
ouslyunknownissues,thesename-valuepairswillbereportedas
warnings.Weinspectthetop-30predictions,sortedbytheproba-
bility score provided by the model, and classify each warning into
one of three categories:
â—Misleading name. Name-value pairs where the name clearly fails
to match the value it refers to. These cases do not lead to wrong
program behavior, but should be fixed to increase the readability
and maintainability of the code.
â—Incorrectvalue.Name-value pairswherethemismatchbetween
anameandavalueisduetoanincorrectvaluebeingassigned.
These cases cause unexpected program behavior, e.g., a program
crash or incorrect output.
1476
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:28:46 UTC from IEEE Xplore.  Restrictions apply. Learning from Runtime Behavior to Find Name-Value Inconsistencies ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Table 1: Examples of warnings produced by Nalin.
Code Example Category Run-time value Comment
name ='Philip K. Dick'
...
name =2.5
iftype(name) == str:
print('yes')Misleading
name2.5 Avariablecalled nameistypicallyholdingastring,but
here stores a float value.
file = os.path.exists(â€™reference.csvâ€™)
iffile == False:
print('Warning: ...')Misleading
nameFalse The namefilesuggests that the variable stores either a
file handle or a file name, but it here stores a boolean.
defCustom(information):
prob =get_betraying_probability(information)
if(prob > 1/2):
returnD
elif(prob == 1/2):
returnchoice([D, C])
else:
returnCIncorrect
value"Cooperate" Assigning a string to a variable called probis unusual,
becauseprobusually refers to a probability. The value
isincorrectandleadstoacrashinthenextlinebecause
comparing a string and a float causes a type error.
dwarF = â€™/Users/iayork/Downloads/dwar_2013_2015.txtâ€™
dwar = pd.read_csv(dwarF, sep='' , header=None)False pos-
itive"/Users/.." Thevalueisastringthatdescribesfilepath,whichfitsthe
name, where the Fsupposedly means â€œfileâ€. The model
reports this false positive because it fails to understand
the abbreviation.
â—False positive. Name-value pairs that are consistent with each
other, and which ideally would not be reported as a warning.
The inspection shows that 21 of the warnings correspond to
misleadingnames,2areincorrectvalues,and7arefalsepositives.
That is, the majority of the reported inconsistencies are due to the
name,whereasonlyafewarecausedbyanincorrectvaluebeing
assigned to a meaningful name. This result is expected because in-
correctbehavioriseasiertodetect,e.g.viatesting,thanmisleading
names, for which currently few tools exist. The fact that 23 out
of30warnings(77%)aretruepositivesisalsoconsistentwiththe
developer study in RQ2.
Table1showsrepresentativeexamplesofwarningsproducedby
Nalin.Thefirsttwoexamplesshowmisleadingnames.Forexample,
it is highly unusual to assign a number to a variable called name
or to assign boolean to a variable called file. To the best of our
knowledge,thesemisleadingnamesdonotcauseunexpectedbe-
havior, but developers may still want to fix them to increase thereadability and maintainability of the code. In the third example,
Nalinproducesawarningabouttheassignmentonline2.Thevalueassignedduringtheexecutionisastring
â€™Cooperateâ€™ .Duetothe
stringassignment,thecodeonline3crashessincetheoperator >
does not support a comparison between a string and float. Nalinis correct in predicting this warning because the variable name
probistypicallyusedtorefertoaprobability,nottoastringlike
â€™Cooperateâ€™ . The final example is a false positive, which illus-
tratesoneofthemostcommoncausesoffalsepositivesseenduring
our inspection, namely short (and somewhat cryptic) names for
which the model fails to understand the meaning.Finding3: Themajorityofinconsistenciesdetectedinreal-
world code are due to the name in a name-value pair being
misleading, and occasionally also due to incorrect values.
4.5 RQ4: Comparison with Previous Bug
Detection Approaches
We compare Nalin to three state-of-the-art static analysis tools
aimed at finding bugs and other kinds of noteworthy issues: (i)pyre, a static type checker for Python that infers types and uses
availabletypeannotations.Wecomparewithpyrebecausemanyof
theinconsistenciesthatNalinreportsaretype-related,andhence,
might also be spotted by a type checker. (ii) flake8, a Python lin-
ter that warns about commonly made mistakes. We compare with
flake8becauseitiswidelyusedandbecauselinterssharethegoalof
improving the quality of code. (iii) DeepBugs [47], a learning-based
bug detection technique. We compare with DeepBugs because it
alsoaimstofindname-relatedbugsusingmachinelearning,butus-ingstaticinsteadofdynamicanalysis.Werunpyreandflake8using
theirdefaultconfigurations.ForDeepBugs,weinstalltheâ€œDeep-
BugsforPythonâ€pluginfromthemarketplaceofthePyCharmIDE.
We apply each of the three approaches to the 30 files where Nalin
has produced a warning and which have been manually inspected
(RQ3).Namer[ 22],arecenttechniqueforfindingname-relatedcod-
ing issues through a combination of static analysis, pattern mining,andsupervisedlearningwouldbeanothercandidateforcomparing
with, but neither the implementation nor the experimental results
are publicly available.
Table 2 shows the number of warnings reported by the existing
toolsandhowmanyofthesewarningsoverlapwiththosereported
by Nalin. We find that except one warning reported by pyre, none
1477
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:28:46 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Jibesh Patra and Michael Pradel
Table 2: Comparison with existing static bug detectors.
Approach Warnings Warnings common with Nalin
pyre 54 1/30
flake8 1,247 0/30
DeepBugs 151 0/30
Figure 6: Result of ablation study.
matches with the 30 manually inspected warnings from Nalin. The
matching warning is a misleading name, shown on the first row
of Table 1. The pyre type checker reports this as an â€œIncompatible
variable typeâ€ because in the same file, the variable nameis first
assignedastring â€™Philip K. Dickâ€™ andlaterassignedafloatvalue
2.5. The 1,247 warnings produced by flake8 are mostly about cod-
ing style, e.g., â€œmissing white spaceâ€ and â€œwhitespace after â€™(â€™ â€.
The warnings reported by DeepBugs include possibly wrong oper-
atorusagesandincorrectlyorderedfunctionarguments,butnone
matches the warnings reported by Nalin.
Finding 4: Nalin is complementary to both traditional static
analysis-basedtoolsandtoastate-of-the-artlearning-based
bug detector aimed at name-related bugs.
4.6 RQ5: Comparison with Variants of the
Approach
4.6.1 Type-Guided vs. Purely Random Negative Examples. The fol-
lowing compares the two algorithms for generating negative ex-
amples described in Section 3.2. Following the setup from RQ1, we
find that the purely random generation reduces both precision and
recall, leading to a maximum F1 score of 0.82, compared to 0.89
with the type-guided approach. Manually inspecting the top-30
reportedwarningsasinRQ2,wefind21falsepositives,ninemis-
leading names, and zero incorrect values, which clearly reduces
the precision compared to the type-guided generation approach.
These results confirm motivation for the type-guided algorithm
(Section 3.2.2) and show that it outperforms a simpler baseline.
4.6.2 Ablation Study. We perform an ablation study to measure
theimportanceofthedifferentcomponentsofaname-valuepairfed into the model. To this end, we set the vector representation of
individual components to zero during training and prediction, and
thenmeasuretheeffectontheF1scoreofthemodel.Figure6shows
the results, where the vertical axis shows the F1 score obtained
onthevalidationdatasetateachepochduringtraining.Eachline
inFigure6showstheF1scoreobtainedwhiletrainingthemodel
keeping that particular feature set to zero. For example, the green
line (â€œNo Shapeâ€) is for a model that does not use the shape of a
value,andtheblueline(â€œallâ€)isforamodelthatusesallcomponents
of a name-value pair. We find that the most important inputs tothemodelarethevariablenameandthestringrepresentationofthe value. Removing the length or the type of a value does not
significantly decrease the modelâ€™s effectiveness. The reason is that
thesepropertiescanoftenbeinferredfromotherinputsgivento
the model, e.g., by deriving the type from the string representation
of a value. We confirm this explanation by removing both the type
andthestringrepresentationofavalue,whichyieldsanF1score
similar to the model trained by removing only values.
Finding5: Eachcomponentoftheapproachcontributesto
the overall effectiveness, but there is some redundancy in the
properties of values given to the model.
5 THREATS TO VALIDITY
Internal Validity. Several factors may influence our results. First,
the filtering of name-value pairs based on the length of namesmay accidentally remove short but meaningful names, such as
abbreviationsthatarecommoninaspecificdomain.Preliminary
experimentswithoutsuchfilteringresultedinmanyfalsepositives,
and we prefer false negatives over false positives to increase devel-
oper acceptance. Second, our manual classification into different
kinds of inconsistencies is subject to our limited knowledge of the
analyzed Python files. To mitigate this threat, the classificationis done by two of the authors, discussing any unclear cases until
reaching consensus.
ExternalValidity. Severalfactorsmayinfluencethegeneralizabil-
ityofourresults.First,ourapproachisdesignedwithadynamically
typedprogramminglanguageinmind,becausemeaningfuliden-
tifier names are particularly important in such languages. Thisfocus and the setup of our experiments implies that we cannotdraw conclusions beyond Python or beyond the kind of Pythoncode foundin Jupyter notebooks. Second, ourdeveloper study is
limited to eleven participants, and other developers may assess the
understandability of the name-value pairs differently. We mitigate
thisthreat bygetting elevenopinions abouteach name-valuepair
and by statistically analyzing the relevance of the results.
6 RELATED WORK
DetectingPoorNames. Theimportanceofmeaningfulnamesdur-
ing programming has been studied and established [ 15,32]. There
areseveraltechniquesforfindingpoorlynamedprogramelements,
e.g.,basedonpre-definedrules[ 2],bycomparingmethodnames
againstmethodbodies[ 26],andthroughatypeinference-likeanaly-
sisofnamesandtheiroccurrences[ 30].Toimproveidentifiernames,
1478
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:28:46 UTC from IEEE Xplore.  Restrictions apply. Learning from Runtime Behavior to Find Name-Value Inconsistencies ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
rule-basedexpansion[ 31],n-grammodelsofcode[ 3],andlearning-
basedtechniquesthatcomparemethodbodiesandmethodnames
have been proposed [ 34,38]. Namer [ 22] combines static analy-
sis,patternmining,andsupervisedlearningtofindname-related
coding issues. Many of the above approaches focus on method
names,whereaswetargetvariables.Moreover,noneoftheexisting
approaches exploits dynamically observed values.
Predicting Names. When namesare completely missing, e.g.,in
minified, compiled, or obfuscated code, learned models can predict
them [12,29,48,53]. Another line of work predicts method names
giventhebodyofamethod[ 4,7,9],whichbeyondbeingpotentially
useful for developers serves as a pseudo-task to force a model to
summarize code in a semantics-preserving way. Nalin differs by
considering values observed at runtime, and not only static source
code,andbycheckingnamesforinconsistencieswiththevalues
they refer to, instead of predicting names from scratch.
Name-basedProgramAnalysis. DeepBugsintroducedlearning-
basedandname-basedbugdetection[ 47],whichdiffersfromNalin
by being purely static and by focusing on different kinds of er-rors. The perhaps most popular kind of name-based analysis is
probabilistictypeinference[59],oftenusingdeepneuralnetwork
models [5,23,35,46,58] that reason about the to-be-typed code.
RefiNumusesnamestoidentifyconceptualtypes,whichfurtherre-
fine the usual programming language types [ 16]. SemSeed exploits
semantic relations between names to inject realistic bugs [ 42]. All
of the above work is based on the observation that the implicit
information embedded in identifiers is useful for program analyses.
Our work is the first to exploit this observation to find name-value
inconsistencies.
NaturalLanguagevs.Code. Beyondnaturallanguageintheform
ofidentifiers,commentsanddocumentationassociatedwithcode
are another valuable source of information. iComment [ 51] and
tComment[ 52]usethisinformationtodetectinconsistenciesbe-
tweencommentsandcode.Ourworkdiffersbyfocusingonvariable
names instead of comments, by comparing the natural languageartifact against runtime values instead of static code, and by us-
ingalearning-basedapproach.Anotherlineofworkusesnatural
language documentation to infer specifications of code [ 19,37,40],
which is complementary to our work.
LearningonCode. Inadditiontotheworkdiscussedabove,ma-
chinelearningoncodeisreceivingsignificantinterestrecently[ 45].
Embeddingsofcodeareoneimportanttopic,e.g.,usingASTpaths[ 10],
controlflowgraphs[ 57],ASTs[60],oracombinationoftokense-
quencesandagraphrepresentationofcode[ 24].Ourencoderof
variable names could benefit from being combined with an en-
codingofthecodesurroundingtheassignmentusingthoseideas.
Otherworkmodelscodechangesandthenmakespredictionsabout
them [14,25], or trains models for program repair [ 18,21], code
completion [8, 11, 27], and code search [20, 50].
LearningfromExecutions. Despitetherecentsurgeofworkon
learning on code, learning on data gathered during executions is a
relativelyunexploredarea.Onemodelembedsstudentprograms
based on dynamically observed input-output relations [ 43]. Wang
et al.â€™s â€œblendedâ€ code embedding learning [56] combines runtimetraces,whichincludevaluesofmultiplevariables,andstaticcodeel-ementstolearnadistributedvectorrepresentationofcode.Beyondcodeembedding,BlankIt[
44]usesadecisiontreemodeltrainedon
runtimedatatopredictthelibraryfunctionsthatacodelocation
mayuse.Incontrasttothesepapers,ourworkaddressesadifferent
problem and feeds one value at a time into the model.
7 CONCLUSION
Using meaningful identifier names is important for code under-
standability and maintainability. This paper presents Nalin, which
addressestheproblemoffindinginconsistenciesthatarisedueto
theuseofamisleadingnameorduetoassigninganincorrectvalue.
ThekeynoveltyofNalinistolearnfromnamesandtheirvalues
assigned at runtime. To reason about the meaning of names and
values, the approach embeds them into vector representations that
assign similar vectors to similar names and values. Our evalua-tionwithabout500kname-valuepairsgatheredfromreal-world
Python programs shows that the model is highly accurate, leading
to warnings reported with a precision of 80% and recall of 76%.
Our implementation and experimental results are available:
https://github.com/sola-st/Nalin
ACKNOWLEDGMENTS
This work was supported by the European Research Council (ERC,
grant agreement 851895), and by the German Research Foundation
within the ConcSys and Perf4JS projects.
REFERENCES
[1][n.d.]. TIOBE Index. https://www.tiobe.com/tiobe-index. Accessed: 2021-08-31.
[2]SurafelLemmaAbebe,SoniaHaiduc,PaoloTonella,andAndrianMarcus.2009.
Lexicon bad smells in software. In 2009 16th Working Conference on Reverse
Engineering. IEEE, 95â€“99.
[3]Miltiadis Allamanis, Earl T. Barr, Christian Bird, and Charles A. Sutton. 2014.
Learningnaturalcodingconventions.In Proceedingsofthe22ndACMSIGSOFT
International Symposium on Foundations of Software Engineering, (FSE-22), Hong
Kong, China, November 16 - 22, 2014. 281â€“293.
[4]Miltiadis Allamanis, Earl T. Barr, Christian Bird, and Charles A. Sutton. 2015.
Suggestingaccuratemethodandclassnames.In Proceedingsofthe201510thJoint
MeetingonFoundationsofSoftwareEngineering,ESEC/FSE2015,Bergamo,Italy,
August 30 - September 4, 2015. 38â€“49.
[5]MiltiadisAllamanis,EarlT.Barr,SolineDucousso,andZhengGao.2020. Typilus:
Neural Type Hints. In PLDI.
[6]MiltiadisAllamanis,MarcBrockschmidt,andMahmoudKhademi.2018. Learning
to Represent Programs with Graphs. In 6th International Conference on Learn-
ing Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018,
Conference Track Proceedings. https://openreview.net/forum?id=BJOFETxR-
[7]Miltiadis Allamanis, Hao Peng, and Charles A. Sutton. 2016. A Convolutional
AttentionNetworkforExtremeSummarizationofSourceCode.In ICML.2091â€“
2100.
[8]UriAlon,ShakedBrody,OmerLevy,andEranYahav.2019. code2seq:Generating
Sequences from Structured Representations of Code. In 7th International Con-
ferenceonLearningRepresentations,ICLR2019,NewOrleans,LA,USA,May6-9,
2019. https://openreview.net/forum?id=H1gKYo09tX
[9]Uri Alon, Meital Zilberstein, Omer Levy, and Eran Yahav. 2018. A General
Path-Based Representation for Predicting Program Properties. In PLDI.
[10]UriAlon,MeitalZilberstein,OmerLevy,andEranYahav.2019. code2vec:learning
distributedrepresentationsofcode. Proc.ACMProgram.Lang. 3,POPL(2019),
40:1â€“40:29. https://doi.org/10.1145/3290353
[11]Gareth Ari Aye and Gail E. Kaiser. 2020. Sequence Model Design for Code
CompletionintheModernIDE. CoRRabs/2004.05249(2020). arXiv:2004.05249
https://arxiv.org/abs/2004.05249
[12]Rohan Bavishi, Michael Pradel, and Koushik Sen. 2018. Context2Name: A Deep
Learning-Based Approach to Infer Natural Variable Names from Usage Contexts.
CoRRarXiv:1809.05193 (2018).
1479
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:28:46 UTC from IEEE Xplore.  Restrictions apply. ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA Jibesh Patra and Michael Pradel
[13]Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2017.
Enriching Word Vectors with Subword Information. TACL5 (2017), 135â€“146.
https://transacl.org/ojs/index.php/tacl/article/view/999
[14]ShakedBrody,UriAlon,andEranYahav.2020. AStructuralModelforContextual
Code Changes. In OOPSLA.
[15]SimonButler,MichelWermelinger,YijunYu,andHelenSharp.2010.Exploringthe
Influence of Identifier Names on Code Quality: An Empirical Study. In European
Conference on Software Maintenance and Reengineering (CSMR). IEEE, 156â€“165.
[16]SantanuKumarDash,MiltiadisAllamanis,andEarlT.Barr.2018. RefiNym:Using
Names to Refine Types. In ESEC/FSE.
[17]Yaniv David, Uri Alon, and Eran Yahav. 2020. Neural reverse engineering of
stripped binaries. In OOPSLA.
[18]ElizabethDinella,HanjunDai,ZiyangLi,MayurNaik,LeSong,andKeWang.
2020. Hoppity: Learning Graph Transformations to Detect and Fix Bugs in
Programs. In ICLR.
[19]Alberto Goffi, Alessandra Gorla, Michael D Ernst, and Mauro PezzÃ¨. 2016. Auto-
matic generation of oracles for exceptional behaviors. In Proceedings of the 25th
International Symposium on Software Testing and Analysis. 213â€“224.
[20]XiaodongGu,HongyuZhang,andSunghunKim.2018. DeepCodeSearch.In
ICSE.
[21]Rahul Gupta, Soham Pal, Aditya Kanade, and Shirish Shevade. 2017. DeepFix:
Fixing Common C Language Errors by Deep Learning. In AAAI.
[22]Jingxuan He, Cheng-Chun Lee, Veselin Raychev, and Martin T. Vechev. 2021.
Learning to find naming issues with big code and small supervision. In PLDI â€™21:
42ndACMSIGPLANInternationalConferenceonProgrammingLanguageDesign
and Implementation, Virtual Event, Canada, June 20-25, 20211, Stephen N. Freund
and Eran Yahav (Eds.). ACM, 296â€“311. https://doi.org/10.1145/3453483.3454045
[23]V. Hellendoorn, C. Bird, E. T. Barr, and M. Allamanis. 2018. Deep Learning Type
Inference. In FSE.
[24]Vincent J. Hellendoorn, Charles Sutton, Rishabh Singh, Petros Maniatis, and
DavidBieber.2020. GlobalRelationalModelsofSourceCode.In 8thInternational
ConferenceonLearningRepresentations,ICLR2020,AddisAbaba,Ethiopia,April
26-30, 2020. OpenReview.net. https://openreview.net/forum?id=B1lnbRNtwr
[25]Thong Hoang, Hong Jin Kang, David Lo, and Julia Lawall. 2020. CC2Vec: Dis-
tributed Representations of Code Changes. In ICSE.
[26]Einar W. HÃ¸st and Bjarte M. Ã˜stvold. 2009. Debugging Method Names. In
EuropeanConferenceonObject-OrientedProgramming(ECOOP).Springer,294â€“
317.
[27]Seohyun Kim, Jinman Zhao, Yuchi Tian, and Satish Chandra. 2020. Code Predic-
tion by Feeding Trees to Transformers. arXiv preprint arXiv:2003.13848 (2020).
[28]Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic opti-
mization. arXiv preprint arXiv:1412.6980 (2014).
[29]Jeremy Lacomis, Pengcheng Yin, Edward J. Schwartz, Miltiadis Allamanis,
ClaireLeGoues,GrahamNeubig,andBogdanVasilescu.2019. DIRE:ANeural
Approach to Decompiled Identifier Naming. In ASE.
[30]Julia L. Lawall and David Lo. 2010. An automated approach for finding variable-
constantpairingbugs.In InternationalConferenceonAutomatedSoftwareEngi-
neering (ASE). ACM, 103â€“112.
[31]DawnLawrieandDaveBinkley.2011. Expandingidentifierstonormalizesource
code vocabulary. In 2011 27th IEEE International Conference on Software Mainte-
nance (ICSM). IEEE, 113â€“122.
[32]DawnLawrie,ChristopherMorrell,HenryFeild,andDavidBinkley.2006. Whatâ€™s
inaName?AStudyofIdentifiers.In InternationalConferenceonProgramCom-
prehension (ICPC). IEEE, 3â€“12.
[33]YiLi,ShaohuaWang,TienN.Nguyen,andSonVanNguyen.2019. ImprovingBugDetectionviaContext-BasedCodeRepresentationLearningandAttention-Based
Neural Networks. In OOPSLA.
[34]KuiLiu,DongsunKim,TegawendÃ©F.BissyandÃ©,Tae-youngKim,KisubKim,Anil
Koyuncu,SuntaeKim,andYvesLeTraon.2019. Learningtospotandrefactor
inconsistent method names. In Proceedings of the 41st International Conference on
Software Engineering, ICSE 2019, Montreal, QC, Canada, May 25-31, 2019. 1â€“12.
https://dl.acm.org/citation.cfm?id=3339507
[35] Rabee Sohail Malik, Jibesh Patra, and Michael Pradel. 2019. NL2Type: Inferring
JavaScriptfunctiontypesfromnaturallanguageinformation.In Proceedingsof
the 41st International Conference on Software Engineering, ICSE 2019, Montreal,
QC, Canada, May 25-31, 2019. 304â€“315. https://doi.org/10.1109/ICSE.2019.00045
[36]Tomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S. Corrado, and Jeffrey Dean.
2013. Distributed Representations of Words and Phrases and their Composi-
tionality.In AdvancesinNeuralInformationProcessingSystems26:27thAnnual
ConferenceonNeuralInformationProcessingSystems2013.Proceedingsofameeting
held December 5-8, 2013, Lake Tahoe, Nevada, United States. 3111â€“3119.
[37]ManishMotwaniandYuriyBrun.2019. AutomaticallygeneratingpreciseOracles
fromstructurednaturallanguagespecifications.In Proceedingsofthe41stInter-
nationalConferenceonSoftwareEngineering,ICSE2019,Montreal,QC,Canada,
May 25-31, 2019. 188â€“199. https://doi.org/10.1109/ICSE.2019.00035
[38]SonNguyen,HungPhan,TrinhLe,andTienN.Nguyen.2020. SuggestingNatural
Method Names to Check Name Consistencies. In ICSE.[39]Trong Duc Nguyen, Anh Tuan Nguyen, Hung Dang Phan, and Tien N. Nguyen.
2017. Exploring API embedding for API usages and applications. In Proceedings
ofthe39thInternationalConferenceonSoftwareEngineering,ICSE2017,Buenos
Aires, Argentina, May 20-28, 2017. 438â€“449.
[40]Rahul Pandita, Xusheng Xiao, Hao Zhong, Tao Xie, Stephen Oney, and AmitParadkar. 2012. Inferring method specifications from natural language API
descriptions. In 2012 34th international conference on software engineering (ICSE).
IEEE, 815â€“825.
[41]Md. Rizwan Parvez, Saikat Chakraborty, Baishakhi Ray, and Kai-Wei Chang.2018. BuildingLanguageModelsforTextwithNamedEntities.In Proceedings
of the 56th Annual Meeting of the Association for Computational Linguistics, ACL
2018, Melbourne, Australia, July 15-20, 2018, Volume 1: Long Papers. 2373â€“2383.
https://doi.org/10.18653/v1/P18-1221
[42]JibeshPatraandMichaelPradel.2021. Semanticbugseeding:alearning-based
approachforcreatingrealisticbugs.In ESEC/FSEâ€™21:29thACMJointEuropean
SoftwareEngineeringConferenceandSymposiumontheFoundationsofSoftware
Engineering, Athens, Greece, August 23-28, 2021, Diomidis Spinellis, GeorgiosGousios, Marsha Chechik, and Massimiliano Di Penta (Eds.). ACM, 906â€“918.
https://doi.org/10.1145/3468264.3468623
[43]Chris Piech, Jonathan Huang, Andy Nguyen, Mike Phulsuksombati, Mehran
Sahami,andLeonidasJ.Guibas.2015. LearningProgramEmbeddingstoProp-
agate Feedback on Student Code. In Proceedings of the 32nd International Con-
ference on Machine Learning, ICML 2015, Lille, France, 6-11 July 2015 . 1093â€“1102.
http://proceedings.mlr.press/v37/piech15.html
[44]Chris Porter, Girish Mururu, Prithayan Barua, and Santosh Pande. 2020. BlankIt
library debloating: getting what you want instead of cutting what you donâ€™t. In
Proceedingsof the41stACM SIGPLANInternationalConference onProgramming
LanguageDesignandImplementation,PLDI2020,London,UK,June15-20,2020,
AlastairF.DonaldsonandEminaTorlak(Eds.).ACM,164â€“180. https://doi.org/
10.1145/3385412.3386017
[45]MichaelPradelandSatishChandra.2022. NeuralSoftwareAnalysis. Commun.
ACM(2022). https://arxiv.org/abs/2011.07986 To appear.
[46]Michael Pradel, Georgios Gousios, Jason Liu, and Satish Chandra. 2020. Type-
Writer:NeuralTypePredictionwithSearch-basedValidation.In ESEC/FSEâ€™20:
28th ACM Joint European Software Engineering Conference and Symposium on
the Foundations of Software Engineering, Virtual Event, USA, November 8-13, 2020.
209â€“220. https://doi.org/10.1145/3368089.3409715
[47]Michael Pradel and Koushik Sen. 2018. DeepBugs: A learning approach toname-based bug detection. PACMPL 2, OOPSLA (2018), 147:1â€“147:25. https:
//doi.org/10.1145/3276517
[48]VeselinRaychev,MartinT.Vechev,andAndreasKrause.2015.PredictingProgramPropertiesfrom"BigCode"..In PrinciplesofProgrammingLanguages(POPL).111â€“
124.
[49]Adam Rule, AurÃ©lien Tabard, and James D. Hollan. 2018. Exploration and Ex-planation in Computational Notebooks. In Proceedings of the 2018 CHI Con-
ference on Human Factors in Computing Systems (Montreal QC, Canada) (CHI
â€™18).AssociationforComputingMachinery,NewYork,NY,USA,1â€“12. https:
//doi.org/10.1145/3173574.3173606
[50]Saksham Sachdev, Hongyu Li, Sifei Luan, Seohyun Kim, Koushik Sen, and Satish
Chandra.2018.Retrievalonsourcecode:aneuralcodesearch.In Proceedingsofthe
2ndACMSIGPLANInternationalWorkshoponMachineLearningandProgramming
Languages. ACM, 31â€“41.
[51]Lin Tan, Ding Yuan, Gopal Krishna, and Yuanyuan Zhou. 2007. /* iComment:
Bugs or bad comments?*. In Proceedings of twenty-first ACM SIGOPS symposium
on Operating systems principles. 145â€“158.
[52]ShinHweiTan,DarkoMarinov,LinTan,andGaryTLeavens.2012. @tcomment:
Testing javadoc comments to detect comment-code inconsistencies. In 2012 IEEE
Fifth International Conference on Software Testing, Verification and Validation.
IEEE, 260â€“269.
[53]Bogdan Vasilescu, Casey Casalnuovo, and Premkumar T. Devanbu. 2017. Recov-
ering clear, natural identifiers from obfuscated JS names. In Proceedings of the
201711thJointMeetingonFoundationsofSoftwareEngineering,ESEC/FSE2017,
Paderborn, Germany, September 4-8, 2017. 683â€“693.
[54]YazaWainakh,MoizRauf,andMichaelPradel.2021. IdBench:EvaluatingSeman-ticRepresentationsofIdentifierNamesinSourceCode.In IEEE/ACMInternational
Conference on Software Engineering (ICSE).
[55]Jiawei Wang, KUO Tzu-Yang, Li Li, and Andreas Zeller. 2020. Assessing and
Restoring Reproducibility of Jupyter Notebooks. In 2020 35th IEEE/ACM Interna-
tional Conference on Automated Software Engineering (ASE). IEEE, 138â€“149.
[56]KeWangandZhendongSu.2020.Blended,precisesemanticprogramembeddings.InProceedingsofthe41stACMSIGPLANInternationalConferenceonProgramming
LanguageDesignandImplementation,PLDI2020,London,UK,June15-20,2020,
AlastairF.DonaldsonandEminaTorlak(Eds.).ACM,121â€“134. https://doi.org/
10.1145/3385412.3385999
[57]YuWang,FengjuanGao,LinzhangWang,andKeWang.2020. LearningSemantic
Program Embeddings with Graph Interval Neural Network. In OOPSLA.
1480
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:28:46 UTC from IEEE Xplore.  Restrictions apply. Learning from Runtime Behavior to Find Name-Value Inconsistencies ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
[58] Jiayi Wei, Maruth Goyal, Greg Durrett, and Isil Dillig. 2020. LambdaNet: Proba-
bilisticTypeInferenceusingGraphNeuralNetworks.In 8thInternationalCon-
ferenceonLearningRepresentations,ICLR2020,AddisAbaba,Ethiopia,April26-30,
2020. OpenReview.net. https://openreview.net/forum?id=Hkx6hANtwH
[59]Zhaogui Xu, Xiangyu Zhang, Lin Chen, Kexin Pei, and Baowen Xu. 2016.
Pythonprobabilistictypeinferencewithnaturallanguagesupport.In Proceed-
ingsofthe24thACMSIGSOFTInternationalSymposiumonFoundationsofSoft-
ware Engineering, FSE 2016, Seattle, WA, USA, November 13-18, 2016. 607â€“618.https://doi.org/10.1145/2950290.2950343
[60]JianZhang,XuWang,HongyuZhang,HailongSun,KaixuanWang,andXudong
Liu.2019. ANovelNeuralSourceCodeRepresentationbasedonAbstractSyntax
Tree. InICSE.
1481
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:28:46 UTC from IEEE Xplore.  Restrictions apply. 