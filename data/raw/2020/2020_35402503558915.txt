SFLKit: A Workbench forStatistical FaultLocalization
Marius Smytzek
CISPA Helmholtz Center forInformationSecurity
Saarbr√ºcken, Germany
SaarlandUniversity
Saarbr√ºcken, Germany
marius.smytzek@cispa.deAndreas Zeller
CISPA Helmholtz Center forInformationSecurity
Saarbr√ºcken, Germany
zeller@cispa.de
ABSTRACT
Statisticalfaultlocalizationaimsatdetectingexecutionfeaturesthat
correlate with failures, such as whether individual lines are part of
the execution. We introduce SFLKit, an out-of-the-box workbench
forstatisticalfaultlocalization.Theframeworkprovidesstraight-
forwardaccesstothefundamentalconceptsofstatisticalfaultlo-
calization.Itsupports fivepredicatetypes,four coverage-inspired
spectra,likelines,and44similaritycoefficients,e.g., TARANTULA
orOCHIAI,for statisticalprogram analysis.
SFLKitseparatestheexecutionoftestsfromtheanalysisofthere-
sultsandisthereforeindependentoftheusedtestingframework.It
leverages program instrumentation to enable the logging of events
and derives the predicates and spectra from these logs. This instru-
mentationallowsforintroducingmultipleprogramminglanguages
andtheextensionofnewconceptsinstatisticalfaultlocalization.
Currently,SFLKitsupportstheinstrumentationofpythonprograms.
SFLKitis highly configurable,requiringonly the loggingof the re-
quiredevents.
CCS CONCEPTS
¬∑Softwareanditsengineering ‚ÜíSoftwaretestinganddebug-
ging;Softwarelibraries and repositories .
KEYWORDS
statistical fault localization, statistical debugging,spectrum-based
faultlocalization,similaritycoefficient
ACMReference Format:
Marius Smytzek and Andreas Zeller. 2022. SFLKit: A Workbench for Sta-
tistical Fault Localization. In Proceedings of the 30th ACM Joint European
Software Engineering Conference and Symposium on the Foundations of Soft-
wareEngineering(ESEC/FSE‚Äô22),November14≈õ18,2022,Singapore,Singapore.
ACM,NewYork,NY,USA, 5pages.https://doi.org/10.1145/3540250.3558915
1 INTRODUCTION
The basic concept of statistical fault localization is easy to explain.
Supposeaparticularlineintheprogramisexecutedprimarilyon
failing runs. In that case, its execution correlates with a failure and
Permissionto make digitalor hard copies of allorpart ofthis work for personalor
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthefirstpage.Copyrights forcomponentsofthisworkownedbyothersthanthe
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or
republish,topostonserversortoredistributetolists,requirespriorspecificpermission
and/or a fee. Request permissions from permissions@acm.org.
ESEC/FSE ‚Äô22, November 14≈õ18,2022, Singapore, Singapore
¬©2022 Copyright heldby the owner/author(s). Publicationrightslicensed to ACM.
ACM ISBN 978-1-4503-9413-0/22/11...$15.00
https://doi.org/10.1145/3540250.3558915‚ñ†:coveredstatements x3 1 3 5 5 2
y3 2 2 5 3 1
1defmiddle(x, y, z): z 5 3 1 1 4 3
2ify < z: ‚ñ† ‚ñ† ‚ñ† ‚ñ† ‚ñ† ‚ñ† 2
3 ifx < y:‚ñ°‚ñ†‚ñ° ‚ñ° ‚ñ° ‚ñ° 3
4 returny‚ñ°‚ñ†‚ñ° ‚ñ° ‚ñ° ‚ñ° 4
5 elifx < z:‚ñ†‚ñ° ‚ñ° ‚ñ°‚ñ† ‚ñ† 5
6 returny‚ñ†‚ñ° ‚ñ° ‚ñ° ‚ñ°‚ñ†6
7else: ‚ñ†‚ñ°‚ñ† ‚ñ†‚ñ° ‚ñ° 7
8 ifx > y:‚ñ° ‚ñ°‚ñ†‚ñ° ‚ñ° ‚ñ° 8
9 returny‚ñ° ‚ñ°‚ñ†‚ñ° ‚ñ° ‚ñ° 9
10 elifx > z:‚ñ° ‚ñ° ‚ñ° ‚ñ° ‚ñ° ‚ñ° 10
11 returnx‚ñ° ‚ñ° ‚ñ° ‚ñ° ‚ñ° ‚ñ° 11
12returnz‚ñ† ‚ñ† ‚ñ† ‚ñ† ‚ñ† ‚ñ† 11
‚úî ‚úî ‚úî ‚úî ‚úî ‚úò
Figure 1: Statistical fault localization [ 7]. Themiddle() func-
tiontakesthreevaluesandreturnstheonethatisneitherthe
minimumnorthemaximum;Line6moststronglycorrelates
with failure.
givesessential hintsonthefailure causes,notablyapossible loca-
tion. Theseminal TARANTULA paper[7]uses amiddle() function
to illustrate the concept, shown in Figure 1.middle(x, y, z) is
supposed to return the ≈Çmiddle≈æ of the three values x,y,z√êthe
value that is neither the minimum, nor the maximum of the three:
middle(5, 3, 4) ,for instance,correctlyreturns 4.
However, the middle() code in Figure 1is faulty, as middle(2,
1, 3)returns 1 rather than 2. By feeding middle() various values
and observing the executed lines, we can determine that the execu-
tion of Line 6 has the strongest correlation with failure. Line 6 also
happens tobe the fault location√êitshouldreturn xrather than y.
Whatworkswellinasmallexampledoesnotnecessarilyscaleto
largesystems.Onalargescale,statisticalfaultlocalizationcansuffer
from reporting a multitude of potentially suspicious lines [14,15].
Variousstatisticalapproacheshavebeensuggestedoverthepast
two decades, each improving over the previous benchmark results,
tomakefaultlocalizationmoreprecise[ 14].However,eachofthese
approachesintroducestheiruniqueinfrastructurethatwithcustom
debuggingloggers, custompredicates and customspectra [ 2,6,8].
Yet, for research, we‚Äôd like to be able to selectandcombinethese
elements inamodular,reusablefashion.
This paper introduces SFLKit, a modular statistical fault local-
ization framework that provides easy-to-use essential concepts of
statistical debugging and spectrum-based fault localization. SFLKit
1701
ESEC/FSE ‚Äô22, November14≈õ18, 2022,Singapore, Singapore Marius Smytzek andAndreas Zeller
ishighlyconfigurableandeffortlesstoextendwithnewapproaches,
makingitagreatbasefor future researchandeducation.
2 BACKGROUND
2.1 Spectrum-BasedFaultLocalization
Spectrum-Based Fault Localization (SBFL) [7] is a technique to lo-
calize the code location of a fault, founded on so-called program
spectra,whichdescribeaprogram‚Äôsexecution.Typicallysuchan
approachconsidersafaultyprogramandatestsetcomprisingat
least one failing test. This approach then collects coverage infor-
mation for each test case as the spectrum and correlates each code
element, described by the coverage, with the failure by calculating
a suspiciousness score. This score ranks how likely a specific code
location is faulty. The general idea behind SBFLis that elements
oftenexecutedinfailingtestcasesandnotsoofteninpassingones
are more likely to be faulty. In recent years, this technique became
more popular as part of automated program repair and was the
subjectofsomestudiesinthis context[ 16].
In practice, SBFLtechniques consider executed lines and use
a similarity coefficient to compute the suspiciousness. Different
approaches vary only in the choice of this similarity coefficient.
Thisresearchtrendresultsinanuncountablenumberofpossible
coefficients[ 5,9,12].TARANTULA [7,8]wasoneofthefirstmetrics
introducedto SBFLandisstillapopular choice.
SFLKit implements four spectra and 38 similarity coefficients
that ausercan leverage(see Table 1).
2.2 Statistical Debugging
In contrast to SBFL, statistical debugging ( SD) leverages predicates
onthecodethat canbe true,false,or notexecuted. Dependingon
theresultofthesepredicates, SDallowsforderivingpropertiesthat
needtoholdforproducingthefault.While SBFLreliesonsimilarity
coefficients to measure the suspiciousness of an element, SDrelies
onthe standardizedmetrics Failure,Context,andIncrease[11].
Failureistheprobabilityafailureoccursundertheconditionthat
apredicate evaluates to true.
Context istheprobabilitythatafailureoccurswhenthepredicate
isobserved.
Increase describeshowmuchthepredicatebeing trueincreases
the probability of a failure occurring. The Increaseof a pred-
icateùëùiscalculatedas
Increase(ùëù)=Failure(ùëù) ‚àíContext(ùëù)
The most common example of SDis to leverage the condition of
branches, whichwasintroducedbyLiblit etal.[ 11].
SFLKitsupportsfivetypesofpredicatesthatcovervariouspro-
gram properties, allowing for tracking different program behaviors
that could leadto afault(see Table 1).
3 DESIGN AND IMPLEMENTATION
We designedour frameworksuch thatwe canseparate itinto two
stages.Thefirstisthecollectingofexecutionfeatures.Thisstage
representsa debugging logger where we collect eventsduring the
program‚Äôs execution to capture its behavior. It is entirely inde-
pendent of statistical fault localization and allows for using ourTarget.pyPython
Visitor
Meta
Visitor
Line
Event
FactoryBranch
Event
FactoryModificationsOut.py
Figure 2: A description of the meta-level instrumentation
used inour statistical faultlocalizationframework.
framework as a debugging logger. We describe this phase in Sec-
tion3.1.Thesecondstageisanalyzingthecollectedfeatureswith
conceptsofstatisticalfaultlocalization.Weexplainthisphasein
Section3.2.
3.1 Collecting Execution Features
The base of our statistical fault localization framework is an instru-
mentation of the source code that enables the logging of specified
events.
This concept leverages the abstract syntax tree ( AST) of the
source code and an interface enabling the visiting of a node of the
ASTon a meta-level. Each event we use comes with a factory to
produceit.Thefactoryrepresentsthevisitoronthemeta-leveland
onlyproducestheinstrumentationforthesingleeventitrepresents.
For example, we implemented a line event that gets triggered
every time a line (or a statement in other programming languages)
occurs.Theoverallvisitor,inthiscaseforPython,callseverymeta-
visitorforeachnode.Theeventfactoryknowstheinjectionsand
modificationsofthecodeforeachnode.Withthisdesign,wecanex-
tend our framework with new programming languages and events
whilethe eventsare independent.
Our framework accomplishes the instrumentation in three steps
ontheAST.
(1)Parse the source code to an abstract syntax tree ( AST). Visit
eachnodeofthe AST.Weleveragethe astmodulecoming
withPythonfor our Pythonsupport.
(2)Callthecorrespondingmeta-levelvisitorontheASTnode
that knowsthe statements itneedsto inject.
(3)Combine all injections and changes to modify the source
code.
The implementation of our instrumentation allows the exten-
sion with other programming languages without modifying the
core functionalities by implementing the event factories for anew
programminglanguageandanASTvisitorvisitingallnodesand
combining the results ofthesefactories.
Figure2provides an overview of the instrumentation process in
our statisticalfaultlocalizationframework.
Ourcurrentimplementationsupportssolely Pythonprogramsbe-
cause we did our experiments and evaluation in this programming
language.
1702SFLKit: A WorkbenchforStatisticalFaultLocalization ESEC/FSE ‚Äô22, November14≈õ18, 2022,Singapore, Singapore
Table 1: The implemented concepts of statistical fault localization. The first column describes the type of the concept, the
second thenumberofimplemented conceptsofthistype,andthelastcolumn lists theconcepts.
Type Number Concepts
Events 11 LineEvent,BranchEvent,DefEvent,UseEvent,FunctionEnterEvent,FunctionExitEvent,FunctionErrorEvent,LoopBegin-
Event,LoopHitEvent,LoopEndEvent,ConditionEvent
Spectra 4 Lines[ 7], Functions, DefUse Pairs[ 17], Loops[13]
SimilarityCoefficients [ 5,9,12] 44 AMPLE[4], AMPLE2[ 4], Anderberg, ArithmeticMean, Binary, CBIInc, Cohen, Crosstab[ 22], Dice, DStar[ 21], Euclid, Fleiss,
GP02[24],GP03[24],GP13[24],GP19[24],Goodman,Hamann,HammingEtc,HarmonicMean,Jaccard[ 3],Kulczynski1,
Kulczynski2,M1,M2,Naish1[ 10],Naish2[ 10],Ochiai[ 1],Ochiai2[ 1],PairScoring,qe,RogersAndTanimoto,Rogot1,Rogot2,
RusselAndRao, Scott,SimpleMatching,Sokal, SorensenDice, Tarantula[ 7], Wong1[ 23], Wong2[ 23], Wong3[ 23], Zoltar
Predicates 5 Branch[ 11], Scalar Pairs[ 11], VariablePredicates,ReturnPredicates[ 11], Condition
Thecoreofourstatisticalfaultlocalizationframeworkareevents
collected during the execution of the program under test. In detail,
aunittestissuitableforextractingtheexecutioneventswithour
framework.Theseeventsinjecttheirrequiredstatementsintothe
target program as part ofthe instrumentation.
Ourinstrumentationcancollecttheexecutioneventsduringa
testrunandputthemasideforlateranalysis.Thecriticalcompo-
nent here is a shared library that is part of the instrumentation.
Whentheprogramlogsanevent,ittellsthesharedlibrarytowrite
thedeterminedeventintothelog.Theanalysiscanthenreadthe
log and construct the needed data from this log. This separation
allowsfor using our framework as an executioneventlogger.
Table1providesan overviewofthe implementedevents.
3.2 AnalyzingExecution Features
Toanalyzetheexecutionfeatures,weleveragetheloggedevents
to rebuild amodelthat we can modify whilereplaying the events.
This model is a practical way of keeping track of the program‚Äôs
behaviorduringtheexecutionandenablesourframeworktoderive
the spectraandpredicates usedfor future analysis.
Foreachrun,forwhichalogexists,SFLKitbuildsamodeland
checkswhatspectraandpredicatesareobservedand,inaddition,
howtheyevaluate,i.e.,forpredicatesto trueorfalse.Itleverages
theseobservationstocalculateavarietyofsuspiciousnessscoresde-
finedbytheuser.Thesuspiciousnessscoresprovideanoverviewof
howlikelyananalysisobjectcorrelateswiththefaulttoinvestigate.
Weimplementedmanypreviouslyintroducedanalysisobjects
likelines,branches,ordef-usepairs.Asanovelaspect,weintroduce
a new predicate we are not aware already exists to the best of
our knowledge. We based this novel analysis subject on existing
coveragecriteria.
Conditions We introducecondition predicatesderivedfrom con-
dition coverage. For this predicate, we log sub-condition
events thatoccurwheneverasub-conditionoccurs,e.g., all
terms of the test of an if-statement. The predicate checks
whetherasub-conditionbeingtrue(orfalse)correlateswith
the program‚Äôs failure.
After extracting all analysis objects, we evaluatethem with the
defined similarity coefficients or, in the case of predicates, with the
Increasemetric as explainedinSection 2.2.
Table1provides an overview of the supported program spectra,
predicates, andsimilaritycoefficients.Event
LogsModelSpectra
PredicatesSimilarity
Coefficients
Figure 3: An overview of the analysis stage of our statistical
faultlocalizationframework.
4 TOOL USAGE
We provide our workbench as a Python package that is instal-
lable by running pip install . inside the root directory of the
framework.Afterinstallingthepackage,thevariousconceptsare
accessible by importing sflkitin a Python script. The easy-to-
use access points to SFLKit are sflkit.instrument(config) and
sflkit.analyze(config) thattakethepathtoaconfigfileandex-
ecute the instrumentation and the analysis of the execution events.
Consider the example in Figure 1. Figure4shows an example of
a config file for this scenario. sflkit.instrument(config) lever-
agesthepredicatestoinvestigate,extracttheneededevents,and
then instruments thetarget path asdescribed inSection 3.1to the
instrumentationpath. sflkit.analyze(config) parsestheevents
frompassingandfailingparameters,buildsamodelforeachrun,
andthenanalysistheexecutedlinesandcomputestheinmetrics
provided OCHIAI[1,2],JACCARD[3],andTARANTULA [7,8]onthese
lines.
All these steps allow for an individual execution and can be
interferedwithat any time to leverageintermediate results.
In addition, our tool provides a command-line interface that
leveragestheseconfigurationfiles.Toexecutethecommand-line
interface, a user needs to run python sfl.py instrument -c
configandpython sfl.py analyze -c config whereconfig
isthe pathto the config file.
5 EXPERIMENTALEVALUATION
WeinvestigatedbugsfromtheBugsInPy[ 19,20]benchmarktotest
SFLKit under authentic conditions. This collection of real-world
faultyPythonprogramscomprises501subjectswithpassingand
failingteststhat wecanleverage.In addition,thebenchmarkpro-
videsapatchfileforeachbugthatwecanusetoextractthecode
locations that contributeto the fau
1703ESEC/FSE ‚Äô22, November14≈õ18, 2022,Singapore, Singapore Marius Smytzek andAndreas Zeller
1[target]
2path=middle.py
3language =Python
4
5[events]
6predicates =Line
7metrics =Ochiai,Tarantula,Jaccard
8passing =events/passing
9failing =events/failing
10
11[instrumentation]
12path=tmp.py
Figure 4:Anexample ofaconfigfile forSFLKit
BugsInPy provides the test file for each bug that contains the
tests that trigger it. We used only the test cases in the provided
file because these are more likely to relate to the fault. In addition,
using only these tests instead of all provided test files significantly
speedsupour evaluation.
We selected three bugs for each project included in BugsInPy to
investigate,ifpossible.Severalprogramshavenofailingtests.Even
theteststhatshouldtriggerthebugdidnotfail,soweskippedthem
forourselection.Moreover,someapplicationshavenopassingtests,
which we excluded too because there would be no logical expla-
nation for a particular code location to be faulty. In addition, we
didnotinvestigatematplotlib/matplotlibandpandas-dev/pandas
because both come with a tremendous number of test cases that
take too long to run in our cross-validation setup for which we
neededtoexecuteeachsubjectmultipletimes.Moreover,weneeded
toexcludeexplosion/spaCy,sincetherewerenosuitablesubjects
as specified by our criteria. However, we want to investigate the
subjects we skipped in further evaluating our statistical fault local-
izationframework.
Besides this subject selection, we could not leverage each pro-
vided test in our evaluation. We excluded such test cases that
changed theoutcome because ofour instrumentation.We noticed
two reasons for this. The first is that some ofthe tests verified the
integrityofthesourcecode,i.e.,itwasnotaltered,whichwedid.
The other reason is that a few tests ran into performance issues
wheninstrumented.Theseperformanceissuesaresomethingwe
want to investigate further.
Table2providesan overviewofallthe bugsandtests we lever-
aged to test our framework. We investigated 41 subjects from 15
of BugsInPy‚Äôs 17 projects with a combined number of 1,823 test
cases. Moreover, the chosen subjects demonstrate the scalability of
SFLKit,withsubjectscomprisingupto 68,801linesofcode.
We investigatedlines asananalysistargetfor thesereal-world
experimentations. We calculated the precision, recall, precision@k,
andrecall@konthesuggestionstheanalysisreturnsconcerningthe
actual faulty lines. We leveraged the OCHIAI[1,2], theJACCARD [3],
andthe TARANTULA [7,8]similaritycoefficientsfortheexperimental
evaluation. Table 3demonstratesthe results ofthis evaluation.
SFLKitproducedmeaningfulresultsfortheinvestigatedsubjects,
with an average precision of 0.237 and a recall of 0.139, aligning
withsimilar experiments, e.g.,Jiangetal.[ 6].Table 2: The subjects of BugsInPy we investigated. Bugs,
#Bugs,#Tests,#linesdonatetothenumberofbugspersubject,
thebugsweinvestigated,thenumberoftestsweleveraged,
and the average lines of code analyzed per bug, respectively.
Project Bugs #Bugs #Tests #Lines
cool-RR/PySnooper 3 1 5 216
ansible/ansible 18 3 245 53,651
psf/black 23 3 341 145
cookiecutter/cookiecutter 4 3 26 997
tiangolo/fastapi 16 3 20 4,268
jakubroztocil/httpie 5 3 37 2,128
keras-team/keras 45 3 199 21,747
spotify/luigi 33 3 211 14,894
huge-success/sanic 5 3 158 4,023
scrapy/scrapy 40 3 53 10,962
nvbn/thefuck 32 3 65 3,953
tornadoweb/tornado 16 3 146 23,868
tqdm/tqdm 9 3 153 3,744
ytdl-org/youtube-dl 43 3 164 68,801
Total 501 41 1,823 639,772
Table 3: The results of the experimental evaluation. p@k
donatestoprecision@kandr@ktorecall@k,respectively.
p@1 andr@1 are equivalent to precision and recall.
Coefficient k=1 k=3 k=5 k=10
p@1 r@1 p@3 r@3 p@5 r@5 p@10 r@10
OCHIAI 0.22 0.13 0.21 0.14 0.18 0.16 0.12 0.17
JACCARD 0.22 0.13 0.22 0.14 0.18 0.16 0.12 0.17
TARANTULA 0.27 0.15 0.25 0.16 0.22 0.18 0.14 0.19
Average 0.237 0.139 0.228 0.149 0.194 0.163 0.130 0.178
6 CONCLUSION
In this paper, we presented SFLKit, a statistical fault localization
framework that is accessible and out-of-the-box usable for real-
world applications. The framework provides all common key com-
ponents of statistical debugging and spectrum-based fault localiza-
tion.
SFLKit leverages extendable program instrumentation to log
executionfeaturesasoccurringeventsandderivesamodelfrom
these features. Leveraging this model, our framework provides
variousanalysesforstatisticallycorrelatingtheseexecutionfeatures
withfailures.
SFLKit opens the door for uniform and comparable future re-
search in the area of statistical fault localization. Our framework is
available as open sourceat
https://github.com/uds-se/sflkit
DATA AVAILABILITY
Thedatarequiredtoreproducetheabovefindingsareopenlyavail-
ableathttp://doi.org/10.1145/3554333 ,reference number [ 18].
1704SFLKit: A WorkbenchforStatisticalFaultLocalization ESEC/FSE ‚Äô22, November14≈õ18, 2022,Singapore, Singapore
REFERENCES
[1]Rui Abreu, Peter Zoeteweij, and Arjan J. C. van Gemund. 2006. AnEvaluation of
Similarity Coefficients for Software Fault Localization. In Proceedings of the 12th
Pacific Rim International Symposium on Dependable Computing (PRDC ‚Äô06) . IEEE
Computer Society, USA,39≈õ46. https://doi.org/10.1109/PRDC.2006.18
[2]Rui Abreu, Peter Zoeteweij, and Arjan J.C. van Gemund. 2007. On the Accuracy
of Spectrum-based Fault Localization. In Testing: Academic and Industrial Confer-
encePracticeandResearchTechniques -MUTATION(TAICPART-MUTATION2007) .
89≈õ98.https://doi.org/10.1109/TAIC.PART.2007.13
[3]MikeChen,EmreKiciman,EugeneFratkin,ArmandoFox,andEricBrewer.2002.
Pinpoint:problemdeterminationinlarge,dynamicInternetservices. Proceedings
ofthe2002InternationalConferenceonDependableSystemsandNetworks ,595≈õ
604.https://doi.org/10.1109/DSN.2002.1029005
[4]Valentin Dallmeier, Christian Lindig, and Andreas Zeller. 2005. Lightweight Bug
LocalizationwithAMPLE.In ProceedingsoftheSixthInternationalSymposium
onAutomatedAnalysis-DrivenDebugging (Monterey,California,USA) (AADE-
BUG‚Äô05). Association for Computing Machinery, New York, NY, USA, 99≈õ104.
https://doi.org/10.1145/1085130.1085143
[5]Patrick Daniel and Kwan Yong Sim. 2013. Spectrum-based Fault Localization: A
Pair Scoring Approach. Journal of Industrial and Intelligent Information 1 (2013),
185≈õ190. https://doi.org/10.12720/jiii.1.4.185-190
[6]Jiajun Jiang, Ran Wang, Yingfei Xiong, Xiangping Chen, and Lu Zhang. 2019.
Combining Spectrum-Based Fault Localization and Statistical Debugging: An
Empirical Study. In Proceedings of the 34th IEEE/ACM International Conference on
Automated Software Engineering (San Diego, California) (ASE ‚Äô19). IEEE Press,
502≈õ514. https://doi.org/10.1109/ASE.2019.00054
[7]J.A. Jones, M.J. Harrold, and J. Stasko. 2002. Visualization of test information
to assist faultlocalization.In Proceedingsofthe 24thInternationalConference on
Software Engineering. ICSE 2002 . 467≈õ477. https://doi.org/10.1145/581396.581397
[8]James A. Jones and Mary Jean Harrold. 2005. Empirical Evaluation of the taran-
tulaAutomaticFault-LocalizationTechnique. 273≈õ282. https://doi.org/10.1145/
1101908.1101949
[9]David Landsberg, Hana Chockler, Daniel Kroening, and Matt Lewis. 2015.
Evaluation of Measures for Statistical Fault Localisation and an Optimising
Scheme.In FundamentalApproachestoSoftwareEngineering ,AlexanderEgyed
and Ina Schaefer (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg, 115≈õ129.
https://doi.org/10.1007/978-3-662-46675-9_8
[10]HuaLee,LeeNaish,andKotagiriRamamohanarao.2009. TheEffectivenessof
Using Non redundant Test Cases with Program Spectra for Bug Localization.
ComputerScienceandInformationTechnology,InternationalConferenceon 0(08
2009),127≈õ134. https://doi.org/10.1109/ICCSIT.2009.5234587
[11]Ben Liblit, Mayur Naik, Alice X. Zheng, Alex Aiken, and Michael I. Jordan.
2005. Scalable Statistical Bug Isolation. SIGPLAN Not. 40, 6 (jun 2005), 15≈õ26.
https://doi.org/10.1145/1064978.1065014
[12]LeeNaish,HuaJieLee,andKotagiriRamamohanarao.2011. AModelforSpectra-
Based Software Diagnosis. ACM Trans. Softw. Eng. Methodol. 20, 3, Article 11
(aug 2011),32pages. https://doi.org/10.1145/2000791.2000795[13]PruthvirajP.2021. FineGrainedStatisticalDebuggingfortheIdentificationof
Multiple Bugs. InternationalJournal ofEngineering Research 10,05(2021), 7.
[14]Chris Parnin and Alessandro Orso. 2011. Are Automated Debugging Tech-
niques Actually Helping Programmers?. In Proceedings of the 2011 International
Symposium on Software Testing and Analysis (Toronto, Ontario, Canada) (IS-
STA‚Äô11).AssociationforComputingMachinery,NewYork,NY,USA,199≈õ209.
https://doi.org/10.1145/2001420.2001445
[15]Chris Parnin and Alessandro Orso. 2021. Automated Debugging: Past, Present,
and Future (ISSTA Impact Paper Award) . Association for Computing Machinery,
NewYork, NY, USA,1. https://doi.org/10.1145/3460319.3472397
[16]YuhuaQi,XiaoguangMao,YanLei,andChengsongWang.2013.UsingAutomated
ProgramRepairforEvaluatingtheEffectivenessofFaultLocalizationTechniques.
InProceedings of the 2013 International Symposium on Software Testing and Anal-
ysis(Lugano,Switzerland) (ISSTA2013) .AssociationforComputingMachinery,
NewYork, NY, USA,191≈õ201. https://doi.org/10.1145/2483760.2483785
[17]Raul Santelices, James A. Jones, Yanbing Yu, and Mary Jean Harrold. 2009. Light-
weightFault-LocalizationUsingMultipleCoverageTypes.In Proceedingsofthe
31st International Conference on Software Engineering (ICSE ‚Äô09) . IEEE Computer
Society, USA,56≈õ66. https://doi.org/10.1109/ICSE.2009.5070508
[18]Marius Smytzek and Andreas Zeller. 2022. SFLKit. https://doi.org/10.1145/
3554333
[19]RatnadiraWidyasari,ShengQinSim,CamelliaLok,HaodiQi,JackPhan,Qijin
Tay, Constance Tan, Fiona Wee, Jodie Ethelda Tan, Yuheng Yieh, Brian Goh,
FerdianThung,HongJinKang,ThongHoang,DavidLo,andEngLiehOuh.2020.
BugsInPy. https://github.com/soarsmu/BugsInPy/tree/master/projects .
[20]RatnadiraWidyasari,ShengQinSim,CamelliaLok,HaodiQi,JackPhan,Qijin
Tay, Constance Tan, Fiona Wee, Jodie Ethelda Tan, Yuheng Yieh, Brian Goh,
FerdianThung,HongJinKang,ThongHoang,DavidLo,andEngLiehOuh.2020.
BugsInPy:adatabaseofexistingbugsinPythonprogramstoenablecontrolled
testinganddebuggingstudies.In Proceedingsofthe28thACMJointMeetingon
EuropeanSoftware Engineering Conference and Symposium onthe Foundations of
SoftwareEngineering .ACM,1556≈õ1560. https://doi.org/10.1145/3368089.3417943
[21]W.EricWong,VidrohaDebroy,YihaoLi,andRuizhiGao.2012. SoftwareFault
Localization Using DStar (D*). In 2012 IEEE Sixth International Conference on
SoftwareSecurityand Reliability . 21≈õ30.https://doi.org/10.1109/SERE.2012.12
[22]W.EricWong,VidrohaDebroy,andDianxiangXu.2012. TowardsBetterFaultLo-
calization: A Crosstab-Based Statistical Approach. IEEE Transactions on Systems,
Man, and Cybernetics, Part C (Applications and Reviews) 42, 3 (2012), 378≈õ396.
https://doi.org/10.1109/TSMCC.2011.2118751
[23]W. Eric Wong, Yu Qi, Lei Zhao, and Kai-Yuan Cai. 2007. Effective Fault Lo-
calization using Code Coverage. In 31st Annual International Computer Soft-
ware and Applications Conference (COMPSAC 2007) , Vol. 1. 449≈õ456. https:
//doi.org/10.1109/COMPSAC.2007.109
[24]XiaoyuanXie,Fei-ChingKuo,TsongYuehChen,ShinYoo,andMarkHarman.
2013. ProvablyOptimalandHuman-CompetitiveResultsinSBSEforSpectrum
Based Fault Localisation. In Proceedings of the 5th International Symposium on
Search Based Software Engineering - Volume8084 (St. Petersburg, Russia) (SSBSE
2013). Springer-Verlag, Berlin, Heidelberg, 224≈õ238. https://doi.org/10.1007/978-
3-642-39742-4_17
1705