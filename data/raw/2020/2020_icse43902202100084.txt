Interpretation-enabled Software Reuse Detection
Based on a Multi-Level Birthmark Model
Xi Xuy, Qinghua Zhengy, Zheng Yanx{, Ming Fanz, Ang Jiaz, and Ting Liuz
Key Laboratory of Intelligent Networks and Network Security, Ministry of Education, China
ySchool of Computer Science and Technology, Xi‚Äôan Jiaotong University, China
zSchool of Cyber Science and Engineering, Xi‚Äôan Jiaotong University, China
xState Key Lab on Integrated Services Networks, School of Cyber Engineering, Xidian University, China
{Department of Communications and Networking, Aalto University, Finland
xx19960325@stu.xjtu.edu.cn; qhzheng@xjtu.edu.cn; zyan@xidian.edu.cn;
mingfan@mail.xjtu.edu.cn; jiaang@stu.xjtu.edu.cn; tingliu@mail.xjtu.edu.cn
Abstract ‚ÄîSoftware reuse, especially partial reuse, poses legal
and security threats to software development. Since its source
codes are usually unavailable, software reuse is hard to be de-
tected with interpretation. On the other hand, current approaches
suffer from poor detection accuracy and efÔ¨Åciency, far from
satisfying practical demands. To tackle these problems, in this
paper, we propose ISRD , an interpretation-enabled software reuse
detection approach based on a multi-level birthmark model that
contains function level, basic block level, and instruction level. To
overcome obfuscation caused by cross-compilation, we represent
function semantics with Minimum Branch Path (MBP) and
perform normalization to extract core semantics of instructions.
For efÔ¨Åciently detecting reused functions, a process for ‚Äúintent
search based on anchor recognition‚Äù is designed to speed up reuse
detection. It uses strict instruction match and identical library
call invocation check to Ô¨Ånd anchor functions (in short anchors)
and then traverses neighbors of the anchors to explore potentially
matched function pairs. Extensive experiments based on two real-
world binary datasets reveal that ISRD is interpretable, effective,
and efÔ¨Åcient, which achieves 97:2%precision and 94:8%recall.
Moreover, it is resilient to cross-compilation, outperforming state-
of-the-art approaches.
Index Terms ‚ÄîBinary Similarity Analysis, Software Reuse
Detection, Multi-Level Software Birthmark, Interpretation
I. I NTRODUCTION
Along with the growing popularity of open-source software,
software reuse becomes a common phenomenon. However,
extensive reuse of existing codes leads to numerous license
violation issues [1], [2]. For example, Cisco and VMWare
were exposed to signiÔ¨Åcant legal issues because they did not
adhere to the licensing terms of Linux kernel [3], [4]. What is
more, security issues could be raised due to careless software
reuse [5].
The goal of software reuse detection is to determine whether
a candidate program contains similar codes already used in a
target program. There are many approaches [6], [7] proposed
in the literature. According to the analysis objects, these
approaches can be divided into two groups: source code reuse
detection and binary code reuse detection. The Ô¨Årst calculates
code similarity by abstracting source codes into a set of
characteristics, such as string [8], [9], token [10], [11], [12],
Corresponding author: Zheng Yan.[13], Abstract Syntax Tree (AST) [14], [15], [16], [17] and
Program Dependency Graph (PDG) [18], [19], [20]. Since the
source code of a candidate program is typically unavailable in
reality, binary code reuse detection is used widely for software
plagiarism detection [21], [22], [23], malware detection [24],
[25], [26], patch analysis [27], [28], [29], and so on.
However, the existing binary code reuse detection ap-
proaches suffer from three limitations, as described below.
Poor interpretability : The detection results of the existing
approaches [21], [24], [27] lack of the ability to provide
detailed evidence to support reuse detection results because
they usually only report their results in form of similarity
scores ranging from 0 to 1. The ability to comprehensively
interpreting the detection results is extremely important since
it can provide the details or reasons to make the detection
results acceptable or easy to be understood.
Poor accuracy : Most approaches [30], [31], [32], [33], [34]
that rely on structural and syntax information fail to deal with
the differences caused by variations in compilation. This is
because different compilations of a source program naturally
produce different structures and syntax in its binary codes,
forming obfuscation. For example, the approaches proposed
in [35], [36] that operate at the boundaries of a basic block
might fail to deal with basic block splitting or merging.
Poor efÔ¨Åciency : Several works [34], [35] use a brute force
method to identify reused functions, which is prohibitively
expensive since it measures the similarities of all function
pairs between a target program and a candidate program. Such
approaches lead to poor efÔ¨Åciency if the numbers of functions
in both programs are big. Therefore, these approaches are
neither effective in case that a reused part only makes up a
small percentage of the candidate program, nor efÔ¨Åcient if an
excessive number of function pairs need to be compared.
To overcome the above limitations, we propose ISRD , a
novel Interpretation-enabled Software Reuse Detection ap-
proach based on a multi-level birthmark model, which holds
the following salient advantages:
Interpretable detection results. ISRD is capable of capturing
program semantics from coarse granularity to Ô¨Åne granularity
and uniquely identifying a program with a multi-level birth-
8732021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)
1558-1225/21/$31.00 ¬©2021 IEEE
DOI 10.1109/ICSE43902.2021.00084
mark model that contains function level, basic block level,
and instruction level. SpeciÔ¨Åcally, at the function level, a
Function Call Graph (FCG) is constructed to proÔ¨Åle program
behavior. The FCG of a program is a directed graph, which
consists of a set of nodes representing functions and a set
of edges representing caller and callee relationships among
functions [37]. Then, basic block chains and normalized
instructions are extracted to demonstrate the semantics of the
function at the basic block level and the instruction level,
respectively. The similar parts between the birthmark of a
target program and that of a candidate program in the above
three levels can reconstruct a reuse scene to interpret and
justify detection results. Obviously, this kind of demonstration
can assist easy understanding and trust on a detection result,
unlike a simple value reuse indicator.
High accuracy. To achieve high accuracy of reuse detection,
we perform normalization at different levels of our birthmark
model. SpeciÔ¨Åcally, at the basic block level, we Ô¨Årst transform
each function into a set of Minimum Branch Paths (MBPs),
which are length variant partial execution paths starting from
an initial node or a branch node and ending at a terminal node
or an adjacent branch node. Then, to mitigate huge differences
in instructions caused by cross-compilation, we only consider
the key instructions to represent their core semantics. Fur-
thermore, we lift low-level assembly instructions up to high-
level operations and remove operands from them to address
syntax differences of instructions to complete the process of
instruction normalization.
High efÔ¨Åciency. To speed up the similarity calculation
among thousands of function pairs, we propose a process for
‚Äúintent search based on anchor recognition‚Äù to Ô¨Årst recognize
anchor functions (in short anchors) and then perform intent
search originated from the anchors to discover all potentially
matched function pairs. In this way, we signiÔ¨Åcantly reduce
the number of comparisons before similarity calculation and
meanwhile ensure comparison quality. Concretely, the process
leverages on strict instruction match and identical library call
invocation check to search for matched function pairs as
anchors by considering both developer-deÔ¨Åned functions and
library functions. Through intent search originated from the
anchors, it further explores neighbors of the anchors to Ô¨Ånd
new function pairs with high similarity scores.
Moreover, since there is currently no dataset that can be
directly used for partial reuse detection tests, we construct
a dataset that contains 24 real-world software projects and
manually label a total of 74 partial reuses. The dataset has
been published on website [38]. By evaluating ISRD based
on our constructed dataset and a widely used dataset, we
demonstrate that ISRD exhibits impressive software reuse
detection performance. In summary, the major contributions
of this paper include:
(i) We propose a novel Ô¨Åne-granular multi-level birthmark
model to uniquely represent program semantics and
enable interpretability of software reuse detection result.
(ii) We perform normalization at both the basic block level
and the instruction level to resist semantics-preservingobfuscation for accurate software reuse detection.
(iii) We design a process to recognize anchors and conduct
intent search originated from the anchors, which can
greatly reduce the number of comparisons, thus signiÔ¨Å-
cantly accelerate detection speed.
(iv) We implement ISRD and evaluate its performance with
extensive experiments. The results reveal that ISRD
is interpretable, can effectively and efÔ¨Åciently detect
partial reuse. It is also resilient to cross-compilation,
outperforming the state-of-the-art approaches.
II. R ELATED WORK
According to analysis techniques, existing binary code reuse
detection approaches can be divided into two main categories:
static analysis and dynamic analysis.
Static Analysis. Static analysis is applied on binaries without
running programs. Bindiff [34] was proposed to use the
structural similarity of CFG to compare binary codes. Luo et
al. [21] proposed CoP, a binary-oriented, obfuscation-resilient
method for code reuse detection, which combines rigorous
program semantics with the longest common subsequence
based fuzzy matching. David et al. [36] proposed a new
approach Eshof calculating binaries‚Äô similarity, which Ô¨Årstly
decomposes binary codes into small comparable fragments,
then deÔ¨Ånes semantic similarity between fragments, and fur-
ther uses statistical reasoning to lift fragment similarity into
the similarity between procedures. Chandramohan et al. [39]
proposed Bingo , which captures complete function semantics
by inlining the relevant library and developer-deÔ¨Åned functions
and models binary functions in a program structure agnostic
fashion by using length variant partial traces. Feng et al. [40]
proposed Genius to search vulnerabilities in massive IoT
ecosystems by converting Attributed Control Flow Graph
(ACFG) into high-level numeric feature vectors. Different
from Genius that embeds an ACFG by taking a codebook-
based approach, Xu et al. [41] proposed Gemini to take a
neural network-based approach to transform the ACFGs into
embeddings of binary functions for similarity detection. Liu et
al. [42] proposed a solution named Diff, which employs three
semantic features: intra-function feature, inter-function feature
and inter-module feature, to address cross-version binary code
similarity detection challenges.
Dynamic Analysis. A dynamic approach for binary code
reuse detection is performed during code execution by run-
ning programs. Tian et al. [43], [22] proposed DYKIS to
uniquely identify a program for detecting similar programs.
Tian et al. [44] presented a framework called Thread Oblivious
dynamic Birthmark (TOB) that revives existing techniques
to detect reuse of multi-thread programs. Ming et al. [45]
proposed a logic-based approach LoPD by leveraging dynamic
symbolic execution and theorem proving techniques to capture
dissimilarities between two programs in order to rule out
semantically different programs.
For better understanding the differences of the above ap-
proaches from ISRD , we compare them in Table I in terms of
874Fig. 1: ISRD Overview
TABLE I: Comparison with Existing Approaches
Approach Type1Granu.2Inter.3Effec.3EfÔ¨Åc.3
Bindiff [34] St B
Cop [21] St B
Esh[36] St I
Bingo [39] St B
Genius [40] St B
Gemini [41] St B
Diff [42] St N.A.
DYKIS [43] Dy -
TOB[44] Dy -
LoPD [45] Dy -
ISRD St I, B, F
1St:Static; Dy: Dynamic.
2Granu.: Granularity; I: Instruction Level; B: Basic Block Level;
F: Function Level.
3Inter.: Interpretability; Effec.: Effectiveness; EfÔ¨Åc.: EfÔ¨Åciency;
,and respecti vely represent satisfying the criteria, par-
tially satisfying the criteria, and not satisfying the criteria.
analysis type, granularity of applied birthmark, interpretabil-
ity, effectiveness for resisting obfuscation caused by cross-
compilation, and efÔ¨Åciency. From Table I, we observe that the
existing approaches cannot interpret detection results, although
they can resist obfuscation caused by cross-compilation to
some extent. Genius [40], Gemini [41] andDiff [42] use deep
learning [46] to detect reuse and achieve high efÔ¨Åciency, but
they cannot interpret detection results. None existing approach
can comprehensively overcome the aforementioned limitations
except for ISRD , which shows the novelty and advantages of
ISRD .
III. ISRD DESIGN
In this section, we introduce the technical details of ISRD ,
which contains two main stages as illustrated in Fig.1.
Birthmark Generation. This stage constructs the birthmarks
of the target program and the candidate program. The birth-
mark relates to three levels, i.e., function level, basic block
level, and instruction level. At the function level, an FCG
is constructed to depict the program semantics. At the basic
block level, the MBPs of a given function are extracted to
proÔ¨Åle its behaviors. At the instruction level, normalization is
performed to capture instruction core semantics.
Reuse Detection. Since the direct comparison of all function
pairs between two programs is a time-consuming job, a process
for ‚Äúintent search based on anchor recognition‚Äù is proposed to
recognize anchors and conduct intent search originated from
the anchors to signiÔ¨Åcantly accelerate function pair matching.
SpeciÔ¨Åcally, in Anchor Recognition , strict instruction match
and identical library call invocation check are used to Ô¨Ånd theanchors. Then, in Intent Search , we originate from the anchor
pairs to explore potentially matched function pairs based on
their function call relationships.
A. Birthmark Generation
A birthmark is a set of characteristics extracted from a
program that reÔ¨Çects its semantic behaviors, which can be used
to uniquely identify a program and is resilient to semantics-
preserving code transformations.
In the literature, there are many proposed birthmarks with
different granularities to represent a program. But in practice,
applying coarse granularity may restrict program similarity
catching in a precise way. For example, a program-level
birthmark is unable to detect partial reuse, since a candidate
program often reuses only a part of a target program. Mean-
while, the birthmark similarity at a Ô¨Åne granularity level cannot
be used to infer the similarity at a coarse granularity level.
For example, given the similarity at instructions, we cannot
conclude that the functions of two programs are similar.
To address this problem, we propose a multi-level birthmark
model to characterize a program by involving three-level gran-
ularities to form a hierarchical birthmark, from the function
level, to the basic block level, and Ô¨Ånally the instruction level.
On the top of the hierarchical birthmark, to depict the
program semantics from the point of a macroscopic view, we
Ô¨Årst construct the FCG of a program to describe its behavior.
Then, we turn our attention to the individual functions in
the program by distilling the function semantics with MBP
representation. Finally, to further capture the instruction se-
mantics, we perform normalization on the Ô¨Ånest-granularity
instructions. Consequently, a program can be identiÔ¨Åed by a
three-level birthmark that contains function birthmark, basic
block birthmark, and instruction birthmark. Next, We discuss
the details of birthmark at each level.
1) FCG Construction: To capture program semantics at the
function level, we construct FCG for both the target program
and the candidate program. The FCG captures the functionality
and objective of a program semantically from its structural
information to proÔ¨Åle program behaviors [47], [48], [49].
In order to construct FCG of a given program, we Ô¨Årst
identify the invocation statements (i.e., ‚Äúcall‚Äù) from its as-
sembly code to extract callers and callees. Then, the callers
and the callees are added into a graph as nodes. In addition,
if a function call relation exists between a caller and a callee,
an edge is inserted between them in the graph.
8752) MBP Extraction: To characterize function semantics,
Control Flow Graph (CFG) is applied, which contains detailed
information of the basic blocks in a function. In a CFG, each
node represents a basic block that is a straight-line piece of
code without any branch, and each edge represents the control
Ô¨Çow relationship among blocks. A CFG is deÔ¨Åned as follows.
DeÔ¨Ånition 1: Control Flow Graph (CFG) : A CFG is a
directed graph G= (V;E ).
V=fvij1ingdenotes the set of basic blocks of a
function, where vi2Vis theith block.
EVVdenotes the set of control Ô¨Çows, where
(vi;vj)2Eindicates that a control Ô¨Çow is from vito
vj. 
However, existing approaches [36], [35] that operated at the
boundaries of basic blocks are vulnerable to block splitting or
merging when different compilation processes are applied. Our
solution to this problem is inspired by TRACY [31], which
uses tracelets ‚Äì partial traces of an execution to compare
function similarity. Concretely, we propose MBPs that are
partial straight-line execution paths between branching nodes
in a CFG. A branching node is a node that has more than one
successor node.
To extract MBPs, we Ô¨Årstly pre-process the CFG by group-
ing basic blocks into a number of straight-line paths (i.e.,
replacing edges that connect two blocks with a single out-edge
and a single in-edge, respectively). This kind of grouping does
not affect the function semantics and is only for the purpose
of simplifying the generated MBPs, which is deÔ¨Åned as below.
DeÔ¨Ånition 2: Minimum Branch Path (MBP) : Let a path
extracted from a CFG be denoted as a node sequence p=
hvp1;:::;vpni. A pathpis a MBP if the following conditions
are satisÔ¨Åed:
vp1is an initial node, which has no predecessor or is a
branching node.
vpnis a terminal node, which has no successor or is a
branching node.
No other nodes in pare initial or terminal nodes. 
Unlike the Ô¨Åx-lengthed tracelet proposed in [31], MBP is
variable in length according to the structure of CFG. It has a
number of characteristics making it suitable for representing
function semantics:
Semantics Exhibition : The combination of basic blocks
and control Ô¨Çow in MBP can represent the execution of
a function and capture its semantics.
Effectiveness and EfÔ¨Åciency : Trying to gather and analyze
all paths in a CFG is clearly infeasible. MBP effectively
cuts down the size and the number of paths of CFG
by only considering sub-paths between branching nodes.
Thus, it can help in speeding up function semantics
matching.
Structural Variation Resilience : The absence of branches
in MBP implies that it would be less vulnerable than
CFG to structural changes caused by block splitting and
merging.Algorithm 1: MBP Extration from CFG
Input:G= (V;E )//Gis a CFG.
Output:P //Pis the set of all MBPs.
1P=;
2foreachvi2Vdo
3 ifIn(vi) = 0 orOut(vi)>1then
4 EXTRACT (vi)!P
5returnP
6Function EXTRACT(vi):
7Pi=;
8 foreach (vi;vj)2Edo
9vi;vj!p
10 while Out(vj) = 1 do
11 vk;(vj;vk)2E!p
12 vj=vk
13p!Pi
14 returnPi
Fig. 2: A sample CFG and its extracted MBPs
Resilience to Jump Instruction Variations : Jump instruc-
tions are sensitive to obfuscation. MBP is by nature free
from jump instructions due to branch omission.
Algorithm 1 shows the steps of extracting MBPs from a
given CFG. The output Pdenotes the set of extracted MBPs.
The functions InandOutreturn the in-degree and out-degree
of a given node. SpeciÔ¨Åcally, Pis initialized as an empty set.
Then, for every node viinV, ifvihas no direct predecessor
nodes or more than one direct successor node, the function
EXTRACT is invoked to extract MBPs from vi. Finally, the
extracted MBPs are added to P.
Fig. 2 depicts an example of CFG and its extracted MBPs.
We observe that the original basic blocks in a control-
Ô¨Çow are grouped as execution Ô¨Çows, which are already
determined. There are two basic blocks BB 1,BB 2that
have more than one direct successor basic blocks. There-
fore, the extracted MBPs from the CFG are: (BB 1;BB 2),
(BB 1;BB 3;BB 5);(BB 2;BB 4;BB 5):(BB 2;BB 3;BB 5).
3) Instruction Normalization: Syntax is the most direct
birthmark to represent instruction semantics. However, differ-
ent compilation processes may cause signiÔ¨Åcant differences
in the assemblies [31], [43]. To retain the core semantics
of instructions and be resilient to obfuscation introduced by
cross-compilation, normalization over instructions is applied.
Key Instruction Extraction. First, equally treating all kinds
of instructions may be defeated by compilation variations. That
is because some kinds of instructions are not closely related to
semantics and are easily changed across compilation. To solve
this problem, we only consider key instructions. Ideally, the
key instructions should constitute a small portion of a whole
876execution sequence and must be relatively unique. Through
observation, we Ô¨Ånd that there exist a large number of data-
transfer instructions, such as push andpop, especially mov, in
almost all MBPs. These instructions can be discarded because
they usually facilitate computations rather than belong to a
part of MBP logic. Furthermore, they are easily added and
deleted compared with other instructions.
Actually, deleting all data-transfer instructions is probably
the simplest approach to solve the problem caused by cross-
compilation, but it might lead to the loss of data-transfer se-
mantics. Thus, we only keep the Ô¨Årst data-transfer instruction
when multiple data-transfer instructions appear continuously.
Instruction Lifting. As we discussed earlier, the same op-
eration can be expressed in different instructions. To achieve
semantics equivalence on instructions, we lift the instructions
into high-level operations. For example, two instructions inc
andadd can be mapped to one addition operation.
Operand Removing. The operands in the instructions are
easily changed in the compilation. Even compiling the same
source code with the same compilation settings, the operands
can be different due to their differences in memory layout.
Therefore, we strip the operands from the instructions.
At this point, by using the proposed multi-level birthmark
model, we construct the three-level birthmarks for both target
and candidate programs, which give a detailed description
of the program semantics from coarse granularity to Ô¨Åne
granularity.
B. Reuse Detection
After Birthmark Generation , given the target program and
the candidate program, we can capture their similarity rela-
tionship based on their birthmarks for reuse detection.
To trade off between coarse granularity and Ô¨Åne granularity,
it is reasonable to take the function as a comparison unit.
In order to compare functions, we Ô¨Årst perform comparison
at the instruction level, then combine the comparison results
to compute the similarity at the basic block level, and then
the function similarity is determined. Finally, the comparison
results between functions are aggregated to capture the simi-
larity between the target program and the candidate program.
In addition, the matching relationship at the three levels is
presented to interpret the detection results.
However, matching target functions with a large number of
candidate functions remains a major bottleneck. The reason
is that the scale of function pair-wise comparison increases
exponentially with the number of functions.
To tackle this problem, an efÔ¨Åcient matching process that
signiÔ¨Åcantly accelerates the search for matched function pairs
between the target and the candidate programs is proposed.
The process contains two main steps, i.e., Anchor Recognition
andIntent Search , to predict which function pairs are likely
to match, thereby making the matching process much more
efÔ¨Åcient by avoiding unnecessary matching. The process Ô¨Årst
performs strict instruction match and identical library call
invocation check to identify matched anchor function pairs,
then it explores neighbors of the matched anchors to Ô¨Ånd newAlgorithm 2: Anchor Recognition
Input:
DT;LT //DT;LTdenotes the developer-deÔ¨Åned functions and
library functions in the target program.
DC;LC //DC;LCdenotes the developer-deÔ¨Åned functions and
library functions in the candidate program.
Output:
Anchor //Anchor denotes the set of matched anchor function
pairs
1Anchor =fg
2foreachdT2DTdo
3IdT=GETFUNCINS(dT)
4 foreachdC2DCdo
5IdC=GETFUNCINS(dC)
6simins=SIMINS(IdT;IdC)
7 ifsimins== 1 then
8 Anchor (dT;dC)
9foreachlT2LTdo
10 foreachlC2LCdo
11 iflC==lTthen
12 Anchor (lT;lC)
function pairs with a high similarity score under the guidance
of function level birthmark. By doing this, we can effectively
reduce the number of comparisons before program similarity
score calculation to make reuse detection execute swiftly.
1) Anchor Recognition: This step attempts to Ô¨Ånd matched
anchor function pairs, which can efÔ¨Åciently instruct later
reused function matching. SpeciÔ¨Åcally, we jointly use two
ways to recognize the anchors among a huge number of
functions in the candidate program.
Way 1 : Given a function in the target program, we search the
functions in the candidate program that meet strict instruction
matching. Here, the strict instruction matching indicates that
both the numbers of instructions and their sequences in two
functions are exactly the same.
Way 2 : Considering that library call invocations provide an
important partial semantics of a function [50], we also look
for identical library call invocations that appeared in both the
candidate program and the target program.
Note that Way 1 andWay 2 operate on the developer-deÔ¨Åned
functions and library functions, respectively.
Algorithm 2 shows the process of Anchor Recognition .
The inputsDTandLTdenote the developer-deÔ¨Åned functions
and library functions in the target program, respectively. DC
andLCdenote the developer-deÔ¨Åned functions and library
functions in the candidate program, respectively. The output
Anchor denotes a set of matched anchor function pairs. The
function GETFUNCINS takes a function as input and returns
its all instructions. At line 6, we use Jaccard distance to
measure the similarity between the function pairs in terms
ofWay 1 , i.e., their similarity in instructions. After that, we
obtain the identical library function invocations in both the
target program and the candidate program (lines 9-12).
2) Intent Search: In the intent search, we originate from
the matched anchors to discover new matched function pairs.
ISRD loops over each recognized anchor and explores its direct
877Algorithm 3: Intent Search
Input:
Anchor //Anchor denotes the matched anchor function pair set.
fTB//fTBdenotes the function which has the highest priority in
the target program.
FCG T;FCG C //FCG T;FCG Cdenote the function level
birthmark of the target program and the candidate program.
Output:
FF //FF denotes a set of potential matched function pair of
fTB.
1FF;Pre;Suc =fg
2foreach (fTA;fTB)(fTA;fCa)2Anchor2FCG Tdo
3Pre (fTB;fCb)(fCa;fCb)2FCG C
4foreach (fTB;fTD)(fTD;fCd)2Anchor2FCG Tdo
5Suc (fTB;fCb)(fCb;fCd)2FCG C
6iflen(Pre )>0andlen(Suc)>0then
7FF Pre\Suc
8else
9FF Pre[Suc
neighbors to Ô¨Ånd new matched function pairs that have a
high similarity score. The valid correspondences found in the
previous step are propagated to their neighbors. And the new
identiÔ¨Åed matched function pairs are added as new anchors.
Given a matched anchor function pair Aanda, the basic
idea of intent search is that the neighboring functions of A
that are connected to Awith an edge in the function level
birthmark usually correspond to those of a.
In order to search for new matched function pairs, we use
the function invocation relationship to guide our processing.
We consider the cues got from the current state of the matched
function pairs and the function call relationship in FCG.
Instead of exploring completely at random, we set a priority to
guide the search and improve its efÔ¨Åciency by increasing the
probability of Ô¨Ånding matched function pairs. We give a high
priority to the functions that have the most number of matched
neighbors. Subsequently, the process should Ô¨Årstly operate on
the high priority functions in the candidate program. With this
process, all matched function pairs between the target program
and the candidate program can be identiÔ¨Åed.
Algorithm 3 shows the process of Intent Search . The input
Anchor denotes the set of matched anchor function pairs;
fTBdenotes the function that has the highest priority in the
target program; FCGTandFCGCdenote the function level
birthmarks of the target program and the candidate program,
respectively. The output FF denotes a set of potentially
matched function pairs of fTB.
Firstly, for each precursor node fTAoffTBinFCGT, if
(fTA;fCa)is inAnchor ,(fTB;fCb)is added in Pre, where
fCbis the successor node of fCa(lines 2-3).
Then for each successor node fTDoffTBinFCGT, if
(fTD;fCd)is inAnchor ,(fTB;fCb)is added in Suc, where
fCbis the precursor node of fCd(lines 4-5).
Finally, ifPre andSuc are not empty, the intersection of
them is added into FF, otherwise their union is added into
FF (lines 6-9).3) Similarity Calculation: After identifying the potentially
matched function pairs, we are able to measure the similarities
of two functions by calculating the similarity scores based on
their basic block level birthmarks - MBP sets. To compute
a similarity score for each pair of MBP sets, we Ô¨Årst show
how to compute the similarity score for a pair of MBPs using
Equation (1).
sim(mbp 1; mbp 2) =2lcs(mbp 1; mbp 2)
jmbp 1j+jmbp 2j(1)
We compute the Longest Common Subsequence (LCS)
of two MBPs by utilizing the LCS dynamic programming
algorithm, denoted as lcs(mbp 1;mbp 2). Then, the similarity
score between two MBPs is calculated by taking the length of
LCS divided by the average length of two MBPs. By trying
each pair of MBPs, we use the collected individual similarity
scores to calculate the similarity of two MBP sets ( MBP 1,
MBP 2) according to the following Equation (2-3).
sim(MBP 1; MBP 2) =X
mpb 12MBP 1jmpb 1jMaxScoreP
mpb 12MBP 1jmpb 1j(2)
MaxScore =Max (sim(mbp 1; mbp 22MBP 2) (3)
For each MBP in MBP 1, the highest similarity score,
denoted as MaxScore , is Ô¨Årst obtained using Equation (3)
inMBP 2. Then, the similarity score of two MBP sets
sim(MBP 1;MBP 2)is the sum of the highest similarity score
of each MBP in MBP 1timed by the length of mbp 1and
divided by a base, which is the total length of all MBPs in
MBP 1. This allows the similarity score to vary between zero
and one, inclusively.
The similarities between functions are not sufÔ¨Åcient to
describe the similarity relationship between the target program
and the candidate program. We combine the matched function
pairs and the function innovation relationship into a graph
that is the similar part of the function level birthmarks, which
can reconstruct the similarity scene. Consequently, to prove
the similarity between the target program and the candidate
program, the similar parts between their three-level birthmarks
are distilled to serve as the interpretable detection results. The
similarity between the target program and candidate program
can be measured according to the following Equation (4)
sim(T; C ) =jFFj
jCj(4)
The similarity score of the target program and candidate
programsim(T;C )is calculated by using the number of
matched function pairs FF to divide a base, which is the
function number of candidate program. The score denotes the
percent of reused functions in the candidate program with
regard to the target program.
IV. E VALUATION
In this section, we Ô¨Årst introduce the setup of our experi-
ments. Then, we answer the following six research questions
to validate the performance of our approach.
878RQ1: Can ISRD effectively and efÔ¨Åciently detect partial
reuse?
RQ2: Are the detection results of ISRD interpretable?
RQ3: Is ISRD resilient to cross-compiler-version?
RQ4: Is ISRD resilient to cross-optimization-level ?
RQ5: Is ISRD resilient to cross-compiler-vendor?
RQ6: How good is the result of ISRD, compared to other
related works?
A. Study Setup
1) Evaluation Datasets: ISRD takes the binary code of
program pairs as input. To perform a thorough evaluation,
we needed ground-truth datasets of which the binary code
really share the same code. To this end, we used two datasets,
including a dataset that is constructed by ourselves ( Dataset-
I) and a widely used benchmark dataset Dataset- II that is
provided from Bingo [39] and diff [42].
To test whether ISRD can successfully detect partial reuses,
we collected real-world data from open source platforms
to construct Dataset- I. We Ô¨Årst downloaded 24 open-source
projects from open-source platforms (e.g., Github and Source-
Forge), which fall into different application domains. Then,
we selected and labelled a total of 74 real partial reuses as
ground truth by using both a manual method and an automatic
method. Finally, a dataset containing 24 programs with 74
partial reuses was constructed. We compiled these 24 programs
into binaries using gccwith default optimization (O2). The
static information of Dataset I is listed in Table III, where
the numbers in the third and the fourth columns are the
lines of program source code and the number of functions
in the corresponding compiled binaries, respectively. After
compiling, some programs would generate more than one
binary. Herein, we only present the information of the binaries
that are used in our evaluation. We have published Dataset I
at [38].
Dataset- II is a widely-used benchmark to evaluate cross-
compilation robustness. It was commonly used in the liter-
atures [39], [42], [51], [52]. Thus, it was adopted to com-
pare the performance of ISRD with existing approaches. The
binaries in Dataset- II were compiled from the experimental
object Coreutils [53], which are the basic Ô¨Åle, shell and text
manipulation utilities of the GNU operating system written in
C. There are 107 components in Coreutils and as a result, each
compilation produces 107 binaries. Following [39], [42], [35],
[36], we used three compilers in our experiment ( gcc v4.6 ,gcc
v4.8, and clang v3.0 ) and four optimization levels (O f0,1,2,
and3g), resulting in 12 different variants for each of the 107
binaries. Table III lists the information of Dataset- II, where
the numbers in the 4th-7th columns denote the maximum,
minimum, average, and total numbers of functions of the 107
binaries in Coreutils , respectively.
2) Evaluation Metrics: The metrics used to measure the
performance of ISRD are shown in TABLE IV. False Positive
Rate (FPR) stands for the ratio of non-reusable functions being
falsely detected as reusable functions. False Negative Rate
(FNR) quantiÔ¨Åes the ratio of the reusable functions that areTABLE II: Descriptions of Dataset I.
Program Version # LOC # Function
bzip2 [54]1.0.6 6019 84
1.0.8 6026 84
zstd [55]1.4.3 76465 848
1.4.5 78667 895
lzo [56]2.09 23736 206
2.10 24002 208
minizip [57] 2.8.7 28478 577
precomp [58] 0.4.7 96840 1739
TurboBench [59] - 509182 2486
lzbench [60] 1.8 207315 2664
brotli [61] 1.0.7 30072 233
libbsc [62] 3.1.0 9192 70
libdeÔ¨Çate [63] 1.6 79071 70
lzfse [64] 1.0 3382 35
lzlib [65] 1.11 4709 98
zlib [66] 1.2.11 25504 133
zlib-ng [67] - 14288 187
csc [68] - 6373 119
gipfeli [69] - 1112 84
blosc [70] 1.18.1 58867 742
liblzg [71] 1.0.10 1648 30
xz [72] 5.2.4 24175 401
Exserver [73] - 5625 133
cknit [74] - 6054 139
exjson [75] - 3384 83
libsndÔ¨Åle [76] 1.0.28 50764 44438
sndÔ¨Åle2k [77] - 59532 39299
TABLE III: Descriptions of Dataset II.
Compiler VersionOptimization
LevelMax Min Average Total
gccv4.6O0 379 17 128 13711
O1 284 14 106 11382
O2 275 14 110 11809
O3 258 14 107 11510
v4.8O0 380 18 129 13825
O1 266 15 104 11186
O2 277 15 112 12047
O3 253 15 106 11424
clang v3.0O0 484 17 168 17978
O1 486 17 169 18110
O2 278 13 116 12504
O3 267 13 115 12308
not detected as reusable functions. The values of precision ,
Recall andF-Measure are calculated as described in TABLE
IV.
3) Parameter Setting and Experimental Environment: Sim-
ilarity threshold plays an important role in ISRD . A function
pair is determined as matched if its similarity score is greater
than the similarity threshold. To determine a proper threshold,
we varied its values to test over both datasets. According to
our testing results, setting the similarity threshold as 0.5 made
ISRD achieve the best performance.
We implemented ISRD inpython 3.6 onUbuntu 18.04 . All
programs ran at DELL desktop P2417H with CPU i7-7700 &
3.60GHz and 16GB memory. In the experiments, ISRD utilized
angr [78] to disassemble binaries.
B. Answer to RQ 1: Effectiveness and EfÔ¨Åciency of ISRD
In this evaluation, we used Dataset I to test whether ISRD
can effectively and efÔ¨Åciently detect partial reuse. We ran ISRD
with Dataset I as input and compared its results with the
879TABLE IV: Evaluation Metrics.
Term Abbr DeÔ¨Ånition
True Positive TPthe number of reusable functions that are
correctly detected as reusable.
True Negative TNthe number of unreusable functions that are
correctly detected as unreusable.
False Negative FNthe number of reusable functions that are
incorrectly detected as unreusable.
False Positive FPthe number of unreusable functions that are
incorrectly detected as reusable.
False Positive Rate FPR FP= (FP +TN)
False Negative Rate FNR FN= (TP+FN)
Precision P TP= (TP+FP)
Recall R TP= (TP+FN)
F-measure F1 2PR= (P+R)
(a)CDF of Precision
 (b)CDF of Recall
Fig. 3: CDFs of ISRD Precision and Recall on Dataset I
ground truth. Fig. 3 and Fig. 4 report the performance of ISRD
in terms of effectiveness and efÔ¨Åciency to detect partial reuse.
Fig. 3 presents the Cumulative Distribution Function (CDF)
for the precision and recall of the evaluation results. Almost
all the precision values are higher than 82% and its average
value can reach 97:2%. Moreover, 15 binary pairs achieve
precision equal to 1, indicating that all reused functions can
be accurately detected as reusable. For the recall metric, its
average value reaches 94:8%, indicating that our approach can
effectively Ô¨Ånd reused function pairs.
Fig. 4 reports the CDF with regard to the ratio of the reduced
number of function pairs that were calculated by ISRD to the
original number of function pairs. We can observe that ISRD
effectively reduces the size of the function pairs by 97:9%on
average during reused function detection. SpeciÔ¨Åcally, when
the reused code is only a small fraction of the target program
and the candidate program, the reduced ratio is up to 99:9%.
For example, the reused code of bzip2 only account for
about 2% ofprecomp , 208824 functions pairs are needed
to be calculated if applying some existing approaches (i.e.,
BinDiff [34], TRACY [31]), whereas 128 function pairs are
calculated by ISRD . Thus, we can conclude that the number
of function pairs used in ISRD is much smaller than the total
number of all function pairs between the target program and
the candidate program. This huge reduction in reuse detection
makes ISRD practical for large real-world programs.
Answering RQ 1: ISRD effectively detect partial
reuse and its average precision achieves 97:2%.ISRD
can signiÔ¨Åcantly reduce the number of function pairs
required for reuse detection up to 97:9%on average.
Thus, it is efÔ¨Åcient to handle a large scale of programs.
Fig. 4:CDF for Reduced Ratio of Partial Reuse Detection on Dataset I
C. Answer to RQ 2: Interpr etability of ISRD
Toevaluate whether the detection results of ISRD are
interpretable, we leveraged tw o programs precomp [58] and
minizip [57] in Dataset I to perform a case study . The case
study illustrates the interpretability of ISRD by pro viding a
graphic demonstration of reuse. Herein, precomp is a com-
mand line precompressor and minizip is a zip manipulation
library in C. Note that both precomp andminizip reuse tw o
compression libraries lzma [79] and bzip2 [54].
Fig. 5 illustrates the detection res ults of ISRD . The FCGs
ofprecomp and minizip are presented on the left side of
the Ô¨Ågure, where the nodes in red and in blue represent the
functions in the library lzma andbzip2 , respecti vely. Running
ISRD onprecomp andminizip , we got program similarity as
17:9%, which implied that 17:9%functions of precomp have
been already used in minizip .
The detailed detection results are illustrated and interpreted
on the right side of the Ô¨Ågure. F or presentation purpose, only
thelzma is given. After identifying all matched function pairs
between precomp and minizip , the matched subgraph were
constructed by combining the matched function pairs with
their function call relationship in order to reconstruct the reuse
scene in the function level of the tw o programs. The matched
subgraph between the tw o programs is presented in Fig. 5 (1).
In the matched subgraph, the node pairs are the matched
function pairs between the two programs that have the same
function call relationship.
Furthermore, we singled out function lzma alone decoder
with its matched function, whose similarity score is 1.0, as an
example by including the matched part of this function at the
basic block level and the instructi on le vel.In the basic block
level, as showed in Fig. 5 (2), 4 matched MBP pairs were
recognized to demonstrate the similarity between the function
pair. The matched MBPs are displayed with the same colors.
Finally, the similarity relationship of the last matched MBP
pair is described in detail at the instruction level. 9 high-
level matched operation pairs explain the semantic equiv alence
at the Ô¨Ånest granularity , as displayed in Fig. 5 (3) with a
similarity score as 1.0.
Answering RQ 2: The case study shows that the
detection results of ISRD is interpretable by describing
the matched part between the target program and the
candidate program in detail at the function level, the
basic block level and the instruction level.
880Fig. 5: The Detection Results of minizip andprecomp
TABLE V: Detection Results on Resilience to Cross-Compiler-Version
gcc4.6-gcc 4.8 P R F 1 FPR FNR
O0-O0 1.000 0.996 0.998 0.000 0.004
O1-O1 0.997 0.990 0.994 0.000 0.010
O2-O2 0.911 0.997 0.952 0.003 0.003
O3-O3 0.932 0.987 0.958 0.001 0.013
Average 0.960 0.993 0.975 0.001 0.007
D. Answer to RQ 3: Resilience to Cross-Compiler-Version
We compiled Coreutils using gcc v4.6 and gcc v4.8 with
various optimization levels (O0 to O3). Such a setup led to 8
different versions for each binary in Coreutils . Subsequently,
we evaluated ISRD by comparing the binaries compiled using
different compiler versions with the same optimization levels.
Table V summarizes this experiment‚Äôs results, where each
row heading represents the optimization level used for com-
pilation, and the last row reports the average value of each
evaluation metric. For example, the second row represents the
detection results when the target programs and the candidate
programs were compiled using gcc v4.6 andgcc v4.8 with the
same optimization level, O0.
The results demonstrate that the average precision can
achieve 96:0%and the recall is 99:3%, indicating that ISRD
is resilient to the obfuscation caused by different compiler
versions. Moreover, for no code optimization (i.e., O0), the
precision is 100% while the FPR is 0%. That is, even
with different version compilers, the compilations without
code optimization levels lead to highly similar binary codes,
whereas compiling with high optimization levels yields more
differences between binaries.
Answering RQ 3: ISRD is resilient to cross-compiler-
version with 96:0% precision and 99:3% recall on
average.
E. Answer to RQ 4: Resilience to Cr oss-Optimization-Level
Wecompiled Coreutil for x86-32bit architecture using clang
v3.0 andgcc v4.8 with v arious optimization levels (O0 to O3).
With this setup, each binary inCoreutils had 8 variants. WeTABLE VI:Detection Results on Resilience to Cross-Optimization-Le vel
P R F 1 FPR FNR
gcc4.8O0-O1 0.977 0.753 0.847 0.000 0.247
O0-O2 0.859 0.764 0.806 0.003 0.236
O0-O3 0.863 0.624 0.720 0.001 0.376
O1-O2 0.873 0.982 0.924 0.004 0.018
O1-O3 0.913 0.923 0.916 0.001 0.077
O2-O3 0.980 0.973 0.976 0.000 0.027
Average 0.911 0.836 0.865 0.002 0.164
clang 3.0O0-O1 0.968 0.975 0.971 0.001 0.025
O0-O2 0.962 0.792 0.864 0.002 0.208
O0-O3 0.960 0.784 0.858 0.002 0.216
O1-O2 0.929 0.844 0.883 0.003 0.156
O1-O3 0.925 0.835 0.876 0.003 0.165
O2-O3 1.000 0.999 0.999 0.000 0.001
Average 0.957 0.871 0.909 0.002 0.129
compared the binaries compiled using the same compiler with
different optimization le vels.
Table VI summarizes the results, where each row heading
represents the optimization le velused to compile the detection
objects. F or example, the second ro w represents the detection
results of the tar get programs that were compiled by gcc v4.8
with O0 while the candidate programs were com piled with O1
using the same compiler .
We observe that ISRD performs much better re garding
precision in clang v3.0 than in gcc v4.8 . SpeciÔ¨Åcally , the
average precision is95:7%forclang v3.0 yet only 91:1%is
obtained for gcc v4.8 .
Another interesti ng observ ation is that we get similar pat-
terns for both compilers. Within one compiler type (e.g.,
gcc v4.8 .), the F-measure achie vedby matching between the
binaries that were all compiled with high code optimization
levels (i.e., O2 and O3) is always better than that obtained by
matching between the binaries where one is compiled with a
high code optimization le vel(i.e., O2 and O3) and the other
is compiled with no code optimization (i.e., O0). SpeciÔ¨Åcally,
the highest F-measure is achiev ed when the tar get program and
the candidate program were both compiled with high optimiza-
tion, O2 and O3, respectiv ely.Howe ver, F-measure drops to
72:0%if the target program and the candidate program were
respectiv ely compiled with no code optimization (i.e., O0)
881TABLE VII: Detection Results on Resilience to Cross-Compiler-Vendor
clang3.0-gcc4.8 P R F 1 FPR FNR
O0-O0 0.999 0.919 0.956 0.000 0.081
O1-O1 0.929 0.765 0.835 0.001 0.235
O2-O2 0.930 0.903 0.913 0.002 0.097
O3-O3 0.912 0.867 0.886 0.001 0.133
Average 0.942 0.864 0.898 0.001 0.136
and high code optimization level (i.e., O3). This suggests that
regardless of the compiler vendor, the binaries compiled with
high optimization levels are similar. The inÔ¨Çuence of whether
the optimization kicks into the binaries is very evident.
Answering RQ 4: ISRD is resilient to cross-
optimization-level to some extent. Evaluating the bi-
naries compiled by gcc v4.8 and clang v3.0 ,ISRD
achieves on average 91:1%precision and 95:7%pre-
cision, respectively.
F. Answer to RQ 5: Resilience to Cr oss-Compiler-V endor
Wecompiled Coreutil for x86-32bit architecture using clang
v3.0 and gcc v4.8 with v arious optimization levels (O0 to
O3). 8 different variants were generated for each binary in
Coreutils with this setup. Subsequently , we evaluated ISRD on
binaries compiled by dif ferent v endors‚Äô compilers with same
optimization le vels.
Welist the results in Table VII, where each ro w heading
represents the optimization level used to compile the compared
objects. Experimental results sho w that the a verage precision
reaches a high de gree, 94:2%with FPR as0:1%. From the
table, we Ô¨Ånd that the best results are obtained when the
candidate programs were compiled with no optimization le vel
as the target one. Besides, the precision hits the lowest point
of91:2%when the detection binaries were compiled with
optimization le velO3. Further , across compiler v endors, the
detection precision drops with the rise of the optimization
level, except when the detection programs were compiled with
optimization le velO1, where the detection programs compiled
with optimization level O2 yield better accuracy . .
Answering RQ 5: Experimental results demonstrate
the resilience of ISRD across compiler vendors. More-
over, it achieves on average 94:2%precision.
G.Answer to RQ 6: Comparison with Related W orks
In this experiment , we compared ISRD with three base-
line approaches, including, BinDif f [34], BinGo [39], and
Diff [42].
1) Bindif f [34] is a binary code similarity detection tool,
which matches a pair of binaries using a variant of graph-
isomorphism algorithm.
2) Bingo [39] is a scalable and rob ust binary search engine
that supports cross-compilation by applying a selectiv e
inlining technique to reco vercomplete function seman-
tics.TABLE VIII: Comparison with Three Baseline Approaches Indicated by
Recall
Bindif f BinGo diff ISRD
clang-O0 vs. gcc-O3 0.271 0.332 0.462 0.644
clang-O0 vs. clang-O3 0.351 0.372 0.492 0.784
clang-O2 vs. clang-O3 0.994 0.576 0.969 0.999
gcc-O0 vs. clang-O3 0.258 0.333 0.484 0.562
gcc-O0 vs. gcc-O3 0.255 0.302 0.441 0.624
gcc-O2 vs. gcc-O3 0.757 0.480 0.765 0.973
Average 0.481 0.399 0.602 0.764
3)diff[42] is a method to detect binary code similarity
with a neural netw ork solution to extract intra-function
semantic features from ra w bytes of binary functions.
Tomake a head-to-head comparison with these approaches,
we used the same experimental conÔ¨Ågurations and the same
metric as theirs. More speciÔ¨Åcally, we compiled Coreutils
using gcc v4.8 andclang v3.0 with v arious optimization levels
(from O0 to O3). Weevaluated six experimental settings. The
recall v alues of reuse detection are reported in Table VIII,
where each rowheading represents the optimization level used
to compile the tar get programs and the candidate programs.
Through comparison on recall, we can see that ISRD out-
performs the three baseline approaches by 27:0%on average,
especially outperforms BinGo by 36:5%on average. Wenote
that the average recall ofISRD is76:4%, which is lower than
the upper experiment results. This is because the obfuscations
of both cross-compiler-v endor and cross-optimization-lev el
were in volved, maki ng the detection much harder than the
situation where only one type of obfuscation occurs. Moreov er,
the w orst result was obtained by each approach when the
target programs were compiled by gcc v4.8 with no code
optimization and the candidate programs were compiled by
gcc v4.8 with the highest optimization level O3. On the other
hand, the best results of all approaches were achiev ed when
the tar get programs and the candidate programs were compiled
by the same compiler with the high optimization level, O2 and
O3, respecti vely.
Answering RQ 6: Compared with the baseline ap-
proaches, ISRD achieves better performance regarding
a widely used benchmark dataset.
V. LIMITATIONSOFISRD
A. Impacts Caused by Internal Reasons
Function Inlining .Function inlining is a major internal
limitation to ISRD . In ISRD , the function semantics inside
a program is distilled independently. Tobe speci Ô¨Åc, a callee
function‚Äôs semantics is not inte grated into a caller function‚Äôs
semantics. This leads to a partial semantics problem, because
the strate gy of inlining is selectiv ely applied according to a
conÔ¨Ågured optimization level during compilation. Inlining is
utilized in compilers to optimize the binaries for achie ving
maximum speed or minimum size [80]. Other approaches
(e.g., the selectiv e inlining strategy of Bingo [39]) that inline
relev ant libraries and de veloper -deÔ¨Åned function semantics can
be incorporated into ISRD to address the problem.
882Library Functions. InISRD , two ways are leveraged to
recognize the anchors. The second way is based on check-
ing identical library call invocations. However, this way is
limited for two reasons: (1) the library functions are OS
dependent; (2) it fails to recognize the library calls that have
different names yet with similar functionality (e.g., memcpy
andmemmove ) [39]. To address the above problems, inspired
by CLCDSA [81], the similarity of cross-os library calls can
be learned with the help of the documentation and Mikolov‚Äôs
Word2Vec [82] model.
B. Impacts Related to Datasets
Due to the difÔ¨Åculty of collecting partial reuse samples
with accurate labels, only 24 programs were selected to
construct Dataset I and 74 real partial reuses were manually
labeled. In future work, we plan to collect additional real-
world partial reuse samples and further evaluate and optimize
the performance of ISRD .
VI. C ONCLUSION
In this paper, we proposed ISRD , an interpretation-enabled
software reuse detection approach based on a multi-level
birthmark model. We used the multi-level birthmark model to
distill the program semantics from coarse granularity to Ô¨Åne
granularity. Through normalization, the function semantics
and the core semantics of instructions can be effectively
represented. In reuse detection, intent search originated from
recognized anchors was employed to speed up function pair
matching. Extensive experiments reveal that ISRD is effective
and efÔ¨Åcient in detecting partial reuse with interpretation.
It also outperforms state-of-the-art approaches in terms of
resilience to cross-compilation.
ACKNOWLEDGMENT
This work was supported by National Key R&D Program of
China (2018YFB1004500), National Natural Science Founda-
tion of China (61632015, 61772408, U1766215, 61721002,
61532015, 61833015, 61902306, 62072351), China Post-
doctoral Science Foundation (2019TQ0251, 2020M673439),
Youth Talent Support Plan of Xi‚Äôan Association for Science
and Technology (095920201303), Ministry of Education In-
novation Research Team (IRT 17R86), and Project of China
Knowledge Centre for Engineering Science and Technology,
as well as Academy of Finland (Grants 308087 and 335262).
REFERENCES
[1] A. Hemel, K. T. Kalleberg, R. Vermaas, and E. Dolstra, ‚ÄúFinding
software license violations through binary code clone detection,‚Äù pp.
63‚Äì72, 2011.
[2] R. Duan, A. Bijlani, M. Xu, T. Kim, and W. Lee, ‚ÄúIdentifying open-
source license violation and 1-day security risk at large scale,‚Äù pp. 2169‚Äì
2185, 2017.
[3] ‚ÄúCisco settles fsf gpl lawsuit.‚Äù [Online]. Available:
http://arstechnica.com/information-technology/2009/05/ cisco-settles-
fsf-gpl-lawsuit-appoints-compliance-ofÔ¨Åcer
[4] ‚ÄúVmware sued for failure to comply with linux license.‚Äù [Online].
Available: http://www.zdnet.com/article
[5] Z. Li, D. Zou, S. Xu, H. Jin, H. Qi, and J. Hu, ‚ÄúVulpecker: an automated
vulnerability detection system based on code similarity analysis,‚Äù pp.
201‚Äì213, 2016.[6] T. Kamiya, ‚ÄúAgec: An execution-semantic clone detection tool,‚Äù in
2013 21st International Conference on Program Comprehension (ICPC) .
IEEE, 2013, pp. 227‚Äì229.
[7] F.-H. Su, J. Bell, K. Harvey, S. Sethumadhavan, G. Kaiser, and T. Jebara,
‚ÄúCode relatives: detecting similarly behaving software,‚Äù in Proceedings
of the 2016 24th acm sigsoft international symposium on foundations of
software engineering , 2016, pp. 702‚Äì714.
[8] S. Ducasse, M. Rieger, and S. Demeyer, ‚ÄúA language independent
approach for detecting duplicated code,‚Äù pp. 109‚Äì118, 1999.
[9] B. S. Baker, ‚ÄúOn Ô¨Ånding duplication and near-duplication in large
software systems,‚Äù pp. 86‚Äì95, 1995.
[10] R. Brixtel, M. Fontaine, B. Lesner, C. Bazin, and R. Robbes, ‚ÄúLanguage-
independent clone detection applied to plagiarism detection,‚Äù pp. 77‚Äì86,
2010.
[11] G. Cosma and M. Joy, ‚ÄúAn approach to source-code plagiarism detection
and investigation using latent semantic analysis,‚Äù IEEE Transactions on
Computers , vol. 61, no. 3, pp. 379‚Äì394, 2012.
[12] M. J. Wise, ‚ÄúYap3: improved detection of similarities in computer
program and other texts,‚Äù vol. 28, no. 1, pp. 130‚Äì134, 1996.
[13] G. Whale, ‚ÄúIdentiÔ¨Åcation of program similarity in large populations,‚Äù
The Computer Journal , vol. 33, no. 2, pp. 140‚Äì146, 1990.
[14] L. Zhang, D. Liu, Y . Li, and M. Zhong, ‚ÄúAst-based plagiarism detection
method,‚Äù Computer Engineering and Design , pp. 611‚Äì618, 2012.
[15] H. Kikuchi, T. Goto, M. Wakatsuki, and T. Nishino, ‚ÄúA source code
plagiarism detecting method using alignment with abstract syntax tree
elements,‚Äù pp. 1‚Äì6, 2014.
[16] L. Jiang, G. Misherghi, Z. Su, and S. Glondu, ‚ÄúDeckard: Scalable and
accurate tree-based detection of code clones,‚Äù pp. 96‚Äì105, 2007.
[17] R. Koschke, R. Falke, and P. Frenzel, ‚ÄúClone detection using abstract
syntax sufÔ¨Åx trees,‚Äù pp. 253‚Äì262, 2006.
[18] J. Krinke, ‚ÄúIdentifying similar code with program dependence graphs,‚Äù
pp. 301‚Äì309, 2001.
[19] R. Komondoor and S. Horwitz, ‚ÄúUsing slicing to identify duplication in
source code,‚Äù pp. 40‚Äì56, 2001.
[20] M. Gabel, L. Jiang, and Z. Su, ‚ÄúScalable detection of semantic clones,‚Äù
pp. 321‚Äì330, 2008.
[21] L. Luo, J. Ming, D. Wu, P. Liu, and S. Zhu, ‚ÄúSemantics-based
obfuscation-resilient binary code similarity comparison with applica-
tions to software plagiarism detection,‚Äù in Proceedings of the 22nd
ACM SIGSOFT International Symposium on Foundations of Software
Engineering . ACM, 2014, pp. 389‚Äì400.
[22] Z. Tian, Q. Zheng, T. Liu, and M. Fan, ‚ÄúDkisb: Dynamic key instruction
sequence birthmark for software plagiarism detection,‚Äù in 2013 IEEE
10th International Conference on High Performance Computing and
Communications & 2013 IEEE International Conference on Embedded
and Ubiquitous Computing . IEEE, 2013, pp. 619‚Äì627.
[23] X. Wang, Y .-C. Jhi, S. Zhu, and P. Liu, ‚ÄúDetecting software theft
via system call based birthmarks,‚Äù in 2009 Annual Computer Security
Applications Conference . IEEE, 2009, pp. 149‚Äì158.
[24] C. Kruegel, E. Kirda, D. Mutz, W. Robertson, and G. Vigna, ‚ÄúPolymor-
phic worm detection using structural information of executables,‚Äù pp.
207‚Äì226, 2005.
[25] D. Bruschi, L. Martignoni, and M. Monga, ‚ÄúDetecting self-mutating
malware using control-Ô¨Çow graph matching,‚Äù vol. 4064, pp. 129‚Äì143,
2006.
[26] J. Ming, D. Xu, and D. Wu, ‚ÄúMemoized semantics-based binary difÔ¨Ång
with application to malware lineage inference,‚Äù pp. 416‚Äì430, 2015.
[27] D. Gao, M. K. Reiter, and D. Song, ‚ÄúBinhunt: Automatically Ô¨Ånding
semantic differences in binary programs,‚Äù pp. 238‚Äì255, 2008.
[28] Y . Hu, Y . Zhang, J. Li, and D. Gu, ‚ÄúCross-architecture binary semantics
understanding via similar code comparison,‚Äù vol. 1, pp. 57‚Äì67, 2016.
[29] Z. Xu, B. Chen, M. Chandramohan, Y . Liu, and F. Song, ‚ÄúSpain: security
patch analysis for binaries towards understanding the pain and pills,‚Äù pp.
462‚Äì472, 2017.
[30] H. Tamada, M. Nakamura, A. Monden, and K.-i. Matsumoto, ‚ÄúDesign
and evaluation of birthmarks for detecting theft of java programs.‚Äù in
IASTED Conf. on Software Engineering , 2004, pp. 569‚Äì574.
[31] Y . David and E. Yahav, ‚ÄúTracelet-based code search in executables,‚Äù in
Proceedings of the 35th ACM SIGPLAN Conference on Programming
Language Design and Implementation , ser. PLDI ‚Äô14. New
York, NY , USA: ACM, 2014, pp. 349‚Äì360. [Online]. Available:
http://doi.acm.org/10.1145/2594291.2594343
883[32] H.-i. Lim, H. Park, S. Choi, and T. Han, ‚ÄúA method for detecting the
theft of java programs through analysis of the control Ô¨Çow information,‚Äù
Information and Software Technology , vol. 51, no. 9, pp. 1338‚Äì1350,
2009.
[33] H. Lim, H. Park, S. Choi, and T. Han, ‚ÄúA static java birthmark based
on control Ô¨Çow edges,‚Äù vol. 1, pp. 413‚Äì420, 2009.
[34] ‚ÄúBindiff,‚Äù https://www.zynamics.com/bindiff.html, 2019.
[35] Y . David, N. Partush, and E. Yahav, ‚ÄúSimilarity of binaries through
re-optimization,‚Äù in Proceedings of the 38th ACM SIGPLAN Conference
on Programming Language Design and Implementation , ser. PLDI
2017. New York, NY , USA: ACM, 2017, pp. 79‚Äì94. [Online].
Available: http://doi.acm.org/10.1145/3062341.3062387
[36] ‚Äî‚Äî, ‚ÄúStatistical similarity of binaries,‚Äù in Proceedings of the
37th ACM SIGPLAN Conference on Programming Language
Design and Implementation , ser. PLDI ‚Äô16. New York,
NY , USA: ACM, 2016, pp. 266‚Äì280. [Online]. Available:
http://doi.acm.org/10.1145/2908080.2908126
[37] S. Shang, N. Zheng, J. Xu, M. Xu, and H. Zhang, ‚ÄúDetecting malware
variants via function-call graph similarity,‚Äù in 2010 5th International
Conference on Malicious and Unwanted Software . IEEE, 2010, pp.
113‚Äì120.
[38] ‚ÄúDataset.‚Äù [Online]. Available: https://github.com/ISRD2020/ISRD
[39] M. Chandramohan, Y . Xue, Z. Xu, Y . Liu, C. Y . Cho, and H. B. K. Tan,
‚ÄúBingo: Cross-architecture cross-os binary search,‚Äù in Proceedings of
the 2016 24th ACM SIGSOFT International Symposium on Foundations
of Software Engineering . ACM, 2016, pp. 678‚Äì689.
[40] Q. Feng, R. Zhou, C. Xu, Y . Cheng, B. Testa, and H. Yin, ‚ÄúScalable
graph-based bug search for Ô¨Årmware images,‚Äù in Proceedings of the 2016
ACM SIGSAC Conference on Computer and Communications Security .
ACM, 2016, pp. 480‚Äì491.
[41] X. Xu, C. Liu, Q. Feng, H. Yin, L. Song, and D. Song, ‚ÄúNeural network-
based graph embedding for cross-platform binary code similarity detec-
tion,‚Äù in Proceedings of the 2017 ACM SIGSAC Conference on Computer
and Communications Security . ACM, 2017, pp. 363‚Äì376.
[42] B. Liu, W. Huo, C. Zhang, W. Li, F. Li, A. Piao, and W. Zou, ‚Äú diff:
cross-version binary code similarity detection with dnn,‚Äù in Proceedings
of the 33rd ACM/IEEE International Conference on Automated Software
Engineering . ACM, 2018, pp. 667‚Äì678.
[43] Z. Tian, Q. Zheng, T. Liu, M. Fan, E. Zhuang, and Z. Yang, ‚ÄúSoftware
plagiarism detection with birthmarks based on dynamic key instruction
sequences,‚Äù IEEE Transactions on Software Engineering , vol. 41, no. 12,
pp. 1217‚Äì1235, 2015.
[44] Z. Tian, T. Liu, Q. Zheng, E. Zhuang, M. Fan, and Z. Yang, ‚ÄúReviving
sequential program birthmarking for multithreaded software plagiarism
detection,‚Äù IEEE Transactions on Software Engineering , vol. 44, no. 5,
pp. 491‚Äì511, 2017.
[45] J. Ming, F. Zhang, D. Wu, P. Liu, and S. Zhu, ‚ÄúDeviation-based
obfuscation-resilient program equivalence checking with application
to software plagiarism detection,‚Äù IEEE Transactions on Reliability ,
vol. 65, no. 4, pp. 1‚Äì18, 2016.
[46] Y . Lecun, Y . Bengio, and G. E. Hinton, ‚ÄúDeep learning,‚Äù Nature , vol.
521, no. 7553, pp. 436‚Äì444, 2015.
[47] M. Fan, X. Luo, J. Liu, M. Wang, C. Nong, Q. Zheng, and T. Liu, ‚ÄúGraph
embedding based familial analysis of android malware using unsuper-
vised learning,‚Äù in 2019 IEEE/ACM 41st International Conference on
Software Engineering (ICSE) . IEEE, 2019, pp. 771‚Äì782.
[48] M. Fan, J. Liu, X. Luo, K. Chen, Z. Tian, Q. Zheng, and T. Liu, ‚ÄúAndroid
malware familial classiÔ¨Åcation and representative sample selection via
frequent subgraph analysis,‚Äù IEEE Transactions on Information Foren-
sics and Security , vol. 13, no. 8, pp. 1890‚Äì1905, 2018.
[49] M. Fan, J. Liu, W. Wang, H. Li, Z. Tian, and T. Liu, ‚ÄúDapasa: Detecting
android piggybacked apps through sensitive subgraph analysis,‚Äù IEEE
Transactions on Information Forensics and Security , vol. 12, no. 8, pp.
1772‚Äì1785, 2017.
[50] J. Qiu, X. Su, and P. Ma, ‚ÄúUsing reduced execution Ô¨Çow graph
to identify library functions in binary code,‚Äù IEEE Transactions on
Software Engineering , vol. 42, no. 2, pp. 1‚Äì1, 2016.
[51] M. Egele, M. Woo, P. Chapman, and D. Brumley, ‚ÄúBlanket execution:
Dynamic similarity testing for program binaries and components,‚Äù in
23rdfUSENIXgSecurity Symposium ( fUSENIXgSecurity 14) , 2014,
pp. 303‚Äì317.
[52] S. Wang and D. Wu, ‚ÄúIn-memory fuzzing for binary code similarity anal-
ysis,‚Äù in Proceedings of the 32nd IEEE/ACM International Conference
on Automated Software Engineering . IEEE Press, 2017, pp. 319‚Äì330.[53] ‚ÄúCoreutils.‚Äù [Online]. Available: https://www.gnu.org/software/coreutils/
[54] ‚Äúbzip2.‚Äù [Online]. Available: http://www.bzip.org/
[55] ‚Äúzstd.‚Äù [Online]. Available: https://github.com/facebook/zstd
[56] ‚Äúlzo.‚Äù [Online]. Available: http://www.oberhumer.com/opensource/lzo
[57] ‚Äúminizip.‚Äù [Online]. Available: https://github.com/nmoinvaz/minizip
[58] ‚Äúprecomp.‚Äù [Online]. Available: https://github.com/schnaader/precomp-
cpp
[59] ‚ÄúTurbobench.‚Äù [Online]. Available:
https://github.com/powturbo/TurboBench
[60] ‚ÄúLzbench.‚Äù [Online]. Available: https://github.com/inikep/lzbench
[61] ‚Äúbrotli.‚Äù [Online]. Available: https://github.com/google/brotli
[62] ‚Äúbrotli.‚Äù [Online]. Available: https://github.com/IlyaGrebnov/libbsc
[63] ‚ÄúlibdeÔ¨Çate.‚Äù [Online]. Available: https://github.com/ebiggers/libdeÔ¨Çate
[64] ‚Äúlzfse.‚Äù [Online]. Available: https://github.com/lzfse/lzfse
[65] ‚Äúlzlib.‚Äù [Online]. Available: http://www.nongnu.org/lzip/lzlib.html
[66] ‚Äúzlib.‚Äù [Online]. Available: https://zlib.net/
[67] ‚Äúzlib-ng.‚Äù [Online]. Available: https://github.com/zlib-ng/zlib-ng
[68] ‚ÄúCsc.‚Äù [Online]. Available: https://github.com/fusiyuan2010/CSC
[69] ‚Äúgipfeli.‚Äù [Online]. Available: https://github.com/google/gipfeli
[70] ‚Äúblosc.‚Äù [Online]. Available: https://github.com/Blosc/c-blosc
[71] ‚Äúliblzg.‚Äù [Online]. Available: https://liblzg.bitsnbites.eu/
[72] ‚Äúxz.‚Äù [Online]. Available: https://tukaani.org/xz/
[73] ‚ÄúExserver.‚Äù [Online]. Available: https://github.com/liqiongfan/Exserver
[74] ‚Äúcknit.‚Äù [Online]. Available: https://gitee.com/josinli/cknit
[75] ‚Äúexjson.‚Äù [Online]. Available: https://github.com/guedes/exjson
[76] ‚ÄúlibsndÔ¨Åle.‚Äù [Online]. Available: https://github.com/erikd/libsndÔ¨Åle
[77] ‚ÄúsndÔ¨Åle2k.‚Äù [Online]. Available: https://github.com/evpobr/sndÔ¨Åle2k
[78] ‚Äúangr.‚Äù [Online]. Available: https://github.com/angr/angr
[79] ‚Äúlzma.‚Äù [Online]. Available: https://tukaani.org/xz/
[80] P. P. Chang, S. Mahlke, W. Y . Chen, and W. W. Hwu, ‚ÄúProÔ¨Åle-guided
automatic inline expansion for c programs,‚Äù Software - Practice and
Experience , vol. 22, no. 5, pp. 349‚Äì369, 1992.
[81] K. W. NaÔ¨Å, T. S. Kar, B. Roy, C. K. Roy, and K. A. Schneider, ‚ÄúClcdsa:
Cross language code clone detection using syntactical features and api
documentation,‚Äù pp. 1026‚Äì1037, 2019.
[82] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean,
‚ÄúDistributed representations of words and phrases and their composi-
tionality,‚Äù pp. 3111‚Äì3119, 2013.
884