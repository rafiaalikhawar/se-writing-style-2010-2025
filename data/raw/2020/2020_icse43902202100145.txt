PyART: Python API Recommendation in Real-Time
Xincheng He, Lei Xuz, Xiangyu Zhangy, Rui Hao, Yang Fengand Baowen Xu
State Key Laboratory for Novel Software Technology, Nanjing University, China
yPurdue University, USA
xinchenghe2016@gmail.com, xlei@nju.edu.cn, xyzhang@cs.purdue.edu,
rui.hao.gm@gmail.com, fengyang@nju.edu.cn, bwxu@nju.edu.cn
Abstract ‚ÄîAPI recommendation in real-time is challenging for
dynamic languages like Python. Many existing API recommenda-
tion techniques are highly effective, but they mainly support static
languages. A few Python IDEs provide API recommendation
functionalities based on type inference and training on a large
corpus of Python libraries and third-party libraries. As such,
they may fail to recommend or make poor recommendations
when type information is missing or target APIs are project-
speciÔ¨Åc. In this paper, we propose a novel approach, PyART,
to recommending APIs for Python programs in real-time. It
features a light-weight analysis to derive so-called optimistic
data-Ô¨Çow, which is neither sound nor complete, but simulates
the local data-Ô¨Çow information humans can derive. It extracts
three kinds of features: data-Ô¨Çow, token similarity, and token
co-occurrence, in the context of the program point where a
recommendation is solicited. A predictive model is trained on
these features using the Random Forest algorithm. Evaluation
on 8 popular Python projects demonstrates that PyART can
provide effective API recommendations. When historic commits
can be leveraged, which is the target scenario of a state-of-the-
art tool ARIREC, our average top-1 accuracy is over 50% and
average top-10 accuracy over 70%, outperforming APIREC and
Intellicode (i.e., the recommendation component in Visual Studio)
by 28.48%-39.05% for top-1 accuracy and 24.41%-30.49% for
top-10 accuracy. In other applications such as when historic
comments are not available and cross-project recommendation,
PyART also shows better overall performance. The time to make
a recommendation is less than a second on average, satisfying
the real-time requirement.
Index Terms‚ÄîAPI recommendation, context analysis, data Ô¨Çow
analysis, real-time recommendation, Python
I. I NTRODUCTION
APIs are widely used in modern software development to
simplify the process of software implementation and main-
tenance. Recently, many approaches [1]‚Äì[14] have been pro-
posed to provide intelligent API recommendation. However,
most existing API recommendation approaches are mainly for
statically typed languages, such as Java. Few can provide
effective and efÔ¨Åcient API recommendations for dynamic
languages, such as Python and JavaScript, due to the dif-
Ô¨Åculties in handling their dynamic features. Python is one
of the most popular programming languages1. Many popular
Machine Learning and Deep Learning programming platforms
such as TensorÔ¨Çow and PyTorch support applications written
in Python. As such, an effective API recommendation solution
for Python is of importance.
zCorresponding author
1https://octoverse.github.com/However, it is challenging to achieve the goal. Python
applications are dynamically typed. The type of a variable
is not explicitly declared and hardly known until runtime.
Traditional type inference techniques may not be effective for
Python because the type of a variable at a given program point
may change along different paths and/or with different inputs
as Python allows changing types, attributes, and methods of
objects in an arbitrary fashion. The lack of type information
greatly degrades the accuracy of traditional static analysis on
Python and increases the uncertainty of API recommendation,
which heavily relies on these analyses. For example, in order
to handle path sensitivity, traditional static analysis typically
merges results along different paths, even if many of them
are bogus. As such, a variable may have a long list of types
and thus the IDE (Integrated Development Environment) has
to provide an over-sized list of recommendations to cover all
these possible types.
Besides type inference, many traditional static analyses,
such as data-Ô¨Çow analysis and alias analysis, have difÔ¨Åculty
handling Python too. Many existing API recommending ap-
proaches are built on these analyses and hence do not support
Python. For example, data-Ô¨Çow features are widely used in
existing API recommendation approaches [11], [15], [16].
However, it‚Äôs challenging to extract accurate data-Ô¨Çow for
Python programs. Existing Python data-Ô¨Çow analyses tools
produce substantial false dependencies [15], [17]‚Äì[20]. Hence,
as we show in Section IV, they lead to poor recommendation
accuracy.
Furthermore, providing real-time API recommendation
poses additional challenges. Recommendations are solicited
during development, where the syntax and semantics of the
current context of a recommendation point (i.e., an API
invocation point where the developer expects the IDE to
Ô¨Åll in) are incomplete. Hence it is challenging to perform
sophisticated static analysis. Developers often expect the IDE
to make instant recommendations, which preclude any heavy-
weight online analysis.
A few Python IDEs provide API recommendation function-
alities. For example, Pycharm relies on python-skeletons2and
typeshed3to make API recommendations. Visual Studio In-
telliCode4leverages Machine Learning to learn programming
2https://github.com/JetBrains/python-skeletons
3https://github.com/python/typeshed
4https://visualstudio.microsoft.com/zh-hans/services/intellicode
16342021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)
1558-1225/21/$31.00 ¬©2021 IEEE
DOI 10.1109/ICSE43902.2021.00145
patterns from a huge repository of Python projects. As we will
show in Section II, they still have various drawbacks, caused
by the aforementioned challenges. For example, IntelliCode
focuses on learning APIs of standard libraries and popular
third-party libraries, it can hardly handle APIs deÔ¨Åned within
the same project.
A state-of-the-art API recommendation research prototype
for Java is APIREC [9]. Given an invocation for which the
developer wants API recommendation, APIREC Ô¨Årst extracts
a bag of Ô¨Åne-grained atomic code changes and a set of
code tokens that precede the current editing location. Then
it computes the likelihood score for each candidate API by
looking up the co-occurrence frequency of code changes and
tokens in a large corpus. It heavily relies on Ô¨Åne-grained
code changes that happen on Abstract Syntax Tree (AST)
nodes and hence the accuracy of recommendation results is
heavily dependent on the accuracy of AST differencing tools
and the quality of code change histories. In this paper, we
ported APIREC to Python and use it as a baseline. Our results
show that it is not as effective as on Java due to the inherent
challenges of analyzing Python programs.
In this paper, we propose a new real-time API recom-
mendation approach for Python called PyART (Py thon A PI
Recommendation in Real-T ime). Compared to existing solu-
tions, PyART can recommend both library APIs and APIs
deÔ¨Åned within the same project; it does not rely on any
third party tools; it is lightweight and provides recommen-
dations without noticeable delay; and it delivers recommenda-
tions with good accuracy. The key to the success of many
existing API recommendation projects lies in the use of
high quality data-Ô¨Çow information [11], [15], [16]. They
largely utilize data-Ô¨Çow analyses in mature compilers/analysis-
infrastructures, which tend to be conservative as they were
designed to ensure safety in code transformation. Such con-
servativeness is substantially aggravated by the uncertainty
in dynamic languages. We observe that the conservativeness
is not necessary in our context because the essence of API
recommendation is to precisely model the joint-distribution
of APIs and their surrounding syntactic entities and semantic
properties. The semantic properties may not need to be as
accurate and complete as in the traditional application sce-
narios (e.g., code transformation and bug Ô¨Ånding), as long as
the approximate ones and the APIs have regularity in their
joint-distribution. As such, we develop a technique to extract
so-called optimistic data-Ô¨Çow from the context preceding a
recommendation point. This data-Ô¨Çow is derived in a way
similar to how humans reason about data-Ô¨Çow: heavily relying
on local variables, function ids, syntactic structures, and
ignoring global effects such as those by aliasing. SpeciÔ¨Åcally,
our technique Ô¨Årst collects a comprehensive list of candidate
APIs, without relying on type inference tools like IntelliCode
does. It then extracts and encodes three kinds of features in
the context of the recommendation point: optimistic data-Ô¨Çow ,
token similarity along data-Ô¨Çow that measures if the data-
Ô¨Çow paths reaching the recommendation point involve some
token similar to a candidate API, and token co-occurrence thatmodels the joint-distribution of a candidate API with a token
in its neighborhood. During training, these features are used to
construct a predictive model based on Random Forest . During
deployment, these features are provided to the trained model
to generate a ranked list of recommendations.
Our main contributions are summarized as follows:
We propose to derive optimistic data-Ô¨Çow that is neither
sound nor complete, but sufÔ¨Åcient for API recommenda-
tion and cost-effective to collect.
We propose to use three kinds of features: data-Ô¨Çow, to-
ken similarity and token co-occurrence. We also develop
a method to encode them to feature vectors.
We develop a prototype PyART based on the proposed
idea, and evaluate it on 8 real-world projects. The evalua-
tion results demonstrate that PyART can provide effective
API recommendations. When historic commits can be
leveraged, which is the target scenario of a state-of-the-
art tool ARIREC, our average top-1 accuracy is over 50%
and average top-10 accuracy over 70%, outperforming
APIREC and Intellicode by 28.48%-39.05% for top-1
accuracy and 24.41%-30.49% for top-10 accuracy. In
other applications such as when historic comments are
not available and cross-project recommendation, PyART
also shows better overall performance.
Our datasets and source code are available on Github5.
The rest of this paper is organized as follows: the motivating
example is presented in Section II. The technical details
of PyART are described in Section III. The evaluation for
our approach is shown in Section IV. Related work and
conclusions are in Section V and Section VI.
II. M OTIVATING EXAMPLE
API recommendation approaches based on Machine Learn-
ing tend to have better performance for Python than most
traditional methods [21]‚Äì[24]. However, existing Machine
Learning based approaches have some limitations. We take
the recommendation results of Visual Studio IntelliCode, one
of the state-of-the-art recommendation tools for Python, as an
example, to demonstrate these limitations (Figure 1).
Observation 1. The ability to recommend APIs is heavily
dependent on the type inference result for the object of the
API call.
Most recommendation tools collect candidate APIs accord-
ing to the type of the object at the recommendation point.
For instance, type of aina.f(). However, due to the dynamic
nature of Python, it is hard to precisely infer object type. If
the type cannot be inferred, IntelliCode cannot produce any
recommendation results. For example, at the recommendation
point kwargs. in Figure 1 (a). That is, assume the developer
has keyed in ‚Äú kwargs. ‚Äù and he/she wants IntelliCode to recom-
mend the API that is supposed to call (which shall be ‚Äú get(...) ‚Äù
as shown in the Ô¨Ånal form of the code). However, IntelliCode
5https://github.com/PYART0/PyART
1635Fig. 1. Motivating example
cannot provide any recommendation due to the lack of type
information about kwargs .
Observation 2. Even if the object type can be successfully
inferred, it is possible that the recommendation list contains
too many candidates that do not have an order better than
the alphabetical order.
The problem typically occurs at recommendation points for
APIs beyond standard libraries. IntelliCode is trained based
on massive data from Github to learn the most frequent
programming patterns. It does very well in recommending
frequently called APIs, but not the project-speciÔ¨Åc ones. For
example, at the recommendation point self. in Figure 1 (b),
the target API is one of the methods deÔ¨Åned in a class of the
current project. IntelliCode provides all of the callable methods
of the class in the alphabetical order as the recommendation.
Although the list contains the right answer crawl() , it ranks
too low to be found. The main reason is that IntelliCode is
largely Machine Learning based. It is very likely that it has
not seen (or trained on) many project-speciÔ¨Åc APIs. As such,
its recommendation cannot be more informative than listing
all callable methods.
Observation 3. Even if IntelliCode manages to type the
object and determines a nontrivial order with some can-
didates labeled with ‚Äô ?‚Äô to indicate high conÔ¨Ådence, the
recommendations can nonetheless be wrong.
The problem occurs due to the uncertainty in Machine
Learning. That is, even though IntelliCode has seen a similar
API invocation context, the API that it learned may not be the
one intended for the current recommendation point. For exam-
ple, at the recommendation point pkg resources. in Figure 1
(c), IntelliCode provides a list of specially recommended APIs
labeled by ‚Äô ?‚Äô, in which the top-4 answers are not expected
but are more frequently used in the training corpus than the
right API.
We propose a novel API recommendation technique specif-
ically designed for Python. It was shown that data-Ô¨Çowis extremely useful in improving API recommendation re-
sults [11], [15], [16]. However, existing techniques heavily
rely on some precise data Ô¨Çow analysis engine, which is
very difÔ¨Åcult for a dynamic language like Python. Traditional
data-Ô¨Çow analyses [25]‚Äì[27] tend to be conservative due to
their application context (i.e., compilation). For example, if
they cannot determine if a read and a preceding write must
access different objects, they conservatively assume that there
is data-Ô¨Çow between the two. As such, they tend to generate
substantial false positives for dynamic languages where type
inference and points-to analysis are much more challenging.
This substantially degrades the recommendation results. The
key observation is API recommendation can be formulated as
a distribution modeling problem that does not require using
conservative analysis . In other words, we aim to determine the
probabilities of different API candidates at a recommendation
point based on various kinds of hints that do not have to be
sound or complete, as long as the joint-distribution of the
hints and the APIs can be precisely modeled. Our method
leverages three kinds of hints/features: optimistic data-Ô¨Çow ,
token similarity along data Ô¨Çow , and token co-occurrence ,
and uses Random Forest to learn the joint-distribution of API
functions (to recommend) and these hints. The learned model
is then used to make recommendation.
Optimistic Data-Ô¨Çow. Optimistic data-Ô¨Çow is data-Ô¨Çow that
appears to be true. The derivation of such data-Ô¨Çow is not
through conservative standard data-Ô¨Çow analysis, but rather in
a way similar to how humans derive data-Ô¨Çow. SpeciÔ¨Åcally,
a set of data-Ô¨Çow derivation rules are deÔ¨Åned for various
syntactic structures such as function calls and loops. We say
these rules are optimistic as they do not consider the possible
disruption/injection of data-Ô¨Çow induced by aliasing. Instead,
they derive data-Ô¨Çow that appears to be true (from variable
ids and control Ô¨Çow structure). For example, in Figure 1 (b),
PyART derives the optimistic data-Ô¨Çow at the recommendation
point as self!targetAPI!statusjnewtasksjresult . Here, the ar-
rows denote the data-Ô¨Çow direction and targetAPI denotes the
API we want to predict. Observe that it only includes the
1636data-Ô¨Çow that can be derived before the API invocation, to
simulate the real-time API recommendation scenario where
only the context before recommendation point is available.
Observe that the data-Ô¨Çow is optimistic as it may not be true.
For example, there may not be any data-Ô¨Çow from self to
any of the result variable. Neither is it complete. Similarly,
for Figure 1 (c), PyART extracts the optimistic data-Ô¨Çow
pkg resources!targetAPI!entry point . Optimistic data-Ô¨Çow
paths are universally extracted at all statements and linked
together if possible. PyART then leverages the similarity of
the data-Ô¨Çow paths at the recommendation point with those
that it has seen in other places during training to help make
prediction.
Token Similarity Along Data-Ô¨Çow. PyART also assumes
that an API should have token similarity with some vari-
able/function along an optimistic data-Ô¨Çow path extracted
above. As such, for each candidate API, it measures the
similarity scores between the candidate and tokens in the data-
Ô¨Çow paths. For example, in Figure 1 (c), the similarity score
between the target API iter entry points and its neighbor to-
ken in the data Ô¨Çow, entry point , is higher than other candidate
APIs, which provides strong hint for the recommendation.
Token Co-occurrence. In the third kind of hints, PyART
leverages co-occurences of tokens. That is, it predicts an API
based on the tokens preceding the recommendation point (in
the same source Ô¨Åle). This includes the enclosing function,
preceding variables, preceding function invocations, etc. Note
that these tokens may not have data-Ô¨Çow with the target API.
For example, for a recommendation point with open(...) as
f: f. , candidates read() andwrite() are more likely to be
invoked due to the high co-occurrence frequency with token
open . In Figure 1 (a), PyART computes the co-occurrence of
candidate API with each token in the bag: fdef, crawl, self, url,
None, track, kwargs, if g. And in Figure 1 (b), PyART computes
the co-occurrence of candidate API and each token in the bag
fdef, test 10notstatus, status, newtasks, result, self g. Here,
a bag is a set of tokens before the recommendation point.
These three kinds of hints are encoded as feature vectors
and used to train a predictive model using Random Forest.
III. A PPROACH
A. Overview
The workÔ¨Çow of PyART is shown in Figure 2. Basically,
PyART takes √ÄPython Code Context before the recom-
mendation point as an input, which consists of statements
preceding the recommendation point (in the same Ô¨Åle), and
outputs a ranked list of recommended APIs to developers. It is
composed of Ô¨Åve main components: √ÅAPI Recommendation
Point Locator ,√ÇData Extractor ,√ÉData Encoder ,√ÑModel
Constructor and√ÖAPI Recommender .
Given a python code context, the API Recommendation
Point Locator Ô¨Årst identiÔ¨Åes the recommendation point in the
form of [Expression].targetAPI() . The Candidate Generator
in the Data Extractor Ô¨Årst performs static type inference
for the object of the target API, i.e., [Expression] , with anexisting light-weight type inference tool pytype6. If the type
inference is successful, the Candidate Generator takes all the
callable methods of the inferred type as the API candidates.
Otherwise, it collects API candidates from the following three
sources: standard libraries, imported third-party libraries and
all the callable methods declared in the current scope. As such,
PyART would not yield an empty list even if the type inference
is not successful. For each recommendation point, the Feature
Collector in the Data Extractor analyzes the source code
before the recommendation point to collects three kinds of
hints, i.e., optimistic data-Ô¨Çow ,token similarity along data-
Ô¨Çow andtoken co-occurrence . Then, all the hints/features are
encoded to feature vectors by the Data Encoder. Each feature
vector is a tuple of 4: ~t= (t1;t2;t3;t4), witht1representing
the optimistic data-Ô¨Çow hint, t2the token similarity along
data-Ô¨Çow hint, and t3andt4the token co-occurrence hints,
speciÔ¨Åcally, t3the co-occurrence (of an API) with the object
(that invokes the API) and t4the co-occurrence with other
tokens.
In model training by the Model Constructor , feature vectors
are extracted from the projects in the training corpus and used
to compose positive and negative samples. Positive samples are
constructed with APIs and their feature vectors, and negative
samples are composed of feature vectors with the API candi-
dates other than the true positives identiÔ¨Åed by the Candidate
Generator . Then, a real-time recommendation model is trained
using the Random Forest algorithm. It essentially learns a
joint-distribution of the hints and the APIs. In the process
of API recommendation, the API Recommender uses the pre-
trained model to compute the probability piof each candidate
API and ranks all these candidates according to pi.
Due to the demand of real-time API recommendation, these
steps have to be lightweight. In the following, we discuss a
number of the important steps in details.
B. Feature Collector
Feature collection needs to address two main challenges: (1)
due to the dynamic nature of Python, there are very few static
analysis tools that are capable of providing accurate results
for Python applications in a cost-effective manner; and (2) in
the context of API recommendation, it is mandatory to deal
with partial code. Therefore, PyART features an efÔ¨Åcient way
of extracting optimistic data-Ô¨Çow around the recommendation
point. As mentioned in Section II, such data-Ô¨Çow is neither
sound nor complete, it just appears to be correct. The idea
is to simulate how humans reason about data-Ô¨Çow. It is
supposed to be concise and largely precise. Our hypothesis
is that it is sufÔ¨Åcient to build a joint-distribution for API
prediction. SpeciÔ¨Åcally, humans infer data-Ô¨Çow largely based
on local symbolic information such as surrounding variables
and program structures and rarely (and in most case unable
to) reason about aliasing that is obscure and global.
SpeciÔ¨Åcally, we deÔ¨Åne rules to derive optimistic data-Ô¨Çow
from Ô¨Åve basic abstract syntax units (AUs): assignment, loop,
6https://github.com/google/pytype
1637Python Code Context API Recommendation 
Point LocatorData EncoderCandidate Genetator
Feature CollectorSample Labeling Training
API Recommender Ranked APIs DevelopersData ExtractorModel Constructor23
45
61Fig. 2. WorkÔ¨Çow of PyART
TABLE I
OPTIMISTIC DATA-FLOW EXTRACTION RULES
Rule name Data-Ô¨Çow derivation Example
`:Assign (v;e) f8u2VM[`](e); u!vgDFS [`](v) e.g.v=e
`:For(v;e) f8u2VM[`](e); u!vgDFS [`](v) e.g.for v in e
`:Invoke (u;v) fu!vgDFS [`](v) e.g.u:v
`:Access (v;e) f8u2VM[`](e); u!vgDFS [`](v) e.g.v[e]
`:Para (f;E);E= (e1;:::;e n)f8ei2E:8uiVM [`](ei); ui!fgDFS [`](f) e.g.f(e1;:::;e n)
`:Aggregate ,Ui;Ujprecedes`8v2Ui\Uj:DFS [`](v)Ui[DFS [`](v)UjDFS [`](v) e.g.for v inu:f(e;x[y])
`:Propagation ,`12pred(`)8v2VM:DFS [`1](v)DFS [`](v)
`:Preservation 8v2VMnkill(`):DFS [`](v)DFS [`](v)
object attribute access/invocation, container access, and func-
tion parameter passing. As mentioned earlier, optimistic data-
Ô¨Çow does not have to be complete such that these rules are
not intended to be comprehensive but rather model the intuitive
methods humans use to infer data-Ô¨Çow. Table I presents these
rules. In the table, label `2Lrepresents the location of each
unit,e2Erepresents an expression, fu;v;x;ygVM rep-
resents a variable object or a method object, f2Frepresents
a function in the code, and Ui;Uj2AU represent instances
of the abstract syntax units. Note that Python considers any
type an object, including a method. As such, we can consider
there is data-Ô¨Çow between an object and the API it invokes.
The notations `and`indicate the program points immediately
before and after the point labelled `, respectively. For example,
VM[`](e)represents all the variable and method objects in
expressionebefore the location labelled `, andDFS [`](v)
contains all the data-Ô¨Çow paths involving object vafter the
location labelled `. The Ô¨Årst column of the table presents the
rule names; the second column presents the corresponding
data-Ô¨Çow derivation and the last column presents examples
for the corresponding AUs.
In the Ô¨Årst rule about assignment, for any variable and
method object uin the right-hand-side operand ebefore a
location`, there is (optimistic) data-Ô¨Çow from uto the left-
hand operand v. The second rule `:For(v;e)speciÔ¨Åes
data-Ô¨Çow extraction for a loop: there is data-Ô¨Çow from anyvariable or method object in the iterator eto the loop vari-
ablev. The third rule `:Invoke (u;v)is about attribute
loading/invocation: if an object uaccesses a Ô¨Åeld attribute
or invokes a method attribute v, there is data-Ô¨Çow between u
andv. Rule`:Access (v;e)speciÔ¨Åes data-Ô¨Çow for container
accesses: if a container v, such as a list, a set or a class,
is accessed through an index e, there is data-Ô¨Çow from any
objectuineto the container object v. Rule`:Para (f;E)is
for function parameter passing. It speciÔ¨Åes that any variable
involved in any of the parameters e1, ...,enhas data-Ô¨Çow
tof. Since the Ô¨Åve units may occur in combinations, rule
Aggregation aggregates the data-Ô¨Çow relations derived from
individual units. Note that they may form paths. SpeciÔ¨Åcally,
for a variable or method object voccurring in both units
UiandUj, the data-Ô¨Çow of vafter location `will contain
both the data-Ô¨Çow relations generated by Uiand byUj
before the location `. Note that the subscripts denote the units
which derive the relations. For example, for an expression
for v inu:f(e;x[y]), there are four units, including the for
loop, attribute invocation, and container access and parameter
passing. The feature collector combines results of each unit
and outputs a long data-Ô¨Çow sequence: (ejy!x)!f!u!v.
In addition, it models the effect of control Ô¨Çow following
thePropagation rule: for any location `after`1, the data-
Ô¨Çow relations right before `contain all those after `1. The
Preservation rule retains all the data-Ô¨Çow relations whose
1638variable or method objects are not affected by a unit (and
hence should be killed, i.e., removed). For example, the value
of a global variable awill not be changed by any statement in
a local block when the key word global is not given. In this
case, data-Ô¨Çow relations that point to ashould be killed.
These rules are strictly syntax and variable name driven
and do not consider aliasing. As such, they can be performed
locally (whereas aliasing requires global analysis) and even
on partial code. These are critical for real-time recommenda-
tion. According to our experiment in Section IV, these rules
allow us to produce data-Ô¨Çow with both high precision (i.e.,
92.06%-98.66%) and high recall ( i.e., 92.58%-98.48%). In
comparison, an existing analysis engine Pysonar2 has very
good precision (up to 100%) but extremely low recall (only
8.48%-28.11%), meaning that it can hardly be used to make
API recommendations. Our results using the optimistic data-
Ô¨Çow show that having concise and largely accurate data-Ô¨Çow
is sufÔ¨Åcient for achieving good recommendation outcomes.
In addition, the Feature Collector also collects the tokens
involved in the data-Ô¨Çow relations (for the later token similar-
ity feature encoding) and the tokens within individual source
code Ô¨Åles (for the later co-occurrence feature encoding). They
are elided due to simplicity.
C. Data Encoder
The Data Encoder encodes the data extracted by the Data
Extractor, including the API candidates and the features. As
such, the encoded information can be used for training during
model construction and for recommendation during deploy-
ment. For a candidate API, the encoder generates a feature
vector~t=(t1;t2;t3;t4) that includes the three aforementioned
features, i.e., optimistic data-Ô¨Çow, token similarity along data-
Ô¨Çow and token co-occurrence. In the following, we discuss
how to encode individual features.
Optimistic Data-Ô¨Çow Encoding. Data-Ô¨Çow propagates impor-
tant information for API recommendation. Intuitively, assume
we have two objects aandband there is an assignment b=a
that induces data-Ô¨Çow between the two. According to Python
semantics,binherits all the method attributes of a. In other
words, if we want to recommend an API for b(e.g.,b:),
we can get hints from what we should recommend for a, and
vice versa. Therefore, in this part of encoding, PyART aims
to quantify the similarity between the data Ô¨Çow path leading
to the recommendation point and some paths it has seen from
the corpus.
SpeciÔ¨Åcally, PyART encodes optimistic data-Ô¨Çow as fol-
lows. For a data-Ô¨Çow path x0!x1!!]API!!
xnthat contains an API, PyART collects the corresponding
token sequence (x0;x1;:::;]API;:::;x n)and learns the or-
der of tokens using a common statistical language model N-
Gram. With a fully pre-trained N-Gram model built on plenty
of data-Ô¨Çow paths containing APIs, PyART is able to learn the
implicit regularity between data-Ô¨Çow and APIs. For instance,
the N-Gram model can predict an API from the preceding data-
Ô¨Çow sub-path. However, in PyART, the model is not directly
used to make recommendation but rather to encode feature.During deployment, upon a recommendation request PyART
encodes the features for each candidate API. It Ô¨Årst extracts
all the data-Ô¨Çow paths related to the current recommendation
location through the Data Extractor. Since PyART focuses on
real-time recommendation, we assume it only extracts data-
Ô¨Çow before the current recommendation point. After that, the
encoder appends the API to the extracted data-Ô¨Çow, which
includes the tokens along all the data-Ô¨Çow paths, sorted by
their distances, to construct an input to the trained N-Gram
model. The model then outputs a log probability score p, which
is taken as the Ô¨Årst element t1of the feature vector ~tof the
API.
Example. For instance, given a recommendation point: for k,v
in dict. , PyART extracts two data-Ô¨Çow paths (ending at k
andv, respectively), denoted as dict!tagetAPI!kjvand
then appends each candidate API to the list fk; v; dicgto
construct an input to the N-Gram model. Among the inputs
(from different candidates), the list denoting the true positive
dict!items!kjvgets the highest log probability (-3.99),
higher than the probabilities of others (i.e., from -7.16 to -
12.3738). The probability -3.99 is used as the Ô¨Årst element of
the feature vector for the candidate API items .
Encoding Token Similarity Along Data-Ô¨Çow. Intuitively,
PyART considers that a candidate API is likely the intended
one if it z sXCQDV1GFHWEYBSJQ1‚Äò Q v has similarity
to some token along a data-Ô¨Çow path reaching the recommen-
dation point. SpeciÔ¨Åcally, for a data-Ô¨Çow path x0!x1!
!]API!!xn, PyART produces a set of triples
in the form of ( xi;]API;d ), in whichxirepresents a token in
the path and drepresents the distance between xiand]API ,
with 0in,0< dn. For a triple ( xi;]API;d ), the
encoder measures the similarity between ]API and tokevcn xi.
It also assigns a xicloser to]API a larger weight (for their
similarity score). For example, in Figure 1 (c), PyART acquires
a data-Ô¨Çow path: pkg resources!targetAPI!entry point , in
which the true positive recommendation iter entry points()
fortargetAPI shares a common sub-string with the token
entry point , and is thus given a larger similarity score.
More precisely, for a token xialong some data-Ô¨Çow path to
the recommendation point, the encoder computes the similarity
score between xiand a candidate API as follows.
sim(xi;API ) =2jlcsk(xi;API )j
d(jxij+jAPIj)(1)
Note thatlcsk(x;API )computes the longest common
token sub-sequence of xiandAPI .
Upon a recommendation request, the encoder computes
the total similarity score tosim (DFS;API )between each
candidateAPI and the tokens in all the data-Ô¨Çow paths that
reach the recommendation point, denoted by a set DFS , as
the second element t2of the feature vector ~tofAPI , using
the following equation:
tosim (DFS;API ) =P
x2DFSsim(x;API )
jDFSj 1(2)
1639Encoding Token Co-occurrence. For each candidate API
in a recommendation request, the encoder derives and en-
codes the token co-occurrence feature in two aspects: (1) co-
occurrence between the object (whose API needs recommen-
dation) and the candidate, called object-API co-occurrence ;
(2) co-occurrence between tokens in the current context (all
the code up to the recommendation point) and the candidate
(called context-API co-occurrence ). Intuitively, the Ô¨Årst kind
leverages the observation that the object and the API are the
closest couple and their co-occurrence distribution provides
strong indication, whereas the second kind aims to leverage a
broader set of information.
For object-API co-occurrences, the encoder replaces the
object name with its type if available, for better gener-
ality. Some example type-API patterns are shown as fol-
lows: List.append() ,String.join() and File.read() . They are
frequently used in Python projects.
More precisely, the encoder computes the object-API co-
occurrence frequency of an object xand a candidate API as
the third element t3of the feature vector ~tofAPI with the
following equation:
confidence (x!API ) =p(APIjx) =N(API;x )
N(x); N(x)6= 0
0; N (x) = 0
(3)
HereN(x)represents the number of occurrences of object
x, andN(API;x )represents the number of co-occurrences
(i.e.,x:API ()).
For context-API co-occurrences, the encoder considers all
the tokens in the current context before the recommendation
point. For example, the built-in function open() that aims to
open a Ô¨Åle always appears with some speciÔ¨Åc tokens like with,
as,f, since the statement is in the form of with open(...) as
f:is widely used in software development. In particular, the
encoder computes the co-occurrence frequency of a token x
and a candidate API with the following equation.
confidence (x!API ) =p(APIjx) =N(API;x )
N(x); N(x)6= 0
0; N (x) = 0
(4)
HereN(x)represents the number of Ô¨Åles in which xoccurs,
andN(API;x )represents the number of Ô¨Åles in which xand
API co-occur.
For a set of tokens S(of the current context before the
recommendation point) S=fx0;x1;:::;x ng, the encoder
computes the overall co-occurrence frequency of Sand a
candidate API as the fourth element t4of the feature vector ~t
with the following equation.
totalCnfd (S;API ) =1
jSjX
xiconfidence (xi!API)
dist(xi;API )
(5)
Heredist(xi;API )computes the distance between xiand
API . Recall a closer xihas a larger weight for their co-
occurrence score.D. Training and Recommendation
Model Constructor. The Model Constructor performs super-
vised learning using Random Forest. The model learns to
predict API from the feature vectors. The training feature
vectors are divided into two categories: (1) positive cases:
feature vectors generated from the true positive APIs, labeled
as1; and (2) negative cases: feature vectors generated from
other candidate APIs, labeled as 0.
API Recommender. For a recommendation request [Expres-
sion]. , PyART Ô¨Årst collects all the candidate APIs. For each
candidate API, it computes the corresponding feature vector.
Then, the API recommender takes all the candidate feature
vectors as test cases and provides them to the recommendation
model that is pre-trained. For each candidate vector, the
recommendation model produces a probability pithat the label
of the vector is 1. Finally, it ranks all the candidates according
topiand outputs the ranked list to developers.
IV. E VALUATION
A. Research Questions
To evaluate PyART, we propose the following research
questions.
RQ1: How effective is PyART in data-Ô¨Çow analysis, com-
pared with one of the state-of-art approaches, Pysonar2?
RQ2: In comparison with the state-of-the-art approaches,
Visual Studio IntelliCode and Py-APIREC, how effective is
PyART in recommending APIs within a project?
RQ3: In comparison with the state-of-the-art approaches,
Visual Studio IntelliCode and Py-APIREC, how effective is
PyART in recommending API calls across projects?
RQ4: How efÔ¨Åcient is PyART in recommending APIs in
real-time?
RQ5: What is the impact of each kind of features?
B. Baselines
To evaluate the effectiveness and efÔ¨Åciency of PyART,
we choose a state-of-the-art, Pysonar2, as the baseline for
data-Ô¨Çow analysis evaluation (RQ1), and two state-of-the-art
approaches Visual Studio IntelliCode and Py-APIREC as the
baselines for the API recommendation evaluation (RQ2-3).
Pysonar2. Pysonar27is an advanced static analyzer
for Python, which performs (costly) whole-project inter-
procedural analysis to infer types.
Visual Studio IntelliCode. Visual Studio IntelliCode is an
experimental set of AI-assisted developer productivity tools,
trained from thousands of open-source projects on GitHub
with high star ratings8. For an API recommendation task,
IntelliCode places the most relevant ones at the top of the
recommendation list and labels them with a star.
Py-APIREC. We reproduce a state-of-art API recommenda-
tion method for Java named APIREC [9] and port it to Python.
Since Py-APIREC relies heavily on Ô¨Åne-grained code changes
that happen on AST nodes, the accuracy of recommendation
7https://github.com/yinwang0/pysonar2
8https://visualstudio.microsoft.com
1640results is hence heavily dependent on the accuracy of AST
differencing tools and code change histories. Following the
original paper, we diff the consecutive commits to identify
code changes. We validate the correctness of the reproduced
APIREC (before porting it to Python) by comparing the results
acquired by our reproduced system with the ones published in
the original paper. The error is within 5%.
C. Implementation
We make our evaluation on Linux Ubuntu 4.15.0-66-generic
with Intel(R) Xeon(R) Gold 5118 CPU @ 2.30GHz. All
approaches (including Py-APIREC and PyART) are realized
in Python 3. In the process of porting APIREC, We use the
state-of-the-art AST diff tool Gumtree9to extract Ô¨Åne-grained
code changes. We learn two parameters wCandwTfor Py-
APIREC from a training set using the hill-climbing adaptive
learning algorithm [9], and use the following settings: (1) we
set the value of fold number kas 10; (2) we set the step size
in hill-climbing as 0.01; (3) we set the maximum number
of iterations in adaptive learning as 1000. Besides, in order to
provide a simple static type inference for PyART, we use a
type inference tool Pytype10.
D. Evaluation Setup
For fair comparison with Py-APIREC and Intellicode, we
set up three scenarios about the corpora used in evaluation.
Project Edition (PE). We randomly collect 8 Python projects
from Github that have a long development history with 12,194
commits and 1,195,994 Ô¨Åles in total as a corpus called Project
Edition .Project Edition was deÔ¨Åned in [9], which uses the
oldest 90% of project commits for training and the 10% most
recent commits for recommendation. In particular, we train Py-
APIREC and PyART on the Ô¨Årst 90% commits of each project,
and test Py-APIREC, IntelliCode and PyART on the remaining
10% commits. Since Py-APIREC can only recommend APIs
in speciÔ¨Åc kinds of code changes (i.e., Add that inserts a
node into an AST, MethodInvocation that changes a method
invocation, and APIName that denotes the name of a method)
and cannot deal with APIs in other kinds of changes, we select
code changes that Py-APIREC can identify and recommend in
the remaining 10% commits as the recommendation points for
a fair comparison. The results of PE are used to answer RQ2
(intra-project effectiveness). Moreover, we record the time of
each recommendation of PyART to answer RQ4.
Intra-Project Edition (IPE). To evaluate the intra-project ef-
fectiveness of PyART when historic commits are not available,
we prepare another set as follows. We call it the Intra-Project
Edition (IPE). SpeciÔ¨Åcally, we collect the last commit of each
project in PE to form the IPE corpus, consisting of 474 Python
Ô¨Åles and 86,853 LOCs. We then divide the source Ô¨Åles of each
project in 10 folds. We train PyART on 9 of the 10 folds and
test it on the 1. The 10-fold evaluation is performed Ô¨Åve times
9https://github.com/GumTreeDiff/gumtree
10https://github.com/google/pytypeTABLE II
DATA SET STATISTICS FOR PE AND CE
PE CE
Total projects 8 30
Total source Ô¨Åles 1,195,994 7,634,717
Total SLOCs 166,146,606 1,344,587,261
Number of commits 12,194 86,078
Total changed Ô¨Åles 20,390 106,817
Total AST nodes of changed Ô¨Åles 7,538,521 113,657,525
Total changed AST nodes 1,024,072 10,043,518
Total detected changes 264,683 2,040,272
Total detected changes with APIs 21,795 285,216
on each project. The average results are shown in Table V as
part of the answer to RQ2.
Community Edition (CE). APIREC collects a large corpus
called Community Edition . It trains its prediction model on this
corpus ad then tests it on a different (and smaller) corpus to
evaluate the cross-project recommendation effectiveness. We
conduct a similar experiment. We collect the top-30 forked
Python projects from Github, with long development histories
(i.e., 86,078 commits and 7,634,717 Ô¨Åles) as the CE corpus.
We train Py-APIREC on all the commits of the 30 projects and
train PyART only on the last commit of the 30 projects for the
sake of cost-saving. Then, we use Py-APIREC, IntelliCode and
PyART to make recommendations for code changes in all the
commits of the 8 projects in PE to answer RQ3. In addition,
we train PyART with different subsets of feature vectors from
CE and evaluate the trained model on the projects from PE to
study how the features impact accuracy (RQ5).
The statistics for the PE and CE sets are shown in Table II.
E. Metrics and Settings
Data-Ô¨Çow analysis evaluation. We evaluate the effectiveness
of data-Ô¨Çow analysis in PyART and also in Pysonar2 (for
comparison) using precision, recall and F1-score. In order to
construct a good baseline like the ‚Äúground truth‚Äù, two authors
that have more than three years of Python coding experience
inspect a subset of source Ô¨Åles in IPE (10 random Ô¨Åles per
project with each Ô¨Åle having 27-1725 LOC) and manually
recognize the data-Ô¨Çow in these Ô¨Åles. Here we look at pair-
wise data-Ô¨Çow relations (i.e., deÔ¨Ånition and use). We use
manual inspection as the ground truth because there is not
an existing tool that can report sound and complete data-Ô¨Çow
information. We do recognize that humans may not extract
global data-Ô¨Çow and hence the human results may be biased.
Note that we do not claim that our data-Ô¨Çow analysis is
accurate and complete. Instead, optimistic data Ô¨Çow analysis
is to simulate how humans reason about data Ô¨Çow and hence
we argue the human study can serve as a reasonable baseline.
API Recommendation evaluation. We evaluate PyART, Py-
APIREC and IntelliCode using Top-k accuracy(%). For a list
of possible APIs recommended with the length of l, we search
for the correct answer among the Ô¨Årst kelements of the list.
We set the value of kto 1, 2, 3, 4, 5, and 10, respectively. For a
1641more intuitive and objective evaluation of PyART and the other
baselines, we also use MRR as an evaluation measure. MRR
(Mean Reciprocal Rank) evaluates the process that produces a
list of possible APIs ordered by the probability of correctness,
and computes the average of the reciprocal ranks of results
with Equation (6):
MRR =1
jQjjQjX
i=11
rank i(6)
Qrefers to a sample of queries, and rank irefers to the rank
of the Ô¨Årst relevant API for the i-th query. Intuitively, a larger
MRR value means a more accurate recommendation.
F . Result Analysis
Data Flow Analysis Evaluation (RQ1). According to Ta-
ble III, PyART‚Äôs data-Ô¨Çow results align well with the human
baseline (92.06%-98.66% precision and 92.58%-98.48% re-
call). In contrast, PySonar2 has very good precision (up to
100%) but extremely low recall (only 8.48%-28.11%). The
reason is that PySonar2 aims to avoid false dependences
caused by aliasing. As such, when it is not sure, it does not
report. Note that traditional data-Ô¨Çow analyses conservatively
assume there is data-Ô¨Çow when they are not sure (for safety).
Such sparse data-Ô¨Çow information generated by PySonar2 can
hardly be used to make API recommendations. Observe it has
runtime failures during analysis in a few cases too.
Effectiveness within Projects (RQ2). According to Table IV,
PyART achieves better accuracy and MRR score than the
baselines Py-APIREC and IntelliCode on almost all projects.
The top1 accuracy of PyART is generally high (i.e., up
to 70.49%), which supports the effectiveness of PyART on
recommending APIs within projects. In addition, we conduct
an experiment using the IPE set (i.e., no historic commits).
We train the model on 90% of the source Ô¨Åles and evaluate it
on the remaining 10% Ô¨Åles. The recommendation points are
selected in the same way as before. Note that Py-APIREC
is not applicable in this scenario. The results are shown in
Table V. Observe that PyART is still highly effective even
it does not get to learn from other commits. It substantially
outperforms IntelliCode in majority of the cases.
Effectiveness Evaluation across Projects (RQ3). According
to Table VI, the average accuracy and MRR of PyART
are higher than those of Py-APIREC and IntelliCode, which
supports the effectiveness of PyART across projects. Although
the top-k accuracies and MRR of PyART are generally higher,
a small part of projects show inferior results (than Intellicode).
This is acceptable since Intellicode is trained based on thou-
sands of Python code on Github, while PyART is only trained
on 30 projects.
EfÔ¨Åciency Evaluation (RQ4). It is important for recommen-
dation tools to respond in a short period of time. According
to Figure 3, the average API recommendation time of PyART
for a query in each project is generally lower than one second,
hardly noticeable.
Fig. 3. Recommendation time of PyART
Feature Importance Analysis (RQ5). We evaluate each kind
of feature by subtracting one kind at a time to construct a new
random forest model. Figure 4 shows the effects of each kind
of feature on top-1 accuracy, top-5 accuracy, top-10 accuracy,
and the MRR value. According to the results, we observe
that each kind has a non-trivial positive contribution to the
accuracy. For 6 out of the 8 projects, accuracy is most heavily
affected by the optimistic data-Ô¨Çow feature.
G. Threats to Validity
Internal validity. Our evaluation is performed on a limited
set of Python projects. The performance of PyART may vary
for different programs. The ground truth of the data Ô¨Çow
evaluation and the results of API recommendation by using
Intellicode are both provided manually, which may lead to
biases. To mitigate such risk, two authors performed the same
experiments independently and cross-checked afterwards. An-
other author was employed to resolve any conÔ¨Çict. The conÔ¨Çict
rate is lower than 5% and all of them were resolved. For
validation and reproduction purpose, we release our code and
datasets.
External validity. There are often run-time errors when using
Gumtree and parser on Python programs. This is different from
the case for Java programs. Such errors may lead to biases.
V. R ELATED WORK
API recommendation for natural language queries. Re-
searchers use embeddings [1]‚Äì[4], [6], [28]‚Äì[33] to model
and translate among natural language queries, application
documentation, and API functionalities. Others use graphs for
representation and recommendation [5], [7]. These techniques
aim to answer queries in natural languages and differ from our
real-time scenario.
Method recommendation based on code corpus and con-
text. Nguyen et al. [10] proposed a graph-based language
model Gralan learned from a source code corpus. Based
on the model, an API suggestion engine and an AST-based
language model are constructed to make recommendation.
Nguyen et al. [9] proposed to learn from a corpus the regularity
between Ô¨Åne-grained code changes [34], [35] and APIs, and
use that to make recommendations. Liu et al. [11] proposed
a method independent of historical commits by ranking the
Top-10 recommendations of Gralan [10] to achieve better
1642TABLE III
DATA FLOW ANALYSIS RESULTS FOR PYTHON (compared to the human extracted baseline )
Model Metrics cornice pyspider bs4 httpbin allennlp gitsome simplejson Ô¨Çask
Pysonar2Precision 100 100 100 100 Failure Failure 100 Failure
Recall 9.03 8.48 14.77 9.83 Failure Failure 28.11 Failure
F1-score 16.56 15.63 25.74 17.90 Failure Failure 43.88 Failure
PyARTPrecision 96.46 98.54 95.57 96.75 95.85 92.06 97.53 98.66
Recall 94.06 96.97 98.48 96.65 92.58 98.03 96.42 96.00
F1-score 95.24 97.75 97.00 96.70 94.19 94.95 96.97 97.31
(a) Top-1 Accuracy (%)
 (b) Top-5 Accuracy (%)
(c) Top-10 Accuracy (%)
 (d) MRR (%)
Fig. 4. Impact of each kind of features on accuracy and MRR
Top-1 accuracy than APIREC [9]. Nguyen et al. [12] mine
open-source software (OSS) repositories [36], [37] to provide
developers with API function calls and usage patterns by
analyzing how APIs are used in projects similar to the current
project using a 3D matrix. Although existing works achieve
very good results, most of them aim at recommending APIs
for static languages such as Java. API recommendation for
dynamic languages in real-time poses many new challenges.
Sch¬®afer et al. [38] proposed an effective smart completion
method for JavaScript by combining a static alias analysis
[39], [40] enhanced with support for usage-based property
inference and a fully automatic dynamic analysis which infersAPI models based on the framework‚Äôs test suite. D‚ÄôSouza et al.
[15] leveraged API use patterns from open-source repositories
to order Python API recommendations. However it does not
focus on addressing the prominent challenges in dynamic
languages, such as type dynamics, path sensitivity and third-
party libraries. There are some IDEs such as Intellicode [22]
that provide real-time recommendations for Python APIs based
on artiÔ¨Åcial intelligence technologies. However, they are often
dependent on type information and cannot make accurate
recommendations for project-speciÔ¨Åc APIs.
1643TABLE IV
RECOMMENDAITON RESULTS WITHIN PROJECTS
Model top1 top2 top3 top4 top5 top10 MMR
allennlpPy-APIREC 17.39 26.09 26.09 30.43 30.43 39.13 23.74
IntelliCode 1.64 3.28 3.28 3.28 14.75 21.31 8.14
PyART 19.70 23.96 26.46 28.77 30.06 34.51 24.95
bs4Py-APIREC 27.27 27.27 27.27 27.27 27.27 45.45 31.42
IntelliCode 41.67 50.00 50.00 50.00 50.00 58.33 48.76
PyART 70.49 77.97 80.08 81.60 83.21 86.26 76.22
cornicePy-APIREC 7.50 15.00 22.50 27.50 27.50 32.50 17.04
IntelliCode 13.33 13.33 13.33 13.33 20.00 26.67 17.62
PyART 48.55 56.41 63.05 65.01 66.90 70.94 56.89
Ô¨ÇaskPy-APIREC 5.56 11.11 11.11 11.11 16.67 27.78 12.04
IntelliCode 44.44 48.15 48.15 48.15 48.15 59.26 48.71
PyART 53.84 63.68 67.64 70.17 71.89 76.21 62.02
gitsomePy-APIREC 4.04 8.31 10.56 11.01 11.69 15.06 8.71
IntelliCode 19.78 21.98 25.27 30.77 34.07 36.26 24.71
PyART 30.85 40.69 44.56 47.54 49.78 55.74 39.75
httpbinPy-APIREC 11.11 11.11 22.23 44.44 44.44 44.44 24.13
IntelliCode 38.10 38.10 42.86 42.86 42.86 42.86 41.39
PyART 67.06 79.22 80.78 80.78 82.35 83.92 74.42
pyspiderPy-APIREC 13.59 33.7 42.93 43.48 44.56 45.65 27.51
IntelliCode 6.06 10.61 13.64 16.67 16.67 57.58 15.48
PyART 60.41 71.87 75.47 77.46 78.61 82.90 68.99
simplejsonPy-APIREC 8.33 8.33 16.67 66.67 75.00 75.00 26.20
IntelliCode 14.29 28.57 28.57 57.14 57.14 71.43 31.35
PyART 65.11 80.65 81.58 85.77 85.91 87.18 74.57
avgPy-APIREC 11.84 17.62 22.42 32.74 34.70 40.63 21.35
IntelliCode 22.41 26.75 28.14 32.78 35.46 46.71 29.52
PyART 50.89 60.27 63.43 65.54 66.99 71.12 58.47
TABLE V
RESULTS OF INTRA -PROJECT EVALUATION
Model top1 top2 top3 top4 top5 top10 MRR
allennlpIntelliCode 13.74 16.44 18.02 18.24 20.05 22.07 17.24
PyART 13.17 16.01 19.57 19.93 20.64 24.91 17.42
bs4IntelliCode 23.08 25.00 25.00 30.77 44.23 50.00 29.59
PyART 39.29 39.29 42.86 42.86 50.00 57.14 43.16
corniceIntelliCode 4.65 16.28 16.28 20.93 25.58 32.56 14.20
PyART 32.05 39.07 39.87 39.87 39.87 46.09 37.12
Ô¨ÇaskIntelliCode 15.69 21.57 23.53 29.41 31.37 45.10 24.20
PyART 15.18 17.31 19.44 19.44 23.80 28.06 19.56
gitsomeIntelliCode 6.71 8.05 8.05 8.72 8.72 10.74 8.72
PyART 32.30 36.77 46.05 48.45 50.52 56.01 40.02
httpbinIntelliCode 15.66 16.87 26.51 27.71 30.12 33.73 21.64
PyART 11.11 20.64 20.64 24.60 30.16 40.48 20.28
pyspiderIntelliCode 22.75 28.74 29.94 30.54 32.34 37.13 28.18
PyART 36.55 42.26 43.79 45.09 45.50 46.77 40.97
simplejsonIntelliCode 14.81 18.52 18.52 22.22 29.63 33.33 21.23
PyART 16.05 30.57 34.91 36.38 36.38 41.50 26.53
avgIntelliCode 14.64 18.93 20.73 23.57 27.78 33.08 20.63
PyART 24.46 30.24 33.39 34.58 37.11 42.62 30.63
VI. C ONCLUSION
We propose a novel approach, PyART, to recommending
APIs in real-time for Python. It overcomes the challenges of
handling dynamic language features by extracting so-called
optimistic data-Ô¨Çow, which is neither sound nor complete,TABLE VI
RECOMMENDAITON RESULTS ACROSS PROJECTS
Model top1 top2 top3 top4 top5 top10 MMR
allennlpPy-APIREC 0 1.78 4.32 5.04 5.04 10.07 4.27
IntelliCode 12.32 18.01 23.38 30.02 31.12 46.45 22.28
PyART 13.59 18.26 22.05 24.72 32.29 45.66 22.09
bs4Py-APIREC 3.03 3.03 3.23 3.23 3.23 6.45 5.83
IntelliCode 11.39 14.77 15.19 19.41 26.16 40.93 18.72
PyART 13.65 22.60 23.03 25.59 29.64 35.39 21.48
cornicePy-APIREC 3.42 9.22 16.99 17.48 18.93 24.76 11.25
IntelliCode 14.00 19.20 20.40 22.80 25.60 35.60 20.45
PyART 17.89 24.31 26.61 27.98 32.11 38.99 24.89
Ô¨ÇaskPy-APIREC 4.65 10.47 13.95 17.44 17.44 18.60 11.13
IntelliCode 20.79 25.14 27.98 29.87 30.25 37.62 26.38
PyART 12.80 21.39 24.68 33.64 37.48 44.79 22.90
gitsomePy-APIREC 12.24 14.29 15.31 17.35 18.37 21.43 15.94
IntelliCode 19.47 24.34 28.76 31.86 33.19 33.19 25.88
PyART 27.81 28.48 32.45 33.77 34.44 39.74 31.44
httpbinPy-APIREC 10.77 20.77 24.62 26.92 27.69 48.46 22.63
IntelliCode 27.19 30.70 31.58 31.58 32.46 35.96 31.19
PyART 27.16 32.10 37.04 39.51 45.68 53.09 34.95
pyspiderPy-APIREC 16.95 16.95 18.64 18.64 22.03 22.03 18.87
IntelliCode 15.70 21.94 24.09 25.38 26.45 40.00 22.92
PyART 15.74 25.63 30.46 32.23 35.03 42.13 24.97
simplejsonPy-APIREC 3.23 6.45 12.90 19.35 19.35 29.03 12.31
IntelliCode 20.00 27.50 27.50 32.50 35.00 45.00 28.36
PyART 26.32 26.32 36.84 36.84 63.16 78.95 38.08
avgPy-APIREC 6.79 10.37 13.75 15.68 16.51 22.60 12.74
IntelliCode 17.61 22.70 23.99 27.93 30.03 39.34 24.52
PyART 19.37 24.89 29.15 31.79 38.73 47.34 27.60
but resembles the data-Ô¨Çow information humans derive. It
also extracts token similarity and token co-occurrences as
additional features and encodes them together to numerical
vectors. Random forest is then used to train a model from a
corpus of Python projects. Our results show that our technique
substantially outperforms a state-of-the-art research prototype
and the API recommendation technique in a mainstream
Python IDE.
ACKNOWLEDGMENT
We thank the anonymous reviewers for their construc-
tive comments. This research was supported, in part by
NSFC 61832009, Jiangsu Postgraduate Innovation Program
KYCX20 0041, Cooperation Fund of Huawei-Nanjing Uni-
versity Next Generation Programming Innovation Lab (No.
YBN2019105178SW11), NSF 1901242 and 1910300, ONR
N000141712045, N000141410468 and N000141712947. Any
opinions, Ô¨Åndings, and conclusion in this paper are those of
the authors only and do not necessarily reÔ¨Çect the views of
our sponsors.
1644REFERENCES
[1] Q. Huang, X. Xia, Z. Xing, D. Lo, and X. Wang, ‚ÄúApi method
recommendation without worrying about the task-api knowledge gap,‚Äù
inProceedings of the 33rd ACM/IEEE International Conference on
Automated Software Engineering . ACM, 2018, pp. 293‚Äì304.
[2] W. Xiong, Z. Lu, B. Li, B. Hang, and Z. Wu, ‚ÄúAutomating smart rec-
ommendation from natural language api descriptions via representation
learning,‚Äù Future Generation Computer Systems , vol. 87, pp. 382‚Äì391,
2018.
[3] M. M. Rahman, C. K. Roy, and D. Lo, ‚ÄúRack: Automatic api recom-
mendation using crowdsourced knowledge,‚Äù in 2016 IEEE 23rd Interna-
tional Conference on Software Analysis, Evolution, and Reengineering
(SANER) , vol. 1. IEEE, 2016, pp. 349‚Äì359.
[4] X. Sun, C. Xu, B. Li, Y . Duan, and X. Lu, ‚ÄúEnabling feature location for
api method recommendation and usage location,‚Äù IEEE Access , vol. 7,
pp. 49 872‚Äì49 881, 2019.
[5] L. Qi, Q. He, F. Chen, W. Dou, S. Wan, X. Zhang, and X. Xu, ‚ÄúFinding
all you need: Web apis recommendation in web of things through
keywords search,‚Äù IEEE Transactions on Computational Social Systems ,
2019.
[6] W. Yuan, H. H. Nguyen, L. Jiang, Y . Chen, J. Zhao, and H. Yu, ‚ÄúApi
recommendation for event-driven android application development,‚Äù
Information and Software Technology , vol. 107, pp. 30‚Äì47, 2019.
[7] C.-Y . Ling, Y .-Z. Zou, Z.-Q. Lin, and B. Xie, ‚ÄúGraph embedding based
api graph search and recommendation,‚Äù Journal of Computer Science
and Technology , vol. 34, no. 5, pp. 993‚Äì1006, 2019.
[8] C. Chen, X. Peng, J. Sun, Z. Xing, X. Wang, Y . Zhao, H. Zhang, and
W. Zhao, ‚ÄúGenerative api usage code recommendation with parameter
concretization,‚Äù Science China Information Sciences , vol. 62, no. 9, p.
192103, 2019.
[9] A. T. Nguyen, M. Hilton, M. Codoban, H. A. Nguyen, L. Mast,
E. Rademacher, T. N. Nguyen, and D. Dig, ‚ÄúApi code recommendation
using statistical learning from Ô¨Åne-grained changes,‚Äù in Proceedings of
the 2016 24th ACM SIGSOFT International Symposium on Foundations
of Software Engineering . ACM, 2016, pp. 511‚Äì522.
[10] A. T. Nguyen and T. N. Nguyen, ‚ÄúGraph-based statistical language
model for code,‚Äù in 2015 IEEE/ACM 37th IEEE International Confer-
ence on Software Engineering , vol. 1. IEEE, 2015, pp. 858‚Äì868.
[11] X. Liu, L. Huang, and V . Ng, ‚ÄúEffective api recommendation without
historical software repositories,‚Äù in Proceedings of the 33rd ACM/IEEE
International Conference on Automated Software Engineering , 2018, pp.
282‚Äì292.
[12] P. T. Nguyen, J. Di Rocco, D. Di Ruscio, L. Ochoa, T. Degueule, and
M. Di Penta, ‚ÄúFocus: A recommender system for mining api function
calls and usage patterns,‚Äù in Proceedings of the 41st International
Conference on Software Engineering . IEEE Press, 2019, pp. 1050‚Äì
1060.
[13] C. Chen, Z. Xing, Y . Liu, and K. L. X. Ong, ‚ÄúMining likely analogical
apis across third-party libraries via large-scale unsupervised api seman-
tics embedding,‚Äù IEEE Transactions on Software Engineering , pp. 1‚Äì15,
2019.
[14] X. Ren, J. Sun, Z. Xing, X. Xia, and J. Sun, ‚ÄúDemystify ofÔ¨Åcial api
usage directives with crowdsourced api misuse scenarios, erroneous code
examples and patches,‚Äù in 2020 IEEE/ACM 42th IEEE International
Conference on Software Engineering . IEEE, 2020, pp. 925‚Äì936.
[15] A. R. D‚ÄôSouza, D. Yang, and C. V . Lopes, ‚ÄúCollective intelligence for
smarter api recommendations in python,‚Äù in 2016 IEEE 16th Interna-
tional Working Conference on Source Code Analysis and Manipulation
(SCAM) . IEEE, 2016, pp. 51‚Äì60.
[16] R. Xie, X. Kong, L. Wang, Y . Zhou, and B. Li, ‚ÄúHirec: Api recom-
mendation using hierarchical context,‚Äù in 2019 IEEE 30th International
Symposium on Software Reliability Engineering (ISSRE) . IEEE, 2019,
pp. 369‚Äì379.
[17] M. Gorbovitski, Y . A. Liu, S. D. Stoller, T. Rothamel, and T. K. Tekle,
‚ÄúAlias analysis for optimization of dynamic languages,‚Äù in Proceedings
of the 6th Symposium on Dynamic Languages , 2010, pp. 27‚Äì42.
[18] L. Fritz and J. Hage, ‚ÄúCost versus precision for approximate typing
for python,‚Äù in Proceedings of the 2017 ACM SIGPLAN Workshop on
Partial Evaluation and Program Manipulation , 2017, pp. 89‚Äì98.
[19] Z. Xu, X. Zhang, L. Chen, K. Pei, and B. Xu, ‚ÄúPython probabilistic
type inference with natural language support,‚Äù in Proceedings of the
2016 24th ACM SIGSOFT International Symposium on Foundations of
Software Engineering , 2016, pp. 607‚Äì618.[20] M. Salib, ‚ÄúStarkiller: A static type inferencer and compiler for python,‚Äù
Ph.D. dissertation, Massachusetts Institute of Technology, 2004.
[21] A. Svyatkovskiy, S. K. Deng, S. Fu, and N. Sundaresan, ‚ÄúIntelli-
code compose: Code generation using transformer,‚Äù arXiv preprint
arXiv:2005.08025 , 2020.
[22] A. Svyatkovskiy, Y . Zhao, S. Fu, and N. Sundaresan, ‚ÄúPythia: ai-assisted
code completion system,‚Äù in Proceedings of the 25th ACM SIGKDD
International Conference on Knowledge Discovery & Data Mining ,
2019, pp. 2727‚Äì2735.
[23] M. Asaduzzaman, C. K. Roy, K. A. Schneider, and D. Hou, ‚ÄúCscc:
Simple, efÔ¨Åcient, context sensitive code completion,‚Äù in 2014 IEEE In-
ternational Conference on Software Maintenance and Evolution . IEEE,
2014, pp. 71‚Äì80.
[24] M. Bruch, M. Monperrus, and M. Mezini, ‚ÄúLearning from examples
to improve code completion systems,‚Äù in Proceedings of the 7th joint
meeting of the European software engineering conference and the ACM
SIGSOFT symposium on the foundations of software engineering , 2009,
pp. 213‚Äì222.
[25] G. A. Kildall, ‚ÄúA uniÔ¨Åed approach to global program optimization,‚Äù in
Proceedings of the 1st annual ACM SIGACT-SIGPLAN symposium on
Principles of programming languages , 1973, pp. 194‚Äì206.
[26] M. Rapoport, O. Lhot ¬¥ak, and F. Tip, ‚ÄúPrecise data Ô¨Çow analysis in the
presence of correlated method calls,‚Äù in International Static Analysis
Symposium . Springer, 2015, pp. 54‚Äì71.
[27] K. D. Cooper, T. J. Harvey, and K. Kennedy, ‚ÄúIterative data-Ô¨Çow
analysis, revisited,‚Äù Tech. Rep., 2004.
[28] Y . Bengio, A. Courville, and P. Vincent, ‚ÄúRepresentation learning: A
review and new perspectives,‚Äù IEEE transactions on pattern analysis
and machine intelligence , vol. 35, no. 8, pp. 1798‚Äì1828, 2013.
[29] A. Coates, A. Ng, and H. Lee, ‚ÄúAn analysis of single-layer networks
in unsupervised feature learning,‚Äù in Proceedings of the fourteenth
international conference on artiÔ¨Åcial intelligence and statistics , 2011,
pp. 215‚Äì223.
[30] W. Hamilton, Z. Ying, and J. Leskovec, ‚ÄúInductive representation
learning on large graphs,‚Äù in Advances in neural information processing
systems , 2017, pp. 1024‚Äì1034.
[31] Y . Li, L. Xu, F. Tian, L. Jiang, X. Zhong, and E. Chen, ‚ÄúWord embedding
revisited: A new representation learning and explicit matrix factoriza-
tion perspective,‚Äù in Twenty-Fourth International Joint Conference on
ArtiÔ¨Åcial Intelligence , 2015, pp. 3650‚Äì3656.
[32] O. Levy and Y . Goldberg, ‚ÄúNeural word embedding as implicit matrix
factorization,‚Äù in Advances in neural information processing systems ,
2014, pp. 2177‚Äì2185.
[33] Y .-Y . Lee, H. Ke, T.-Y . Yen, H.-H. Huang, and H.-H. Chen, ‚ÄúCombining
and learning word embedding with wordnet for semantic relatedness
and similarity measurement,‚Äù Journal of the Association for Information
Science and Technology , vol. 71, no. 6, pp. 657‚Äì670, 2020.
[34] S. Negara, M. Codoban, D. Dig, and R. E. Johnson, ‚ÄúMining Ô¨Åne-grained
code changes to detect unknown change patterns,‚Äù in Proceedings of the
36th International Conference on Software Engineering , 2014, pp. 803‚Äì
813.
[35] M. Dias, A. Bacchelli, G. Gousios, D. Cassou, and S. Ducasse, ‚ÄúUntan-
gling Ô¨Åne-grained code changes,‚Äù in 2015 IEEE 22nd International Con-
ference on Software Analysis, Evolution, and Reengineering (SANER) .
IEEE, 2015, pp. 341‚Äì350.
[36] B. Fitzgerald, ‚ÄúThe transformation of open source software,‚Äù MIS
quarterly , pp. 587‚Äì598, 2006.
[37] D. Spinellis, Z. Kotti, K. Kravvaritis, G. Theodorou, and P. Louridas,
‚ÄúA dataset of enterprise-driven open source software,‚Äù arXiv preprint
arXiv:2002.03927 , 2020.
[38] M. Sch ¬®afer, M. Sridharan, J. Dolby, and F. Tip, ‚ÄúEffective smart
completion for javascript,‚Äù Technical Report RC25359 , 2013.
[39] P. Fegade and C. Wimmer, ‚ÄúScalable pointer analysis of data structures
using semantic models,‚Äù in Proceedings of the 29th International Con-
ference on Compiler Construction , 2020, pp. 39‚Äì50.
[40] M. Hind, ‚ÄúPointer analysis: Haven‚Äôt we solved this problem yet?‚Äù
inProceedings of the 2001 ACM SIGPLAN-SIGSOFT workshop on
Program analysis for software tools and engineering , 2001, pp. 54‚Äì61.
1645