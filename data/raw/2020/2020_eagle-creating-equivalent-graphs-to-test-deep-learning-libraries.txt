EAGLE: Creating Equivalent Graphs to Test Deep Learning
Libraries
Jiannan Wang
Purdue University
West Lafayette, USA
wang4524@purdue.eduThibaud Lutellier
University of Waterloo
Waterloo, Canada
tlutelli@uwaterloo.caShangshu Qian
Purdue University
West Lafayette, USA
shangshu@purdue.edu
Hung Viet Pham
University of Waterloo
Waterloo, Canada
hvpham@uwaterloo.caLin Tan
Purdue University
West Lafayette, USA
lintan@purdue.edu
ABSTRACT
Testing deep learning (DL) software is crucial and challenging.
Recentapproachesusedifferentialtestingtocross-checkpairsof
implementationsofthesamefunctionalityacrossdifferentlibraries.
SuchapproachesrequiretwoDLlibraries implementingthesame
functionality,which isoftenunavailable. Inaddition,theyrely on
ahigh-levellibrary,Keras,thatimplementsmissingfunctionality
in all supported DL libraries, which is prohibitively expensive and
thus no longer maintained.
To address this issue, we propose EAGLE, a new technique that
uses differential testing in a different dimension, by using equiv-alent graphs to test a single DL implementation (e.g., a single DL
library). Equivalent graphs use different Application Programming
Interfaces (APIs), data types, or optimizations to achieve the same
functionality. The rationale is that two equivalent graphs executed
on a single DL implementation should produce identical outputgiven the same input. Specifically, we design 16 new DL equiva-lence rules and propose a technique, EAGLE, that (1) uses these
equivalence rules to build concrete pairs of equivalent graphs and
(2) cross-checks the output of these equivalent graphs to detect
inconsistency bugs in a DL library.
Ourevaluationontwowidely-usedDLlibraries,i.e.,TensorFlow
and PyTorch, shows that EAGLE detects 25 bugs (18 in TensorFlow
and 7 in PyTorch), including 13 previously unknown bugs.
CCS CONCEPTS
‚Ä¢Software and its engineering ‚ÜíSoftware testing and de-
bugging; Software reliability.
KEYWORDS
softwaretesting,deeplearning,differentialtesting,graphequiva-
lence
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthefirstpage.Copyrightsforthird-partycomponentsofthisworkmustbehonored.
For all other uses, contact the owner/author(s).
ICSE ‚Äô22, May 21‚Äì29, 2022, Pittsburgh, PA, USA
¬© 2022 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-9221-1/22/05.
https://doi.org/10.1145/3510003.3510165ACM Reference Format:
JiannanWang,ThibaudLutellier,ShangshuQian,HungVietPham,andLin
Tan.2022.EAGLE:CreatingEquivalentGraphstoTestDeepLearningLi-
braries. In 44th International Conference on Software Engineering (ICSE ‚Äô22),
May 21‚Äì29, 2022, Pittsburgh, PA, USA. ACM, New York, NY, USA, 13 pages.
https://doi.org/10.1145/3510003.3510165
1 INTRODUCTION
Testing DL systems is crucial because an increasing number of
DL systems, e.g., self-driving cars and cancer detection, have been
deployed.BugsinDLsystemscausesevereconsequences;forex-
ample, when a self-driving system incorrectly responds to a traffic
sign, it causes severe personal injury and economic damage [8].
WhenDLsoftwarefailstoimplementamodelfaithfully,e.g.,due
toabuginthesoftware,theoutputfromthesoftwarecanbewrong
even if the model is correct [ 31]. Here DL software includes in-
frastructure code that performs core neural network computations
andapplicationcodethatloadsmodelweights.Thus,inaddition
to testing DL models [ 9,22,26,36‚Äì38,40,46,49], there is a high
demand for testing DL software [14, 28, 29, 31, 42, 43, 45, 47].
Existing techniques such as CRADLE [ 31] and Audee [ 14] test a
pair of DL libraries to cross-check the two implementations of the
same functionality to detect inconsistency bugs. These differential
testingtechniquesrequireatleasttwoimplementationsindiffer-
ent DL libraries, which is often unavailable for DL software. For
example, onecould implementa newDL algorithmin onelibrary,
e.g., TensorFlow [ 1], which does not have a counterpart in another
library (e.g., CNTK [ 33]). Since only one single implementation
exists, existing cross-library testing techniques cannot test it.
In addition, differential testing on two libraries [ 14,31] requires
a high-level library such as Keras [ 4] to switch across DL libraries
such as TensorFlow and CNTK. Such a high-level library is hard
to develop and maintain because it essentially reimplements func-
tionalities that are only available in one library in all other sup-
portedlibraries.ThisisoneofthemainreasonswhyKerasstopped
supporting different DL libraries [ 18]. Without such a high-level
library, it would be prohibitively expensive to cross-check DL li-
braries because one would need to create separate, complex DL
implementationsfor other DL libraries.
To address these challenges, we propose to leverage differential
testinginadifferentdimension:ourtool, EAGLE,uses equivalent
graphstotestasingleDLimplementation.Forexample,theclas-
sificationoutputshouldbeidenticalifaDLimplementationuses
7982022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:18:33 UTC from IEEE Xplore.  Restrictions apply. ICSE ‚Äô22, May 21‚Äì29, 2022, Pittsburgh, PA, USA Jiannan Wang, Thibaud Lutellier, Shangshu Qian, Hung Viet Pham, and Lin Tan
2,
)RUZDUG511WIWUDQVSRVH
WIWUDQVSRVH5HYHUVH511
UHYHUVHWLPHUHYHUVHWLPHWINHUDVOD\HUV
%LGLUHFWLRQDO EDWFKPDMRU *UDSK
a. Correct batch-major graph,
)RUZDUG511 5HYHUVH511
UHYHUVH EDWFKUHYHUVHWLPHWINHUDVOD\HUV
%LGLUHFWLRQDO WLPHPDMRU *UDSK
2¬µ
b. Buggy time-major graph
√èODH@¬≠?DH √ì¬ªDAB@O<OOM ¬üN@GA¬âAJMR<M?¬≠G<T@M¬Ü ¬ÆODH@¬≠H<EJM¬Æ ¬Ü	<GN@¬†@GN@¬º
√èT¬≠M@Q√ì¬âM@Q@MN@ ¬üT¬≠M@Q¬ÜODH@¬≠?DH¬†¬äT¬≠M@Q√ì¬âM@Q@MN@ ¬üT¬≠M@Q¬Ü ¬º¬†
c. Developer‚Äôs Fix
Figure1:Equivalentgraphsthatwedesignedtodetectareal
buginTensorFlow.Redbackgroundindicatesthebuggyline.
ùêº1isthetensorinput. ùëÇ1andùëÇ1/primeareoutputthatisexpected
to be identical. The bug causes ùëÇ1‚â†ùëÇ1/prime.
two different but equivalent Recurrent Neural Networks (RNN) to
performaclassificationtask.Wedefine equivalentgraphs ascom-
putational graphs that achieve the same functionality, which should
produce identical output given the same input. The equivalence is
achieved with different APIs, data types, optimizations, etc.
For example, an optimized way of representing mostly-empty
tensorsofDLmodelsisusingsparsetensors.Onecangeneratetwo
equivalentcomputationgraphs:thefirsttakingadensetensoras
inputandthesecondtakingasparsetensorasinput.Whilethese
twographsmayinvokedifferentAPIfunctions,theyareequivalent,
i.e., they should produce the same output given the same input
represented as a dense tensor in the first graph, or a sparse tensor
inthesecond.WhentheAPIfunctionscontainbugs,theoutputmay
be different. EAGLE detects seven bugs related to sparse tensors in
TensorFlow and PyTorch using equivalent graphs.
1.1 Our Approach
A motivating example: Figure 1 shows a real bug in TensorFlow
2.1detectedbyEAGLEusingtwoequivalentgraphs.Theequiva-
lenceruleusedtogeneratethetwoequivalentgraphsinFigures1a
and 1b is inspired by RNN functions that accept two input formats.
Acommonformatis [batch, time] (calledbatch-major ),whichis
the usual input format developers use. The other format is [time,
batch](calledtime-major ). The time-major format better fits RNN
computations because RNNs compute batches step-by-step, and
similarstepsfromdifferentsequencesarerepresentedcontiguously
in flattened time-major arrays, thus reducing training time. For
example,giventhefollowingtwobatchesofthreewords(i.e.,threetimesteps)[Ilikedogs]and[Ieatapples],theinputcanbefedtothe
RNNinbatch-majorformat(i.e.,/bracketleftbiggùêºùëô ùëñ ùëò ùëí ùëë ùëú ùëî ùë†ùêºùëí ùëé ùë°ùëé ùëù ùëù ùëô ùëí ùë†/bracketrightbigg
)ortime-major
format (i.e.,‚é°‚é¢‚é¢‚é¢‚é¢‚é£ùêºùêº
ùëôùëñùëòùëí ùëíùëéùë°
ùëëùëúùëîùë† ùëéùëùùëùùëôùëíùë†‚é§‚é•‚é•‚é•‚é•‚é¶
). The first matrix is the transpose of
the second matrix. Developers use an argument (e.g., parameter
time_major TrueorFalseinTensorFlow)ofRNNfunctionstospec-
ifyinput‚Äôsformat.Bytransposingthecorrectdimension,onecan
transformatime-majorinputmatrixtoabatch-majorinputmatrix.
Therefore,leveragingthetime-major/batch-majorandtranspose
properties,wecreatetwoequivalentgraphs.ThegraphinFigure1a
firsttransposesthetime-majorinputtensor ùêº1tobatch-major,feeds
it to a batch-major RNN ( tf.keras.layers.Bidirectional in
this example), then transposes the output back to time-major. The
graphinFigure1bdirectlyfeedstheoriginaltime-majorinputto
thetime-majorRNNtoproduceatime-majoroutput.IftheRNN
API implementation is correct, these two equivalent graphs should
generate the same output given the same time-major input.
Figure 1b shows a real bug in the TensorFlow API function
tf.keras.layers.Bidirectional (whichimplementsbidirection-
al RNNs) and how the bug causes an inconsistency: the same func-
tiontf.keras.layers.Bidirectional generatesdifferentoutput
ùëÇ1andùëÇ1/primegiventhesameinput ùêº1(e.g.,atensorrepresentation
of [I like dogs]) on two equivalent graphs. The bug is in red inGraph 2 (Figure 1b) since the function
reverse should be per-
formed on the timedimension instead of the batchdimension.
The bidirectional RNN consists of two independent RNNs: a for-
ward RNN and a reverse RNN. The forward RNN processes the
inputinthenormalorder,andthereverseRNNinthereverseorder
(e.g., ‚ÄúI like dogs" becomes ‚Äúdogs like I"). Since the output of the
reverseRNNisnotinthecorrectorder,itneedstobereversed.The
API‚Äôsbatch-majormode(Figure1a)corr ectlyusesthe reversefunc-
tion on the time dimension, but its time-major mode (Figure 1b)incorrectly reverses the batch dimension instead of the time di-
mension,i.e., reverse(batch) (inred)isincorrectandshouldbe
reverse(time), resulting in incorrect output ùëÇ1/prime.
ItischallengingtodetectthisbugwithoutEAGLEbecausewith-
out Graph 1 in Figure 1a, one may not know ùëÇ1/primein Graph 2 in
Figure 1b is the wrong output for input ùêº1. The reason is that it
is hard to know the expected output ùëÇ1 given input ùêº1 since the
DL calculation (e.g., reverse RNN) is complex [ 31]. Our equivalent
graphapproach addressesthischallenge bycomparingthe output
from two equivalent graphs to identify inconsistencies to detect
software bugs.
Figure1cshowsthefixprovidedbyTensorFlowdevelopers,who
fixed the bug by setting the appropriate dimension to reverse ac-
cording tothe input format, withthe buggy line inred background
and the fixed line in blue background.
Such graph equivalence on time-major and batch-major is gen-
eralasmostDLlibraries,includingTensorFlowandPyTorch,use
such representation. We apply EAGLE to test 13 RNN functions in
TensorFlow and PyTorch and detect that allbidirectional RNNs in
TensorFlow incorrectly implement the time-major functionality.
799
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:18:33 UTC from IEEE Xplore.  Restrictions apply. EAGLE: Creating Equivalent Graphs to Test Deep Learning Libraries ICSE ‚Äô22, May 21‚Äì29, 2022, Pittsburgh, PA, USA
Thismotivatingexample demonstrateshowequivalentgraphs
enablethediscoveryofhard-to-findbugsinDLlibraries.Wepresent
below the main steps of our approach.
Equivalenceruledefinition: Thefirststepistogeneraterulesto
buildequivalentgraphs.Therearetwomaincriteriaforgenerating
theserules.First,therulesshouldbegeneralizabletomultipleAPIs
andDLlibraries.Second,therulesshouldbenon-trivialtodetect
real-worldbugs.Tocoverasmanylibrariesaspossible,wecarefullyinspectAPIdocumentationfromTensorFlowandPyTorchlibraries.
In total, we design a list of 16 new equivalence rules that covers
1,427 APIs of these two DL libraries.
Equivalent graph construction: Once we have a set of equiva-
lencerules,weconcretizethesegeneralabstractrulesintoconcrete
graphs. Specifically, we test a concrete DL function with specific
configurations (e.g., weights) and input. For example, the rule pre-
sentedinFigure1appliestoanyRNNfunction(e.g.,RNN,LSTM,
GRU,andbiLSTM).Thisresultsin10pairsofTensorFlowequiva-
lent graphs, each is tested with 400 sets of (input, configuration).
We follow previous work [ 43] to generate valid input based on
constraints automatically extracted from the API documentation.
Bug detection: We compare the output from a pair of concrete
equivalent graphs to detect inconsistency bugs.
1.2 Contributions
In this paper, we make the following contribution:
‚Ä¢We design 16 new equivalence rules to create equivalent graphs
to test DL libraries. These rules cover six categories of DL graph
equivalence,i.e.,optimization,APIredundancy,datastructure
equivalence, data format equivalence, inverse equivalence, and
model evaluation equivalence.
‚Ä¢We propose a novel idea of using equivalent graphs to detect
bugsandimplementthisideaasanewtestingtechnique‚ÄîEAGLE,
thatgeneratesequivalentgraphsanddetectsbugsinDLlibraries.
‚Ä¢We evaluate EAGLE on five of the latest versions of the most
popular DL libraries (TensorFlow and PyTorch). Using the 16rules, EAGLE generates 6,861 pairs of equivalent graphs and
detects25bugs(18inTensorFlowand7inPyTorch),including
13 previously unknown bugs.
Availability: Data is available in our GitHub repository1.
The rest of the paper is organized as follows. Section 2 presents
thedefinitionofkeyconceptssuchasgraphs,inputs,andconfig-
urations. Section 3 describes the equivalence rules and EAGLE‚Äôsimplementation. Section 4 describes our experimental setup. In
Section5,weevaluateEAGLEontwopopularDLlibraries,describe
some bugs that EAGLE detects, compare EAGLE to state-of-the-art
DL testingtechniques,and present itsexecution time.Sections 6and 7 respectively describe threats to validity and related work.
Finally, Section 8 concludes the paper.
2 DEFINITION AND TERMINOLOGY
Agraphinthispaperrepresentsacomputationalgraphinwhich
the nodes are operations performed on variables.
A set of (input, configuration) is required to compute a graph
and generate an output. The input(ùêº1 in Figure 1) is the object,
1https://github.com/lin-tan/eagleoftenoneorseveraltensors,onwhichthecomputationisdone.We
callconfiguration all the other arguments necessary to perform the
computation(e.g.,weights,numberofneurons,etc.).Forsimplicity,
we only list the input ùêºin the equivalence rules (Table 1), but
the configuration of the two equivalent graphs is assumed to be
identical, except when explicitlydescribedin therule. For example,
for the batch-major/time-major rule presented in Figure 1, the two
graphshaveidenticalconfigurations(weightsandotherarguments),
exceptforthe time_major argument,whichis FalseinGraph1,
andTruein Graph 2. Since it is the only difference, it is the only
configuration explicitly described in Table 1 for this rule.
3 APPROACH
Findingbugs,especiallynon-crashbugs,inDLlibrariesischalleng-
ingbecauseitisdifficulttoknowtheexpectedoutput,giventhat
DL computations are complex. We cannot use the ground truthas the expected output of DL software since DL models are not
100% accurate [ 31]. When a model makes a mistake on input ùêº, the
expectedoutput ùëÇofthesoftwareisdifferentfromthegroundtruth
outputùëÇ0.EAGLEusesdifferentialtestingtoaddressthischallenge
to find non-crash bugs.
Figure2presentstheoverviewofourwork,whichconsistsof
threemainsteps.First,wedefinegeneralizablerulesforcreating
equivalent graphs (Step 1 in Figure 2). Second, for each rule, we
obtain applicable APIs bycheckingDL API‚Äôsdocumentation, and
build pairs of concrete equivalent graphs (Step 2). Finally, we exe-
cute thetwo equivalent graphsby feeding themfuzzed input [ 43]
and compare theiroutput (for example ùëÇ1 andùëÇ1/primein Figure 2)to
detect inconsistency bugs (Step 3).
The rest of the approach section describes the equivalence rules
(Section3.1),theequivalentgraphconstruction(Section3.2),and
the bug detection process (Section 3.3).
3.1 Equivalence Rules
The first step is to create rules to build equivalent graphs. Recall
thatequivalentgraphs arecomputationalgraphsthatachievethe
samefunctionality,whichshouldproduceidenticaloutputgiven
thesameinput.Inpractice,iftheoutputdifferenceisbelowathresh-
oldùë°, we also consider the outputs identical. Such a threshold is
neededbecauseDLcomputationsaremostlyperformedonfloating
numbers, and equivalent floating-point computations often result
in slightly different outputs.
Tocreateequivalencerulesthataremorelikelytofindrealbugs
in DL libraries, we examine the following two sources:
(1) API documentation: The API documentation of neural net-
work functions provides us with information about their imple-
mentation. Sometimes, the description of several APIs providesconnections among these APIs that help us create equivalencerules. For example, by reading the description of the function
tf.keras.layers.DepthwiseConv2D ,wefoundthatthisfunction
could be implemented by multiple invocations of the function
tf.keras.layers.Conv2D , each of which is performed over a sin-
glechanneloftheinputto tf.keras.layers.DepthwiseConv2D .
This implementation using tf.keras.layers.Conv2D is different
fromtheimplementationof tf.keras.layers.DepthwiseConv2D
in TensorFlow. Although tf.keras.layers.DepthwiseConv2D
800
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:18:33 UTC from IEEE Xplore.  Restrictions apply. ICSE ‚Äô22, May 21‚Äì29, 2022, Pittsburgh, PA, USA Jiannan Wang, Thibaud Lutellier, Shangshu Qian, Hung Viet Pham, and Lin Tan
%XJGHWHFWLRQ (TXLYDOHQWJUDSKFRQVWUXFWLRQ (TXLYDOHQFHUXOHGHILQLWLRQ(TXLYDOHQFHUXOHV
), )VSDUVH,
), RSWLPL]HG),$3,GRFXPHQWDWLRQ '/LVVXHVDERXW
QRQFUDVKEXJV5HOHYDQW$3,H[WUDFWLRQ
5HOHYDQW$3,V
&RQFUHWH'/JUDSKJHQHUDWLRQWINHUDVOD\HUV'HQVH
,QSXW
JHQHUDWLRQ(TXLYDOHQWJUDSKH[HFXWLRQ2XWSXWFRPSDULVRQ2 2¬µ
2 'HQVH,
2¬µ 'HQVH,WRBVSDUVH
  
(TXLYDOHQWJUDSKV2  2¬µ
'HQVH, 'HQVH,WRBVSDUVH , ,DWLRQ '/LVVXHVDERXW
QRQFUDVKEXJV
%XJGHWHFWLRQ (TXLYDOHQWJUDSKFRQVWUXFWLRQ (TXLYDOHQFHUXOHGHILQLWLRQ(TXLYDOHQFHUXOHV
), )VSDUVH, 
), RSWLPL]HG),
 2¬µ 'HQVH,WRB
  (TXLYDOHQ
'HQVH,
 'HQVH,WRBVSDUVH
Figure 2: Overview of EAGLE
canbeimplementedusing tf.keras.layers.Conv2D ,TensorFlow
choosesamoreefficientimplementationandcomputesthedepth-
wiseconvolutiondirectlywithoutsplittingitbythechannels.There-
fore, we have two different but equivalent implementations of
tf.keras.layers.DepthwiseConv2D andwecanusethemtobuild
equivalent graphs to detect bugs.
(2) Non-crash bugs in DL libraries: Similar to prior work [ 17],
we study non-crash bugs in DL libraries to summarize common
bugpatternsandequivalencerulesthatcanpotentiallydetectthose
bugs.WefirstmanuallyinvestigateGitHubissuesrelatedtonon-
crash bugs in TensorFlow and PyTorch‚Äôs repositories. Then we
reproducethosebugsandbuildapairofequivalentgraphstodetect
each bug for the particular buggy API described in the issue. We
thenconvertthegraphstoageneralequivalencerulebyabstracting
the inputs, API functions, and configurations (e.g., metrics and
optimizations used).
DesigningEquivalenceRules: Wefirstcreateaconcreteequiva-
lence rule for a specific API for which we read the documentation
or that contains a known bug. Then, we generalize the rule by ab-
stractingtheinputs,APIfunctions,andconfigurations(e.g.,metrics
and optimization used). For example, the concrete rule used for
theAPIfunction tf.keras.layers.Bidirectional inFigure1is
(Bidirectional( ùêº1ùëá,...,return_sequences ,...,batch-major))ùëá
‚â°Bidirectional( ùêº1,...,return_sequences ,...,time-major ),whe-
reùêº1 is an input tensor and ùêº1ùëáis the transpose of ùêº1. This rule
requiresthe time_major argumenttobe False(i.e.,using batch-
major)forthegraphinFigure1aand Truefortheequivalentgraph
in Figure 1b. We generalize the API function Bidirectional to
all relevant API functions ùêπ, generalize input ùêº1 to any input ùêº,
and generalize the configuration return_sequences so that the
parameter return_sequences can be TrueorFalse, while only
Truewasusedinthisconcreterule.Thegeneralizedequivalence
rule is (F(ùêºùëá, batch-major))ùëá‚â°F(ùêº, time-major) . To make
the generalized rules look cleaner, we generalize but omit in the
rule notation all other parameters of the API functions includ-
ingreturn_sequences ,whichispartoftheconfigurationsasex-
plained in Section 2.
Based on our study of DL bugs and API documentation, we
define 16 equivalence rules that can transform a graph into an
equivalent graph. We group these rulesinto 6 categories (Table 1),whereùêºis a general input (often a tensor) and ùêπdenotes an API
function. Function implement(ùêπ ùê¥,ùêπùêµ)is a function that uses
function ùêπùêµto implement the functionality of function ùêπùê¥.ùêπ2ùê∑
andùêπ3ùê∑are API functions that compute 2D and 3D operations
(e.g., tf.keras.layers.Conv2D and tf.keras.layers.Conv3D )
respectively. Function densetransfers input ùêºto a dense tensor,
while Function sparsetransfers input ùêºto a sparse tensor. Func-
tions normalize and denormalize transfer image input ùêºfrom
float representation in range [0,1.0]to integer representation in
range[0,255],andtrasferthefunction ùêπ‚Äôsoutputbackfrominteger
to float. Function castis a type-casting function that converts ùêºto
the expected data type, while ùë°ùë¶ùëùùëíùëãandùë°ùë¶ùëùùëíùëåare two different
data types. Functions decodeandencodeare a pair of functions
thatdecodeanimagefiletoatensororencodeatensortoanimage
file (e.g., tf.io.decode_png and tf.io.encode_png ). Function
paddenotesapaddingfunction,while unpadisafunctionthatre-
verses the padding procedure, (e.g., tf.image.extract_glimpse ).
Finally,ùëÄindicatesapretrainedDLmodel,while evalisthemodel
evaluation procedure.
Below, we first go through a detailed example of one rule, then
describe the other rules.
3.1.1 A Detailed Example: Optimization Equivalence Rule. Tensor-
Flow and PyTorch include several graph compilation optimizationsthat cause a function to be compiled as a callable graph. Compiling
the program into callable graphs enables optimizations such as op-
erationpruningorconstantfolding,whichcansignificantlyreduce
execution time.
Optimization is known to cause many bugs [ 23,41] in other
domains (e.g., compiler optimization [ 20,21,35]). DL optimization
(e.g.,autographtransformation)isalsocomplexanderror-prone.
Forexample,wefoundtwonon-crashbugsrelatedtoTensorFlow
optimization by looking at GitHub issues (GitHub issue 479702).
Function tf.math.floordiv behavesdifferentlywithandwithout
optimization,and so does tf.linalg.eigh.
Basedonthisbugreport,webuildtwoequivalentgraphs(Fig-
ures3)toreproducethebug.Thenwegeneralizetheequivalence
rulebyabstractingtheAPI tf.math.floordiv ,theoptimization
@tf.function ,anditsinputtobuildRule1inTable1.Rule1states
2https://github.com/tensorflow/tensorflow/issues/47970
801
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:18:33 UTC from IEEE Xplore.  Restrictions apply. EAGLE: Creating Equivalent Graphs to Test Deep Learning Libraries ICSE ‚Äô22, May 21‚Äì29, 2022, Pittsburgh, PA, USA
*UDSK *UDSK
WIPDWKIORRUGLY#WIIXQFWLRQ
WIPDWKIORRUGLY,
2,
2¬µ
Figure3:Exampleofpairofconcreteequivalentgraphsgen-
erated from TensorFlow issue 47970.
Table 1: List of rules. ùêπis an API function, ùêºis input, and ùëÄ
is a pretrained model.
IDEquivalence Rule
Optimization
1ùêπ(ùêº)‚â°optimized(ùêπ (ùêº))
API Redundancy
2ùêπ(ùêº, padding=SAME) ‚â°ùêπ(pad(ùêº,SAME))
3implement(ùêπ 2ùê∑,ùêπ3ùê∑)(ùêº)‚â°ùêπ2ùê∑(ùêº)
4implement(depthwise, conv2d)( ùêº)‚â°depthwise( ùêº)
5implement(separable, depthwise)( ùêº)‚â°separable( ùêº)
6implement(dilated, conv2d)( ùêº)‚â°dilated(ùêº)
7implement(ùêπ , document ùêπ)(ùêº)‚â°ùêπ(ùêº)
Data Structure Equivalence
8ùêπ(dense(ùêº))‚â°ùêπ(sparse(ùêº))
Data Format Equivalence
9ùêπ(ùêº)‚â°denormalize(ùêπ (normalize( ùêº)))
10(ùêπ(ùêºùëá, batch-major))ùëá‚â°ùêπ(ùêº, time-major)
11ùêπ(ùêº)‚â°ùêπ(Dataset(ùêº))
12ùêπ(cast(ùêº,ùë°ùë¶ùëùùëíùëã))‚â°ùêπ(cast(ùêº,ùë°ùë¶ùëùùëíùëå))
Inverse Equivalence
13decode(encode( ùêº))‚â°ùêº
14unpad(pad( ùêº))‚â°ùêº
Model Evaluation Equivalence
15eval(ùëÄ,ùêº, batch-size= ùë†1)‚â°eval(ùëÄ,ùêº, batch-size= ùë†2)
16eval(ùëÄ,ùêº)‚â°save(ùëÄ), eval(load( ùëÄ),ùêº)
thatthecomputationofanarbitraryfunction ùêπoninputùêºisequiva-
lenttotheoptimizedversionofthiscomputationonthesameinput.
Using this rule, EAGLE detects ten new bugs, including seven of
them already confirmed or fixed by the developers. (Section 5.1).
3.1.2 Description of All Other Rules. We describe all other equiva-
lence rules that we create category by category.
API Redundancy (Rules 2 to 7): The second category of rules
concernsAPIredundancy,i.e.,generatinganequivalentgraphusing
a different API. We identified several types of API redundancy.Some APIs have built-in functionalities that can be executed ex-
ternally. For example, many DL functions support built-in padding
as an argument. SAMEpadding is a popular padding setting that
producesanoutputofidenticalshapetotheinputwhenthestrideisset to one. Therefore, using the built-in padding argument is equiv-
alent to padding the input using SAMEpadding and then feeding
the padded input to the function without using its padding option
(Rule 2).
Many 2D functions (e.g., tf.keras.layers.Conv2D ) can be im-
plemented using the 3D version of the function by adding a dimen-sionoflengthonetoboththeinputandkernel,settingthestridetoone for this dimension, and removing that dummy dimension from
theoutput.TheselayerscoverdifferentAPIfunctionsbutshould
behave identically (Rule 3).
Rules4to6 areaboutthereimplementationofadvancedconvo-
lutions. There are many variants of advanced convolutions (e.g., di-lated,depthwise,orseparable).DLlibrariesprovidebuilt-inAPIsfortheseadvancedconvolutions,buttheycanbereimplementedusing
other convolutions. For example, TensorFlow‚Äôs DepthwiseConv2D
function can be reimplemented using only Conv2D(Rule 4)b y
splitting the input and filters into ùëãslices (ùëãbeing the number of
channelsoftheinput)andcomputingtheconvolutionforeachslice
of input and filter.
Finally,Rule 7leverages formulas found in API documenta-
tion to reimplement specific functions. For example, TensorFlow‚Äôs
tf.keras.layers.BatchNormalization ‚Äôsdocumentationstates
that ‚Äúthe layer (function) returns ùëîùëéùëöùëöùëé*(ùëèùëéùë°ùëê‚Ñé-ùëöùëíùëéùëõ(ùëèùëéùë°ùëê‚Ñé))/
ùë†ùëûùëüùë°(ùë£ùëéùëü(ùëèùëéùë°ùëê‚Ñé)+ùëíùëùùë†ùëñùëôùëúùëõ)+ùëèùëíùë°ùëé." From this formula, two equiv-
alent graphs can be created. The first one uses the API call to
BatchNormalization , and the second one contains our reimple-
mentationbasedonthedocumentation‚Äôsformula.Wegeneralize
thisexampleto obtainthefollowingequivalence rule:whenafor-
mula isavailable inthe APIdocumentation, usingthe APIshould
beequivalenttousingtheformula.Whiletheformulawilllikelybe
implemented in some way in the API, the function likely contains
additional control flow or conversion to handle exceptions or edge
cases that might introduce inconsistencies.
DataStructureEquivalence(Rules8): ManyAPIstakedifferent
typesofdatastructuresasinput,andthefunctionalityofsuchan
API is identical regardless of the types of data structures used. For
example, DL libraries often use tensors (multi-dimensional data
structures) asinput. Thesetensors can berepresented asdense or
sparse tensors. Sparse tensors are a tensor representation that is
moreefficientwithmostly-emptytensors.DLlibrariesareexpected
to handle both representations either by having an API supporting
bothdenseandsparsetensorsorbyprovidinganequivalentAPI
specificallyforsparsetensors.Therefore,giventhesameinput,any
functiontakingdensetensorsshouldproduceidenticaloutputto
thesamefunction(oritssparseversion)takingasparsetensoras
input, with the only difference being computation time.DataFormatEquivalence(Rules9to11):
Datacanbepresented
to DL APIs in different formats that can become equivalent with a
few transformations.
Forexample,therearetwoprincipalwaystofeedimagestoaDL
network.Inthefirstone,eachpixelisrepresentedasaninteger(e.g.,
between0and255fortheRGBfileformat).Inthesecondone,each
802
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:18:33 UTC from IEEE Xplore.  Restrictions apply. ICSE ‚Äô22, May 21‚Äì29, 2022, Pittsburgh, PA, USA Jiannan Wang, Thibaud Lutellier, Shangshu Qian, Hung Viet Pham, and Lin Tan
pixelisrepresentedasafloating-pointnumber(e.g.,between0.0and
1.0).Onecannormalizevaluesbetween0and255tovaluesbetween
0.0 and1.0, andvice versa. Manydifferent functions aresupposed
to support both types of representation without any casting. Given
thesameinputinthetworepresentations,eithernormalizedornot,
the outputs (one as is and one denormalized) of these functionsshould be equivalent (given a threshold related to floating-pointimprecision). Thus, we create
Rule 9to build equivalent graphs
using these two types of image formats.
In addition to images, text is another common type of input
to DL functions. Textual input can be fed to RNN either in time-
major or batch-major format. Thus, we create the equivalence rule
(Rule 10) described in the Introduction (Figures 1a and 1b). While
these two Figures display two concrete equivalent graphs for a
specificTensorFlowfunction( tf.keras.layers.Bidirectional ),
this rule applies to any API that supports time-major and batch-
major inputs.
DLlibrariesprovideaspecificclasscalled DatasetinPyTorch
andTensorFlowtosupportcomplexinputpipelinesformodeltrain-
ing and evaluation. Input can be applied to DL functions in two
ways: (1) the input ùêºcan be passed to the DL function ùêπdirectly, or
(2)theinput canbetransformedto a Datasetobjectbeforebeing
fedtoùêπ.Transformingtheinputtoa Datasethasseveraladvan-
tages,includingmanybuilt-inAPIsthatcanbeusedtointeractwiththe
Dataset efficiently.Wegenerateanequivalencerule( Rule11)
based on these two ways of applying an input to a DL function.
Finally, DL libraries accept different input data formats that are
oftenequivalentforspecificdataranges.Webuild Rule 12based
onthisobservation.Wecasttheinputtotwodifferentdatatypes,
ùë°ùë¶ùëùùëíùëãandùë°ùë¶ùëùùëíùëå, and then feed them to an API function. The
outputsareexpectedtobethesame,iftheinputiswithintheinter-
sectionof ùë°ùë¶ùëùùëíùëãandùë°ùë¶ùëùùëíùëå‚Äôsranges,unlessdataoverflowsoccur.
For example, if a function accepts both int8andint16integers as
input,any int16inputthatfallswithinthe int8range([-128,127])
shouldproduceanequivalentoutputtoits int8counterpart‚Äôscom-
putation output. One exception is when the int8computation
overflows, e.g., an addition of two int8numbers may not overflow
int16but overflow int8, in which case an exception would be
thrown.
Inverse Equivalence (Rules 13 to 14): Many DL APIs have in-
verse functions. We develop two rules based on two extremely
common DL preprocessing steps that can be inversed: encoding
and padding.
Many types of input (e.g., image, sound, and text) have multiple
encoding types (e.g., gif and png for images). Many of these en-
codingsarebuilt-ininDLlibrariesandshouldthereforebetested
thoroughly. Any input encoded then decoded with the correct loss-
less encoding and decoding algorithms should be equivalent to the
original input (Rule 13).
Paddingiswidelyusedtoenlargethesizeofinput.Wecanunpad
the padded input by extracting a window of the original size from
thepadded input.Theextracted inputshouldbe equivalenttothe
initial input (Rule 14).ModelEvaluationEquivalence(Rules15and16):
Ininference
mode, evaluating the same trained model on the same test datashouldresultinthesameoutput(e.g.,thesamelabelforaninstance
or the same accuracy) independently of the batch sizes (Rule 15).
A model should behave equivalently (in terms of accuracy, loss
function, and weights) before and after being saved and loaded,
independentofhowitwassavedandloaded( Rule16).Bugsinthe
savingandloadingcodecancauseinconsistencies,thusenabling
EAGLE to detect such bugs.
3.2 Equivalent Graph Construction
The equivalence rules presented in Section 3.1 are general and
applicable to many DL API functions. The next step (step 2 in
Figure2)istoconcretizetheserulesintospecificgraphsbyreplacing
abstract elements of the rules (e.g., ùêπandùêº) with concrete APIs,
input, and configurations.
For each rule, we identify a list of relevant APIs for the DL li-
brary under test by referencing its documentation. EAGLE then
concretizes the rules for each applicable API. For example, EAGLE
concretizesRule1toagraphbyreplacing ùêπwiththeTensorFlow
APItf.math.xdivy and ‚Äúoptimized‚Äù with tf.function (Tensor-
Flow‚Äôs graph compilation optimization). It is relatively straight-
forward to extract applicable APIs in the target library by usingheuristics and regular expression matching, and then manually
verify them.
SomerulesapplytomanyAPIs:forexample,Rule1ofEAGLE
generates equivalentgraphs for 960TensorFlowand 435 PyTorch
APIs. Other rules such as Rule 10 are only applicable to certainAPI functions: for example, PyTorch‚Äôs documentation lists three
mainRNNfunctionsthatcanbetestedwithRule10( torch.nn.RNN ,
torch.nn.LSTM ,and torch.nn.GRU ).WhiletestingonlythreeAPIs
might not seem general, these high-level APIs support multiple
configurationsthatwilltestdifferentunderlyingAPIs.Forexample,under some configurations, the
torch.nn.GRU function might also
callthe DropoutorBidirectional functions.Obtainingapplicable
APIs is a one-time cost, and it is fast using heuristics.
3.3 Bug Detection
Thefinalstep(step3inFigure2)istogenerateinput,e.g.,tocon-
cretizeùêºinRule1,andcomparetheoutputoftheconcretizedgraphs
given the same input. We use existing work D2C [ 43] to gener-
ateinputautomatically.Forexample,EAGLEfurtherconcretizesthe
ùêºof Rule 1 for API tf.math.xdivy(x,y) to[-3.e+38+0.j,
2.e+37-2.e+38j] (Figure 4). We then compare the output of each
pairofconcreteequivalentgraphs,giventhesameinput.Tomit-igate the impact of non-determinism of DL computation, we use
thesamerandomseedforthetwoequivalentgraphs‚Äôexecutions
and report all inconsistent output above a threshold.
With the concrete function and input, EAGLE detects a pre-
viously unknown bug in TensorFlow 2.5 and 2.6 that developers
confirmed (Figure 4 in Section 5.2).
The main contribution of EAGLE is equivalence rules, which
can be used together with any other test generation approach. Sec-
tion 5.3 shows that 20 bugs that EAGLE detects cannot be detected
bythechosentestgenerationtechnique(i.e.,D2C)withoutequiv-
alentgraphs.Sinceourgoalistodetecthard-to-detectnon-crash
bugs (due to the oracle challenge [ 3]) by detecting inconsistent
behaviors (as opposed to, for example, crashes due to mishandling
803
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:18:33 UTC from IEEE Xplore.  Restrictions apply. EAGLE: Creating Equivalent Graphs to Test Deep Learning Libraries ICSE ‚Äô22, May 21‚Äì29, 2022, Pittsburgh, PA, USA
of invalid input), we need a technique that is capable of generating
valid input for DL API functions.
Instead of manually writing input constraints, which is com-
monly used in testing [ 10,27], we leverage D2C that analyzes rele-
vant API documentation to extract input constraints, and uses the
constraintstoguidethegenerationofinput.Forexample,giventhe
APIdocumentsentencefor tf.math.xdivy(x,y) ‚Äî‚ÄúATensor.Must
beoneofthefollowingtypes: half,float32,float64,complex64 ,
orcomplex128 ‚Äù, it randomly generates a tensor whose elements
are of type half,float32,float64,complex64 ,o rcomplex128 .
D2Cextractsfourcategoriesofconstraints: structuresuchaslist,tu-
ple, and n-dimensional array (i.e., tensor), typesuch as int,float,
boolean,and String,shapesuchastwo-dimensional(2-D)array,
andvalid value such as parameter padding can only be one of
‚Äúzeros‚Äù, ‚Äúborder‚Äù, and ‚Äúreflection‚Äù.
D2Cuses sequentialpatternmining [13,15]tominefrequently
occurringpatterns(e.g.,‚ÄúMustbeoneofthefollowingtypes‚Äù)in
API documents and transforms them into rules (e.g., ‚ÄúMust be one
ofthefollowingtypes <type1>,<type2>‚Äù)toextractinputcon-
straints automatically. The precision and recall is 94.4% and 92.4%
forTensorFlowand95.6%and93.5%forPyTorch.Wethenmanually
verify the extracted constraints and add any missing ones.
For test generation, given an API function and its extracted
constraints,thetechniqueaimstogeneratevalidinputfollowing
the extracted constraints. Specifically, it chooses a typefrom the
list oftypesin the constraints and creates a shapefollowing the
constraints. If the constraints do not specify a list of valid types,
the test generation selects one from typessupported by the library.
Finally, the structure constraints are checked. For example, if the
generated value is 1-dimensional and the constraints explicitly
specifythe structure(e.g.,tupleorlist),theinputgeneratorconverts
the generated value accordingly.
Wefinallyexecuteallinputsandreportinconsistenciesbetween
equivalent graphs.
4 EXPERIMENTAL SETUP
In total, we investigate 1,542 issues in TensorFlow and PyTorch.
For TensorFlow, we focus on issues in TensorFlow 2.X only. Forboth PyTorch and TensorFlow, we use the GitHub search enginefor closed issues labeled as ‚Äúbug‚Äù with the keywords ‚Äúfix.‚Äù Then
wemanuallycheckalltheissuestofilteroutcrash-relatedissues.
Out of these 1,542 issues, 35 are relevant non-crash bugs, from
which we create and generalize rules. Many GitHub issues are
not relevant because (1) they are not bugs, e.g., user mistakes or
feature requests, and (2) many issues describe crash bugs. In total,
we extract 16 equivalence rules.
For rules 1-14, we use D2C to generate inputs. We generate
up to 400 inputs per API. We use D2C to generate inputs for 963
TensorFlow APIs and 464 PyTorch APIs. For rule 15 and rule 16,
we save 18 TensorFlow Keras pretrained models and 12 PyTorch
pretrainedmodelsfortesting.Fortheinput,weextract1,000images
fromtheImageNetdatasetandpreprocessthemaccordingtothe
models.
After we generate inputs, we define a list of applicable APIs for
each rule by referencing the API documents. EAGLE uses theserules to generate equivalent graphs for each applicable API and
uses the inputs generated to compute the results.
WeconsulttheinconsistencythresholdformulathatTensorFlow
andPyTorchuseintheirtestsuitetodeterminewhetherthetwo
outputsfromtwoequivalentgraphsareequivalent.Forexample,
fortheequivalentgraphs ùê∫1andùê∫2withrespectiveoutputs ùëÇ1and
ùëÇ1/prime(giveninput ùêº1),theirresultsareequivalentif ùëéùëèùë†(ùëÇ1,ùëÇ1/prime)<=
ùëéùë°ùëúùëô+ùëüùë°ùëúùëô‚àóùëéùëèùë†(ùëÇ1/prime), withùëéùë°ùëúùëô=10‚àí2andùëüùë°ùëúùëô=10‚àí5.
WeevaluateEAGLEonTensorFlow2.1,2.2,and2.3andPyTorch
1.6and1.9sincetheywerethelatestversionsavailablewhenwe
startedthisproject.Weonlyreportabugtodevelopersifwecan
reproducethebugonthelatestversionofTensorFlowandPyTorch
(TensorFlow 2.6 and PyTorch 1.9) at the time of writing.
We obtain the total number of bugs by considering all inconsis-
tencies for each rule and API pair as one bug. For example, in Rule
16, if five different models display inconsistencies to load with one
API (e.g., load_state_dict), we only count it as one unique bug.
5 EVALUATION AND RESULTS
This section presents the results of our five Research Questions
(RQs).RQ1(Section5.1)presentsthenumberofbugsEAGLEdetects.
RQ2(Section5.2)describessomeofthebugsforeachcategory.RQ3
(Section 5.3) compares EAGLE to other DL testing approaches, and
RQ4(Section5.4)exploreshowdevelopersuseequivalentgraphs.
Finally, RQ5 (Section 5.5) studies EAGLE‚Äôs execution time.
5.1 RQ1: How many bugs does EAGLE detect?
Weimplement16rulestotestthetwomostpopularDLlibraries,
TensorFlowandPyTorch,resultingin6,861pairsofconcreteequiv-
alent graphs. We use previous work [ 43] to generate up to 400
sets of (input, configurations) per pair of equivalent graphs. Aset of (input, configuration) consists of input to an API and itsconfiguration (weights, etc.). For example, when testing the API
tf.keras.layers.Dense , the input is a Tensor, and the config-
urations include weights, kernel initializer, and bias regularizer.For each set of input and configuration values, we compare the
corresponding equivalent graphs.
Table2displaysthenumberofbugsfoundinTensorFlowand
PyTorch.Overall,EAGLEgenerates6,861pairsofequivalentgraphs
and detects 1,212 inconsistencies automatically. Multiple inconsis-
tencies that are triggered by the same API function (with different
inputs)arecountedasonebug.Asaresult,theseinconsistenciesmapto25bugs,including13previouslyunknownbugs(Table2).
Most(9)ofthesepreviouslyunknownbugshavebeenconfirmed
or fixed by TensorFlow or PyTorch developers. EAGLE also detects
crashes for 42 APIs, among which we have only manually verified
fivesinceourfocusisonnon-crashbugs,whichexistingtechniques
have a hard time detecting.
Table2alsoshowsthenumberofbugsfoundineachrulecate-
gory. For example, Optimization is the category for which EAGLE
finds the most number of bugs, with a total of ten bugs found. All
those ten bugs are previously unknown bugs, seven of which have
been confirmed or fixed by the developers. Section 5.2 describes
examples of bugs found by EAGLE.
804
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:18:33 UTC from IEEE Xplore.  Restrictions apply. ICSE ‚Äô22, May 21‚Äì29, 2022, Pittsburgh, PA, USA Jiannan Wang, Thibaud Lutellier, Shangshu Qian, Hung Viet Pham, and Lin Tan
Table 2: Bugs found by each rule category.
Category TensorFlow PyTorch Sum
Optimization 10 0 10
API Redundancy 00 0
Data Structure Equivalence 34 7
Data Format Equivalence 13 4
Inverse Equivalence 20 2
Model Evaluation Equivalence 20 2
Total 18 7 25
, ^QSDUUD\>HM@GW\SH 
FRPSOH[

HHM`
*UDSK *UDSK
2 7HQVRU> M@ 2¬µ 7HQVRU> M@,QFRQVLVWHQF\UHYHDOLQJLQSXW
2XWSXW 2XWSXWWIPDWK[GLY\#WIIXQFWLRQ
WIPDWK[GLY\
Figure 4: Two equivalent graphs that detect a new inconsis-
tency bug in TensorFlow, which has been confirmed by de-
velopers after we reported it.
Summary : EAGLE detects 25 bugs in the most widely-used
DLlibrariesTensorFlowandPyTorch,including13previously
unknownbugs,nine ofwhichhavealreadybeenconfirmed or
fixed after we report them.
5.2 RQ2: What bugs are detected by EAGLE?
We describe non-crash bug examples in each category of rules.
Optimization: EAGLEdetectstenbugsthatarerevealedbyincon-
sistenciesbetweenastandardgraphandanoptimizedgraph.Allof
these bugs are previously unknown bugs for which optimized Ten-
sorFlow APIfunctions generate incorrectoutputs. Figure 4shows
an example of a new bug in the tf.math.xdivy API detected by
EAGLE that TensorFlow developers confirmed after we reported it.
Theannotation @tf.function onGraph2tellsTensorFlowthatthe
function below should be optimized. According to TensorFlow de-
velopers,thisbugiscausedbyanoverflowfor complex64 divisions
in the optimization.
Data Structure Equivalence: With the rules of data structure
equivalence, EAGLE detects three bugs in TensorFlow and four
bugs in PyTorch. Figure 5 displays two equivalent graphs that EA-
GLE generated, which revealed a bug in PyTorch. API functions
torch.addmm andtorch.sspaddmm performthesamecomputation
fordenseandsparsetensors,respectively.Giventhreeinputten-
sors,ùëá1,ùëá2, andùëá3, these functions multiply ùëá2 andùëá3, then add
ùëá1 to the result. The bug was deep in the C++ backend code of
torch.sspaddmm inalow-levelfunction( indices.data_ptr )that, ^7 WRUFKWHQVRU>>@>@@
7 WRUFKWHQVRU>>@>@@
7 WRUFKWHQVRU>>@>@@`
*UDSK
2 WRUFKWHQVRU>> @> @@ 2¬µ WRUFKWHQVRU>> @> @@,QFRQVLVWHQF\UHYHDOLQJLQSXW
2XWSXW 2XWSXWWRUFKDGGPP7WRBVSDUVH
WRUFKVVSDGGPP
WRBGHQVH7WRBVSDUVH
7WRBVSDUVH*UDSK
Figure 5: Pair of equivalent graphs that detects an inconsis-
tency bug in PyTorch.
assumesrow-contiguousstorageoftensors,while torch.sspaddmm
used another type of storage. The APIs under test ( torch.addmm
andtorch.sspaddmm )donothaveadirectcounterpartinTensor-
Flow,soitwouldbeverydifficulttofindthisbugusingcross-library
differential testing techniques such as CRADLE or Audee.
Data Format Equivalence: EAGLE detects four bugs in this cate-
gory,includingthebuginFigure1.Theotherthreebugsareincon-
sistencybugsinthreedifferentPyTorchAPIs.In torch.fmod and
torch.remainder ,thereisalargeinconsistencybetweenequiva-
lentint64andfloat64 input while the cosine_similarity API
hasinconsistenciesbetween int8andint16.Thesearebugsinthe
C++ low-level tensor library (ATen) used by PyTorch.Inverse Equivalence:
EAGLE detects two bugs in this category,
includingone newbug relatedto the tf.io.decode_gif API. Gif
encodingissupposedtobelossless,butwefoundthatinTensor-
Flow,forspecificinputs,thisencodingisnotlossless,i.e.,encoding
and then decoding an input instance can result in significantly dif-
ferentoutputs.Theconsequenceofthisbugisseverebecauseimage
preprocessingisanessentialpartofmanyDLsystems,andanybugin thatpreprocessingmay modifythe inputto theDL modelsin anunexpectedwaythatmayleadtoincorrectoutput,whichwouldbe
hard to debug.
ModelEvaluationEquivalence: EAGLEdetectstwobugsinthis
category. Those two bugs are inconsistency bugs in model configu-
rations or metrics. For example, Rule 16 enables EAGLE to detect a
buginTensorFlowAPI tf.keras.Sequential.from_config .Ten-
sorFlowAPIs get_config andfrom_config extractamodel‚Äôscon-
figurationandbuildamodelobjectfromsuchaconfigurationre-
spectively. Combined with get_weights andset_weights , they
canachievethefunctionalityofsavingandloadingamodel.Saving
themodelusing get_config andget_weights andloadingitusing
from_config andset_weights cause the model‚Äôs configuration
to be incorrect, which leads to the detected inconsistencies.
805
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:18:33 UTC from IEEE Xplore.  Restrictions apply. EAGLE: Creating Equivalent Graphs to Test Deep Learning Libraries ICSE ‚Äô22, May 21‚Äì29, 2022, Pittsburgh, PA, USA
APIRedundancy: EAGLEfindsnobugsusingtheAPIredundancy
rules.AfterinvestigatingbothTensorFlowandPyTorchlibraries,we
findapossiblereasonisthatdevelopersalreadyimplementedsome
rulesfromthiscategoryintheirtestsuiteafterfindingabugina
previousversion.Forexample,aconcretepairofequivalentgraphs
thatEAGLEgeneratesfor Rule 7withthe BatchNormalization
APIisincludedintheTensorFlowtestsuite.Similarly,wealsofound
reimplementations of depthwise convolutions using Conv2Din the
TensorFlow test suite ( Rule 4). This demonstrates that developers
arealreadyusingsomeequivalencerulestotesttheirlibrariesas
an afterthought of relevant bugs. A comprehensive set of rules and
atechniquethatusestherulestogenerateequivalentgraphsand
detects bugs would be beneficial for them to improve their testing
system further.
False Positives: Out of all 26 inconsistent APIs detected by EA-
GLE, we found one false positive (the other 25 are true bugs). This
false positive is revealed by Rule 16 in PyTorch. When testing
Rule 16 in PyTorch, we evaluate the pretrained model InceptionV3
before saving its internal states and after reloading them using
load_state_dict . InceptionV3‚Äôs input needs to be normalized
and the normalization process is included along with the model
architecture.Whenthepretrainedweightsareused,PyTorchnot
onlyloadstheweightsbutalsoconfiguresthemodelarchitecture
byaddingtheinputnormalizationprocessaccordingly.However,
the input normalization is not configured correctly after model
saving and loading, which leads to the inconsistencies.GeneralizabilityoftheRules:
All 16 rules apply to both Tensor-
Flow and PyTorch, and Rule 8 finds bugs in both libraries. While a
single rulecanfind bugsin bothTensorFlowandPyTorch,it does
not mean that these bugs can be found by cross-library differential
testing techniques [ 14,31], because when the rules are concretized
toconcretegraphs,theconcreteAPIsoftenonlyexistinonelibrary.
For example, Rule 8 finds bugs in both TensorFlow and PyTorch,
buttheAPIinwhichsomeofthebugsoccur( torch.sspaddm )only
exists in PyTorch.
Intotal,wegenerate6,861pairsofconcreteequivalentgraphs
(429pairsofgraphsperruleonaverage)thatareeachtestedon400
sets of (input, configuration). The largest number of APIs covered
byauniqueruleis963and464forTensorFlowandPyTorch,respec-
tively.Overall,the25bugsdetectedbyEAGLEoccurinverydiverse
APIs, from DL layers ( tf.keras.layers.Bidirectional ), low-
level computation libraries ( torch.smm ), utility APIs
(tf.keras.Sequential.from_config ), optimization
(@tf.function), or data preprocessing (tf.image.decode_gif).
Summary : The 25 bugs detected by EAGLE in TensorFlow and
PyTorch are in a very diverse set of DL APIs, including prepro-
cessing, DL layers, low-level APIs, and utility functions, demon-
strating the diversity and generality of our rules.
5.3 RQ3: Does EAGLE detect bugs not detected
by other DL library testing techniques?
We compare EAGLE with two types of techniques that test DL
libraries to better understand EAGLE‚Äôs contribution. First, we com-
pare EAGLE with a state-of-the-art fuzzing technique, D2C [ 43].Second,wecomparewithtwostate-of-the-artdifferentialtesting
techniques for DL libraries, CRADLE [31] and Audee [14].
Comparison with D2C [43] We ran D2C on the same PyTorch
andTensorFlowversionsonwhichweevaluatedEAGLE.Although
EAGLE uses D2C‚Äôs input generation, only five of the bugs detected
by EAGLE are also detected by D2C. D2C cannot detect any of the
other bugs because it focuses on crash bugs, while the majority (20
out of 25) of the bugs found by EAGLE are non-crash bugs.
ComparisonwithCRADLE[31]andAudee[14] CRADLEand
Audee are DL testing approaches that rely on Keras‚Äô high-level
APIto performdifferentialtesting acrosslibraries.Audee alsohas
non-differential testing checkers, but since they do not detect in-
consistencies,we focuson thedifferential testingaspect ofAudee
for this RQ).
Differential testing techniques such as CRADLE and Audee can-
notdetectbugsthatEAGLEdetectsforthefollowingreasons.Keras
isahigh-levellibrarythatallowsuserstobuildDLmodelsinaback-
end library-independent manner, i.e., one can seamlessly switch
thebackendDLlibrary.Kerasmodelscanthenbeexecutedwith-
out reimplementation using different DL backends (TensorFlow,
Theano,andCNTK).Todothat,allbackendsmusteitherimplement
thesamefunctionalities,orKerasmustimplementmissingfeatures
of backends.
With theexplosionof DL in thelast few years, DLlibraries are
growing fast, and many new types of DL functions are proposed
thatarenotimplementedinalllibraries,makingitextremelyhardto
maintain cross-backend execution in Keras (since functions unique
toaDLlibrarymustbereimplementedforalllibraries).Inaddition,
new DL libraries have grown to be very popular (e.g., PyTorch and
HuggingFace‚ÄôsTransformer)thatarenotsupportedbyKeras,while
libraries (Theano and CNTK) supported by Keras are no longer
maintained.Asaresult,maintainingcross-backendsupportinKeras
became unmanageable, and Keras dropped this feature in 2019,
making it challenging to run differential testing techniques such as
CRADLE or Audee. Reimplementing such a high-level library to
allowdifferentialtestingwouldbeextremelyexpensiveandtedious.
EAGLEaddressesthischallengebyrequiringonlyoneDLlibrary
to detect bugs.
It is possible to perform differential testing only on functionali-
ties thatare implementedidentically inboth libraries(e.g., Dense
layer and Conv2D). However, doing so would miss many bugs, i.e.,
15ofthe25bugs(60%)thatEAGLEdetects.Forexample,thebug
displayed in Figure 5 occurs in a PyTorch API that does not have a
direct counterpart in TensorFlow.
In addition, even if we have a high-level library that supports
cross-backendexecution,CRADLEandAudeemightstillnotfind
the remaining ten bugs that EAGLE detects because they focus on
complete system testing (i.e., they take a full DL model as input
andmeasureinconsistenciesinaccuracy).Incontrast,EAGLEfo-
cuses on single low-level API testing (unit testing) to find bugsburied deep in a DL library. For example, while all the inconsis-tencies reported by Audee concern incorrectly implemented DLlayers (
ThresholdedReLU ,DepthwiseConv2D ,SeparableConv2D ,
and padding implementation), EAGLE finds bugs in very low-level
functionalitiessuch as ATen, the low-level tensor library used by
PyTorch(Section5.2).CRADLEandAudeemightmissthesebugs
806
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:18:33 UTC from IEEE Xplore.  Restrictions apply. ICSE ‚Äô22, May 21‚Äì29, 2022, Pittsburgh, PA, USA Jiannan Wang, Thibaud Lutellier, Shangshu Qian, Hung Viet Pham, and Lin Tan
because they only produce inconsistencies at a system level for
specific models and input.
Theequivalencerulesareorthogonalcontributions,whichcan
be combined with CRADLE or Audee to help them generate more
DLmodelstotestmoreDLlibrarycode.Forexample,CRADLEand
Audee may use our Rule 1 to test optimization code cross libraries
if a high-level library such as Keras is revamped.
Summary :Themajority(20)ofthe25bugsdetectedbyEAGLE
arenon-crashbugs,whoserelevantAPIshavelittlecross-library
redundancy.Thus,itwouldbedifficultforexistingtestingap-
proaches to detect these bugs.
5.4 RQ4: Do DL library developers use
equivalent graphs?
InthisRQ,weinvestigateifourrulesarenewbystudyingifandhow
developershavebeenusingequivalentgraphstotestDLlibraries.
We manually examine TensorFlow and PyTorch‚Äôs test suites and
checkifanytestcasesimplement(orpartiallyimplement)ourrules.
Most (15 of the 16) rules are not implemented or not fully im-
plementedinPyTorchtestcases:13rulesarenotimplementedat
all, whiletwo rules(1 and 16)are implemented onlyfor a few APIs.
Only Rule 8 is implemented for all the APIs tested by EAGLE.
The majority (13 out of 16 rules) are not implemented or not
fully implemented in TensorFlow test cases: nine rules are not
implementedatall,fourrules(1,8,15,and16)areimplementedfor
only a few APIs, and only three rules (4, 6, and 7) are implemented
for all the APIs tested by EAGLE for that rule. Such test cases were
createdlikelyasanafterthoughtafterabugwasfound.Forexample,
after findinga bug in torch.sspaddmm from GitHubissue 451133,
developers implemented a test case to test torch.sspaddmm and
its dense version torch.addmm in PyTorch 1.7.
Thefactthatdevelopersuseequivalentgraphstomakesurea
bugisfixedshowsthatsuchgraphsareusefultotestDLlibraries.
However, equivalent graphs have not been implemented proac-
tivelytocreatetestcases(i.e.,tofindbugs).EAGLEoffersamore
complete list of equivalence rules to generate equivalent graphs
that developers have not manually implemented and can therefore
improve the reliability of DL libraries.
Summary :Most(13outof16)rulesarenotimplementedinDL
libraries‚Äô test suites. The few test cases that implement equiva-
lentgraphswereonlyimplementedasanafterthoughtaftera
bughasbeenreported.ThisindicatesthatEAGLEcomplements
developers‚Äôtestcasesandcandetectbugsthatwouldbehard
to find manually.
5.5 RQ5: What is the run time of EAGLE?
Table 3 shows EAGLE‚Äôs execution time. On average, it takes 33
minutes to execute a pair of equivalent graphs with a set of 400
(input, configuration) in TensorFlow and 26 minutes in PyTorch. In
total,EAGLEexecutes6,861pairsofequivalentgraphs.Itiseasyto
executegraphsinparallel.Forexample,onourXeonGold5120R
CPUs (56 cores in total) and 512 GB of memory server, we execute
24 graphs at a time.
3https://github.com/pytorch/pytorch/issues/45113Table 3: Execution Time of EAGLE
TensorFlow PyTorch
# of pairs of concrete graphs 5,817 1,044
# of (input, config) per graph 400 400
Time per pair (minutes) 33 26
6 THREATS TO VALIDITY
EAGLEdoesnotfindallbugs: Sincewefocusondetectingincon-
sistenciesbetweenequivalentgraphs,EAGLEmightmissbugsthatdonotcauseinconsistentoutputs.Forexample,ifarulegeneratesapairofequivalentgraphsthatusetworedundantAPIsthatcontain
thesamebug,EAGLEwillnotdetecttheinconsistency.However,
EAGLEiseffectiveindetecting25bugsinTensorFlowandPyTorch
automatically.
Manualruleconstruction: Therulestogenerateequivalentgraphs
have been manually designed. As a result, they might not be fully
representative of real bugs in DL systems. To mitigate this issue,
welookatexistingbugreportsintwopopularDLlibraries(Tensor-
FlowandPyTorch)whendesigningourrules.Ourresultsshowthat
the rules designed for EAGLE find 13 previously unknown bugs,
showing that they can be used to detect new real-world bugs.GenerabilitytodifferentDLlibraries:
Ourapproachmightnot
begeneralizabletootherDLlibraries.Tomitigatethisthreat,we
evaluate EAGLE on the two most popular DL libraries, Tensor-
Flow and PyTorch. EAGLE finds bugs in both libraries. In the fu-
ture, we could further extend EAGLE to test different libraries (e.g.,
DeepLearning4J) to show EAGLE‚Äôs generalizability.
Potential bugs in our implementation: Our implementations
mightbebuggy.Ifthatisthecasewewilleither(1)incorrectlydetect
inconsistencies or (2) not detect the inconsistency. We mitigate
(1) by manually looking at the inconsistencies we detect before
consideringthemasbugs.NoneoftheinconsistenciesEAGLEfinds
aretheresultofabuginourcode.Inaddition,developersconfirmednineofthe13newbugsEAGLEdetects.For(2),ourapproachmight
not detect some bugs because of issues in our implementation.However, this can only hurt our results and therefore does notimpact the validity of our findings. If bugs in our code cause us
tomissinconsistencies,ourtechniquemightperformevenbetter
once we fix them.
Nondeterminism: Not all inconsistencies are bugs because DL
APIs can be nondeterministic [ 32]. We address nondeterminism by
fixing the random seed to make API testingreproducible. We also
use a threshold used by popular DL libraries to take into considera-
tion floating-point precision inconsistencies. Overall, all but one
inconsistenciesthat EAGLE detects are the result of true bugs.
7 RELATED WORK
DL library testing suffers from the oracle problem. Specifically,
DL API functionalities are very complex, and it is often hard to
knoworevenapproximatetheexpectedoutputmanually.Previous
work [28,48] shows that such oracle approximations are often
usedinDLlibrariesbutareerror-prone,resultinginflakytestsor
requiring a manual update from the developers.
807
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:18:33 UTC from IEEE Xplore.  Restrictions apply. EAGLE: Creating Equivalent Graphs to Test Deep Learning Libraries ICSE ‚Äô22, May 21‚Äì29, 2022, Pittsburgh, PA, USA
Fuzzing and differential testing can be used to mitigate the ora-
cleproblem.Fuzzing oftenonlydetectscrashes,whiledifferential
testinggenerallyrequirestwodifferentlibrariesthatimplementthe
same functionality, which is difficult to achieve and error-prone.
Ourworkisdifferentsinceweleveragewithinlibraryequivalences
suchasAPIredundancyoroptimizationtobuildequivalentgraphs
todetectnon-crash bugs.Sincethegraphs EAGLEusesare equiv-
alent, they both have the same expected output, addressing theoracle problem. To the best of our knowledge, we are the first to
proposeequivalentgraphsandtousethemtofind25bugsinDL
libraries.
DifferentialtestingofDLlibraries: Previouswork[ 6,14,28,31,
34,39,42] uses differential testing to find inconsistencies between
DLlibraries.SuchinconsistenciesareoftentheresultofabuginDL
libraries.Forexample,CRADLE[ 31]findsbugsinKerasbyrunning
thesame modelwithdifferent DLbackends(TensorFlow,Theano,
and CNTK).
These approaches require either (1) a high-level library that
supportsseveralDLbackends(e.g.,Keras),(2)agoodmodelcon-
verter (e.g., MMdnn), or (3) heavy engineering to reimplement the
sameDLcomputationindifferentDLlibraries.Unfortunately,while
Kerasinitiallysupportedseveralbackendsandwasusedinprevi-
ous studies [ 14,28,31,42], Keras now only supports TensorFlow.
MMdnn[24]orONNX[ 2]areframeworksthatallowtransferring
models across DL libraries, but MMdnn only supports a few popu-
lar layers (e.g., RNN layers are not supported), and PyTorch, oneof the most popular DL libraries, cannot execute ONNX models.
Therefore,theonlysolutionforthoroughdifferentialtestingacross
DL libraries is to reimplement the DL computation in different
frameworks, which is time-consuming and error-prone. For exam-
ple, previous work [ 34] only reimplemented two ML algorithms
(K-NearestNeighboursandNaiveBayes)whenusingdifferential
testing on Weka, Rapid Miner, and KNIME.
In contrast, EAGLE uses equivalent graphs to find bugs in DL
APIs,whichisnotlimitedbythird-partylibraries(converterorhigh-
level API support). For example, EAGLE detects a bug in biRNN
layersofTensorFlow,whichwouldnothavebeenfoundbydifferen-
tial testing using MMdnn or Keras since MMdnn does not support
biRNNlayersandKerasdoesnotsupportmultiplebackendsany-
more.
FuzzingDLlibraries: Fuzzingisanotherpopularapproachtotest
DL networks. Classic fuzzing techniques [ 11,25,30] can be used
to find some crash bugs, but more advanced fuzzing techniques
targetting DL systems have been proposed [ 29,43,45,47]. We use
theapproachdevelopedbyXieetal.[ 43]togeneratevalidinputsfor
ourapproach;however,thesefuzzingapproachesstillsufferfrom
theoracleproblemandcanonlyfindcrashbugs(seeSection5.3).
Forexample,previouswork[ 43]couldonlyfindfiveofthe25bugs
detected by EAGLE; hence our approach complements existing
fuzzing techniques.
Some of ProbFuzz‚Äôs [ 6] checkers use differential testing and can
detect non-crash bugs in probabilistic systems. They use across
library differential testing or several implementations of the sameAPI in different languages (e.g., Py-Stan and R-Stan). Similar to
other differential testing techniques, ProbFuzz requires multiple
libraries implementing the same functionality and has some scope
limitations (e.g., ProbFuzz does not support loops) that make it
difficult to apply to DL libraries. EAGLE tests DL APIs generally
and aims at finding general bugs that ProbFuzz does not cover.
Other work testing DL libraries: Static analysis has been used
to detect specific types of bugs (e.g., shape-related bugs) in DL sys-
tems[19].EAGLEfindsverydiversebugsinDLsystems(Section5.2)
that are hard to find without equivalent graphs. Metamorphic test-
ing has also been used to test and validate ML classifiers [ 5,7,44].
These approaches have only found injected bugs in ML systems,
andpreviousworkshowsthatinjectedbugsoftenonlyhaveaweak
correlation with real bugs [12].Equivalent graph generation:
TASO [16] automatically gener-
atesgraphsubstitutionstooptimizeagivendeepneuralnetwork
computation graph. It generates equivalent graph substitutions
basedonagivenarchitectureandfindstheonewiththeleastin-ference time among all the substitutions. While TASO generates
equivalentgraphs,itdoesnotusethemtofindbugs;instead,ituses
equivalent graphs to optimize DL computations. Most of the TASO
equivalencerulesaremathematicalequivalencerulessuchasfor
anytensors ùê¥,ùêµ,andùê∂ofconcreteshape, (ùê¥‚äóùêµ)‚äóùê∂=ùê¥‚äó(ùêµ‚äóùê∂),
where‚äódenotesmatrixmultiplication.Weimplementedeightof
the TASO rules and none detected any bugs. We focus on building
rules that are inspired by real bugs and API documentation. All
oftherulesthatwedesignforEAGLEarenew,differentfromthe
ones in TASO.
Differentialtestingforcompilers: Differential testing has been
usedfortestingcompilers[ 20,21,35].Insteadofequivalentgraphs,
theseworkgenerate equivalentprogramsmoduloinput (EMI).The
keyinEMIistocreateacollectionofcorrectprogramsthathavethesameoutputgiventhesameinput(butmighthavedifferentoutputs
forother inputs.Ourwork isdifferentsince programcompilation
is a different problem than DL graph execution which presents its
own challenges.
8 CONCLUSION
We propose and evaluate EAGLE, a new differential testing ap-
proachthatusesequivalentgraphstotestasingleDLlibrary.We
design16newequivalencerulesthatcangeneratepairsofequiv-
alent graphs. We evaluate EAGLE on the two most popular DL
libraries,TensorFlowandPyTorch,andfound25bugs,13ofthem
are previously unknown bugs, and nine have already been con-
firmedorfixedbydevelopers.Inthefuture,theruleswedescribe
couldbecombinedtodetectbugsinmorecomplexAPIinteractions
within DL libraries.
ACKNOWLEDGEMENT
Theauthorsthanktheanonymousreviewersfortheirinvaluable
feedback. The research is partially supported by NSF 2006688, a
J.P.MorganAIFacultyResearchAward,andaFacebookResearch
Award.
808
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:18:33 UTC from IEEE Xplore.  Restrictions apply. ICSE ‚Äô22, May 21‚Äì29, 2022, Pittsburgh, PA, USA Jiannan Wang, Thibaud Lutellier, Shangshu Qian, Hung Viet Pham, and Lin Tan
REFERENCES
[1]Mart√≠n Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen,
Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, San-jay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard,
YangqingJia,RafalJozefowicz,LukaszKaiser,ManjunathKudlur,JoshLevenberg,
DandelionMan√©,RajatMonga,SherryMoore,DerekMurray,ChrisOlah,Mike
Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul
Tucker,VincentVanhoucke,VijayVasudevan,FernandaVi√©gas,OriolVinyals,
Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng.
2015. TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems.
https://www.tensorflow.org/ Software available from tensorflow.org.
[2]JunjieBai,FangLu,KeZhang,etal .2019.ONNX:OpenNeuralNetworkExchange.
https://github.com/onnx/onnx.
[3]AriannaBlasi,AlbertoGoffi,KonstantinKuznetsov,AlessandraGorla,MichaelD
Ernst, Mauro Pezz√®, and Sergio Delgado Castellanos. 2018. Translating code
comments toprocedure specifications. In Proceedings ofthe 27th ACM SIGSOFT
International Symposium on Software Testing and Analysis. 242‚Äì253.
[4] Fran√ßois Chollet et al. 2015. Keras. https://keras.io.[5]
Junhua Ding, Xiaojun Kang, and Xin-Hua Hu. 2017. Validating a Deep Learning
Framework by Metamorphic Testing. In Proceedings of the 2nd International
Workshop on Metamorphic Testing (MET ‚Äô17). IEEE Press, 28‚Äì34.
[6]SaikatDutta,OwolabiLegunsen,ZixinHuang,andSasaMisailovic.2018. Testing
probabilistic programming systems. In Proceedings of the 2018 26th ACM Joint
Meeting on European Software Engineering Conference and Symposium on the
Foundations of Software Engineering. 574‚Äì586.
[7]Anurag Dwarakanath, Manish Ahuja, Samarth Sikand, Raghotham M. Rao, R. P.
Jagadeesh Chandra Bose, Neville Dubash, and Sanjay Podder. 2018. Identify-
ing Implementation Bugs in Machine Learning Based Image Classifiers UsingMetamorphic Testing. In Proceedings of the 27th ACM SIGSOFT International
Symposium on Software Testing and Analysis (ISSTA 2018). ACM, New York, NY,
USA, 118‚Äì128. https://doi.org/10.1145/3213846.3213858
[8]Amir Efrati. 2018. Uber Finds Deadly Accident Likely Caused by Software Set to
Ignore Objects on Road. The information (2018).
[9]Simos Gerasimou, Hasan Ferit-Eniser, Alper Sen, and Alper √áakan. 2020.
Importance-Driven Deep Learning System Testing. In ICSE.
[10]P.Godefroid,A.Kiezun,andM.Y.Levin.2008.Grammar-basedWhiteboxFuzzing.
InProceedings of the ACM SIGPLAN conference on Programming language design
and implementation. 206‚Äì215.
[11] Google. 2021. OSS-Fuzz. https://github.com/google/oss-fuzz
[12]Rahul Gopinath, Carlos Jensen, and Alex Groce. 2014. Mutations: How close
aretheytorealfaults?.In 2014IEEE25thInternationalSymposiumonSoftware
Reliability Engineering. IEEE, 189‚Äì200.
[13]KaramGouda,MosabHassaan,andMohammed JZaki.2010. Prism:Aneffective
approach for frequent sequence mining via prime-block encoding. J. Comput.
System Sci. 76, 1 (2010), 88‚Äì102.
[14]Qianyu Guo, Xiaofei Xie, Yi Li, Xiaoyu Zhang, Yang Liu, Xiaohong Li, and Chao
Shen.2020. Audee:Automatedtestingfordeeplearningframeworks.In 202035th
IEEE/ACM International Conference on Automated Software Engineering (ASE).
IEEE, 486‚Äì498.
[15]Jiawei Han, Jian Pei, Behzad Mortazavi-Asl, Helen Pinto, Qiming Chen, Umesh-
war Dayal, and Meichun Hsu. 2001. Prefixspan: Mining sequential patterns
efficiently by prefix-projected pattern growth. In proceedings of the 17th interna-
tional conference on data engineering. Citeseer, 215‚Äì224.
[16]ZhihaoJia,OdedPadon,JamesThomas,ToddWarszawski,MateiZaharia,and
AlexAiken.2019.TASO:OptimizingDeepLearningComputationwithAutomatic
GenerationofGraphSubstitutions.In Proceedingsofthe27thACMSymposiumon
OperatingSystemsPrinciples (SOSP‚Äô19).AssociationforComputingMachinery,
New York, NY, USA, 47‚Äì62. https://doi.org/10.1145/3341301.3359630
[17]Guoliang Jin, Linhai Song, Xiaoming Shi, Joel Scherpelz, and Shan Lu. 2012.Understanding and detecting real-world performance bugs. ACM SIGPLAN
Notices47, 6 (2012), 77‚Äì88.
[18]Keras.2019. Keras2.3.0:Thisisalsothelastmajorreleaseofmulti-backendKeras.
https://github.com/keras-team/keras/releases/tag/2.3.0.
[19]SifisLagouvardos,JulianDolby,NevilleGrech,AnastasiosAntoniadis,andYannis
Smaragdakis. 2020. Static analysis of shape in TensorFlow programs. In 34th
European Conference on Object-Oriented Programming (ECOOP 2020). Schloss
Dagstuhl-Leibniz-Zentrumf√ºr Informatik.
[20]Vu Le, Mehrdad Afshari, and Zhendong Su. 2014. Compiler Validation viaEquivalence modulo Inputs. In Proceedings of the 35th ACM SIGPLAN Con-
ference on Programming Language Design and Implementation (PLDI ‚Äô14).A s -sociation for Computing Machinery, New York, NY, USA, 216‚Äì226. https:
//doi.org/10.1145/2594291.2594334
[21]VuLe,ChengnianSun,andZhendongSu.2015. FindingDeepCompilerBugsvia
Guided Stochastic ProgramMutation. In Proceedings of the2015 ACM SIGPLAN
InternationalConferenceonObject-OrientedProgramming,Systems,Languages,and Applications (OOPSLA 2015). Association for Computing Machinery, New
York, NY, USA, 386‚Äì399. https://doi.org/10.1145/2814270.2814319[22]Zenan Li, Xiaoxing Ma, Chang Xu, Chun Cao, Jingwei Xu, and Jian L√º. 2019.Boosting Operational DNN Testing Efficiency through Conditioning. In Pro-
ceedingsofthe201927thACMJointMeetingonEuropeanSoftwareEngineering
Conference and Symposium on the Foundations of Software Engineering.
[23]J. Liang, Y. Chen, M. Wang, Y. Jiang, Z. Yang, C. Sun, X. Jiao, and J. Sun. 2019.
Engineering a Better Fuzzer with Synergically Integrated Optimizations. In 2019
IEEE 30th International Symposium on Software Reliability Engineering (ISSRE).
82‚Äì92. https://doi.org/10.1109/ISSRE.2019.00018
[24] Yu Liu, Cheng Chen, RuZhang, Tingting Qin, Xiang Ji,Haoxiang Lin, and Mao
Yang. 2020. Enhancing the interoperability between deep learning frameworks
by model conversion. In Proceedings of the 28th ACM Joint Meeting on European
SoftwareEngineeringConferenceandSymposiumontheFoundationsofSoftware
Engineering. 1320‚Äì1330.
[25]LLVM. 2021. libFuzzer ‚Äì a library for coverage-guided fuzz testing. http:
//llvm.org/docs/LibFuzzer.html
[26]LeiMa,FelixJuefei-Xu,FuyuanZhang,JiyuanSun,MinhuiXue,BoLi,ChunyangChen,TingSu,LiLi,YangLiu,JianjunZhao,andYadongWang.2018. DeepGauge:
Multi-Granularity Testing Criteria for Deep Learning Systems. In ASE.
[27]R.MajumdaandR.Xu.2007. DirectedTestGenerationUsingSymbolicGrammars.
InProceedings of the 22nd IEEE/ACM International Conference on Automated
Software Engineering. 134‚Äì143.
[28]MahdiNejadgholiandJinqiuYang.2019. Astudyoforacleapproximationsin
testingdeeplearninglibraries.In 201934thIEEE/ACMInternationalConference
on Automated Software Engineering (ASE). IEEE, 785‚Äì796.
[29] Augustus Odena,CatherineOlsson,DavidAndersen,andIanGoodfellow.2019.
Tensorfuzz: Debugging neural networks with coverage-guided fuzzing. In Inter-
national Conference on Machine Learning. PMLR, 4901‚Äì4911.
[30]Carlos Pacheco and Michael D Ernst. 2007. Randoop: feedback-directed random
testingforJava.In Companiontothe22ndACMSIGPLANconferenceonObject-
oriented programming systems and applications companion. 815‚Äì816.
[31]HungVietPham,ThibaudLutellier,WeizhenQi,andLinTan.2019. CRADLE:
cross-backendvalidationtodetectandlocalizebugsindeeplearninglibraries.
In2019IEEE/ACM41stInternationalConferenceonSoftwareEngineering(ICSE).
IEEE, 1027‚Äì1038.
[32]Hung Viet Pham, Shangshu Qian, Jiannan Wang, Thibaud Lutellier, Jonathan
Rosenthal,LinTan,YaoliangYu,andNachiappanNagappan.2020. Problemsand
opportunities in training deep learning software systems: an analysis of vari-
ance. InProceedings of the 35th IEEE/ACM International Conference on Automated
Software Engineering. 771‚Äì783.
[33]Frank Seide and Amit Agarwal. 2016. CNTK: Microsoft‚Äôs open-source deep-
learningtoolkit.In Proceedingsofthe22ndACMSIGKDDInternationalConference
on Knowledge Discovery and Data Mining. 2135‚Äì2135.
[34]Siwakorn Srisakaokul, Zhengkai Wu, Angello Astorga, Oreoluwa Alebiosu, and
Tao Xie. 2018. Multiple-implementation testing of supervised learning software.
InWorkshops at the Thirty-Second AAAI Conference on Artificial Intelligence.
[35]Chengnian Sun, Vu Le, and Zhendong Su. 2016. Finding Compiler Bugs via Live
CodeMutation.In Proceedingsofthe2016ACMSIGPLANInternationalConference
on Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA
2016). Association for Computing Machinery, New York, NY, USA, 849‚Äì863.
https://doi.org/10.1145/2983990.2984038
[36]Youcheng Sun, Min Wu, Wenjie Ruan, Xiaowei Huang, Marta Kwiatkowska, and
Daniel Kroening. 2018. Concolic Testing for Deep Neural Networks. In ASE.
[37]YuchiTian,KexinPei,SumanJana,andBaishakhiRay.2018.DeepTest:Automated
TestingofDeep-Neural-Network-DrivenAutonomousCars.In Proceedingsofthe
40th International Conference on Software Engineering.
[38]Yuchi Tian, Ziyuan Zhong, Vicente Ordonez, Gail Kaiser, and Baishakhi Ray.
2020. Testing DNN Image Classifier for Confusion & Bias Errors. In ICSE.
[39]Jackson Vanover, Xuan Deng, and Cindy Rubio-Gonz√°lez. 2020. Discoveringdiscrepancies in numerical libraries. In Proceedings of the 29th ACM SIGSOFT
International Symposium on Software Testing and Analysis. 488‚Äì501.
[40]Huiyan Wang, Jingweiu Xu, Chang Xu, Xiaoxing Ma, and Jian Lu. 2020. DIS-SECTOR: Input Validation for Deep Learning Applications by Crossing-layer
Dissection. In ICSE.
[41]Mingzhe Wang, Jie Liang, Chijin Zhou, Yu Jiang, Rui Wang, Chengnian Sun, and
JiaguangSun.2021. RIFF:ReducedInstructionFootprintforCoverage-Guided
Fuzzing.In 2021USENIXAnnualTechnicalConference(USENIXATC21).147‚Äì159.
[42]ZanWang, MingYan,Junjie Chen,ShuangLiu,and DongdiZhang.2020. Deep
learning library testing via effective model generation. In Proceedings of the 28th
ACM Joint Meeting on European Software Engineering Conference and Symposium
on the Foundations of Software Engineering. 788‚Äì799.
[43]Danning Xie, Yitong Li, Mijung Kim, Hung Viet Pham, Lin Tan, Xiangyu Zhang,
andMichaelGodfrey.2021. LeveragingDocumentationtoTestDeepLearning
Library Functions. (2021). arXiv:cs.SE/2109.01002
[44]XiaoyuanXie,JoshuaWKHo,ChristianMurphy,GailKaiser,BaowenXu,and
TsongYuehChen.2011. Testingandvalidatingmachinelearningclassifiersby
metamorphic testing. Journal of Systems and Software 84, 4 (2011), 544‚Äì558.
[45]XiaofeiXie,LeiMa,FelixJuefei-Xu,MinhuiXue,HongxuChen,YangLiu,JianjunZhao, Bo Li, Jianxiong Yin, and Simon See. 2019. Deephunter: a coverage-guidedfuzztestingframeworkfordeepneuralnetworks.In Proceedingsofthe28thACM
809
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:18:33 UTC from IEEE Xplore.  Restrictions apply. EAGLE: Creating Equivalent Graphs to Test Deep Learning Libraries ICSE ‚Äô22, May 21‚Äì29, 2022, Pittsburgh, PA, USA
SIGSOFT International Symposium on Software Testing and Analysis. 146‚Äì157.
[46]Mengshi Zhang, Yuqun Zhang, Lingming Zhang, Cong Liu, and Sarfraz Khur-
shid.2018. DeepRoad:GAN-BasedMetamorphicTestingandInputValidation
Framework for Autonomous Driving Systems. In ASE.
[47]XufanZhang,NingSun,ChunrongFang,JiaweiLiu,JiaLiu,DongChai,Jiang
Wang, and Zhenyu Chen. 2021. Predoo: precision testing of deep learning
operators. In Proceedings of the 30th ACM SIGSOFT International Symposium
on Software Testing and Analysis. 400‚Äì412.[48]WujieZheng,WenyuWang,DianLiu,ChangrongZhang,QinsongZeng,Yuetang
Deng,WeiYang,PinjiaHe,andTaoXie.2019. Testinguntestableneuralmachinetranslation:Anindustrialcase.In 2019IEEE/ACM41stInternationalConferenceon
Software Engineering: Companion Proceedings (ICSE-Companion). IEEE, 314‚Äì315.
[49]HushengZhou,WeiLi,ZelunKong,JunfengGuo,YuqunZhang,LingmingZhang,
BeiYu,andCongLiu.2020. DeepBillboard:SystematicPhysical-WorldTesting
of Autonomous Driving Systems. In ICSE.
810
Authorized licensed use limited to: LAHORE UNIV OF MANAGEMENT SCIENCES. Downloaded on August 07,2025 at 08:18:33 UTC from IEEE Xplore.  Restrictions apply. 