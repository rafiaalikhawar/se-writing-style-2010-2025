Pair Programming Conversations with Agentsvs. Developers:
Challengesand Opportunities forSE Community
PeterRobe
pjr144@utulsa.edu
Universityof Tulsa
Tulsa, Oklahoma, USASandeepK.Kuttal
sandeep-kuttal@utulsa.edu
Universityof Tulsa
Tulsa, Oklahoma, USA
JakeAuBuchon
jsa6790@utulsa.edu
Universityof Tulsa
Tulsa, Oklahoma, USAJacobHart
jch389@utulsa.edu
Universityof Tulsa
Tulsa, Oklahoma, USA
ABSTRACT
Recentresearchhasshownfeasibilityofaninteractivepair-programming
conversational agent, but implementing such an agent poses three
challenges:alackofbenchmarkdatasets,absenceofsoftwareen-
gineering specific labels, and the need to understand developer
conversations.Toaddressthesechallenges,weconductedaWizard
of Oz study with 14 participants pair programming with a simu-
latedagentandcollected4,443developer-agentutterances.Based
on this dataset, we created 26 software engineering labels using
an open coding process to develop a hierarchical classification
scheme. To understand labeled developer-agent conversations, we
compared the accuracy of three state-of-the-art transformer-based
languagemodels,BERT,GPT-2,andXLNet,whichperformedinter-
changeably.Inordertobegincreatingadeveloper-agentdataset,re-
searchersandpractitionersneedtoconductresourceintensiveWiz-
ardofOzstudies.Presently,thereexistsvastamountsofdeveloper-
developer conversations on video hosting websites. To investigate
thefeasibilityofusingdeveloper-developerconversations,wela-
beled a publicly available developer-developer dataset (3,436 utter-
ances) with our hierarchical classification scheme and found that a
BERT model trained on developer-developer data performed ~10%
worsethantheBERTtrainedondeveloper-agentdata,butwhen
using transfer-learning, accuracy improved. Finally, our qualita-
tiveanalysisrevealedthatdeveloper-developerconversationsare
more implicit, neutral, and opinionated than developer-agent con-
versations. Our results have implications for software engineering
researchersandpractitioners developingconversational agents.
CCS CONCEPTS
Â·Softwareanditsengineering â†’Collaborationinsoftwarede-
velopment ; Â·Computing methodologies â†’Artificial intelligence ;
Â·Human-centered computing â†’Empiricalstudiesin HCI .
Permissionto make digitalor hard copies of allorpart ofthis work for personalor
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
on the first page. Copyrights for components of this work owned by others than ACM
mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,
topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora
fee. Request permissions from permissions@acm.org.
ESEC/FSE â€™22, November 14Å›18,2022, Singapore, Singapore
Â©2022 Associationfor Computing Machinery.
ACM ISBN 978-1-4503-9413-0/22/11...$15.00
https://doi.org/10.1145/3540250.3549127KEYWORDS
Pair programming conversations, Conversational agents, Datasets,
Pair programming questions, Labels, Classification, Language mod-
els
ACMReference Format:
PeterRobe,SandeepK.Kuttal,JakeAuBuchon,andJacobHart.2022.Pair
ProgrammingConversationswithAgentsvs.Developers:Challengesand
Opportunities for SECommunity.In Proceedings ofthe 30thACM JointEu-
ropean Software Engineering Conference and Symposium on the Foundations
of Software Engineering (ESEC/FSE â€™22), November 14Å›18, 2022, Singapore,
Singapore. ACM, New York, NY, USA, 13pages.https://doi.org/10.1145/
3540250.3549127
1 INTRODUCTION
Recentadvancesinchatbotshaveincreasedinterestinthesoftware
engineeringcommunity,asevidencedbythegrowingnumberof
conferences and workshops that focus on bots for developers. Bots
are helping developers to generate and maintain architectures [ 66],
mine repositories [ 5] and Stack Overflow posts [ 4,123], perform
loadtest[ 81],andpatch/debugcode[ 109,120,121].Botsfrequently
(26%)automatetasks inopensourcesoftware(OSS) such as main-
tainingcode,reporting continuousintegration failures, reviewing
code and pull requests, ensuring license agreement signatures, and
assigning reviewers [ 116]. These bots help developers by saving
timeandeffortontedioustasks[ 116].Althoughbotsincreasede-
velopersâ€™ productivity, the primary limitation is their lack of in-
teraction with human developers [ 35], unlike existing voice-based
chatbots (alsoknownas conversational agents) inotherdomains.
Conversationalagentsarewellestablishedindomainssuchas
health, politics, and daily life. They have increased accessibility for
physicallydisabledpeople[ 67,108],formedemotionalconnections
through personal conversations (e.g., Cleverbot, Xiaoice, Mitsuku),
provided correct and concise answers to user queries (Bing QA),
steereddiscussionstopromotespecificideas(e.g.,Twitterbotsaf-
fected US presidential elections [ 100]), met customer needs for
two-thirdsofbusinessesontheweb[ 1],andtransformeddailycon-
versations (e.g., Alexa, Siri, and Google Assistant). Inspired from
the conversational agent literature, Robe and Kuttal [ 91] reported
designguidelinestoimprovedeveloper-agentinteractionsforacon-
versational agent to facilitate pair programming Å› an agile method
wheretwoprogrammersswitchrolesbetweendriverandnavigator
to develop software [ 10,13,92]. This agent performed on par with
319ESEC/FSE â€™22, November14Å›18, 2022,Singapore, Singapore Peter Robe,Sandeep K.Kuttal,Jake AuBuchon, andJacob Hart
developers when analyzing their productivity, code quality, and
self-efficacy [ 62]; however, the development of such a pair pro-
grammingconversationalagentorvoice-basedbotsforsoftware
developers poses the following challenges:
â€¢LackofBenchmarkDatasets: Currently,nobenchmark
dataset for developer-agent conversations exists for pair-
programming. The only methodology feasible for collect-
ing Human-AI conversational data is by conducting Wizard
ofOzstudies[ 124],whereresearcherssimulateanagentâ€™s
behavior.Thewizardâ€™sbehaviorneedstobesimulatedfor
specificsoftwareengineeringdomainsforwhichtheagent
isbeingdeveloped,e.g.,thewizardshouldbehaveasapair
programmingagentsince nosuch agentsexist.
â€¢No SoftwareEngineering Labels: Currently, no software
engineering labels exist to annotate the data needed to train
conversational agents for pair-programming. Past research
on conversational agents usedDialogue Acts for represent-
ing generic human-human conversations. Dialogue Acts are
insufficient toexpresstheuniqueintent of developerâ€™s con-
versations,astheserevolvearoundimplementationandtest-
ingofsoftware.
â€¢Understanding Developer Conversations: Algorithms
fornaturallanguageunderstanding(NLU)needtobetrained
ondeveloper-agentconversationsforbetterclassifyingde-
veloper dialog. Transformer-based language models have
become standard for naturallanguage understanding tasks
[30,40,84,125].These language models are capableof con-
textually representing words by utilizing neural networks
with a large range of parameters, from 110 million [ 30] to
175billion[ 40],andaretrainedonvastamountsoftextdata
(e.g., Wikipedia, BookCorpus, Reddit). However, this text
data excludes programming concepts such as data types,
loops,andmethods.
This paper takes the first step to address these challenges and
lays the groundwork towards understanding developer-agent con-
versations. Hence,we formulatedRQ1:
â€¢RQ1:TowhatextentcanNLU-basedalgorithmsunder-
stand developer-agentconversations? Towards creating
a dataset of developer-agent conversations, we conduct a
Wizard of Oz study with a simulated agent using the de-
sign guidelines from Robe and Kuttal [ 91]. Our study task
and design is inspired by Robe et al. [ 90] to augment the
collected data. We collected 4,443 utterances from 14 par-
ticipantsconversingwithasimulatedagent.Basedonthis
dataset, we created software engineering labels using an
open coding process to develop a hierarchical classification
scheme that allows identification of intent and applicable
sub-intents.A hierarchical approachwas usedoverlinearto
reducethenumberofoverallintents,thisreducedourlabels
to 26. We used three transformer-based language models
for NLU, BERT [ 30], GPT2 [ 84], and XLNet [ 125], for clas-
sifying developer-agent dialog. We found that these mod-
els largelyperformed interchangeably; however, BERT per-
formedmarginallybetter(Precisionof+0.6%andRecallof
+0.1%).ThissuggestsTransformer-basedLanguagemodelscan be utilized for modeling the intent and understanding
ofdeveloper-agentconversations.
Inordertobegincreatingadeveloper-agentdataset,researchers
and practitioners need to conduct resource intensive Wizard of
Oz (WoZ) studies. At present, there are vast amounts of developer-
developerconversationsonvideohostingwebsites,suchasTwitch.tv
andYoutube,thatcouldbetranscribedandlabeled;however,itis
notevidentiftheseconversationsareequivalenttodeveloper-agent
conversations. Hence,we formulatedRQ2:
â€¢RQ2: To what extent can developer-developerconver-
sations be utilized for training a pair-programming
conversationalagent? Tounderstandwhetherdeveloper-
developer conversations can be utilized to train pair pro-
gramming agents, we used the existing developer-developer
datafromRobeetal.[ 90]andlabeleditwithourhierarchical
classification scheme.
(a)Feasibilityofusingdeveloper-developerdata. Tomeasure
the utility of developer-developer conversations, we trained
BERT solely on developer-developer data and a separate
BERTmodelondeveloper-agentdataandfoundtheaccuracy
ofthe firstBERTmodellower by~10%.
(b)Feasibilityofapplyingtransferlearning. Theefficacyof
using transfer learning between human-human and human-
agentconversationsforclassifyingdialoghasbeenwidely
demonstratedforconversationalagentsintheAIcommunity
[6,24,74,120].Hence,weevaluatedthefeasibilityoftransfer
learning for pair-programming contexts. We found the accu-
racy of BERT increased when trained initially on developer-
developerdataandthenfine-tuningwithdeveloper-agent
data.Thetransferlearningmodelwasmarginallybetterthan
the baselinedeveloper-agentmodel(+0.1%,+0.6%).
(c)Differencesindialogstyle. Tounderstandthestylistic
differences in the dialogs between the two datasets, we con-
ductedqualitativeanalysis.Wefounddeveloper-developer
conversations are more implicit, neutral, and opinionated
thandeveloper-agentconversations.
The rest of the paper is structured as follows. Section 2 dis-
cusses the related work. Section 3 presents RQ1, details on data
collection,thehierarchicallabels,andclassification/modelingusing
BERT,GPT2,andXLNet.InSection4,wepresentRQ2,detailson
developer-developerdata,compareaccuracyofBERTondeveloper-
developeranddeveloper-agentdata,evaluatethefeasibilityofus-
ingdeveloper-developerconversationsusingtransferlearning,and
evaluatequalitativedifferencesinthedialogstyles.Section5dis-
cusses the threats to validity. Section 6 highlights opportunities
forsoftwareengineeringresearchersandpractitioners.Section7
concludes andliststhe contributionsof our paper.
2 RELATED WORKINSE
Insoftwareengineering,researchhasbeenconductedtocreatebots
fordevelopers,designandstudythefeasibilityofpair-programming
conversational agents, labeled data for software designand devel-
opment, anduse transformer-basedlanguagemodels.
320Pair ProgrammingConversationswithAgents vs. Developers: Challenges andOpportunities forSE Community ESEC/FSE â€™22, November14Å›18, 2022,Singapore, Singapore
2.1 BotsforDevelopers
Researchers and practitioners have created tools to aid various
softwaredevelopmenttasks.Forexample,IDEtoolsdetectsyntax
errors in real-time, automate repetitive tasks, and debug code. OSS
projectsonGitHubmakeampleuseofbots[ 116]andchatbotshave
assisted newcomers and assigned them a task [ 32,98]. Lin et al.
[66]createdachatbottohelpdeveloperswithmicroservicebased
architectures.Williamsetal.[ 117]automatedfeedbackoncodecor-
rectness and Mussbacher et al. [ 76] created an intelligent modeling
assistantforcodefeedback.Urlietal.[ 109]developedabottoauto-
maticallysuggestpatchesbasedonfailedtestcases,andOkanoviÄ‡et
al.â€™s [81] bot helped developers perform load testing. Chatbots also
helpeddeveloperseffectivelyfindStackOverflowposts[ 4,123]and
mine repositories [ 5]. Outside of traditional software development
activity Matthies et al. [ 70] explored developing a chatbot for agile
retrospectivestohelpteamstrackissuesacrossdevelopmentcycles.
Additionally, platforms for training agents have been created such
as Googleâ€™s RecSim and Metaâ€™s web-enabled simulation. Finally,
Bradley et al. [ 19] envisioned a voice-based context-aware agent
that works via the Amazon Alexa Platform. While past research
focusesonspecificpointsinthesoftwarelifecycle,noneofthemen-
vision an immersive, interactive pair-programming conversational
agent.
Woodsetal.[ 121]collectedconversationaldataonbugrepair,
generated labels using open coding, and then used a logistic re-
gression model to classify the data. Our study design for RQ1 was
inspired from their WoZ study, while they envisioned a Q/A agent,
we envision an interactive pair-programming agent. Later, Woods
etal.[120]analyzeddifferentapproachesfortransferlearningstart-
ing with the AMI business meeting corpus and fine-tuning with
their previously collected bug-repair data [ 121]. Our paper investi-
gatedthefeasibilityoftransferlearningforlanguagemodelstrained
on developer-developer dataand fine-tuned with developer-agent
data.
2.2 Pair-programmingConversational Agent
Robe and Kuttal [ 91] recently reported design guidelines for a
pair-programming conversational agent. Later, Kuttal et al. [ 62]
investigated the feasibility of their designed pair-programming
conversationalagentbyconductinglabandWizardofOzstudies.
They found no significant differences in code quality, productivity,
orself-efficacybetweendeveloper-developeranddeveloper-agent
participants. They found developers were trusting, humble, and
agents facilitate knowledge transfer. These results motivate the
developmentofapair-programmingconversational agent.
Further, Robe et al. [ 90] investigated the feasibility of a third-
party facilitation agent in developer-developer conversations by
conducting a lab study to simulate remote pair programming. The
data collected from this study was then annotated using generic
DialogueActsthatrepresentthefunctionofanutteranceinhuman-
human conversations [ 12,97,105]. Robe et al. found annotating
programming dialog using only Dialogue Acts to be insufficientat capturing the sporadic nature of remotepair programming con-
versations. Further, they analysed results using support vector ma-
chines (SVMs) to classify the utterances, achieving a 57.9% accu-
racy. In contrast, we collected data for developer-agent conver-
sation using WoZ studies, generated new labels specifically for
developer-agent conversations, investigated transfer learning of
developer-developeranddeveloper-agentdata,andusedstate-of-
the-art pre-trained language models for analyzing the data. We
envision a conversational pair programming agent rather than a
thirdpartyfacilitation agent.
2.3 Labeling ofData
Researchers have created labels and annotated data for software
design and development tasks. Viviani et al. [ 111,112] studied the
automationoflocatingdialogrelatedtodesigndiscussioninpullre-
questsandonlinediscussions,Ed-douibietal.[ 34]developedaQ/A
chatbot to assist the understanding of RESTAPIs, Ebertetal.[ 33]
andPascarellaetal.[ 83]identifiedtheintentionofquestionsduring
code reviews. These approaches investigated highly specific activi-
ties (code reviews, design processes) or speech types (questions),
whereaswecreated26hierarchicallabels,tailoredspecificallyto
the developer-agentdomain.
2.4 ApplicationsofLanguage Models
Researchershaveevaluatedthecapabilitiesoftransformer-based
languagemodelsforsoftwareengineeringapplications.Xieetal.
[122]categorizedfunctionalityverbswithinAPIdescriptionsinto
87 categories by fine-tuning a pre-trained BERT model. Additional
applications of BERT include machine translation failure detection
[47], software analysis [ 113], and technology comparison tools
via online discussions [ 114]. Futher, GPT-2 has been adapted by
Svyatkovskiyetal.[ 107]forautomatedcodegenerationinavariety
ofprogramminglanguages,whileXLNet,asanewernichelanguage
model,hasyettobeappliedtomanysoftwareengineeringdomains.
We differ from previous research, sincewe investigated the utility
oflanguagemodels to classifypair-programming conversations.
3 RQ1: DEVELOPER-AGENTDATA
3.1 Data Collection
To address the challenge of lack of developer-agent datasets, we
conductedvirtuallabstudies,simulatinganagentusingtheWizard
ofOz (WoZ) methodto collectdeveloper-agentconversations.
3.1.1 Wizard of Oz Method. WoZ is a simulation study where par-
ticipantsinteractwithanautomatedagent,secretlycontrolledby
another human, the â€œwizardÅ¾. This simulated experience allows
researchers to analyze human-AI interactions prior to the imple-
mentation of an agent [ 64,118,124]. WoZ has been extensively
usedfor(1)machinelearning(ML)feasibilitystudies[ 49,62],(2)
designresearch[ 20,80],(3)naturallanguageinterfacessuchascon-
versationalagents[ 18,89,115,121,124],and(4)question/answer
conversations about bug repair with an agent [ 121]. Transcripts
gathered from WoZ studies lay the foundation for the use of ML
algorithms, as it considers the unique qualities of human-agent
dialogas opposedto typical human discourse [ 26].
321ESEC/FSE â€™22, November14Å›18, 2022,Singapore, Singapore Peter Robe,Sandeep K.Kuttal,Jake AuBuchon, andJacob Hart
Figure 1: Wizard of Oz study. The agentâ€™s avatar and text-to-
speech(TTS)weresecretlycontrolledbyresearchersÅ‚Wiz-
ardÅ¾.
3.1.2 SimulatedAgentDesign. Wedesignedouragentanditsre-
sponses based on past research by Robe and Kuttal [ 91] which
recommendeddesignguidelinesforcreatingapair-programming
conversationalagent.Theiragentâ€™sdesignwasinspiredfrommulti-
disciplinaryresearchonsoftwareengineering,conversationalagents,
human-computer interactions, human-robotic interactions, educa-
tion, intelligent tutoring systems, psychology, and management
science. Further, technical and social skills are crucial for being
an effective team member in the software engineering industry
[7,25,79,94];therefore,both are simulated.
Social Skills of a Developer To give the agent a human-like
embodiment, it was given a 3D avatar [ 61,126] and text-to-speech
synthesistocommunicate.Whenactingasadriver,codewaspasted
withinasharedwindow inchunkstoappearmorerobotic. When
acting as a navigator the agent gave guidance by suggesting or
clarifying goals, offering abstract code ideas, and asking questions
to promote divergent thinking. As the agent would not have an all
encompassing knowledge, it would deflect with itsâ€™ own questions
(e.g.,Å‚Whatdoyouthink?Å¾ )orsuggestedthatthedeveloperwrite
the implementation (e.g., Å‚What would that idea look like? Can
you write it?Å¾ ) when participants asked questions outside of itsâ€™
capabilities. The agent negotiated the driver and navigator roles
withtheparticipanttobalancecontributions.Theagentadopted
the personality of an anthropomorphic and effective developer
by introducing itself [ 54], acting as a team-player [ 53], showing
uncertainty and asking for verification [ 11,55,61], and motivating
itsâ€™partner[ 9,23,29,42].Thesefeaturesprovideclearbenefitstoa
developersâ€™ performance,productivity,andcreativity[ 61].
Technical Skills of a Developer To simulate technical skills,
both as a driver and a navigator, the agent design was informed
byvastresearchonsoftwareengineeringliterature.Whenacting
as a driver, automatic code contribution was facilitated by code
search [56,57,85] and feedback generation [ 28,127] techniques.
Test case generation was based on past research, including the
conversionofdiagrams,suchasUMLandFSMs,totestcases[ 72,
73],andconversionofuserstoriestoscenarios,thentotestcases
[8,86].Codelocationwasbasedonpreviouslyinvestigatedstatic
and dynamic techniques [ 68,95], unnecessary code was found
through automated tools such as UCDetector [ 103], and missingcode was found through research in the Haskell programming
language[ 44].
3.1.3 WizardofOzStudy. We designedour studyto mimicRobe
etal.[90]research,thisallowedustoaugmentthecollecteddata
andtoinvestigatethefeasibilityofdeveloper-developerdata(see
4.3.1).SimilartoRobeâ€™sstudy,ourstudyparticipantsweretasked
to complete a tic-tac-toe game implementation within a 40 minute
timeframe(toavoidfatigue)usingtest-drivendevelopment.Our
participants completed a demographics background questionnaire
prior to starting the study.
Participants learned the concepts of pair programming, think-
aloudmethod,andtest-drivendevelopmentthroughvideotutori-
als. Participants were also provided with a tutorial outlining the
functionality of the agent. The think-aloud method encourages
participantstovocalizetheirthoughtsandfeelingsastheyperform
the task; this helps model their cognitive processes [ 65,96,102]
and, in our study, to collect conversations with an agent. To collect
adiverserangeofdialog,participantsadheretotest-drivendevel-
opment,apracticewheredeveloperswritetestcasesbeforewriting
code [15].
Figure1illustrates our WoZ study design. Participants pair pro-
grammed with an agent using the Saros plugin for the Eclipse IDE.
Theagentâ€™s3DavatarwasgeneratedbytheFacerigembodiment
software,alsoprovidinglip-synchronizationofthewizardâ€™sface,
and GoogleText-to-Speechsynthesizedthewizardâ€™s voice. Video
and audio communication, with the agent, was conducted over
Skype,Discord,orGoogleHangouts.Twowizardsmonitoredthe
participantâ€™s face, voice, and screen, while collaboratively control-
ling the agentâ€™s actions. One wizard was a graduate student with 5
years of programming experience and the other was an undergrad-
uate student with 3 years of experience. Both wizards were trained
by conducting preliminary studies. They maintained the illusion
of an agent by adhering to a script of templated dialog options
[3].Basedon theutterancefromtheparticipant,thewizard chose
fromalimitedselectionofresponse,withoutreplacement,filling
inblankswithcontextual wordsas necessary.
UsingaconstrainedWoZprotocol[ 88],thewizardssimulated
all components of a conversational agent [ 43] including intent un-
derstanding, dialogue state tracking, dialogue policy, and response
generation. Wizard 1 interacted with the participant using our
customElectronApplication(aGUIframework)toautomatethe
selectionofdialogresponsesfromthewizardsâ€™scriptwithaclick
ofabutton.Wizard2simulatedthetechnicalskillsofadeveloper.
In the future, Copilot [ ?] can be utilized for the automated code
recommendation. While the wizards attempted to provide an equal
ratioofcontributionsbetweenstudies,someparticipantsmayhave
receivedless helpif they ignoredthe agentâ€™ssuggestions.
3.1.4 Participants. 14participants(6professionalsand8computer
science majors) were recruited to pair program with an agent. Par-
ticipantsâ€™programmingexperiencerangedfrom2to20years.These
studieswereconductedduringtheCOVID-19pandemic,forcingall
studiestobeconductedvirtuallythusparticipantswerenotsubject
to all the control parameters of a traditional lab study as they used
theirowndevicesandworkedintheirworkspaces.Thisallowedus
torecruitparticipantsfromoutsideouruniversityandprofessionals
from differentgeographicregions.
322Pair ProgrammingConversationswithAgents vs. Developers: Challenges andOpportunities forSE Community ESEC/FSE â€™22, November14Å›18, 2022,Singapore, Singapore
3.2 Labeling
Toaddressthelackofsoftwareengineeringlabels,wecreatedan
initialsetofdialogintentlabels.
To mimic the agents actions, the wizards based their actions on
the developerâ€™s intent. If a participant asked, Å‚Can I drive now?Å¾
the wizard determined that the developer intended to switch roles
and drive. However, agents cannot intuitively understand intent,
andmustclassifydialogintodiscretecategories.Wedevelopeda
hierarchicalclassificationschemeonthedeveloper-agentdatato
reflectthedialog-intentofdeveloper-agentconversations.Thiswas
done because (1) developersâ€™ conversations are uniquely specific to
the implementation and testing of code. The existing conversation
benchmarkscontaindialogspecifictodomainssuchascustomer
support, restaurant ordering; which can not be adapted for soft-
wareengineeringdomain;(2)Theagentinteractedwithdevelopers
usingaspecific, hand-craftedprotocol,so the emergingrange of
interactions with developers became quite narrow. By capturing
this specific style of engagement, the labels will effectively satisfy
theinformationneedsofafuturepair-programmingconversational
agent;(3)Lastly,ahierarchicalscheme reducesthenumberofpo-
tentialclassifications.
3.2.1 Hierarchical Classification Scheme . For generating labels,
weadoptedanopencodingprocessfromsocialsciences[ 17]and
pastresearch[ 121].Asafoundationweadoptedgenerallabelssuch
as Feedback, Thanking, and Answers from Dialogue Acts (blue
rowsin Table 1). DialogueActsrepresent the function of an utter-
ance within the domain of computational modeling [ 12,97,105].
Dialogue Acts have been used to (1) categorize intent in the devel-
opmentofconversationalagentsinotherdomains[ 48,99,105,110],
and (2) study conversational speech in co-located [ 87] and remote
pair programming studies [ 90]. While Dialogue Acts generally cap-
turesyntacticandstylisticinformationcommonacrossallformsof
communication, the kind of information exchanged via pair pro-
gramming dialog necessitates a further specialized set of labels.
For example, if a developer asked, Å‚Wait, are we working on the
horizontal win test?Å¾ traditional Dialogue Acts would be able to
identifythatitisayes-no-question,butmightnotknowthatthe
developer is requesting a clarification of the current programming
task goal. Hence, through an open coding process, we generated
more specific pair programminglabels, useful to our domain.
Weiterativelylabeled,merged,pruned,andmodifiedpotential
labelsacrossmultipleroundsuntilafinalsetofdistinctlabelswere
established (Table 1). Figure2illustrates our hierarchical approach,
workinglikeaUnixPipeline||,itbeginswiththeroot Intentclassi-
fier whose output may result in further classification in a subset of
thefollowingfoursub-intentclassifiers: Delivery ,Programming
Acts,Role,andTone.Table1listsourlabelswithexamples,andFig-
ure2illustrates the relationship between the root Intentclassifier
labelsandeachassociatedsub-intent.Returningtoourpreviousex-
ample, the developer asked Å‚Wait, are we working on the horizontal
wintest?Å¾ ,itsrootIntentisTask Related ,seetheredoutlineson
figure2,whichtriggersthe Delivery andProgramming Acts sub-
intent classifiers resulting in the Clarification andTask Goal
labelsrespectively.Finally,byhavingmultiplerootintentsshare
sub-intentswithinourhierarchy, Tone,forexample,canbetrainedTable 1: Pair Programming Labels (blue rows represent Di-
alogue Acts adapted from [ 105] others have been tailored
explicitlyto accommodatedevelopers
)
Intent Example
Task Control Can I drive?
Task-Related Which test caseshould we do next?
Answer No,I donâ€™tthinkso.
Feedback Ohok I see what youâ€™re doing.
Greeting Nice to meetyou.
Think-Aloud For int i isless than3.
Thanking Yeah. Thank you.
Repeat Wait,what didyou say?
Uncertain Iâ€™mnot sure whatâ€™s going onhere.
Delivery Example
Question Where should we start?
Recommendation No,I donâ€™tthinkso.
Direction Ohok I see what youâ€™re doing.
Clarification Wait,what are we workingon?
Programming Acts Example
Task Goal Letâ€™s work onahorizontal win.
Comprehension Letâ€™s take alook at whatâ€™s written.
Attend Location Oh,thatâ€™sonline64.
HaltWork Nonono,donâ€™twritethat.
Code Italsoneedsto be changedto true.
Idea Howcan we checkfor awin?
RunCode/Test Shouldwe run the tests?
Role Example
Driver Can I try?
Navigator Howaboutyou give itago?
Either ShouldI startorwouldyou like to?
Tone Example
Positive Yes, that looks great!
Neutral Okay,sure.
Negative I donâ€™tlike where this isgoing.
using utterances from both AnswerandFeedback . NoteTonede-
tectioncanbeperformedbyexistingsentimentanalysisalgorithms
[22,52]infuture agentdesign.
Weutilizeahierarchicalapproachoveralinearapproachforclas-
sificationtolimitthetotalnumberoflabels.Whilealinearapproach
wouldconsider Task Control Å›DriverÅ›Clarification tobecom-
pletelyindependentfrom Task Control Å›DriverÅ›Direction ,ahi-
erarchicalapproachrecognizesthattheybothshare Task Control Å›
Driver. Rather than distinguish between 100+ label combinations,
ahierarchicalapproachfocusesonasetof26distinctlabels.The
small label setisbeneficialfor betteraccuracyof ML algorithms.
3.2.2 TranscriptLabelingMethodology. Onceourlabelswerees-
tablished on developer-agent data, two researchers independently
labeled20%ofthetranscriptsandreachedainner-ratereliabilityof
0.760usingCohenâ€™sKappa,whichisconsideredsubstantialagree-
ment. Cohenâ€™s Kappa is calculated using ð‘˜=1âˆ’1âˆ’ð‘ƒð‘œ
1âˆ’ð‘ƒð‘’whereð‘ƒð‘œis
the â€œObserved Rater AgreementÅ¾ and ð‘ƒð‘’is the â€œExpected Random
AgreementÅ¾,orexpectedagreementbychance.Thus,tocalculate ð‘ƒð‘’
323ESEC/FSE â€™22, November14Å›18, 2022,Singapore, Singapore Peter Robe,Sandeep K.Kuttal,Jake AuBuchon, andJacob Hart
Figure2:Hierarchicalrelationshipbetweenintent,sub-intents,andlabels(white).HighlightedLabels(red)representtheintent
TaskRelated-Clarification-TaskGoalfortheutterance "Wait, are we workingon thehorizontal win test?"
asummationwasused: ð‘ƒð‘’=1
ð‘2/summationtext.1
ð¾ð‘›ð‘˜1ð‘›ð‘˜2wherenisthenumber
ofpredictionsforeachcategory,K,byeachreviewer.As ð‘ƒð‘œisthe
observedagreement,thisisfoundbytakingthenumberofagree-
ments divided by the total number of dialogues. The remaining
80%wasindependentlylabeledbyoneresearcher.Ourfully-labeled
dataset is available at [ 3]. On average, transcription and labeling
for an individual study session averaged ~14 hours of consistent
effort(~196 hoursintotal).
3.3 Classification andModeling
Oncethedatawascollectedandlabeled,weneededtodetermine
ifthisdatacouldbeusedtotrainnaturallanguageunderstanding
(NLU) algorithms for future agents. We used transformer-based
languagemodelswhichhavebecomestandardfornaturallanguage
processing tasksto classifyintents [ 30,40,84,125].
3.3.1 Utilizing Transformer-Based Language Models. We evaluated
threetransformer-basedlanguagemodels,BERT,GPT-2,andXLNet
becausethesemodelsarepre-trainedtoestablishabaseunderstand-
ing of language (e.g., English), and can be further fine-tuned for
down-streamtasks(e.g.,intentclassification)inspecificdomains
(e.g., restaurant reservation). We chose BERT, as it is a state-of-
the-art language model, GPT-2 as it is another well-established
language model that uses its own transformer architecture, and
XLNet asit has out-performed BERT in other benchmark datasets
[27].
BERT:Bidirectional Encoder Representations from Transform-
ers(BERT),wasdevelopedbyGooglein2018[ 30].BERTisbuiltus-
ingstackedtransformerencoderblocksandallowsforthefusionof
both left-to-right and right-to-left context simultaneously through
itsbi-directionaldesign.BERTiscommonlyusedforlanguagetasks
such as classification, question/answer (Q/A), and named entity
recognition(locateandclassifycertainwordswithinasentence).
BERTusestheBookCorpus(800Mwords)andEnglishWikipedia
(2,500Mwords) corporafor pre-training.
GPT-2:GenerativePre-trainedTransformer2(GPT-2)wasre-
leased in 2019 by OpenAI as a successor to GPT [ 84]. GPT-2 differs
fromBERTsinceitusesastackoftransformerdecoder(ratherthanencoder) blocks, and it is uni-directional meaning it only uses left-
to-rightcontext.Additionally,itistrainedonanincrediblylarge
dataset of8million webpages(i.e.,WebText).
XLNet:XLNet is a bidirectional transformer similar to BERT,
releasedin2019byCMU andGoogle researchers,that largelydis-
tinguishesitselfbyitsimprovedtrainingmethodology[ 125].When
training,insteadofpredictingindividualmaskedwordsfromeither
theleftorrightdirection,XLNetpredictsasequenceofwordswith
respecttoallpossiblepermutationsoftheordering.Additionally,
XLNet incorporates ideas from the state-of-the-art auto-regressive
model, Transformer-XL [ 27], including relative position encoding
andasegment recurrence mechanism.
3.3.2 Implementation. Inthis paper,we usedthe transformers py-
thon package from Huggingface [ 119] and specifically selected the
following pre-trained models: bert-base-uncased ,xlnet-base
-cased, andgpt-2. For our classification task, we connected the
pooledoutputofeachmodelwithadropoutandalinearregression
layerusing a ð‘‡ð‘Žð‘›â„Žactivation function that outputs avector, sized
according to the number of classes. The model was trained sepa-
ratelyforeachcategoryoflabels( Intent,Delivery ,Programming
Acts,Role,andTone)foratotalof5models.Weusedthedefault8
batchsize,5e-5learningrate,500warm-upsteps,0.01weightdecay,
andAdamWas the optimizer.
3.3.3 Metrics. We report the result of each classifier as an average
over 5 separate runs using new train/validate/test splits. The splits
followed the same trainingmethodology as performedby Nguyen
et al. [78] to present BERTweet and Namazifar et al. [ 77] to map
Natural Language Unit for a Question/Answer problem. We report
common metrics for evaluating classifiers i.e., precision, recall, and
F1-measure[ 14].Precisionscoresdescribethenumberoftimesa
predictionfor anindividual labelis correct(i.e., thepercentageof
true positives out of all the predictions for a given label). Recall
scoresarethepercentageofinstancescorrectlypredicted,outofall
ofalabelstotalinstances.TheF1-scoregivesaharmonicaverage
of the precision and recall scores. When averaging these metrics
across all of our labels, we utilized weighted averages to normalize
representation among the labels.
324Pair ProgrammingConversationswithAgents vs. Developers: Challenges andOpportunities forSE Community ESEC/FSE â€™22, November14Å›18, 2022,Singapore, Singapore
Table 2: Comparison of three transformer-based language models: BERT vs. GPT2 vs. XLNet, trained on developer-agent data.
ModelIntent Delivery PAs Role Tone Weighted Average
Prec. Recall Prec. Recall Prec. Recall Prec. Recall Prec. Recall Prec. Recall
BERT 80.1 80.0 80.1 76.6 74.4 73.7 95.2 94.6 80.2 79.9 79.9[78.2, 80.5] 79.2[78.3, 80.1]
GPT-2 80.3 80.2 76.1 75.8 73.1 73.1 92.9 92.3 80.8 80.6 79.3[78.4, 79.9] 79.1[78.5, 79.6]
XLNet 79.8 79.5 77.0 76.6 75.3 74.6 90.2 89.1 79.8 79.2 79. 2[78.6, 79.9] 78.7[77.7, 79.5]
3.3.4 CanNLU-basedAlgorithmsUnderstandDeveloper-AgentCon-
versations? Toinvestigatetheperformanceoftransformer-based
language models in a pair programming context, we compared
threelanguagemodels,BERT,GPT-2,andXLNet,thatdifferintheir
training dataset (BERT, GPT-2) and architecture (BERT, GPT-2, and
XLNet).Modelsweretrained/validated/testedon75%,10%,and15%
ofdeveloper-agentdata respectively.
Results in Table 2show all three models performed interchange-
ably, but BERT had a slight edge over GPT-2 (+0.6% and +0.1%) and
XLNet(+0.7%and+0.5%)attheaggregatelevel.Themostnotable
differencesincludeXLNetperformedbestonlyinthe Programming
Actsub-category,BERT(+0.9%and+0.9%)andGPT-2(+2.2%and
+1.5%);whereas,BERTandGPT-2eachtook2categorieswithBERT
takingRole,thebestperformingsub-category,andaggregateac-
curacy. Additionally, we performed a one-way analysis of variance
acrossthethreemodelswithprecisionandrecallreceivingap-value
ofX and Yrespectively, showing thatthe modelsperformed inter-
changeably. Given BERTâ€™s aggregate and sub-category scores in
comparison to the other models, we report our results using BERT;
furthermore, the similarityamong scores suggests little benefit to
exploringothertransformer-basedlanguagemodels.
4 RQ2: DEVELOPER-DEVELOPERDATA
To utilize the vast arrays of existing developer-developer conversa-
tion data available though video hosting websites such as Youtube
andTwitch, we were motivatedto frameRQ2.
4.1 Data Collection
We used the developer-developer conversational data from Robe
et al. [90] as they used a machine learning algorithm (SVM) to
understand developer conversations inpair programmingcontext.
4.2 Labeling
We labeled the data obtained from Robe et al. [ 90] studies using
our hierarchical classification scheme (Figure 2). For the developer-
developer data we found Cohenâ€™s Kappa of 0.743 for the two re-
searchers each labelling 20% of the transcripts. The remaining data
waslabeledbyoneresearcher.Thetranscribingandlabelingtook
~126 hoursofwork.
4.3 Classification andModeling
As discussed in section 3.3.4, we used BERT to compare developer-
developer anddeveloper-agentconversations to answer RQ2:
4.3.1 FeasibilityofUsingDeveloper-DeveloperData. Tomeasure
the utility of developer-developer data, we compared two BERT
language models trained exclusively on either developer-developer
ordeveloper-agentdatatopredictlabelsfordeveloper-agentdialog.
ThefirstBERTmodel(DA)wasentirelytrained/validated/testedonTable3:Resultsofclassifyingdeveloper-agentdialogusing
BERT trained on developer-agent (DA), developer-developer
(DD),anddeveloper-developerfine-tunedbydeveloper-agent
conversations (DD>DA).
BERT Precision Recall F1-measure
DA 79.5[78.5, 80.5] 79.2[78.3, 80.1] 79.1[78.2, 80.1]
DD 71.2[70.9, 71.5] 69.0[68.7, 69.4] 68.9[68.5, 69.2]
DD>DA 80.0[78.5, 81.6] 79.8[78.3, 81.2] 79.7[78.2, 81.2]
75%,10%,and15%ofdeveloper-agentdatarespectively.Thesecond
Bertmodel(DD)wastrainedon100%ofthedeveloper-developer
data and validated/tested on 40% and 60%of developer-agent data.
Overall results can be found in Table 3. Precision and recall scores
for eachcategory can be foundinTable 4.
Thedeveloper-agentdataisrepresentativeofanidealizeddataset
andthedeveloper-developerdataissymbolicofthereadilyavail-
able data. For our baseline DA model, Roleperformed the best
(95.2%, 94.6%) followed closely behind by Intent(80.1%, 80.0%),
Delivery (80.1%,76.6%),and Tone(80.2%,79.9%). Itisnotablethat
Programming Acts (74.4%,73.7%)performedtheworst;however,it
isthe secondlargestclassifier bynumber of sub-intents.
Based on the overall metrics, training with developer-developer
data(DD)had10.2%lowerrecall,8.7%lowerprecision,and10.2%
lower F1-measure. Results forDD (Table 4),IntentandTonehad
the highest precision and recall (72.4%, 69.9% and 75.9%, 75.0%),
while for Programming Acts they were moderately high (67.2%,
65.2%)consideringitdistinguishedbetween seven separatelabels;
however,theprecisionandrecallof Delivery andRolewere66.2%,
64.0%and63.7%,63.7%,evenwhenonlyclassifyingbetweenfour
and three labels respectively. These results show that at least for
some categories, training exclusively with developer-developer
conversations isfeasible.
4.3.2 FeasibilityofApplyingTransferLearning. In4.3.1,wewere
able to demonstrate that developer-developer data can be used
withreducedaccuracy.Theefficacyofusingtransferlearningbe-
tween human-human and human-agent conversations for clas-
sifying dialog has been widely demonstrated in AI community
[6,16,24,51,74,106,120].Bothsupervisedandunsupervisedtrans-
ferlearningapproacheshavebeenusedinthedomainofconver-
sational agents [ 43], Question/Answer agents [ 24,120], and for
naturallanguageprocessingapplications[ 74].Woodsetal.classi-
fied Dialogue Acts for virtual agents for software engineers during
debugging [ 120] and presented transfer learning from general con-
versations[ 120].Toevaluatethefeasibilityoftransferlearningin
the pair programming context,we formulated 4.3.2.
325ESEC/FSE â€™22, November14Å›18, 2022,Singapore, Singapore Peter Robe,Sandeep K.Kuttal,Jake AuBuchon, andJacob Hart
Table 4: BERT precision and recall for intent and sub-intents trained on developer-agent (DA), developer-developer (DD), and
developer-developerfine-tuned by developer-agentconversations (DD>DA).
BERTIntent Delivery ProgActs Role Tone
P R P R P R P R P R
DA 80.180.080.176.6 74.4 73.7 95.2 94.6 80.2 79.9
DD 72.4 69.9 66.2 64.0 67.2 65.2 63.7 63.7 75.9 75.0
DD>DA 80.180.0 77.4 76.980.179.5 96.8 96.1 80.3 80.1
Table 5: BERT model precision and recall trained via transfer learning from developer-developer to developer-agent domains
(DD>DA). Support (#occurrences)within DD andDAdatasetsislisted; significantdifferences (blue)based on percentage.
BERTDD>DA Precision Recall F1DD Support DASupport
# % # %
Intent 80.1 80.0 79.9 3433 100 4445 100
Task Control 86.5 86.8 86.6 36 1.05 2345.25
Task-Related 75.8 80.2 77.9 921 26.83 905 20.31
Answer 58.1 50.4 53.7 126 3.67 223 5.23
Feedback 76.9 75.3 76.1 80823.54 854 19.17
Greeting 93.8 93.5 93.2 0 0 360.81
Think-Aloud 85.1 83.8 84.5 1463 42.62 2011 45.14
Thanking 79.0 82.6 80.5 4 0.12 32 0.72
Repeat 67.5 90.0 76.2 20 0.58 20 0.45
Uncertain 72.2 80.0 75.8 55 1.60 130 2.92
Delivery 77.4 76.9 76.9 957 100 1105 100
Question 88.0 80.4 83.9 125 13.06 37233.67
Recommendation 67.0 64.3 65.5 289 30.20 301 27.24
Direction 74.6 81.5 77.9 51053.29 282 25.52
Clarification 75.1 87.1 80.3 33 3.45 15013.57
Program Acts 80.1 79.5 79.1 921 100 915 100
Task Goal 85.0 81.7 83.3 134 14.55 24927.21
Comprehension 69.3 85.7 73.6 18 1.95 14 1.53
Attend Location 79.7 82.2 80.8 24 2.61 9410.27
HaltWork 80.0 70.0 73.3 3 0.33 14 1.53
Code 74.4 88.7 80.7 34737.68 302 33.01
Idea 71.9 54.8 61.5 35838.87 150 16.39
RunCode/Test 91.6 90.7 90.9 37 4.02 9210.05
Role 96.8 96.1 96.2 36 100 235 100
Driver 99.3 94.5 96.8 12 33.33 12553.19
Navigator 92.8 99.2 95.8 18 50.00 97 41.28
Either 70.0 100.0 80.0 616.67 13 5.53
Tone 80.3 80.1 80.1 934 100 1079 100
Positive 77.1 82.0 79.4 190 20.34 48945.32
Neutral 79.0 75.0 77.0 65670.24 447 41.43
Negative 94.1 90.1 91.9 88 9.42 143 13.25
We initially trained a BERT model on developer-developer data,
and subsequently fine-tuning it on developer-agent data. This two-
step approach outperformed training on exclusively developer-
developerdata(DD)by~10%onaverage.Thefirsttrainingstepuses
100%developer-developerdatafollowedbya75/10/15train/validate/test
split withdeveloper-agentdata.
Tables3and4showthatthetransferlearningapproach(DD>DA)
achievedprecisionandrecallscoresof80.0%and79.8%.Thesere-
sultsareslightlyhigher(+.1%and+.6%)thanourbaselinelanguage
modeltrainedondeveloper-agentdata(DA).Notably, Programming
Actswas the most improved, scoring +5.7% and +5.8% higher. Oth-
erwise,Intentremainedthesame(+0.0%and+0.0%),and Delivery(-2.7% and +0.3%), Role(+1.6% and +1.5%), and Tone(+0.1% and
+0.2%) saw marginal changes. Further, we performed a one-way
ANOVA testwiththethreetrainingapproachesgettingap-value
of 1.29e-10, implying a difference between the three groups. We
thenperformedat-testwiththeDDandDA,DDandDD->DA,and
DA and DD->DA, getting p-values of 4.81e-6, 5.92e-5, and 0.455,
respectively. The results from the t-test show that training with
DA and DD->DA performed interchangeably and suggests that
transferlearningfromdeveloper-developerdatamayprovidesome
utility when classifying developer-agent dialog, particularly for
programming-relatedknowledge.
326Pair ProgrammingConversationswithAgents vs. Developers: Challenges andOpportunities forSE Community ESEC/FSE â€™22, November14Å›18, 2022,Singapore, Singapore
4.3.3 DifferencesinDialogStyle. Ourresultsshowdifferencesinac-
curacy when training on developer-developer and developer-agent
conversationaldata.ThesealignwithRobeetal.[ 90]whofound
thatpairprogrammingdialogposesauniquechallengeformachine
learning, as it is often unpremeditated and inadequately structured
compared to normal conversational speech. To understand the dif-
ferences in-depth, we conducted qualitative analysis of our data to
findstylisticdifferencesinthedialogsofdeveloper-developervs.
developer-agent.
Table5comparesthefrequencies(Support)ofpairprogramming
labelsbetweenthedeveloper-developeranddeveloper-agentcon-
versations.Whilemostsub-intentsdifferedinfrequencyitisnotable
that the intent categories adopted from dialogue acts remained the
same (Answer, Thanking, and Uncertain); as these capture aspects
ofgenericconversations.
Implicit vs. Explicit Communication. Our analysis of the
supportmetricsidentifiedacommontrend:developer-developer
studies relied on more implicit means of communication while
developer-agent studies utilized more explicit questions and re-
quests. Developer-developer studies focused on the exchange of
ideas,Idea(38.87% vs. 16.39%) through the use of Directions
(53.29%vs.25.52%).However,whenworkingwithanagent,develop-
ersoftenasked Questions (13.06%vs.33.67%)and Clarifications
(3.45% vs. 13.57%) related to the Task Goal (14.55% vs. 27.21%),
Attend Location (2.61% vs. 10.27%), and Run Code /Test (4.02%
vs.10.05%).Whiledeveloperscouldeasilyprogressthroughtasks
withanotherdeveloper,developer-agentstudiesrequiredexplicit
communication which led to a higher number of Task Control
(1.05% vs. 5.25%) requests and accompanying Answers (3.67% vs.
5.23%).Forexample,indeveloper-agentstudy,theagentstated Å‚I
think we are missing codeÅ¾ Participant 7 responded with a question
Å‚ShouldIhavenottakenthatout?Å¾ .Onthecontrary,indeveloper-
developer study 2, Participant 1 as a driver was uncertain on the
implementationofcode;Participant2asanavigatorgavethedirec-
tionÅ‚So why donâ€™t we just ... write the false assertion before ... we fill
that row.Å¾ developers communicatedimplicitly inwaysthe agents
cannot.
Further,bothstudies switchedpair programmingrolesat sim-
ilar rates; however, control was communicated through formal
exchangesindeveloper-agentstudies,whilecontrolflowedmore
freelyindeveloper-developerstudies.Inordertobecomethedriver
the agent had to explicitly ask, as seen with Participant 3, Å‚Can
I drive for a bit?Å¾ . This kind of exchange happened more subtly
indeveloper-developerstudies,instudy9,Participant2gavethe
driver role to Participant 1 by saying Å‚Can you do the or thing, I
donâ€™t know where that is on thisÅ¾ . While there was still an exchange
ofrolestherewasnoexplicitdialogabouttherolesused.Thediffer-
ences in regard to explicit vs. implicit communication styles across
studiescorrespondswithpreviousresultsonuserexpectationsof
conversational agents, which found that usersassessed the intel-
ligence of agents and adapted their own behavior to the agentâ€™s
capabilities [ 69].
Pointedvs. NeutralFeedback. Participantsof thedeveloper-
agentstudymoreoftenexpressedeither Positive (20.34%vs.45.32%)
orNegative (9.42% vs. 13.25%) Tone, while developer-developer
studiesremainedmore Neutral(70.24%vs.41.43%).Whenworking
with a fellow developer, participants would often â€œnod alongÅ¾ asthe navigator, using dialog such as Å‚Okay,Å¾ Å‚Uh huh,Å¾ andÅ‚Yeah.Å¾
Thisleadto higher Feedback occurrencesindeveloper-developer
studies (23.53% vs. 19.17%). This suggests that participants were
lessworriedaboutthesocialcostofgivingtheiropinionwithan
agent,as foundinprior research [ 62].
Askingforvs.GivingOpinionsRegardingCodeVerifica-
tion.After writing code, participants (in driver role) were more
likelytoasktheagentforverificationoftheirworkusing Clari-
ification (3.45%vs.13.57%) togetherwith Code.For instance, af-
ter writing a section of code, Participant 12 asked, Å‚Are you okay
with that?Å¾ Similarly, Participant 13 asked, Å‚Is this good?Å¾ Likely,
participantsassumedthattheagentknewthecorrectanswerand
wanteditsfeedback,asParticipant9said, Å‚Itrustedthecodethat(the
agent)gavemebecauseIknewitalreadyknewtheanswer.Å¾ While
verification did occur often within developer-developer studies,
participants voiced their opinions on their own (in Navigator role),
rather than waiting for the driver to ask. For example in developer-
developer study 4, Participant 2 said Å‚Like when it equals to zero,
the three minus zeroÅ¾ , and her partner Participant 1 responded with
Å‚Oh ya ya. Definitely. Yes.Å¾ These results align with [ 63] where they
foundthatdevelopersgivemoreinstructionsandfeedbacktoother
developers as well as ask more questions to agents rather than
humans.
WeconjecturetheloweraccuracyoftheBERTmodelfordeveloper-
developer conversations was because the dialogs were more im-
plicit,neutral, andopinionatedthandeveloper-agentdialog.
5 THREATS TO VALIDITY
Wheninterpretingresultsofempiricalstudies,threatstovalidity
mustbeconsidered.Externalthreatstovaliditymayarisefromour
small datasetof 8,324 utterances.But thesedialogs were collected
from 24diverseparticipants witha widerange ofdialog, and we
release our complete set of transcripts publicly [ 3]. Additionally,
athreatmayarisefromourselectionofparticipants.Weonlyre-
cruited6professionalsforourstudiesincomparisonto26students.
Despitethisdisparity,wearguethatstudentscanbejustaseffective
asprofessionals,especiallyconsideringoursimpletask(tic-tac-toe).
Further,Koetal.[ 59]establishedthatstudentsandprofessionalsare
equivalent Å‚whentheirknowledge,skills,andexperiencesfitwithin
thetoolâ€™sintended userpopulation.Å¾
Threats to internal validity may arise based on the design of our
agent.Thisisduetothe factthatthe scope oftheagentmaynot
be representative of all pair programming agents. Further, alterna-
tive agent models may spur different kinds of dialog. However, the
agentâ€™s interactions and capabilities were informed from a breadth
ofresearchinavarietyofdomainsandrepresentsanelegantan-
thropomorphic agent design [ 91]. Further, there are possible errors
that may have arisen in our manual labeling process. Additionally,
ourhierarchymaynotencompassallpossiblepair-programming
specificlabels.Weattemptedtomitigatethesethreatsbyfollowing
state-of-the-artdata collection, labeling,andprocessing methods.
Construct threats arise from the simplicity of our task. We have
notconsideredhowdeveloper-agentdatamightchangewithdialog
frommorecomplextasks(e.g.,APIs,recursion,classhierarchies).
Butoursimpletaskwasessentialforevaluatingthefeasibilityof
transformer-basedlanguagemodels andtransfer learning.
327ESEC/FSE â€™22, November14Å›18, 2022,Singapore, Singapore Peter Robe,Sandeep K.Kuttal,Jake AuBuchon, andJacob Hart
6 OPPORTUNITIES FORSE COMMUNITY
The implementation of a pair-programming conversational agents
for developers encompasses challenges that present opportunities
for further research.
6.1 CreatingPair ProgrammingBenchmark
AkeytosuccessinemergingAIresearch,suchasconversational
agentsistheavailabilityofopenbenchmarkssuchasMultiWOZ
[21], PERSONA-CHAT [ 39], AVSD [ 38], Alexa Prize Data [ 36], and
SWITCHBOARD[ 46].Eachbenchmarktargetsdataforspecificap-
plicationsand domains[ 43];for example, MultiWOZis comprised
of10-thousand touristreservationdialogs.Creatingabenchmark
dataset is challenging, in AI, researchers have collected benchmark
datasets using various mechanismssuch as participant compensa-
tion platforms like Amazon Mechanical Turk (MultiWoz), live user
interactionsfromAlexaPrizecompetitions[ 36],websitessuchas
Reddit and Twitter (DSTC [ ?]), and Bing usersâ€™ search queries (MS
MARCO [ 75]). Currently, our dataset consists of dialogs related
to the implementation of a tic-tac-toe game, but more data must
be collected for different tasks to increase the robustness of future
conversational agentsfor programming.Ourdataset laysground-
worktowardthecreationofaholisticbenchmarkdatasetforpair
programming.Thoughprogresshasbeenmade,weasasoftware
engineering community need to collect robust conversational data
allowing researchers and practitioners to more easily develop and
compare conversational agentsandpedagogical tools.
6.2 Generalizability forTraining Data
A pair programming conversational agent must be generalizable
acrossanynumberoftaskobjectives,codebases,orprogramming
languages,andtherefore,mustbetrainedoveradiverserangeofap-
plications.Itisimpracticaltorelysolelyondeveloper-agentdatafor
trainingduetothehighcostofconductingWoZsimulations.Hence,
usageofexistingdeveloper-developerconversationsavailablevia
onlineresourcescan beintegrated throughtransferlearning.Our
paperdemonstratedthefeasibilityofusingtransferlearningand
our transfer-learning model (DD->DA) was only marginally better
(+0.1%and+0.6%)thanourbaselinedeveloper-agentmodel(DA).
Previously,Ahmadvandetal.[ 6]achievedanadditional2.7%im-
provement using transfer learning from human-human to human-
agentcontextsontheirownconvolutionneuralnetwork(CDAC
model) using a benchmark dataset, SWITCHBOARD (spontaneous
telephone speech) and fine-tuning with an Alexa Prize dataset (so-
cialbotinteractions).Theyfoundthatfine-tuningthemodelwith
asmallamountofhuman-agentconversationshelpsimproveac-
curacy. Future research must identify the optimal ratio of training
data from developer-developer and developer-agent conversations
toachieveoptimalresultswhilealsolimitingthecostofdatacol-
lection.
Anotherpromisingavenueisutilizingunsupervisedpre-training,
a common technique to tailor deep-learning language models to
specific domains. TOD-BERT [ 37], a BERT model, was pre-trained
on human-human task-oriented datasets via unsupervised masked
language modeling, outperforming the baseline BERT model for
natural language understanding of conversational agents. These
pre-trainedtechniquescanhelpinreducingthecostofmanually
Figure3:ArchitectureDiagramForConversationAgent.Nat-
ural Language Understanding component is addressed in
thispaper.Thefutureresearchneedstoexploreothercom-
ponents.
labeling data for specific domains; however, this technique still
needsto be exploredinthis domain.
6.3 Implementing Conversational Agent
PlatformsfordevelopingconversationalagentssuchasIBMWat-
sonAssistant[ 50],SAPConversationalAI[ 2],andOracleDigital
Assistant[ 82]cannotbeusedbecausetheyfocusonsimple/basic
enterprise problems such as answering questions and solving tasks
based on web or enterprise data. A conversational agent for pair
programming depends strongly on unique aspects such as code
state, test cases, success and errors obtained by interacting with an
IDE. Also, stylistic differences between pair programming and nor-
mal conversations require an alternative feature selection strategy
whenusingmachinelearningalgorithms.Hence,theconversational
agentanditâ€™scomponentsneedto be developedfrom scratch.
Figure3shows the overall architecture and related components
ofaconversationalagent.Apairprogrammingconversationalagent
should be able to track developerâ€™s dialog as well as programming
states on IDE (to implement Dialogue State Tracking), generate
policy based on developers context (Dialogue Policy), and generate
responsestothedeveloper(NaturalLanguageGeneration).Forcode
generation we can either rely on the previously collected samples
or future work should explore utilizing tools such as CodeBERT
[41]andCopilot[ ?]to generatecode.
6.4 Implications forTools
6.4.1 Virtual Question/Answer Agent. We classified developersâ€™
questions from our developer-agent studies that can be utilized
forcreatingavirtualQuestion/Answer(Q/A)agent.Ourqualitative
analysis showed that developers desired continuous feedback from
theagentasseenbyanincreasein Question s(13.06%vs.33.67%)
andClarification s (3.45% vs. 13.57%). These results align with
past research [ 55], showing developer pairs tend to verify software
development progress and tend to ask more questions when work-
ingwithanagent.Weanalyzedourtranscriptsforany Question or
Clarification aswellas Recommendation labelsthatexpectedan
immediateresponsefromouragentandusingopencodingprocess
(see Section 3.2.1)identifiedthe questions asked by participants to
ouragent(Table 6).Outofthe23questiontypesidentifiedinour
studies,onlyfourweresimilartopreviousresearchthatinvestigated
developersâ€™questions:(1)Sillitoetal.[ 101]categorized44question
typesthatdevelopersaskedduringasoftwareevolutiontaskand(2)
Ko et al. [ 58,60] explored developerâ€™s information needs. The low
328Pair ProgrammingConversationswithAgents vs. Developers: Challenges andOpportunities forSE Community ESEC/FSE â€™22, November14Å›18, 2022,Singapore, Singapore
Table6:Thetypesofquestionsparticipantsaskedduringthe
developer-agentstudyandtheirrespectiveoccurrences."*"
representsquestions fromprevious research[ 58,60,101]
QuestionType #ClarifyWho should be driver/navigator? 52
Whatshould we donext? 46
Should this user story/functionality be implemented? 8
Is this functionalityimplementedyet? 1
Total 107ImplementIs this ideavalid? 37
HowdoI writethis code? 23
Whatare you thinking? 20
What is the purpose of this code? How is it imple-
mented?*9
Are there alternative solutions? 7
Where isthe entity? 7
Shouldwe remove this code? 3
Where should this code be written? 3
Whatvariable should we return? 2
Where is the code involved in the implementation of
this behavior?*2
Where isthe entity namedsomething like this?* 1
Whatare the arguments to this function?* 1
Whatshould the name ofthis entity be?* 1
Documentation-related Å› e.g.,Å‚What asserts can I
do?Å¾1
Total 118TestShouldwe test it? 16
Is the code complete/correct? 17
Whyisthere an error? 10
Study-related Å›e.g.,Å‚Whereis theuserstories?Å¾ 5
Howdowe knowitworks? 1
Total 51
correlation is because (1) previous research identified questions re-
gardingcodeevolutionratherthanpotentialsolutions,and(2)more
advanced questions related to variable types or class hierarchies
anddidnotmanifestwithoursimpletaskoftic-tac-toe.Theseques-
tions canbe utilizedfor qualitative analysisof pair-programming
conversations as well as creating Q/Aassistants.
6.4.2 IntelligentTutoring Systems. Howdeveloperscommunicate
andthetypesofquestionstheyaskcanbeusefulinotherprogram-
mingrelatedapplications,suchasintelligenttutoringsystems(ITS)
and assisting developers with disabilities. Future ITS agents should
be designedtobe explicitsincedevelopersprefer explicitcommu-
nication with agents. Researchers and practitioners of ITSs can
design their agents to support more precise dialog. Furthermore,
allofourclassifiers,exceptfor role,canbeutilizedbyITSs,specif-
icallyfocusedonprogramming.Finally,abetterunderstandingof
these differences allows us to make programming more accessible.
Past research [ 71,93,104] has revealed different ways in which
programmingislargelyinaccessibletothosewhoarevisuallyim-
paired.Bycreating interactive tools suchas conversationalagentsand virtual Q/A assistants, we open up the world of programming
to more diversedevelopers, includingthe visually impaired.
6.4.3 Supporting Software Engineering Activities. A fully imple-
mented conversational agent can be adapted to support current
botsforsoftwareengineeringtasks[ 5,32,66,70,81,98,109,123]to
provideamoreimmersiveconversationalagentthatcommunicates
viavoice throughapersona.
7 CONCLUSIONS
Oursisthefirststudythatcollecteddeveloper-agentconversational
data,generatedsoftwareengineeringspecificlabels,investigated
theefficacyofusingtransformer-basedlanguagemodels,andex-
plored the feasibility of transfer learning for pair programming
conversations. Our paper makes the following contributions: (1)
We provide hierarchical label scheme for developersâ€™ intent, de-
velopedusingamanualopencodingprocessandtailoredforpair
programmingagents.Oursetoflabelscanbeusedforbothmachine
learningalgorithmsaswellasmetricsforqualitativeanalysisofpair
programmingconversations.(2)Wemanuallylabeledtranscripts
ofutterancesfordeveloper-agent(4,443)anddeveloper-developer
(3,436) with our hierarchical labels. Our dataset serves as a starting
point for the creation of a future pair programming benchmark
dataset. For reproducibility, our data can be found at [ 3]. (3) We
gatheredandcategorizedquestionsthatdevelopersaskedouragent.
(4) We demonstrated the applicability of transfer learning between
developer-developer and developer-agent data for an agent and
establishedtheutilityofusingtransformer-basedlanguagemod-
els for developer-agent dialog. Our results have implications for
programming virtualQ/Aassistants, intelligenttutoringsystems,
and bots that support software engineering activities. Addition-
ally,wehighlightopportunitiesforresearchersandpractitioners
tocreateapair-programmingbenchmarkdataset,continuallyex-
ploreavenuesthatwillincreasethegeneralizabilityoftrainingdata,
and implementthe remainingcomponents of a pair-programming
agent.
ACKNOWLEDGMENTS
This material is based upon work supported by the Air Force Of-
ficeofScientificResearch under award numberFA9550-21-1-0108
andNationalScienceFoundation(CAREER)underawardnumber
2046205. Any opinions, findings, and conclusions or recommenda-
tions expressed in this material are those of the authors and do not
necessarily reflectthe viewof the NSF andAFOSR.
REFERENCES
[1]2020. Chatbot Statistics. https://www.smallbizgenius.net/by-the-numbers/
chatbot-statistics/#gref
[2]2020. SAP Conversational AI. https://www.sap.com/products/conversational-
ai.html
[3]2021. Wizardâ€™sScript,LabeledDataset,andModelData. https://drive.google.
com/drive/folders/1QJJsV_HbxLfwXx5xttdXDw6TvZxctNfp?usp=sharing
[4]Ahmad Abdellatifand etal. 2020. Challenges in Chatbot Development: A Study
ofStackOverflowPosts . ACM,174Å›185.
[5]Ahmad Abdellatif and Emad Shihab. 2020. MSRBot: Using Bots to Answer
QuestionsfromSoftwareRepositories. EmpiricalSoftwareEngineering 25(2020),
1834Å›1863. Issue 3.
[6]Ali Ahmadvand, J. Choi, and Eugene Agichtein. 2019. Contextual Dialogue Act
Classification for Open-Domain Conversational Agents. SIGIR(2019).
[7]B.Al-AniandD.Redmiles.2009.InStrangersWeTrust?FindingsofanEmpirical
Studyof Distributed Teams.In ICGSE. 121Å›130.
329ESEC/FSE â€™22, November14Å›18, 2022,Singapore, Singapore Peter Robe,Sandeep K.Kuttal,Jake AuBuchon, andJacob Hart
[8]S.Ali,L.C.Briand,H.Hemmati,andR.K.Panesar-Walawege.2010.ASystematic
Review of the Application and Empirical Investigation of Search-Based Test
Case Generation. TSE(2010), 742Å›762.
[9]Teresa M. Amabile and Michael G. Pratt. 2016. The dynamic componential
modelof creativityand innovation in organizations:Makingprogress,making
meaning. Research inOrganizationalBehavior (2016), 157Å› 183.
[10]Erik Arisholm, Hans Gallis, Tore DybÃ¥, and Dag SjÃ¹berg. 2007. Evaluating Pair
ProgrammingwithRespecttoSystemComplexityandProgrammerExpertise.
TSE(2007), 65Å›86.
[11]Zahra Ashktorab, Mohit Jain, Q. Vera Liao, and Justin D. Weisz. 2019. Resilient
Chatbots: Repair Strategy Preferences for Conversational Breakdowns. In CHI.
[12]J.L.Austin,J.L.Austin,J.O.Urmson,J.O.Urmson,andM.SbisÃ .1975. HowtoDo
Thingswith Words . Harvard UniversityPress.
[13]Prashant Baheti, Dr Gehringer, and P. Stotts. 2002. Exploring the Efficacy of
Distributed Pair Programming.
[14]Gustavo E. A. P. A. Batista, Ronaldo C. Prati, and Maria Carolina Monard. 2004.
AStudyoftheBehaviorofSeveralMethodsforBalancingMachineLearning
Training Data. SIGKDD Explor. Newsl. (2004), 20Å›29.
[15]Kent Beck. 2002. Test Driven Development: By Example . Addison-Wesley Long-
manPublishing Co., Inc.
[16]ShaiBen-David,JohnBlitzer,KobyCrammer,AlexKulesza,FernandoPereira,
and Jennifer Vaughan. 2010. A theory of learning from different domains.
MachineLearning (2010), 151Å›175.
[17]BruceL.BergandHowardLune.2017. QualitativeResearchMethodfortheSocial
Sciences. Pearson EducationLimited.
[18]Timothy Bickmore and Justine Cassell. 2001. Relational agents: a model and
implementation of buildingusertrust. In CHI. 396Å›403.
[19]Nick C. Bradley, Thomas Fritz, and Reid Holmes. 2018. Context-Aware Conver-
sationalDeveloper Assistants. In ICSE. ACM,993Å›1003.
[20]Jacob T. Browne. 2019. Wizard of Oz Prototyping for Machine Learning Experi-
ences.In CHIEA. 1Å›6.
[21]PaweÅ‚ Budzianowski and et al. 2018. MultiWOZ - A Large-Scale Multi-Domain
Wizard-of-Oz Datasetfor Task-OrientedDialogue Modelling.In Conference on
Empirical Methods in Natural Language Processing . Association for Computa-
tionalLinguistics,5016Å›5026.
[22]FabioCalefato,FilippoLanubile,FedericoMaiorano,andNicoleNovielli.2017.
Sentiment Polarity Detectionfor SoftwareDevelopment. CoRR(2017).
[23]ChristopherPCerasoli,JessicaMNicklin,andMichaelTFord.2014. Intrinsic
motivation and extrinsic incentives jointly predict performance: A 40-year
meta-analysis. Psychological bulletin (2014), 980.
[24]Yu-AnChung,Hung-YiLee,andJamesGlass.2018.SupervisedandUnsupervised
TransferLearningfor Question Answering.
[25]FabioQBdaSilva,CatarinaCosta,ACesarCFranca,andRafaelPrikladinicki.
2010. Challenges and solutions in distributed software development project
management: A systematic literaturereview. In ICGSE. 87Å›96.
[26]N.DahlbÃ¤ck,A.JÃ¶nsson,andL.Ahrenberg.1993. WizardofOzstudies:why
and how. In Internationalconference onIntelligentuserinterfaces . 193Å›200.
[27]ZihangDaiandetal.2019. Transformer-XL:AttentiveLanguageModelsBeyond
a Fixed-Length Context. CoRR(2019).
[28]M. Day, M. R. Penumala, and J. Gonzalez-Sanchez. 2019. Annete: An Intelligent
Tutoring Companion Embedded intothe EclipseIDE.In CogMI. 71Å›80.
[29]Edward L Deci, Anja H Olafsen, and Richard M Ryan. 2017. Self-determination
theory in work organizations: The state of a science. Annual Review of Organi-
zationalPsychology and OrganizationalBehavior (2017), 19Å›43.
[30]JacobDevlin,Ming-WeiChang,KentonLee,andKristinaToutanova.2018.BERT:
Pre-training of Deep Bidirectional Transformers for Language Understanding.
arXiv preprint arXiv:1810.04805 (2018).
[45]]dstc7DialogSystemTechnologyChallenges[n.d.]. DialogSystemTechnology
Challenges. http://workshop.colips.org/dstc7/
[32]James Dominic and et al. 2020. Conversational Bot for Newcomers Onboarding to
OpenSourceProjects . ACM,NewYork, NY, USA,46Å›50.
[33]Felipe Ebert, Fernando Castor, N. Novielli, and A. Serebrenik. 2018. Commu-
nicativeintention in codereviewquestions.In ICSME. IEEE,519Å›523.
[34]Hamza Ed-Douibi and et al. 2020. OpenAPI Bot: A Chatbot to Help You Un-
derstand REST APIs. In Web Engineering . Springer International Publishing,
538Å›542.
[35]LindaErlenhov,FranciscoGomesdeOliveiraNeto,RiccardoScandariato,and
Philipp Leitner. 2019. Current and Future Bots in Software Development. In
BotSE (BotSEâ€™19) . IEEE Press,7Å›11.
[36]AshwinRametal.2018. ConversationalAI:TheScienceBehindtheAlexaPrize.
CoRR(2018).
[37]Chien-Sheng Wu et al. 2020. TOD-BERT: Pre-trained Natural Language Under-
standing for Task-Oriented Dialogue.
[38]Huda AlAmri et al. 2018. Audio Visual Scene-Aware Dialog (AVSD) Challenge
at DSTC7. CoRR(2018).
[39]Saizheng Zhang et al. 2018. Personalizing Dialogue Agents: I have a dog, do
you havepets too? CoRR(2018).[40]Tom B. Brown et al. 2020. Language Models are Few-Shot Learners. CoRR
(2020).
[41]Zhangyin Feng et al. 2020. CodeBERT: A Pre-Trained Model for Programming
and Natural Languages. CoRR(2020).
[42]Carmen Fischer, Charlotte P. Malycha, and Ernestine Schafmann. 2019. The
InfluenceofIntrinsicMotivationandSynergisticExtrinsicMotivatorsonCre-
ativity and Innovation. FrontiersinPsychology (2019), 137.
[43]JianfengGao,MichelGalley,andLihongLi.2018. NeuralApproachestoConver-
sationalAI.In ConferenceonResearch&DevelopmentinInformationRetrieval .
1371Å›1374.
[44]AlexGerdes,BastiaanHeeren,JohanJeuring,andL.ThomasvanBinsbergen.
2016. Ask-Elle:anAdaptableProgrammingTutorforHaskellGivingAutomated
Feedback. InternationalJournal ofArtificial IntelligenceinEducation (2016).
[45] ]copilotGitHub. [n.d.]. Copilot. https://copilot.github.com/
[46]JohnJ.Godfrey,EdwardC.Holliman,andJaneMcDaniel.1992.SWITCHBOARD:
TelephoneSpeech CorpusforResearchandDevelopment. In ICASSP-Volume1 .
517Å›520.
[47]Shashij Gupta, Pinjia He, Clara Meister, and Zhendong Su. 2020. Machine
Translation Testingvia Pathological Invariance . 863Å›875.
[48]M. Hijjawi, Z. Bandar, and K. Crockett. 2013. Userâ€™s utterance classification
using machine learning for Arabic Conversational Agents. In ICCSIT. 223Å›232.
[49]ScottHudsonandetal.2003. PredictingHumanInterruptibilitywithSensors:
AWizard of Oz FeasibilityStudy. In CHI. 257Å›264.
[50]IBM Watson Assistant 2021. IBM Watson Assistant. https://cloud.ibm.com/
apidocs/assistant/assistant-v2
[51]Hal III. 2009. Frustratingly Easy Domain Adaptation. Annual Meeting of the
Associationfor ComputationalLinguistics (2009).
[52]MdRakibulIslamandMinhazF.Zibran.2017. LeveragingAutomatedSentiment
Analysis in SoftwareEngineering.IEEE Press,203Å›214.
[53]Ewa Kacewicz, James W. Pennebaker, Matthew Davis, Moongee Jeon, and
Arthur C. Graesser. 2014. Pronoun Use Reflects Standings in Social Hierar-
chies.Journal ofLanguage and Social Psychology (2014), 125Å›143.
[54]PeterH.Kahnandetal.2008. DesignPatternsforSocialityinHuman-Robot
Interaction.In HRI. 97Å›104.
[55]SandeepKaurKuttal,KevinGerstner,andAlexandraBejarano.2019. Remote
Pair Programming in Online CS Education: Investigating through a Gender
Lens.InVL/HCC. 75Å›85.
[56]ImanKeivanloo,JuergenRilling,andYingZou.2014. SpottingWorkingCode
Examples.In ICSE. 664Å›675.
[57]Kisub Kim and et al. 2018. FaCoY: A Code-to-Code Search Engine. In ICSE.
946Å›957.
[58]Andrew J. Ko, Robert DeLine, and Gina Venolia. 2007. Information Needs in
Collocated SoftwareDevelopmentTeams.In ICSE. 344Å›353.
[59]AndrewJ.Ko,ThomasD.LaToza,andMargaretM.Barnett.2015. Apractical
guide to controlled experiments of software engineering tools with human
participants. ESEJ(2015), 110Å›141.
[60]AndrewJ.KoandBradA.Myers.2009. FindingCausesofProgramOutputwith
the JavaWhyline. In CHI. 1569Å›1578.
[61]S. K. Kuttal, J. Myers, S. Gurka, D. Magar, D. Piorkowski, and R. Bellamy. 2020.
Towards Designing Conversational Agents forPair Programming:Accounting
for Creativity Strategies and Conversational Styles.In VL/HCC. 1Å›11.
[62]Sandeep Kaur Kuttal, Bali Ong, Kate Kwasny, and Peter Robe. 2021. Trade-Offs
forSubstitutingaHumanwithanAgentinaPairProgrammingContext:The
Good,the Bad, and the Ugly. In CHI. Article243, 20pages.
[63]S.K. Kuttal,A.Sedhain,andJ.AuBuchon. 2021. Designinga Gender-Inclusive
Conversational Agent For Pair Programming: An Empirical Investigation. In
ArtificialIntelligenceinHCI ,H.DegenandS.Ntoa(Eds.).SpringerInternational
Publishing,59Å›75.
[64]Thomas K Landauer. 1987. Psychology as a mother of invention. ACM SIGCHI
Bulletin(1987), 333Å›335.
[65]Clayton Lewis. 1982. Using the "thinking-aloud" method in cognitive interface
design. IBM T.J.WatsonResearchCenter.
[66]Chun-TingLin,Shang-PinMa,andYu-WenHuang.2020. MSABot:AChatbot
Framework for Assisting in the Development and Operation of Microservice-Based
Systems. ACM,NewYork, NY, USA,36Å›40.
[67]Kate Lister, Tim Coughlan, Francisco Iniesto, Nick Freear, and Peter Devine.
2020. Accessible Conversational User Interfaces: Considerations for Design. In
InternationalWeb for All Conference . ACM.
[68]Dapeng Liu, Andrian Marcus, Denys Poshyvanyk, and Vaclav Rajlich. 2007.
Feature Location via Information Retrieval Based Filtering of a Single Scenario
ExecutionTrace. In ASE. 234Å›243.
[69]Ewa Luger and Abigail Sellen. 2016. "Like Having a Really Bad PA": The Gulf
betweenUser Expectation and Experienceof ConversationalAgents . 5286Å›5297.
[70]Christoph Matthies, Franziska Dobrigkeit, and Guenter Hesse. 2019. An Ad-
ditionalSetof(Automated)Eyes:ChatbotsforAgileRetrospectives.In BotSE
(BotSEâ€™19) . IEEE Press,34Å›37.
[71]Sean Mealin and Emerson Murphy-Hill. 2012. An exploratory study of blind
softwaredevelopers.In VL/HCC. 71Å›74.
330Pair ProgrammingConversationswithAgents vs. Developers: Challenges andOpportunities forSE Community ESEC/FSE â€™22, November14Å›18, 2022,Singapore, Singapore
[72]Meiliana, Irwandhi Septian, Ricky Setiawan Alianto, Daniel, and Ford Lumban
Gaol. 2017. Automated Test Case Generation from UML Activity Diagram and
Sequence Diagram using Depth First Search Algorithm. Procedia Computer
Science(2017), 629Å› 637.
[73]MatheusMonteiro,EricaSouza,AndreEndo,andNandamudiVijaykumar.2019.
Analyzinggraph-basedalgorithms employedtogeneratetestcasesfromfinite
state machines. In IEEE LATS .
[74]Lili Mou and et al. 2016. How Transferable are Neural Networks in NLP Appli-
cations?. In EMNLP. 479Å›489.
[75]MS MARCO 2016. MS MARCO Dataset. https://microsoft.github.io/msmarco/
[76]GunterMussbacherandetal. 2020. TowardsanAssessmentGridforIntelligent
ModelingAssistance. In MODELs. ACM,10pages.
[77]Mahdi Namazifar, Alexandros Papangelis, Gokhan Tur, and Dilek Hakkani-TÃ¼r.
2020. Language Model is All You Need: Natural Language Understanding as
Question Answering. arXiv preprint arXiv:2011.03023 (2020).
[78]Dat Quoc Nguyen, Thanh Vu, and Anh Tuan Nguyen. 2020. BERTweet: A
pre-trained languagemodelfor English Tweets. CoRR(2020).
[79]J. Noll, S. Beecham, and I. Richardson. 2011. Global Software Development and
Collaboration:Barriersand Solutions. ACMInroads (2011), 66Å›78.
[80]MasayukiOkamoto,YeonsooYang,andToruIshida.2001. WizardofOzMethod
for Learning Dialog Agents. In Cooperative Information Agents V , Matthias
Kluschand FrancoZambonelli(Eds.).SpringerBerlin Heidelberg, 20Å›25.
[81]DuÅ¡an OkanoviÄ‡ and et al. 2020. Can a Chatbot Support Software Engineers
withLoadTesting?ApproachandExperiences.In ICPE.ACM,NewYork,NY,
USA,120Å›129.
[82]Oracle Digital Assistant 2021. Oracle Digital Assistant. https://www.oracle.
com/solutions/chatbots/
[83]Luca Pascarella, Davide Spadini, Fabio Palomba, Magiel Bruntink, and Alberto
Bacchelli.2018. Information Needs in Contemporary CodeReview. Proc. ACM
Hum.-Comput. Interact. (2018), 27pages.
[84]Alec Radford and et al. 2019. Language models are unsupervised multitask
learners. OpenAI blog (2019).
[85]MukundRaghothaman,YiWei,andYoussefHamadi.2016. SWIM:Synthesizing
What iMean: CodeSearch and Idiomatic Snippet Synthesis. In ICSE. 357Å›367.
[86]P. Rane. 2017. Automatic Generation of Test Cases for Agile using Natural
Language Processing.
[87]EugÃ©nio Ribeiro, Ricardo Ribeiro, and David Martins de Matos. 2019. Recon-
hecimento de Actos de DiÃ¡logo HierÃ¡rquicos e Multi-Etiqueta em Dados em
Espanhol. LinguamÃ¡tica (2019), 17Å›40.
[88]LaurelDRiek.2012. Wizardofozstudiesinhri:asystematicreviewandnew
reporting guidelines. Journal ofHuman-RobotInteraction (2012), 119Å›136.
[89]Verena Rieser and Oliver Lemon. 2011. Reinforcement Learning for Adaptive
Dialogue Systems: A Data-Driven Methodology for Dialogue Management and
Natural Language Generation . SpringerPublishing Company, Incorporated.
[90]PeterRobe,SandeepKaurKuttal,YunfengZhang,andRachelBellamy.2020. Can
Machine Learning Facilitate Remote Pair Programming? Challenges, Insights &
Implications.In VL/HCC. 1Å›11.
[91]PeterRobeandSandeepKaurKuttal.2022. DesigningPairBuddyÅ›Conversational
Agent for PairProgramming . Vol. 29. 1Å›13. Issue 4.
[92]Fernando J. RodrÃ­guez, Kimberly Michelle Price, and Kristy Elizabeth Boyer.
2017. Exploring the Pair Programming Process: Characteristics of Effective
Collaboration.In TechnicalSymposiumonComputerScienceEducation .507Å›512.
[93]JaimeSÃ¡nchezandFernandoAguayo.2005. BlindLearnersProgrammingthrough
Audio. ACM,1769Å›1772.
[94]Anita Sarma, Xiaofan Chen, Sandeep Kuttal, Laura Dabbish, and Zhendong
Wang. 2016. Hiring in the Global Stage: Profiles of Online Contributions. In
ICGSE. 1Å›10.
[95]T.Savage,M.Revelle,andD.Poshyvanyk.2010. FLAT3:featurelocationand
textual tracing tool. In ICSE. 255Å›258.
[96]C. B. Seaman. 1999. "Qualitative Methods in Empirical Studies of Software
Engineering". TSE(1999), 557Å›572.
[97]John R. Searle. 1969. Speech Acts: An Essay in the Philosophy of Language .
CambridgeUniversityPress.
[98]LuizPhilipeSerranoAlves,IgorScalianteWiese,AnaPaulaChaves,andIgor
Steinmacher. 2022. How to Find My Task? Chatbot to Assist Newcomers in
Choosing Tasks in OSS Projects. In Chatbot Research and Design . Springer
International Publishing,90Å›107.[99]Lee Seung-Ik and Cho Sung-Bae. 2001. An Intelligent Agent With Structured
PatternMatching for a Virtual Representative . 305Å›309.
[100]ChengchengShaoandetal.2018. Thespreadoffakenewsbysocialbots. Nature
Communication 13(2018).
[101]JonathonSillito, Gail C. Murphy, andKris DeVolder. 2008. Asking andAnswer-
ingQuestionsduring aProgrammingChange Task. TSE(2008), 434Å›451.
[102]M.W.van.Someren,Y.F.Barnard,andJ.Sandberg.1994. Thethinkaloudmethod
:a practical guide tomodellingcognitiveprocesses . Academic Press.
[103] JÃ¶rg Spieler. 2020. UCDetector . Open Source. http://www.ucdetector.org/
[104]Andreas Stefik, Roger Alexander, Robert Patterson, and Jonathan Brown. 2007.
WAD:AFeasibilitystudyusing the Wicked Audio Debugger. In ICPC. 69Å›80.
[105]Andreas Stolcke and et al. 2000. Dialogue Act Modeling for Automatic Tagging
and Recognition of Conversational Speech. Computational linguistics (2000),
339Å›373.
[106]Baochen Sun, Jiashi Feng, and Kate Saenko. 2016. Return of Frustratingly Easy
DomainAdaptation.In Conference onArtificial Intelligence . 2058Å›2065.
[107]Alexey Svyatkovskiy, Shao Kun Deng, Shengyu Fu, and Neel Sundaresan. 2020.
IntelliCodeCompose:CodeGeneration UsingTransformer . 1433Å›1443.
[108]Cecilia Torres, Walter Franklin, and Laura Martins. 2019. Accessibility in Chat-
bots:The State ofthe Art inFavor ofUsers with Visual Impairment . 623Å›635.
[109]SimonUrli,ZhongxingYu,LionelSeinturier,andMartinMonperrus.2018. How
to Design a Program Repair Bot? Insights from the Repairnator Project. In
ICSE-SEIP (ICSE-SEIP â€™18) . ACM,NewYork, NY, USA,95Å›104.
[110]AlexandriaVailandKristyBoyer.2014. IdentifyingEffectiveMovesinTutoring:
Onthe Refinementof Dialogue Act Annotation Schemes.199Å›209.
[111]GiovanniViviani,MichalisFamelis,XinXia,CalahanJanik-Jones,andGailC.
Murphy.2019. Locatinglatentdesigninformationindeveloperdiscussions:a
studyonpullrequests. IEEE TSC (2019), 1402Å›1413.
[112]GiovanniViviani,CalahanJanik-Jones,MichalisFamelis,andGailC.Murphy.
2018. TheStructureofSoftwareDesignDiscussions.In CHASEWorkshop .ACM,
104Å›107.
[113]Deze Wang, Wei Dong, and Shanshan Li. 2020. A Multi-Task Representation
Learning Approachfor SourceCode . 1Å›2.
[114]HanWang,ChunyangChen,ZhenchangXing,andJohnGrundy.2020. DiffTech:
AToolforDifferencingSimilarTechnologiesfromQuestion-and-AnswerDiscus-
sions. 1576Å›1580.
[115]Pierreetal.Wargnier.2016. Fieldevaluationwithcognitively-impairedolder
adults of attention management in the Embodied Conversational Agent Louise.
InSeGAH. 1Å›8.
[116]MairieliWesselandetal.2018. ThePowerofBots:CharacterizingandUnder-
standing Bots in OSS Projects. Proc. ACM Hum.-Comput. Interact. 2, Article 182
(2018).
[117]Alex C. Williams and et al. 2019. Mercury: Empowering Programmersâ€™ Mobile
WorkPracticeswith Microproductivity. In UIST. 81Å›94.
[118]JamesWilsonandDanielRosenberg.1988. Rapidprototypingforuserinterface
design. In Handbook ofhuman-computerinteraction . Elsevier, 859Å›875.
[119]Thomas et al. Wolf. 2020. Transformers: State-of-the-Art Natural Language
Processing. In Conference on Empirical Methods in Natural Language Processing:
SystemDemonstrations . Associationfor Computational Linguistics,38Å›45.
[120]Andrew Wood, Zachary Eberhart, and Collin McMillan. 2020. Dialogue Act
Classification for Virtual Agents for Software Engineers during Debugging . ACM,
462Å›469.
[121]Andrew Wood and et al. 2018. Detecting Speech Act Types in Developer
Question/Answer Conversations DuringBugRepair. In ESEC/FSE 2018 .
[122]Wenkai Xieand et al.2020. API Method RecommendationviaExplicitMatching
ofFunctionality VerbPhrases . 1015Å›1026.
[123]BowenXu,ZhenchangXing,XinXia,andDavidLo.2017. AnswerBot:Auto-
mated generation of answer summary to developersâ€™ technical questions. In
ASE. 706Å›716.
[124]Qian Yang, Aaron Steinfeld, Carolyn RosÃ©, and John Zimmerman. 2020. Re-
ExaminingWhether,Why,andHowHuman-AIInteractionIsUniquelyDifficult
toDesign. ACM,1Å›13.
[125]Zhilin Yang and et al. 2019. XLNet: Generalized Autoregressive Pretraining for
Language Understanding. CoRR(2019).
[126]Mohan Zalake and et al. 2018. Assessing the Impact of Virtual Humanâ€™s Ap-
pearance onUsersâ€™Trust Levels. In IVA. 329Å›330.
[127]Rui Zhi and et al. 2019. Toward Data-Driven Example Feedback for Novice
Programming. In IEDMS. ERIC, 218Å›227.
331