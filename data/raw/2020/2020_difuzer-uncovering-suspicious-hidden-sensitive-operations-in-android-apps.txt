Difuzer: Uncovering Suspicious Hidden Sensitive Operations inAndroid AppsJordan Samhi1, Li Li2, Tegawendé F. Bissyandé1, Jacques Klein11SnT, University of Luxembourg, Luxembourg,/f_irstname.lastname@uni.lu2Monash University, Australia,/f_irstname.lastname@monash.eduABSTRACTOne prominent tactic used to keep malicious behavior from beingdetected during dynamic test campaigns islogic bombs, where ma-licious operations are triggered only when speci/f_ic conditions aresatis/f_ied. Defusing logic bombs remains an unsolved problem inthe literature. In this work, we propose to investigate SuspiciousHidden Sensitive Operations (SHSOs) as a step towards triaginglogic bombs. To that end, we develop a novel hybrid approach thatcombines static analysis and anomaly detection techniques to un-cover SHSOs, which we predict as likely implementations of logicbombs. Concretely, D"#/u.sc%/e.sc/r.scidenti/f_ies SHSO entry-points using aninstrumentation engine and an inter-procedural data-(ow analysis.Then, it extracts trigger-speci/f_ic features to characterize SHSOs andleverages One-Class SVM to implement an unsupervised learningmodel for detecting abnormal triggers.We evaluate our prototype and show that it yields a precisionof 99.02% to detect SHSOs among which 29.7% are logic bombs.D"#/u.sc%/e.sc/r.scoutperforms the state-of-the-art in revealing more logicbombs while yielding less false positives in about one order ofmagnitude less time. All our artifacts are released to the community.ACM Reference Format:Jordan Samhi1,L iL i2, Tegawendé F. Bissyandé1, Jacques Klein1. 2022. Di-fuzer: Uncovering Suspicious Hidden Sensitive Operations in Android Apps. In44th International Conference on Software Engineering (ICSE ’22), May21–29, 2022, Pittsburgh, PA, USA.ACM, New York, NY, USA, 13 pages.https://doi.org/10.1145/3510003.35101351 INTRODUCTIONSecurity and privacy in Android have become paramount given itspervasive use in a wide range of user devices, be it handheld, athome, or in the o)ce [34]. Yet, regularly, new threats are discovered,even in the o)cial Google Play app store [18]. Typically, thousandsof apps are regularly(agged by antivirus engines: for the year 2020alone, the A/n.sc+/r.sc,Z,,[4] repository has collected over228 000apps, among which over10 000apps are(agged by at least/f_iveantivirus engines hosted by VirusTotal. Addressing the spread ofmalware in app markets is therefore a prime concern for researchersand practitioners. In the last decade, several approaches have beenproposed in the literature to automate malware identi/f_ication. Theseapproaches explore static analysis techniques [24,25,37,58,85],This work is licensed under a Creative Commons Attribution International 4.0 License.ICSE ’22, May 21–29, 2022, Pittsburgh, PA, USA© 2022 Copyright held by the owner/author(s).ACM ISBN 978-1-4503-9221-1/22/05.https://doi.org/10.1145/3510003.3510135dynamic execution [60,77,86], or a combination of both [11,17,81],as well as the use of machine-learning [59, 65].While the aforementioned techniques have been provene-ectiveon benchmarks, attacks evolve rapidly with increasingly sophisti-cated evasion techniques. Typically, malware writers rely on codeobfuscation [20] to bypass static analyses. To evade detection dur-ing dynamic analysis, attackers seek to hide malicious code behindtriggering conditions. These are known aslogic bombs, the trigger-ing conditions of which being varied. For example, a logic bombcould execute malicious instructions only at a speci/f_ic time thatis not likely to be reached when market maintainers dynamicallyanalyze the software before it is distributed.Logic bombs can be used for any malicious activity such asadware [22], trojan [61], ransomware [83], spyware [64], etc. [89].Furthermore, as the trigger and the malicious code are generallyindependent of the core application code, logic bombs can easilybe added in legitimate apps and repackaged for distribution [27,42,44,88]. Therefore, detecting logic bombs is of great importance,especially in mobile devices that carry much personal information.However, due to the undecidable nature of this detection problemin general [63], and the fact that dynamic analyses will likely failto detect such behaviors [1], analysts explore static-analysis basedheuristic or machine learning approaches to detect logic bombs.A logic bomb is characterized by the fact that it implementsa hidden sensitive operation. Therefore, recent works addressinglogic bombs have focused on the identi/f_ication of Hidden SensitiveOperations (HSOs) as a target [57]. However, not all HSOs are logicbombs. Indeed, an HSO may be neitherintentionalnormalicious,while logic bombs always are. In this work, we propose to identifySuspicious HSOs(SHSO) towards triaging logic bombs amongHSOs. Indeed, we consider that an SHSO is an HSO that is likelyimplementing a logic bomb. Further note that, in this study, we donot attempt to address a binary classi/f_ication problem of discrimi-nating malware from benign apps (e.g., by using logic bombs as akey criteria of maliciousness). Instead, our ambition is to improvethe detection of logic bombs, which are considered sweet spotsfor targeting the understanding of malware’s malicious behaviors.Indeed, while the literature proposes a variety of approaches forpredicting Android apps’ maliciousness (i.e., malware detection),the community still seeks to make signi/f_icant breakthroughs inthe location of malicious code parts. Detecting logic bombs thusprovides an opportunity to locate and characterize malicious codeimplemented as hidden sensitive operations.Recent literature on Android has already approached the prob-lem of detecting sensitive behavior triggered only when certainconditions are met. Such triggers are referred hereafter assensitivetriggers.T/r.sc"../e.sc/r.scS/,0/e.sc[26] was proposed as a static analysis tool todetect logic bombs: its analyses are based on heuristics and are thus7232022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)
ICSE ’22, May 21–29, 2022, Pi/t_tsburgh, PA, USAJordan Samhi1, Li Li2, Tegawendé F. Bissyandé1, Jacques Klein1limited to certain trigger types (i.e., time-related, location-related,and SMS-related triggers). T/r.sc"../e.sc/r.scS/,0/e.scfurther relies on symbolicexecution, which reduces its capacity to scale to massive datasets.Unlike T/r.sc"../e.sc/r.scS/,0/e.sc,H1,M"/n.sc/e.sc/r.sc[57] leverages a supervised learn-ing approach with engineered features to reveal sensitive triggers.H1,M"/n.sc/e.sc/r.sc, however, does not speci/f_ically target malicious triggers:it(ags up to20% of apps, which makes it ine)cient for isolatingdangerous triggers in the wild; it also takes on average13min/app,which makes it challenging to exploit for large-scale experiments.HSO triggering conditions are typically implemented byif state-ments. A given app code, however, may contain from hundredsto thousands of such conditional statements. Therefore, a majorchallenge in the research around HSO is to reduce the search spacefor accurately spotting suspicious sensitive triggers. Our core ideatowards achieving this ambition is to model speci/f_ic trigger charac-teristics to spot SHSOs.In this work, we propose a novel approach to identify suspicioushidden sensitive operations where we rely on an unsupervisedlearning technique to perform anomaly detection. We intend todetect suspicious triggers deviating from the normality of the myr-iads of conditional checks performed in typical apps. To do so, weexplore speci/f_ic trigger/behavior features to guide our detectionsystem towards enumerating truly suspicious triggers and thusre/f_ine the search space for uncovering logic bombs. We proposeD"#/u.sc%/e.sc/r.sc, a novel hybrid approach that combines❶code instrumen-tation to insert particular statements required for taint analysis,❷inter-procedural static taint analysis to/f_ind suspicious sensi-tive triggers, and❸anomaly detectionto revealSuspicious HiddenSensitive Operationsin Android apps.While the literature includes work [57] that proposed supervisedlearning techniques for detecting HSOs, D"#/u.sc%/e.sc/r.screlies on unsu-pervised learning to spot “abnormal” triggers. Moreover, towardsensuring that the model is accurate in the detection of suspiciousHSOs, D"#/u.sc%/e.sc/r.scleverages features that are speci/f_ically-engineeredto capture semantic properties of maliciousness.The main contributions of our work are as follows:•We propose D"#/u.sc%/e.sc/r.sc, a novel approach to detect SHSOs in An-droid apps. D"#/u.sc%/e.sc/r.sccombines code instrumentation, static inter-procedural taint tracking and anomaly detection techniques.•We evaluate D"#/u.sc%/e.sc/r.scand show its ability to reveal SHSOs witha99.02% precision in less than 35 seconds on average per app,outperforming previous approaches.•We demonstrate that the trigger- and behavior-speci/f_ic featuresof D"#/u.sc%/e.sc/r.scare relevant for triaging logic bombs among HSOs:29.7% of detected SHSOs are indeed con/f_irmed as logic bombs.•We compare D"#/u.sc%/e.sc/r.scagainst a state of the art logic bomb de-tector, T/r.sc"../e.sc/r.scS/,0/e.sc:D"#/u.sc%/e.sc/r.screveals more logic bombs thanT/r.sc"../e.sc/r.scS/,0/e.scwhile yielding less false positives.•We further applied D"#/u.sc%/e.sc/r.scon a dataset of “benign” apps fromGoogle Play. By analysing the yielded SHSOs, D"#/u.sc%/e.sc/r.sccon-tributed to suspect 8 adware apps, which Google removed fromGoogle Play after we have pointed them out.•We release the D"#/u.sc%/e.sc/r.scprototype in open-source and furthermake available to the research community the/f_irst Android logicbomb dataset, called D232B,45: https://github.com/Trustworthy-Software/Difuzer2 BACKGROUND AND DEFINITIONSIn this section, we/f_irst introduceTaint AnalysisandAnomaly De-tection, two techniques used in our approach. Then, we carefullyde/f_ine important concepts and/f_inally succinctly give the contextfor our study.Taint analysis:Taint analysis is a data(ow analysis that followsthe(ow of speci/f_ic values within a program. A variable/u1D449is taintedwhen it gets a value from speci/f_ic functions calledsources. The taintis propagated to other variables if they receive a derivation of thevalue in/u1D449. If a tainted variable is used as a parameter of speci/f_icfunctions calledsinks, it means that during execution, the valuederived from asourcecan be used as a parameter of asink. In thispaper’s context, we rely on taint analysis to check if the conditionalexpression involves sensitive data value(s).Anomaly detection:When analyzing data of the same class,several items can signi/f_icantly di-er from the majority. They arecalledoutliersand can be viewed as abnormal. There are numeroustechniques in the state-of-the-art for achieving this outlier detectionin sets of data [13]. This paper relies onOne-Class Support VectorMachine(OC-SVM) [69], an unsupervised learning algorithm thatlearns common behavior based on features extracted in an initialdataset. Once the model is learned, a prediction is performed bychecking whether a new sample features make it more or less abnor-mal w.r.t. the common model. In this paper’s context, an anomalyis computed by considering distances among vectors representingtriggers, i.e., a condition along with the behavior triggered.De/f_initions:We de/f_ine terms that will be used and referred tothroughout the paper. Figure 1 visually depicts our de/f_initions.
(a) TriggerDe/f_initions1, 2, 3(b) Hidden Sensitive OperationDe/f_inition4, 5(c) Logic BombDe/f_inition6if(/u1D70B)/u1D450∈/uni03A3/uni0393=/u1D447/u1D450∪/uni03A6/u1D450/u1D70F/u1D447/u1D450/uni03A6/u1D450if(/u1D70B)/u1D702
/u1D446⊆/u1D447/u1D450∨/u1D446⊆/uni03A6/u1D450SensitiveBehaviorif(/u1D70B)/u1D706
/u1D440⊆/u1D446MaliciousBehaviorFigure 1: De/f_initions illustrations. The graphs represent theControl-Flow Graph of the same function.De/f_inition 1(Trigger). A trigger is a piece of code that activatesoperations under certain conditions. In Figure 1a, the trigger/u1D70F(dashed rectangle) is represented by the condition/u1D450(rounded rec-tangle node), the true branch/u1D447/u1D450and the false branch/uni03A6/u1D450. The truebranch/u1D447/u1D450represents all the statements (nodes) for which each pathfrom the entry-point must go through/u1D450and are executed if andonly if/u1D70Bis true. Note that every path from the entry-point to thehatched node must go through/u1D450. In other words,/u1D450strictly domi-nates the hatched node. However, the hatched node can be executedif/u1D70Bis true or false. Therefore it is not part of/u1D447/u1D450nor/uni03A6/u1D450. The falsebranch/uni03A6/u1D450represents all the statements for which each path fromthe entry-point must go through/u1D450and are executed if and only if/u1D70Bis false.724Difuzer: Uncovering Suspicious Hidden Sensitive Operations in Android AppsICSE ’22, May 21–29, 2022, Pi/t_tsburgh, PA, USAMore formally, let/uni03A3be the set of statements of a function (nodesin Fig. 1). Let/u1D450∈/uni03A3be a conditional statement (i.e., an if statement,rectangle nodes in Fig. 1). Let/u1D70Bbe/u1D450’s predicate. Let/u1D700be the condi-tional execution function such as/u1D700(/u1D70B,/u1D70E)is true if/u1D70E∈/uni03A3is executedif and only if/u1D70Bis true. Let,be the dominator function such as,(/u1D451,/u1D70E)is true if/u1D451∈/uni03A3strictly dominates/u1D70E∈/uni03A3, false otherwise.Let/u1D447/u1D450and/uni03A6/u1D450be thetrueand thefalsebranch1of/u1D450such as:/u1D447/u1D450={/u1D70E|/u1D70E∈/uni03A3∧,(/u1D450,/u1D70E)∧/u1D700(/u1D70B,/u1D70E)}/uni03A6/u1D450={/u1D70E|/u1D70E∈/uni03A3∧,(/u1D450,/u1D70E)∧/u1D700(¬/u1D70B,/u1D70E)}Then, a trigger/u1D70Fis de/f_ined as a triplet:/u1D70F=(/u1D450,/u1D447/u1D450,/uni03A6/u1D450).De/f_inition 2(Guarded code). Let/u1D70Fbe a trigger such as:/u1D70F=(/u1D450,/u1D447/u1D450,/uni03A6/u1D450).Then, the code guarded by/u1D450is:/uni0393=/u1D447/u1D450∪/uni03A6/u1D450.De/f_inition 3(Trigger entry-point). We de/f_ine a trigger entry-pointas the condition triggering the guarded code. More formally, givena trigger/u1D70F=(/u1D450,/u1D447/u1D450,/uni03A6/u1D450),/u1D450is de/f_ined as its entry-point.De/f_inition 4(Hidden Sensitive Operation (HSO)). An HSO is apiece of code that represents a set of instructions, which (1) im-plement a security-sensitive operation and (2) are only executedwhen speci/f_ic criteria are met (cf. Figure 1b). More formally, let/u1D702=(/u1D450,/u1D447/u1D450,/uni03A6/u1D450)be a trigger and/u1D446a piece of sensitive behavior suchas/u1D446⊂/uni03A3. Then,/u1D702is a hidden sensitive operation if/u1D446⊆/u1D447/u1D450∨/u1D446⊆/uni03A6/u1D450.De/f_inition 5(Suspicious Hidden Sensitive Operation (SHSO)). AnSHSO refers to an HSO that implements a sensitive operation thatappears to be suspicious given the context of the app. For example, anavigation app may legitimately retrieve user location information(which is a sensitive operation), while a calculator is suspicious ifit attempts to retrieve such sensitive data.De/f_inition 6(Logic bomb). A logic bomb is a piece of maliciouscode triggered under speci/f_ic circumstances. More formally, let/u1D706=(/u1D450,/u1D447/u1D450,/uni03A6/u1D450)be an SHSO,/u1D446its sensitive behavior, and/u1D440a pieceof malicious code such as/u1D440⊂/uni03A3. Then,/u1D706is a logic bomb if/u1D440⊆/u1D446(cf. Figure 1c). In other words, a logic bomb is an SHSO whichsuspicious sensitive behaviour is malicious.1// Example simplified for reading, with renamed methods2public staticvoidm() {3m1();4performMaliciousActivity();5}6public staticvoidm1() {7if(m2()){8System.exit(0);9}10}11public staticbooleanm2() {12String str1=Build.MODEL;13String str2=encryptedString();// str2 =/quotedbl.VarEmulator/quotedbl.Var14returnstr1.contains(str2);15}16public staticStringencryptedString() {17String s1=/quotedbl.Varcb6624dec24f889f4fcdf6c8cda99d4a/quotedbl.Var;18returnBYDecoder.decode(s1,/quotedbl.Var0ec47edd8db3a02b/quotedbl.Var);19}Listing 1: Logic bomb identi/f_ied by D"/f.sc/u.sc/z.sc/e.sc/r.scin"com.(yingbees.BrasilTvEnvivo" with emulator evasion.In Listing 1, we summarize the general behavior of a concreteexample of a logic bomb extracted from a real-world app. This logicbomb was detected by D"#/u.sc%/e.sc/r.sc. In this example, the di-erent partsof the SHSO (including the triggering condition checks) are splitacross several methods (.1,.2,.). The actual triggering conditioncheck is done in line 3:.2 will returntrueif the device runs in1Note that in case there is no false branch,/uni03A6/u1D450=∅.an emulator and the app execution will be halted. Otherwise, themalicious behavior (line 2) will be triggered.The challenge in detecting the aforementioned logic bomb isthat analysts cannot rely on rules or models to detect it due tothe lack of a formal de/f_inition of malicious behavior. Therefore,we note that, with little coding e-ort, malware authors could pushmalicious code that will be missed in most dynamic analyses. Indeed,sandboxes and testing environments usually return default valuesfor environment variables [60]. Besides the device’s model, di-erentenvironment values (e.g., sensors, settings, GPS, remote values, etc.)can be used to trigger malicious code.Comparing to previous works, we note that the presented simpleexample of logic bomb detected by D"#/u.sc%/e.sc/r.scwould constitutea challenge to the existing state of the art. T/r.sc"../e.sc/r.scS/,0/e.sc[26]cannot identify this logic bomb. Indeed, since its heuristics arelimited to time-, location-, and SMS-related triggers, logic bombswith a new trigger (e.g., environment variable such asBuildclass/f_ields) are missed. H1,M"/n.sc/e.sc/r.sc[57] could detect this logicbomb if its training set includes similar examples. Unfortunately,H1,M"/n.sc/e.sc/r.sc (ags too many HSOs (e.g.,(20% of apps), making themanual check a cumbersome task. In contrast, D"#/u.sc%/e.sc/r.sco-ers areasonable number of warnings to be checked manually.3 APPROACHGoal:With D"#/u.sc%/e.sc/r.sc, we do not aim at detecting any HSOs, butonly suspicious HSOs (SHSOs) for which the likelihood of beinglogic bombs is high.Intuition:As shown in previous studies [57], the number of HSOsper app can be large, even in benign apps. This suggests that al-though HSOs are "sensitive" operations, most of them are legitimate,i.e., they are used to implement common behavior. In contrast, logicbombs are rare, especially in benign apps. The idea behind D"#/u.sc%/e.sc/r.scis to use an anomaly detection approach, with speci/f_ically designedfeatures, to triage logic bombs among SHSOs.Overview:In Figure 2, we present an overview of our approach,which consists of two main modules: (1) identi/f_ication of SHSOentry-point candidates via control(ow analysis, instrumentation,and taint tracking (left dotted block); (2) From these entry-points,triggers are extracted, and the second module (right dotted block)extracts speci/f_ically designed features fed into an outliers predictor.This predictor is previously trained on a set of reference apps (i.e.,apps considered benign) to learn legitimate usages of triggers.3.1 Identifying SHSO candidate entry-pointsPrevious works [3,19,55,60,73] have shown that speci/f_ic values,such as system inputs and environments variables, are often usedto trigger HSOs. State-of-the-art approaches have thus proposedto check whether the conditions ofif statementscontain thesesensitive data. To that end, they rely on symbolic execution [26]or backward data-dependency graphs [57] that could su-er fromscalability problems. With D"#/u.sc%/e.sc/r.sc, we propose to use taint analysisto track sensitive data values and check if they are involved inconditional expressions.725ICSE ’22, May 21–29, 2022, Pi/t_tsburgh, PA, USAJordan Samhi1, Li Li2, Tegawendé F. Bissyandé1, Jacques Klein1
Control FlowAnalysis
Instrumen-tationTaintTracking
TriggersExtractionFeaturesExtractionPredictionof Outliers
TrainingPhaseFeaturesExtraction
SourcesSinksSourcesSystematicStudy
ICFGLibrariesFeaturevectorsModelFeaturevectorsTriggerentry-points
SHSOEntry-Points Detection CandidatesAnomalyDetectionSuspiciousHidden Sensitive OperationsPotentiallogic bombsWhitelistsofmethodsReferenceSetTriggersTriggers
Figure 2: Overview of the D"/f.sc/u.sc/z.sc/e.sc/r.scapproach.Taint analysis tools generally track data from sources to sinks.The implementation of F6,7D/r.sc,"+, a popular taint analysis frame-work for tracking sensitive information, considers sources and sinksat the method level. In our case however, sinks are/f_ine-grainedcode locations, which are conditional expressions ofif statements.This requires for D"#/u.sc%/e.sc/r.scto instrument apps in order to insertdummy method calls that will make the apps ready for analysis byF6,7D/r.sc,"+(cf. Section 3.1.2). Moreover, sources can be methodcalls or data/f_ield accesses. To build the set of source and sinks wepropose to make a systematic mapping (cf. Section 3.1.1) that ex-plores internal and external system properties and their associatedAPIs as well as environment variables.3.1.1 Systematic mapping toward defining sources.As already ex-plained, a/f_irst step is to track sensitive values. In this work, thesevalues are derived from particular source methods. Then, if a sensi-tive value falls into anif statement, we consider the condition asa potential SHSO entry-point. This section will describe how wegathered a comprehensive list of source methods used for the tainttracking phase. Note that we did not rely on the reference sourceslist produced by S/u.scS"[5] since it has been shown that most of themethods are inappropriate for tracking sensitive data, and lead to ahigh amount of false-positives (e.g.,>80%) [36, 51, 56].In general, decisions on whether to trigger SHSOs or not aretaken on system properties [19,57,71,73]. Hence, we performed asystematic mapping of the Android framework from SDK version 3to 30 (versions 1 and 2 were unavailable) to gather a comprehensivelist of source methods. In particular, since in the case of Androidapps, system properties can be derived from the device’sinternalandexternalproperties, we inspect the successive versions of theframework to identify various means to access these properties.DeviceInternalExternalSystemContentBuildSIMInternetGPSExamplesSensors,CallLogs,Model,Phone call,Parameters,Latitude,CameraContactsHardwareSMSContentLongitudeTable 1: Examples of sensitive sourcesIn Table 1, we enumerate the di-erent property types (with ex-amples) on which we reasoned to retrieve sensitive sources, whichare classically focused on in the literature [19,57,71,73]. We fol-low a systematic process to perform the retrieval of sources fromthe given property types: we/f_irst extracted patterns from the dif-ferent ways to access the aforementioned properties. Then, weused those patterns to automatically discover the sensitive sourcesthat we make available to the research community in the D"#/u.sc%/e.sc/r.scproject’s repository. In the following, we further detail the internaland external properties that we consider.Internal:In the case of internal properties, a developer can getsensitive information of the device from three main channels: 1)System properties, 2) Content in internal databases, and 3) Informa-tion fromBUILDclass (see Table 1). In the following, we describehow we obtain a list of sources for those three channels:❶System properties: While developing an Android app, developershave access to several useful APIs. In this case, the most interestingisandroid.content.Context.getSystemService(java.lang.-String)[30] which returns the system-level handler for a givenservice. The service is described by a string given as parameter togetSystemServicemethod. TheContextclass gives developersaccess to pre-de/f_ined constants (e.g.,SENSOR_SERVICE).In fact, every constant contains the name of the service with/quotedbl.Var_SERVICE/quotedbl.Varappended to it. The return value type of thegetSystem-Servicemethod call is derived from the constant name (e.g.,SENSOR-SERVICEwill give aSensorManager[33]) which in turn can be usedto get a object whose type is also derived from the constant name(e.g., a SensorManager object can be used to obtain a Sensor ob-ject [32]). We used this pattern to compile our list of sensitivesources for the System properties. More speci/f_ically, we verify ifthe class exists in at least one SDK version for each class obtained.If this is the case, we list the methods of the class and keep only the"getter methods", i.e., those starting by "get" or "is" (e.g., methodssuch asgetId()orisWifiEnabled()).❷Content in internal databases: To access databases/f_ields, one hasto perform a query which returns aandroid.database.Cursor[31]object. This object is then used to iterate over the result of the query.Hence, to get sensitive source methods related to content in internaldatabases, we applied the same process as for system properties(i.e., to retrieve the "getter" methods) but on theCursorclass.❸Buildclass: TheBuildclass [29] allows developers to accessinformation about the current build of the device from its/f_ields.For instance, one can get the brand associated with the device byaccessingBuild.BRAND. Note that our objective is to retrieve a listof source methods. However, the information a developer can getfrom theBuildclass can only be retrieved from class/f_ields, notmethod calls. Consequently, in Section 3.1.2, we will explain howwe instrument the app under analysis to add method call statementsrepresentingBuild/f_ield accesses.We gathered a list of 618 unique methods for internal values.726Difuzer: Uncovering Suspicious Hidden Sensitive Operations in Android AppsICSE ’22, May 21–29, 2022, Pi/t_tsburgh, PA, USAExternal:In the case of external properties, a developer can getsensitive information from three channels: 1) SIM card, 2) InternetConnection, and 3) GPS chip. The process to collect the sourcemethods is similar to the one followed withCursorclass, exceptwe do not know in advance the name of the classes to inspect.Therefore we relied on a heuristic to identify such classes: for eachSDK version, we listed all the classes and kept only those with classnames containing the following words: "Sms, Telephony, Location,Gps, Internet, and Http". Once the classes were retrieved, we listedthe methods for each class and kept those starting by "get" or "is".The intuition is the same as in the case of internal sources.We gathered a list of 794 unique methods for external values.Finally, after combining sensitive sources from internal and externalvalues, our list contains 1285 unique methods (127 duplicates).3.1.2 Instrumentation.Performing taint tracking, as brie(y de-scribed in Section 2, consists of a data-(ow algorithm that propa-gates the taint from a source method to a sink method.Sinks related challenge:We remind that one objective of D"8#/u.sc%/e.sc/r.scis to identify SHSOs’ trigger entry-points. Consequently,the taints that D"#/u.sc%/e.sc/r.sctracks are supposed to fall intoif state-ments.H o w e v e r ,b e i n gnot a method call, anif statementcannot beconsidered as a sink when using state-of-the-art static taint analyz-ers [6,28,79]. A concrete example of what D"#/u.sc%/e.sc/r.sctracks is givenin Listing 2. On line 7,countryCodevariable is tainted fromgetNet-workCountryIso()source. This value is then used (line 9) to performa test and trigger malicious activity (line 9). As anif statementisnot considered a sink, a(ow cannot be found.1publicvoidmethod() {2String b=Build.BRAND;3+b=BuildClass.getBRAND();// dummy method call for field access4String p=Context.TELEPHONY_SERVICE;5Object o=this.getSystemService(p);6TelephonyManager tm=(TelephonyManager)o;7String countryCode=tm.getNetworkCountryIso();8+IfClass.ifMethod(countryCode,/quotedbl.VarRU/quotedbl.Var);// dummy method call for if statement9if(countryCode.equals(/quotedbl.VarRU/quotedbl.Var)){performMaliciousActivity(); }10}Listing 2: Example of app instrumentation performed by D")/f.sc/u.sc/z.sc/e.sc/r.sc(Lines with ”+” represent added lines).Our approach overcomes this limitation by instrumenting apps.To accomplish this, the app code is/f_irst transformed into Jimple [76],the internal representation of Soot [75]. Then, D"#/u.sc%/e.sc/r.sciterates overevery condition of the app, and for each condition, D"#/u.sc%/e.sc/r.scinsertsa dummy methodifMethodwith the variables involved in thecondition as parameters. ThisifMethod()is static and declared ina dummy classIfClassthat contains all instrumented methodsrelated to conditions. See line 8 in Listing 2.Once the instrumentation is over, we dynamically register everynewly generated method calls as sinks to F6,7D/r.sc,"+.Sources related challenge:As described in Section 3.1.1, we con-sider, in this study,Buildclass’/f_ields as sources. Since/f_ield ac-cesses are not method calls, we follow the same process as forifstatementsto insert dummy methods. More speci/f_ically, D"#/u.sc%/e.sc/r.scgenerates a static method call on-the-(y representing a/f_ield accessfrom theBuildclass. Listing 2 depicts an example of this instru-mentation process, where the dummy methodgetBRAND()of thedummy classBuildClassis inserted in line 3. Furthermore, newlygenerated method calls are registered as sources for taint tracking.3.2 Anomaly detectionThis section presents D"#/u.sc%/e.sc/r.sc’s second module, which relies onanomaly detection. In particular, we detail the unsupervised ma-chine learning technique used to detect abnormal triggers.3.2.1 Why a One-Class SVM?.A classical classi/f_ication problem re-quires samples from positive and negative classes to build a model,which is then used to assign labels to test instances [39]. This in-duces possessing a reasonable amount of samples from two classes,which is not the case in our study. Indeed, the SHSO detectionproblem is challenging, and to the best of our knowledge, there isno ground truth made publicly available. Thus, using supervisedlearning in our study is not practical and present limited feasibility.Therefore, we decided to rely on an unsupervised learning tech-nique to detect SHSOs, particularly on a One-Class Support VectorMachine (OC-SVM) machine learning technique. An SVM algorithmwas chosen due to its ability to generalize [78] and its resistanceto over-/f_itting [80]. The general idea of OC-SVM is to identify thesmallest hyper-sphere to include most of the samples of the positivesamples [84]. A sample considered as an outlier by the model meansthe data-point is not in the hyper-sphere.3.2.2 Features extraction.As already said, the second D"#/u.sc%/e.sc/r.scmodule’s objective is to detect abnormal triggers with the intuitionthat these triggers are HSOs for which the likelihood to be a logicbomb is high, namely SHSOs. This module implements an OC-SVMalgorithm which takes as input feature vectors computed from thetriggers previously extracted from the entry-points yielded by the/f_irst module of D"#/u.sc%/e.sc/r.sc(cf. Figure 2).To engineer anomaly detection features, we reviewed surveys [47,89] and related-papers [2,57,62,87] discussing Android malwareand investigated the techniques used by malware writers to hidemalicious code within apps. Eventually, we identi/f_ied nine uniquetrigger/behavior features that are described in the following.In the remainder of this section, we consider a trigger/u1D70F=(/u1D450,/u1D447/u1D450,/uni03A6/u1D450)and its guarded code/uni0393=/u1D447/u1D450∪/uni03A6/u1D450(cf. Section 2).D"#/u.sc%/e.sc/r.scbuilds a feature vector/u1D463=</u1D446,/u1D441,/u1D437,/u1D445,/u1D435,/u1D443,/u1D4401,/u1D4461,/u1D43D>for a given trigger where:S: Number of sensitive methods used in guarded code.In-tuitively, this feature represents how much a trigger controls theexecution of sensitive methods. Indeed, while HSOs guard the execu-tion of sensitive operations for performing sensitive activities [25],benign triggers, in the general case, perform benign activities, i.e.,invoke few sensitive methods, or not at all. To retrieve this value,D"#/u.sc%/e.sc/r.sciterates over every statement of/uni0393and recursively checkswhether a sensitive method is called or not. For this purpose, wegathered a list of sensitive APIs constructed in previous work [7].N: Is native code used in guarded code?Since analyzing nativecode is more challenging than Java bytecode [46], Android malwaredevelopers tend to hide malicious code from automated analysesin native code [2,62]. Hence, this feature is a boolean value that,when set to 1, means native code is used in/uni0393, 0 otherwise.D: Is dynamic loading used in guarded code?Dynamic classloading is not exclusively used in malware. However, as malware isbecoming increasingly sophisticated, they use built-in capabilitieslike dynamic loading to hide from automated analyses [87]. Conse-quently, likewise native code, this feature is a boolean value set to1 if dynamic loading is used in/uni0393, 0 otherwise.727ICSE ’22, May 21–29, 2022, Pi/t_tsburgh, PA, USAJordan Samhi1, Li Li2, Tegawendé F. Bissyandé1, Jacques Klein1R: Is re(ection used in guarded code?Android malware writerstend to use more and more re(ection-based code [87] since most ofthe state-of-the-art techniques overlook this property due to thechallenging task of resolving it. Therefore, this feature is set to 1 ifre(ection is used in/uni0393, 0 otherwise.B: Does guarded code trigger background tasks?Android appsrely on the Service component to run background tasks. Hence,with this feature, we aim at capturing the fact that the app underanalysis performs stealthy operations without user knowledge. Theintuition here is that SHSOs’ role is to hide code both from securityanalysts and end-users (e.g., in the case of a logic bomb). This featureis set to 1 if background services are triggered in/uni0393, 0 otherwise.P: Are parameters of condition used in guarded code?Thisfeature captures the dependency of a condition to its guarded code.The hypothesis is that, in the case of SHSOs, the guarded code doesnot use values used in the condition since they represent di-erentbehaviors. To achieve this, D"#/u.sc%/e.sc/r.scperforms a def-use analysisof the guarded code to verify if any variable used in the conditionis used before being assigned a new value. If this is the case, thefeature is set to 1, 0 otherwise.M1: Number of app methods called only in guarded code.With this attribute, we attempt to uncover the number of methodsde/f_ined in the app called only in the guarded code of a trigger. Therationale is that app methods that are only used under a speci/f_iccircumstance are likely to be de/f_ined only for this speci/f_ic circum-stance, representing hidden behavior [26]. To retrieve this number,D"#/u.sc%/e.sc/r.scqueries the call-graph (built using SPARK [40] algorithm)for each method call in the guarded code to verify if it has only oneincoming edge (i.e., it is only called within the current method).S1: Number of sensitive methods called only in guarded code.In the same way as M1, we aim to capture the number of sensitivemethods only used in the guarded code of a given trigger.J: Behavior diﬀerence between branches.Intuitively, two bran-ches of an SHSO should be noticeably di-erent. Indeed, of thetwo branches, one is considered the normal behavior (no or fewsensitive operations) if the condition is not satis/f_ied and the otheras the sensitive behavior (sensitive operations) if the conditionis satis/f_ied [57]. Therefore, to compute this di-erence, D"#/u.sc%/e.sc/r.sc/f_irst inter-procedurally retrieves sensitive method calls in bothbranches of a given trigger. Let/u1D44B/u1D447/u1D450and/u1D44B/uni03A6/u1D450respectively be the setsof sensitive methods in the true and the false branch of a trigger.Therefore, to compute this di-erence of the two branches, D"#/u.sc%/e.sc/r.screlies on the Jaccard distance:/u1D437/u1D457(/u1D44B/u1D447/u1D450,/u1D44B/uni03A6/u1D450)=1)|/u1D44B/u1D447/u1D450∩/u1D44B/uni03A6/u1D450||/u1D44B/u1D447/u1D450∪/u1D44B/uni03A6/u1D450|, whichcharacterizes the behavior di-erence of the two branches. A valueclose to 1 means that both branches are dissimilar.3.2.3 Training phase.To train our OC-SVM model, we need sam-ples of a positive set, i.e., triggers considered normal. Therefore,we randomly chose10 000goodware (i.e., VirusToal [74] score =0) from A/n.sc+/r.sc,Z,,[4]. Then, for each of these apps, we appliedD"#/u.sc%/e.sc/r.scto extract a feature vector for each app’s condition.Afterward, we randomly chose10 000feature vectors2fromthose yielded by D"#/u.sc%/e.sc/r.sc, which we labeled as positive (i.e., part ofthe normal behavior). We then trained our One-Class Classi/f_ication2The number of extracted vectors is orders of magnitude higher. However, for e)ciency,we validated that a random set of10 000vectors yields an acceptable performance.based anomaly detector, leveraging LibSVM [14]. To ensure thatthe selected training set does not bias the trained model’s perfor-mance, we split it and compute Accuracy in 10-fold cross-validation.Overall, we achieve a stable Accuracy of 99.91% on average.4 EVALUATIONTo evaluate D"#/u.sc%/e.sc/r.sc, we address the following research questions:RQ1:What is the performance of D"#/u.sc%/e.sc/r.scfor detecting SuspiciousHidden Sensitive Operations (SHSOs) in Android apps?RQ2:Can D"#/u.sc%/e.sc/r.scbe used to detect logic bombs? We address thisquestion by considering three sub-questions:•RQ2.a:Are SHSOs detected by D"#/u.sc%/e.sc/r.sclikely logic bombs?•RQ2.b:How does D"#/u.sc%/e.sc/r.sccompare against T/r.sc"../e.sc/r.scS/,0/e.sc,a state of the art logic bomb detector?•RQ2.c:From a qualitative point of view, does D"#/u.sc%/e.sc/r.scleadto the detection of non-trivial triggers/logic bombs?RQ3:Can SHSO detection in goodware reveal suspicious behavior?4.1 RQ1: Suspicious Hidden SensitiveOperations in the wildIn this section, we assess the e)ciency of D"#/u.sc%/e.sc/r.scto/f_ind SHSOson a dataset of malicious applications.Dataset.To the best of our knowledge, there is no SHSO ground-truth available in the literature. Consequently, in this study, weconsidered10 000malicious Android apps as our malicious dataset.These apps were released in 2020, collected from the A/n.sc+/r.sc,Z,,[4]repository, and have been(agged as malware by at least/f_ive an-tivirus scanners in VirusTotal.We contacted the authors of state of the art approaches (e.g.,H1,M"/n.sc/e.sc/r.sc[57], and T/r.sc"../e.sc/r.scS/,0/e.sc[26]) to get their artifacts (data-sets and tools) for comparative assessment. Unfortunately, no arti-fact was made available to us.Libraries.It has been shown in the literature [15,45] that librarycode can a-ect analyses performed over Android apps since it oftenaccounts for a larger part than the app’s core code. Consequently,in this study, we considered two cases: (1) with-lib analysis (i.e., weconsider the entire app code including library code); (2) without-libanalysis (i.e., we consider only developer code). To rule out libraries,we rely on the state-of-the-art list available in [45].Post-Filter.As a precaution, before analyzing the results withoutlibs, we listed the classes in which D"#/u.sc%/e.sc/r.scfound potential sensitivetriggers to search for redundant classes that could indicate libraries.We were able to/f_ilter out19additional libraries that were not listedin the list we used and provided by [45].In the following, when referring to the analysis without libraries,we consider the19libraries previously presented as well as thelibraries of the list in [45] as/f_iltered. It accounts for a total of5982library classes and packages/f_iltered.4.1.1 Eﬀiciency of Detecting SHSOs.We recall that D"#/u.sc%/e.sc/r.scistargeted at detecting SHSOs. While in RQ2 we investigate the like-lihood for these SHSOs to be logic bombs, we/f_irst investigate thee)ciency (with RQ1) of D"#/u.sc%/e.sc/r.scin the detection of SHSOs. Wefurther perform an ablation study to highlight the performance ofthe anomaly detection module.728Difuzer: Uncovering Suspicious Hidden Sensitive Operations in Android AppsICSE ’22, May 21–29, 2022, Pi/t_tsburgh, PA, USAIn Table 2, we report the results of applying D"#/u.sc%/e.sc/r.sc(with theanomaly detection step activated) on our10 000malware dataset.When analyzing the entire apps, D"#/u.sc%/e.sc/r.scdetects at least one SHSOin339apps (3.39%). Overall, D"#/u.sc%/e.sc/r.scdetects5575SHSOs in these339 apps leading to an average number of16.4SHSOs per app. Incomparison, when only the app developers’ code is considered,D"#/u.sc%/e.sc/r.scdetects at least one SHSO in259apps (2.59%), with a totalnumber of2435SHSOs detected and an average number of8.2SHSOs per app. We note that the3437(5575-2435) SHSOs that arenot in the app developer code, are actually detected in 68 librariessuggesting that only a few libraries contain SHSOs . Figure 3 furtherdetails the distribution of detected SHSOs per apps.όХаФШХОЮНЮХСЯόХаФЫбаШХОЮНЮХСЯFigure 3: Distribution of the number of SHSO(s) per app inanalyses with and without libraries (only apps with at leastone SHSO are considered).These/f_irst results show that SHSOs indeed exist in malicious apps,but in relatively low number (in around 3% of the apps). However,when SHSOs are present in an app, they are not rare (on average,about 8 SHSOs per app in the developer code). Finally, SHSOs are moreprevalent in library code than in app developer code, but only a fewlibraries contain SHSOs.Table 2 also reports the average numbers of triggers before andafter applying the anomaly detection step (i.e., the second moduleof D"#/u.sc%/e.sc/r.sc). Interestingly, we can see that this anomaly detectiondrastically reduces the number of triggers that are considered asSHSOs. Indeed, when considering the10 000apps, there are onaverage 174336/10000≈17.43and 146018/10000≈14.60triggersper apps (with or without libraries respectively) generated by the/f_irst module of D"#/u.sc%/e.sc/r.sc, i.e., by the taint analysis step. After theanomaly detection step, these numbers drop to5575/10000≈0.56and2435/10000≈0.24respectively, corresponding to a decrease of96% and 98% respectively.These results show that the anomaly detection step has a signi/f_icantimpact on the number of detected SHSOs by signi/f_icantly reducing thesearch space of triggers by up to 98%. This search space reduction iskey when the ultimate goal is to detect malicious code and to supportsecurity analysts manual inspection (cf. Section 4.2).Table 2: Results of the experiments executed on10 000mal-ware with and without taking into account libraries.Analysis with libsAnalysis without libsNumber of apps with SHSO(s)339259Number of SHSOs55752435Number of SHSOs/app16.48.2Average # triggers (i.e., before Anomaly detection)17.4314.60Average # SHSOs (i.e., after Anomaly detection)0.560.24Meananalysis time35.63 s33.54 sWe further inspect the SHSOs detected by D"#/u.sc%/e.sc/r.scby focusingon the app developer code only (we do not consider library code).Table 3 lists the top 10 types of trigger that D"#/u.sc%/e.sc/r.scwas able todiscover. The second column gives some examples of methods con-sidered sources for the taint tracking to uncover SHSO entry-points.We note the diversity of types of triggers that developers use. Forinstance, a developer can decide to trigger (or not) the sensitive codeif: (Database trigger type) speci/f_ic values are present in databases(e.g., contacts, messages); (Internet trigger type) external orders sayso; (Build, Telephony, and Camera trigger types) the device is notan emulator; (Connectivity, and Wi-Fi trigger types) the device hasInternet access; (Location rigger type) the user is in a pre-de/f_inedlocation; Note that the methods in Row 3 have been dynamicallygenerated by D"#/u.sc%/e.sc/r.scduring instrumentation to track the Buildclass’s/f_ield values.Table 3: Top ten trigger types discovered by D"/f.sc/u.sc/z.sc/e.sc/r.scin thedeveloper code.(T. = Triggers)Trigger TypeExamplesof methods#T.Trigger TypeExamplesof methods#T.DatabasegetString,getInt, getCount785LocationgetLastKnownLocation, getLongitude84InternetgetResponseCode, getResponseMessage715Wi-FiisWi/f_iEnabled, getConnectionInfo76BuildgetMODEL,getMANUFACTURER374PowerisScreenOn, isInteractive47TelephonygetDeviceId, getNetworkOperatorName97AudiogetStreamVolume, isMusicActive37ConnectivitygetActiveNetworkInfo, getNetworkInfo88CameragetCameraIdList28Regarding the component types in which D"#/u.sc%/e.sc/r.scfound SHSOs,90% of SHSOs are in methods of "normal" classes, i.e., not An-droid components. SHSOs are found inActivitiesin 9% of thecases. However, they are rarely found inServicesandBroadcastReceivers(less than 1%).4.1.2 Manual Analyses.Since static analysis approaches often suf-fer from false alarm issues, i.e., they report a large proportion offalse-positive results, we decided to verify the detection capabili-ties of D"#/u.sc%/e.sc/r.scmanually. To that end, the authors of this paperrandomly selected a statistically signi/f_icant sample of102apps outof the259apps in which SHSOs exist in developer code, with acon/f_idence level of 99% and a con/f_idence interval of±10%. Only onesample was found to be a false-positive result. Indeed this app veri-/f_ies if it is running in an emulator by comparingBuild.PRODUCT,Build.MODEL,Build.MANUFACTURER, andBuild.HARDWAREagainstwell-known strings such as "generic", "Emulator", "google_sdk", etc.This test seems sensitive, but the guarded code displays the fol-lowing message to the user: "Scooper Warning: App is runningon emulator.". Therefore, D"#/u.sc%/e.sc/r.scachieves a precision of99.02%to/f_indSuspicious Hidden Sensitive Operationson this dataset. Werelease the annotated list of102apps that were manually checkedfor transparency in the project’s repository.4.1.3 Analysis Time.The last row in Table 2 reports D"#/u.sc%/e.sc/r.scanal-ysis time. D"#/u.sc%/e.sc/r.scoutperforms state-of-the-art trigger detectorswith an average of33.54s per app (35.63s for the analysis withlibraries, with an average DEX size of7.03MB per app), makingD"#/u.sc%/e.sc/r.scsuitable for large-scale analyses. In comparison, state-of-the-art tools such as T/r.sc"../e.sc/r.scS/,0/e.sc[25] and H1,M"/n.sc/e.sc/r.sc[57])require219.21s and765.3s per app respectively. Note that85.42%(i.e.,28.65seconds on average) of this time is reserved for the taintanalysis. Also,24apps (0.24%) reached the timeout (i.e., 1 hour)before the end of the analysis.RQ1 answer:D"#/u.sc%/e.sc/r.scdetects SHSOs in Android malware withhigh precision, i.e.,99.02% in less than 35 seconds on average.Among the average 14.6 HSOs identi/f_ied in an app based on trig-gers spotted by static taint analysis, only 2% are suspicious accord-ing to anomaly detection, which shows that D"#/u.sc%/e.sc/r.scis e-ectivein reducing the search space for manual analysis.729ICSE ’22, May 21–29, 2022, Pi/t_tsburgh, PA, USAJordan Samhi1, Li Li2, Tegawendé F. Bissyandé1, Jacques Klein14.2 RQ2: Can D"/f.sc/u.sc/z.sc/e.sc/r.scdetect logic bombs?In this section, we❶evaluate D"#/u.sc%/e.sc/r.sc’s e)ciency in detectinglogic bombs (RQ2.a),❷compare it against T/r.sc"../e.sc/r.scS/,0/e.sc(RQ2.b),and❸discuss logic bomb use cases in real-world apps (RQ2.c).4.2.1 RQ2.a: Are SHSOs detected likely to be logic bombs?xUntil now, we have shown that D"#/u.sc%/e.sc/r.scis e-ective in detectingSHSOs. From a security perspective, however, we must further showthat these SHSOs are actually malicious. In other words, are theseSHSOs likely to be logic bombs. Unfortunately, such assessment ischallenged by the lack of ground truth in the literature. We thereforerequire extra manual analysis e-ort of reported results.Initial Manual Analysis:In previous Section 4.1.2, we presentour manual analysis of SHSOs detected in102apps. During thisanalysis, we further checked if the detected SHSOs contain mali-cious code. In particular, for each app under analysis, we gatheredinformation about the reason it was(agged by antiviruses (e.g.,on VirusTotal). Then, in the guarded code of the potential SHSOfound by D"#/u.sc%/e.sc/r.sc, we looked for malicious behavior matchingour information previously gathered. For instance, if: (1) an appis labeled as being a trojan stealing the device’s information; (2)the potential SHSO is performing emulator detection (e.g., callingSystem.exit()method if the device is running in an emulator);and (3) the behavior exhibited in the code guarded by the conditiondetected by D"#/u.sc%/e.sc/r.scis gathering the device’s information (e.g.,unique identi/f_ier, current location, etc.) and sending it outside thedevice, the SHSO is considered a logic bomb.Eventually,30apps (i.e.,29.7%) were manually con/f_irmed to belogic bombs, i.e., the SHSOs were triggering malicious code.Semi-Automated further Analysis:Manual investigation istime-consuming. This is the reason why we inspected102appsand not all259apps reported to having at least one SHSOs withinthe developer code parts. To quickly enlarge the set of identi/f_iedlogic bombs, we decided to follow a simple but e)cient process. Itis known that malicious developers often reuse the same piece ofcode in di-erent apps [47]. Therefore, for each already identi/f_iedlogic bomb, we search for similarities (i.e., SHSOs found in the sameclass name, same method name, and the same type of trigger used)in SHSOs contained in the 157 (259)102) remaining apps. Ouranalysis yielded16additional apps containing logic bombs thatwere manually veri/f_ied and con/f_irmed. Eventually, our logic bombdataset, called D232B,45, contains46Android apps, each with anidenti/f_ied logic bomb. We believe this dataset to be useful to thecommunity to further improve logic bomb detection in Androidapps. We made it publicly available in the project’s repository.Discussion about HSO, SHSO and Logic Bomb:In the liter-ature [26,57], HSO is consistently de/f_ined as a sensitive operationthat is hidden by speci/f_ic triggering conditions. Nevertheless, thenotion of “sensitive operation” is not clearly delineated, which chal-lenges comparison across approaches. In our work, we postulatethat while detecting HSOs is an important/f_irst step, it is not enoughto help security analysts. Indeed, as shown by our manual analysis,a large proportion of HSOs are indeed sensitive but not necessarilysuspicious. As a result, most of the detected HSOs are legitimateand do not require any inspection e-ort from security analysts.In this context, if the goal is to detect real security issues and re-duce the burden of security analysts, a tool such as H1,M"/n.sc/e.sc/r.sc[57]which detectsHSOsin18.7% of apps within a set of over300 000apps (including malicious and benign apps) appears to be unprac-tical. In contrast, D"#/u.sc%/e.sc/r.scdetectssuspicious HSOsin3.39% of theanalyzed apps (when libraries are considered), and our manual anal-yses con/f_irm that in about 30% of the apps, these SHSOs are logicbombs, making the work of security analysts easier. Though bothH1,M"/n.sc/e.sc/r.scdataset and our dataset are di-erent (we were not ableto get the H1,M"/n.sc/e.sc/r.sc’s authors dataset), if we compare the18.7% ofapps with HSOs reported by H1,M"/n.sc/e.sc/r.sc, with the3.39% reported byD"#/u.sc%/e.sc/r.sc, we can say that D"#/u.sc%/e.sc/r.screduces the search space by upto81.9%((18.7)3.39)×10018.7=81.9) to accelerate the identi/f_icationof logic bombs.RQ2.a answer:By triaging HSOs to focus on suspicious onesbased on anomaly detection, D"#/u.sc%/e.sc/r.scwas able to reveal 30 logicbomb instances in a sampled subset of malware apps havingSHSOs. Besides, we release D232B,45, an annotated dataset of46 Android apps con/f_irmed to be using logic bombs.4.2.2 RQ2.b: How does D/i.sc/f.sc/u.sc/z.sc/e.sc/r.sccompare against T/r.sc/i.sc/g.sc/g.sc/e.sc/r.scS/c.sc/o.sc/p.sc/e.sc,astate of the art logic bomb detector?xIn the absence of a public ground-truth for Android logic bombinstances, we perform experimental comparisons against the T/r.sc".8./e.sc/r.scS/,0/e.scstate-of-the-art detector in the literature that relies onstatic analysis. Although T/r.sc"../e.sc/r.scS/,0/e.scis not publicly available,we are able to build on a replication based on technical detailsprovided in T/r.sc"../e.sc/r.scS/,0/e.scpaper [26].Overall, our approach di-ers from T/r.sc"../e.sc/r.scS/,0/e.sc’s by threemajor di-erences:❶Technique:T/r.sc"../e.sc/r.scS/,0/e.scuses symbolic ex-ecution to tag variables with a limited number of values, we usestatic data(ow analysis;❷Target:T/r.sc"../e.sc/r.scS/,0/e.scdetects hiddensensitive operations (i.e., whether at least one sensitive method iscalled within the guarded code of a trigger), whereas D"#/u.sc%/e.sc/r.sc’sgoal is to detect suspicious hidden sensitive operations (i.e., theguarded code is sensitive and implements an abnormal behavior);and❸Approach:T/r.sc"../e.sc/r.scS/,0/e.scmaintains a list of sensitive meth-ods and uses the occurrence of any of them as the sole criterion,D"#/u.sc%/e.sc/r.scimplements an anomaly detection scheme where the pres-ence of sensitive methods is one feature among many others. WhileT/r.sc"../e.sc/r.scS/,0/e.scand D"#/u.sc%/e.sc/r.scboth rely on list of sources to/f_indtriggers of interest, T/r.sc"../e.sc/r.scS/,0/e.schandpicks a limited set of meth-ods, whereas D"#/u.sc%/e.sc/r.sc’s list is based on a systematic mapping (cf.Section 3.1.1 - we leverage patterns to systematically search forsources).Does T/r.sc/i.sc/g.sc/g.sc/e.sc/r.scS/c.sc/o.sc/p.sc/e.scidentify as logic bombs the SHSOs flaggedby D/i.sc/f.sc/u.sc/z.sc/e.sc/r.sc?We applied T/r.sc"../e.sc/r.scS/,0/e.scon the subset of102apps where D"8#/u.sc%/e.sc/r.scidenti/f_ied a SHSO (cf. Section 4.2.1). The objective is to checkwhether T/r.sc"../e.sc/r.scS/,0/e.scis more or less accurate than D"#/u.sc%/e.sc/r.sc. Typ-ically, among the 30 logic bombs that have been manually veri/f_iedas true positives, how many are detected by T/r.sc"../e.sc/r.scS/,0/e.sc. Sim-ilarly, does T/r.sc"../e.sc/r.scS/,0/e.scdetect logic bombs (manually veri/f_iedas true positives) that D"#/u.sc%/e.sc/r.sccould not. Figure 4 illustrates thedi-erences in logic bomb detection (left/f_igure). Overall:•T/r.sc"../e.sc/r.scS/,0/e.scdid not(ag any logic bomb that D"#/u.sc%/e.sc/r.scdid not.•T/r.sc"../e.sc/r.scS/,0/e.sccould only detect 2 logic bombs among the 30logic bombs that D"#/u.sc%/e.sc/r.sccorrectly identi/f_ied.730Difuzer: Uncovering Suspicious Hidden Sensitive Operations in Android AppsICSE ’22, May 21–29, 2022, Pi/t_tsburgh, PA, USA•As reported in the literature [67], T/r.sc"../e.sc/r.scS/,0/e.scexhibits a veryhigh false positive rate at 94.6%: 35 among its 37 detections arefalse positives (the rate for D"#/u.sc%/e.sc/r.scis 70.6%, 72/102).Does D/i.sc/f.sc/u.sc/z.sc/e.sc/r.scfail to flag as SHSOs the logic bombs detectedby T/r.sc/i.sc/g.sc/g.sc/e.sc/r.scS/c.sc/o.sc/p.sc/e.sc?We recall that, contrary to D"#/u.sc%/e.sc/r.sc, which builds on anomalydetection, T/r.sc"../e.sc/r.scS/,0/e.scis restricted to detect only logic bombswhere the trigger involves location-, time-, and SMS-related prop-erties. Aligning with the assessment of D"#/u.sc%/e.sc/r.sc, we applied T/r.sc".8./e.sc/r.scS/,0/e.scon our set of10 000malware. T/r.sc"../e.sc/r.scS/,0/e.screported591 logic bombs in 149 apps ((4/app):98.6% of the reported casesare time-related. In the absence of ground truth, we again proposeto manually verify a random sample set of reported logic bombs. Tofacilitate comparison with D"#/u.sc%/e.sc/r.sc, we sample102apps (we simplyconsidered the same number of apps as in the previous question),and manually con/f_irmed that for 97 (95.1%) apps, the reported logicbombs are false positives. In 5 (4.9%) apps, we found at least onereported logic bomb to be a true positive.We further check whether on these 102 apps where T/r.sc"../e.sc/r.sc8S/,0/e.screported a logic bomb, D"#/u.sc%/e.sc/r.scalso(ags any case of SHSO:D"#/u.sc%/e.sc/r.sc (agged 68 apps as containing SHSOs, among which 7 aremanually con/f_irmed to be logic bombs. The details of the compari-son between T/r.sc"../e.sc/r.scS/,0/e.scand D"#/u.sc%/e.sc/r.scare presented in the VennDiagram in Figure 4 (right/f_igure). We note that:•2 logic bombs are detected by both D"#/u.sc%/e.sc/r.scand T/r.sc"../e.sc/r.scS/,0/e.sc.•5 SHSOs detected by D"#/u.sc%/e.sc/r.scare actual logic bombs, but notdetected by T/r.sc"../e.sc/r.scS/,0/e.sc. Indeed, T/r.sc"../e.sc/r.scS/,0/e.scis limited byits focus on time, location and SMS-related triggers.•3 logic bombs are detected by T/r.sc"../e.sc/r.scS/,0/e.sc, but not detectedby D"#/u.sc%/e.sc/r.sc. Our prototype implementation considers a limitedlist of sources, which do not cover those 3 logic bomb cases.Although we do not have a complete ground truth (with infor-mation about all cases of logic bombs), con/f_irming and comparingdetection reports by D"#/u.sc%/e.sc/r.scand T/r.sc"../e.sc/r.scS/,0/e.sco-ers an alter-native to assess to what extent each may be missing some logicbombs. The results described above suggest that D"#/u.sc%/e.sc/r.scsu-erssigni/f_icantly less from false-negative results than T/r.sc"../e.sc/r.scS/,0/e.sc.	
		
		
		
	Figure 4: Venn Diagram representing results of T/r.sc"++/e.sc/r.sc)S,-./e.scand D"/f.sc/u.sc/z.sc/e.sc/r.scon 102 apps originally detected by D")/f.sc/u.sc/z.sc/e.sc/r.scon the left, and T/r.sc"++/e.sc/r.scS,-./e.scon the right.(FP = FalsePositive, TP = True Positive)RQ2.b answer:Overall, D"#/u.sc%/e.sc/r.scoutperforms T/r.sc"../e.sc/r.scS/,0/e.scbydetecting more logic bombs more accurately (wrt. false positives),and by missing less logic bombs (wrt. false negatives).4.2.3 RQ2.c: From a qualitative point of view, does D/i.sc/f.sc/u.sc/z.sc/e.sc/r.sclead tothe detection of non-trivial triggers/logic bombs?xIn this section, we discuss two real-world apps in which D"#/u.sc%/e.sc/r.screvealed logic bombs that cannot be detected by T/r.sc"../e.sc/r.scS/,0/e.sc.Advertisement Triggering.D"#/u.sc%/e.sc/r.screvealed an interesting logicbomb in "com.walkthrough.knife.assassin.hunter.baoer" app whichis an adware app of the HiddenAd family. The app uses theandroid.-app.job.JobServiceclass of the Android framework to schedulethe execution of jobs (the developer can handle the code of thejob inonStartJobmethod). In theonStartJobmethod, the apptakes advantage of thePowerManagerof the Android framework tocheck if the device is in an interactive state (i.e., the user is probablyusing the device) with methodisScreenOn(). If this is the case,the app displays advertisements to the user and schedules the sameclass’s execution after a certain time.Data Stealer.Logic bombs can also be used to trigger data theftunder the condition that the data is available. For instance, in app"com.magic.clmanager", which is a Trojan (hidden behind a clean-ing app) capable of stealing data on the device, D"#/u.sc%/e.sc/r.scfound alogic bomb related to the device unique identi/f_ier. Indeed, in methodd(Context c)of the classc.gdf, a check is performed against thevalue returned by methodgetDeviceId()to verify if the valuematches speci/f_ic values (emulator detection) in a given/f_ile named"invalid-imei.idx". In the case the app considers that the device isnot an emulator, it triggers the stealing of sensitive informationabout the device such as the current location, phone number, in-formation on the camera, information about the Bluetooth, diskspace left, whether the device is rooted or not, the current country,the brand, the model, information about the Wi-Fi, etc. Afterward,this information is written in a/f_ile and sent to a native method forfurther processing.4.3 RQ3: SHSOs in benign appsUntil now, we have focused on malware. However, SHSOs are notexclusively found in malicious apps [57]. Therefore, in this section,we intend to conduct a study on benign applications.Results.As con/f_irmed in Section 4.1.1 and in previous stud-ies [26,57], benign libraries and benign Android apps implementHSOs. Our study con/f_irms this/f_inding. Even more,354benign apps(3.54%) were(agged by D"#/u.sc%/e.sc/r.scto contain suspicious HSOs. Wefurther manually analyzed 20 apps randomly selected from our re-sults and con/f_irmed that they all contain at least one SHSO. Table 4shows the di-erent trigger types used in benign apps to triggerSHSOs. A signi/f_icant result here is that benign apps use consid-erably less the "Build" trigger type (see Table 3 for comparison)than malicious apps. Similarly, the "Telephony" trigger type is lessused in benign apps than in malicious apps. This induces that, inbenign apps, decisions are less taken depending on values derivedfrom methods like:getDeviceId(),getNetworkOperatorName(),getPhoneType(),getMODEL(),getMANUFACTURER(), orget-FINGERPRINT(). A hypothesis would be that benign apps are lessprone to recognize an emulator environment (and use this informa-tion to set triggering conditions).Besides, we can see in Figure 5 that, in comparison with maliciousapps, benign apps tend to have signi/f_icantly fewer triggers per app.731ICSE ’22, May 21–29, 2022, Pi/t_tsburgh, PA, USAJordan Samhi1, Li Li2, Tegawendé F. Bissyandé1, Jacques Klein1Table 4: Top ten trigger types used by benign Android apps.DatabaseInternetLocationConnectivityAudioTelephonyWi-FiViewActivityBuild89728326474635825211919Figure 5: Distribution of the number of SHSO(s)/app in good-ware and malware(apps with at least 1 SHSO are considered).4.3.1 Case Study.This section presents an SHSO of a benign app.Benign App.The app we consider in this case study is "no.apps.dn-bnor". D"#/u.sc%/e.sc/r.scdetected an SHSO in method<bom./uni222E: java.lang.-String··· ·()>which tests if the value ofBuild.CPU_ABIorBuild.CPU_ABI2is equal to pre-de/f_ined values stored in a/f_ile. Inthe case a match is found, it triggers the copy of a native code/f_ileinto a second/f_ile. The native code/f_ile name is in the form: "lib/"+str+ "/lib" +f9+ ".so". Thestrvariable represents aCPU_ABIvalue and thef9variable represents a string to designate the/f_ile.This/f_ile is then opened and eventually copied in the user datadirectory of the running app.Although not malicious in this case, this behavior is suspicious,and D"#/u.sc%/e.sc/r.scwas able to reveal it.4.3.2 Malicious activities in Google Play.We now illustrate howD"#/u.sc%/e.sc/r.sccontributed to removing8apps whose behavior was po-tentially harmful to users (in the form of aggressive, unsolicited,and intrusive ads) in Google Play. Developers of suchadware appsmanaged to evade classical checks performed in Google Play.During our manual analyses of benign apps, we stumbled uponan app with an SHSO(agged by D"#/u.sc%/e.sc/r.sc. Our inspection of thecode suggested that the SHSO is not a logic bomb per se since itdoes not trigger the malicious code. However, during this manualanalysis, we noticed that the app was apparently mainly designed todisplay advertising content aggressively. To con/f_irm our hypothesis,we downloaded the sample and executed it in an emulator. First,we noticed poor app design, poor quality, and low content. Thenin nearly every screen (i.e.,Activitycomponent), we receivedembedded ads and full-screen ads. This behavior is characteristicof adware apps. After veri/f_ication, we found that the app was stillin Google Play with a relatively high number of downloads (a fewthousands) but with negative comments. In fact, the app pretendedto provide users with a "walkthrough" version of an existing gameto display a profusion of ads on each screen.We then search in our analyzed apps if D"#/u.sc%/e.sc/r.scdetected similarSHSOs. Eventually, D"#/u.sc%/e.sc/r.scdetected three apps with the exactsame SHSO and the exact same service proposed to the user (walk-through games). We tested these apps to con/f_irm they were adware.They were also still in Google Play.We then checked if similar "walkthrough games" were also stillin Google Play and not in our initial dataset. Therefore, we searchedfor apps made by the same developers of the three previous appsdetected by D"#/u.sc%/e.sc/r.sc. We also searched for "walkthrough games"in Google Play and browsed the resulting apps. We inspected thenewly collected apps and con/f_irmed they were adware apps. Even-tually, we identi/f_ied 8 apps with the same adware behavior.We contacted Google to report these8apps. They were removedin less than two weeks from Google Play. We make available thesamples in the project’s repository.RQ3 answer:Our experiments show that SHSOs are present inbenign apps and in widely-used libraries. We have seen throughreal-world examples that D"#/u.sc%/e.sc/r.sccan reveal potentially harmfulapplications (PHA) and raise alarms concerning some apps’ po-tential maliciousness. Overall, D"#/u.sc%/e.sc/r.sccontributed to removing8 adware apps from Google Play.5L I M I T A T I O N S A N D T H R E A T S T O V A L I D I T YAn essential step in our approach is the identi/f_ication of SHSOsentry-points. To do so, D"#/u.sc%/e.sc/r.screlies on state-of-the-art tool F6,78D/r.sc,"+[6]. Therefore, it carries the analysis limitations of F6,78D/r.sc,"+, i.e., unsoundness regarding re(ective calls [43], dynamicloading [82], multi-threading [53] and native calls [48].Although our approach proved to be e)cient to detect SHSOsand logic bombs, feature selection can impact the performances.Indeed, feature engineering is a challenging task and can be proneto unsatisfactory selection since it does not captureeverything.Besides, our approach is based on SHSO entry-points detectionusing taint analysis, which relies on sources and sinks methods.Sinks are not an issue in our approach since they always representif conditions. However, sources selection is at risk since they havebeen selected systematically, using heuristics and human intuitions.Therefore, our list of sources might not be complete.Although, we have implemented T/r.sc"../e.sc/r.scS/,0/e.scby strictly fol-lowing the description in the original paper, our implementationmight not be exempt from errors.In the absence of a-priori ground truth, some of our assessmentactivities rely on manual analysis based on our own expertise. Whilewe follow a consistent process (e.g., we carefully verify the hiddenbehaviour implementation against the antivirus report), our con-clusions remain a-ected by human subjectivity. Nevertheless, wemitigate the threat to validity by sharing all our artefacts to theresearch community for further exploitation and veri/f_ication.6 RELATED WORKLogic bombs in general.Hidden code triggered under speci/f_icconditions is a concern in many programming environments. Theliterature includes studies of the logic bomb phenomenon in pro-gramming prior to the Android era [11,16] and targeting the Win-dows platform for example. Since then, various approaches havebeen proposed to tackle the challenging task of trigger-based be-havior detection [9,35,38,49,70]. State-of-the-art techniques forthe detection of trigger-based behaviour are varied and leveragefully-static analyses [26,58,85], dynamic analyses [86], hybridanalyses [10, 11], and machine-learning-based analyses [57].Trigger-based behavior detection for AndroidD"#/u.sc%/e.sc/r.sccom-bines static taint analysis and unsupervised machine learning tech-niques. Our closest related work is thus H1,M"/n.sc/e.sc/r.sc[57], whichrelies on static analysis and automatic classi/f_ication to detectHSOs.732Difuzer: Uncovering Suspicious Hidden Sensitive Operations in Android AppsICSE ’22, May 21–29, 2022, Pi/t_tsburgh, PA, USAContrary to our work, however, H1,M"/n.sc/e.sc/r.scis not targeting suspi-cious HSOs and therefore does not focus on logic bombs.Fratantonio et al. [26] proposed T/r.sc"../e.sc/r.scS/,0/e.sc, an automatedstatic-analysis tool that can detect logic bombs in Android apps.T/r.sc"../e.sc/r.scS/,0/e.scleverages a symbolic execution engine to modelspeci/f_ic values (i.e., SMS-, time-, location-related variables). T/r.sc".8./e.sc/r.scS/,0/e.scmodels conditions usingpredicate recovery. It combinessymbolic execution results and path predicate recovery results to in-fer suspicious triggers. Finally, potential suspicious triggers undergoa control dependency step to verify if it guards sensitive operations.Nevertheless, the whole approach relies on static analysis to checkde/f_ined properties of suspiciousness. In contrast, D"#/u.sc%/e.sc/r.sctakesadvantage of unsupervised learning to discover abnormal (hencesuspicious) trigger-based behavior.Anomaly detection for security.We note that the idea of usinganomaly detection to detect malware has been presented in theAvdiienko et al.’s paper [8]. Indeed, they present M/u.sc+F6,7thatrelies on anomaly detection to spot malware for which sensitivedata(ows deviate from benign data(ows. It proved to be e)cientby detecting more than86% malware. While our approach is alsobased on anomaly detection to triageabnormaltriggers (i.e., suspi-cious sensitive behavior) that deviate from normality (i.e., normaltriggers/conditions), the end goal of both approaches is di-erent.Indeed, M/u.sc+F6,7addresses a binary classi/f_ication problem to dis-criminate malware from goodware. In contrast, D"#/u.sc%/e.sc/r.scaddressesthe problem of detecting and locatingSuspicious Hidden SensitiveOperationsthat are likely to be logic bombs in Android apps.Malicious behavior detection in Android apps.Malware de-tection does not only focus on trigger-based malicious behavior.Indeed, the Android security research community worked on tack-ling general security aspects [12,50,52,72,89]. In the literature,numerous approaches have been proposed to detect Android hostileactivities. Among which, machine-learning techniques [66], deep-learning techniques [54], static analyses through semantic-baseddetection [23], privacy leaks detection [6,41,68], as well as dynamicanalyses[21,60,77]. Each of these approaches tackles a particularaspect of Android security. Therefore, analysts could combine ourapproach with the aforementioned techniques to detect a widevariety of Android malicious behavior more e)ciently.7 CONCLUSIONWe proposed D"#/u.sc%/e.sc/r.sc, a novel approach for detectingSuspiciousHidden Sensitive Operationsin Android apps. D"#/u.sc%/e.sc/r.sccombinesbytecode instrumentation, static inter-procedural taint tracking,and anomaly detection for addressing the challenge of accuratelyspotting relevant SHSOs, which are likely logic bombs. After empiri-cally showing that our prototype implementation can detect SHSOswith high precision (i.e.,99.02%) in less than 35 seconds per app,we assessed its capabilities to reveal logic bombs and demonstratethat up to30% of detected SHSOs were logic bombs. We there-fore improve over the performance of the current state of the art,notably T/r.sc"../e.sc/r.scS/,0/e.sc, which yields signi/f_icantly more false posi-tives, while detecting less logic bombs. Finally, we apply D"#/u.sc%/e.sc/r.scon goodware to investigate potential SHSOs: D"#/u.sc%/e.sc/r.sceventuallycontributed to removing 8 new adware apps from Google Play.8 DATA AVAILABILITYFor the sake of Open Science, we provide to the community allthe artifacts used in our study. In particular, we make available thedatasets used during our experimentations, the source code of ourprototype, the executable used for our experiments, the annotatedlist of our manual analyses, and a dataset of logic bombs.The project’s repository including all artefacts (tool, datasets,etc.) is available at:https://github.com/Trustworthy-Software/Difuzer9 ACKNOWLEDGMENTThis work was partly supported (1) by the Luxembourg National Re-search Fund (FNR), under projects Reprocess C21/IS/16344458 theAFR grant 14596679, (2) by the SPARTA project, which has receivedfunding from the European Union’s Horizon 2020 research and in-novation program under grant agreement No 830892, (3) by the Lux-embourg Ministry of Foreign and European A-airs through theirDigital4Development (D4D) portfolio under project LuxWAyS, and(4) by the INTER Mobility project Sleepless@Seattle No 13999722.REFERENCES[1]Hira Agrawal, James Alberi, Lisa Bahler, Josephine Micallef, Alexandr Virodov,Mark Magenheimer, Shane Snyder, Vidroha Debroy, and Eric Wong. 2012. De-tecting hidden logic bombs in critical infrastructure software. InInternationalConference on Information Warfare and Security. Academic Conferences Interna-tional Limited, Vol. 1.[2]Shahid Alam, Zhengyang Qu, Ryan Riley, Yan Chen, and Vaibhav Rastogi.2017. DroidNative: Automating and optimizing detection of Android nativecode malware variants.Computers & Security65 (2017), 230 – 246. https://doi.org/10.1016/j.cose.2016.11.011[3]Scott Alexander-Bown. [n. d.].Android Security: Adding Tampering Detection toYour App. https://www.airpair.com/android/posts/adding-tampering-detection-to-your-android-app#4-1-emulator Accessed February 2021.[4]Kevin Allix, Tegawendé F. Bissyandé, Jacques Klein, and Yves Le Traon. 2016.AndroZoo: Collecting Millions of Android Apps for the Research Community. InProceedings of the 13th International Conference on Mining Software Repositories(Austin, Texas)(MSR ’16). ACM, New York, NY, USA, 468–471. https://doi.org/10.1145/2901739.2903508[5]Steven Arzt, Siegfried Rasthofer, and Eric Bodden. 2013. Susi: A tool for thefully automated classi/f_ication and categorization of android sources and sinks.University of Darmstadt, Tech. Rep. TUDCS-2013-0114(2013).[6]Steven Arzt, Siegfried Rasthofer, Christian Fritz, Eric Bodden, Alexandre Bar-tel, Jacques Klein, Yves Le Traon, Damien Octeau, and Patrick McDaniel. 2014.FlowDroid: Precise Context, Flow, Field, Object-Sensitive and Lifecycle-AwareTaint Analysis for Android Apps.SIGPLAN Not.49, 6 (June 2014), 259–269.https://doi.org/10.1145/2666356.2594299[7]Kathy Wain Yee Au, Yi Fan Zhou, Zhen Huang, and David Lie. 2012. PScout:Analyzing the Android Permission Speci/f_ication. InProceedings of the 2012 ACMConference on Computer and Communications Security(Raleigh, North Carolina,USA)(CCS ’12). Association for Computing Machinery, New York, NY, USA,217–228. https://doi.org/10.1145/2382196.2382222[8]Vitalii Avdiienko, Konstantin Kuznetsov, Alessandra Gorla, Andreas Zeller, StevenArzt, Siegfried Rasthofer, and Eric Bodden. 2015. Mining Apps for AbnormalUsage of Sensitive Data. In2015 IEEE/ACM 37th IEEE International Conference onSoftware Engineering, Vol. 1. 426–436. https://doi.org/10.1109/ICSE.2015.61[9]Davide Balzarotti, Marco Cova, Christoph Karlberger, Engin Kirda, ChristopherKruegel, and Giovanni Vigna. 2010. E)cient Detection of Split Personalities inMalware.. InNDSS. Citeseer.[10]Luciano Bello and Marco Pistoia. 2018. Ares: triggering payload of evasive androidmalware. In2018 IEEE/ACM 5th International Conference on Mobile SoftwareEngineering and Systems (MOBILESoft). IEEE, 2–12.[11]David Brumley, Cody Hartwig, Zhenkai Liang, James Newsome, Dawn Song, andHeng Yin. 2008. Automatically identifying trigger-based behavior in malware.InBotnet Detection. Springer, 65–88.[12]Iker Burguera, Urko Zurutuza, and Simin Nadjm-Tehrani. 2011. Crowdroid:behavior-based malware detection system for android. InProceedings of the 1stACM workshop on Security and privacy in smartphones and mobile devices. 15–26.733ICSE ’22, May 21–29, 2022, Pi/t_tsburgh, PA, USAJordan Samhi1, Li Li2, Tegawendé F. Bissyandé1, Jacques Klein1[13]Varun Chandola, Arindam Banerjee, and Vipin Kumar. 2009. Anomaly Detection:A Survey.ACM Comput. Surv.41, 3, Article 15 (July 2009), 58 pages. https://doi.org/10.1145/1541880.1541882[14]Chih-Chung Chang and Chih-Jen Lin. 2011. LIBSVM: A Library for SupportVector Machines.ACM Trans. Intell. Syst. Technol.2, 3, Article 27 (May 2011),27 pages. https://doi.org/10.1145/1961189.1961199[15]K. Chen, X. Wang, Y. Chen, P. Wang, Y. Lee, X. Wang, B. Ma, A. Wang, Y. Zhang,and W. Zou. 2016. Following Devil’s Footprints: Cross-Platform Analysis ofPotentially Harmful Libraries on Android and iOS. In2016 IEEE Symposium onSecurity and Privacy (SP). 357–376. https://doi.org/10.1109/SP.2016.29[16]Xu Chen, Jon Andersen, Z Morley Mao, Michael Bailey, and Jose Nazario. 2008.Towards an understanding of anti-virtualization and anti-debugging behaviorin modern malware. In2008 IEEE international conference on dependable systemsand networks with FTCS and DCC (DSN). IEEE, 177–186.[17]M. Choudhary and B. Kishore. 2018. HAAMD: Hybrid Analysis for AndroidMalware Detection. In2018 International Conference on Computer Communicationand Informatics (ICCCI). 1–4. https://doi.org/10.1109/ICCCI.2018.8441295[18]Catalin Cimpanu. [n. d.].Play Store identi/f_ied as main distribution vector for mostAndroid malware. https://www.zdnet.com/article/play-store-identi/f_ied-as-main-distribution-vector-for-most-android-malware/ Accessed February 2021.[19]Hitesh Dharmdasani. [n. d.].Android.HeHe: Malware Now Disconnects PhoneCalls. https://www./f_ireeye.com/blog/threat-research/2014/01/android-hehe-malware-now-disconnects-phone-calls.html Accessed December 2020.[20]Shuaike Dong, Menghao Li, Wenrui Diao, Xiangyu Liu, Jian Liu, Zhou Li, FenghaoXu, Kai Chen, XiaoFeng Wang, and Kehuan Zhang. 2018. Understanding AndroidObfuscation Techniques: A Large-Scale Investigation in the Wild. InSecurity andPrivacy in Communication Networks, Raheem Beyah, Bing Chang, Yingjiu Li, andSencun Zhu (Eds.). Springer International Publishing, Cham, 172–192.[21]William Enck, Peter Gilbert, Seungyeop Han, Vasant Tendulkar, Byung-GonChun, Landon P Cox, Jaeyeon Jung, Patrick McDaniel, and Anmol N Sheth. 2014.TaintDroid: an information-(ow tracking system for realtime privacy monitoringon smartphones.ACM Transactions on Computer Systems (TOCS)32, 2 (2014),1–29.[22]Emre Erturk. 2012. A case study in open source software security and privacy:Android adware. InWorld Congress on Internet Security (WorldCIS-2012). IEEE,189–191.[23]Yu Feng, Saswat Anand, Isil Dillig, and Alex Aiken. 2014. Apposcopy: Semantics-based detection of android malware through static analysis. InProceedings ofthe 22nd ACM SIGSOFT International Symposium on Foundations of SoftwareEngineering. 576–587.[24]H. Fereidooni, M. Conti, D. Yao, and A. Sperduti. 2016. ANASTASIA: ANdroidmAlware detection using STatic analySIs of Applications. In2016 8th IFIP In-ternational Conference on New Technologies, Mobility and Security (NTMS). 1–5.https://doi.org/10.1109/NTMS.2016.7792435[25]Y. Fratantonio, A. Bianchi, W. Robertson, E. Kirda, C. Kruegel, and G. Vigna. 2016.TriggerScope: Towards Detecting Logic Bombs in Android Applications. In2016IEEE Symposium on Security and Privacy (SP). 377–396. https://doi.org/10.1109/SP.2016.30[26]Yanick Fratantonio, Antonio Bianchi, William Robertson, Engin Kirda, Christo-pher Kruegel, and Giovanni Vigna. 2016. Triggerscope: Towards detecting logicbombs in android applications. In2016 IEEE symposium on security and privacy(SP). IEEE, 377–396.[27]Olga Gadyatskaya, Andra-Lidia Lezza, and Yury Zhauniarovich. 2016. Evaluationof Resource-Based App Repackaging Detection in Android. InSecure IT Systems,Billy Bob Brumley and Juha Röning (Eds.). Springer International Publishing,Cham, 135–151.[28]Clint Gibler, Jonathan Crussell, Jeremy Erickson, and Hao Chen. 2012. Androi-dLeaks: Automatically Detecting Potential Privacy Leaks in Android Applicationson a Large Scale. InTrust and Trustworthy Computing, Stefan Katzenbeisser, EdgarWeippl, L. Jean Camp, Melanie Volkamer, Mike Reiter, and Xinwen Zhang (Eds.).Springer Berlin Heidelberg, Berlin, Heidelberg, 291–307.[29]Google. [n. d.]. Build Class, https://developer.android.com/reference/android/os/Build. Accessed February 2021.[30]Google. [n. d.].Context Class, https://developer.android.com/reference/android/content/Context#getSystemService(java.lang.String). Accessed February 2021.[31]Google. [n. d.]. Cursor Class, https://developer.android.com/reference/android/database/Cursor. Accessed February 2021.[32]Google. [n. d.]. Sensor Class, https://developer.android.com/reference/android/hardware/Sensor. Accessed February 2021.[33]Google. [n. d.]. SensorManager Class, https://developer.android.com/reference/android/ hardware/SensorManager. Accessed February 2021.[34]IDC. [n. d.].Smartphone Market Share, https://www.idc.com/promo/smartphone-market-share/os. Accessed January 2021.[35]Xiaoqi Jia, Guangzhe Zhou, Qingjia Huang, Weijuan Zhang, and Donghai Tian.2017. Findevasion: an e-ective environment-sensitive malware detection systemfor the cloud. InInternational Conference on Digital Forensics and Cyber Crime.Springer, 3–17.[36]Mohsin Junaid, Donggang Liu, and David Kung. 2016. Dexteroid: Detectingmalicious behaviors in Android apps using reverse-engineered life cycle models.computers & security59 (2016), 92–117.[37]Hyunjae Kang, Jae wook Jang, Aziz Mohaisen, and Huy Kang Kim. 2015. Detectingand Classifying Android Malware Using Static Analysis along with Creator Infor-mation.International Journal of Distributed Sensor Networks11, 6 (2015), 479174.https://doi.org/10.1155/2015/479174 arXiv:https://doi.org/10.1155/2015/479174[38]Dhilung Kirat, Giovanni Vigna, and Christopher Kruegel. 2014. Barecloud: bare-metal analysis-based evasive malware detection. In23rd{USENIX}SecuritySymposium ({USENIX}Security 14). 287–301.[39]Sotiris B Kotsiantis, I Zaharakis, and P Pintelas. 2007. Supervised machinelearning: A review of classi/f_ication techniques.Emerging arti/f_icial intelligenceapplications in computer engineering160, 1 (2007), 3–24.[40]Ond9ej Lhoták and Laurie Hendren. 2003. Scaling Java Points-to Analysis UsingSpark. InCompiler Construction, Görel Hedin (Ed.). Springer Berlin Heidelberg,Berlin, Heidelberg, 153–169.[41]Li Li, Alexandre Bartel, Tegawendé F Bissyandé, Jacques Klein, Yves Le Traon,Steven Arzt, Siegfried Rasthofer, Eric Bodden, Damien Octeau, and Patrick Mc-Daniel. 2015. Iccta: Detecting inter-component privacy leaks in android apps. In2015 IEEE/ACM 37th IEEE International Conference on Software Engineering, Vol. 1.IEEE, 280–291.[42]L. Li, T. F. Bissyande, and J. Klein. 2019. Rebooting Research on DetectingRepackaged Android Apps: Literature Review and Benchmark.IEEE Transactionson Software Engineering(2019), 1–1. https://doi.org/10.1109/TSE.2019.2901679[43]Li Li, Tegawendé F Bissyandé, Damien Octeau, and Jacques Klein. 2016. Droidra:Taming re(ection to support whole-program analysis of android apps. InPro-ceedings of the 25th International Symposium on Software Testing and Analysis.318–329.[44]L. Li, T. F. Bissyandé, and J. Klein. 2017. SimiDroid: Identifying and ExplainingSimilarities in Android Apps. In2017 IEEE Trustcom/BigDataSE/ICESS. 136–143.https://doi.org/10.1109/Trustcom/BigDataSE/ICESS.2017.230[45]L. Li, T. F. Bissyandé, J. Klein, and Y. L. Traon. 2016. An Investigation into the Useof Common Libraries in Android Apps. In2016 IEEE 23rd International Conferenceon Software Analysis, Evolution, and Reengineering (SANER), Vol. 1. 403–414.[46]Li Li, Tegawendé F. Bissyandé, Mike Papadakis, Siegfried Rasthofer, AlexandreBartel, Damien Octeau, Jacques Klein, and Le Traon. 2017. Static analysis ofandroid apps: A systematic literature review.Information and Software Technology88 (2017), 67 – 95. https://doi.org/10.1016/j.infsof.2017.04.001[47]L. Li, D. Li, T. F. Bissyandé, J. Klein, Y. Le Traon, D. Lo, and L. Cavallaro. 2017.Understanding Android App Piggybacking: A Systematic Study of MaliciousCode Grafting.IEEE Transactions on Information Forensics and Security12, 6(2017), 1269–1284. https://doi.org/10.1109/TIFS.2017.2656460[48]Cheng-Min Lin, Jyh-Horng Lin, Chyi-Ren Dow, and Chang-Ming Wen. 2011.Benchmark dalvik and native code for android system. In2011 Second InternationalConference on Innovations in Bio-inspired Computing and Applications. IEEE, 320–323.[49]Martina Lindorfer, Clemens Kolbitsch, and Paolo Milani Comparetti. 2011. De-tecting environment-sensitive malware. InInternational Workshop on RecentAdvances in Intrusion Detection. Springer, 338–357.[50]Martina Lindorfer, Matthias Neugschwandtner, Lukas Weichselbaum, YanickFratantonio, Victor Van Der Veen, and Christian Platzer. 2014. Andrubis–1,000,000apps later: A view on current Android malware behaviors. In2014 third interna-tional workshop on building analysis datasets and gathering experience returns forsecurity (BADGERS). IEEE, 3–17.[51]Linghui Luo, Eric Bodden, and Johannes Späth. 2019. A Qualitative Analysis ofAndroid Taint-Analysis Results. In2019 34th IEEE/ACM International Conferenceon Automated Software Engineering (ASE). 102–114. https://doi.org/10.1109/ASE.2019.00020[52]Arvind Mahindru and Paramvir Singh. 2017. Dynamic permissions based androidmalware detection using machine learning techniques. InProceedings of the 10thinnovations in software engineering conference. 202–210.[53]Pallavi Maiya, Aditya Kanade, and Rupak Majumdar. 2014. Race detection forAndroid applications.ACM SIGPLAN Notices49, 6 (2014), 316–325.[54]Niall McLaughlin, Jesus Martinez del Rincon, BooJoong Kang, Suleiman Yerima,Paul Miller, Sakir Sezer, Yeganeh Safaei, Erik Trickel, Ziming Zhao, Adam Doupé,et al.2017. Deep android malware detection. InProceedings of the Seventh ACMon Conference on Data and Application Security and Privacy. 301–308.[55]Trend Micro. [n. d.].Hacking Team Spying Tool Listens to Calls.https://www.trendmicro.com/en_us/research/15/g/hacking-team-rcsandroid-spying-tool-listens-to-calls-roots-devices-to-get-in.html Accessed February2021.[56]Yuhong Nan, Zhemin Yang, Xiaofeng Wang, Yuan Zhang, Donglai Zhu, and MinYang. 2018. Finding Clues for Your Secrets: Semantics-Driven, Learning-BasedPrivacy Discovery in Mobile Apps.. InNDSS.[57]Xiaorui Pan, Xueqiang Wang, Yue Duan, XiaoFeng Wang, and Heng Yin. 2017.Dark Hazard: Learning-based, Large-Scale Discovery of Hidden Sensitive Opera-tions in Android Apps.. InNDSS.734Difuzer: Uncovering Suspicious Hidden Sensitive Operations in Android AppsICSE ’22, May 21–29, 2022, Pi/t_tsburgh, PA, USA[58]Dorottya Papp, Levente Buttyán, and Zhendong Ma. 2017. Towards semi-automated detection of trigger-based behavior for software security assurance.InProceedings of the 12th International Conference on Availability, Reliability andSecurity. 1–6.[59]N. Peiravian and X. Zhu. 2013. Machine Learning for Android Malware DetectionUsing Permission and API Calls. In2013 IEEE 25th International Conference onTools with Arti/f_icial Intelligence. 300–305. https://doi.org/10.1109/ICTAI.2013.53[60]Thanasis Petsas, Giannis Voyatzis, Elias Athanasopoulos, Michalis Polychronakis,and Sotiris Ioannidis. 2014. Rage against the Virtual Machine: Hindering DynamicAnalysis of Android Malware. InProceedings of the Seventh European Workshopon System Security(Amsterdam, The Netherlands)(EuroSec ’14). Association forComputing Machinery, New York, NY, USA, Article 5, 6 pages. https://doi.org/10.1145/2592791.2592796[61]Heloise Pieterse and Martin S Olivier. 2012. Android botnets on the rise: Trendsand characteristics. In2012 information security for South Africa. IEEE, 1–5.[62]Siegfried Rasthofer, Irfan Asrar, Stephan Huber, and Eric Bodden. 2015. HowCurrent Android Malware Seeks to Evade Automated Code Analysis. InInforma-tion Security Theory and Practice, Raja Naeem Akram and Sushil Jajodia (Eds.).Springer International Publishing, Cham, 187–202.[63]H. G. Rice. 1953. Classes of Recursively Enumerable Sets and Their DecisionProblems.Trans. Amer. Math. Soc.74, 2 (1953), 358–366. http://www.jstor.org/stable/1990888[64]Mustafa Hassan Saad, Ahmed Serageldin, and Goda Ismaeel Salama. 2015. An-droid spyware disease and medication. In2015 second international conference oninformation security and cyber forensics (InfoSec). IEEE.[65]J. Sahs and L. Khan. 2012. A Machine Learning Approach to Android MalwareDetection. In2012 European Intelligence and Security Informatics Conference. 141–147. https://doi.org/10.1109/EISIC.2012.34[66]Justin Sahs and Latifur Khan. 2012. A machine learning approach to android mal-ware detection. In2012 European Intelligence and Security Informatics Conference.IEEE, 141–147.[67]Jordan Samhi and Alexandre Bartel. 2021. On The (In)E-ectiveness of StaticLogic Bomb Detector for Android Apps. arXiv:2108.10381 [cs.CR][68]J. Samhi, A. Bartel, T. F. Bissyande, and J. Klein. 2021. RAICC: Revealing AtypicalInter-Component Communication in Android Apps. In2021 IEEE/ACM 43rdInternational Conference on Software Engineering (ICSE). IEEE Computer Society,Los Alamitos, CA, USA, 1398–1409. https://doi.org/10.1109/ICSE43902.2021.00126[69]Bernhard Schölkopf, John C. Platt, John Shawe-Taylor, Alex J. Smola, and Robert C.Williamson. 2001. Estimating the Support of a High-Dimensional Distribu-tion.Neural Computation13, 7 (2001), 1443–1471. https://doi.org/10.1162/089976601750264965 arXiv:https://doi.org/10.1162/089976601750264965[70]Dawei Shi, Xiucun Tang, and Zhibin Ye. 2017. Detecting environment-sensitivemalware based on taint analysis. In2017 8th IEEE International Conference onSoftware Engineering and Service Science (ICSESS). IEEE.[71]Maddie Stone. [n. d.].The Path to the Payload: Android Edition, 2019. https://cfp.recon.cx/reconmtl2019/talk/TMHQGV/ Accessed December 2020.[72]Kimberly Tam, Salahuddin J Khan, Aristide Fattori, and Lorenzo Cavallaro. 2015.Copperdroid: Automatic reconstruction of android malware behaviors.. InNdss.[73]Oguzhan Topgul. [n. d.].Android Malware Evasion Techniques - Emulator De-tection. https://www.oguzhantopgul.com/2014/12/android-malware-evasion-techniques.html Accessed December 2020.[74]Virus Total. 2020.Virus total free online virus, malware and url scanner. https://www.virustotal.com/en[75]Raja Vallée-Rai, Phong Co, Etienne Gagnon, Laurie Hendren, Patrick Lam, andVijay Sundaresan. 2010. Soot: A Java Bytecode Optimization Framework. InCASCON First Decade High Impact Papers(Toronto, Ontario, Canada)(CASCON’10). IBM Corp., USA, 214–224. https://doi.org/10.1145/1925805.1925818[76]Raja Vallee-Rai and Laurie J Hendren. 1998. Jimple: Simplifying Java bytecodefor analyses and transformations.[77]Victor Van Der Veen, Herbert Bos, and Christian Rossow. 2013. Dynamic analysisof android malware.Internet & Web Technology Master thesis, VU UniversityAmsterdam(2013).[78]V. N. Vapnik. 1999. An overview of statistical learning theory.IEEE Transactionson Neural Networks10, 5 (1999), 988–999. https://doi.org/10.1109/72.788640[79]Fengguo Wei, Sankardas Roy, Xinming Ou, and Robby. 2014. Amandroid: APrecise and General Inter-Component Data Flow Analysis Framework for Se-curity Vetting of Android Apps. InProceedings of the 2014 ACM SIGSAC Con-ference on Computer and Communications Security(Scottsdale, Arizona, USA)(CCS ’14). Association for Computing Machinery, New York, NY, USA, 1329–1341.https://doi.org/10.1145/2660267.2660357[80]Huan Xu, Constantine Caramanis, and Shie Mannor. 2009. Robustness andRegularization of Support Vector Machines.Journal of machine learning research10, 7 (2009).[81]Lifan Xu, Dongping Zhang, Nuwan Jayasena, and John Cavazos. 2018. HADM:Hybrid Analysis for Detection of Malware. InProceedings of SAI Intelligent SystemsConference (IntelliSys) 2016, Yaxin Bi, Supriya Kapoor, and Rahul Bhatia (Eds.).Springer International Publishing, Cham, 702–724.[82]Yinxing Xue, Guozhu Meng, Yang Liu, Tian Huat Tan, Hongxu Chen, Jun Sun,and Jie Zhang. 2017. Auditing anti-malware tools by evolving android malwareand dynamic loading technique.IEEE Transactions on Information Forensics andSecurity12, 7 (2017), 1529–1544.[83]Tianda Yang, Yu Yang, Kai Qian, Dan Chia-Tien Lo, Ying Qian, and Lixin Tao. 2015.Automated detection and analysis for android ransomware. In2015 IEEE 17thInternational Conference on High Performance Computing and Communications,2015 IEEE 7th International Symposium on Cyberspace Safety and Security, and2015 IEEE 12th International Conference on Embedded Software and Systems. IEEE,1338–1343.[84]Yunqiang Chen, Xiang Sean Zhou, and T. S. Huang. 2001. One-class SVM forlearning in image retrieval. InProceedings 2001 International Conference on ImageProcessing (Cat. No.01CH37205), Vol. 1. 34–37 vol.1. https://doi.org/10.1109/ICIP.2001.958946[85]Qingchuan Zhao, Chaoshun Zuo, Brendan Dolan-Gavitt, Giancarlo Pellegrino,and Zhiqiang Lin. 2020. Automatic Uncovering of Hidden Behaviors From InputValidation in Mobile Apps. In2020 IEEE Symposium on Security and Privacy (SP).IEEE, 1106–1120.[86]Cong Zheng, Shixiong Zhu, Shuaifu Dai, Guofei Gu, Xiaorui Gong, Xinhui Han,and Wei Zou. 2012. Smartdroid: an automatic system for revealing ui-basedtrigger conditions in android applications. InProceedings of the second ACMworkshop on Security and privacy in smartphones and mobile devices.[87]M. Zheng, M. Sun, and J. C. S. Lui. 2014. DroidTrace: A ptrace based Androiddynamic analysis system with forward execution capability. In2014 InternationalWireless Communications and Mobile Computing Conference (IWCMC). 128–133.https://doi.org/10.1109/IWCMC.2014.6906344[88]Wu Zhou, Xinwen Zhang, and Xuxian Jiang. 2013. AppInk: WatermarkingAndroid Apps for Repackaging Deterrence. InProceedings of the 8th ACM SIGSACSymposium on Information, Computer and Communications Security(Hangzhou,China)(ASIA CCS ’13). Association for Computing Machinery, New York, NY,USA, 1–12. https://doi.org/10.1145/2484313.2484315[89]Yajin Zhou and Xuxian Jiang. 2012. Dissecting android malware: Characterizationand evolution. In2012 IEEE symposium on security and privacy. IEEE, 95–109.
735