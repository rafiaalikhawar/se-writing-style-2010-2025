A HighlyScalable,Hybrid,Cross-Platform Timing Analysis
FrameworkProviding AccurateDiﬀerential Throughput
Estimation via Instruction-Level Tracing
Min-Yih Hsu
minyihh@uci.edu
University ofCalifornia, Irvine
California, USAFelicitasHetzelt∗
fhetzelt@uci.edu
University ofCalifornia, Irvine
California, USADavid Gens∗†
dgens@uci.edu
University ofCalifornia, Irvine
California, USA
MichaelMaitland
michael.maitland@si/f_ive.com
SiFive
California, USAMichaelFranz
franz@uci.edu
University ofCalifornia, Irvine
California, USA
ABSTRACT
Diﬀerentialthroughputestimation,i.e.,predictingtheperformance
impactofsoftwarechanges,iscriticalwhendevelopingapplications
thatrelyonaccuratetimingbounds,suchasautomotive,avionic,or
industrialcontrolsystems.However,developersoftenlackaccess
to the target hardware to perform on-device measurements, and
hencerelyoninstructionthroughputestimationtoolstoevaluate
performance impacts.
State-of-the-arttechniquesbroadlyfallintotwocategories:dy-
namic and static. Dynamic approaches emulate program execution
usingcycle-accuratemicroarchitecturalsimulatorsresultinginhigh
precisionatthecostoflongturnaroundtimesandconvolutedse-
tups. Static approaches reduce overhead by predicting cycle counts
outside of a concrete runtime environment. However, they are lim-
ited by the lack of dynamic runtime information and mostly focus
onpredictionsoversinglebasicblockswhichrequiresdevelopers
tomanually construct criticalinstruction sequences.
We present MCAD, a hybrid timing analysis framework that
combinestheadvantagesofdynamicandstaticapproaches.Instead
of relying on heavyweight cycle-accurate emulation, MCAD col-
lectsinstructiontracesalongwithdynamicruntimeinformation
from QEMU and streams them to a static throughput estimator.
This allows developers to accurately estimate the performance im-
pact of software changes for complete programs within minutes,
reducing turnaround times by orders of magnitude compared to
existingapproacheswithsimilaraccuracy.Ourevaluationshows
thatMCADscalestoreal-worldapplicationssuchasFFmpegand
Clangwithmillionsofinstructions,achieving <3%geo.meanerror
compared to ground truth timings from hardware-performance
counters on x86andARM machines.
∗Bothauthors contributed equallytothis research.
†Nowaﬃliated withCerebras
ESEC/FSE ’23,December 3–9, 2023, SanFrancisco, CA, USA
©2023 Copyright held bytheowner/author(s).
ACM ISBN979-8-4007-0327-0/23/12.
https://doi.org/10.1145/3611643.3616246CCSCONCEPTS
•Generalandreference →Performance ;•Computingmethod-
ologies→Modelingandsimulation ;•Softwareanditsengineer-
ing→Software performance ;Software evolution .
KEYWORDS
performance, throughput analysis, diﬀerential throughput analysis,
combiningstatic anddynamic analyses
ACM ReferenceFormat:
Min-Yih Hsu, Felicitas Hetzelt, David Gens, Michael Maitland, and Michael
Franz.2023. AHighlyScalable,Hybrid,Cross-PlatformTimingAnalysis
Framework Providing Accurate Diﬀerential Throughput Estimation via
Instruction-Level Tracing. In Proceedings of the 31st ACM Joint European
Software Engineering Conference and Symposium on the Foundations of Soft-
wareEngineering(ESEC/FSE’23),December3–9,2023,SanFrancisco,CA,USA.
ACM,NewYork,NY,USA, 11pages.https://doi.org/10.1145/3611643.3616246
1 INTRODUCTION
Semantically equivalent modi/f_ications of a given piece of software
canresult invaryingdegreesofperformance degradationdue to
resourcecontentionsonthearchitecturalandmicroarchitectural
level. For systems that have tight timing restrictions, it is therefore
criticaltoidentifyspeci/f_icimplementationsthatminimizenegative
performance impacts and maintain timing restrictions over the
executionofthewholeprogram.Ifthetargetsystemisnotavailable
toperformon-devicemeasurements,developersinsteadneedtorely
ontoolstoestimatecyclecountsforagivenprogramorinstruction
sequence.Tothatend,severalapproacheshavebeendevelopedthat
roughlyfallintooneoftwocategories:(i)emulatingtheexecutionof
concrete runtime instances of the program on simulated hardware
(i.e.,dynamic approaches ) and (ii) estimating the cycle count of
programinstructionswithoutconcreteexecutionunderanabstract
runtime environment (i.e., static approaches ).
Dynamic approaches achieve high precision using architectural
simulators [ 9,11,25] which faithfully model the runtime behavior.
Theyprovideconcreteandgenerallyaccurateestimates,however,
theysuﬀerfromhighruntimeoverheadandcanrequirehoursto
daystoanalyze aprogram.Furthermore, architectural simulators
exhibit a high architecture dependence and are complicated to set
Thiswork islicensedunderaCreativeCommonsAttribution4.0Interna-
tional License.
821
ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA Min-Yih Hsu, Felicitas Hetzelt, David Gens,MichaelMaitland, andMichaelFranz
up,oftenrequiringdedicatedexpertknowledgeand/orgivingriseto
compatibility issues with standard tools and default environments.
Static approaches [ 2,6,13,14,16–18,20,23] alleviate the per-
formance and setup cost of dynamic hardware simulators. Tradi-
tionally,suchapproachestarget worst-caseexecutiontimepredic-
tions over all possible execution paths [ 13,14,17,18,23]. More
recent works [ 2,6,16,20] focus on smaller execution sequences
andalsoconstructparametricmodelsthatgeneralizetomultiple
architectures. These models are either trained end-to-end using
throughputdata[ 20]orprogrammaticallytunedforkeyparameters
thatarepubliclyavailableorobtainedfrommeasurements[ 6,16].
However,staticapproachesarefundamentallylimitedinpractice
due to their lack of concrete dynamic runtime information. Hence,
traditionalstaticapproacheslacksupportforessentialprogramcon-
structssuchasloops,data-dependentcontrol/f_lows,andmemory
accesses[ 7,21].Inaddition,thescopeofmanystaticthroughput
estimationtoolsislimitedto throughputpredictions ofindividual
basic blocks [ 6,16,20], i.e., only a handful of instructions. Even
fortoolsthatcanintheoryprocessmultiplebasicblocksatonce,
predictionsdonotusuallyholdacrosscontrol-/f_lowtransfers.For
example, MCA [ 2] does not follow call or jump targets and instead
simplyfallsthroughtothenextinstructionwhileaddingastatic
cyclepenalty1.
Inthispaper,wepresentMCAD,alightweight alternativethat
provides whole-program throughput prediction of binary software.
MCAD follows a hybrid approach that supplements static through-
put estimates with dynamic runtime information. To avoid the
overhead of cycle accurate architectural simulation, MCAD uses
an emulation-based approach to obtain execution traces using
QEMU [8] and forwards them to the LLVM Machine Code Ana-
lyzer(MCA)[ 2]forinstruction-levelanalysis.Inaddition,MCADex-
tendsMCAtoresolveseveralinherentlimitationsofstaticthrough-
put estimation. First MCA’s instruction analysis is redesigned to
processinstructionsinastreamingfashion,whichenablestheanal-
ysisto scaletolarge real-worldbinaries. Second, MCAD provides
an interfacetoincorporatedynamicinformationintothe analysis.
The dynamic information captures concrete control-/f_low which
allows MCAD to accurately predict instruction cycle counts across
basicblockboundaries.Inaddition,theinstructionstreamcanbe
supplementedwitharbitrary metadata,such asmemory aliasing
properties or execution context information, to further improve
prediction accuracy.
ThemainpurposeofMCADistoprovidefast,yetaccuratediﬀer-
ential timinganalyses:cyclecounts forwholeprogramexecution
traceswhichtypicallycontainhundredsofthousandstomillionsof
instructionscanusuallybeproducedwithintheorderofminutes
orseconds,whichallowsdeveloperstoquicklyidentifytheleast
intrusive change with respect to execution time. We extensively
testandevaluateMCADwithrespecttoscalabilityandaccuracyon
a number of diﬀerentreal-world applicationssuch as FFmpeg and
Clang to demonstrate that MCAD can model microarchitectural
behaviors,suchasinstructionlatenciesinsuperscalarprocessors,
accuratelyandwithlowcost.Thegeo.meanerrorindiﬀerential
timing between MCAD and hardware performance counters in our
1https://github.com/llvm/llvm-project/blob/main/llvm/lib/MCA/InstrBuilder.cpp#
L224loop:
vmulps %xmm0, %xmm1, %xmm2
vhaddps %xmm2, %xmm2, %xmm3
vhaddps %xmm3, %xmm3, %xmm4
cmp %r9d, %eax
jle L1
L0:
mulq %r8
jump loopL1:
movl 16(%ebp),%eax
addl 8,%ebp
jno loop
Figure 1:x86_64 assemblycontrol/f_low.
experiments is smaller than 3% across several diﬀerent microarchi-
tectures andapplicationsoftware.
SummaryofContributions:
•WepresentMCAD:anewopen-source2frameworkforthrou-
ghputestimationyielding highlyaccurate diﬀerential tim-
ings,onparorbetterthanthecurrentstate-of-the-art,while
reducing turnaround time byseveral orders of magnitude.
•Our prototype implementation leverages QEMU as a fast
instruction executor, utilizing MCA to model individual per-
instructionexecutioncycles,ratherthansimulation-based
approachesthatfaithfullymodelcomplexprocessorfront-
ends.
•WeprovideadetailedevaluationofMCADwithrespectto
accuracy and scalability for the popular x86 and ARMv8
instruction-setarchitectures usingseveral diﬀerentdevices
andhardware-performancecountersto collect timingmea-
surements for real-world traces as ground truth.
2 BACKGROUNDAND MOTIVATION
Inthissectionweprovidebackgroundoninherentlimitationsof
static throughput estimation approaches and present a use case
scenario to motivate the designgoalsof MCAD.
2.1 Static Throughput EstimationChallenges
Throughput estimation is an active area of research that aims to
statically predict the performance upper bound of a program, usu-
allymeasuredbycyclecountsorInstructionPerCycle(IPC),ofa
singlebasicblock.Currenttoolsmodelmicroarchitecturaldetails
such asinstruction latency and numberof micro-opsof the target
processor. However, there are two major issues with this approach:
(i) it does not easily transfer across branch instructions or function
call boundaries (ii) dynamic information such as execution context
andmemory aliasingisusually not taken intoaccount.
ControlFlowTransfers. Figure1showsthecontrol/f_lowofanx86_64
assembly code snippet consisting of three basic blocks, loop,L0,
andL1. Blockloopcalculates a vector dot product followed by
a conditional branch into either block L0orL1based on a data-
dependent comparison, withboth blocks jumping back to loopat
the end.
UsingIntelCoﬀeeLakeasanexampletargetarchitecture,through-
putpredictionsoftheindividualbasicblocksofthisprogramwill
2https://github.com/securesystemslab/LLVM-MCA-Daemon.Someofour contribu-
tions in thisworkhavebeen adopted and arecurrently in use as part of LLVM.
822A Highly Scalable, Hybrid,Cross-Platform DiﬀerentialThroughput EstimationFramework ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
notgeneralizeacrossexecutions.Thereasonisthatinstruction-level
throughputforthisprogramactuallydependsontheorderingof
executedbasicblocksonthatarchitecture.Inparticular,executions
whereL0followsloop(Listing1)areroughly5 ∼10cyclesslower,
per iteration, than executions in which L1followsloop(Listing2).
This might seem counterintuitive as Listing 1contains fewer in-
structions than Listing 2and, more importantly, there is a memory
read instruction ( movl 16(%ebp), %eax ) in the latter trace, which
shouldbeslowerthanscalarmultiplication( mulq %r8 ).However,
measurements on the target architecture reveal that there is a sub-
stantial slowdown in traces that follow the shorter Listing 1due to
resourcecontentionbetween the twobasic blocks.
1 vmulps %xmm0, %xmm1, %xmm2
2 vhaddps %xmm2, %xmm2, %xmm3
3 vhaddps %xmm3, %xmm3, %xmm4
4 cmp %r9d , %eax
5 jle L1
6 mulq %r8
7 jmp loop
Listing 1:Traceofexecuting L0afterloopinFigure 1
1 vmulps %xmm0, %xmm1, %xmm2
2 vhaddps %xmm2, %xmm2, %xmm3
3 vhaddps %xmm3, %xmm3, %xmm4
4 cmp %r9d , %eax
5 jle L1
6 movl 16(%ebp ) , %eax
7 addl 8 , %ebp
8 jno loop
Listing 2:Traceofexecuting L1afterloopinFigure 1
Speci/f_ically, the vhaddps instruction always requiresexecution
port 5, which is also demanded by the mulqinstruction [ 5]. This
createsadependencybetweenthosetwoinstructionsandforcesthe
mulqinstructiontostalluntilprevious vhaddpsinstructionsrelease
thedesiredexecutionport.Ontheotherhand,inListing 2movland
addldo not have con/f_licting resource requirements with the previ-
ousinstruction.Thatmeansbothinstructionswillbedispatched
intoexecutionnolaterthantheprevious vhaddps instructionsand
execute in parallel, thus, resulting in higher instructions-per-cycle
count thanListing 1.
As explained earlier, current static throughput prediction ap-
proaches will use static instruction ordering as a substitute for
dynamiccontrol/f_low,resultinginalow-accuracyprediction.More-
over, existing approaches face severe practical limitations with
regardstoscalability.InSection 3wedetailourdesignofMCAD
whichtackles both ofthesechallenges.
1 vsetvli zero , a0 , e8 , m2, tu , mu
2 vadd.vv v12 , v12 , v12
3 vsetvl rd , rs1 , rs2
4 vadd.vv v12 , v12 , v12
Listing 3:Example RISC-VassemblycodeExecutionContext. Listing3showsaRISC-Vassemblysnippetcom-
prisedofvectorinstructions.InRISC-V,the VSETVLandVSETVLI
instructionssetthevectorlengthmultiplier(LMUL)whichdeter-
mines the number of elements that are processed by subsequent
vectorinstructions.Therefore,thelatencyofeachvectorinstruc-
tion diﬀers depending on thecurrent value of LMUL. For instance,
line 1 in Listing 3sets LMUL to 2 (due to the m2operand), which
resultsina cycle latencythatre/f_lects a LMUL of 2for the VADDin-
structioninthenextline;inline3LMULissettothevaluestoredin
registerrs2, resulting in a potentially diﬀerentlatency that re/f_lects
the LMUL that was just set, for VADDat line 4. Due to the lack of
dynamicruntimeinformation,staticapproachescannotdetermine
theconcretevalueof rs2andthereforecannotaccuratelymodel
the latency ofthe VADDinstructioninline4.
This example shows that while the instructions on line 2 and
4 areidentical,theirexactlatenciesare actuallyin/f_luencedbythe
environment values, namely LMUL, as well as dynamic values
storedintheregisters.Currentthroughoutpredictionapproaches
fail to provide accurate estimations for these cases and resort to
a conservative upper bound latency due to the lack of dynamic
information. Some existing tools can circumvent this issue with
manualannotations.Forinstance,LLVMMCAallowsdevelopers
to instrument their programs with special comments that contain
runtime information, which MCA uses to make more accurate
queriesintotheschedulermodel.However,whiletheseinstrument
comments can improve analysis, handwriting themdoesnot scale
well withlarge number of instructions.
Memory Aliasing. Real processors reorderinstructions tooptimize
instructionthroughput.Tothatend,theyanalyzememorydepen-
dencies between individual load and store instructions to deter-
mine a valid instruction scheduling that minimizes contention.
Static throughput estimators trying to model this behaviour are
limited due to the lack of concrete memory aliasing information.
Forinstance,Listing 4showstwox86_64instructionsthataccess
memoriesindexedbybaseregisters %r13and%r14.Withoutknow-
ing the exact values in these base registers, it’s hard to know if
memoryaliasingpreventstheinstructionsfrombeingreordered,
whichmakesabigdiﬀerenceintermsoflatency.Sometoolslike
MCA either assumes that individual memory operationsnever ac-
cessaliasingaddressesorthatallmemoryaccessesalias;bothcases
resultinginloweredprediction accuracy.
1 addq7 , 8(%r13 )
2 movq%r9 , 8(%r14 )
Listing 4:x86_64 assemblycodewith memory accesses
2.2 Diﬀerential Throughput Estimation
Diﬀerentialthroughputestimationismeanttopredicttheperfor-
mance impacts of applying certainchanges ( e.g.software patches)
on the target programs. To motivate MCAD’s diﬀerential through-
out estimating capabilities, we detail how MCAD can be applied to
/f_indtheoptimalvariantofasecuritypatchtoabinarywithtight
timing requirements post deployment. In our scenario, a buﬀer
over/f_low vulnerability due to a missing bounds check has been
identi/f_ied. To /f_ix the vulnerability the developer needs to patch the
missingcheckintothebinary.AsdetailedinSection 2.1thelocation
823ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA Min-Yih Hsu, Felicitas Hetzelt, David Gens,MichaelMaitland, andMichaelFranz
QEMU
ABCD Plugin
Target Binary
EmulationBroker Frontend
Instruction 
streamBroker
Disassembler
Sub-Region 
Address Range
Debug InfoScheduler
Load / Store 
UnitResource 
ManagerSub-Region 
ManagerHW Component SimulatorsMCAD Core
Summary ViewSocket
Analysis 
Pipeline
Timeline ViewViewerCore
Figure2:Generalwork/f_lowandmajorcomponentsinMCAD.
Components with dashed outline are optional
ofthepatchaswellasthespeci/f_icassemblyinstructionscanhavea
highimpactonoverallperformanceduetoresourcecontentionson
the micro architectural level. Developers therefore typically iterate
throughseveralsemanticallyequivalentversionsofapatchinorder
to minimize the performance degradation. MCADprovidesdevel-
operswiththemeanstoquicklyiteratethroughseveralversionsof
the target binary to estimate the resulting performance impact and
triagepotential bottleneckswithoutrequiringaccesstotheactual
hardware.
To perform the throughput estimation, a developer runs the
originalbinaryaswellasseveralpatchcandidateswithconcrete
inputs through the MCAD pipeline and compares estimated cy-
clecountsbetweenversions.Ifrequired,MCADallowstorestrict
the analysis to speci/f_ic regions of the program (see Section 3.1).
In addition, MCAD provides a timeline view which details each
instruction’s state transitions through the instruction pipeline (see
Section4.3). This information helps developers to triage perfor-
mance degradations and guides them towards execution paths that
are less sensitive to changes.
3 DESIGN
In this section we present our overall design of MCAD depicted in
Figure2. As explained in the previous section, current throughput
predictionapproachesfaceseverechallengeswithrespecttopre-
diction across basic blocks, lack of dynamic information, as well
as scalability and turnaround times. The main goal of MCAD is
totackleallofthesechallengestoenablescalableandprecisedif-
ferential throughput analyses that can be used to actively drive
development and steer engineers towards implementations with
favorable runtimebehavior.
3.1 GoalsandChallenges
MCAD’s designshould tackle three main goals:
First, MCAD aims to provide whole-program throughput esti-
matesacross thousandsofbasic blocks and potentially millions of
instructions. At a high level, MCAD consists of a broker compo-
nentthatprovidesexecutiontracesinformofinstructionstream
alongwithitsdynamiccontexts,andacorecomponentthatana-
lyzesinstruction-levelthroughputoftherespectivetraceon-the-/f_ly.
Resultscanthenbeprocessedbyaviewercomponentforhuman-
readablesummarizationanddatareporting.Inprinciple,themethod
bywhichexecutiontracesareobtainedandstreamedtothecore
component is not tightly coupled to the method that is used to
analyze the instruction stream. In early tests we compared severalexistingthroughputanalysistoolsforusewithourcorecomponent.
However, we encountered several challenges with adopting any of
themforourframework.Asillustratedintheprevioussection,state
of the art throughput prediction approaches do not generalize over
dynamic contexts like control-/f_low transfers, register state, and
memoryaliasing.Besides,asexistingthroughputpredictiontools
are designed for single basic block use, they also fail to scale up,
in terms of both memory consumption and processing capabilities,
when streaming input instructions on-the-/f_ly from the broker com-
ponentevenfortrivialprograms.Wealsoencounterednumerous
bugswhenusingthetoolsthatseemedmost/f_ittinginthisdynamic
context,someofwhichwe detailinSection 4.
Second,MCADaimstosupportadevelopment-drivenwork/f_low.
Thismeans,thatdevelopersareabletouseMCADtoanalyzethe
timing impact after modifying some part of the code, which might
taketheformofbothabinarypatchorasource-levelchangeofthe
originalprogramunderourmodel.Inadditiontowhole-program
analyses, developershenceare able to chooseto analyze only parts
of the program. Selecting which parts of the program to analyze is
doneatvaryinglevelsofgranularitytoreducenoiseintheresulting
reports and speed up the analysis if so required. For example, in
the scenario outlined by Section 2.2, the target program might
contain components such as unmodi/f_ied sequences of code, which
areirrelevanttothethroughputanalysis,butwhoseruntimemight
dependonunpredictableinputs( e.g.randomnumbergenerators).
Insuchcases,thedevelopercancircumventthosecomponentsby
excluding theirtraces from MCAD’s analysis.
Third,MCADaimstoprovide timelyfeedbackforthethrough-
putestimatesusinganapproachthatideallyalso generalizes across
architectures.Whilepurelydynamic approachesare alreadycapa-
ble of producing whole-program estimates today, the associated
turnaround times and costs of setting up and running full-scale
system simulation can be prohibitively expensive (i.e., on the order
ofhoursorevendays)[ 9,11,25].Furthermore,existingdynamic
throughput analysis tools are often tightly coupled to a speci/f_ic
architecture,whichiswhyweoptforanemulation-basedapproach
for producing execution traces inside our broker component using
QEMU [8].
We will elaborate how MCAD tackles each of the respective
challengestoachievethesegoalsthroughouttherestofthissection.
3.2 ScalableThroughput Prediction
AsexplainedinSection 2.1allexistingthroughputpredictionen-
gines are designed with single-basic-block use in mind. In our pro-
totypewebuildontopofMCA[ 2],aperformanceanalysistooland
librarythatwasdesignedtoestimatethebasicblockthroughputin
a static fashion. MCA employs a microarchitectural simulator to
emulate an individual instruction’s timeline inside an out-of-order
processor. It taps into the LLVM compiler’s scheduling database,
a mature and production-tested data source whose contents are
curatedbyhardware vendors.
However, we found that MCAhasdiﬃculties toscale upin our
dynamicscenario.Likeotherthroughputpredictionengines,itdoes
notsupportaccurateanalysisofinstructionsbeyondabranchpoint
or a function call out of the box. On top of that, we found that
some of the design trade-oﬀs inside MCA make it prone to high
824A Highly Scalable, Hybrid,Cross-Platform DiﬀerentialThroughput EstimationFramework ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
memory pressure while processing large number of instructions.
EnablingonlineanalysiswithinMCADrequiredseveralchangesto
the underlying analysis infrastructure, such as MCA’s serialization,
memory model,andinstructionlifecycle.
In Section 4.2, we explain our modi/f_ications of MCA used in
MCADtotackletheaforementionedissuesandmakeMCAD’score
componentscaleupto real-world applications.
3.3 Development-DrivenWork/f_low
MCAD enablesadevelopment-drivenwork/f_low byproviding fast
whole-program throughput estimates that can easily be compared
between two versions of a program. Furthermore, for cases that
only modify a small portion of the original binary, MCAD also
provides an option to analyze only part of the binary. In this mode,
developers can designate the desired area by either specifying the
symbol of a function or providing explicit address ranges in the
program. If an address range is provided, MCAD essentially yields
theoriginalbasic-blockgranularity oftheunderlyinganalysis en-
gine, while providing the /f_lexibility of comparing the execution of
multiple basic blocks at the same time. The proposal in Section 3.5
to automatically insert runtime information via instrumentcom-
mentsintheexecutiontracelowerstheburdenondevelopers,since
they no longer have to insert handwriten comments everytime the
LMUL changes, nor modify existing comments when a program
changes.
3.4 Analysis Performance andGeneralization
Across Architectures
Thebrokercomponentisresponsibleforsupplyingexecutiontraces
tothecorecomponent.Thisincludesinteroperatingwiththeorigin
of execution traces and converting them into a uni/f_ied low-level
representation. This also means that the broker and core compo-
nents need to work together to enable a timely and architecture-
independentoperationofMCAD.Bydefault,executiontracesare
transmitted remotely from QEMU using a custom plugin. QEMU’s
emulation-basedapproachincursaround30%runtimeoverhead[ 15],
eﬀectivelyenablingnear-nativeexecutionspeedswhenusinghard-
warevirtualizationextensions.QEMUalsohasextensivesupport
for many major architectures,3meaning that MCAD’s broker com-
ponentisabletoful/f_illbothoftheserequirements.Itisnoteworthto
mention that MCAD also provides a facility for reading oﬄine exe-
cutiontraces,whichcanbecollectedfromexecutionsonaphysical
deviceusinganykindoftracingmethodavailableforthatdevice.
Asmentionedearlier,MCAD’scorecomponentusesMCA.Since
MCAusesLLVM’s infrastructure,targetingdiﬀerent hardwarear-
chitecturesandprocessormodelsintheanalysisenginerequires
littleeﬀort.4Asaresult,boththebrokerandthecorecomponentof
MCADgeneralizewellacrossseveralarchitecturesandprovidetop-
of-the-line performance. Moreover, with QEMU and LLVM MCAD
uses tools that many software developers will already be deeply
familiar with.
3QEMU supports x86, MIPS, SPARC, ARM, PowerPC, RISC-V among many others,
includingindividual processor models and speci/f_icmicroarchitectures
4LLVM supports x86,MIPS, SPARC,ARM, PowerPC, RISC-Vamongmanyothers.3.5 Supplementing DynamicInformation
As detailed in Section 2.1, due to unknown runtime state static
throughput estimators fail to model many essential programming
constructs accurately. MCAD addresses this issue by providing
concrete runtime information that resolves ambiguities regarding
blockordering, registerstate andmemory aliasing.
Ingeneral,thepredictionsofstaticthroughputestimatorstonot
generalizeaccrossbasicblockboundariesduetothelackofinfor-
mation aboutdynamic targets anddata-dependent control/f_lows.
MCA,forexample,simplyfallsthroughtothenextinstructionupon
encountering ajump or call. MCAD supplements this information
basedontheconcreteexecutiontracesobtainedfromQEMUand
forwardedto our analysiscore.
TheexampleillustratedbyListing 3(§2.1)showsthediﬃculties
oftraditionalthroughputanalysistoprovideaccuratepredictionsin
the presence of run time information such as values of immediates
or data in registers. Although existing tools like LLVM MCA are
abletocircumventthisissuewithmanualannotations,suchsolu-
tionsdon’tscalewellwithlargenumberofinstructionscommonin
an execution trace. With MCAD, a potential solution to accurately
analyzeListing 3isprovidingnecessarydynamicinformationofthe
executiontracetotheanalysisengine.Morespeci/f_ically,thetool
responsible for generating execution traces (QEMU by default) can
extract LMUL when it comes across either the VSETVLorVSETVLI
instruction. Such LMUL values are subsequently provided along
withthe trace to the analysisengine to aid precision, withoutany
intervention fromthedeveloper.This caneasilybe generalizedto
otherapplicationsbysendingdiﬀerentkindsofdynamicinforma-
tionto the analysisengine accordingly.
MCA contains a component called Load Store Unit (LSUnit in
Figure2)whichsimulatesloadandstorereorderingthatcouldhap-
peninthehardwareschedulerofthesimulatedprocessormodel.
This type of hardware optimization re-orders memory instructions
to break dependencies when possible, which is largely determined
by their memory aliasing properties at runtime, as shown in the
exampleillustratedbyListing 4(§2.1).However,withoutprecise
memoryaccessinformation,MCAcanonlymakecoarse-grained
assumptions, for instance, all memory instructions are aliasing
witheachother,whicharecontrolledby acommandlineparame-
ter.MCADleveragesthememorytracescollectedfromQEMUto
improvethissituation.Wemodi/f_iedMCA’sLoadStoreUnitsuch
thataliasingpropertiesarenowdictatedby/f_ine-grainedmemory
accessing traces as provided by our QEMU plugin. This enables
our customcore componenttosimulateloadandstore reordering
with higher accuracy by using dynamic information as it becomes
available duringexecution.
3.6 Model Assumptions
MCAD is able to model out-of-order and superscalar execution
commonlyseeninmodernprocessors.SupportforSimultaneous
Multithreading (SMT), data or instruction cache and branch pre-
dictor simulation, are planned as future additions to the project. In
addition,MCADcurrentlyonlysupportsanalysisofsinglethreaded
executions.
825ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA Min-Yih Hsu, Felicitas Hetzelt, David Gens,MichaelMaitland, andMichaelFranz
4 IMPLEMENTATION
In this section we describe the work/f_low and implementation of
MCADindetail.Figure 2depictstheinteractionbetweenthedif-
ferent components: /f_irst, the target binary program is executed
byQEMU,whichcollectsexecutiontracesandsendsthemtoour
analysisengineinrealtime.Insideouranalysisenginetheexecuted
instructionsarefurtherprocessedbytiminganalysesbuiltontop
of MCA [ 2], which provides algorithms for microarchitectural sim-
ulationandinstructionschedulingofmodernprocessors.Finally,
MCAD provides estimates for key timing and performance metrics
liketheprospectivecyclecounts,instruction-levelthroughput,and
the abilityto identifypotentialbottlenecks.
4.1 InstructionBroker
MCAD’sbrokerimplementationisastandaloneprocessthatpro-
ducesMCInst[4]objects,aninternalrepresentationformachine
codeinstructionsusedwithinLLVM,andforwardstheminbatches
tothecorecomponent.Thebrokerinterfaceisdesignedtobeexten-
sible andallow integrationof customimplementations and enable
streamingofinstructionsequencestothecorecomponentfroma
variety of diﬀerent sources. So far, we integrated and tested two
brokerimplementations:anassembly/f_ilebrokerthattakesitsin-
put from an assembly /f_ile on disk and a QEMU broker that uses
a QEMU plugin to communicate with the QEMU-broker process
usingTCP socketstoprocess therawexecutiontraceinrealtime
before streamingthemintothe core componentfor analysis.
Brokerimplementationscanchoosetoattacharbitrarymetadata
tothestreamedinstructiontrace:forinstance,byattachingloadand
storeaddressesandthesizeofmemoryoperationswecanenable
moreprecisedependencydetectionbetweenmemoryaccessesin
the analysisengine ofthe core component. In particular,MCAD’s
QEMUplugincollectsrawinstructionsasexecutedbytheemulator
alongside additional information regarding memory operations,
which is then used to improve analysis results with respect to
instructionreordering.InthismodeofoperationMCAD’sbroker
dynamically instruments memory read and write operations to
gathertargetaddressandsizeofthedata.TheQEMUpluginwill
then send these data to the receiving core component that runs
in parallel in a separate process. Inside the core component this
metadata that is attached to memory operations is then inserted
intoaregistrythatisusedbythecorecomponentforjointanalysis.
Developingcustombrokersisstraightforwardandonlyrequires
implementing a few callback functions before loading them as
sharedlibrariesduringruntime.Thisallowsuserstorapidlyswitch
between diﬀerent workloads and environments depending ontheir
needs.Itisimportanttonotethatwedonotmakeanyassumptions
aboutabroker’sinternalexecutionmodel–solongasthebroker
adheres to the streaming interface to supply the next batch of
instructions.
4.2 Analysis Core
Ourcorecomponentbuildsontopofstate-of-the-artthroughput
prediction engines, which are designed as oﬄine tools for static
throughput estimation ofsmall sequences ofmachineinstructions
(usually at the basic block granularity). Given a (short) sequence of
assembly instructions, they provide throughput estimation resultsonthemicroarchitecturalleveleitherthroughend-to-endtrained
models for a given architecture or through simulation of the diﬀer-
entstagesinside amodern processorwithvaryinglevels ofdetail
andmanuallytunedkeyparametersperarchitecture.Unfortunately,
all existingthroughput prediction tools failed to scale up with our
dynamic model of execution: as an example, using the standard
videoandaudioencoderFFmpeg[ 24]executesaround20million
instructions on a Linux x86_64 machine while decoding a short
MPEG-4 video with duration of 2 seconds. Within MCAD, this
typeofapplicationwouldbeconsideredalightweightreal-world
workload.Wefoundthatnoneoftheexistingapproacheswereable
to analyze anywhere near this kindof workload.
However, since MCA already has support for slightly larger
pieces of code compared to all other related approaches through
theirloopkernel analysis,weimplementedMCAD’sdefaultanalysis
engineontopofthat.OurinvestigationintoadoptingMCAforour
corecomponentshowedseveralfailurecaseswhilehandlinglarger
workloads.Internally,MCAmodelsfourdistinctexecutionstages
Entry,Dispatch,Execute,andRetire.UnderMCAD’swork/f_low the
instruction stream provided by the broker enters from the Entry
stageandisprocessedbyeachsubsequentstagesequentially.MCA
then assigns aninternal datastructure to eachinstruction to keep
track of its scheduling status within the simulation pipeline. Origi-
nally, this pipeline reads all input instructions ahead of time before
the start of the analysis. Because MCA assumes those instructions
tocomefroma/f_ile.Thisproperty,whileitalignswiththeoverall
designgoalofMCAtoprovidethroughputestimatesforonlysmall
sequences of assembler instructions, is not suited for whole pro-
gramanalysis.Insomeofourtests,MCAconsistentlydrainedall
available physical memory on the machine running the analysis
dueto the allocation ofthis internal instructionrepresentation.
To address the scalability issue we created a new incremental
mode for the MCA simulation pipeline. In this mode, the simu-
lation pipeline fetches input instructions incrementally. If there
are no instructions available from the input source, the pipeline
willsaveitscurrentstateandexit.Uponthearrivalofnewinput
instructions,thesimulationwillberestoredandproceedfromits
previousstate. Toreduce memoryconsumption,weimplemented
a new instruction recycling mechanism for the MCA simulation
pipeline. This instruction recycler will reclaim and collect inter-
nal instruction data structures from retired instructions, instead of
releasing their memory. These recycled data structures will then
bereusedtomodelnewincominginstructions.Ourexperiments
showedthatwiththis recycling mechanism,MCAD’score analysis
uses one third of memory on average than the unmodi/f_ied MCA
implementation.
MCA simulates diﬀerent execution units which process individ-
ual instructions and determine results of the operation in question.
Theseestimatesincludecyclecounts,potentialpipelinestalling,and
predictionsofpossibleinstructionre-ordering.Forinstance,MCA’s
Load-StoreUnittrackstheavailabilityofmemoryoperationsand
their(data)dependencies.Thisiscrucialforsimulatingout-of-order
schedulinginmodernprocessors,whichfrequentlyreordermemory
operations based on their dependencies. We signi/f_icantly extended
theseexistingcapabilitiesbyprovidingan onlineanalysiswork/f_low:
by sequentially processing the incoming instruction stream and
itsdynamiccontextsaccordingtothesimulatedpipeline,MCAD
826A Highly Scalable, Hybrid,Cross-Platform DiﬀerentialThroughput EstimationFramework ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
is able to present an estimate of how arbitrarily long instruction
sequencesmightbe scheduledwithin the processor.
4.3Sub-Region Feature and Viewer Component
MCAD’s viewer component displays throughput estimations with
informationliketotalcyclecountsorpotentialpipelinestalls.An
exampleof this can be seeninListing 5. We also prototypeda view
of the timingitineraryof individualinstructionin a timeline view.
For instance, Listing 6shows the timeline of the execution trace
in Listing 1. From this timeline we can easily spot the resource
contentionbetween mulqandvhaddps asmentionedinSection 2.1.
This particular view is a fork from the timeline view that exists
in MCA. However, the timeline view in MCA has limitations on
the maximum number of analyzed instructions and cannot inspect
theitineraryofasubsetofananalyzedexecutiontracewhichwe
implemented as part of MCAD’s subregion feature. For this reason,
third-partyvisualizationtoolsarealsosupportedinthiscomponent.
For instance, we prototyped a new timeline view based on Chrome
Developer Tools (DevTools) [ 1]. In our early test we already found
thisaloteasiertoscrollandnavigatethroughthethousandsoreven
millions of instructions that are processed by MCAD, compared to
the terminal-based LLVM MCA timeline view. Since this view was
designed to analyze large number of network requests it provides
asolidbasisto helpour newtimelineviewscaleup.
Instructions: 350
Total Cycles: 262
Total uOps: 600
Dispatch Width: 6
uOps Per Cycle: 2.29
IPC: 1.34
Block RThroughput: 5.0
Listing 5:Summary View
[1,0] . D=eeeeE---------R .. vmulps
[1,1] . D====eeeeeeE---R .. vhaddps
[1,2] . D==========eeeeeeER vhaddps
[1,3] . D==eE------------R cmpl
[1,4] . D===eE-----------R jle
[1,5] . D=====eeeeE------R mulq
[1,6] . DeE--------------R jmp
Listing 6:Timeline View
5 EVALUATION
MCAD’s main goal is to enable developers to quickly assess and
iterateonthetimingimpactofprogrammodi/f_ications,including
patches,acrosscontroltransfers( e.g.branchesandfunctioncalls).
Inthissection,weusebinaryprogramsofdiﬀerentreleaseversions
to evaluateperformanceand cycle-countaccuracyagainstphysical
hardwaretracestoquantifyhowMCADfaresincomparison.More
formally, given two diﬀerent versions /u1D456and/u1D457of a program /u1D443, de-
notedas/u1D443/u1D456and/u1D443/u1D457,aswellasathroughputpredictor /u1D43Bthatprovides
the number of execution cycles under a speci/f_ic input for the re-
spective program, we de/f_ine the diﬀerential throughput Δ/u1D43B(/u1D443/u1D456,/u1D443/u1D457)describingthechangeincyclecountsbetweenversion /u1D456andversion
/u1D457ofprogram /u1D443as predictedby /u1D43Bas follows:
Δ/u1D43B(/u1D443/u1D456,/u1D443/u1D457)=/u1D43B(/u1D443/u1D457)
/u1D43B(/u1D443/u1D456)
Given two versions of a program /u1D443/u1D456and/u1D443/u1D457, as well as their inputs,
we/f_irstuseMCADtopredicttheirdiﬀerentialthroughput,resulting
inΔ/u1D440/u1D436/u1D434/u1D437(/u1D443/u1D456,/u1D443/u1D457). Second, we similarly measure their relative dif-
ference in cycle counts from version /u1D456to version /u1D457using hardware-
performancecountersonphysicaldevices,resultingingroundtruth
diﬀerential throughput Δ/u1D43A(/u1D443/u1D456,/u1D443/u1D457). Finally, we formally de/f_ine the
error of MCAD’s prediction of diﬀerential throughput between
version/u1D456andversion /u1D457as:
/u1D438/u1D456/u1D457=|Δ/u1D43A(/u1D443/u1D456,/u1D443/u1D457) −Δ/u1D440/u1D436/u1D434/u1D437(/u1D443/u1D456,/u1D443/u1D457)|
5.1 Diﬀerential Throughput Prediction
To assess the overall accuracy and ability to generalize throughput
predictions across control transfers we conduct experiments using
two popularand widely usedapplicationsastarget programs: the
ffmpegvideo encoder/decoder and the C/C++/Objective-C com-
pilerclang.Weselect ffmpegforourcasestudyasvideoencoding
represents acomplex andhighly performance-intensive taskwith
manyapplicationsinreal-worldusecases. clangrepresentsalarge-
scalesoftwareconsistingofcomplexbranchinglogic,whichiswell
suitedtotestMCAD’scross-branchpredictionaccuracyandalso
plays an importantrole inmanyreal-world scenarios.
Wecollectbaselinecycle-countmeasurementsonthreephysical
machines with diﬀerent instruction set architectures (ISAs) and
microarchitectures:
•IntelCoﬀeeLake: 6-coreInteli78700Kx86_64CPU,clocked
at 3.70GHz and32Gof RAM running Ubuntu 20.04
•AMDZen2: 12-coreAMDRyzen93900Xx86_64CPU,clocked
at 2.48GHz and32Gof RAM running Ubuntu 20.04
•ARM Cortex-A57: 4-core ARM Cortex-A57 AArch64 CPU,
clockedat 1.73GHz and4G of RAM running Ubuntu 16.04
Compared to running baseline measurements on smaller pro-
gram scopes ( e.g.a single basic block), measuring larger execution
traces faces much more operating system noise. To avoid noise
due to CPU migration or context switching we allocate a single
processor core exclusively for theprocess under measurement. In
addition,wedisableSimultaneousMultithreading(SMT,alsocalled
Hyper-Threading on Intel processors) on the benchmarking core
sinceitisnotsupportedbyouranalysisengineasmentionedinSec-
tion3.6. The baseline measurements are obtained using Linux Perf,
which leverages the Performance Monitor Unit (PMU) provided by
the underlying hardware,andare averagedover 1000 repetitions.
5.1.1 FFmpeg. Weevaluate ffmpegonsubsequentversionpairs
using 9 diﬀerent release versions in the following order: 2.0, 2.2,
2.4,2.6,2.8,3.1,3.3,4.2,and4.4.Foreachexperiment,weusethe
same14KBMPEG-4video/f_ileasreferenceinputandexecutethe
following command:
ffmpeg -i input.mp4 -f null -
Figure3a,3b, and3cdepict the diﬀerential throughput predictions
ofMCAD Δ/u1D440/u1D436/u1D434/u1D437(ffmpeg/u1D456,ffmpeg /u1D457)andthebaseline Δ/u1D456/u1D457forver-
sion pairs (/u1D456, /u1D457)as(2.0,2.2),(2.2,2.4), and so forth. In addition, the
827ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA Min-Yih Hsu, Felicitas Hetzelt, David Gens,MichaelMaitland, andMichaelFranz
PerfDiﬀ. Throughput MCAD Diﬀ. Throughput Geomean Error Error
2.0-2.22.2-2.42.4-2.62.6-2.82.8-3.13.1-3.33.3-4.24.2-4.400.511.5Diﬀ. Throughput
(a)ffmpegIntelCoﬀeeLake2.0-2.22.2-2.42.4-2.62.6-2.82.8-3.13.1-3.33.3-4.24.2-4.4
(b)ffmpegAMDZen22.0-2.22.2-2.42.4-2.62.6-2.82.8-3.13.1-3.33.3-4.24.2-4.4051015
Error (Percentage)
(c)ffmpegARM Cortex-A57
6.0-7.07.0-8.08.0-9.09.0-10.010.0-11.011.0-12.012.0-13.000.511.5Diﬀ. Throughput
(d)ClangIntelCoﬀeeLake6.0-7.07.0-8.08.0-9.09.0-10.010.0-11.011.0-12.012.0-13.0
(e)ClangAMDZen26.0-7.07.0-8.08.0-9.09.0-10.010.0-11.011.0-12.012.0-13.0051015
Error (Percentage)
(f)ClangARM Cortex-A57
Figure 3: Diﬀerential execution timing comparisons between subsequent development versions of ffmpegandclang. Relative
cyclecount diﬀerences are plotted inblue andorange.Graybars represent MAPE with geo.mean plotted inred.
CoﬀeeLake Zen 2
2.02.22.42.62.83.13.34.24.420,00040,00060,00080,000
#CM CoﬀeeLake100,000200,000300,000400,000#CM Zen2
Figure 4: Number of cache misses during the execution of
diﬀerent ffmpegversionsonCoﬀeeLakeandZen2machines.
Figures present the resulting error rates /u1D438/u1D456/u1D457for the correspond-
ing version pairs between ground truth measurements on physical
devices andpredictions byMCAD.
Our results show that MCAD closely follows hardware cycle
countsandneverdeviatesfromchangesinthebaselinecountby
more than 15%. On average, the error is 1.8% for Intel, 2.6% for
AMD, and 1.1% for the ARM Cortex-A57 with a standard deviation
of less than 6.3% in all cases. Nevertheless, on both Intel and AMD
machines,twoversionpairsshowunusuallyhigherror: (3.1,3.3)
and(3.3,4.2)deviatefrombaselinemeasurementsbyaround10%to
15%. Furtherinvestigationshowedthatthisdeviation islikelydue
to a high number of cache misses during the execution of ffmpeg
version3.3onIntelandAMDmachines.Figure 4showsthenumber
ofcachemisseswhenrunningdiﬀerentversionsof ffmpegonCof-
feeLakeandZen2,measuredusinghardwareperformancecounters
averagedover1000repetitions.Onbothmachinesthenumberof
cachemissesspikesforversion3.3,exceedingthesecondhighest
measurement by at most 30%. As detailed in Section 3.2, MCAD
utilizes LLVM’s instruction scheduling database for instruction la-
tencyinformationwhichassumesthatallmemoryaccessesresult
in cache hits. Therefore, without proper and potentially expen-
sivecachesimulation(SeeSection 3.6),MCAD’sprecisionwillbe
hinderedbycyclecount penaltiesoriginatingfrom cache misses.
5.1.2 Clang. We conducted our experiments for clangusing 8
diﬀerentreleaseversionsasfollows:6.0,7.0,8.0,9.0,10.0,11.0,12.0,and 13.0. In order to reduce the amount of I/O interference and
simplify the experiments without losing generality, we focus on
the backend of clang’s compilation pipeline. More speci/f_ically, we
measure the cycles consumed by clangin compiling an unopti-
mizedLLVMIRprogramtoanobject/f_ile.TheLLVMIRinput/f_ile
(input.ll ) isgeneratedfrom the following C program:
int foo(int x, int y) {
return x * 2 + y;
}
Weuseinput.ll asthereferenceinputforourexperimentsand
executethe following command:
clang -O2 -c input.ll -o /dev/null
Figure3d,3e,and3fdepict the diﬀerentialthroughput predictions
ofMCAD Δ/u1D440/u1D436/u1D434/u1D437(clang/u1D456,clang/u1D457)andthebaseline Δ/u1D456/u1D457aswellas
the error rates /u1D438/u1D456/u1D457between predictions by MCAD and baseline for
versionpairs (/u1D456, /u1D457)as(6,7),(7,8),andsoforth.
Again,ourresultsshowthatMCADcloselyfollowsthehardware
cycle count and never deviates from the changes in the baseline
count by more than 12%. On average, the error is 2.3% for Intel,
2.2%forAMD,and1.9%fortheARMCortex-A57withastandard
deviationoflessthan5%inallcases.OnbothIntelandAMDma-
chines, we observe a spike of nearly 10% error on version pair
(12.0,13.0). Similar to the culprit for unusually high error percent-
age in Section 5.1.1, we /f_ind that this spike of error is caused by
higher number of cache misses on version 13.0: compared to other
clangversions, clang13.0creates13%to35%morecachemisses
onbothmachines.Inaddition,ontheARMmachine,weobserve
around10%oferroronversionpairs (11.0,12.0)and(12.0,13.0).We
/f_indthatthisiscausedbysuddenincreaseofmemoryoperationsin
bothversionpairs.Forinstance,thenumberof LDUR(memoryload)
andSTR(memorystore)instructions increases byafactorof 27in
said version pairs. Modern processors usually apply advanced opti-
mizations,suchasload-storeforwarding,duringtheexecutionof
828A Highly Scalable, Hybrid,Cross-Platform DiﬀerentialThroughput EstimationFramework ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
PerfDiﬀ.TP MCAD Diﬀ.TP Geomean Error Error
4.2-4.2.14.2.1-4.2.24.2.2-4.2.34.2.3-4.2.44.2.4-4.2.54.2.5-4.2.64.2.6-4.2.700.40.81.21.6
Error (Percentage) 0.9511.051.11.15Diﬀ. Throughput
(a)ffmpeg
14.0.0-14.0.1 14.0.1-14.0.2 14.0.2-14.0.3 14.0.3-14.0.4 14.0.4-14.0.5 14.0.5-14.0.600.250.50.751
Error (Percentage) 0.940.960.9811.02Diﬀ. Throughput
(b)Clang
Figure5:Diﬀerentialthroughputpredictionofsmallchanges
inffmpegandClangon IntelCoﬀeeLake
these memory operations which might not be accurately modeled
byMCA.
5.2 Diﬀerential Throughput Predictionon
SmallChanges
Sofar,MCADhasshownitsaccuratediﬀerentialthroughputpre-
dictions on changes between major software release versions. In
this sub-section, we futher illustrate MCAD’s capability of pre-
dicting diﬀerential throughput originating from (much) smaller
changes, like software patches. This issupported byrepeating the
IntelCoﬀeeLakeexperimentsfromSection 5.1.1andSection 5.1.2,
but using minorffmpegandclangreleases, which have far less
modi/f_icationsbetweenthem,ratherthantheirmajorreleasesasthe
analysis targets. Ideally, we should characterize the size of changes
between two diﬀerent versions based on their program binaries.
However, measuring diﬀerences between two binaries is a hard
problem[ 12,22].Therefore, we uselinesof(source)codechanges
(#LoCC)asanapproximatemetricofchangebetweentwosoftware
versions.
For our evaluation, we repeat the experiments detailed in Sec-
tion5.1.1forffmpegon7minorreleasesforversion4.2:4.2.1,4.2.2,
4.2.3, 4.2.4, 4.2.5, 4.2.6, and 4.2.7. The # LoCC between minor re-
leases range from 132 to around 2000 lines with a geomean of 735
lines,whereas#LoCCbetweenmajor ffmpegreleasesevaluatedin
Section5.1.1rangefrom128kto390klineswithageomeanof227k.
Figure5ashowsthediﬀerentialthroughputresultsalongwiththeir
errorpercentage.
We repeat the experiment for clang, for which we evaluate 6
minor 14.0 releases: 14.0.1, 14.0.2, 14.0.3, 14.0.4, 14.0.5, and 14.0.6.
The # LoCC between these minor releases range from 76 to around
4k lines with a geomean of 1171 lines. In contrast, the # LoCC
between major clangreleases evaluated in Section 5.1.2range
from 2.6M to 6M lines with a geomean of 3.6M lines. Figure 5bshowsthediﬀerentialthroughputresultsaswellastherespective
theirerrorpercentage.
Both experiments show that MCAD’s predictions follow the
hardwarecyclecountsclosely,withonlymarginalerrorrateofless
than1% onaverageand1.5%inthe worst case.
5.3 ScalabilityandComparison
Besides accurate predictions that generalize across control-/f_low
transfers, another major goal of MCAD is scalability. In particular,
weaimforMCADtoscaleupwiththecomplexityofreal-worldtar-
get programs. In this section, we compare against fourstate-of-the-
artthroughputpredictionandanalysisapproaches:OSACA[ 16],
Ithemal [20], uiCA [6], and LLVM MCA [ 2]. We present the results
inTable1.
First,wefocusonthebenchmarksthesetoolsusedintheirrepos-
itoriesorpublications.Wecomparethetypeandsizeofbenchmark,
aswellastheirsupportedtargetinstructionsets.Allpriorartop-
erates on the individual basic block level with the exception of
LLVMMCAwhichalsocontainsdesignatedsupportforloopker-
nels. However, in both cases instruction sequences usually consist
of only 10 ∼20 instructions at most. On the other hand, MCAD was
designed to work on real-world program traces containing mil-
lionsof instructions. MCAD also supports most of the hardware
architectures that QEMU and LLVM support, which amounts to
nearly 20 diﬀerent Instruction-Set Architectures (ISAs). In contrast,
mostother tools are highly architecture speci/f_icand onlysupport
x86_64.
We further evaluatethesetoolsusing thesame reference input
and compare their performance with respect to execution time and
memoryconsumption.Forthispurpose,wecollectedtheexecution
traceofa ffmpeginvocation using version 4.2asdescribed inSec-
tion5.1.1storing the results into a /f_ile. The resulting instruction
stream consists of roughly 27 million x86_64 instructions. To give
state-of-the-art approaches the bene/f_it of the doubt we perform
thisexperimentonan80-coreIntelXeonE7-4870machine,clocked
at 2.4GHz,equipped with 198GB of RAM and the same amount of
swapspace,settinga48-hour time limit onthe execution.
As shown, OSACA and Ithemal did not /f_inish this task: OSACA
bailedoutwithfailuresrelatedtoloadinghardwaremodelsafter
parsingtheinput/f_ile;Ithemalpromotedanout-of-memoryerror
from its DynamoRIO [ 10] runtime before bailing out. Similarly,
uiCA could not /f_inish within the time limit after consuming sig-
ni/f_icant amount of memory. Last but not the least, despite being
ableto /f_inish,LLVMMCA consumedsigni/f_icantlymore timeand
memorycomparedtoMCAD,demonstratingtheeﬀectivenessof
our changes over standardMCAinour implementation.
6 DISCUSSION
Currentstate-of-the-artthroughputpredictionapproacheseither
explicitlymodelorlearnmicroarchitecturalimplementationdetails,
resourceusage,instructionscheduling,andlatencynumbers,using
data.Thisdataissometimesprovidedbyprocessorvendorsdirectly,
although, most of the time it is collected using emperical methods,
5uiCA uses the Mean Absolute Percentage Error (MAPE) to compare the error of a
predictionagainstasingleexecutiononaphysicaldevice,whereasweusethemean
errorof the predicted diﬀerence in cyclesbetween twoexecutions.
829ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA Min-Yih Hsu, Felicitas Hetzelt, David Gens,MichaelMaitland, andMichaelFranz
Table 1:Comparison ofdiﬀerenttools to predictcyclecountsofsoftware across various dimensions.While the errormetrics
diﬀer,we presenterrornumbers as reported by themostrecentwork[ 6]forcompleteness.5
uiCA[6] OSACA [ 16] Ithemal[ 20] LLVMMCA[ 2]MCAD
execution time Timeout after48h. Exitw/errorafter24h. Exitw/errorafter2m. 219.98s 52.69s
ffmpegresults ✗ ✗ ✗ ✓ ✓
clangresults ✗ ✗ ✗ ✓ ✓
memory usage 113GB N/A N/A 29.39GB 2.16GB
scalesto #ofinstrs. 10 ∼20 ∼40 10 ∼20 ∼1000 >1000000
mean error 3%[6] ∼30%[6] ∼5%[6] ∼20%[6] 3%
benchmarktype basic block loop kernel basic block loop kernel whole program
supported ISAs x86_64only x86_64only x86 &x86_64 ∼20 ISAs ∼20 ISAs
handlesbranches ✗ ✗ ✗ ✗ ✓
like measuring instruction latencies using many diﬀerent software
con/f_igurations,andlargenumbersofrepetitionstoreduceinherent
errorsignals.
MCAD builds on top of this prior work that provides insights
intomodernprocessorpipelinesthroughdetailedmeasurements
andexperiments.Since alot ofthisresearchhas beencontributed
inpart by vendors directly andinotherparts incorporatedby the
community into the LLVM compiler infrastructure, MCAD cur-
rently usesLLVM MCAas thecore analysisengine. However, the
core analysis component in our designcan support other through-
put analysis engines in principle, which would allowus to predict
timingeﬀectsofanumberofoptimizationsinmodernprocessors
thatarenotcurrentlymodeledbyLLVMMCA,suchasincluding
instructionprefetchingandbranch prediction whichusually hap-
penintheprocessorfrontend.Themainobstacletowardsthatas
demonstrated by our experiments in Section 5.3, however, remains
overcoming scalability issuesofthe relatedapproaches.
Lookingaheadtofutureworkweanticipatethatresearchinto
analysis of multi-process and multi-thread executions should be
feasiblewithinMCAD inprinciple.Asintroduced inSection 3we
collect execution traces using QEMU and a custom plugin and
certain recently-added QEMU plugin interfaces would allow us
to distinguish traces originating from diﬀerent virtual CPUs at
runtime.Nevertheless,howtoincorporatemodernprocessors’con-
currency models into current throughput prediction approaches
remains an open research question. It would also be possible to
substituteQEMUforothermethodsofexecutiontracecollectionen-
tirely: for instance, leveraging binary rewriting tools would enable
us to insert instrumentations that report the executed instructions
natively.
Last but not least, we believe a more scalable, intuitive, and
interactive timeline or waterfall view could provide developers
with more insights by visualizing resource dependencies among
instructions, pointing towards potential avenues for improving
continuous developmentoftiming-sensitive code.
7 RELATED WORK
Inthissection,wecategorizethemostrelevantpriorapproachesand
alsocomparethemagainstMCAD.Tothebestofourknowledge,noneoftheexistingsystemssupportsanalyzingtimingeﬀectsof
programsinatimelymannerthatsupportsadevelopment-driven
work/f_lowthatcanguideimplementationchangeswithrespectto
timing-sensitive systembehavior.
A large body of prior research focused on static prediction of
worst-case timing behavior [ 13,14,17,18,23]. However, reason-
ingabouttimingpropertiesofarbitraryprogramsreducestothe
halting problem inthe generalcaseandas aresult approachesfor
calculating worst case execution time make strong assumptions
suchasanupperboundonthenumberofloopiterations,recursion
depth,eﬀectsofmemoryaccesses, andexternalI/O operations.In
practice,thismeansthattheuseroftraditionaltoolshastoprovide
upperboundinformationforallloopconstructs,recursion,avoid
indirectmemoryaccessesthroughpointers,andavoidtheuseof
I/O operations inanalyzedparts of the code.Ensuringproper and
correctusagethentypicallyrequiresdedicatedbuildtoolchainsand
environmentsetups,aswellasexpertknowledgeabouttheanalysis
framework. Moreover, such tools typically over-approximate cycle
countsuptoseveralordersofmagnitudeoverphysicalhardware
executioninordertoremainsound,withseveraltoolsproviding
timingestimatesinunitsof wall-clocktime ratherthancycles[ 7,21].
More recently, a number of approaches [ 2,6,16,20] proposed
throughputmodelingofmachinecodeusingparametricmodelsfor
accurate,yetfastthroughputprediction.Suchapproachespredict
timing aspects of a particular instruction sequence of the target
program rather than reasoning about the entire set of possible
executions at once like prior static approaches do. While their
underlyingparametricmodelsrequireknowledgeofkeymicroar-
chitectural aspects such as port usage, instruction latencies, and
other internal details that may not be publicly available, recent ad-
vancesinmachinelearningshowedthatarchitecturedependence
canbe tackledtosomeextent by learningmodel parametersfrom
data[20].However,withoutrulingouttheuseoflearning-based
solutions, our evaluation show that currently such approaches are
severelylimitedwithrespecttoscalability,providingthroughputes-
timatesonlyforahandfuluptoafewhundredinstructionsatmost,
also lacking support for predictionacrosscontrol-/f_lowtransfers.In
830A Highly Scalable, Hybrid,Cross-Platform DiﬀerentialThroughput EstimationFramework ESEC/FSE ’23, December3–9, 2023,San Francisco, CA, USA
contrast,MCADhandlescomplexbinaryprogramscontainingliter-
ally millions of individualinstructionswithnear-native execution
speeds.
Dynamicapproachesaimatprovidingdetailedandconcretetim-
ing analyses of the runningsoftware using concrete inputs. There
are two main /f_lavors of dynamic timing analysis tools: either us-
ing physical hardware tracing or using architectural simulators.
Approaches using physical tracing execute the program on the
target architecture and measure cycle counts directly using the
facilities provided by the device [ 3,19]. While in theory this yields
the most precise results and should also be reasonably fast, in prac-
tice this is often not the case: the target architecture might be a
productionsystemthatisnotreadilyavailabletothedeveloperrun-
ning the test and in a collaborative environment each team would
require their own physical device to test their changes against. Ad-
ditionally,settingupandusingfacilitiesforaccuratecycle-count
measurementscanbeatime-intensivetaskinandofitself,requiring
complicated setup, and potentially support by the target program’s
buildtoolchainaswellastheoperatingsystemoftheproduction
system.
Cycle-accuratearchitecturalsimulators[ 9,11,25]ontheother
handpromisetoprovideasimilarlevelofaccuracyasphysicaltrac-
ingwithoutrequiringanactualphysicaldevicetocaptureprogram
execution.Unfortunately,simulation-based approaches also come
with major drawbacks: /f_irst, performance is typically at least three
orders of magnitude slower than native execution (or even slower)
astheyfaithfullysimulatemicroarchitecturaldetailsofmodernpro-
cessorpipelinescompletelyinsoftware.Second,theyareusually
aimedtowardsexplorativehardwaredesignandimplementation
studiesofnovelarchitecturesratherthansimulatingthroughputof
software for existing platforms.Asaresult, theseframeworks are
noteasilyaccessibleandcanbediﬃculttointegrate withexisting
software development tools and continuous integration work/f_lows
duetothehighresourcerequirementsandtime-intensivenature
ofthe simulation-basedapproach.
8 CONCLUSION
Tosummarize,ourresultsshowthatMCADimprovesonthestateof
theartbyscalinguptocomplexreal-worldsoftware.Itiswellsuited
to providing cycle count estimates with rapid developer-centric
turn-around times while targeting a range of diﬀerent hardware
architectures.MCADcandrivesoftwaredevelopmentbyquickly
iterating on small changes and assessing their timing impact on
real-world programs such as ffmpegandclang, with a mean error
indiﬀerentialthroughputestimatesof <3%comparedtohardware-
basedmeasurements.
ACKNOWLEDGMENTS
This material is based upon work partially supported by United
StatesDefenseAdvancedResearchProjectsAgency(DARPA)and
Naval Information Warfare Center Paci/f_ic (NIWC Paci/f_ic) under
contract N66001-20-C-4027.
REFERENCES
[1][n.d.]. Chrome DevTools. https://developer.chrome.com/docs/devtools/ . Ac-
cessed:2021-12-13.[2][n.d.]. LLVM MCA. https://llvm.org/docs/CommandGuide/llvm-mca.html . Ac-
cessed:2021-06-28.
[3][n.d.]. Perf: Linux pro/f_iling with performance counters. https://perf.wiki.kernel.
org/index.php/Main_Page . Accessed:2021-11-08.
[4]2010. IntrototheLLVMMCProject. https://blog.llvm.org/2010/04/intro-to-llvm-
mc-project.html . Accessed:2021-07-08.
[5]AndreasAbelandJanReineke.2019. uops.info:CharacterizingLatency,Through-
put, and Port Usage of Instructions on Intel Microarchitectures. In ASPLOS
(Providence, RI, USA) (ASPLOS ’19) . ACM, New York, NY, USA, 673–686. https:
//doi.org/10.1145/3297858.3304062
[6]AndreasAbelandJanReineke.2021. AccurateThroughputPredictionofBasic
BlocksonRecentIntelMicroarchitectures. arXivpreprintarXiv:2107.14210 (2021).
[7]Jaume Abella, Carles Hernández, Eduardo Quiñones, Francisco J Cazorla,
Philippa Ryan Conmy, Mikel Azkarate-Askasua, Jon Perez, Enrico Mezzetti, and
TullioVardanega. 2015. WCET analysis methods:Pitfalls and challenges on their
trustworthiness.In 10thIEEEInternationalSymposiumonIndustrialEmbedded
Systems(SIES) . IEEE,1–10.
[8]Fabrice Bellard. 2005. QEMU, a fast and portable dynamic translator.. In USENIX
annualtechnicalconference, FREENIXTrack , Vol. 41.Califor-nia,USA,46.
[9]Nathan Binkert, Bradford Beckmann, Gabriel Black, Steven K Reinhardt, Ali
Saidi, Arkaprava Basu, Joel Hestness, Derek R Hower, Tushar Krishna, Somayeh
Sardashti,etal .2011.Thegem5simulator.In ACMSIGARCHcomputerarchitecture
news, Vol. 39.1–7.
[10]DerekBrueningandSamanAmarasinghe.2004. Eﬃcient,transparent,andcompre-
hensive runtime code manipulation . Ph.D. Dissertation.Massachusetts Institute
of Technology, Department of ElectricalEngineering ....
[11]Doug Burger and Todd M Austin. 1997. The SimpleScalar tool set, version 2.0. In
ACMSIGARCHcomputer architecturenews , Vol. 25.13–25.
[12]Yue Duan, Xuezixiang Li, Jinghan Wang, and Heng Yin. 2020. Deepbindiﬀ:
Learning program-widecode representations for binary diﬃng. In Network and
DistributedSystemSecuritySymposium .
[13]Heiko FalkandJan CKleinsorge.2009. Optimal staticWCET-aware scratchpad
allocation of program code. In Proceedings of the 46th Annual Design Automation
Conference . 732–737.
[14]DamienHardy,BenjaminRouxel,andIsabellePuaut.2017. Theheptanestatic
worst-case execution time estimation tool. In 17th International Workshop on
Worst-Case Execution Time Analysis (WCET 2017) . Schloss Dagstuhl-Leibniz-
ZentrumfuerInformatik.
[15]DiarmuidCorcoranLarsRasmusson.2013. PerformanceOverheadofKVMon
Linux3.9onARMCortex-A15. https://www.diva-portal.org/smash/get/diva2:
1043325/FULLTEXT01.pdf .
[16]Jan Laukemann, Julian Hammer, Johannes Hofmann, Georg Hager, and Gerhard
Wellein. 2018. Automated instruction stream throughput prediction for intel and
amd microarchitectures. In 2018 IEEE/ACM performance modeling, benchmarking
and simulation ofhigh performancecomputer systems(PMBS) . IEEE,121–131.
[17]Xianfeng Li, Yun Liang, Tulika Mitra, and Abhik Roychoudhury. 2007. Chronos:
Atiminganalyzerfor embeddedsoftware. In ScienceofComputerProgramming ,
Vol. 69.56–67.
[18]Björn Lisper. 2014. SWEET–a tool for WCET /f_low analysis. In International Sym-
posium On Leveraging Applications of Formal Methods, Veri/f_ication and Validation .
Springer, 482–485.
[19]RapitaSystems LTD. 2017. Automating WCET analysis for DO-178B/C. https:
//www.rapitasystems.com//f_iles/MC-WP-004AutomatingWCETanalysisforDO-
178C.pdf. (2017).
[20]Charith Mendis, Alex Renda, Saman Amarasinghe, and Michael Carbin. 2019.
Ithemal: Accurate, portable and fast basic block throughput estimation using
deepneuralnetworks.In InternationalConferenceonmachinelearning .PMLR,
4505–4515.
[21]Enrico Mezzetti and Tullio Vardanega. 2011. On the industrial /f_itness of wcet
analysis. na.
[22]Xiaolei Ren, Michael Ho, Jiang Ming, Yu Lei, and Li Li. 2021. Unleashing the
hidden power of compiler optimization on binary code diﬀerence: An empirical
study. In Proceedings of the 42nd ACM SIGPLAN International Conference on
ProgrammingLanguage Designand Implementation . 142–157.
[23]DanielSehlberg,AndreasErmedahl,JanGustafsson,BjörnLisper,andSteﬀen
Wiegratz.2006. Static WCET analysisof real-time task-orientedcode in vehicle
controlsystems.In SecondInternationalSymposiumonLeveragingApplicationsof
FormalMethods,Veri/f_ication and Validation (isola2006) . IEEE,212–219.
[24]SuramyaTomar.2006. ConvertingvideoformatswithFFmpeg. LinuxJournal
2006,146(2006), 10.
[25]Matt T Yourst. 2007. PTLsim: A cycle accurate full system x86-64 microarchitec-
tural simulator. In 2007 IEEE International Symposium on Performance Analysis of
Systems& Software . IEEE,23–34.
Received 2023-03-02; accepted 2023-07-27
831