When Does MyProgram Do This?
Learning
CircumstancesofSoftwareBehavior
Alexander Kampmann
CISPA Helmholtz Center for InformationSecurity
Saarbrücken, Germany
alexander.kampmann@cispa.saarlandNikolas Havrikov
CISPA Helmholtz Center forInformationSecurity
Saarbrücken, Germany
nikolas.havrikov@cispa.saarland
Ezekiel O.Soremekun
CISPA Helmholtz Center for InformationSecurity
Saarbrücken, Germany
ezekiel.soremekun@cispa.saarlandAndreas Zeller
CISPA Helmholtz Center forInformationSecurity
Saarbrücken, Germany
zeller@cispa.saarland
ABSTRACT
Aprogramfails.Underwhichcircumstancesdoesthefailureoccur?
OurAlhazen approach starts with a run that exhibits a particular
behaviorandautomaticallydeterminesinputfeaturesassociated
withthebehaviorinquestion:(1)Weusea grammar toparsethe
inputintoindividualelements.(2)Weuseadecisiontreelearner
toobserveandlearnwhich input elements are associated withthe
behavior in question. (3) We use the grammar to generate addi-
tional inputs to further strengthen or refute hypotheses as learned
associations. (4) By repeating steps 2 and 3, we obtain a theory
that explains and predicts the given behavior. In our evaluation
usinginputsfor find,grep,NetHack,andaJavaScripttranspiler,
the theories produced by Alhazen predictandproducefailures
with high accuracy and allow developers to focuson a small set of
input features: ł grepfails whenever the --fixed-strings option
is usedinconjunction withan emptysearch string.ž
CCS CONCEPTS
·Softwareanditsengineering →Softwaretestinganddebug-
ging;·Theory of computation →Grammars and context-free
languages ;Oraclesand decision trees ; Active learning.
KEYWORDS
debugging, errordiagnosis,machine learning,software behavior
ACMReference Format:
AlexanderKampmann,NikolasHavrikov,EzekielO.Soremekun,andAn-
dreas Zeller. 2020. When Does My Program Do This? Learning Circum-
stancesofSoftwareBehavior.In Proceedingsofthe28thACMJointEuropean
Software Engineering Conference and Symposium on the Foundations of Soft-
wareEngineering(ESEC/FSE’20),November8–13,2020,VirtualEvent,USA.
ACM,NewYork,NY,USA, 12pages.https://doi.org/10.1145/3368089.3409687
ESEC/FSE ’20, November 8–13, 2020, Virtual Event, USA
© 2020 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-7043-1/20/11.
https://doi.org/10.1145/3368089.3409687Parser
LearnerGeneratorInitial inputs + test outcomes
Input
grammar
Hypotheses
to r
eﬁne or refuteInput features
+ test outcomes
Theory
Figure 1: How Alhazen w orks. Given a set of initial inputs
andtheirtestoutcomeswhichdeterminewhetherthebehav-
ior in question is present or not, we parsethe input into its
elements using a given input grammar, A learnerthen de-
terminestheassociationsofinputpropertiesandoutcomes,
producing hypotheses on the circumstances under which
the behavior occurs. By producing inputs from the gram-
mar, we generate additional tests to further refine or refute
hyoptheses,eventuallyobtaininga theorythatexplainsand
predicts whenthe behavior inquestionoccurs.
1 INTRODUCTION
Whendiagnosingwhyaprogramfails,oneofthefirststepsisto
preciselyunderstandthe circumstances ofthefailureÐthatis,when
the failure occurs and when it does not. Such circumstances are
necessary for three reasons. First, knowing the circumstances is
necessarytoprecisely predictwhenthefailuretakesplace;thisis
importanttodevisetheseverityofthefailure.Second,oneneeds
them to design a precise fix: A fix that addresses only a subset of
circumstancesisincomplete,whileafixthataddressesasuperset
may alter behavior in non-failing scenarios. Third, one can use
themtocreate testcases thatreproducethefailureandeventually
validate the fix.
1228This work is licensed under a Creative Commons Attribution International 4.0 License.
ESEC/FSE ’20, November8–13,2020,VirtualEvent, USA Alexander Kampmann, Nikolas Havrikov, EzekielO. Soremekun, andAndreas Zeller
In this paper, we introduce Alhazen Ðan approach that auto-
maticallydeterminesthecircumstancesunderwhichsomeprogram
behaviorofinteresttakesplace.1Asallprogrambehaviorisdeter-
minedbyitsinputs,weseefailurecircumstancesaspropertiesof
theprograminput;ouraimisthustodetermineinputfeaturesthat
wouldbe associatedwiththe behaviorinquestion.
As an example of how Alhazen works and what it produces,
assumesomeprogram Ptoevaluatemathematicalfunctions;the
inputsqrt(4),forinstance,producestheoutput 2.Giventheinput
sqrt(-900) , however, Phangs. At this point, the astute reader
alreadymayhaveanideaonthecircumstancesofthefailure;but
we want to determine these automatically . To do so, Alhazen
makesuse ofthree key ingredients, illustratedin Figure 1:
Parsing. We use a grammar toparseprogram inputs into individ-
ual elements. This allows us to express fine-grained relation-
ships between input elements (and their features) and program
behavior(i.e.presenceorabsenceofafailure).
Figure2liststheinputgrammarfor P.Thisgrammarwillallow
us to expressfailure circumstances by means of the ⟨function⟩
being usedandthe ⟨number⟩being passed.
Learning. We use a decisiontree tolearnwhichfeatures ofinput
elementsareassociatedwiththeprogrambehaviorinquestion.
By default, the features used in Alhazen test whether a partic-
ular element occurs in the input or not; in our failure-inducing
input,sqrtis present, whereas sinis not. If some element has
anumericalinterpretation(suchas ⟨number⟩),italsousesits
maximum valueas feature.
The decision tree learner produces a tree that explains and
predictswhenthebehaviorinquestionoccursbasedonasubset
of the input features. Figure 3shows the initial decision tree
learnedfromthepassinginput sqrt(4)andthefailinginput
sqrt(-900) . The initial hypothesis is that the failure occurs
whenthelargest2⟨number⟩islessthanorequalto-445.5Ða
predicatechosenbythedecisiontreelearneras afeaturethat
correctlydistinguishes allobservations sofar.
1H.asanIbnal-Haytham(Latinizedas Alhazen;∼965ś∼1040)wasanArabresearcher
of the Islamic Golden Age. His Kit¯ab al-Man ¯az.irłBook of Opticsž(1011ś1021) was
one of the first embodiments of the modern scientific method, proving hypotheses
through reproducible experiments that vary the experimental conditions in a system-
atic manner [ 34].
2In the example, there cannot be more than one number, but Alhazen would be able
to handleit if therewere.
⟨start⟩ → ⟨function⟩"("⟨number⟩")";
⟨function⟩ →"sqrt" | "sin" | "cos" | "tan";
⟨number⟩ →"-"?/[1-9][0-9]*/ ("."/[0-9]+/ )?;
Figure 2:Agrammarforevaluating functions.
max/parenleftbig⟨number⟩/parenrightbig≤ −445.5?
✘ ✔yes no
Figure 3: Alhazen ’sinitial hypothesis inthesqrtexample.⟨function⟩="sqrt"?
✔max/parenleftbig⟨number⟩/parenrightbig≤0.0?
✘ ✔no yes
yes no
Figure 4:Final decision tree after iteration 29.
⟨function⟩="sqrt"?
result<4.0max/parenleftbig⟨number⟩/parenrightbig≥16.0?
result≥4.0result<4.0noyes
yes no
Figure 5:Circumstancesforthe resultbeing 4.0 ormore.
Generating. To precisely capture the failure circumstances, we
needfurtherexperiments.Tothisend, Alhazen usesthegram-
mar as aproducer of inputs and systematically explore alterna-
tivesto the inputs observed so far. For each decision branch in
thetree,Alhazen generatesfurtherinputstorefineorrefute
the associationwiththe predictedoutcome.
Inourexample, Alhazen wouldgeneratemoreinputsforeach
branch in Figure 3. These satisfy the given conditions from the
tree,butotherwisearerandomlychosenfromthegrammarÐ
say,cos(-444.5) for the left branch and cos(-446.5) for the
rightbranch.Sincebothpass,theoriginaldecisiontreeisinade-
quate.Instead, Alhazen refinesthefailurehypothesissuchthat
⟨number⟩must be less than -673.25. Note that this hypothesis
isconsistent withallobservations sofar.
AsAlhazen generatesfurther inputsfor allbranches, iteven-
tually learns that the failure depends on sqrt()being called.
After 29 iterations, Alhazen deliversFigure 4, which correctly
describes the failure conditions: The ⟨function⟩"sqrt"is used,
andthe⟨number⟩isless thanorequal to 0.
Beyond just pass and fail predicates, Alhazen can be applied to
obtain explanations and predictions for arbitrary predicates over
theprogramexecution.Forinstance,onecanuseittodeterminethe
circumstances under which a specific output is produced; Figure 5
showsthecircumstancesfortheoutputbeing4ormore.(Notethat
the trigonometricfunctionsreturn valuesinthe range [−1,1].)
Since it requires no program analysis, Alhazen scales to arbi-
trarylargeprograms. NetHackisanadventuregames,consistingof
240424 lines ofcode. In January 2020, it was found thatNetHack
wasvulnerabletoabufferoverflow[ 11].Usinga.inigrammarto
parse its configuration file, Alhazen easily determines that the
failure occurs as soon as some line in the configuration file has
more than619characters ( Figure 6).
Alhazen can be seen as a full automation of the scientific
method, creating, refining and refuting hypotheses from obser-
vations over specifically constructed experiments to eventually
produce a theoryof when the program exhibits a specific behavior.
1229When DoesMy Program DoThis? Learning Circumstancesof Software Behavior ESEC/FSE ’20, November8–13,2020,VirtualEvent, USA
len/parenleftbig⟨line⟩/parenrightbig≤619?
✔ ✘yes no
Figure 6:Decision tree foraNetHackfailure.
The grammar serves as parser and producer of inputs; the decision
tree captures the circumstances that distinguish program behavior.
The structure of this paper follows its three main contributions:
Input elements as features. (Section2)Usingagrammartoparse
inputsintofine-grainedelements,wecanassociatethepresence
orabsenceof suchelementswithobservedprogrambehavior.
Thismakestheseelements featuresformachinelearnersthat
can thus infer precise models of program behavior from ob-
served runs. To the best of our knowledge, ours is the first
approach to combine general-purpose parsing and machine
learninginsoftware engineering.
Creatinghypotheses forprogram behavior. (Section 3) Using
a decision tree learner, we can extract associations between
inputfeaturesandprogrambehavior.Decisiontreelearnersare
not very precise, but they provide very good explanations to
humansÐinourcase,predicatesoverinputfeaturesthatcapture
thecircumstancesofthebehavior.Tothebestofourknowledge,
thisisthefirstuseofmachinelearnersovergeneral-purpose
inputfeatures for predicting, fixing, andproducing failures.
Refining andrefuting hypotheses. (Section 4) Using the gram-
mar, we can produce additional test cases to refine or refute
hypotheses as produced from the learner; we thus combine
the explainability of decision trees with the production power
ofgrammars.Asthegrammarallowsustosystematicallytest
alternatives, this active learningapproach makesthe resulting
diagnosis much more precise. To the best of our knowledge,
the production of additional inputs to satisfy and refine deci-
sion tree constraints is novel, making ours the first automated
debuggingapproachproducingatheoryoversyntacticfeatures.
InSection 5, we evaluate the models generated by Alhazen for
their accuracy. Applied on a variety of real-world bugs in standard
programs,including grepandfind,wefindthattheresultingmod-
els preciselycapture failurecircumstances. Applied on JavaScript
and its processors, Alhazen is able to isolate nontrivial conditions
over elements that lead to failure. After discussing related work
(Section6),Section7 closesthepaperwithconclusionandfuture
work, as well as linksto code anddata.
2 INPUTELEMENTS ASFEATURES
Alhazen associates properties of the input with program behavior.
Thosepropertiesarederivedfromacontext-freegrammarofthe
inputlanguage.Weusepresenceandabsenceofnon-terminalsym-
bolsinthegrammar,thelengthofindividualnodesinthepathtree,
thecodepointofcharactersinnodesandthenumericinterpreta-
tionofparsetreenodesasfeatures.Thefollowingsectiondescribes
the extractionofthesefeatures from an input.⟨start⟩ → ⟨empty⟩|⟨start⟩ ⟨suffix⟩;
⟨suffix⟩ →"a";
⟨empty⟩ →"";
Figure 7:Agrammarwith aloop.
2.1 Context-FreeGrammars
A context-free grammar consists of a start symbol and a set of
production rules. A production rule ⟨P⟩ →αconsists of a non-
terminalsymbol ⟨P⟩ontheleftandacontrolform αontheright.
A controlform can be one of the following:
Terminalsymbol. A quotedstring.
Non-terminal symbol. A symbolname inangle brackets.
Concatenation. A sequenceof controlforms.
Quantification. Acontrolform,calledthesubject,annotatedwith
one of+,*or?.
Alternation. A sequenceof controlforms,separatedby |.
Whenwriting grammars, we use regular expressions delimited
with slashes as control forms for better readability (e.g. in the
⟨number⟩production of Figure 2). This is possible because any reg-
ular expression can be transformed into an equivalent context-free
grammar.Weuseparenthesestoavoidconfusionaboutprecedence.
If a production rule has an alternation as its right-hand side, we
call the control forms within this alternation the alternatives of
the non-terminal. In a production rule ⟨P⟩ →α|(β(γ|δ)),⟨P⟩has
the alternatives αandβ(γ|δ). Note that γandβare not considered
alternatives of ⟨P⟩ontheir own.
Aproducer generates a parse tree from a grammar. A simple
basealgorithmforaproduceristogeneratethenodesofthetreein
pre-order.Contrarytomoststandardtextbooks,wehaveanodefor
eachcontrolform,soaderivationfor ⟨function⟩ →"sqrt"|"cos"
has three nodes in total, one for ⟨function⟩, one for the alternation
andone for the chosenalternative.
Wecallthesequenceofcontrolformsintheorderthenodeswere
producedthe derivationsequence .Onepossiblederivationsequence
for the parse tree of sqrt(-900) is (1)⟨start⟩(2) Concatenation
of⟨function⟩"("⟨number⟩")"(3)⟨function⟩(4) alternation of
"sqrt"|"tan"| ... (5)"sqrt"(6)"("(7)⟨number⟩(8)"-900"
(9)")".This isapre-order traversal of the parse tree.
There is one catch to look out for when implementing this algo-
rithm.Assumewewanttogenerateaparsetreeforthegrammar
inFigure 7, and we want the leaf word to contain "a". Within a
node for⟨start⟩, we need to decide which alternative we want. We
choose the second, as this allows us to generate "a". In a pre-order
traversal, we need to generate another node for ⟨start⟩now. As we
didnot yet generate "a", it isquite easy to take thesame decision
again, and run into an endless loop. We therefore allow the algo-
rithm to create the child nodes for a concatenation in any order,
andadd themto the parentnode inthe requiredorder.
However, this means that there are several derivation sequences
forthesameleafword.Asanexample,(1) ⟨start⟩(2)Concatenation
of⟨function⟩"("⟨number⟩")"(3)"("(4)")"(5)⟨function⟩(6)al-
ternationof "sqrt"|"tan"|... (7)"sqrt"(8)⟨number⟩(9)"-900"
isapossible derivation sequencefor sqrt(-900) just as well.
In some cases, there can be different parse trees for the same
word. In this case, we call the grammar ambiguous . Ambiguities in
1230ESEC/FSE ’20, November8–13,2020,VirtualEvent, USA Alexander Kampmann, Nikolas Havrikov, EzekielO. Soremekun, andAndreas Zeller
Before therewrite
⟨start⟩ → ⟨function⟩"("⟨number⟩")";
⟨function⟩ →"sqrt" | "tan" | "sin" | "cos";
⟨number⟩ →"-"?/[1-9][0-9]*/ ( "."/[0-9]+/ )?;
After therewrite
⟨start⟩ → ⟨function⟩"("⟨number⟩")" | "sqrt(-900) ";
⟨function⟩ →"sqrt" | "tan" | "sin" | "cos";
⟨number⟩ →"-"?/[1-9][0-9]*/ ( "."/[0-9]+/ )? | "-900";
Figure 8: The last alternatives for startandnumber are
added by therewritestep.
grammars usually stem from the fact that disambiguation relies on
propertiesnotreflectedinacontext-freegrammar,apoorquality
ofthe formalizationofthe inputlanguage,oramixture ofboth.
Throughoutthispaper,weneedanotionofwhetheracontrol
form⟨Q⟩isreachable from a control form ⟨P⟩. Thedistancefrom a
controlform ⟨P⟩toacontrolform ⟨Q⟩isthe minimalnumberof
operations required to create a node labeled ⟨Q⟩, after the creation
ofanodelabeled ⟨P⟩,inthesubtreeof ⟨P⟩.Iftherecanbeanode
labeled with ⟨Q⟩in the subtree of a node labeled with ⟨P⟩, we call
⟨Q⟩reachable from⟨P⟩.Otherwise, ⟨Q⟩isnotreachable from⟨P⟩,
andthe distancefrom ⟨P⟩to⟨Q⟩isinfinite.
2.2 GrammarTransformation
Thebehaviorswewanttoexplainaretriggeredbycomplexinput
structures.Whileallinputsarewordsofthegrammar,thegrammar
is often too fine-grained to capture the essence of what causes a
bug. Therefore, we perform a rewrite step which adds additional
alternatives that capture more complex structures. To this end, for
allnon-terminalsymbolsinthegrammar,wedeterminetheword
derivedbythissymbolinthebug-triggeringinput,and addthose
wordsasalternativestothesymbol. Figure8showstherewritten
grammarfor the calculatorexample.
In the rewritten grammar, "-900"is added as alternative to
⟨number⟩. Also, the full string is added as an alternative to the
start symbol. We do not add "sqrt"as an alternative to ⟨function⟩,
because it is already there. Note that the rewrite step makes all our
grammars more ambiguous as they always have at least two parse
trees for the inputwe startedwith.
3 CREATING HYPOTHESES
FORPROGRAM BEHAVIOR
Weuseadecisiontreelearner[ 32]tolearnassociationsbetween
programbehaviorandinputfeatures.Ineachiteration, Alhazen
trains a learner on all known input samples, and uses the obtained
treetogeneratemoreinputs,whichhelptorefinethetreeinthe
nextiteration.
Decisiontreelearnersexpressassociationsintermsofpredicates
over numeric features, i.e.max(⟨number⟩) ≤0.0. As we want to
reason about program inputs, we need to extract numeric features
fromprograminputs.Wedosoby parsingeachinput,andextracting
features from the parse tree. For each production rule and each
alternative,we considerthe following features:Existence. This feature has a value of 1 iff the production rule
wasusedinthederivation sequencefor an inputat leastonce.
We write the existence feature for the production ⟨start⟩as
exists(⟨start⟩).Foralternatives,wehaveanexistencefeature
forthenon-terminal(e.g. exists(⟨function⟩))andindividual
existence features for each alternative (e.g. exists(⟨function⟩
== "sqrt")).
Length. If for a production ⟨P⟩,⟨P⟩itself is reachable from ⟨P⟩
or a quantification is reachable from ⟨P⟩, we use the number
of charactersin the word derived by ⟨P⟩as a feature. Forthe
production ⟨number⟩, we write this feature as len(⟨number⟩).
Iftheright-handsideoftheproductionrulefor ⟨P⟩isaquan-
tification,we insteadintroduceafeature qu-len(⟨P⟩),which
gives the number of child nodes of this quantification. If ⟨P⟩
isusedmultipletimesinthederivation,weusethemaximum
valuefor both lenandqu-len.
MaximalCodePoint. For all productions ⟨P⟩that have more
than one derivation, we introduce a feature max-char( ⟨P⟩)
for themaximal code point Ðthat is, the maximal integer repre-
sentation for all characters in the word derived by ⟨P⟩. If there
are multiple wordsderived by ⟨P⟩,we usethemaximumcode
pointacrossallwords.
NumericInterpretation. If a production ⟨P⟩only derives words
composedofthecharacters 0-9,.and-,weintroduceafeature
max(⟨P⟩),whichinterpretsthewordasafloating-pointnumber.
Again,weusethemaximumvalueformultipleproductionuses.
All those features are derived from the parse tree of an input.
Due to the ambiguity in our grammars, we need to consider all
possibleparsetrees.Therefore,weuseanEarleyParser[ 15],which
gives usallpossible parse trees, ratherthanjust one.
Table1showsthefeaturevaluesfor sqrt(-900) .The⟨start⟩rule
isused,andsoisournewly-introducedalternative,so exists(⟨start⟩)
andexists(⟨start⟩== "sqrt(-900) ")bothhaveavalueof1.The
length of this word is 11 characters, and the maximal code point is
116 (which corresponds to ’t’). If we had just one parse tree, that
wouldhavebeenall.However,wecanalsoseethealternativeparse
tree,whichuses the pre-existing rulefor ⟨start⟩.In this parsetree,
wehaveexists(⟨function⟩)andexists(⟨function⟩== "sqrt")
as1,but⟨function⟩== "cos"as0.Wecanagainseemaximumcode
point features for ⟨function⟩and⟨number⟩, as well as the numeric
interpretationfor ⟨number⟩,whichis-900.
4 GENERATING TESTS
TO REFINEHYPOTHESES
Asshownin Figure1,Alhazen usesafeedbackloop tosystemati-
callyrefineorrefutehypotheses.Tothisend,we generatetests that
explore the variouspathsfrom the decision tree.
4.1 Extracting PredictionPaths
In a decision tree, each internal node contains a predicate f≤v,
wherefis a feature. Leaves are labeled with the program behavior.
Whenadecisiontreelearnerclassifiesasample s,ittraversesits
internalstructureinthefollowingway:Startingattherootnode,
the predicate in the node is checked against the (features of) the
sample.Ifitisfulfilled,thełyesžbranchisexaminednext,otherwise
the traversal continues at the łnož branch. As soon as the traversal
1231When DoesMy Program DoThis? Learning Circumstancesof Software Behavior ESEC/FSE ’20, November8–13,2020,VirtualEvent, USA
Table1:Allfeaturevaluesfor sqrt(-900) andthetransformed
subgrammarin Figure 8
Feature Value
max-char( ⟨start⟩) 116
len(⟨start⟩) 11
⟨function⟩== "sqrt" 1
⟨function⟩== "cos" 0
⟨function⟩== "sin" 0
exists(⟨start⟩) 1
exists(⟨start⟩) == "sqrt(-900) ") 1
⟨function⟩== "tan" 0
max-char( ⟨function⟩) 116
⟨number⟩ 1
⟨number⟩== "-900" 1
max-char( ⟨number⟩) 57
max(⟨number⟩) -900
len(⟨number⟩) 4
reachesaleaf,thelabelofthisleafistheprediction.Thatis,each
prediction traverses a path from the root to a child node of the
treeÐthe predictionpath for this sample.
Each path in the tree, from root to leaf, can be written as a
sequenceofpredicates ofthe form fi≤vorfi>v.
To generate test inputs, for all paths in the tree, we take all
subsetsofpredicatesonthepathand negatethem.Forinstance,for
a path with the predicates f1≤v1andf2>v2we would generate
(1)f1≤v1∧f2>v2,(2)f1>v1∧f2>v2,(3)f1≤v1∧f2≤v2,
and(4)f1>v1∧f2>v2.
Letusnowgeneratesampleswhichfulfillthesesetsofpredicates.
We then proceedinthree steps:
(1)Weslicethe grammar into a subset that does not contain
productions prohibitedbythe tree predicates ( Section 4.2 ).
(2)We eliminate predicate sets that are infeasible within the
grammar( Section 4.3 ).
(3)We produce solutions for feasible predicates ( Section 4.4 ),
whichwerepeatuntilthebestpossiblecandidateisfound
within atime budget ( Section 4.5 ).
4.2 Slicing theGrammar
Westartbygeneratinga subsetofthegrammarwithoutproductions
that would be prohibited by the existence predicatesÐthat is, it
excludesallproductions or alternativeswhere the predicate states
that the existence feature is <1. As an example, if the predicate
exists(⟨number⟩=="-900") ≤0.5isinthepredicateset,wewould
rewrite the production rule for ⟨number⟩as⟨number⟩ →"-"?
/[1-9][0-9]*/ ("."/[0-9]+/ )?.
Due to ambiguity, a production may implicitly use a different
productioninanotherderivationsequenceforthesameword.In
the transformed grammar for our example ( Figure 8), using⟨start⟩
=="sqrt(-900) "means that ⟨number⟩=="-900"is used implic-
itly,viaadifferentparsetreeforthesameword.Forallproductions
and alternatives which derive the same word in all parse trees
(that is, the right-hand side contains only terminal symbols or non-
terminal symbols with just one production that recursively always
derives the same word), we precompute the set of productions
that are used implicitly. We also remove a production if this setcontains a prohibited production. In the example, the predicate
exists(⟨number⟩=="-900") ≤0.5wouldleadtoremovalofboth
"-900"and"sqrt(-900) ". This addresses the ambiguity we in-
troduced in the grammar transformation, but not necessarily all
ambiguities inthe grammar.
4.3 Feasibility Check
Inournextstep,weidentifyandeliminatepredicatesetsthatare
infeasible within the grammar:
Existence. Productions and alternatives corresponding to exis-
tence features with f>0.5 predicates are required by the
predicateset.Wecheckwhetherthosearereachablewithinthe
grammarwithoutprohibitedfeatures.
Length. Forlengthfeatures,wecheckreachabilityonly,aswith
the existencefeatures.
MaximalCodePoint. We check reachability of the production
rule, and we check whether there is a terminal symbol that
containstherequiredcodepointreachablefromtheproduction.
NumericInterpretation. We try to parse the string of the re-
quiredvaluestarting at the production of the feature.
As an example, let’s assume we want to fulfill the predicate
setmax-char (⟨number⟩)==55. 55 is the ASCII value for 7, and
"7"canbecontainedin "-"?/[1-9][0-9]*/ ("."/[0-9]+/ )?.So
thepredicatesetpassesthefirsttest.Next,wecheckreachability
within the sliced grammar. ⟨number⟩is reachable via the ⟨start⟩
production, andtherefore this test ispassedas well.
Ifapredicate setfailsoneof thosetests,itisinfeasibleandwill
not be considered.
4.4 ProducingInputs
Inthenextstep,weproducecandidatesforderivationsequences
that fulfill the given predicates.
Togenerateaninput,weproducethenodesofaparsetreeinpre-
orderasdescribedin Section2.1 .Duringthisprocess,thealgorithm
needsto make three decisions:
(1) For aconcatenation, decidethe order of the children.
(2) For aquantification,decidehowmanychildren to add.
(3) For an alternation, decidewhichcontrolform to use.
Each of those decisions corresponds to an element in the deriva-
tionsequence,andeverytimethereismorethanonepossiblechoice.
Each derivation sequence is split into a prefixand apostfix. When
this process creates a new sequence, it lists all possible choices
for the first decision in the postfix, and generates one derivation
sequencefor eachof those,byappendingeachone ofthosetothe
prefixofthissequence.Foreachnewderivationsequence,ituses
a greedy approach to finish off the sequence. The part that was
generatedgreedilyisthenewpostfix.Inthefollowing,wedescribe
this greedy approach.
Each feature is associated with a control form. When the greedy
approach has to take a decision, we choose an option such that the
label in the new (or next) child node minimizes the distance to the
closestofthosecontrolforms.Whenthiscontrolformisreached,
mostfeatures require otherheuristics for the subtree of this node.
1232ESEC/FSE ’20, November8–13,2020,VirtualEvent, USA Alexander Kampmann, Nikolas Havrikov, EzekielO. Soremekun, andAndreas Zeller
•Forcodepointfeatures,thereisalwaysaterminalsymbol
that contains the required code point, and we can use it as a
target for the distancecheck.
•For numeric interpretations, we parse the required value,
and try to reach the root of this parse tree and the same
children as inthe knownparse tree belowthe root.
•Forlengthpredicates,wecanusethedistancetotheproduc-
tionthatthelengthrequirementbelongsto,andwecanthen
try to use longer orshorterderivations.
If there is no predicate which influences a decision, we use the
alternative whichallowsfor the shortest derivation sequence.
4.5 Searching theBest Derivation Sequence
The processin Section 4.4 can generatedifferent candidates, which
needto be rankedandrefined.
The search process maintains a list Lof already analyzed deriva-
tionsequences.Werankthosesequencesbasedonhowmanypred-
icates they fulfill, and choose the current-best derivation sequence
for modification. The newly generated derivation sequences are
added to the list, and may be chosen for refinement in the input
productionfrom Section 4.4 .Assoonasaderivation sequenceful-
fills all predicates, the algorithm returns this input as a solution
andterminates.
This search process will not terminate if the feature set is infea-
sible, that is, if it contains a combination of predicates that cannot
befulfilled.Ifwecouldnotgenerateasamplewithinthetimeout
oftwominutes,we considerapredicate setinfeasible.
WithinAlhazen ,wealwayshavealistofpredicatesetswhen
westartthesearch.Whileweuseonlyonesetforratingderivation
sequences,andstartwithempty Lforthenextpredicatesetassoon
aswefindasolution,wecheckeachderivationsequenceagainst
all predicate sets and output all matching inputs for each sequence.
5 EVALUATION
We evaluate Alhazen inthree differentscenarios:
Predictor. CanAlhazen beusedtopredictwhetheraninputtrig-
gers the bug?( Section 5.2 )
Producer. CanAlhazen be used to produce more inputs that
trigger the bug?( Section 5.3 )
Debugging Aid. DoesAlhazen reducethesearchspaceindebug-
ging?(Section 5.4 )
Aswearenotawareofotherapproachesthatactaspredictorsor
producers,weevaluatethe accuracy ofAlhazen inthesescenar-
ios. By assessing the quality of decision trees both as predictors
andproducers,weensurethattheyneitheroverspecialize(which
wouldmakethemaccurateproducers,butinaccuratepredictors)nor
overgeneralize(whichwouldmakethemaccuratepredictors,but
inaccurate producers). For the third scenario, we evaluate whether
Alhazen separatesrelevantfromirrelevantinputfeatures,allowing
developers to focusonasubsetofthe inputlanguage.
5.1 EvaluationSetup
5.1.1 Subjects. For any predicate over observable program be-
havior,Alhazen can explain the circumstances that trigger this
behavior in terms of input features. In our evaluation, we focusTable 2:Subjectsand Predicates ofInterest
BugID Predicate BugID Predicate
ofInterest ofInterest
calculator.1 errormessage find.24bf33c0 property
Closure.1978 exception find.b445af98 regression
Closure.2808 exception find.e1d0a991 regression
Closure.2842 exception find.ff248a20 timeout
Closure.2937 exception grep.c96b0f2c property
Closure.3178 exception grep.2be0c659 regression
Closure.3379 exception grep.3220317a crashoracle
rhino.385 exception grep.3c3bdace crashoracle
rhino.386 exception grep.55cf7b6a regression
genson.120 exception grep.5fa8c7c9 timeout
find.07b941b1 crashoracle grep.7aa698d3 regression
find.091557f6 crashoracle grep.c1cb19fe regression
find.dbcb10e9 crashoracle
on explaining undesired program behavior (bugs). Table 2lists our
subjectsandpredicates.
Usingthesamefuzzeras[ 18],wefoundninebugsintheGoogle
ClosureCompiler[ 10],theMozillaRhinoJavaScriptRuntime[ 9]
andthe GensonJSON parser [ 6].
Thosebugsareagoodfitfor Alhazen becausetheyaretriggered
by a specific input (by construction, fuzzing generates inputs). All
three subjects are written in Java, and report the exception type,
fileandlinenumberifanerroroccurs.Weusedthisinformation
for our predicate ofinterestinthe same wayas [ 18]did.
Asfourthandfifthsubject,wetookthe grepandfindcommand
lineutilsfromthedbgbenchbenchmark[ 13].Dbgbenchprovides
themeanstocompileandexecuteoldversionsof grepandfind,
and documents the bugs that were present in those old versions.
We useddifferentpredicates of interesthere.
Crash.We checkwhether the program crashes.
Timeout. Wecheckwhethertheprogramterminateswithin500ms.
Regression. Wecheckwhethermorerecentversionsof grepor
findrespectivelyshowthe same behavior.
Property. greponly ever outputs a substring of the input, and
find only ever outputs path to existing files. We use checks for
thosepropertiesas oracles.
Table2listsour subjectsandthe relatedpredicate type.
5.1.2 Evaluation Grammars. In our evaluation, we use a grammar
for eachsubject:
•FortheGoogleClosureCompiler,MozillaRhino,andGenson
we adaptedgrammarsfound inthepopular GitHubrepos-
itory for ANTLR grammars [ 7]. (ANTLR [ 28] is a widely
knownparser generator.)
Forgrepandfind,we wrotegrammars ourselves.
•Forgrep, the grammar generates a full shell command, con-
sisting of an input, a list of environment variables and an
invocation of grep. The input is an alphanumeric string,
whichmaycontainutf-8multibytecharacters.Thegrammar
allows for all environment variables that are documented in
the man page of grepfor the oldest version we used. The
grammar allows for all command line flags that are docu-
mentedinthe manpage of grepfortheoldest version we
used.
1233When DoesMy Program DoThis? Learning Circumstancesof Software Behavior ESEC/FSE ’20, November8–13,2020,VirtualEvent, USA
•Thefindgrammaralsogeneratesafullshellcommand,and
allowsforenvironmentvariablesandcommandlineflags.In
addition, the findgrammar generates a sequence of mkdir,
touchandlnshellcommandstogeneratedirectories,files
andsymbolic links.
5.1.3 GeneratingDataSets. Asothermachinelearningapproaches,
evaluatingourapproachrequiresalargesetofinputdata.Wecould
just generate samples randomly, but it is very unlikely to generate
abehavior-triggeringsamplewithapurerandomproducer.Having
nobehavior-triggering samples inthe data setmakesituseless.
Toavoidthis,weuseamodifiedversionofthełmoreofthesamež
approach taken by Pavese et al. [ 29]. A word is derived from the
grammarbyreplacingnon-terminalswiththeright-handsideofone
oftheirproduction rules,untilthereisnonon-terminalleftinthe
resulting sequence. If a production rule has multiple alternatives, a
random produceris employedto select which alternative is chosen.
The input sample is a word in the grammar, therefore it has a
sequence of derivations that generate it. In our sample generation,
weincreasetheprobabilityofchoosingthesamealternativeasin
the initialbug-triggering input.
Foraword w,let#w(⟨P⟩)bethenumberofoccurrencesof ⟨P⟩
withinw’s derivation sequence, and let # (⟨P⟩ →α)be the number
ofoccurrencesofthealternative ⟨P⟩ →αwithinthissequence.For
ambiguous grammars,let# w(•)be the sumofthosecounts for all
possible parse trees.
Using those counts to calculate probabilities directly would gen-
eratethesamesampleoverandoveragain.Foraproductionrule
⟨Q⟩ →α|β|γ,wethereforedefineasmoothedcount, s(⟨Q⟩ →α)
withs(⟨Q⟩ →α)=#(⟨Q⟩ →α)+1.Further, s(⟨Q⟩)isthesumover
thesmoothed counts for all alternatives of ⟨Q⟩.For our grammar-
based fuzzing, the probability to choose the alternative ⟨Q⟩ →β
(over⟨Q⟩ →αor⟨Q⟩ →γ) isP(⟨Q⟩ →γ)=s(⟨Q⟩→α)
s(⟨Q⟩).
This approach may (still) generate the same sample over and
overagain,soweremoveduplicates,andre-rununtilwehave1000
unique, behavior-triggering samples (the number of non behavior-
triggering samples usually is larger than 1000 at this point). We
stoppedwithasmallernumberofsamplesif20re-runscouldnot
generate enough behavior-triggering samples, or a timeout of 1
hourwasexhausted. Table3givesthenumberofbug-triggeringand
nonbug-triggeringsamplesforeachsubject.Pleasenotethatwe
ranthisalgorithmwiththetransformedgrammars(see Section2.2 ).
Itisclearlyvisiblethatsomebugsarehardertotriggerthenoth-
ers.Forfind.07b941b1 [1]andfind.24bf33c0 [2],itseemstobe
eveneasiertotriggerthebugthangenerateabenigninputsamples.
Ontheotherhand,somebugsareparticularlyhardtotrigger.For
grep.7aa698d3 [4],wehavejust25bug-triggeringinputsamples.
Thisbugrequiresamultibytecharacterintheinput,and aregex
matching this multibyte character as an argument to grep. The
probabilities do not model relations between different parts of the
input,sothe producergeneratesthis structure only bychance.
Then, we split the generated samples into sets.1
4of the bug-
triggeringsamples(thebenignsamples,iftherewerelessbenign
thanbug-triggeringsamples)willbeusedastrainingset,andthe
remaining3
4of them will be the test set. Afterwards, we randomly
selectbenignsamplesforthetrainingset,suchthatthetrainingset
has the same number ofbenign andbug-triggering samples.Table3:Numberofbug-triggeringvs.nonbug-triggeringin-
putsafter generating inputs.
SubjectAllSamples TrainingSamples
benign bug-triggering benign bug-triggering
calculator.1 7163 1041 260 260
closure.1978 8295 868 217 217
closure.2808 3952 1173 293 293
closure.2842 8186 75 19 19
closure.2937 6041 1076 269 269
closure.3178 9558 638 159 159
closure.3379 2915 1152 288 288
rhino.385 4066 1079 270 270
rhino.386 2930 1139 285 285
genson.120 15455 1046 261 261
find.07b941b1 808 1260 202 202
find.091557f6 3487 578 144 144
find.24bf33c0 574 1475 143 143
find.b445af98 3020 76 19 19
find.dbcb10e9 1839 1228 307 307
find.e1d0a991 2758 285 71 71
find.ff248a20 3358 736 184 184
grep.2be0c659 2861 239 60 60
grep.3220317a 3625 475 119 119
grep.3c3bdace 1904 1377 344 344
grep.55cf7b6a 2250 751 188 188
grep.5fa8c7c9 4829 543 136 136
grep.7aa698d3 3075 25 6 6
grep.c1cb19fe 4922 179 45 45
grep.c96b0f2c 3147 50 12 12
Next, we split the remaining samples into sets such that each
set isas large as the training set,each set has the same number of
benignandbug-triggeringsamplesandeachsampleiscontained
inat leastone set.
5.2Alhazen as aPredictor
Toevaluatewhether Alhazen canpredictwhetheraninputisbug-
triggering,wegeneratedsamplesetswithadifferentapproach(see
Section 5.1.3 ), andcalculatedprecision andaccuracyonthose.
WeranAlhazen onthetrainingsetwithtwodifferentseedsfor
therandomproducer,andevaluatedeachrunonallthesets.Within
theseruns,weperformedatmost40iterationsofthefeedbackloop,
andstoppedifwedidnotgenerateanynewsamplesinaniteration.
Theresultsarereportedin Table4.Precisionandaccuracynumbers
are averagesover tworuns for eachset.
We see that Alhazen works very well as apredictor:
Used as predictor, Alhazen classifies 92% of all inputs correctly.
Besidesdemonstratingthehighaccuracyofthedecisiontrees
produced by Alhazen , this also has some practical value. Most
importantly, it means that Alhazen can be used for automatic
workarounds, divertingpotentially failure-inducinginputbefore it
reachestheprograminquestionÐafeaturethatwouldbeespecially
valuable if the failure of interest is a vulnerability. Since Alhazen
runs fully automatically, such workarounds can be deployed as
soonas afailure isdetected.
1234ESEC/FSE ’20, November8–13,2020,VirtualEvent, USA Alexander Kampmann, Nikolas Havrikov, EzekielO. Soremekun, andAndreas Zeller
Table 4: Precision and accuracy when using Alhazen as a
predictor.All valuesare averages over2 runs.
Bug Precision Accuracy Bug Precision Accuracy
calculator.1 100.0% 100.0% find.ff248a20 99.1% 97.6%
closure.1978 97.2% 86.4%genson.120 100.0% 98.6%
closure.2808 99.6% 96.2%grep.2be0c659 78.0% 66.0%
closure.2842 98.6% 96.7%grep.3220317a 99.7% 99.4%
closure.2937 99.5% 92.3%grep.3c3bdace 99.6% 98.9%
closure.3178 96.1% 87.6%grep.55cf7b6a 90.9% 90.6%
closure.3379 94.0% 89.1%grep.5fa8c7c9 100.0% 99.5%
find.07b941b1 100.0% 100.0% grep.7aa698d3 79.4% 84.1%
find.091557f6 96.7% 95.5%grep.c1cb19fe 87.4% 86.6%
find.24bf33c0 87.7% 91.5%grep.c96b0f2c 82.0% 74.8%
find.b445af98 96.1% 96.2%rhino.385 100.0% 92.6%
find.dbcb10e9 100.0% 100.0% rhino.386 100.0% 96.4%
find.e1d0a991 97.3% 93.6%
Total 95.0% 92.0%
The only case where Alhazen has an accuracy of less than
80%isgrep.2be0c659 [3],wherethefailureoccursifagivenregex
matches the inputÐa property not modelled by our features. While
Alhazen can check for features which make such a match more
likely (e.g.a’.’inthe regex),the predictive power suffers.3
5.3Alhazen as aProducer
Let us now examine how well Alhazen performs as a producerfor
moresamples.Weran Alhazen onthetrainingsetswegeneratedin
Section5.1.3 ,andobtainedthepredicatesetsfromthefinaltree.As
before,wegeneratedsamplesforallpaths,andgeneratedvariations
ofthosesubsetsasdescribedin Section4.Wethencheckedwhether
the prediction ofthe tree matches actual program behavior.
Table5givestheresultsforthisexperiment.ThełFailingInputsž
column lists the absolute number of new failure-inducing inputs
generated. The final decision tree may have multiple paths that
leadtothepredictionofafailure. Alhazen generatesanewsample
foreachofthesepaths,however,ifitrunsintoasamplethatfulfills
allpredicatesononepathwhilesolvinganother,thissamplewill
also be reported. Hence, a value of 4 means either that the tree had
four paths; or it had two paths, and three solutions for one of them
were discoveredwhilesearching for asolution for the otherone.
Forthelargemajorityofsubjects, Alhazen produced several
new failure-inducinginputs.
Such additional inputs that trigger the bug can be very valuable
in practice. In manual debugging, they can serve as a test set to
ensurethebughasactuallybeenfixed.Forautomatedrepairs,they
canensurethatallaspectsofabughavebeenfixed,andnotonly
the symptoms ofthe singlefailure inquestion.
ThełPrecisionžcolumnshowsthepercentageofthesefailure-
inducing inputs within the entire set of inputs. We see that in total,
about two thirdsof allproducedinputs actuallytrigger the failure.
3In practice, what would be helpful here is a more domain-specific feature such
as łregex matchesž. For this evaluation, however, we stick to the generic features
introduced in Section 3 , which we chose well before starting the evaluation. Over-
specialization in the set of features is a real risk for evaluation: In the extreme, a
hypotheticalłwill failž featurewould always yield perfect results.Table 5: Precision and accuracy when using Alhazen as a
producer.Precision and accuracyare averages over2 runs.
Bug Failing Inputs Precision Accuracy
calculator.1 1100% 100%
closure.1978 116.7% 95.5%
closure.2808 1152.4% 84.4%
closure.2842 00.0% 1.000
closure.2937 14.5% 72.0%
closure.3178 822.9% 80.0%
closure.3379 00.0% 100.0%
find.07b941b1 6100.0% 100.0%
find.091557f6 4981.7% 90.7%
find.24bf33c0 14100.0% 77.3%
find.b445af98 2087.0% 98.4%
find.dbcb10e9 20100.0% 100.0%
find.e1d0a991 6158.1% 78.5%
find.ff248a20 9468.6% 87.1%
genson.120 480.0% 94.1%
grep.2be0c659 2670.0% 90.4%
grep.3220317a 1297.9% 98.0%
grep.3c3bdace 30100.0% 100.0%
grep.55cf7b6a 64100.0% 94.9%
grep.5fa8c7c9 7100.0% 100.0%
grep.7aa698d3 2281.5% 96.3%
grep.c1cb19fe 1341.9% 59.2%
grep.c96b0f2c 00.0% 90.9%
rhino.385 8100.0% 100.0%
rhino.386 1392.9% 98.1%
Total 3093 68.5% 92.3%
On average,68.5% ofthe inputsproduced by Alhazen as
failure-inducingactuallytriggerthe failure.
For programs where a bug is easily triggered, this number indi-
catesahighefficiencyoftestgeneration.Evenifatestunexpectedly
passes, one can simply repeat it with the next input; a precision of
68.5% means that fewtests needto be repeated.
For some programs, however, the conditions to trigger a bug
arehardtomeet,andevenhardertomodel.Indeed,forsomesub-
jects,Alhazen doesnotgenerateanynewfailure-inducinginput
atall.Forbug grep.c96b0f2c [5],Alhazen needstogeneratean
inputthatcontainsanemptyline,andaregexwhichmatchesan
emptyline;for closure.2937 [8],thebugistriggeredonlybyaspe-
cific nesting of syntax elements. Both regex matching and element
nestingare not reflectedbyour genericinputfeatures.
On the other hand, if one uses Alhazen to produce passing
inputs, a failure is very unlikely. This is reflected in the łAccu-
racyž column, where we see how manyoftheinputs produced by
Alhazen as passing and failing actually are passing and failing.
The total shows the overall very high accuracy of Alhazen as a
producer.
On average,92.5% ofthe inputsproduced by Alhazen as
passing orfailingactuallypassand fail as produced.
1235When DoesMy Program DoThis? Learning Circumstancesof Software Behavior ESEC/FSE ’20, November8–13,2020,VirtualEvent, USA
5.4Alhazen as aDebuggingAid
Wealreadyhaveseenthatusing Alhazen aspredictorandproducer
can be very useful in debugging. It may also be interesting how to
use thetrees directly.However,it isnot yetclear tous,and outof
scope for this work, howto present thosetrees to developers.
Most published automated debugging techniques are evaluated
for theirfault localization capability, that is, their ability to predict
whereabugshouldbefixed.Focusingoncodeisnotappropriate
forAlhazen , as it does not predict a bug location; actually, as it
treats the program under test as a black box, it neither has nor
needs nor produces any concept of a fault location. (This makes
Alhazen especially useful if the program in question, say a neural
network, has noconcept ofafaultlocation either.)
Otherautomateddebugging techniquesallow developersto fo-
cus on the relevant parts of the input; delta debugging [ 37], for
instance,automaticallyreducestheinputtoaminimuminwhich
allcharactersarerelevantforproducingthebug.Theamountby
whichthesearchspaceis reduced,however,depends moreonthe
input (which may contain more or less relevant characters) than
the actual approach.
Thisismoresuitablefor Alhazen ,asAlhazen alsoworkson
input representations. However, we do not minimize an existing
input, as delta debugging does, instead we report which parts of
inputstructurearerelevant.Wedonotyetknowhowtopresent
this information to developers, butwe assume that a model which
reportsasmallpartoftheunderlyinggrammarallowsthedeveloper
tofocusmuchmore.Smallerislesscomplicated,andthereforeeasier
to interpret.
For evaluating how much Alhazen can help in reducing the
searchspace,wethereforeintroduceameasurethatisindependent
ofanimplementation andindependentofconcreteinputs.In Table6,
we have evaluated how many of the non-terminal symbols and
alternatives from the grammar occur in the decision tree. The idea
behindthisisthateachnonterminalandalternativeinthegrammar
standsforaspecificconcept;thefewersuchconceptsaprogrammer
hastodealwith,theeasieritwillbeforhertocapturethespecifics
ofthe bug,andeventually to fixit.
Ifthetreeuses exists(⟨number⟩)inonenodeand max(⟨number⟩)
in another one, this will be counted as one nonterminal symbol,
⟨number⟩, the programmer will have to deal with as a relevant
conceptÐin contrast to ⟨string⟩,⟨loop⟩and several more that do
not occur inthe tree andthus are deemedirrelevantfor the bug.
We see that on average, the decision tree makes use of only
3.62% of nonterminals, and only 4.86% of alternatives in the respec-
tive grammar. In other words, whatever happens with 96.38% of
nonterminalsisirrelevantfortherespectivefailuretooccur.This
meansthatprogrammerscanindeedfocusonasmallpercentage
ofrelevantinputfeatures.
The decision trees produced by Alhazen allow programmers to
focusonlessthan5% ofinputfeatures.
Theactualpercentagehighlydependsonthesizeofthegrammar.
Forcalculator.1 ,whichusesthegrammarin Figure2,33.3%of
thegrammararemarkedasrelevant;however,withsuchasmallTable 6:Tree size and %ofgrammarused persubject.
Bug #nodes #leaves % ofgrammar used
non-terminals alternatives
calculator.1 5.0 3.0 33.3 25.0
closure.1978 29.0 15.0 2.0 1.4
closure.2808 13.0 7.0 0.7 0.8
closure.2842 11.0 6.0 1.5 0.3
closure.2937 23.0 12.0 2.4 0.8
closure.3178 38.0 19.5 2.9 1.7
closure.3379 25.0 13.0 1.5 1.4
find.07b941b1 3.0 2.0 0.5 0.1
find.091557f6 28.0 14.5 4.1 0.8
find.24bf33c0 20.0 10.5 4.1 0.5
find.b445af98 19.0 10.0 4.1 0.4
find.dbcb10e9 3.0 2.0 0.0 0.1
find.e1d0a991 33.0 17.0 6.0 0.8
find.ff248a20 35.0 18.0 4.1 1.0
genson.120 18.0 9.5 23.3 23.7
grep.2be0c659 41.0 21.0 6.5 1.2
grep.3220317a 18.0 9.5 2.2 0.7
grep.3c3bdace 11.0 6.0 2.2 0.3
grep.55cf7b6a 33.0 17.0 4.7 1.1
grep.5fa8c7c9 7.0 4.0 0.9 0.2
grep.7aa698d3 11.0 6.0 2.2 0.3
grep.c1cb19fe 23.0 12.0 5.6 0.5
grep.c96b0f2c 16.0 8.5 2.2 0.3
rhino.385 11.0 6.0 1.3 0.4
rhino.386 13.0 7.0 1.1 0.6
Average 19.48 10.24 3.62 4.86
⟨unicode_no_minus ⟩="U+0130"?
✔no
len(⟨start⟩) ≤66?yes
✔yes
⟨lc_all⟩="en_US.UTF-8 "?no
✔no
⟨first_inputchar ⟩="\"⟨digit⟩⟨digit⟩⟨digit⟩yes
len(first_inputchar ) ≤3?no
len(inputstring ) ≤35?yes
✘yes
✘no
✘yes
✔no
Figure 9:Decision tree forgrep.7aa698d3.
grammar, this means two non-terminal rules. For the largest gram-
mar in our selection, JavaScript (used with Closure and Rhino),
Alhazen can reduce the relevantelements to 1.67% onaverage.
5.5 Limitations
Whileallowingprogrammerstofocusonspecificaspects,thein-
ferreddecisiontreescanstillbecomplex.Thisreflectsthecomplex-
ityoftheunderlyingbugs,whichinturnalsoshowsthelimitsof
ourapproach.Infact,thebugsinourevaluationhavenon-trivial
1236ESEC/FSE ’20, November8–13,2020,VirtualEvent, USA Alexander Kampmann, Nikolas Havrikov, EzekielO. Soremekun, andAndreas Zeller
descriptionseveninnaturallanguage,andthiscomplexityisalso
reflectedinthedecisiontrees:Asweseeinthefirsttwocolumnsof
Table 6, the average decision tree has about 20 nodes and 10 leaves.
The tree in Figure 9 forgrep.7aa698d3 is a typical example
reflecting complex conditions. The actual bug occurs with all char-
acters where the unicode representation of the lower case variant
has fewer bytesthanthe representation ofthe upper casevariant.
Since our tree can only use numeric comparisons of unicode
codepoints,itcannotfullycapturethiscomplexcondition(shortof
listingallcharacterswiththisproperty;notethatUnicodecharac-
ters with this property are not in a continuous area of the Unicode
representation.).Instead,thetreechecksforthesingleunicodechar-
acter"U+0130"(I-with-dot)for which the above condition holds.
This, ofcourse,isan overspecialization.
The notation "\"⟨digit⟩ ⟨digit⟩ ⟨digit⟩is an alternative for how
unicodecharacterscanbeencoded,sothetreere-iteratesthatthere
should be aunicode character inthe input.4
To more precisely capture the failure condition, as above, one
would again have to provide Alhazen with specific features to
check forÐin our case, a vocabulary over external and internal
Unicodeproperties.Butevenwiththetreebeingimperfect,itclearly
points to the correct featuresÐnamely the one important Unicode
character as well as the Unicode context. Both of these are very
relevantfeatures(outofseveralhundredinthegrepinputgrammar)
for understanding the circumstances of the failure, and provide
importanthints for fixing it.
Forbest results,theset ofinputfeatures used by Alhazen
shouldbeadaptedtothefunctionalityoftheprogramundertest.
5.6 Threatsto Validity
InSection5.3 weusethesamealgorithmtogenerateinputsasin
Alhazen ’siterations.Ifthereissomepropertyoftheproducerthat
leads to properties of the generated input that are not described
inthedecisiontrees,thiswouldhaveapositiveinfluenceonour
results. One such property could be that our producer always tries
to minimize the derivation sequences. We are not aware of any
otherproducerthatcouldgeneratesamplesfromagrammarand
apredicate,sothereiscurrentlynoalternativetothisevaluation.
Atthe sametime,ourclaimis that Alhazen canhelp togenerate
more inputs which trigger the desired behavior, which is true even
if itworks only withour producer.
6 RELATED WORK
Grammars andGrammar Mining. The key ingredient to Al-
hazenisagrammar,usedfor(1)extractingfeaturesfromtheinput
byparsingit;and(2) generating additionalinputsforrefiningand
refuting hypotheses. The double usage of grammars as parsers and
producersiswell-knownintheliterature.Whatisnewin Alhazen ,
4What we also see are three lenpredicates in the tree. The first one captures the fact
that you need a minimum length of 66 in our setting to have a unicode character
passed as an argument. The other two are cases of coincidental correlation Ðthat is,
featuresthathappentomatchallobservationssofar,butwhichhavenotbeenrefuted
byourgenerationalgorithmyet.Thesefeaturesdonotsignificantlyimpedeprediction
or production accuracy, however, and would be eliminated with an increasing number
of iterations.though, is the generic usage of a grammar to learn features for
machine learning and debugging, as well as the combination of
parsingandproducing as embodimentof the scientificmethod.
Recentdevelopmentsin mininggrammars fromprograms[ 12,17,
19] might considerably reduce the effort of writing the required
grammars.Parser-directedtestgeneration[ 25]caneliminatethe
needfor sample inputsto learn grammars from.
Input Reduction. Input Reduction refers to techniques that auto-
maticallydetermineasubsetoftheinputthatstillreproducesthe
failure; such simplification is an important prerequisite for debug-
ging.Deltadebugging [37]istheearliestandsimplesttechniquefor
reducing inputs; going through a number of tests, it reduces any
input to a minimum in which removing any character no longer
causesthe failure. Later variantsof input reductioncombine delta
debugging with grammars for faster reduction [ 26,31] or are set
upto simplifycomplex inputlanguages[ 36].
Alhazen sharesanumberofideaswithinputreduction,notably
(1) the goal of eliminating circumstances that are irrelevant for the
failure;(2)theconceptofworkingonsysteminput;and(3)theidea
of refining or refuting hypotheses via generated tests. There are
two core differences, though. First, Alhazen can create theories
fromobservationsonly, withouttheneedforexecutingadditional
tests. Second, Alhazen generalizes over reduction techniques in
that the resultisnot one singlesimplified input,butamodel for a
set ofinputs that explains andreproduces the failure.
StatisticalFaultLocalization. Statistical fault localization [ 21,
24,35]searchesfor statisticalassociations betweenprogramfailures
andprogramruntimefailures,notablytheexecutionofspecificcode
locations. Given a sufficiently large number of executions, a small
setoflinesexecutedonlyinfailingrunsmaybedetermined,making
these natural candidates for further investigation or even fixes.
Whiletheusefulnessofstatisticalfaultlocalizationforprogrammers
isdisputed[ 27],thegivenlocationsmakeimportantstartingpoints
for automatedrepairtechniques [ 23,33].
Chen et al.[ 14] use a decision tree to learn which component in
a large internet site causes a specific failure. This is close to our
approach, in that it uses decision trees, but still a (kind of) fault
localization, as a specific component within a multi-component
systemisidentified.
Just like statistical fault localization, Alhazen creates associations
involving program failures. However, the Alhazen associations
refer to features of the input, which is an important conceptual
difference. Since input features refer to the problem domain and
areindependent ofagiven implementation,theymaybeeasierto
understandthancode locations withoutany context.
A second important conceptual differenceisthat Alhazen allows
for refining or refuting hypotheses through test generation; this is
possible as it uses its grammar as producer. In practice, this means
thatAlhazen can start with a single failing run only. A similar
feature for statistical fault localization would require the ability
to generate tests that execute or do not execute a particular line,
whichishardinpracticeandundecidable ingeneral.
Holmes[20]alsousestestgenerationtocreatemoretestssimilar
to a failing test, but does so on pure luck: There is no systematic
explorationofhypothesis.Rößleretal.[ 30]combinestatisticalfault
localization with test case generation, and therefore systematically
1237When DoesMy Program DoThis? Learning Circumstancesof Software Behavior ESEC/FSE ’20, November8–13,2020,VirtualEvent, USA
test hypothesis. They, however, still work on source code, rather
thaninputs.
Dynamic Invariants. Dynamicinvariantsarepropertiesinferred
overobservationsinagivensetofprogramruns.Iftheargument x
tosqrt(x) is always non-negative, for instance, a dynamic invari-
antdetectorlikeDAIKON[ 16]caninferthepreconditioncandidate
x≥0.DAIKONachievesthisbystartingwithalargesetofpotential
invariants, keeping only thosethat apply inallruns.
Likedynamicinvariants, Alhazen generatesabstractionsthatap-
plyinasetofruns;itspredicates,however,applytoinputelements
ratherthanfunctionargumentsandreturnvalues;thisalsogives
Alhazen theabilitytogenerateadditionaltestsasneeded,whichis
not easily possible for dynamic invariant generation. However, the
Alhazen predicates atthis pointonly involve the presence of spe-
cific elements or production alternatives. A wider set of features as
with DAIKON, including arithmetic, set, and string properties over
input elements, could dramatically improve the diagnostic capabili-
tiesofAlhazen Ðalbeitattheexpenseofmakingtestgeneration
more difficult.
7 CONCLUSION AND FUTUREWORK
Learninghowinputfeaturesdetermineprogrambehavior,as Al-
hazendoes,opensnewperspectivesforprogramunderstanding
anddebuggingÐnotonlycharacterizingthecircumstancesunder
which a program fails, but also predicting failures for given inputs
as well as producing additional inputs that cause failures. Our eval-
uationshowsthat Alhazen performsallofthesetaskswithhigh
accuracy,demonstrating the potentialofthe approach.
WeseeAlhazen asabigsteptowardsbetterdebugging,butalso
asaplatformandopportunityforlotsoffurtherresearch.Future
work includes:
Domain-specific features. The łvocabularyžthat Alhazen can
usetocharacterizefailurecircumstancesisintentionallylimited
to the very syntactical and numerical basics. Adding more fea-
turesthatcatertothedomainoftheprogramathandcouldyield
much crisper, and possibly even more precise failure character-
istics.Thechallengeistostriveabalancebetweengenerality
andspecificity.
Explainable AI. Astheprogramundertestcanbearbitrarylarge
or obscure, Alhazen can also be used to produce explanations
for the behavior of artificial intelligence systems; again, one
wouldneeddomain-specificfeaturesthathelpdistinguishing
behavior.
Efficient refinement. Weareexploringmoresophisticatedmeth-
odsfor testing hypothesesthat systematically cover language
features.
Intercorrelated features. Inagrammar,severalfeaturesintercor-
relate with each other: In our expression example, a ⟨number⟩
canonlyoccurifa ⟨function⟩occursaswell.Thelearnercan
settleoneitherofthesetodistinguishpassingfromfailingruns;
suchchoices,however,mayimpactperformanceanddiagnostic
qualityofthe resultingtrees.
Alternatelearners. Whiledecisiontreescanbeeasilyreadbyhu-
mans,othermachinelearners,suchasSVMsorneuralnetworks,
could capture failure circumstances much more precisely. The
challenge will be to use these learners to generate additionalinputs to refine hypotheses, and to extract human-readable
descriptionsoffailure circumstances.
Program analysis. Guidance from static or dynamic program
analysis could greatly enhance hypothesis forming and testing.
Beyond failures. Thediagnosticcapabilitiesof Alhazen easily
extend to arbitrary program behaviorsÐsuch as the circum-
stances under which a particular resource is accessed, a data
flowtakesplace,afunctioniscovered,memoryisexhausted,
andmanymore.
Alhazen andallexperimentsdescribedinthispaperareavail-
ableforreplicationandextension.Forreviewpurposes,wehave
compiledareplication package[ 22]withallcode anddata at
https://zenodo.org/record/3902142
REFERENCES
[1]2017. DbgBench - find.07b941b1. https://dbgbench.github.io/find.07b941b1.
report.txt
[2]2017. DbgBench-find.24bf33c0. https://dbgbench.github.io/find.24bf33c0.report.
txt
[3]2017. DbgBench - grep.2be0c659. https://dbgbench.github.io/grep.2be0c659.
report.txt
[4]2017. DbgBench - grep.7aa698d3. https://dbgbench.github.io/grep.7aa698d3.
report.txt
[5]2017. DbgBench - grep.c96b0f2c. https://dbgbench.github.io/grep.c96b0f2c.
report.txt
[6] 2017. Genson. https://github.com/owlike/genson . Version 1.4.
[7] 2018. ANTLRGrammars. https://github.com/antlr/grammars-v4/ .
[8]2018.INTERNALCOMPILERERROR:assigningaclassextendingclassexpression
#2937.https://github.com/google/closure-compiler/issues/2937
[9] 2018. Mozilla Rhino. https://github.com/mozilla/rhino . Version 1.7.8.
[10] 2019. Google Closure. https://github.com/google/closure-compiler . v20180101.
[11] 2020. CVE-2020-5214. https://nethack.org/security/CVE-2020-5214.html
[12]Osbert Bastani, Rahul Sharma, Alex Aiken, and Percy Liang. 2017. Synthesizing
programinput grammars. ACMSIGPLAN Notices 52,6 (2017), 95ś110.
[13]Marcel Böhme,Ezekiel OlamideSoremekun,Sudipta Chattopadhyay,Emamurho
Ugherughe, and Andreas Zeller. 2017. Where is the Bug and How is it Fixed?
An Experiment with Practitioners. In Proceedings of the 11th Joint meeting of the
European Software Engineering Conference and the ACM SIGSOFT Symposium on
the FoundationsofSoftwareEngineering (ESEC/FSE 2017) . 1ś11.
[14]MikeChen,AliceXZheng,JimLloyd,MichaelIJordan,andEricBrewer.2004.
Failurediagnosisusing decisiontrees.In InternationalConferenceonAutonomic
Computing, 2004. Proceedings. IEEE,36ś43.
[15]Jay Earley. 1970. An efficient context-free parsing algorithm. Commun. ACM 13,
2 (1970), 94ś102.
[16]MichaelDErnst,JeffHPerkins,PhilipJGuo,StephenMcCamant,CarlosPacheco,
Matthew S Tschantz, and Chen Xiao. 2007. The Daikon system for dynamic
detection of likely invariants. Science of computer programming 69, 1-3 (2007),
35ś45.
[17]Patrice Godefroid, Hila Peleg, and Rishabh Singh. 2017. Learn&fuzz: Machine
learningforinputfuzzing.In 201732ndIEEE/ACMInternationalConferenceon
AutomatedSoftwareEngineering (ASE) . IEEE,50ś59.
[18]Nikolas Havrikov and Andreas Zeller. 2019. Systematically Covering Input
Structure.In 201934thIEEE/ACMInternationalConferenceonAutomatedSoftware
Engineering (ASE) . IEEE,189ś199.
[19]Matthias Höschele and Andreas Zeller. 2016. Mining Input Grammars from
Dynamic Taints. In Proceedings of the 31st IEEE/ACM International Conference on
Automated Software Engineering (ASE 2016) . ACM, New York, NY, USA, 720ś725.
https://doi.org/10.1145/2970276.2970321
[20]Brittany Johnson, Yuriy Brun, and Alexandra Meliou. 2020. Causal Testing:
Understanding Defects’ Root Causes. In Proceedings of the 2020 International
Conference onSoftwareEngineering .
[21]JamesAJonesandMaryJeanHarrold.2005. Empiricalevaluationofthetaran-
tula automatic fault-localization technique. In Proceedings of the 20th IEEE/ACM
international Conference onAutomatedsoftwareengineering . 273ś282.
[22]AlexanderKampmann,EzekielSoremekun,NikolasHavrikov,andAndreasZeller.
2020. When does my Program do this? Learning Circumstances of Software
Behavior. https://doi.org/10.5281/zenodo.3902142
[23]ClaireLeGoues,ThanhVuNguyen,StephanieForrest,andWestleyWeimer.2011.
Genprog:Agenericmethodforautomaticsoftwarerepair. Ieeetransactionson
softwareengineering 38,1 (2011), 54ś72.
[24]BenLiblit, MayurNaik, Alice X Zheng, Alex Aiken,and MichaelI Jordan.2005.
Scalable statisticalbugisolation. ACMSigplan Notices 40,6 (2005), 15ś26.
1238ESEC/FSE ’20, November8–13,2020,VirtualEvent, USA Alexander Kampmann, Nikolas Havrikov, EzekielO. Soremekun, andAndreas Zeller
[25]BjörnMathis,RahulGopinath,MichaëlMera,AlexanderKampmann,Matthias
Höschele, and Andreas Zeller. 2019. Parser-directed fuzzing. In Proceedings
of the 40th ACM SIGPLAN Conference on Programming Language Design and
Implementation . 548ś560.
[26]Ghassan Misherghi and Zhendong Su. 2006. HDD: hierarchical delta debugging.
InProceedingsofthe28thinternationalconferenceonSoftwareengineering .142ś
151.
[27]ChrisParninandAlessandroOrso.2011. Areautomateddebuggingtechniquesac-
tually helping programmers?. In Proceedings of the 2011 international symposium
onsoftwaretestingand analysis . 199ś209.
[28] TerenceParr. 2013. The definitiveANTLR4 reference . Pragmatic Bookshelf.
[29]EstebanPavese,EzekielSoremekun,NikolasHavrikov,LarsGrunske,andAn-
dreasZeller.2018.InputsfromHell:GeneratingUncommonInputsfromCommon
Samples. arXiv preprint arXiv:1812.07525 (2018).
[30]Jeremias Rö βler, Gordon Fraser, Andreas Zeller, and Alessandro Orso. 2012.
Isolatingfailurecausesthroughtestcasegeneration.In Proceedingsofthe2012
international symposiumonsoftwaretestingand analysis . 309ś319.[31]Chengnian Sun, Yuanbo Li, QirunZhang, Tianxiao Gu, and Zhendong Su. 2018.
Perses: Syntax-guided Program Reduction (ICSE ’18) . ACM, New York, NY, USA,
361ś371. https://doi.org/10.1145/3180155.3180236
[32]Philip H Swain and Hans Hauska. 1977. The decision tree classifier: Design and
potential. IEEE Transactions onGeoscienceElectronics 15,3 (1977), 142ś147.
[33]WestleyWeimer,ThanhVuNguyen,ClaireLeGoues,andStephanieForrest.2009.
Automatically finding patches using genetic programming. In 2009 IEEE 31st
InternationalConference onSoftwareEngineering . IEEE,364ś374.
[34]Wikipedia. 2020. Ibn_al-Haytham. https://en.wikipedia.org/wiki/Ibn_al-
Haytham
[35]W Eric Wong, Ruizhi Gao, Yihao Li, Rui Abreu, and Franz Wotawa. 2016. A
survey on software fault localization. IEEE Transactions on Software Engineering
42,8 (2016), 707ś740.
[36]XuejunYang,YangChen,EricEide,andJohnRegehr.2011. Findingandunder-
standingbugsinCcompilers.In Proceedingsofthe32ndACMSIGPLANconference
onProgramminglanguagedesignand implementation . 283ś294.
[37]Andreas Zeller and Ralf Hildebrandt. 2002. Simplifying and isolating failure-
inducing input. IEEE Transactions on Software Engineering 28, 2 (2002), 183ś200.
1239