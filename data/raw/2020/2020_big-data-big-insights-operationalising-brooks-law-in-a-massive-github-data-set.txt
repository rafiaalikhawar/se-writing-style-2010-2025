Big Data = Big Insights? Operationalising Brooksâ€™ Law in a
Massive GitHub Data Set
Christoph Gote
cgote@ethz.ch
Chair of Systems Design, ETH Zurich
Zurich, SwitzerlandPavlin Mavrodiev
pmavrodiev@ethz.ch
Chair of Systems Design, ETH Zurich
Zurich, Switzerland
Frank Schweitzer
fschweitzer@ethz.ch
Chair of Systems Design, ETH Zurich
Zurich, SwitzerlandIngo Scholtesâˆ—
ingo.scholtes@uni-wuerzburg.de
Chair of Computer Science XV - Machine Learning for
Complex Networks, Julius-Maximilians-UniversitÃ¤t
WÃ¼rzburg
WÃ¼rzburg, Germany
ABSTRACT
Massive data from software repositories and collaboration tools
are widely used to study social aspects in software development.One question that several recent works have addressed is how a
software projectâ€™s size and structure influence team productivity, a
question famously considered in Brooksâ€™ law. Recent studies using
massive repository data suggest that developers in larger teams
tendtobelessproductivethansmallerteams.Despiteusingsimilar
methods and data, other studies argue for a positive linear or even
super-linear relationship between team size and productivity, thus
contestingtheviewofsoftwareeconomicsthatsoftwareprojects
arediseconomiesof scale.
In our work, we studychallenges that can explain the disagree-
mentbetween recent studies of developer productivity in massive
repository data. We further provide, to the best of our knowledge,
thelargest,curatedcorpusof GitHubprojectstailoredtoinvestigate
the influence of team size and collaboration patterns on individual
andcollectiveproductivity.Ourworkcontributestotheongoing
discussion on the choice of productivity metrics in the operational-
isation of hypotheses about determinants of successful softwareprojects. It further highlights general pitfalls in big data analysis
andshowsthattheuseofbiggerdatasetsdoesnotautomatically
leadto more reliable insights.
ACM Reference Format:
Christoph Gote, Pavlin Mavrodiev, Frank Schweitzer, and Ingo Scholtes.
2022.BigData=BigInsights?OperationalisingBrooksâ€™LawinaMassive
GitHubDataSet.In 44thInternationalConferenceon SoftwareEngineering
(ICSE â€™22), May 21â€“29, 2022, Pittsburgh, PA, USA. ACM, New York, NY, USA,
12 pages. https://doi.org/10.1145/3510003.3510619
âˆ—AlsowithDataAnalyticsGroup, Department of Informatics, University of Zurich.
This work is licensed under a Creative Commons Attribution-NonCommercial-
ShareAlike International 4.0 License.
ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Â© 2022 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-9221-1/22/05.
https://doi.org/10.1145/3510003.35106191 INTRODUCTION
Empirical research across disciplines is nowadays driven by the
availabilityofbigdataandmethodstoprocessandanalysethem
efficiently. In empirical software engineering, massive data from
softwarerepositoriesandonlinecollaborationtoolsarewidelyused
toinvestigatesocialandhumanaspectsinsoftwaredevelopment.
This intersects with computational social science, which uses big
data to test hypotheses about individual and collective human be-
haviour originally developed in sociology, social psychology, or
organisational theory. Data-driven studies of developer productiv-
ityinlargesoftwareprojectsareanexemplarycaseofhowresearch
inempiricalsoftwareengineeringcanadvancecomputationalsocial
science. The question of how factors like, e.g., team size, influence
theproductivityofteammemberswasalreadyaddressedbyMaxim-
ilien Ringelmann [ 1] in 1913. In social psychology, his finding that
individual productivity tends to linearly decrease with team size is
known as the Ringelmann effect. In software project management,
asimilarobservationisfamously paraphrased as Brooksâ€™law [2].
Here, the anecdote that â€œadding manpower to a late project makes
itlaterâ€capturesthattheoverheadassociatedwithgrowingteam
sizescanreduceteamefficiency.Studiesofcollaborativesoftware
projectsfoundevidenceforastrongRingelmanneffectfordifferentteamsizes,programminglanguages,anddevelopmentphases[
3â€“6].
Otherstudies,however,foundapositivelinearorevensuper-linear
relationship between the size of a team and the productivity of its
members[7â€“9].
Thefactthatdifferentworksstudyingthesameresearchques-
tion yield qualitatively different results, despite applying similar
methods to data from similar or even identical sources, should con-
cern us.Referring tothe massive number of projects,commits, or
developers covered in their studies, authors often corroborate their
findings by the size of the data used to obtain them, thus implying
thattheanalysisofbiggerdataautomaticallyyieldsmorereliable
insights. This points to an important general issue relevant forempirical research beyond software engineering: Apart from ad-
vantages in terms of coverage, resolution, or statistical confidence,
theuseofbigdata alsointroduces new threatsforthevalidityof
results. To address this issue, in this work, we explore four chal-
lenges in the analysis of big data. We study those challenges in a
massiveGitHubdatasetandarguethattheyarelikelytoexplain
2622022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)
ICSEâ€™22,May21â€“29,2022,Pittsburgh,PA, USA Gote, et al.
conflicting results on the Ringelmann effect that were reported in
recent works.
A first challenge is the quality of big data that, rather than
being carefully collected and curated to address a specific research
problem, are often incidentally generated as â€œdigital exhaustâ€ of
largeonlineplatforms.Inempiricalsoftwareengineering,thisholds
for massive data on software repositories harvested from online
platformslike,e.g., GitHuborSourceForge.Whilemassivereposi-
torydatapromiseinsightsintouniversalsofcollaborativesoftware
development, they are known to suffer from various quality issues.
These originate, e.g., from the inclusion of repositories that do not
relate to software projects, projects whose development history is
onlypartiallyrepresentedinthedata,orambiguitiesthathinderthe
reliable identification ofdevelopers [ 10â€“13]. Thisposesparticular
problemsforstudiesaddressingtheeffectofteamsizeondeveloper
productivity,whichrequirereliabledataon collaborative projects
thatprovideacompletepictureofdevelopmentactionsattributable
to individual team members.
Asecondchallengeis population validity ,whichdetermines
whether findings obtained in a given data sample can be extrap-
olated to a larger population. On the one hand, for reasons of
computational efficiency, researchers often base their results on
asubsetoftheobservationsavailableinmassivedata,whichcan
introduce biases that question population validity. On the other
hand,wecannotnecessarilyavoidsuchbiasesbyusingallavailable
datasincepopulationvaliditydependsonthepopulationforwhich
wewanttoansweragivenresearchquestion.Inmassiverepository
data, using full information on all GitHubprojects may be justified
if we want to answer a question about the population of GitHub
projects.However,ifweusedataon GitHubtoobtaingeneralisable
findingsonhowthesizeofsoftwaredevelopmentteamsaffectsthe
productivity of team members, we must carefully select projects
to avoid biased samples in which either small or large teams are
overrepresented.
Athirdchallengeis constructvalidity ,whichincludestheis-
suethatrichandbigdataprovidevariousoptionstooperationalise
researchquestionsorhypotheses.Whetherornotthespecificop-
erationalisation chosen by a study is valid to address a research
questionisanimportantissuethatinfluencesthevalidityofresults.
Inthecontextofdeveloperproductivity,dataonsoftwarereposi-
tories is an example of high-dimensional and time-resolved data.In such data, productivity can be measured in various ways, and
analysescanbeappliedfordifferentlevelsoftemporalaggregation,
whichis likely to affect the results.
Finally,omitted-variable bias is a fourth challenge that limits
the reliability of findings if relevant variables are excluded from an
analysis.Technically,thisisageneralchallengethatisnot dueto
thecharacteristicsofbigdata.Weneverthelessconsideritinour
work because high-dimensional data are likely to contain variables
thatcanbeusedtoaddressthisissue.InthecontextofBrooksâ€™law,
we can think of multiple explanations for an observed relationship
between,e.g.,thesizeofateamandtheproductivityofitsmembers.
Oneexplanationcouldbea causalmechanismbywhichgrowing
team size influences developer productivity, e.g., by reducing or
increasingthemotivationofteammembers.Analternativeexplana-tioncouldbeanadditionalvariablerelatedtothesizeofateam and
developersâ€™productivity,suchase.g.,thecollaborationstructureofa team. A lack of control for such variables not only introduces bi-
asesintheinferenceoftheactualrelationshipbetweenvariablesofinterest.Itcanalsoleadtotheidentificationofspuriouscause-effect
relationships that negatively influence decision-making.
The four challenges summarised above question both the in-
ternalandexternalvalidity [14]ofempiricalresearchinsoftware
engineering,whichcanexplainwhyworksstudyingthesameques-
tioninthesamedataarriveatdifferentconclusions.Focusingon
theoperationalisationofBrooksâ€™law,inthiswork,weshowhow
toaddresstheminmassive GitHubdata.Ourcontributionsareas
follows:
/playTo address the challenges of dataquality andpopulation
validity, we create a large, curated data corpus on Open
SourceSoftware(OSS)projectsthatfacilitatesthestudyof
theinfluenceof team size on both individual and collective
productivity. The projects included in this corpus are sys-
tematically chosen based on (i) transparent filtering criteria
thatavoidcommonperilsinGitHubmining[ 11]and(ii)a
stratifiedsamplingthatsupportsunbiasedanalysesoftheim-
pactof teamsizeondeveloper productivity.Wemakeboth
our corpus and the pipeline to filter, sample, and processdata based on
GHTorrent [15], a database freely available
forresearchers.
/playToaddress constructvalidity ,wesystematicallycompare
metrics for developer productivity in the data corpus cre-ated above. Acknowledging that productivity is a multi-
dimensional phenomenon, we select a set of eight code- and
commit-basedproductivitymeasures.Westudytheircross-
correlation to answer which of the measures are likely to be
interchangeableandwhichcaptureindependentdimensions
of productivity.
/playAddressing omitted-variablebias ,wefinallystudytowhat
extent changes in productivity can be causally explained by
the collaboration structure of projects rather than team size.
Building on a recently developed method to construct time-
evolvingco-editingnetworksbasedon gitrepositories[ 16],
we investigate eight network metrics whose choice is rooted
in social capital theory. We study the cross-correlation of
thosemetricstoidentifywhichofthemcaptureindependent
dimensions.
/playWe apply our methods to study the Ringelmann effect incollaborative software development based on the corpus
and methods developed above. We find a strong and signifi-
cant negative relationship between team size and individual
productivity that can beexplained basedon changesin the
collaboration structure of software teams. We further show
thatafailuretoaccountforthechallengesoutlinedabovecan
lead to spurious results that suggest a positiverelationship.
In summary, we study challenges that can explain the disagree-
mentbetween recent studies of developer productivity in massive
repository data. We further provide, to the best of our knowledge,
thelargest,curatedcorpusof GitHubprojectstailoredtoinvestigate
the influence of team size and collaboration patterns on individual
andcollectiveproductivity.Ourworkcontributestotheongoing
263BigData= Big Insights? Operationalising Brooksâ€™ Law in a Massive GitHub Data Set ICSEâ€™22, May21â€“29,2022,Pittsburgh,PA, USA
discussion on the choice of productivity metrics in the operational-
isation of hypotheses about determinants of successful software
projects. It further highlights general pitfalls in big data analysis
andshowsthattheuseofbiggerdatasetsdoesnotautomatically
leadto more reliable insights.
2 SYSTEMATIC CONSTRUCTION OF DATA
CORPUS
We first introduce a framework to select and mine projects from
GitHubthat can be used to address the first two challenges of
data quality andpopulation validity. We use it to systematically
sample 201 OSS projects covering the entire range of team sizesonGitHub. We further extract time-stamped editing events that
we use to investigate whether collaboration structures can explain
teamproductivity.
2.1 Dataquality
To select suitable projects from GitHub, we propose the project
selectionand samplingpipelineshown inFigure1. Asafirst step,
we need to gain access to the information required to apply our
selection criteria. Because GitHubâ€™s REST API is rate-limited to
5,000 requests per hour1, retrieving the metadata of more than
100 million repositories hosted on GitHub[17] becomes untenable.
We,therefore,usethedatabasemadeavailablebythe GHTorrent
project[15],whichhascrawledmostof GitHubâ€™sRESTAPIusing
donatedAPIkeys.Weusethelatest1availabledumpfromJune2019
that contains data on a total of more than 125 million repositories.
Asasecondstep,wedeterminewhichprojectsinthe GHTorrent
database are suitable to study collaborative OSS development.I th a s
alreadybeenreportedbytheauthorsof[ 11]thatthemajorityof
projects on GitHubare either personal, inactive, or very small and
shouldbeexcludedwhenanalysingcollaborativesoftwaredevel-
opment. We adopt the filtering criteria proposed by the authors of
[11], namely excluding repositories with a single developer, fewer
than 50 commits, or a span of fewer than 100 days between the
first and last commit in the repository. The resulting data set re-
ducestoaround4.5millionOSSprojects,i.e.,3.6%ofall GHTorrent
repositories. In other words, following [ 11], at least 96.4% of the
repositories in the latest GHTorrent database are not suitable for
studyingcollaborative software development.
Wefurtherimproveonthesefilteringcriteriainthefollowing
two ways. First, GitHubis frequently used for applications not
related to software development, such as free file storage or web
hosting [ 11]. Our own analysis revealed a substantial number of
popular repositories2not representative of collaborative software
development, e.g., tutorials on git, code snippet repositories, or
git-based â€œclocksâ€, which are updated with a new commit every
second. Excluding these repositories is crucial to avoid misleading
results.
Second, as a result of the functionality to forkany public reposi-
tory,GitHubcontains a substantial amount of repositories that are
inlargepartsexactcopiesofotherprojects.Wedropallrepositoriesthataredesignatedas forkstoavoidbiasesfromanalysingthesame
commithistory multiple times.
1as of June 2020
2popular judged by a high count of forks, commits, developers, or starsGHTorrent
(offline mirror of
GitHubRESTAPI)Originaland
collaborative
projects
Relevant
projects
forRQSelected
projects
forRQI II
III IVfilteraccordingto [11]
RQ-based
filtering
select projects, e.g., with
randomsampling[18]GitHub
git2net +
gambit+
measure
computation
Figure 1: Pipeline to select and sample collaborative soft-
ware development projects from GitHubto address a given
research question (RQ).
Afterapplyingthesetwoadditionalfilteringsteps,weretainalist
of around 1.8 million original and collaborative repositories, which
is only 1.4% of all repositories in GHTorrent . This underlines the
importance of proper data selection when analysing collaborative
software development on GitHub.
2.2 Population validity
Besidesprojectsthatareoriginalandcollaborative,ourstudyon
team productivity requires projects that fulfil additional conditions
regarding their (i) activity, (ii) size, and (iii) purpose, i.e., collabora-
tive projects for developing software (step 3 in Figure 1).
Project activity. To avoid issues that could arise from mixing
activeprojectswiththosewheredevelopmenthascededlonginthepast,wefocusonprojectsthatareactivelydevelopedatthetimeofourstudy.Weregardaprojectasactiveifthelastcommitwasmade
after May 2020. To ensure this, we take a two-fold approach: we
firstselectprojectsfrom GHTorrent thathavearecordedcommit
activity after May 2019. In a subsequent step, we then use theGitHubRESTAPItofilterthoseprojectsthatadditionallyhavea
recorded commit after May 2020.
Project size. To facilitate an unbiased sampling of projects based
on team size, we first need to determine the size of a development
team.ForOSSprojectswithoutformalteammemberships,thisis
a challenging task. The authors of [ 3] found that the probability
of making future contributions to an OSS project drops below 10%
afteraninactivityofapprox.42weeks.Basedonthisfinding,we
264ICSEâ€™22,May21â€“29,2022,Pittsburgh,PA, USA Gote, et al.
Table 1: Number of projects with different team size ranges.
All given team size ranges include the outer values. Team
sizesarecomputedbasedonthedataavailablein GHTorrent.
Team
SizeProjects
Tot. Sel.
2 â€“ 4 95,763 19
5 â€“ 8 33,027 27
9 â€“ 15 17,221 26
16 â€“ 30 10,027 2731 â€“ 58 3,499 27Team
SizeProjects
Tot. Sel.
59 â€“ 115 1,476 25
116 â€“ 226 665 16227 â€“ 443 231 13
444 â€“ 871 102 15
872 â€“ 1,711 28 6
computethesizeofanOSSdevelopmentteamattime ğ‘¡bycounting
all developers who committed within a moving time window of
294 days, i.e., between ğ‘¡âˆ’294 days and ğ‘¡. Thus, to compute a team
size, projects need to have existed for at least 294 days, increasing
therequirementsbeyondthe100daysconsideredbytheauthorsof
[11].
Table 1 shows the number of projects for different team sizes,
whereteamsizeiscomputedforthelatestavailable294-daytime
window. The project counts are reported for ten log2-spaced strata,
which yields a distribution where the team size roughly doubles
for each consecutive stratum. The resulting distribution is right-
skewed, where the vast majority of projects have small team sizes.
A uniform sample from the complete set of projects would thus
primarilyselectsmallprojects,whichwouldfailtocoverabroad
spectrumofteamsizes.Toremedythis,wesample28projectsfrom
eachstratum,where28isthesizeofthestratumwiththefewest
projects.
While sampling, we ensure that all sampled projects are soft-
waredevelopmentprojectsandcontinuetobe activelydeveloped
at the time of mining. We further remove duplicate projects that
originatefrommanualclonesofotherrepositories.Weachievethis
by applying the following selection criteria:
Project purpose. To identify a projectâ€™s purpose, we query the
GitHubREST API to obtain the most recent information on all
consideredprojects.Wefirstensurethatallsampledprojectsare
softwaredevelopmentprojectsandcontinuetobeactivelydevel-
oped at the time of mining. We consider a project as a software
development project if at least 75% of the code in the repository is
writteninthe17programminglanguagessupportedbythecode
analysis tool lizard[19]. In total, the languages supported by
lizardaccount for over 85% of the code submitted to GitHub[20].
Deduplication. Finally, our set of projects still contains duplicate
repositoriesthatoriginatefrommanualclonespushedtoadifferent
repository rather than using the fork mechanic recorded in the
GHTorrent data. Removing these clones is an important challenge
when selecting repositories for analysis, and independent data sets
listing duplicate repositories have been developed [ 21]. Unfortu-
nately, these data sets were not yet available at the time of our
analysis.Therefore,wemanuallyremovedtheclones,retainingthe
originalproject that was cloned.
Thetwo selection criteria require us to query the GitHubREST
API or perform manual filtering, respectively. Due to the APIâ€™sratelimit,thismeansthatneithercanbeperformedatlargescale
beforesamplingprojects.Instead,theyneedtobeperformedduring
the sampling process. We treat all strata equally and apply the
additionalselectioncriteriatothesampled28projectsfromeach
stratum.AsshowninthefinalcolumnofTable1,thisyieldsbetween
6 and 27 projects for each of the ten strata, resulting in a total of
201 projects with a total of more than 100,000 developers and over
3 million commits (step 4 in Figure 1). Overall, we obtain relatively
similarprojectcountsforallstrata,exceptforthestratawithlargest
andsmallestteamsizes.
2.3 Mining co-editing networks from git
repositories
Weminealleditsandco-editsforthefullhistoryofthe201projects
usingtheOpenSourcePythontool git2net[16].Besidesco-editing
relations,wealsoextractbothcommit-andcode-basedproductivity
measures. To this end, we apply lizard[19] and an optimised ver-
sion of multimetric [22] to the source code before and after each
change.Obtaininghighlygranularinformationonthedevelopment
processofover200OSSprojectsrequiressubstantialcomputational
resources, in our case, over 1 million CPU-hours. Therefore, we
performallcomputationson256computecoreswithinatimeframe
of over six months on the ETH Zurich scientific compute cluster
Euler.
An additional challenge in the analysis of gitrepositories is
theneedtodisambiguatecommitauthors.Thisstepisnecessary
asdeveloperscanmakecontributionsusingdifferentcredentials,
e.g.,duetospellingerrorsinusernamesortheuseofnicknames.Considering different aliases as different users would lead us to
overestimatetheteamsizeandunderestimatetheproductivityof
developerswithmultiplealiases.Wethususetherecentlyproposed
toolgambit[13]to disambiguate all developers in all repositories.
Uponmanualinspection,wefoundthatsomeprojectscontain
very large commits originating from code imports or automated
code refactoring tools. Such, mostly automated, commits are notrepresentative for the coordination requirements between devel-opers. However, due to their size, they could lead to a bias oursubsequent analysis. Therefore, as a final data cleaning step, we
drop outliers by excluding all commits outside the 2 .5th and 97 .5th
percentile regarding their total Levenshtein distance.
A complete list of projects as well as anonymised raw data of all
projects considered in our analysis is archived on zenodo.org3.
3 OPERATIONALISING PRODUCTIVITY AND
COLLABORATION STRUCTURE
To study how team size affects the productivity of OSS projects,
we need to operationalise (i) the size of OSS teams, and (ii) the
productivity of OSS teams. In addition, we aim to understand how
coordination between different team members affects this relation.
Therefore, we need to also operationalise (iii) the collaboration
structure of OSS teams.
We base our operationalisations of all three concepts on the
editsandco-editsobservedwithinnon-overlapping42-weektime
windows. As discussed in Section 2.2, the choice of 42 weeks is
3https://doi.org/10.5281/zenodo.5294964
265BigData= Big Insights? Operationalising Brooksâ€™ Law in a Massive GitHub Data Set ICSEâ€™22, May21â€“29,2022,Pittsburgh,PA, USA
Table2:Productivitymeasuresconsideredinthispaper.All
measuresareevaluatedoveratimewindowoflength Î”ğ‘¡and
normalised by the team size (TS).
Commit-
BasedComms commits /Î”ğ‘¡/TS
Events linesadded, modified, or deleted /Î”ğ‘¡/TS
LevD charactersmodified /Î”ğ‘¡/TSCode-
BasedNLOC lines of code changed /Î”ğ‘¡/TS
Tokens changein number of tokens /Î”ğ‘¡/TS
Funcs changein the number of functions /Î”ğ‘¡/TS
CycC changein cyclomatic complexity /Î”ğ‘¡/TS
HalEff Halsteadeffortto make changes /Î”ğ‘¡/TS
motivated by [ 3] who found that after this time, the probability of
a developer making future contributions to a project is less than
10%. Ensuring that the time window is divisible by full weeks is
essentialtoensurethattheweeklyproductivitypatternspresent
onGitHub[23]do not bias our results.
In the next three sections, we will discuss each of the opera-
tionalisationsin detail.
3.1 Team size
OSSprojectsutilisetheprinciplesofopencollaborationtocreate
newsoftware.Thismeansthattheyrelyoncontributionsofloosely
coordinated participants, who differ significantly regarding the
size of their contributions. Contributors can further join and leave
the team at any time. Due to this method of collaboration, no
organised ledgers listing the members of OSS teams exist. This
makesoperationalising the size of such teams non-trivial.
Theconsensusofpriorliteratureisthatallindividualscontribut-
ing to an OSS project should be considered as team members [ 24].
Withthiswork,westudytheproductionofcodeartefacts.There-
fore, we operationalise team size as the count of all individuals
who contribute code to a project within a given time window. This
includesalldevelopersadding,modifying,orremovingcodefrom
theprojectâ€™s codebase.
3.2 Productivity measures
Before discussing how we operationalise team productivity, we
needtopreciselydefinethisterm.Productivitycapturesoneaspectofthebroaderconceptof teameffectiveness.Here,teameffectiveness
is defined as (i) the productive output of the work group, (ii) the
effectivenessof processesto maintaintheteamâ€™s capabilityinthe
future, and (iii) the satisfaction of group memberâ€™s personal needs
[25, p. 323]. With our study on team productivity, we focus on the
firstaspect.Specifically,weassesstheinput-outputrelationconsid-
ering the size of the code changes made by an OSS development
teamas a function of the teamâ€™s size.
Tooperationaliseteamproductivity,weneedtodefinemeasures
thatallowustocapturethesizeofachangeinaprojectâ€™scodebase.
For this, many different measures have been proposed in the litera-
ture. Addressing construct validity, we consider eight productivity
measures and investigate the extent to which they provide inde-
pendentinformationontheconstructofproductivity.Wefurther
carefullyinvestigateand assesshow these measures interrelate.We categorise our eight productivity measures as commit- or
code-basedmeasures[ 26].Commit-basedmetricsrelysolelyonthe
sizeofthechangeswithinarepository,e.g.,thenumberofcommits,
thenumberofchangedlines,orthenumberofmodifiedcharacters.
Commit-basedproductivitymeasuresrequirelowcomputational
effort and are independent of the programming language used in a
repository. However, by not assessing the content of a repositoryâ€™s
code, they do not allow us to distinguish, e.g., between lines of
codeorcommentsthatareadded.Therefore,wealsoconsidercode-based measures that take these aspects into account. These include
measuresbasedonthenumberofmodifiedlinesofcode(NLOC),
thenumberofcodetokensorfunctions,changesinMcCabeâ€™scy-
clomatic complexity [ 27], or the Halstead effort [ 28]. We provide a
complete overview of the productivity measures considered in our
studyinTable2.Wecomputeproductivityforeachtimewindow
andnormalisetheproductivity by the respective team size (TS).
To illustrate how different productivity measures can introduce
the challenge of construct validity, consider the exemplary Python
code shown in Figure 2. We start with version one of a file that
containsthreelinesoftextwithatotalof53characters(whitespaces
included).Creatingthisfilefromscratchwouldrequirethree line
modification events, i.e. three line-additions where lines 1 and 3
contain actual code, and line 2 contains a comment. Therefore, the
number of line modification events is three, while the lines of code
(NLOC)istwo.Intheexample,wehavehighlightedallcodetokens.
To compute the Halstead effort, we need to distinguish between
tokensthatareoperandsandoperators.Thesearehighlightedin
blueandred,respectively,whereasallothertokensareprintedin
purple.Intotal,wehave12tokens.With aandb,thecodecontains
ğœ‚2=2 distinct operands that appear a total of ğ‘2=4 times. We
further have ğ‘1=6 operators that are all different from each
other (i.e. ğœ‚1=6). The Halstead effort to create this file is thus
defined as ğ¸=(ğ‘1+ğ‘2)Â·log2(ğœ‚1+ğœ‚2)Â·ğœ‚1
2Â·ğ‘2
ğœ‚2=180. Finally,
the file only has one function without any branches resulting in
Functions =CycC =1.
Withthefirstmodification,weaddasecondfunctionimplement-
ing the multiplication of two values. The bottom-left green box in
Figure 2 shows the productivity of this change. The code-based
productivity measures are computed as the productivity difference
tocreatethetwoconsecutiveversionsofthefile.Forthecommit-
basedmeasures,thecontentsofthetwofilesarecompareddirectly.
Withthesecondmodification,wemergethetwofunctionsintoone.
Despitetheincreaseincharacters,thetokenandfunctioncounts
and the Halstead effort of version three are lower than those of
version two. If measures such as the number of functions or the
cyclomatic complexity were to only increase, this would make the
code difficult to maintain and prone to bugs [ 29,30]. Therefore, we
also consider contributions reducing code complexity, e.g., by con-
solidating functions or refactoring code, as productive. We achieve
thisbycomputingtheproductivityofamodificationastheabsolute
valueoftheproductivityvaluestocreatetheversionsbeforeand
aftertheobserved change.
Thissimpleexampleshowsthatoureightproductivitymeasures
can yield considerably different results. This prompts the question
ofwhichmeasureweshoulduseasatargetvariablethatweseek
to explain through the set of features identified above.
266ICSEâ€™22,May21â€“29,2022,Pittsburgh,PA, USA Gote, et al.
R,/27//npHbU- #V,
k,O //b irQ pHm2b
j,`2im`MY#R,/27//npHbU- #V,
k,`2im`MY#
j,
9,/27KmHiBTHvnpHbU- #V,
8,`2b4y
e,7Q`BBM`M;2U#V,
d,`2b4 //npHbU`2b- V
3,`2im`M`2bR,/27+QK#npHbU- #-KV,
k,B7K44^//^,
j,`2im`MY#
9,2HB7K44^KmHiBTHv^,
8,`2im`M #
e,2Hb2,
d,`Bb21t+2TiBQMUV1p2Mib, j
G2p., 8j
LGP*, k
hQF2Mb, Rk
6mM+iBQMb, R
*v+*, R
>H1z, R3y1p2Mib, d
G2p., Rjk
LGP*, d
hQF2Mb, 9R
6mM+iBQMb, k
*v+*, j
>H1z, R-93R1p2Mib, d
G2p., Rk9
LGP*, d
hQF2Mb, j9
6mM+iBQMb, R
*v+*, j
>H1z, R-kRy
*QKKBi R *QKKBi k
*QKKBib, R G2p., Ny hQF2Mb, kN *v+*, k
1p2Mib, e LGP*, 8 6mM+iBQMb, R >H1z, R-jyR*QKKBib, R G2p., N8 hQF2Mb, d *v+*, y
1p2Mib, 3 LGP*, y 6mM+iBQMb, R >H1z, kdRo2`bBQM R o2`bBQM k o2`bBQM j
Figure2:ProductivitymeasuresappliedtothreeconsecutiveversionsofanexemplaryPythonfile.Inthegreyboxes,wereport
the productivity associated with creating each version of the file from scratch. In the green boxes, we show the productivity
related to the changes observed between the versions. We assume that each new version was created in a single commit. All
tokens are highlighted. Tokens that are operands and operators are printed in blue and red, respectively. All other tokensare printed in purple. Individual functions are indicated by yellow bars. For the computations in the example, we assume
Î”ğ‘¡=TS=1.
We address this question in an exploratory study analysing the
201OSSrepositoriesinourcorpus.Forthis,wesplittime-seriesdata
into non-overlapping 42-week time windows. We then compute
ourproductivitymeasuresanddropalltimewindowsinwhicha
teamwasinactive,i.e.,forwhichweobserveaproductivityofzero,yieldingatotalof1,188observations.Wefindthatthedistributions
of all productivity measures are highly skewed. Therefore, we log-
transformallskewedmeasuressuchthattheresultingdistributions
resemble a normal distribution.
Figure3ashowsthePearsoncorrelationbetweenallproductivity
measures. Wefind valueslarger than0.9 betweenall productivity
measures except for the number of commits and Halstead effort.
This suggests that the change in both characters and tokens is
similartothechangeinlines.Wefurtherfindthatthenumberof
functionsandcyclomaticcomplexityarepositivelycorrelated,bothchangingwiththenumberoflines.Withvaluesbetween0.7and0.8,
correlationsareconsiderablysmallerforthe number ofcommits
andHalsteadeffort.Thisindicatesthatcommitsdifferconsiderably
in terms of their size, i.e., with regard to the number of characters,
lines,tokensorfunctionsmodifiedwiththecommit.Halsteadeffort
isuniqueamongtheconsideredproductivitymeasuresas,nextto
thetotalamountofcode,italsoconsidersthesizeofthevocabulary
used.Therefore,slowervocabularygrowthcomparedtothetotal
amountofcodecouldexplaintheobservedsmallercorrelationwith
othermeasures.
In conclusion, all considered productivity measures have differ-
ent motivations. Some analyse the source code at various levelsof detail while others aggregate information at the level of linesor commits. Despite those differences and the strong differencesshown in the example in Figure 2, in our corpus of projects, and
when computing average developer productivities across teams, all
productivity measures are highly correlated.
3.3 Collaborationnetworks of OSS teams
Addressing the challenges of omitted-variable bias, we explore how
the collaborationstructure of teams might modulate team produc-
tivity. In this way, we capture team characteristics beyond mereteam size, highlighting additional variables that we need to control
for when studying Brooksâ€™ law in rich data. The inclusion of addi-
tionalmeasurescapturingcollaborationstructurewasmotivatedby
[3],whichfoundthat ateamâ€™snetworkstructureaffectsthe slope
oftherelationintheirdata.Therefore,forthiswork,weconsider
network-based measures that fit this prior work. In addition, we
also includesoftware-engineering-specific measures.
Specifically, to capture characteristics of different aspects of the
collaborationstructuresofdevelopmentteams,weusemeasures
thatwecomputeontheco-editingnetworkconstructedforournon-
overlapping42-weektimewindows.Intheseco-editingnetworks,
nodes represent different developers and edges ğ´â†’ğµrepresent
eventswheredeveloper ğµmodifiesalineofcodelasteditedby ğ´.
The direction of the edge indicates the change of line ownership
fromğ´toğµ.Multipleco-editingeventsbetweentwodevelopersare
representedasmulti-edgesbetweennodes.Developerseditingtheir
owncodearecapturedasself-loops.Inthefollowing,wepresent
eight measures that can be used as control variables to explain
therelationbetweenteamproductivityandteamsize.Forformal
definitions,we refer to [31].
Number of nodes (N). The number of nodes in the co-editing
networkcountsalldevelopersthatactivelyeditedcodeorwhose
code was edited. The number of nodes is always greater than or
equal to the team size.
Number of edges (Edges). The number of edges counts the co-
editing events within a time window.
Density (Dens). The density captures the proportion of potential
edgespresentinanetwork.Wecomputethedensitybasedonthe
flattened network, in which multi-edges between two nodes are
substituted by a single edge.
Diameter(Diam). Thenetworkâ€™sdiameterisgivenbythelength
of the longest shortest path between any pair of nodes.
ClusteringCoefficient(ClustC). Anodeâ€™slocalclusteringcoeffi-
cient is computed as the fraction of pairs of neighbours that are
267BigData= Big Insights? Operationalising Brooksâ€™ Law in a Massive GitHub Data Set ICSEâ€™22, May21â€“29,2022,Pittsburgh,PA, USA
âˆ’1âˆ’0.8âˆ’0.6âˆ’0.4âˆ’0.200.20.40.60.81Events (log)
NLOC (log) LevD (log) Tokens (log)
CycC (log) Funcs (log) Comms (log)
HalEff (log)
Events (log)
NLOC (log)
LevD (log)
Tokens (log)
CycC (log)
Funcs (log)
Comms (log)
HalEff (log)1
0.98
0.98
0.97
0.950.91
0.81
0.770.98
1
0.98
0.98
0.960.92
0.79
0.740.98
0.98
1
0.98
0.940.89
0.78
0.750.97
0.98
0.98
1
0.95
0.9
0.770.760.95
0.96
0.94
0.95
1
0.95
0.78
0.760.91
0.92
0.89
0.9
0.95
1
0.740.670.81
0.79
0.78
0.77
0.780.74
1
0.670.77
0.74
0.75
0.76
0.760.67
0.67
1
âˆ’1âˆ’0.8âˆ’0.6âˆ’0.4âˆ’0.200.20.40.60.81TS (log) N (log) Diam Dens (log) ClustC InD (log) EigG (sqrt) FModR
TS (log)
N (log)
Diam
Dens (log)
ClustC
InD (log)
EigG (sqrt)
FModR
âˆ’1âˆ’0.8âˆ’0.6âˆ’0.4âˆ’0.200.20.40.60.81Events (log) NLOC (log) LevD (log) Tokens (log) CycC (log) Funcs (log) Comms (log) HalEff (log)
TS (log)
N (log)
Diam
Dens (log)
ClustC
InD (log)
EigG (sqrt)
FModRAB C
Figure 3: Results of exploratory study on team productivity and collaboration structure. a) Pearson correlation between the
transformedproductivitymeasures.b)Pearsoncorrelationbetweenthetransformednetworkmeasures.Clustersbetweenthemeasures are marked. c) Cross-correlation (Pearson) between the transformed network and productivity measures.
connected by an edge. The global clustering coefficient is obtained
astheaveragelocalclusteringcoefficientacrossallnodesinthenet-
work.Networkswithsmalldiameterandlargeclusteringcoefficient
exhibittheso-calledsmall-worldproperty.Linksthatconnectdiffer-
ent clusters in a network lead to low diameters, even for networks
withmanynodes.Thesmall-worldpropertyisdirectlyrelatedto
navigability, knowledge transfer and social capital within social
networks[32,33].
Mean Indegree (InD). In the flattened co-editing network, the
indegreeofanode ğ‘–indicatesthenumberofdeveloperswhosecode
hasbeen edited by ğ‘–.
Mean Foreign Modification Ratio (FModR). A recent work shows
thatthe productivityof developersissignificantly reducedif they
editcodeownedbyotherdeveloperscomparedtoeditingtheirown
code[4].Weaccountforthisusingtheforeignmodificationratio,
which we compute as the fraction of all co-editing events where
thedevelopereditscodeownedbyanotherdeveloper.Weobtain
the numberof allco-edits of adeveloper ğ‘–asğ‘–â€™s indegree,and the
number of co-edits where ğ‘–edit foreign code as the count of all
edges toğ‘–that are not self-loops. The mean foreign modification
ratiooftheteamisobtainedasthemeanforeignmodificationratio
of all team members.
Eigengap(EigG). Finally,theeigengap,alsoreferredtoasspectral
gap,ofanetworkcapturestheefficiencyofdynamicalprocesseson
thenetwork.Networkswithlargereigengapssupportfastspread-
ing, diffusion and synchronisation, which can be interpreted asa proxy for the efficiency of information exchange and consen-
susschemes.Wecomputetheeigengapforthelargestconnected
componentof the network.
The definitions above enable us to capture the collaboration
structure of software development teams in a multi-dimensional
featurespace.Similartotheproductivitymeasures,wefindthatthe
distributions of some network measures are highly skewed. There-
fore, we again apply logarithmic or square-root transformations.
We report the applied transformation for all measures throughout
theremainder of this manuscript.We next aim to select a minimum set of features that capture
independent dimensions of collaboration networks. For this, westudy pair-wise correlations between all features, identify clus-ters of highly correlated features, and select one representative
featurepercluster.Whilewecouldinsteadusedimensionalityre-
ductiontechniqueslikeprincipalcomponentanalysis,ourapproach
provides the advantage that it allows us to analyse interpretable
network features rather than principal components.
Figure 3b shows the Pearson correlation between all pairs of
network measures. A first visible cluster in the upper-left quadrantcontainsteamsize,thenumberofnodes,andthenetworkdiameter,
whichallshowastrongpositivecorrelation.Inaddition,network
densityisstronglynegativelycorrelatedwithallthree.Thus,therel-ativenumberofco-editinginteractionsgoesdownforlargerteams,
leading to the distance between the two furthest team members
in the co-editing network to increase. The second cluster contains
clusteringcoefficient,meanindegree,andeigengap,whichareall
positivelycorrelated.Thus,inteamswhereeveryoneinteractswith
many different team members we obtain a network structure in
whichinformationcanspreadmorequicklythroughouttheteam.
Thethirdclustercontainsonlythemeanforeignmodificationratio,
whichquantifieshowmuchotherdevelopersâ€™codeiseditedwithin
the team. For all downstream analyses, we select team size (TS),mean indegree (InD) and the foreign modification ratio (FModR)from the set of network measures, i.e., we use one measure from
eachcluster.
We finally consider cross-correlations between the network and
productivity measures shown in Figure 3c. The results of this anal-
ysis confirm that all productivity measures exhibit very similar
correlationsto the network metrics.
Overall,withtheresultsfromourcorrelationstudies,weconfirm
andextendthepriorfindingsontherelationsbetweensocialnet-
work measures for OSS projects [ 34,35] and the relations between
classical source code metrics [ 36â€“39] for a broader set of measures
andinournovelandsignificantlymoreextensivecorpusofprojects
designed to study the productivity of OSS development teams.
268ICSEâ€™22,May21â€“29,2022,Pittsburgh,PA, USA Gote, et al.
4 TESTING BROOKSâ€™ LAW IN MASSIVE
GITHUB DATA
Wenowaddresstheongoingscientificdiscourseontherelationship
between team size and productivity [ 7,8,40]. For this, we apply
linear and polynomial regression models to different productivity
target variables, where we additionally use the network metrics
identified in section Section 3.3 as control variables.
Figure4ashowstheproductivityperteammemberasafunction
ofteamsize,exemplifiedforaproductivitymeasurebasedoncy-
clomatic complexity. We fit a linear ( CycCâˆ¼TS) and a polynomial
modelwithmaximumdegreetwo( CycCâˆ¼TS+TS2)toourdata.
Thelinearmodelenablesustoinferapossiblerelationshipbetween
teamsizeandproductivity.Themodel CycCâˆ¼TS+TS2isthebasis
to test for the existence of an optimal team size, which is captured
by the existence of a global maximum of the quadratic function.
The linear model yields a significant negative relationship be-
tween TS and productivity, as reported in Table 3a. Similarly, as
showninTable3b,wefindasignificantnegativecoefficientforTS2
for the quadratic model. This means that, on average, individual
productivity decreases with team size.
That said, all coefficients for TS in the quadratic models are
positive,andthecoefficientsforCycCandHalEffarealsosignifi-
cant. This means that these models can be represented as inverted
parabolas, e.g., as shown by the red curve for CycC in Figure 4a.
The maxima of the parabolas for CycC and HalEff provide some
evidence for an optimal team size of 7 or 19 team members, re-
spectively,whichisroughlyinlinewiththeoptimalteamsizeof
9 suggested by [ 41]. However, we argue that the key insight of
this result is not the exactteam size for which the maximum is
reached,whichislikelyanartefactofthesimplifiedmodelusedfor
ouranalysis.Instead,thekeyinsightisthepossibleincreaseinindi-
vidualproductivityforverysmallteamsâ€”comparedtotheanalysed
range from 2 to 1,711 membersâ€”with decreases thereafter. Due to
the large amount of remaining variance and the small slope of the
parabolaaroundthemaximum,interpretingaspecificnumberas
optimalteamsizeislikelytobemisleading.Wefurthernotethat
fortheregression analyses using theremaining productivity mea-
suresastargetvariables,thecoefficientforteamsizeisinsignificant.
Hence, despite the coefficients being consistently positive, these
models do not provide sufficient statistical evidence to conclude an
increaseinindividualproductivityeveninsmallteams,resulting
in an overall negative relation between productivity and team size.
Importantly, the models considered so far only partially explain
the variance in the relationship between productivity and teamsize. This can be seen from the low
ğ‘…2values of less than 15%
in Table 3a and b. Moreover, Figure 4a shows that, especially forsmall teams, the productivity of team members varies over four
decades. This suggests that additional aspects other than team size
have a substantial influence on the productivity of developers. We
thusconsiderregressionmodels that additionallycontrol for the
networkfeatures identifiedin Section 3.3. Specifically, we addthe
meannumberofinteractionpartnersperteammember(InD)and
theaverageamountofeditedforeigncode(FModR)asadditional
variablesin our regression models.
As shown by the ğ‘…2values in Table 3c, the regression models
thatincludeInDandFModRexplainclosetohalfofthevarianceTable3:Regressionmodelsrelatingteamsize(TS)tofivepro-
ductivity measures. The results are based on 1,188 observa-tions.Allproductivitymeasuresarelog-transformed.Allco-efficients are Bonferroni-corrected for multiple hypothesestesting.
a) Linear relationship
Comms Events LevD CycC NLOC Tokens Funcs HalEff
(IC) 3.38âˆ—âˆ—âˆ—7.75âˆ—âˆ—âˆ—11.24âˆ—âˆ—âˆ—5.22âˆ—âˆ—âˆ—6.99âˆ—âˆ—âˆ—9.02âˆ—âˆ—âˆ—4.22âˆ—âˆ—âˆ—15.82âˆ—âˆ—âˆ—
(0.08)(0.10)(0.10)(0.11)(0.10)(0.11)(0.11)(0.16)
TS (log) âˆ’0.20âˆ—âˆ—âˆ—âˆ’0.31âˆ—âˆ—âˆ—âˆ’0.33âˆ—âˆ—âˆ—âˆ’0.31âˆ—âˆ—âˆ—âˆ’0.31âˆ—âˆ—âˆ—âˆ’0.34âˆ—âˆ—âˆ—âˆ’0.29âˆ—âˆ—âˆ—âˆ’0.22âˆ—âˆ—âˆ—
(0.02)(0.03)(0.03)(0.03)(0.03)(0.03)(0.03)(0.04)
R20.07 0 .10 0.11 0.09 0.10 0 .11 0.08 0.02
Adj. R20.07 0 .10 0.11 0.09 0.10 0 .11 0.08 0.02
b) Quadratic relationship
Comms Events LevD CycC NLOC Tokens Funcs HalEff
(IC) 3.02âˆ—âˆ—âˆ—7.06âˆ—âˆ—âˆ—10.55âˆ—âˆ—âˆ—4.18âˆ—âˆ—âˆ—6.23âˆ—âˆ—âˆ—8.11âˆ—âˆ—âˆ—3.31âˆ—âˆ—âˆ—14.10âˆ—âˆ—âˆ—
(0.17)(0.22)(0.22)(0.23)(0.21)(0.22)(0.23)(0.34)
TS (log) 0.02 0 .12 0.10 0.35âˆ—0.17 0 .24 0.28 0.86âˆ—âˆ—âˆ—
(0.10)(0.12)(0.13)(0.13)(0.12)(0.13)(0.13)(0.19)
TS2(log)âˆ’0.03âˆ—âˆ’0.06âˆ—âˆ—âˆ—âˆ’0.06âˆ—âˆ—âˆ—âˆ’0.09âˆ—âˆ—âˆ—âˆ’0.06âˆ—âˆ—âˆ—âˆ’0.08âˆ—âˆ—âˆ—âˆ’0.08âˆ—âˆ—âˆ—âˆ’0.15âˆ—âˆ—âˆ—
(0.01)(0.02)(0.02)(0.02)(0.02)(0.02)(0.02)(0.03)
R20.08 0 .11 0.12 0.11 0.11 0 .13 0.10 0.05
Adj. R20.07 0 .11 0.12 0.11 0.11 0 .12 0.10 0.05
c) Linear relationship controlling for network properties
Comms Events LevD CycC NLOC Tokens Funcs HalEff
(IC) 3.18âˆ—âˆ—âˆ—7.62âˆ—âˆ—âˆ—11.10âˆ—âˆ—âˆ—5.22âˆ—âˆ—âˆ—6.95âˆ—âˆ—âˆ—8.93âˆ—âˆ—âˆ—4.25âˆ—âˆ—âˆ—15.78âˆ—âˆ—âˆ—
(0.08)(0.09)(0.10)(0.10)(0.09)(0.10)(0.10)(0.16)
TS (log) âˆ’0.36âˆ—âˆ—âˆ—âˆ’0.49âˆ—âˆ—âˆ—âˆ’0.51âˆ—âˆ—âˆ—âˆ’0.48âˆ—âˆ—âˆ—âˆ’0.48âˆ—âˆ—âˆ—âˆ’0.52âˆ—âˆ—âˆ—âˆ’0.45âˆ—âˆ—âˆ—âˆ’0.45âˆ—âˆ—âˆ—
(0.02)(0.02)(0.02)(0.02)(0.02)(0.02)(0.03)(0.04)
InD(log) 1.16âˆ—âˆ—âˆ—1.45âˆ—âˆ—âˆ—1.44âˆ—âˆ—âˆ—1.46âˆ—âˆ—âˆ—1.42âˆ—âˆ—âˆ—1.49âˆ—âˆ—âˆ—1.35âˆ—âˆ—âˆ—1.90âˆ—âˆ—âˆ—
(0.04)(0.05)(0.06)(0.06)(0.05)(0.06)(0.06)(0.09)
FModR âˆ’1.00âˆ—âˆ—âˆ—âˆ’1.90âˆ—âˆ—âˆ—âˆ’1.83âˆ—âˆ—âˆ—âˆ’2.65âˆ—âˆ—âˆ—âˆ’2.33âˆ—âˆ—âˆ—âˆ’2.19âˆ—âˆ—âˆ—âˆ’2.65âˆ—âˆ—âˆ—âˆ’3.26âˆ—âˆ—âˆ—
(0.22)(0.27)(0.28)(0.30)(0.27)(0.28)(0.30)(0.46)
R20.45 0 .49 0.47 0.46 0.49 0 .49 0.42 0.33
Adj. R20.45 0 .49 0.46 0.46 0.49 0 .49 0.42 0.33
d) Quadratic relationship controlling for network properties
Comms Events LevD CycC NLOC Tokens Funcs HalEff
(IC) 3.53âˆ—âˆ—âˆ—7.83âˆ—âˆ—âˆ—11.30âˆ—âˆ—âˆ—5.10âˆ—âˆ—âˆ—7.08âˆ—âˆ—âˆ—8.95âˆ—âˆ—âˆ—4.22âˆ—âˆ—âˆ—15.25âˆ—âˆ—âˆ—
(0.14)(0.17)(0.18)(0.19)(0.17)(0.18)(0.19)(0.30)
TS (log) âˆ’0.58âˆ—âˆ—âˆ—âˆ’0.63âˆ—âˆ—âˆ—âˆ’0.64âˆ—âˆ—âˆ—âˆ’0.41âˆ—âˆ—âˆ—âˆ’0.56âˆ—âˆ—âˆ—âˆ’0.53âˆ—âˆ—âˆ—âˆ’0.42âˆ—âˆ—âˆ—âˆ’0.10
(0.08)(0.10)(0.10)(0.11)(0.10)(0.10)(0.11)(0.17)
TS2(log)0.03âˆ—0.02 0.02âˆ’0.01 0.01 0 .00âˆ’0.00âˆ’0.05
(0.01)(0.01)(0.01)(0.01)(0.01)(0.01)(0.01)(0.02)
InD (log) 1.18âˆ—âˆ—âˆ—1.46âˆ—âˆ—âˆ—1.45âˆ—âˆ—âˆ—1.45âˆ—âˆ—âˆ—1.43âˆ—âˆ—âˆ—1.49âˆ—âˆ—âˆ—1.35âˆ—âˆ—âˆ—1.87âˆ—âˆ—âˆ—
(0.04)(0.05)(0.06)(0.06)(0.05)(0.06)(0.06)(0.09)
FModR âˆ’1.04âˆ—âˆ—âˆ—âˆ’1.93âˆ—âˆ—âˆ—âˆ’1.85âˆ—âˆ—âˆ—âˆ’2.64âˆ—âˆ—âˆ—âˆ’2.34âˆ—âˆ—âˆ—âˆ’2.19âˆ—âˆ—âˆ—âˆ’2.65âˆ—âˆ—âˆ—âˆ’3.20âˆ—âˆ—âˆ—
(0.22)(0.27)(0.28)(0.30)(0.27)(0.28)(0.30)(0.46)
R20.45 0 .49 0.47 0.46 0.49 0 .49 0.42 0.34
Adj. R20.45 0 .49 0.46 0.46 0.49 0 .49 0.42 0.33
e) Linear relationship with controls and interaction effects
Comms Events LevD CycC NLOC Tokens Funcs HalEff
(IC) 2.72âˆ—âˆ—âˆ—7.39âˆ—âˆ—âˆ—10.85âˆ—âˆ—âˆ—5.01âˆ—âˆ—âˆ—6.68âˆ—âˆ—âˆ—8.68âˆ—âˆ—âˆ—4.06âˆ—âˆ—âˆ—15.91âˆ—âˆ—âˆ—
(0.11)(0.14)(0.14)(0.15)(0.13)(0.14)(0.15)(0.23)
TS (log) âˆ’0.22âˆ—âˆ—âˆ—âˆ’0.43âˆ—âˆ—âˆ—âˆ’0.44âˆ—âˆ—âˆ—âˆ’0.42âˆ—âˆ—âˆ—âˆ’0.40âˆ—âˆ—âˆ—âˆ’0.45âˆ—âˆ—âˆ—âˆ’0.39âˆ—âˆ—âˆ—âˆ’0.48âˆ—âˆ—âˆ—
(0.03)(0.04)(0.04)(0.04)(0.04)(0.04)(0.04)(0.06)
InD (log) 1.83âˆ—âˆ—âˆ—1.78âˆ—âˆ—âˆ—1.80âˆ—âˆ—âˆ—1.76âˆ—âˆ—âˆ—1.80âˆ—âˆ—âˆ—1.86âˆ—âˆ—âˆ—1.62âˆ—âˆ—âˆ—1.72âˆ—âˆ—âˆ—
(0.12)(0.15)(0.16)(0.17)(0.15)(0.16)(0.17)(0.26)
TSÃ—InDâˆ’0.18âˆ—âˆ—âˆ—âˆ’0.09âˆ’0.10âˆ’0.08âˆ’0.10âˆ—âˆ’0.10âˆ’0.07 0.05
(0.03)(0.04)(0.04)(0.04)(0.04)(0.04)(0.04)(0.07)
FModR âˆ’0.92âˆ—âˆ—âˆ—âˆ’1.87âˆ—âˆ—âˆ—âˆ’1.79âˆ—âˆ—âˆ—âˆ’2.62âˆ—âˆ—âˆ—âˆ’2.29âˆ—âˆ—âˆ—âˆ’2.15âˆ—âˆ—âˆ—âˆ’2.62âˆ—âˆ—âˆ—âˆ’3.28âˆ—âˆ—âˆ—
(0.22)(0.27)(0.28)(0.30)(0.27)(0.28)(0.30)(0.46)
R20.47 0 .49 0.47 0.46 0.50 0 .49 0.43 0.34
Adj. R20.46 0 .49 0.47 0.46 0.49 0 .49 0.42 0.33
âˆ—âˆ—âˆ—ğ‘<0.001;âˆ—âˆ—ğ‘<0.01;âˆ—ğ‘<0.05
269BigData= Big Insights? Operationalising Brooksâ€™ Law in a Massive GitHub Data Set ICSEâ€™22, May21â€“29,2022,Pittsburgh,PA, USA
110100100010000
10 100 1000
Team SizeCycC / Team MemberA
10100100010000
10 100 1000
Team SizeNLOC / Team MemberInD
0.3
1
25B
0.02.55.07.510.012.5
2âˆ’45âˆ’89âˆ’1516âˆ’3031âˆ’5859âˆ’115116âˆ’226227âˆ’443444âˆ’871872âˆ’1711
Team SizeInDC
Figure 4: a) Productivity (CycC) per team member as a function of team size. A linear /squareand quadratic model /squarehave been
fitted to the data. b) Marginal effect of the mean indegree on the relationship between team size and productivity (NLOC). c)
Increaseof mean indegree (InD) with team size.
in the productivity observations. We further again find a negative
relationship between team size and productivity for all five opera-
tionalisations.Assumingconstant InD andFModR, theregression
results suggest that by doubling the size of a development team,
we reducethe average productivity ofteam members by between
22%and30%.Notably,ahighermeanindegreeisaccompaniedby
higher productivity. Moreover, the foreign modification ratio has a
strongnegative relationship with productivity.
Adding a quadratic term (TS2) to the model, i.e.,
PRODâˆ¼TS+TS2+InD+FModR, (1)
wefindthatcontrarytobefore,thecoefficientofteamsizeremains
negativeandsignificantwhileteamsizesquaredisinsignificant(see
Table3d).Thus,thenon-linearrelationshipbetweenproductivity
and team size found in Table 3b does not persist when accounting
forthemeanindegree and foreign modification ratio.
In conclusion, in a large-scale study using 201 collaborative
GitHubprojects sampled in a systematic and unbiased fashion
acrossdifferentstrataofteamsizes,weconfirmthenegativerela-
tionshipbetweenteamsizeandproductivityfoundbypriorstudies.
Thisnegativerelationshipisrobustagainstthechoiceofproduc-
tivity measure and persists when controlling for the teamâ€™s collab-
oration structure. Only considering team size as a predictor, our
data provide some evidence for an optimal team size of 7 or 19
membersfortwooftheeightoperationalisationsofproductivity.
However, for six out of eight productivity measures, the optimal
productivityperteammemberisreachedforateamsizeofone.This
finding is further supported by the fact that the squared team size
has no significant relationship when controlling for other network
measures.
As mentioned above, our results suggest that the mean indegree
ofdevelopers ispositively relatedtoproductivity, whileteam size
is negatively related to productivity. Importantly, the regressionmodels considered so far assume that the effect of the team sizeon productivity is independent of the mean indegree and vice-
versa,i.e.,theireffectispurelyadditive.However,itisreasonable
to assume that the productivity of developers in a team with dense
collaboration structures is more strongly affected by team size,comparedtoateamwhereeachdevelopercollaborates,onaverage,
with few other team members. This motivates a last experiment,
where we includean interaction term that capturesthe combined
effect of team size and mean indegree as an additional variable:
PRODâˆ¼TS+InD+TSÃ—InD+FModR (2)
The results in Table 3e suggest a negative coefficient for this inter-
action term. However, the effect is only significant for Comms and
NLOC.The analysisof the marginal effect of the mean indegree on
the relationship between team size and productivity is shown in
Figure4b.Inlinewiththepositivecoefficientofthemeanindegree,
wefindthatdevelopersinteamswithlargermeanindegreetendto
bemoreproductiveonaverage,i.e.linescorrespondingtolarger
meanindegreestendtohavelargerintercepts(butnegativeslopes).
Moreover,asshownbythenegativecoefficientoftheinteraction
term,thenegativeeffectofteamsizeonproductivitygrowswith
the mean indegree, i.e. lines corresponding to larger mean inde-grees tend to have steeper negative slopes. The whisker plot inFigure4cfurtherrevealsapositiverelationshipbetweenthesizeof a team (x-axis) and the mean indegree of developers (y-axis),
i.e. developers in larger teams tend to edit code of a larger number
of other developers. This positive relationship specifically holdsfor smaller team sizes, while the mean indegree in larger teams
withmorethanapproximately50developersissimilar.Importantly,
the fact that (i) developers in larger teams tend to have a higher
indegree and (ii) developers in teams with higher indegree tend to
be more productive does notimply that developers in larger teams
are,onaverage,moreproductive.Thisisconfirmedbythenegative
coefficients of team size in all our regression models as well as the
clearnegative marginal effects shown in Figure 4b.
We note that the positive relationship between team size and
themeanindegreecouldexplainthepositivecoefficientforTSin
Table 3b that suggests the existence of an optimal team size. We
further conjecture that this non-trivial finding could be a reason
why empirical studies that do not account for the distribution of
team sizes in GitHubrepositories, and thus inadvertently focus
onprojectswithsmallteamsize,erroneouslyfindapositiverela-
tionship between team size and productivity. Specifically, projects
270ICSEâ€™22,May21â€“29,2022,Pittsburgh,PA, USA Gote, et al.
withsmallteamsizestendtohaveasmallmeanindegree,which
corresponds to a line with smaller intercept (and negative slope)
in Table 3b. Conversely, teams with larger team sizes tend to have
a larger mean indegree, which corresponds to a line with larger
intercept (and negative slope) in Table 3b. The failure to control
for this effect can lead to a reversal of the relationship between
productivityandteamsize,i.e.,awrong positiveslopefortheeffect
iserroneouslyfound.Thiscanbeviewedasaspecificinstanceof
Simpsonâ€™s paradox, where the aggregate effect in a sample that
combines data from different â€œgroupsâ€ of projectsâ€”i.e., teams with
different mean indegreesâ€”can be positive, even though a negative
relationship holds for each group separately.
5 LIMITATIONS AND THREATS TO VALIDITY
Afirstthreattothevalidityofourresultscouldbetheoperationali-
sation of productivity. To guard against this, we have studied eight
different measures that capture different notions of productivity. A
commonissueof productivitymeasures thatare basedon commit
logdataisthattheydonotaccountforthestructureofcontributed
code. To guard against this issue and appropriately value commits
thatdecrease the complexity of code and thus make it more main-tainable, we consider measures that account for tokens, functions,
andcontrol structures.
A second aspect that could potentially influence our results is
the method toassess the size of a softwareteam. We compute the
team size at a given time ğ‘¡by counting all developers who have
made a commit up to 42 weeks before ğ‘¡. This approach to infer the
teamsizeisnecessarysincethereisnoformalisednotionofteam
size inGitHub. The specific choice of this time window is based on
theinter-committimedistributionfor GitHubprojectsfoundin[ 3].
Wehavetestedtherobustnessoftheresultsbychoosingadifferent
windowsizeoftwoyears.Duetothecomputationaleffortthatis
due to the recalculation of all network metrics, a comprehensive
study of different window sizes was beyond the scope of our study
butcouldbe an interesting question for future work.
InSection2.1, weidentifiedprojectselectionand dataprepara-
tionasamajorthreattothevalidity.Wethusspentconsiderable
efforttodevelopageneralprojectselectionpipelineaswellasOpen
Source software tools to infer collaboration networks from commit
data. Despite these efforts, there may be remaining issues, such as
thepossibilitytomanuallymodifythehistoryofa gitrepository,
which we can neither detect nor account for. Due to data issues
relatedtosomemergecommits,wewerefurthernotabletoprocess
allcommitsof the Linux Kernel project4. We therefore excluded
thisproject from our analysis.
Addressingtheissueofomittedvariables,ourregressionmodels
explain roughly 50% of the variance in the relationship between
teamsizeandproductivity,which considerablyimproves thevari-
ance explained by prior studies. Nevertheless, there is additional
variance in the relationship that we cannot explain. This could
either be due to the stochastic nature of the underlying process
or the existence of additional variables that are not included in
our models. To address this issue, future studies could additionally
studydatafrom issue trackers and mailing lists [42â€“44].
4https://github.com/torvalds/linuxInour study,weconsidered 201OSSprojectssampled torepre-
sent the entire spectrum of team sizes present on GitHub. While
our findings are representative for collaborative software develop-
mentonGitHub,itisunclearwhethertheycanbegeneralisedto
proprietarysoftwareprojectsorotherOpenSourcecollaboration
platforms.PlatformslikeSourceForgeorBitbuckethavedifferent
characteristics [ 45â€“47] that will require modifications to our selec-
tionpipeline, which is an interesting issue for future work.
6 RELATED WORK
Ourworktouchesonissuesthathavebeenstudiedinempiricalsoft-
wareengineering,computationalsocialscience,networkscience,
and organisational theory. Namely, how we can use repository log
data to quantify productivity in software development, how the
sizeofteamsinfluencestheproductivityofitsmembers,andhow
networkmodelscanbeusedtostudysocialaspectsincollaborativesoftwareprojects.Atameta-level,ourstudyfurtheraddressescom-
monchallengesandpitfallsintheanalysisofbigrepositorydata,
someof which have been previously highlighted in [10â€“12, 45].
A large body of works has investigated methods to measure
theproductivity of developers based on repository data [ 48,49].
Commit-basedproductivitymeasures calculateproductivitybased
onthenumberofcommits[ 7,50]orpushes[ 8].Whilethisapproach
doesnotrequireadetailedanalysisofthecommittedsourcecode,it
hastheproblemthattheamountofcodechangedwitheachcommit
can vary significantly both within and between projects [ 23]. [26]
found that productivity rankings based on commit-based measures
only show low correlations with rankings obtained from team
leaders.Therefore,morefine-granularmeasuressuchasthenumber
ofmodifiedlinesorthenumberofmodifiedcharacters[ 3]havebeen
proposed. Code-basedproductivitymeasures aimtoovercomethis
limitationbyanalysingthecodecontainedinacommit.Commonly
usedmetricincludethenumberofcodelines[ 5,51â€“53],function
points [54, 55], or tokens [56] changed per time interval.
Alarge bodyofworks inorganisationaltheory, computational
social science and empirical software engineering have studied the
question of how the size of a team is related to its performance. In
the context of software development, [ 2] argues that the increased
coordination requirements in larger teams lead to a reduction of
developerproductivity.Whilethisproposedmechanismhasbeen
corroboratedbyquantitativestudies[ 3,57],otherworkssuggest
synergisticeffectsthatleadtoanincreaseindeveloperproductivity
as teams grow in size [ 7,8]. The combination of these findings
indicatesthatanoptimalsizeforasoftwaredevelopmentteammay
exist,whichisalsodiscussedintheliterature[ 41,58].Areportcited
by[41]suggeststhatforproprietarysoftwaredevelopmentprojects,
an optimal team size with respect to productivity is achieved for
nineteammembers.
Utilising a method to construct a network representation of co-
editingrelationsfromthecommit-loghistoryofaproject,ourwork
finallyaddressesquestionsthatreceivedattentionfromthenetwork
science and computational social science community. A number of
works have investigated how the topology of communication, col-
laboration, or coordination networks is related to the performance
[59â€“61], resilience [ 62,63], or productivity [ 3] of teams in various
271BigData= Big Insights? Operationalising Brooksâ€™ Law in a Massive GitHub Data Set ICSEâ€™22, May21â€“29,2022,Pittsburgh,PA, USA
contexts.Inthecontextofresearchondeveloperproductivity,re-
centstudiesfoundthata densificationof co-editing networks due
to shared code ownership can explain the decrease in productivity
observed for larger teams [3, 4].
7 CONCLUSION
Massive data from software repositories and collaboration tools
provide compelling new opportunities to study social aspects in
softwaredevelopment.Withinthiscontext,thequestionofhowthe
sizeandcollaborationpatternsofsoftwaredevelopmentteamsin-
fluencetheproductivityofdevelopershasemergedasanimportantresearchquestionattheintersectionofcomputationalsocialscience
andempiricalsoftwareengineering.Recentempiricalstudiesusing
big data from software repositories have come to contradictory
answers to this important research question, even though those
studiesused similar data sets and empirical methods.
Addressingcommonchallengesandpitfallsintheanalysisofbig
repository data, our work offers a possible explanation for this dis-
agreementbetweenrecentworksinempiricalsoftwareengineering.
Tothisend,weprovidethe,tothebestofourknowledge,largest,
curated corpus of GitHubprojects that is specifically tailored to
investigatetheinfluenceofteamsizeandcollaborationpatternsonindividualandcollectiveproductivity.Theprojectsincludedinthiscorpusare systematically chosensuchthatweavoidcommonperils
inGitHubmining. We use a stratified sampling that supports unbi-
ased analyses of the impact of team size on developer productivity.
We systematically compare a set of eight code- and commit-based
productivity measures and study which of the measures are likely
to be interchangeable and which capture independent dimensions
ofproductivity.Buildingonamethodtoconstructtime-evolvingco-
editing networks from gitrepositories, we consider eight network
metrics that capture different dimensions of the social organisa-
tion of software teams. We finally use those methods to study the
Ringelmanneffectin collaborativesoftwaredevelopment.Our re-
sultshighlightarobustnegativerelationshipbetweenteamsizeand
developerproductivitythatcanbeexplainedbasedontheteamâ€™s
collaborationstructure.Wearguethatneglectingthehighlyskewed
distribution of team sizes on GitHubcan lead to a reversal of the
relationship between team size and productivity, thus offering a
possible explanation for recent contradictory results.
Apart from this, our work provides several insights that are rel-
evantforthemanagementofsoftwareprojects:Inparticular,we
find(i)anoverallnegativerelationbetweenindividualproductivity
andteamsize,and(ii)anon-linearrelationshipthatgivesriseto
an optimal team size for small teams. These findings can be useful
to define advanced cost estimation models that incorporate the
found non-linear relationship between team size and productivity,
thusprovidingbetterestimatesfortheworkforcerequiredtode-
velop projects with a known (estimated) size of the code base. Our
analysisfurtherhighlightsadditionalfactorsthatinfluenceteam
productivity, such as the amount of foreign code that is edited and
the number of interaction partners of developers. This insight not
only allows us to further improve cost estimation models, it alsopoints to factors that can possibly be optimised by project main-
tainers, e.g., by carefully decomposing the code base into modulesaddressed by different (sub-)teams or by optimising organisational
structures of the development team.
In summary, our work contributes to the ongoing discussion on
how the size and structure of teams influence productivity. Investi-
gatingthecross-correlationsofproductivityandnetworkmetricsinasystematicallyconstructedcorpusofsoftwareprojects,wefurthercontributeavaluablenewresourceforresearchersinempiricalsoft-
wareengineeringandcomputationalsocialscience.Byfocusingon
generic network measures, we further provide the perspective that
our results can generalise beyond empirical software engineering.
Highlighting pitfalls in the analysis of big data, our work finally
demonstratesthattheuseofbiggerdatasetsdoesnotautomatically
lead to more reliable insights.
DATA AVAILABILITY AND REPRODUCIBILITY
To facilitate the reproduction of our results and enable future re-
searchbasedontheextensivedatasetminedforourstudy,wehave
archivedbothareproducibilitypackageandourfulldatasetson
zenodo.org5.
ACKNOWLEDGMENTS
WethankChristianZinggforcontributingtothedevelopmentof
theinfrastructuretomineeditsandco-editsfromsoftwareprojects
onthe ETHZurichscientific computecluster Euler.Ingo Scholtes
acknowledgesfinancialsupportfromtheSwissNationalScienceFoundation through grant no. 176938. Christoph Gote and Ingo
Scholteswrotepartsofthis manuscriptonajointresearchretreat
atNiederzerfermÃ¼hle that was financially supported by the De-
partment of Informatics at University of Zurich and the Chair of
SystemsDesignat ETH Zurich.
REFERENCES
[1]M.Ringelmann,â€œRecherchessurlesmoteursanimes:Travaildelâ€™homme,â€ Annales
de lâ€™Institut National Agronomique, vol. 12, no. 1, pp. 1â€“40, 1913.
[2] F. P. Brooks, â€œThe mythical man-month,â€ 1975.
[3]I. Scholtes, P. Mavrodiev, and F. Schweitzer, â€œFrom Aristotle to Ringelmann:
A large-scale analysis of team productivity and coordination in Open Source
software projects,â€ Empirical Software Engineering, vol. 21, no. 2, pp. 642â€“683,
2016.
[4]C.Gote,I.Scholtes,andF.Schweitzer,â€œAnalysingtime-stampedco-editingnet-
worksinsoftwaredevelopmentteamsusinggit2net,â€ EmpiricalSoftwareEngi-
neering, vol. 26, no. 4, pp. 1â€“41, 2021.
[5]J. D. Blackburn, G. D. Scudder, and L. N. Van Wassenhove, â€œImpr ovingspeedand
productivity of software development: A global survey of software developers,â€
IEEETransactions on Software Engineering, vol. 22, no. 12, pp. 875â€“885, 1996.
[6]K. D. Maxwell, L. Van Wassenhove, and S. Dutta, â€œSoftware development produc-
tivity of european space, military, and industrial applications,â€ IEEE Transactions
on Software Engineering, vol. 22, no. 10, pp. 706â€“718, 1996.
[7]D.Sornette,T.Maillart,andG.Ghezzi,â€œHowmuchisthewholereallymorethan
the sum of its parts? 1+1=2.5: Superlinear productivity in collective group
actions,â€Plos one, vol. 9, no. 8, p. e103023, 2014.
[8]G.Muric,A.Abeliuk,K.Lerman,andE.Ferrara,â€œCollaborationdrivesindividual
productivity,â€ PACMHCI, vol. 3, no. CSCW, pp. 74:1â€“74:24, 2019.
[9]T.MaillartandD.Sornette,â€œAristotlevs.Ringelmann:Onsuperlinearproduction
in open source software,â€ Physica A: Statistical Mechanics and its Applications,
vol. 523, pp. 964â€“972, 2019.
[10]C. Bird, P. C. Rigby, E. T. Barr, D. J. Hamilton, D. M. German, and P. Devanbu,
â€œThepromisesandperilsofmininggit,â€in 20096thIEEEInternationalWorking
Conferenceon Mining Software Repositories. IEEE, 2009, pp. 1â€“10.
[11]E.Kalliamvakou,G.Gousios,K.Blincoe,L.Singer,D.M.German,andD.Damian,
â€œThepromisesandperilsofminingGitHub,â€in Proceedingsofthe11thWorking
Conferenceon Mining Software Repositories, 2014, pp. 92â€“101.
5Reproducibility package: https://doi.org/10.5281/zenodo.5294015
Datasets:https://doi.org/10.5281/zenodo.5294964
272ICSEâ€™22,May21â€“29,2022,Pittsburgh,PA, USA Gote, et al.
[12]â€”â€”, â€œAn in-depth study of the promises and perils of mining GitHub,â€ Empirical
Software Engineering, vol. 21, no. 5, pp. 2035â€“2071, 2016.
[13]C. Gote and C. Zingg, â€œgambit â€“ An Open Source name disambiguation tool
for version control systems,â€ in 2021 IEEE/ACM 18th International Conference on
MiningSoftware Repositories (MSR), 2021, pp. 80â€“84.
[14]D. T. Campbell and J. C. Stanley, Experimental and quasi-experimental designs for
research. Ravenio Books, 2015.
[15]G. Gousios, â€œThe GHTorrent dataset and tool suite,â€ in Proceedings of the 10th
Working Conference on Mining Software Repositories, ser. MSR â€™13. Piscataway,
NJ,USA:IEEEPress, 2013, pp. 233â€“236.
[16]C.Gote,I.Scholtes,andF.Schweitzer,â€œgit2netâ€“Miningtime-stampedco-editing
networksfrom largegitrepositories,â€in 2019IEEE/ACM 16thInternationalCon-
ferenceon Mining Software Repositories (MSR). IEEE, 2019, pp. 433â€“444.
[17]J. Warner, â€œThank you for 100 million repositories,â€ https://github.blog/2018-11-
08-100m-repos/, 2021. [Online]. Available: https://github.blog/2018-11-08-100m-
repos/
[18]J. Seawright and J. Gerring, â€œCase selection techniques in case study research: A
menuofqualitativeandquantitativeoptions,â€ PoliticalResearchQuarterly ,vol.61,
no. 2, pp. 294â€“308, 2008.
[19]T. Yin, â€œLizard,â€ https://github.com/terryyin/lizard, 2020. [Online]. Available:
https://github.com/terryyin/lizard
[20]F. Beuke,â€œGitHut 2.0,â€ https://madnight.github.io/githut/#/pull_requests/2020/2,
2020. [Online]. Available: https://madnight.github.io/githut/#/pull_requests/
2020/2
[21]D.Spinellis,Z.Kotti,andA.Mockus,â€œAdatasetforgithubrepositorydedupli-
cation,â€ in Proceedings of the 17th international conference on mining software
repositories, 2020, pp. 523â€“527.
[22]K.Weihmann,â€œMultimetric,â€https://github.com/priv-kweihmann/multimetric,
2020.[Online]. Available: https://github.com/priv-kweihmann/multimetric
[23]GitHubInc.,â€œThe2020stateoftheOctoverseâ€“Findingbalancebetweenworkand
play,â€https://octoverse.github.com/static/github-octoverse-2020-productivity-
report.pdf,2020.[Online].Available:https://octoverse.github.com/static/github-
octoverse-2020-productivity-report.pdf
[24]B. Vasilescu, D. Posnett, B. Ray, M. G. van den Brand, A. Serebrenik, P. Devanbu,
andV.Filkov,â€œGenderandtenure diversityingithub teams,â€in Proceedingsof
the 33rd annual ACM conference on human factors in computing systems, 2015, pp.
3789â€“3798.
[25]J. R. Hackman, â€œThe design of work teams,â€ in Handbook of organizational be-
haviour, J. W. Lorsch, Ed. Englewood Cliffs, N.J.: Prentice-Hall, 1987, ch. 20, pp.
315â€“342.
[26]E. Oliveira, E. Fernandes, I. Steinmacher, M. Cristo, T. Conte, and A. Garcia,
â€œCodeandcommitmetricsofdeveloperproductivity:Astudyonteamleaders
perceptions,â€ EmpiricalSoftware Engineering, vol. 25, no. 4, pp. 2519â€“2549, 2020.
[27]T.J.McCabe,â€œAcomplexitymeasure,â€ IEEETransactionsonSoftwareEngineering,
vol. 4, pp. 308â€“320, 1976.
[28]M. H. Halstead et al.,Elements of software science. Elsevier New York, 1977,
vol. 7.
[29]I. Stamelos, L. Angelis, A. Oikonomou, and G. L. Bleris, â€œCode quality analysis in
Open Source software development,â€ Information Systems Journal , vol. 12, no. 1,
pp. 43â€“60, 2002.
[30]R.Baggen,J.P.Correia,K.Schill,andJ.Visser,â€œStandardizedcodequalitybench-
markingforimprovingsoftwaremaintainability,â€ SoftwareQualityJournal,vol.20,
no. 2, pp. 287â€“307, 2012.
[31] M. Newman, Networks. Oxford University Press, 2018.
[32]S. Milgram, â€œThe small world problem,â€ Psychology today, vol. 2, no. 1, pp. 60â€“67,
1967.
[33]M. S. Granovetter, â€œThe strength of weak ties,â€ American Journal of Sociology,
vol. 78, no. 6, pp. 1360â€“1380, 1973.
[34]M.Y. AllahoandW.-C.Lee, â€œAnalyzingthesocialnetworks ofcontributorsin
open source software community,â€ in Applications of Social Media and Social
NetworkAnalysis. Springer, 2015, pp. 57â€“75.
[35]J.Teixeira,G.Robles,andJ.M.GonzÃ¡lez-Barahona,â€œLessonslearnedfromap-
plying socialnetwork analysis onan industrial free/libre/opensource software
ecosystem,â€ JournalofInternetServicesandApplications,vol.6,no.1,pp.1â€“27,
2015.
[36]S.Henry,D.Kafura,andK.Harris,â€œOntherelationshipsamongthreesoftware
metrics,â€ ACM SIGMETRICS Performance Evaluation Review, vol. 10, no. 1, pp.
81â€“88,1981.
[37]S. N. Woodfield, V. Y. Shen, and H. E. Dunsmore, â€œA study of several metrics for
programmingeffort,â€ JournalofSystemsandSoftware,vol.2,no.2,pp.97â€“103,
1981.
[38]M. A. A. Mamun, C. Berger, and J. Hansson, â€œCorrelations of software code
metrics: an empirical study,â€ in Proceedings of the 27th international workshop on
softwaremeasurementand12th internationalconferenceon softwareprocess and
product measurement, 2017, pp. 255â€“266.
[39]D. Landman, A. Serebrenik, and J. Vinju, â€œEmpirical analysis of the relationship
betweenccandslocinalargecorpusofjavamethods,â€in 2014IEEEInternational
Conferenceon Software Maintenance and Evolution. IEEE, 2014, pp. 221â€“230.[40]I. Scholtes, N. Wider, R. Pfitzner, A. Garas, C. J. Tessone, and F. Schweitzer,
â€œCausality-drivenslow-downandspee d-up of diffusion innon-Markovian tem-
poral networks,â€ Nature Communications, vol. 5, p. 5024, 2014.
[41]D. RodrÃ­guez, M. Sicilia, E. GarcÃ­a, and R. Harrison, â€œEmpirical findings on team
size and productivity in software development,â€ Journal of Systems and Software,
vol. 85, no. 3, pp. 562â€“570, 2012.
[42]A.Bacchelli,M.Lanza,andM.Dâ€™Ambros,â€œMiler:Atoolsetforexploringemail
data,â€ inProceedings of the 33rd International Conference on Software Engineering.
ACM, 2011, pp. 1025â€“1027.
[43]C.Bird,A.Gourley,P.Devanbu,M.Gertz,andA.Swaminathan,â€œMiningemail
social networks,â€ in Proceedings of the 2006 International Workshop on Mining
Software Repositories. ACM, 2006, pp. 137â€“143.
[44]A.Guzzi,A.Bacchelli,M.Lanza,M.Pinzger,andA.v.Deursen,â€œCommunication
inOpenSourcesoftwaredevelopmentmailinglists,â€in Proceedingsofthe10th
Working Conference on Mining Software Repositories. IEEE Press, 2013, pp.
277â€“286.
[45]J. Howison and K. Crowston, â€œThe perils and pitfalls of mining SourceForge,â€ in
MSR. IET, 2004, pp. 7â€“11.
[46]Y. Ma, C. Bogart, S. Amreen, R. Zaretzki, and A. Mockus, â€œWorld of code: An
infrastructureforminingtheuniverseofopensourceVCSdata,â€in 2019IEEE/ACM
16thInternationalConferenceonMiningSoftwareRepositories(MSR) . IEEE,2019,
pp. 143â€“154.
[47]T.Xie,S.Thummalapenta,D.Lo,andC.Liu,â€œDataminingforsoftwareengineer-
ing,â€Computer, vol. 42, no. 8, 2009.
[48]A. N. Meyer, T. Fritz, G. C. Murphy, and T. Zimmermann, â€œSoftware developersâ€™
perceptionsofproductivity,â€in Proceedingsofthe22ndACMSIGSOFTInternational
Symposiumon Foundations of Software Engineering. ACM, 2014, pp. 19â€“29.
[49]G. Sudhakar, A. Farooq, and S. Patnaik, â€œMeasuring productivity of software
developmentteams,â€ SerbianJournalofManagement ,vol.7,no.1,pp.65â€“75,2012.
[50]A.Mockus,R.T.Fielding,and J.D.Herbsleb,â€œTwocasestudiesofOpenSource
software development: Apache and Mozilla,â€ ACM Transactions on Software Engi-
neering and Methodology (TOSEM), vol. 11, no. 3, pp. 309â€“346, 2002.
[51]P.Devanbu,S.Karstu,W.Melo,andW.Thomas,â€œAnalyticalandempiricalevalua-
tionofsoftwarereusemetrics,â€in Proceedingsofthe18thInternationalConference
on Software Engineering. IEEE Computer Society, 1996, pp. 189â€“199.
[52]H.HulkkoandP.Abrahamsson,â€œAmultiplecasestudyontheimpactofpairpro-
gramming on product quality,â€ in Proceedings of the 27th International Conference
on Software Engineering. ACM, 2005, pp. 495â€“504.
[53]V. Nguyen, L. Huang, andB. Boehm, â€œAn analysis of trends inproductivity and
cost drivers over years,â€ in Proceedings of the 7th International Conference on
Predictive Models in Software Engineering. ACM, 2011, p. 3.
[54]C. Jones, â€œSoftware metrics: Good, bad and missing,â€ Computer, vol. 27, no. 9, pp.
98â€“100,1994.
[55]S. Wagner and M. Ruhe, â€œA systematic review of productivity factors in software
development,â€ arXivpreprint arXiv:1801.06475, 2018.
[56]J. A. Lane and D. Zubrow, â€œIntergrating measurement with improvement: An
action-oriented approach:Experience report,â€ in Proceedings ofthe 19th Interna-
tionalConferenceon Software Engineering. ACM, 1997, pp. 380â€“389.
[57]Z.Jiang,P.NaudÃ©,andC. Comstock,â€œAninvestigationonthevariationofsoft-
waredevelopmentproductivity,â€ InternationalJournalofComputer,Information,
and SystemsSciences,and Engineering , vol. 1, no. 2, pp. 72â€“81, 2007.
[58]M.HeriÄko,A.Å½ivkoviÄ,andI.Rozman,â€œAnapproachtooptimizingsoftware
developmentteamsize,â€ InformationProcessingLetters,vol.108,no.3,pp.101â€“106,
2008.
[59]L.Wu,â€œSocialnetworkeffectsonproductivityandjobsecurity:Evidencefrom
theadoptionofasocialnetworkingtool,â€ Informationsystemsresearch ,vol.24,
no. 1, pp. 30â€“51, 2013.
[60]H.-L. Yang and J.-H. Tang, â€œTeam structure and team performance in is develop-
ment:Asocialnetworkperspective,â€ Information&management,vol.41,no.3,
pp. 335â€“349, 2004.
[61]R.ReagansandE.W.Zuckerman,â€œNetworks,diversity,andproductivity:Thesocial capital of corporate R&D teams,â€ Organization science, vol. 12, no. 4, pp.
502â€“517,2001.
[62]G.F.Massari,I.Giannoccaro,andG.Carbone,â€œTeamsocialnetworkstructure
andresilience:Acomplexsystemapproach,â€ IEEETransactionsonEngineering
Management, 2021.
[63]M. S. Zanetti, I. Scholtes, C. J. Tessone, and F. Schweitzer, â€œThe rise and fallof a central contributor: Dynamics of social organization and performance in
theGentoocommunity,â€in CHASE/ICSEâ€™13Proceedingsofthe6thInternational
WorkshoponCooperativeandHumanAspectsofSoftwareEngineering,2013,pp.
49â€“56.
273