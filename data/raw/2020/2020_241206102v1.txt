Synthesizing Document Database Queries using
Collection Abstractions
Qikang Liu, Yang He, Yanwen Cai, Byeongguk Kwak, Yuepeng Wang
Simon Fraser University, Buranby, BC, Canada
{qla116, yha244, yca452, bka47, yuepeng }@sfu.ca
Abstract —Document databases are increasingly popular in
various applications, but their queries are challenging to write
due to the flexible and complex data model underlying document
databases. This paper presents a synthesis technique that aims to
generate document database queries from input-output examples
automatically. A new domain-specific language is designed to
express a representative set of document database queries in an
algebraic style. Furthermore, the synthesis technique leverages
a novel abstraction of collections for deduction to efficiently
prune the search space and quickly generate the target query.
An evaluation of 110 benchmarks from various sources shows
that the proposed technique can synthesize 108 benchmarks
successfully. On average, the synthesizer can generate document
database queries from a small number of input-output examples
within tens of seconds.
I. I NTRODUCTION
Document databases like MongoDB [29] and CouchDB [10]
have become increasingly popular in various real-world sce-
narios, such as online commercial platforms, financial services,
gaming, and social media applications [30]. Different from
traditional relational databases that primarily use structured
data like tables, document databases persist data in a semi-
structured format such as JSON and BSON. While the semi-
structured data format provides developers with great flexibil-
ity in storing and querying complex data structures directly, it
also raises significant challenges for users to write queries for
document databases.
To help users write document database queries in an easy
and convenient fashion, we develop a synthesis technique to
generate queries automatically. Inspired by prior work on au-
tomated synthesis of SQL queries for relational databases [14],
[46], [53], our technique aims to generate document database
queries from input-output examples. Specifically, the user only
needs to provide a small number of examples to demonstrate
the query, where the input example is a small document
database consisting of a few documents, and the output ex-
ample is the desired query result over the input. The goal of
our synthesis technique is to generate a document database
query such that executing the query over the input example
produces the output example.
However, unlike synthesizing SQL queries, there are several
key challenges to synthesizing queries for document databases.
•Hierarchical and nested data structures . Document data-
bases support hierarchical and nested data structures, such as
arrays, documents, and their combinations. Since queries for
document databases constantly operate over these complexdata structures, it is crucial for synthesizers to reason about
complex data structures efficiently for better performance.
•Specialized query language . Query languages for document
databases may use specialized operators over complex data
structures that relational databases cannot handle. For in-
stance, MongoDB uses a lookup operator in aggregation
pipelines to query data over multiple collections. Synthe-
sizers need to support an expressive query language for
document databases while maintaining the efficiency of
exploring a large search space of the target query.
To address these challenges, we have designed a new
domain-specific language based on the aggregation pipeline
in MongoDB that can express a representative set of queries
with core operators of document databases. The queries of this
language are in an algebraic style similar to relational algebra
but tailored towards document databases.
Furthermore, prior work on program synthesis proposed an
approach to speed up the synthesis process by deduction [13],
[14]. For fast synthesis of document database queries, we have
adapted this approach to our setting and developed a novel
abstraction for collections containing hierarchical and nested
data structures to prune the search space efficiently. The key
insight is that the “shape” and size of collections can help
the synthesizer quickly prune incorrect queries, even if the
query is partial. Thus, our abstraction consists of two pieces of
information about the collection: First, it includes the type of
documents inside the collection. Second, it includes a logical
formula describing constraints over the sizeof the collection.
More specifically, our synthesis technique is presented
schematically in Figure 1. At a high level, the synthesis
technique takes an iterative approach and has two phases in
each iteration. In the first phase, the synthesizer aims to find
a query sketch, which is a partial query with some unknown
constructs. In the second phase, it tries to complete the sketch
into a full query that can satisfy all provided input-output
examples. In general, it is not efficient to check if a sketch is
feasible to be completed into a correct full query by checking
all possible completions against the examples, because a
sketch may have a large number of completions. To avoid
such inefficiency, the key part of our synthesis technique is a
deduction engine, which can check if a sketch is feasible to get
a correct query without checking its completions. In particular,
the deduction engine can directly evaluate the sketch over
abstractions of collections and obtain an abstract collection.
If the expected output example is a valid concretization ofarXiv:2412.06102v1  [cs.DB]  8 Dec 2024IO Examples
Schema
Collection Name
RefinementSketchCompletionDeductionSketch
SketchEvaluationConcretizationChecking
Feasible Sketch
mongoDBAbstractCollections
FailFail
Fig. 1: Schematic workflow.
the resulting abstract collection, the synthesizer concludes the
sketch is feasible to complete and proceeds to find a correct
completion. Otherwise, the synthesizer can safely conclude
the sketch is infeasible to complete, prune the search space
accordingly, and propose a different sketch to the next iteration
by refining the infeasible sketch.
Based on this technique, we have developed a tool called
NOSDAQ that can synthesize document database queries from
input-output examples. To evaluate the synthesis technique,
we have collected 110 benchmarks from various application
scenarios, including StackOverflow, Kaggle, MongoDB offi-
cial documents, and Twitter API documents. The evaluation
result shows that N OSDAQ can successfully synthesize 108
document database queries within the 5-minute time limit.
Furthermore, N OSDAQ only uses 1 – 3 input-output examples
and finishes query synthesis in an average of 25.4 seconds,
which demonstrates the effectiveness and efficiency of our
synthesis technique.
Contributions. To summarize, the main contributions of this
paper are as follows.
1) We develop a technique for synthesizing document
database queries from input-output examples.
2) We design a new domain-specific language to express
document database queries in algebraic style.
3) We design a novel abstraction for collections containing
hierarchical and nested data structures and use this abstrac-
tion to speedup the synthesis of document database queries
based on deduction.
4) We define the abstract semantics of document database
queries based on our abstraction of collections.
5) We develop a tool called N OSDAQ and evaluate it over
110 benchmarks from various sources. The evaluation
result shows that N OSDAQ is effective and efficient in
synthesizing document database queries.
Organization. The remainder of this paper is structured as
follows. Section II provides a motivating example to illustrate
our technique. Section III formalizes the synthesis problem,{posts: [ {
_id: "1", title: "Title-1",
replies: [ {depth: 0 },{depth: 0 },{depth: 1 }]
},{
_id: "2", title: "Title-2",
replies: [ {depth: 0 },{depth: 1 },{depth: 2 }]
},{
_id: "3", title: "Title-3",
replies: [ {depth: 0 },{depth: 1 },{depth: 2 },
{depth: 3 }]
}]}
Fig. 2: Input example.
and Section IV introduces collection abstractions. Sections V
and VI present the synthesis algorithm and its implementation
details, respectively. Section VII presents the experimental
setup and evaluation results. Section VIII discusses the related
work, followed by a conclusion in Section IX.
II. M OTIVATING EXAMPLE
To explain our synthesis technique, let us consider a con-
crete motivating example. Given a document database col-
lected from the Kaggle website that stores a list of Reddit
posts. The database only has one collection called posts with
the following schema1
Arr⟨{_id:String,title :String,replies :Arr⟨{depth :Num}⟩}⟩
where Arr⟨τ⟩denotes the array type of τ. Specifically, the
posts collection contains an array of documents, where each
document has three attributes: _id,title , and replies .
Thereplies attribute is also an array of documents and the
document has one attribute depth denoting the nesting level
of the reply from the root post.
Now suppose the user wants to query the title of posts which
have more than one non-zero-depth replies and the count of
these replies. N OSDAQ can help the user synthesize this query
automatically. The user needs to provide small input-output
examples to demonstrate their intention. For instance, Figure 2
is an input example, and the corresponding output example is
[{reply_count: 3, title: "Title-3" },
{reply_count: 2, title: "Title-2" }]
The goal of N OSDAQ is to synthesize a query such that
executing the query on the input example produces the output
example. N OSDAQ takes an iterative approach to solve the
synthesis problem. In each iteration, it first proposes a query
sketch that may contain unknowns and then checks if the
sketch is feasible to complete. If feasible, N OSDAQ completes
the sketch into a full query by enumerative search and checks
if any query satisfies the input-output example. If the sketch
is infeasible to complete, then N OSDAQ refines the sketch and
starts the next iteration.
First iteration. NOSDAQ starts with the simplest sketch in its
domain-specific language – the posts collection and checks
its feasibility. To do so, the deduction engine of N OSDAQ uses
the collection abstractions and evaluates the sketch based on its
1The database schema is simplified in this section for illustration.abstract semantics. Specifically, the abstraction for the posts
collection is ˜C= (T, ϕ)where
T:{_id:String,title :String,replies :Arr⟨{depth :Num}⟩}
is the type of inside documents and ϕ:l0= 3 is the
formula describing the size of the collection is 3. N OSDAQ
takes the abstract collection as input and evaluates the sketch
posts based on the abstract semantics. The evaluation result
is{˜C1}where ˜C1= (T, ϕ), which is exactly the same as
˜C. An important observation here is that the output example
is not a concretization of ˜C1because its document has type
{title :String ,reply_count :Num}and its size is 2.
Thus, N OSDAQ concludes the sketch posts is not feasible to
complete to a correct query and starts to refine the sketch for
the next iteration. In particular, N OSDAQ generates candidate
sketches based on the grammar of its query language, such as
Project (posts ,⃗h)andMatch (posts , ϕ).
Deduction with collection abstractions. Several iterations
later, N OSDAQ encounters the following sketch Ω2
Project (Match (Unwind (posts , h1), ϕ),⃗h2)
This time, the evaluation result is {˜C2}where ˜C2= (T2, ϕ2)
where T2is{title :String}andϕ2isl0= 3∧l1≥l0∧l2≤
l1∧l3=l2, where l3corresponds to the size of ˜C2. The sketch
Ω2is still infeasible to complete, because the output document
has an additional attribute reply_count that does not match
the type T2. NOSDAQ prunes this sketch Ω2and continues to
search for a feasible sketch.
Feasible sketch. After a few more iterations, N OSDAQ finds
another sketch Ω3
Project (Match (AddFields (Group (Match (
Unwind (posts , h1), ϕ),⃗h2,⃗ a,⃗A),⃗h3,⃗E), ϕ′),⃗h4)
The evaluation result of this sketch over the abstract semantics
is a set of abstract collections Λ, meaning the result can
be some one inside Λ. Among this set, there is an abstract
collection ˜C3= (T3, ϕ3)∈Λwhere
T3:{?+
0:Any,?+
3:Num}
ϕ3:l0= 3∧l1≥l0∧l2≤l1∧l3< l2∧l4=l3∧l5≤l4∧l6=l5
Here, ?+
0and?+
3denote placeholders that can match one or
more attributes. Any denotes any value type. l6is the variable
that corresponds to the size of ˜C3. Observe that the output
example is a concretization of abstract collection ˜C3, because
thetitle matches ?+
0andreply_count matches ?+
3. In
addition, the size of the output collection is consistent with
the size of ˜C3, because l6= 2∧ϕ3is satisfiable. Therefore,
NOSDAQ finds a feasible sketch Ω3.
Sketch completion. Given a feasible sketch Ω3, N OSDAQ
aims to complete Ω3by finding instantiations of all unknown
operators in the sketch, such as h1,⃗h2,⃗ a, etc. Towards this
goal, N OSDAQ performs enumerative search and finds the
following query finally
Project (Match (AddFields (Group (Match (
Unwind (posts ,replies ),replies.depth >0),
[_id,title ],[reply_count ],[Count ()]),[title ],
[_id.title ]),reply_count >1),[reply_count ,title ])Schema S::={N17→TC1, . . . , N m7→TCm}
Collection Type TC::= Arr⟨TD⟩
Document Type TD::={a1:TV1. . . an:TVn}
Value Type TV::= TD|Arr⟨TV⟩ |TP
Primitive Type TP::= Num|String |Bool
| Datetime |ObjectId
N∈Collection Names a∈Attributes
Fig. 3: Schema of document databases.
Database D::={N17→ C 1, . . . , N m7→ Cm}
Collection C::= [ D]
Document D::={a1:v1, . . . , a n:vn}
Value v::= D|[v1, . . . , v n]|c
N∈Collection Names a∈Attributes c∈Constants
Fig. 4: Definition of document databases.
Executing this query on the input example produces exactly
the output example, so the synthesis process is finished. The
query corresponds to the following MongoDB query
db.posts.aggregate([
{$unwind: "$replies" },
{$match: {"replies.depth": {$gt: 0 }}},
{$group:
{_id: {_id: "$_id", title: "$title" },
reply_count: {$count: {}}}} ,
{$addFields: {title: "$_id.title" }},
{$match: {reply_count: {$gt: 1 }}},
{$project: {_id: 0, reply_count: 1, title: 1 }}])
III. P ROBLEM FORMULATION
In this section, we present formulations that are necessary
for the rest of the paper and formally define our problem.
A. Document Schema and Database
We first precisely define the document schema and docu-
ment database considered in this paper.
Document schema. As shown in Figure 3, a document schema
Sis a map from collection names to collection types, where
a collection type is an array of document types. A document
type is a map from attributes to different value types, including
document types, arrays, and primitive types such as Num ,
String , and Bool .
Document database. As shown in Figure 4, a document
database is a map from collection names to their corresponding
collections. A collection is an array of documents. A document
is a map from attributes to values, where the value is a
document, an array of values, or a constant of primitive types.
Typing and conformance. Figure 5 presents a set of typing
rules for conformance checking between document databases
and schemas, where judgments of the form ⊢ D:Smean the
database Dconforms to schema S.2Specifically, according to
the T-Primitive rule, the type of a constant vis simply Type(v).
2We view Null as a special value of any primitive type. If an attribute has
both null values and non-null values in some collection, then its type will be
the same as that of the non-null value.v∈Constants Type (v) =τ
⊢v:τ(T-Primitive)
⊢vi:τ i= 1, . . . , n
⊢[v1, . . . , v n] :Arr⟨τ⟩(T-Array)
D={a1:v1, . . . , a n:vn}
⊢vi:τii= 1, . . . , n
⊢D:{a1:τ1, . . . , a n:τn}(T-Doc)
D={N17→ C 1, . . . , N m7→ Cm}
⊢ Ci:τii= 1, . . . , m
⊢ D:{N17→τ1, . . . , N m7→τm}(T-DB)
Fig. 5: Rules for conformance between databases and schemas.
Query Q::= N|Project (Q,⃗h)|Match (Q, ϕ)
| AddFields (Q,⃗h,⃗E)|Unwind (Q, h)
| Group (Q,⃗h,⃗ a,⃗A)|Lookup (Q, h, h, N, a )
Predϕ::=⊤ | ⊥ | h⊙c|SizeEq (h, c)|Exists (h)
|ϕ∧ϕ|ϕ∨ϕ| ¬ϕ
Expr E::= h|h⊕h|f(h)
AggA::= Sum(h)|Avg(h)|Min(h)|Max(h)|Count ()
LogicOp ⊙::=≤ | <|=| ̸=|>| ≥
ArithOp ⊕::= + | − | × | /|%
N∈Collection Names f∈Math Functions
c∈Constants a∈Attributes h∈Access Paths
Fig. 6: Syntax of MongoDB Query. The two array parameters
of AddFields must have the same length. The last two param-
eters of Group also must have the same length.
The T-Array rule describes that all elements viin an array must
have the same type. If the element type is τ, then the array is of
type Arr⟨τ⟩. The T-Doc rule states that the type of a document
D={a1:v1, . . . , a n:vn}is{a1:τ1, . . . , a n:τn}where τi
is the type of vi. Finally, based on the T-DB rule, the schema
(or the type) of a database is basically a map from collection
names to types of their corresponding collections.
B. Query Language
Next, we describe the syntax and semantics of our query
language for document databases. The query language has a
straightforward correspondence to a core query language of
the MongoDB aggregation pipelines.
The syntax of the query language is shown in Figure 6. At
a high level, a query is a sequence of operations including
Project ,Match ,AddFields ,Unwind ,Group , and Lookup ,
where different operators take different arguments such as a
predicate ϕor an expression E. Each operator corresponds
to a stage of the MongoDB aggregation pipeline. More
specifically, the name Nsimply retrieves collection Nfrom
the database. Project (Q,⃗h)projects fields with access paths
⃗hfrom each document in the collection of Q.Match (Q, ϕ)
filters the documents in Q’s collection, retaining only those
satisfy the predicate ϕ.AddFields (Q,⃗h,⃗E)introduces new
fields ⃗hwith associated values of ⃗Eto each document in Q.
Unwind (Q, h)deconstructs an array field hin the documents
ofQ, mapping each document to a series of documents
where the value of his replaced by individual elements ofthe original array. Group (Q,⃗h,⃗ a,⃗A)groups documents of Q
based on grouping keys h, transforming each group into a
single document with new attributes ⃗ aand aggregated values
⃗A. Finally, Lookup (Q, h1, h2, N, a )adds a new attribute ato
each document of Q, where the attribute’s value is a list of
documents from a foreign collection N. This list only includes
documents whose specified field h2in the foreign collection
is the same as field h1in the original collection.
The predicate ϕcan be true ⊤, false ⊥, logical comparison
h⊙c, size equality SizeEq (h, c), existence of an access path
Exists (h), and boolean connectives. The expression Ecan be
an access path h, arithmetics h⊕h, and mathematical functions
f(h). The access path is a sequence of attributes separated by
dots such as a1.a2.a3, denoting the path to access the data
from the root document.
Example 1. Let us consider a document {_id: 1,
name: "John", class: "SE", info: {score:
90}}. The access path for the score attribute in info is
info.score .
Example 2. Consider a MongoDB query
db.coll.aggregate([ {$group:
{_id: {name: "$name", class: "$class" }},
total: {$sum: "$info.score" }}}])
It can be represented by the following query in our language
Group (coll ,[name ,class ],[total ],[Sum(info.score )])
Example 3. Consider a collection
N= [{a: 1, b: [2,3]},{a: 4, b: [5,6]}]
The evaluation result of Unwind (N, b)is
[{a: 1, b: 2},{a: 1, b: 3},{a: 4, b: 5},{a: 4, b: 6}]
C. Problem Statement
Before we state the problem to solve in this paper, let us
first define input-output examples.
Definition 1 (Input-output example) .An example Eover
schema Sis a pair (I, O)where Iis the document database
over schema S(i.e.,⊢I:S) and Ois the output collection.
Synthesis problem. Given a database schema S, a collection
name N∈dom(S), and input-output examples ⃗EoverS,
the goal of our synthesis problem is to find a query Qover
collection Nin the language shown in Figure 6 such that for
each example (I, O)∈⃗E, it holds that JQKI=O. Here, JQKI
represents the evaluation result of Qgiven input database I.
IV. A BSTRACTION FOR COLLECTIONS
In this section, we will introduce the abstraction for collec-
tions in document databases and how to compute abstractions
for queries and sketches.
Intuitively, since collections in document databases contain
an array of documents, the abstraction for collections should
contain two pieces of information: (1) the type of documentsinside the collection and (2) the sizeof the collection. Based
on this idea, we can define abstract collections and databases.
Definition 2 (Abstract collection) .An abstract collection ˜C=
(τ, ϕ)is a pair that consists of the type τof inside documents
and the formula ϕabout the collection size.
Definition 3 (Abstract database) .An abstract database ˜D=
{N17→˜C1, . . . , N m7→˜Cm}is a map from collection names
to abstract collections.
Since the synthesis process also involves partial programs
that may yield unknown attributes, values, or types in the
documents, we now augment documents with a notion of
placeholders.
Definition 4 (Placeholder) .A placeholder ?mdenotes a top-
level attribute that can match any concrete attribute and m∈
{1,+}denotes how many attributes it can match. ?1means
the placeholder matches exactly one attribute and ?+means
it can match one or more attributes.
Accordingly, we update the type of documents with place-
holders and augment attributes with a special type called Any
that represents any possible value type.
Definition 5 (Augmented type) .An augmented type Tis an
extension of the document type TDin Figure 3 where the
attribute can be a named attribute or a placeholder and its
type can be a value type TVorAny denoting any value type.
Example 4. Let us consider an augmented type
{a:String,?+
1:Any,?+
2:Num,?1
3:Arr⟨{c:Num, d:String}⟩}
Here, ?+
1is a placeholder that matches one or more attributes
of any type. ?+
2is a placeholder that matches one or more
attributes of Num type. ?1
3is a placeholder that matches
exactly one attribute corresponding to a collection where the
document is of type {c:Num, d:String}.
Next, we can lift the notion of abstract collections to cases
where placeholders are involved in the documents.
Definition 6 (Abstract collection with placeholders) .An ab-
stract collection ˜C= (T, ϕ)is a pair consisting of (1)
the augmented type Tof inside documents with potential
placeholders and (2) the formula ϕabout the collection size.
In the rest of the paper, we simply refer to abstract collec-
tions with placeholders as abstract collections, if the meaning
is clear in the context.
Definition 7 (Match) .Letτbe a document type and Tbe
an augmented type. We say τmatches T, denoted τ ◁T, if
(1) replacing ?1and?+with exactly one and at least one
attributes respectively and (2) replacing each occurrence of
Any with a value type in Tyield a type equal to τ.
Having defined the match relation between document types
and augmented types, we can define the relation between
concrete collections and abstract collections.Algorithm 1 Synthesis Algorithm
1:procedure SYNTHESIZE (S, N,⃗E)
Input: Database schema S, collection name N, input-
output examples ⃗E
Output: A query Qor⊥indicating failure
2:W ← { N}
3: while¬IsEmpty (W)do
4: Ω← W .Dequeue ()
5: ifDEDUCE (S,Ω,⃗E)then
6: Q ← COMPLETE SKETCH (S,Ω,⃗E)
7: ifQ ̸=⊥then return Q
8: W.EnqueueAll (REFINE (Ω))
9: return ⊥
Definition 8 (Collection concretization) .A collection Ccon-
cretizes an abstract collection ˜C= (T, ϕ), denoted C ⊑ ˜C, if
(1)τ ◁Twhere ⊢ C:Arr⟨τ⟩and (2) SAT(ϕ∧ln=|C|)where
n=MaxLabel (ϕ).
Intuitively, if collection Cconcretizes abstract collection
˜C= (T, ϕ), then (1) the type of documents in Cmatches
the augmented type Tof documents in ˜C; and (2) the size of
Cis consistent with the size of ˜Cdescribed by formula ϕ.
Example 5. Consider the output collection Cin Section II
[{reply_count: 3, title: "Title-3" },
{reply_count: 2, title: "Title-2" }]
Suppose ˜C= (T, ϕ)is an abstract collection where
T:{?+
0:Any,?+
2:Num}
ϕ:l0= 3∧l1≥l0∧l2≤l1∧l3< l2∧l4=l3∧l5≤l4∧l6=l5
Here, l6is the variable for the size of ˜C. First, the type
{reply_count :Num,title :String}matches the aug-
mented type T. Second, the size predicate l6= 2is consistent
with formula ϕ. Therefore, Cconcretizes ˜C.
We can also lift the concretization relation to databases and
abstract databases.
Definition 9 (DB concretization) .A database Dover
schema Sconcretizes an abstract database ˜D={N17→
˜C1, . . . , N m7→˜Cm}, denoted D ⊑ ˜D, if for all 1≤i≤m
S[Ni] =Arr⟨τi⟩ ⇔˜Ci= (τi, l0=|D[Ni]|)
V. S YNTHESIS USING COLLECTION ABSTRACTIONS
In this section, we present our synthesis technique based on
the abstraction of collections.
A. High-Level Algorithm
As shown in Algorithm 1, our synthesis algorithm adapts
the standard iterative approach based on worklists and
sketches [13], [14] to the setting of document database queries.
Given a database schema S, a collection name N, and input-
output examples ⃗E, the S YNTHESIZE procedure aims to finda query Qover schema Ssuch that it satisfies the examples
⃗E. Specifically, the worklist Wis initialized to be a singleton
queue with the simplest sketch N(Line 2). While the worklist
is not empty, the synthesis procedure enters a loop (Lines 3 –
8) that dequeues the current sketch Ω(Line 4) and checks if it
is feasible to complete (Line 5). If yes, the procedure invokes
the C OMPLETE SKETCH procedure and tries to obtain a correct
query (Lines 6–7). If the sketch is infeasible to complete or
all of its completions are incorrect, the procedure also invokes
the R EFINE procedure to transform the current sketch Ωto a
set of sketches based on the grammar in Figure 6 (Line 8).
This synthesis procedure is repeated until a correct query Q
is found (Line 7) or returns ⊥if the worklist is empty.
B. Sketch Enumeration and Refinement
Definition 10 (Sketch) .A sketch Ωis a query Qwhere only the
collection name is known and other arguments are unknown.
Example 6. Let us consider again the following sketch from
the motivating example.
Project (Match (Unwind (posts , h1), ϕ),⃗h2)
Here, the collection name posts is known, but access path
h1, predicate ϕ, and access paths ⃗h2are unknown.
Given a sketch Ωover collection N, the R EFINE
procedure substitutes the collection Nwith all possible
query operators shown in Figure 6 and obtains a set
SΩ={Project (N,⃗h),Match (N, ϕ),AddFields (N,⃗h,⃗E),
Unwind (N, h),Group (N,⃗h,⃗ a,⃗A),Lookup (N, h, h, N, a )}
and produces six new sketches. The refined sketches are
{Ω[Ωi/N]|Ωi∈SΩ}
C. Abstract Semantics
Since the key novelty of our synthesis technique is perform-
ing deduction on collection abstractions to prune infeasible
sketches, we first introduce the abstract semantics of executing
sketches over abstract collections.
At a high level, the abstract semantics is consistent with
the concrete semantics in describing how an operator mod-
ifies the collection size and the type of its documents, but
it applies to the abstract database. Formally, the abstract
semantics is defined in Figure 7, where judgments of the
form ˜D, τO⊢Ω⇓Λmean that a sketch Ωevaluates to a
set of abstract collections Λgiven an abstract database ˜D
and the output document type τO. Specifically, by the A-
Collection rule, the only abstract collection for query Ncan be
obtained by looking up the abstract database ˜D. By A-Match,
Match reduces the collection size without changing the type
of its inside documents. By A-Project, Project preserves the
collection size but modifies the document type. In particular,
the output document only retains a subset of the original
attributes, and the remaining attributes can be inferred from
the output. According to A-AddFields, AddFields adds one or
more attributes of Any type without changing the size of the
collection. By the A-Unwind rule, Unwind (Ω, h)potentially˜C=˜D[N]
˜D, τO⊢N⇓ {˜C}(A-Collection)
˜D, τO⊢Ω⇓Λ (T, ϕ)∈Λ
(T, ϕ∧lj≤li)∈Λ′
Id(Ω) = iId(Match (Ω, P)) =j
˜D, τO⊢Match (Ω, P)⇓Λ′(A-Match)
˜D, τO⊢Ω⇓Λ (T, ϕ)∈Λ
τk=ToDocType (T)
((T −τk)∪(τk∩τO), ϕ∧lj=li)∈Λ′
Id(Ω) = iId(Project (Ω,⃗h)) =j
˜D, τO⊢Project (Ω,⃗h)⇓Λ′(A-Project)
˜D, τO⊢Ω⇓Λ (T, ϕ)∈Λ
(T ∪{?+
0:Any}, ϕ∧lj=li)∈Λ′
Id(Ω) = iId(AddFields (Ω,⃗h,⃗E)) =j
˜D, τO⊢AddFields (Ω,⃗h,⃗E)⇓Λ′(A-AddFields)
˜D, τO⊢Ω⇓Λ (T, ϕ)∈Λ
Type(aA) =Arr⟨τ⟩ ∧NotInArr (aA)
{(T[τ/aA], ϕ∧lj≥li)|aA∈ T ∧ ∀ p.∀q.aA̸=?q
p} ⊆Λ′
Id(Ω) = iId(Unwind (Ω, h)) =j
˜D, τO⊢Unwind (Ω, h)⇓Λ′(A-Unwind)
˜D, τO⊢Ω⇓Λ (T, ϕ)∈Λ
F={ToDocType (˜D[N]T)|N∈dom(˜D)}
{(T ∪{?1
j:Arr⟨τF⟩}, ϕ∧lj=li)|τF∈F} ⊆Λ′
Id(Ω) = iId(Lookup (Ω, h, h, N, a )) =j
˜D, τO⊢Lookup (Ω, h, h, N, a )⇓Λ′(A-Lookup)
˜D, τO⊢Ω⇓Λ (T, ϕ)∈Λ
G={{?+
j:Num},{}}
{({_id: τK} ∪τg, ϕ∧lj< li)
|τK⊆ToDocType (T)∧τg∈G} ⊆Λ′
Id(Ω) = iId(Group (Ω,⃗h,⃗ a,⃗A) =j
˜D, τO⊢Group (Ω,⃗h,⃗ a,⃗A)⇓Λ′(A-Group)
Fig. 7: Abstract Semantics. The ToDocType function trans-
forms an augmented type to a document type by deleting all
placeholder attributes and the attributes with Any type. The
NotInArr checks whether an attribute is not nested in an array
type otherwise it is unable to be unwinded.
increases the collection size, deconstructs the array hof sketch
Ω, and updates the type accordingly. By the A-Lookup rule,
Lookup preserves the collection size but introduces a new
attribute to the T, where the type of the new attribute is
the same as that of the foreign collection. Finally, as shown
in the A-Group rule, Group reduces the collection size and
constructs a new type. In particular, it introduces a new
attribute _id as the key and uses a new τgto represent a
series of numeric attributes for aggregation results. τgcan also
be empty, indicating the absence of aggregation attributes.
Example 7. Consider again the following sketch in Section II
Project (Match (Unwind (posts , h1), ϕ),⃗h2)
Based on the rules in Figure 8, we recursively evaluate the
sketch. The evaluation result of posts is
{({_id:String ,title :String ,replies :
Arr⟨{depth :Num}⟩}, l0= 3)}The result of Unwind (posts , h1)is
{({_id:String ,title :String ,replies :
{depth :Num}}, l0= 3∧l1≥l0)}
The result of Match (Unwind (posts , h1), ϕ)is
{({_id:String ,title :String ,replies :
{depth :Num}}, l0= 3∧l1≥l0∧l2≤l1)}
The result of Project (Match (Unwind (posts , h1), ϕ),⃗h2) is
{({title :String}, l0= 3∧l1≥l0∧l2≤l1∧l3=l2)}
Next, we establish the relationship among queries, sketches,
concrete semantics, and abstract semantics with a theorem.
Theorem 1. Let˜Dbe an abstract database over schema S,Ω
be a sketch, Qbe a query that is a completion of Ω, and (I, O)
be an input-output example, where ⊢I:Sand⊢O:Arr⟨τO⟩.
IfJQKI=O,I⊑˜D, and ˜D, τO⊢Ω⇓Λ, then there exists
an abstract collection ˜C ∈Λsuch that O⊑˜C.
Intuitively, the theorem states that the abstract semantics is
correct with respect to the concrete semantics. In particular, if
the input is a concretization of the abstract database and the
query is a completion of the sketch, then the evaluation result
of the sketch on the abstract database is an over-approximation
of the output produced by executing the query on the input.
D. Deduction by Collection Abstractions
Next, let us present how to perform deduction based on the
collection abstractions.
Deduction algorithm. Our deduction algorithm is shown in
Algorithm 2. For each example Ej= (Ij, Oj), we compute
the document type in Oj. The C OMPUTE TYPE computes the
type of Ojby the typing rules in Figure 5 (Line 4). Then the
Infunction extracts the document type from the type of Oj,
namely In(Arr⟨τ⟩) =τ. We also compute the abstract input
database ˜Djby computing all the abstractions of collections in
the database (Line 5). Each collection name Niis mapped to
an abstract collection whose augmented type is the document’s
type inside the collection and the predicate is l0equals the
collection size. For all pairs of abstract input database ˜Djand
output document type τOj, we evaluate the sketch Ωbased on
the abstract semantics in Figure 7 and get a set of abstract
collections for each example (Line 6). If for each example
(Ij, Oj), there is an abstract collection ˜C ∈Λjsuch that Ojis
a concretization of ˜C, then the sketch is feasible to complete
(Line 7). Otherwise, the sketch is infeasible.
Concretization check. Recall from Definition 8 that to check
a collection Cis a concretization of abstract collection ˜C=
(T, ϕ), we need to check (1) the type τof documents inside
Cmatches T, i.e. τ ◁T, and (2) the size of Cis consistent
with the formula ϕ. We use an off-the-shelf SMT solver to
check condition (2) by checking the satisfiability of formula
ϕ∧ln=|C|where n=MaxLabel (ϕ). We also develop a
procedure for type match based on Definition 7, which can be
best explained with the following example.Algorithm 2 Deduction by Abstract Collections
1:procedure DEDUCE (S,Ω,⃗E)
Input: The database schema S, a sketch Ωand input-
output examples ⃗E
Output: ⊤ifΩis feasible otherwise ⊥
2: forj←1to|⃗E|do
3: (Ij, Oj)← E j
4: τOj←In(COMPUTE TYPE(Oj))
5: ˜Dj← {Ni7→(In(S[Ni]), l0=|Ij[Ni])|Ni∈dom(S))}
6: Λj←EVAL(˜Dj, τOj,Ω)
7: if∀j.∃˜C.˜C ∈Λj∧Oj⊑˜Cthen return ⊤
8: else return ⊥
Example 8. Suppose we have an augmented type
T={name :String ,id:String ,info :{tel:String},
?+
1:Num,?+
2:Any,
?1
3:Arr⟨{profId :String ,profName :String}⟩}
and document type τ
{id:String ,name :String ,info :{tel:String},
newField :Bool,sum:Num,
profs :Arr⟨{profId :String ,profName :String}⟩}
Here,{name :String ,id:String ,info :{tel :String}}
inTis matched by {name :String ,id:String ,info :
{tel :String}}inτ, because the corresponding attributes
have the same names and types. {?1
3:Arr⟨{profId :
String ,profName :String}⟩} is matched by {profs :
Arr⟨{profId :String ,profName :String}⟩}, because
profs has the same type as placeholder ?1
3and?1
3matches
exactly one attribute. Finally, {?+
1:Num}is matched by
{sum :Num}because they have the same type, and {?+
2:
Any}is matched by {newField :Bool}because Any can
match any value type.
To understand why our deduction algorithm is correct, let
us consider the following theorem.
Theorem 2. Given a database schema S, a sketch Ω, and
input-output examples ⃗E, ifDEDUCE (S,Ω,⃗E)returns ⊥, then
there is no completion QofΩsuch that for all (I, O)∈⃗E,
JQKI=O.
Intuitively, the theorem states that our deduction-based
pruning is sound. In other words, if the deduction algorithm
returns ⊥for a sketch, then no completions of the sketch
satisfy all the input-output examples.
E. Sketch Completion
The C OMPLETE SKETCH takes as input a schema S, a
sketch Ω, and input-output examples ⃗Eand returns a query
Qsatisfying all examples or ⊥if such a query does not exist.
We use an enumerative search algorithm to fill unknowns in
the sketch according to the query operators.1)Project . We compute the common attributes in the input
and output and use these common attributes as arguments.
2)Match . We enumerate all predicates obtained from a com-
bination of access paths, constants, comparisons, and logic
connectives. Also, the observational equivalent class is used
to avoid duplicate predicates.
3)AddFields . We enumerate all possible expressions for
newly generated attributes.
4)Unwind . We enumerate all array attributes in the top level
of the document and unwind them.
5)Group . We enumerate all group keys and accumulators and
use value-based analysis to prune impossible accumulators.
6)Lookup . We enumerate all foreign collections and their
attributes as arguments.
In addition, we also perform type checking to prune im-
possible arguments. For instance, if the value for a newly
generated attribute has a different type than it should be in
the output, we prune this completion from the search space.
We now conclude this section with two theorems about the
overall synthesis algorithm.
Theorem 3 (Soundness) .LetSbe a database schema, ⃗E
be input-output examples, and Nbe a collection name. Sup-
pose COMPLETE SKETCH is sound, if SYNTHESIZE (S,⃗E, N)
returns a query Q, then Qsatisfies examples ⃗E.
Theorem 4 (Completeness) .LetSbe a database schema, ⃗E
be input-output examples, and Nbe a collection name. Sup-
pose COMPLETE SKETCH is complete, if there exists a query
accepted by the grammar in Figure 6 that is over collection
Nand satisfies examples ⃗E, then SYNTHESIZE (S,⃗E, N)does
not return ⊥.
Intuitively, the soundness theorem states that if the synthesis
algorithm returns a query, then the query satisfies all input-
output examples. The completeness theorem ensures that if
there exists a query in our language satisfying all input-output
examples, then the synthesis algorithm can find a query.
VI. I MPLEMENTATION
We have implemented the proposed synthesis technique in
a tool called N OSDAQ and use Z3 [11] as the SMT solver.
Heuristics for sketch completion. Based on the observation
that most Group operators do not have more than two group
keys, we limit the number of group keys to two during sketch
completion. In addition, although N OSDAQ supports simple
constants (e.g., null) in sketch completion, it expects the user
to provide more complicated constants such as string literals.
Translation to MongoDB queries. NOSDAQ performs syntax-
directed translation to transform the document database query
in its domain-specific language to the MongoDB query lan-
guage. Furthermore, it also performs optimizations to improve
the conciseness and efficiency of translated queries, such as
merging continuous AddFields andProject operators.TABLE I: Statistics of datasets. #nis the number of bench-
marks. #a,#d,#e,#i,#o,#cdenote the average number of
document attributes, document depths, examples, collection
sizes in input and output examples, and constants, respectively.
dataset #n #a #d #e #i #o #c
StackOverflow 33 4.9 1.5 2.5 2.4 1.4 0.9
MongoDB Document 26 5.4 1.4 1.1 4.7 2.6 0.6
Twitter API 5 18.4 2.6 1.0 2.0 2.6 0.0
Kaggle 46 19.8 4.1 1.0 1.8 3.6 0.5
Total 110 11.9 2.6 1.5 2.6 2.3 0.6
TABLE II: Statistics of ground truth queries. #s,#op,#P,
#M,#L,#U,#G,#Adenote the number of AST nodes,
query operators, Project ,Match ,Lookup ,Unwind ,Group ,
AddFields , respectively.
dataset #s #op #P #M #L #U #G #A
Stack-
Overflowavg 12 1.88 0.42 0.79 0.03 0.27 0.36 0
med 10 1 0 1 0 0 0 0
min 4 1 0 0 0 0 0 0
max 33 5 1 2 1 2 2 0
Official
Documentavg 8 1.15 0.31 0.42 0.04 0.08 0.27 0.04
med 7 1 0 0 0 0 0 0
min 4 1 0 0 0 0 0 0
max 17 3 1 1 1 2 1 1
Twitter
APIavg 16 2.6 0.8 0 0 1 0.6 0.2
med 14 2 1 0 0 1 1 0
min 9 2 0 0 0 0 0 0
max 26 4 1 0 0 2 1 1
Kaggleavg 13 3.2 0.7 0.52 0 1.54 0.43 0
med 12 3 1 0 0 2 0 0
min 8 2 0 0 0 0 0 0
max 27 6 1 2 0 3 2 0
Totalavg 12 2.29 0.53 0.55 0.02 0.79 0.38 0.02
med 11 2 1 1 0 1 0 0
min 4 1 0 0 0 0 0 0
max 33 6 1 2 1 3 2 1
VII. E VALUATION
In this section, we present several experiments that are
designed to answer the following research questions.
RQ1. Is N OSDAQ effective and efficient to synthesize docu-
ment database queries from input-output examples?
RQ2. How does each component of the collection abstraction
affect synthesis time?
RQ3. How does N OSDAQ compare against other baseline
synthesizers?
RQ4. How does the collection size of input-output examples
impact the performance of N OSDAQ ?
Experimental setup. All experiments are conducted on a
machine with an Intel i9-13905H CPU and 32 GB of physical
memory, running the Ubuntu 22.04 WSL2 operating system.
A. Benchmarks
We have collected 110 benchmarks from 4 representative
sources, i.e., StackOverflow, MongoDB official document,
Twitter API documents, and Kaggle competitions, which cover
a wide spectrum of realistic scenarios.
•StackOverflow. The StackOverflow dataset is adapted from
StackOverflow posts where developers ask about real-world
problems. Each post in our dataset has 453K visits, 4answers, and 127 votes on average, which demonstrates
these queries attract lots of attention from the community.
Most of the the examples and constants are extracted from
the post content. If some post does not provide enough
examples, we add the examples.
•MongoDB Document. The MongoDB official documents
cover a representative set of queries that the MongoDB
community believes are commonly used in practice. The
examples and constants are all collected from the example
section of official documents.
•Twitter API. The Twitter dataset consists of tweets and user
replies which mainly focus on calculating tweet statistics,
such as the count of replies. The benchmarks represent typ-
ical scenarios for data analysts to get information from social
networks and online forums. The examples are collected
from the response data of APIs.
•Kaggle. The Kaggle dataset contains information about
satellite images, where benchmarks reflect scenarios for
scientific research, such as extracting different labels for
training machine learning models and collecting statistics.
The examples are sampled from the provided JSON file.
Table I summarizes the statistics of these datasets. Among
these datasets, Twitter API and Kaggle benchmarks are more
complex than StackOverflow and MongoDB Document in
terms of the number of attributes, collection sizes, etc.
To further understand the complexity of benchmarks, we
have also collected the statistics on the ground truth queries
in Table II. The maximum AST size of ground truth queries
is 33 among all benchmarks, and the average is 12. Over half
of the ground truth queries have an AST size larger than 10.
This indicates a high level of complexity, as longer queries
typically require synthesizers to explore a larger search space.
Furthermore, the number of operators (or pipeline stages) in
a single query ranges from 1 to 6. Frequently occurring oper-
ators include Project ,Match ,Unwind , and Group . Notably,
Unwind andGroup pose significant challenges for synthesis,
as they can substantially change the structure of collections
and documents. In contrast, the Lookup operator appears
infrequently in ground truth queries. This is consistent with the
typical usage of document databases where users try to avoid
“join” operations between multiple collections. Similarly, the
AddFields operator is also not used frequently in our datasets.
B. Effectiveness and Efficiency
The evaluation results and the statistics of synthesized
programs are presented in Table III. Given a time limit of 5
minutes, N OSDAQ can solve 108 out of 110 benchmarks and
only gets timeout on two challenging benchmarks (both in
Kaggle). Note that the ground-truths of these two benchmarks
are more complex than the others from our manual inspection.
This serves as evidence of the effectiveness of N OSDAQ
in synthesizing document database queries from examples.
Further, N OSDAQ can solve most benchmarks in an average of
14.2 seconds as shown in Table III. Furthermore, observing the
number of sketches # Ωand complete programs # Q, NOSDAQ
iterates over 175 sketches but only completes 57 full programsTABLE III: Evaluation results for N OSDAQ .#nand!denote
the number of benchmarks and solved benchmarks, and time
indicates the time (in seconds) to solve benchmarks. #Ω,#Q,
#size refer to the number of sketches, complete programs, and
AST nodes of synthesized programs, respectively.
dataset #n! time (s) #Ω #Q #size
Stack-
Overflow33 33avg 9.2 86 31 12
med 2.6 15 6 11
min 0.5 2 1 4
max 184.5 854 308 32
MongoDB
Document26 26avg 5.7 11 53 9
med 1.1 6 14 10
min 0.5 2 1 4
max 78.6 124 576 19
Twitter
API5 5avg 10.5 81 61 15
med 10.1 36 81 15
min 1.8 15 1 9
max 19.9 165 131 22
Kaggle 46 44avg 23.4 350 79 16
med 6.8 160 4 13
min 1.0 8 1 8
max 201.6 3975 1235 38
Total 110 108avg 14.2 175 57 13
med 3.2 31 7 11
min 0.5 2 1 4
max 201.6 3975 1235 38
on average. It demonstrates that our synthesis technique based
on collection abstractions is efficient in pruning infeasible
sketches and thus speeds up the synthesis process.
Qualitative analysis. We observe that the number of attributes
in the document, the depth of the document, the number of
constants, and the query complexity affect the synthesis time.
For instance, the Kaggle dataset needs longer synthesis time
than others because the benchmark has a large number of
attributes and the documents are deeply nested. In general,
more complex queries need the synthesizer to iterate more
sketches. More attributes, deeper nesting, and more constants
require enumerating more queries while completing the sketch.
Non-desired programs. To understand if N OSDAQ can syn-
thesize desired queries, we have manually inspected all 108
synthesized queries and found 107 of them are equivalent
to the desired ones. There is only one benchmark (from
StackOverflow) where N OSDAQ synthesized a plausible query
in terms of the example but the query is not desired. The
reason is that this benchmark involves a complex predicate that
requires numerous unseen examples to eliminate mismatch
cases. However, only a few examples are provided on the
StackOverflow post, so N OSDAQ cannot find the desired
predicate but synthesize an alternative satisfying the examples.
Answer to RQ1 : NOSDAQ successfully synthesizes 108 out
of 110 benchmarks from examples and the average synthesis
time is 14.2 seconds.
C. Ablation Study
To understand how the type and size information in col-
lection abstractions may affect the efficiency, we perform an
ablation study. Specifically, we have created three variants of
NOSDAQ that disable (1) the size information, (2) the type0 20 40 60 80 100 110
#Solved benchmarks050100150200250300Time (s)
Nosdaq
Nosdaq w/o Size
Nosdaq w/o Type
Nosdaq w/o Size & TypeFig. 8: Ablation study.
0 20 40 60 80 100 110
#Solved benchmarks050100150200250300Time (s)
Nosdaq EUSolver
Fig. 9: Comparison between N OSDAQ and EUS OLVER .
information, and (3) both size and type information in the
abstraction. We run all these variants on the 110 benchmarks
and obtain the result shown in Figure 8, where a point (x, y)
means a variant can synthesize xbenchmarks and the time for
each benchmark is within yseconds. As shown in the figure,
without size in the abstraction, the variant times out on 4 more
benchmarks and requires approximately 10 seconds longer
on average. Without type, the variant triggers timeout on 19
more benchmarks and requires around 27 seconds longer on
average to complete the synthesis process. This indicates that
the document type in the collection abstraction significantly
improves the synthesis time.
Answer to RQ2 : Both type and size information can make
NOSDAQ more efficient but the former is more significant.
D. Comparison with Baselines
To compare N OSDAQ with a baseline, we have instanti-
ated the EUS OLVER framework [1] to synthesize document
database queries from examples. As a generic solver, EU-
SOLVER can be easily extended to support documents and
collections in the specification, since it provides necessary
support for lists and maps. Secondly, EUS OLVER remains a
competitive baseline in program synthesis, as evidenced from
recent work [4], [22], [31]. As shown in Figure 9, as opposed
to 108 benchmarks solved by N OSDAQ , EUS OLVER can only
solve 25 benchmarks within the 5-minute time limit due to the
large search space of document database queries in general.
To compare N OSDAQ with the LLM-based approach, we
have used ChatGPT (version gpt-4o-2024-08-06) to synthesize
all of our 110 benchmarks. Specifically, we have used the
same set of input-output examples and constants in each
benchmark and asked ChatGPT to generate MongoDB queries.
To make fair comparisons, we did not provide additional
natural language descriptions about what the query should do.
The evaluation shows that GPT can only generate the desired
0 2 4 6 8 10
#Collection size051015202530Time (s)
Median AverageFig. 10: Impact of collection size on synthesis time.
0 2 4 6 8 10
#Collection size5060708090100Rate (%)
Desired Plausible
Fig. 11: Impact of collection size on rates of plausible and
desired queries.
query for 53 out of 110 benchmarks. For 24 benchmarks, the
generated query is plausible but undesired, i.e., it is consistent
with the examples but not equivalent to the desired one. For the
remaining 33 benchmarks, the generated query is inconsistent
with the input-output examples. The errors made by GPT
include misunderstanding the semantics of operators, missing
predicates, etc. Recall that N OSDAQ can synthesize desired
queries for 107 benchmarks and plausible but undesired query
for 1 benchmark. We believe our synthesis technique is more
effective and generalizable than GPT to synthesize document
database queries from examples.
Answer to RQ3 : NOSDAQ can solve 108 out of 110 bench-
marks, whereas EUS OLVER can only solve 25 benchmarks,
and ChatGPT-4o can solve 77 benchmarks.
E. Impact of Collection Size
To analyze the impact of collection size on the performance
of N OSDAQ , we have conducted experiments across all 110
benchmarks to evaluate how different collection sizes influence
NOSDAQ ’s behavior. Specifically, we sampled 10 documents
for each collection and ran N OSDAQ on variants with collec-
tion sizes ranging from 1 to 10 documents. The impact on
synthesis time is presented in Figure 10, while the impact on
rates of plausible and desired queries are shown in Figure 11.
The plausible rate is defined as the ratio of benchmarks
synthesized within a 5-minute time limit to the total number
of benchmarks. The desired rate represents the ratio of bench-
marks for which the synthesized query is equivalent to the
desired one to the total number of synthesized benchmarks.
As shown in the figures, the synthesis time of N OSDAQ
remains relatively insensitive to changes in collection size
within the range of 1 to 10 documents in each collection.
Similarly, the plausible rate also remains stable. In contrast, the
desired rate shows a significant increase when the collection
size grows from 1 to 3, after which it stabilizes. This can
be attributed to the fact that smaller collection sizes provide
insufficient examples to synthesize the desired query, leading
to simpler queries that are plausible but not desired.Answer to RQ4 : The synthesis time of N OSDAQ demon-
strates minimal sensitivity to changes in collection size. The
rate of synthesizing a desired query increases rapidly as the
collection size grows from 1 to 3 and stabilizes thereafter.
F . Threats to Validity
First, although we believe our datasets are representative,
which are obtained from various real-world scenarios, our
evaluation results are limited to the collected datasets. The
NOSDAQ tool might perform differently on other datasets.
Second, our domain-specific language only corresponds to a
core subset of the MongoDB aggregation pipeline. While it
is convenient to extend the abstract semantics to other query
operators, the performance of the tool might be different due
to the change in SMT formulas for symbolic reasoning. Third,
all the experiments are conducted on a machine as specified in
Section VII. Running the experiments on a different machine
may yield different results.
VIII. R ELATED WORK
Program synthesis for software engineering. Program synthe-
sis techniques have been applied to address various software
engineering problems, such as program refactoring [9], [32],
[36], [38], program repair [25], [27], [33], [49], code com-
pletion [16], [39], software testing [42], [54], and so on. This
paper focuses on the topic of generating document database
queries from input-output examples.
Synthesizing database queries. Among related papers, the
most related is a body of work on synthesizing database
queries. SQLS YNTHESIZER [53], S CYTHE [46] and PAT-
SQL [43] synthesize SQL queries for relational databases
from examples, while S ICKLE [55] synthesizes analytical SQL
queries given computation demonstrations. SQL IZER [52]
considers nature language description as the specification for
SQL query synthesis. However, none of the prior work can
synthesize queries of document databases such as MongoDB.
Synthesis with deduction. A line of work performs deduc-
tion to prune infeasible programs in program synthesis [7],
[8], [13]–[15], [21], [23], [24], [35], [37]. For example,
MORPHEUS [14] and N EO[13] utilize SMT-based deduc-
tion that generates formulas based on semantics and input-
output examples to prune infeasible programs. NGDS [23]
and C ONCORD [8] combine deduction and machine learning
techniques to prune the search space. N OSDAQ adapts the
high-level approach of M ORPHEUS [14] and N EO[13] to the
setting of document database queries. However, M ORPHEUS
mainly focuses on tabular data, whereas N OSDAQ focuses
on hierarchical data. The abstraction used by M ORPHEUS is
related to the number of rows and columns of tables. This
abstraction cannot be directly used for deduction in a synthe-
sizer that aims to generate document database queries, because
these queries operate over more involved hierarchical data.
Therefore, N OSDAQ uses the novel abstraction consisting of
hierarchically nested types for its documents and the collection
size, which is one of the main contributions of this paper.Synthesis with abstraction. Another line of related work is to
synthesize programs using abstractions [19], [28], [41], [45],
[47]. For example, S IMPL [41] uses abstract interpretation to
guide the synthesis of imperative programs from examples.
Mell et al. [28] also use abstract interpretation for optimal
program synthesis. B LAZE [47] constructs and iteratively
refines the abstract finite tree automata that represent a set
of programs. This approach iteratively prunes and refines
automata when the corresponding programs do not satisfy
examples, until a correct program is found. Unlike prior
techniques, N OSDAQ employs a novel collection abstraction
to represent complex hierarchical data (e.g., BSON) and uses
abstract semantics to rule out infeasible sketches representing
a large set of programs.
Wrangling semi-structured data. Various techniques have
been proposed to wrangle semi-structured data, such as
JSON, XML documents, spreadsheets, and log files. For
example, there is a line of work [2], [3], [40], [44] that
aims to map XML documents to relational data for query
processing. D ATAMARAN [17] converts the semi-structured
log into a structured relational format. F LASH EXTRACT [24]
extracts relevant data from text files, websites, and spread-
sheets. F LASH RELATE [5] extracts relational data from semi-
structured spreadsheets by examples. T REEX [34] synthesizes
extractors for real-world large-scale websites. Since document
databases store semi-structured data by nature, N OSDAQ can
also be viewed as a query synthesizer over semi-structured
data. However, different from prior work, N OSDAQ focuses
on core query language of document databases and aims to
address significant challenges raised by specialized operators
such as Group ,Unwind , and Lookup .
Synthesizing data transformation scripts. Many synthesizers
aim to automatically generate data transformation scripts from
high-level specifications [6], [12], [14], [18], [20], [26], [50],
[51]. For example, H ADES [50] synthesizes scripts to handle
hierarchically structured data such as file systems, XML, and
HDF files. M ITRA [51] aims to synthesize scripts to convert
hierarchical data into relational tables. D YNAMITE [48] trans-
forms data between various types of databases by synthesizing
Datalog programs. In contrast, N OSDAQ is designed to handle
complex data structures in document databases and leverage
collection abstractions to efficiently synthesize queries from
examples, which is beyond the capability of prior work.
For instance, H ADES focuses on structure changes in the
transformation but does not support aggregations, but N OSDAQ
can synthesize aggregate queries with Group operations.
IX. C ONCLUSION
This paper presents a technique that automatically synthe-
sizes document database queries from input-output examples.
To achieve better performance, we develop a novel abstrac-
tion for collections containing hierarchical and nested data
structures and leverage this abstraction for deduction to prune
the search space of target queries. An evaluation of 110
benchmarks from various sources demonstrates our technique
is effective and efficient in solving 108 benchmarks.REFERENCES
[1] Rajeev Alur, Arjun Radhakrishna, and Abhishek Udupa. Scaling enu-
merative program synthesis via divide and conquer. In Proceedings of the
International Conference on Tools and Algorithms for the Construction
and Analysis of Systems (TACAS) , pages 319–336, 2017.
[2] Sihem Amer-Yahia, Fang Du, and Juliana Freire. A comprehensive
solution to the xml-to-relational mapping problem. In Proceedings
of the ACM International Workshop on Web Information and Data
Management (WIDM) , page 31–38, 2004.
[3] Mustafa Atay, Artem Chebotko, Dapeng Liu, Shiyong Lu, and Farshad
Fotouhi. Efficient schema-based xml-to-relational data mapping. Infor-
mation Systems , 32(3):458–476, 2007.
[4] Celeste Barnaby, Qiaochu Chen, Roopsha Samanta, and Isil Dillig.
Imageeye: Batch image processing using program synthesis. Proc. ACM
Program. Lang. , 7(PLDI):686–711, 2023.
[5] Daniel W. Barowy, Sumit Gulwani, Ted Hart, and Benjamin Zorn.
Flashrelate: extracting relational data from semi-structured spreadsheets
using examples. In Proceedings of the 36th ACM SIGPLAN Conference
on Programming Language Design and Implementation , PLDI, page
218–228. ACM, 2015.
[6] Rohan Bavishi, Caroline Lemieux, Roy Fox, Koushik Sen, and Ion
Stoica. Autopandas: neural-backed generators for program synthesis.
Proc. ACM Program. Lang. , 3(OOPSLA), oct 2019.
[7] Qiaochu Chen, Xinyu Wang, Xi Ye, Greg Durrett, and Isil Dillig. Multi-
modal synthesis of regular expressions. In Proceedings of the 41st
ACM SIGPLAN Conference on Programming Language Design and
Implementation , PLDI, page 487–502. ACM, 2020.
[8] Yanju Chen, Chenglong Wang, Osbert Bastani, Isil Dillig, and Yu Feng.
Program synthesis using deduction-guided reinforcement learning. In
International Conference on Computer Aided Verification , pages 587–
610. Springer, 2020.
[9] Yanju Chen, Yuepeng Wang, Maruth Goyal, James Dong, Yu Feng, and
Isil Dillig. Synthesis-powered optimization of smart contracts via data
type refactoring. Proc. ACM Program. Lang. , 6(OOPSLA2):560–588,
2022.
[10] CouchDB. https://couchdb.apache.org, 2024.
[11] Leonardo Mendonc ¸a de Moura and Nikolaj S. Bjørner. Z3: an efficient
SMT solver. In Proceedings of the International Conference on Tools
and Algorithms for the Construction and Analysis of Systems (TACAS) ,
pages 337–340. Springer, 2008.
[12] Ian Drosos, Titus Barik, Philip J. Guo, Robert DeLine, and Sumit
Gulwani. Wrex: A unified programming-by-example interaction for
synthesizing readable code for data scientists. In Proceedings of the
2020 CHI Conference on Human Factors in Computing Systems , CHI,
page 1–12. ACM, 2020.
[13] Yu Feng, Ruben Martins, Osbert Bastani, and Isil Dillig. Program
synthesis using conflict-driven learning. In Proceedings of the 39th
ACM SIGPLAN Conference on Programming Language Design and
Implementation , PLDI, page 420–435. ACM, 2018.
[14] Yu Feng, Ruben Martins, Jacob Van Geffen, Isil Dillig, and Swarat
Chaudhuri. Component-based synthesis of table consolidation and
transformation tasks from examples. In Proceedings of the 38th
ACM SIGPLAN Conference on Programming Language Design and
Implementation , PLDI, page 422–436. ACM, 2017.
[15] John K. Feser, Swarat Chaudhuri, and Isil Dillig. Synthesizing data
structure transformations from input-output examples. In Proceedings of
the 36th ACM SIGPLAN Conference on Programming Language Design
and Implementation , PLDI, page 229–239. ACM, 2015.
[16] Joel Galenson, Philip Reames, Rastislav Bod ´ık, Bj ¨orn Hartmann, and
Koushik Sen. Codehint: dynamic and interactive synthesis of code
snippets. In International Conference on Software Engineering (ICSE) ,
pages 653–663. ACM, 2014.
[17] Yihan Gao, Silu Huang, and Aditya Parameswaran. Navigating the
data lake with datamaran: Automatically extracting structure from log
datasets. In Proceedings of the 2018 International Conference on
Management of Data , SIGMOD, page 943–958. ACM, 2018.
[18] Sumit Gulwani. Automating string processing in spreadsheets using
input-output examples. In Proceedings of the 38th Annual ACM
SIGPLAN-SIGACT Symposium on Principles of Programming Lan-
guages , POPL, page 317–330. ACM, 2011.
[19] Zheng Guo, Michael James, David Justo, Jiaxiao Zhou, Ziteng Wang,
Ranjit Jhala, and Nadia Polikarpova. Program synthesis by type-guided
abstraction refinement. Proc. ACM Program. Lang. , 4(POPL), dec 2019.[20] William R. Harris and Sumit Gulwani. Spreadsheet table transformations
from examples. In Proceedings of the 32nd ACM SIGPLAN Conference
on Programming Language Design and Implementation , PLDI, page
317–328. ACM, 2011.
[21] Kangjing Huang, Xiaokang Qiu, Peiyuan Shen, and Yanjun Wang. Rec-
onciling enumerative and deductive program synthesis. In Proceedings
of the 41st ACM SIGPLAN Conference on Programming Language
Design and Implementation , PLDI, page 1159–1174. ACM, 2020.
[22] Ruyi Ji, Chaozhe Kong, Yingfei Xiong, and Zhenjiang Hu. Improving
oracle-guided inductive synthesis by efficient question selection. Proc.
ACM Program. Lang. , 7(OOPSLA1):819–847, 2023.
[23] Ashwin Kalyan, Abhishek Mohta, Oleksandr Polozov, Dhruv Batra,
Prateek Jain, and Sumit Gulwani. Neural-guided deductive search for
real-time program synthesis from examples. In International Conference
on Learning Representations (ICLR) . OpenReview.net, 2018.
[24] Vu Le and Sumit Gulwani. Flashextract: a framework for data extraction
by examples. In Proceedings of the 35th ACM SIGPLAN Conference
on Programming Language Design and Implementation , PLDI, page
542–553. ACM, 2014.
[25] Fan Long and Martin C. Rinard. Staged program repair with condition
synthesis. In Proceedings of the Joint Meeting on Foundations of
Software Engineering (ESEC/FSE) , pages 166–178. ACM, 2015.
[26] Ruben Martins, Jia Chen, Yanju Chen, Yu Feng, and Isil Dillig. Trinity:
an extensible synthesis framework for data science. Proc. VLDB Endow. ,
12(12):1914–1917, aug 2019.
[27] Sergey Mechtaev, Jooyong Yi, and Abhik Roychoudhury. Angelix:
scalable multiline program patch synthesis via symbolic analysis. In
Proceedings of the International Conference on Software Engineering
(ICSE) , pages 691–701. ACM, 2016.
[28] Stephen Mell, Steve Zdancewic, and Osbert Bastani. Optimal program
synthesis via abstract interpretation. Proc. ACM Program. Lang. ,
8(POPL):457–481, 2024.
[29] MongoDB. https://www.mongodb.com, 2024.
[30] MongoDB. Why use mongodb and when to use it? https://www.
mongodb.com/resources/products/fundamentals/why-use-mongodb,
2024.
[31] Amirmohammad Nazari, Yifei Huang, Roopsha Samanta, Arjun Rad-
hakrishna, and Mukund Raghothaman. Explainable program syn-
thesis by localizing specifications. Proc. ACM Program. Lang. ,
7(OOPSLA2):2171–2195, 2023.
[32] Ansong Ni, Daniel Ramos, Aidan Z. H. Yang, In ˆes Lynce, Vasco M.
Manquinho, Ruben Martins, and Claire Le Goues. SOAR: A synthesis
approach for data science API refactoring. In IEEE/ACM International
Conference on Software Engineering (ICSE) , pages 112–124. IEEE,
2021.
[33] Wonseok Oh and Hakjoo Oh. Pyter: effective program repair for python
type errors. In Proceedings of the ACM Joint European Software
Engineering Conference and Symposium on the Foundations of Software
Engineering (ESEC/FSE) , pages 922–934. ACM, 2022.
[34] Adi Omari, Sharon Shoham, and Eran Yahav. Synthesis of forgiving
data extractors. In Proceedings of the ACM International Conference
on Web Search and Data Mining (WSDM) , pages 385–394. ACM, 2017.
[35] Peter-Michael Osera and Steve Zdancewic. Type-and-example-directed
program synthesis. In Proceedings of the 36th ACM SIGPLAN Con-
ference on Programming Language Design and Implementation , PLDI,
page 619–630. ACM, 2015.
[36] Shankara Pailoor, Yuepeng Wang, and Isil Dillig. Semantic code
refactoring for abstract data types. Proc. ACM Program. Lang. ,
8(POPL):816–847, 2024.
[37] Oleksandr Polozov and Sumit Gulwani. Flashmeta: a framework for
inductive program synthesis. In Proceedings of the 2015 ACM SIGPLAN
International Conference on Object-Oriented Programming, Systems,
Languages, and Applications , OOPSLA, page 107–126. ACM, 2015.
[38] Veselin Raychev, Max Sch ¨afer, Manu Sridharan, and Martin T. Vechev.
Refactoring with synthesis. In Proceedings of the ACM SIGPLAN
International Conference on Object Oriented Programming Systems
Languages & Applications, (OOPSLA) , pages 339–354. ACM, 2013.
[39] Veselin Raychev, Martin T. Vechev, and Eran Yahav. Code completion
with statistical language models. In ACM SIGPLAN Conference on
Programming Language Design and Implementation (PLDI) , pages 419–
428. ACM, 2014.
[40] Jayavel Shanmugasundaram, Eugene Shekita, Jerry Kiernan, Rajasekar
Krishnamurthy, Efstratios Viglas, Jeffrey Naughton, and Igor Tatarinov.
A general technique for querying xml documents using a relational
database system. SIGMOD Rec. , 30(3):20–26, sep 2001.[41] Sunbeom So and Hakjoo Oh. Synthesizing imperative programs from
examples guided by static analysis. In International Symposium on Static
Analysis (SAS) , pages 364–381. Springer, 2017.
[42] Yoshiki Takashima, Ruben Martins, Limin Jia, and Corina S. Pasareanu.
Syrust: automatic testing of rust libraries with semantic-aware program
synthesis. In ACM SIGPLAN International Conference on Programming
Language Design and Implementation (PLDI) , pages 899–913. ACM,
2021.
[43] Keita Takenouchi, Takashi Ishio, Joji Okada, and Yuji Sakata. Patsql:
efficient synthesis of sql queries from example tables with quick
inference of projected columns. Proc. VLDB Endow. , 14(11):1937–1949,
jul 2021.
[44] Igor Tatarinov, Stratis D. Viglas, Kevin Beyer, Jayavel Shanmugasun-
daram, Eugene Shekita, and Chun Zhang. Storing and querying ordered
xml using a relational database system. In Proceedings of the 2002 ACM
SIGMOD International Conference on Management of Data , SIGMOD,
page 204–215. ACM, 2002.
[45] Martin T. Vechev, Eran Yahav, and Greta Yorsh. Abstraction-guided
synthesis of synchronization. In Proceedings of the ACM SIGPLAN-
SIGACT Symposium on Principles of Programming Languages (POPL) ,
pages 327–338. ACM, 2010.
[46] Chenglong Wang, Alvin Cheung, and Rastislav Bodik. Synthesizing
highly expressive sql queries from input-output examples. In Proceed-
ings of the 38th ACM SIGPLAN Conference on Programming Language
Design and Implementation , PLDI, page 452–466. ACM, 2017.
[47] Xinyu Wang, Isil Dillig, and Rishabh Singh. Program synthesis using
abstraction refinement. Proc. ACM Program. Lang. , 2(POPL), dec 2017.
[48] Yuepeng Wang, Rushi Shah, Abby Criswell, Rong Pan, and Isil Dillig.
Data migration using datalog program synthesis. Proc. VLDB Endow. ,13(7):1006–1019, mar 2020.
[49] Yingfei Xiong, Jie Wang, Runfa Yan, Jiachen Zhang, Shi Han, Gang
Huang, and Lu Zhang. Precise condition synthesis for program repair.
InProceedings of the International Conference on Software Engineering
(ICSE) , pages 416–426. IEEE / ACM, 2017.
[50] Navid Yaghmazadeh, Christian Klinger, Isil Dillig, and Swarat Chaud-
huri. Synthesizing transformations on hierarchically structured data. In
Proceedings of the 37th ACM SIGPLAN Conference on Programming
Language Design and Implementation , PLDI, page 508–521. ACM,
2016.
[51] Navid Yaghmazadeh, Xinyu Wang, and Isil Dillig. Automated migration
of hierarchical data to relational tables using programming-by-example.
Proc. VLDB Endow. , 11(5):580–593, oct 2018.
[52] Navid Yaghmazadeh, Yuepeng Wang, Isil Dillig, and Thomas Dillig.
Sqlizer: query synthesis from natural language. Proc. ACM Program.
Lang. , 1(OOPSLA), oct 2017.
[53] Sai Zhang and Yuyin Sun. Automatically synthesizing sql queries
from input-output examples. In Proceedings of the 28th IEEE/ACM
International Conference on Automated Software Engineering , ASE,
page 224–234. IEEE Press, 2013.
[54] Yingquan Zhao, Zan Wang, Junjie Chen, Mengdi Liu, Mingyuan Wu,
Yuqun Zhang, and Lingming Zhang. History-driven test program
synthesis for JVM testing. In IEEE/ACM International Conference on
Software Engineering (ICSE) , pages 1133–1144. ACM, 2022.
[55] Xiangyu Zhou, Rastislav Bodik, Alvin Cheung, and Chenglong Wang.
Synthesizing analytical sql queries from computation demonstration.
InProceedings of the 43rd ACM SIGPLAN International Conference
on Programming Language Design and Implementation , PLDI, page
168–182. ACM, 2022.APPENDIX A
AUXILIARY FUNCTIONS AND DEFINITIONS
τa={aa1:τa1, . . . , a an:τan, a1:τ1, . . . , a p:τp}
τb={ab1:τb1, . . . , a bm:τbm, a1:τ′
1, . . . , a p:τ′
p}
τa∪τb={a1:τa1, . . . , a an:τan, b1:τb1, . . . , a bm:τbm
a1:τ1∪τ′
1, . . . , a p:τp∪τ′
p}(T-Union)
τa/∈ T ∨ τb/∈ T
τa̸=τb
τa∪τb=⊥(T-Union-Ne)τa/∈ T ∨ τb/∈ T
τa=τb
τa∪τb=τa(T-Union-Eq)
τa={aa1:τa1, . . . , a n:τan, a1:τ1, . . . , a p:τp}
τb={ab1:τb1, . . . , a m:τbm, a1:τ′
1, . . . , a p:τ′
p}
τa∩τb={a1:τ1∩τ′
1, . . . , a p:τp∩τ′
p}(T-Inter)
τa/∈ T ∨ τb/∈ T
τa̸=τb
τa∩τb=⊥(T-Inter-Ne)τa/∈ T ∨ τb/∈ T
τa=τb
τa∩τb=τa(T-Inter-Eq)
τ={a1:τ1, . . . , a n:τn, a:⊥}
τ={a1:τ1, . . . , a n:τn}(T-Bot)
⊥ ∪τ=τ(T-Bot-U)τa∩τb=τa
τa∪τb=τb
τa⊆τb(T-Subset)
τ={a1:τ1, . . . , a n:τn}
(∃i.ai=a)∨(∃i.a∈τi∧τi∈TD)
i= 1, . . . , n
a∈τ(T-In)
τ∪τb=τa∪τb
τ∩τb={} τ⊆τa
τa−τb=τ(T-Sub)a /∈τ
τ[τ′/a] =τ(T-Rep-Not-In)
τ={a1:τ1, . . . , a n:τn}
∃i.ai=a
i= 1, . . . , n
τ[τ′/a] ={a1:τ1, . . . , a i−1:τi−1,
ai+1:τi+1, . . . , a n:τn, ai:τ′}(T-Rep-In-1)
τ={a1:τ1, . . . , a n:τn}
∃i.a∈τi
i= 1, . . . , n
τ[τ′/a] ={a1:τ1, . . . , a i−1:τi−1,
ai+1:τi+1, . . . , a n:τn, ai:τi[τ′/a]}(T-Rep-In-2)
Fig. 12: Type Operations
Definition 11. Letτbe a document type and Tbe an
augmented type where τ={a1:τ1, . . . , a n:τn}and
T={b1:T1, . . . , b m:Tm,?1
m+1:Tm+1, . . . ,?1
m+p:
Tm+p,?+
m+p+1:Tm+p+1, . . . ,?+
m+p+q:Tm+p+q}. We say
τmatches T, denoted τ ◁T, if and only if
1) There exists a map Mmfrom the top-level attribute in T
to the top-level attribute in τsuch that ∀i.1≤i≤m⇒
Mm[bi] =a∧bi=a∧Type(bi) =Type(a)
2) There exists a map Mpfrom the top-level attribute in
Tto the top-level attribute in τsuch that ∀i.m+ 1≤
i≤m+p+ 1⇒Mp[bi] =a∧(Type(bi) =Type(a)∨
Type(bi) =Any)
3) There exists a map Mqfrom the top-level attribute in Tto
a set of top-level attributes in τsuch that ∀i.m+p+1≤
i≤m+p+q⇒Mq[bi] =Sa∧Sa̸={} ∧ (∀a.a∈
Sa⇒(Type(bi) =Type(a)∨Type(bi) =Any)).4) All the maps are one-to-one correspondence. Formally,
∀M.M ∈ {Mm, Mp, Mq} ⇒ (∀d.∀e.d∈M∧e∈M∧
d̸=e⇒M[d]̸=M[e])
5)Km∩Kp={}∧Kp∩Kq={}∧Km∩Kq={}∧Km∪
Kp∪Kq=ATwhere Km, Kp, Kqare the key set of
Mm, Mp, MqandAT={b1, . . . , b m,?1
m+1, . . . ,?1
m+p,
?+
m+p+1, . . . ,?+
m+p+q}
6)Vm∩Vp={} ∧ Vp∩(SVq) ={} ∧ Vm∩(SVq) =
{} ∧Vm∪Vp∪(SVq) =Aτwhere Vm, Vp, Vqare the
value set of Mm, Mp, MqandAτ={a1, . . . , a n}.
APPENDIX B
CONCRETE FORMAL SEMANTICS
The denotational semantics of our query language is shown
in Figure 13. Intuitively, since the collection is a array of
documents, we use standard higher-order functions for lists
(e.g., map andfilter ) to formally define the semantics. dedup
is the standard de-duplication function and iteis the standard
if-then-else function. flatmap is a flat map function that flattens
the mapped array.
At a high level, there are seven query operators. Each
query takes as input a database Dand produces as output a
collection. Specifically, a simple collection name Njust looks
up the corresponding collection in the database D, as defined
byJNKD.Project (Q,⃗h)projects out specified access paths ⃗h
for each document in JQKD.Match (Q, ϕ)filters the documents
inJQKDand only keeps those satisfying the predicate ϕ.
AddFields (Q,⃗h,⃗E)adds new access paths ⃗hwith values of
expressions ⃗Eto each document in JQKD.Unwind (Q, h)
requires that the access path hcorresponds to an array and
unwinds the result of Qath. In particular, it first maps each
document in JQKDto a list of documents where the value of
hini-th document is the i-th element in the original array,
and then adds all documents to the result. Group (Q,⃗k,⃗ a,⃗A)
groups all documents in JQKDbased on keys ⃗kand returns a
collection that contains a document for each group with new
attributes ⃗ aand aggregated values ⃗A.Lookup (Q, k, h, N, a )
adds a new attribute ato each document in JQKD. The value
ofais a list of documents from the foreign collection Nsuch
that the value of kinJQKDequals to the value of hinN. The
semantics for predicates and expressions are straightforward
from the operator names.
APPENDIX C
PROOFS
Proof of Theorem 1. Let ˜Dbe an abstract database over
schema S,Ωbe a sketch, Qbe a query that is a completion of
Ω, and (I, O)be an input-output example, where ⊢I:Sand
⊢O:Arr⟨τO⟩. IfJQKI=O,I⊑˜D, and ˜D, τO⊢Ω⇓Λ, then
there exists an abstract collection ˜C ∈Λsuch that O⊑˜C.
Proof. We assume that the newly generated fields (i.e. ones
match ?) attributes cannot be changed and must be all kept in
the output of the whole query. We also assume that AddFields
will not overwrite existing fields.
Prove by structural induction on Ω. To avoid obfuscation,
we use ˜D, τE⊢Ω⇓Λto denote Ωevaluates to Λunder theJQK::Database D → Collection C
JNKD=D[N]
JProject (Q,⃗h)KD= map(λD. ExtractAttrs (D,⃗h),JQKD)
JMatch (Q, ϕ)KD= filter(λD. JϕKD=⊤,JQKD)
JAddFields (Q,⃗h,⃗E)KD= map(λD. AddAttrs (D,⃗h,⃗JEKD),JQKD)
JUnwind (Q, h)KD= flatmap (λD. Flatten (D, h),JQKD)
JGroup (Q,⃗k,⃗ a,⃗A)KD= map(λg.AddAttrs ({id:g},⃗[a],
J⃗AKfilter(λD. ExtractAttrs (D,⃗k)=g,JQKD)),
dedup(map(λD. ExtractAttrs (D,⃗k),JQKD)))
JLookup (Q, k, h, N, a )KD= map(λD.D [a7→C],JQKD)where
C=filter(λF.JkKD=JhKF,D[N])
JϕK::Document D→Bool
JbKD=bwhere b∈ {⊤ ,⊥}
Jh◦cKD= JhKD◦cwhere◦ ∈ { =,̸=}
Jh < c KD= ite(JhKD=Null∨c=Null,⊥,JhKD< c)
Jh > c KD= ite(JhKD=Null∨c=Null,⊥,JhKD> c)
Jh≤cKD= Jh < c KD∨Jh=cKD
Jh≥cKD= Jh > c KD∨Jh=cKD
JSizeEq (h, c)KD= ite(JhKD=Null∨c=Null,⊥,|JhKD|=c)
JExists(h)KD= HasAp (D, h)
Jϕ1∧ϕ2KD= Jϕ1KD∧Jϕ2KD
Jϕ1∨ϕ2KD= Jϕ1KD∨Jϕ2KD
J¬ϕKD=¬JϕKD
JEK::Document D→Value
JhKD= Get(D, h)
Jh1⊕h2KD= ite(Jh1KD=Null∨Jh2KD=Null,Null,Jh1KD⊕Jh2KD)
Jf(h)KD=f(JhKD)
JAK::Document List ⃗D→Value
JSum(h)K⃗D= letxs=map(λD. JhKD,⃗D)inP
x∈xsite(x=Null,0, x)
JMin(h)K⃗D= letxs=map(λD. JhKD,⃗D)in
ite(AllNull (xs),Null,minx∈xsite(x=Null,+∞, x))
JMax(h)K⃗D= letxs=map(λD. JhKD,⃗D)in
ite(AllNull (xs),Null,maxx∈xsite(x=Null,−∞, x))
JAvg(h)K⃗D= letxs=map(λD. JhKD,⃗D)in
ite(AllNull (xs),Null,JSum(h)K⃗D/P
x∈xsite(x=Null,0,1))
JCount()K⃗D=|⃗D|
Fig. 13: Semantics of database queries. ExtractAttrs (D,⃗h)
constructs a document by extracting access paths ⃗hand their
values from document D.AddAttrs (D,⃗h,⃗ v)returns a docu-
ment by adding new access paths ⃗hwith values ⃗Eto document
D.Flatten (D, h)requires hto be an array in document D.
It maps Dto a list of documents where the value of hin
thei-th document is the i-th element in the original array.
HasAp (D, h)checks whether there exists an access path hin
document D.Get(D, h)gets the value of access path hfrom
document D.
context of the abstract database ˜Dand the expected output
document type τE. The context is global and will not change
in evaluation.
1) Base case: Ω =N.
Suppose that Q=N,⊢I:Sand⊢O:Arr⟨τO⟩. By
Figure 7 we have ˜D, τE⊢Ω⇓Λwhere Λ ={˜D[N]}.
By Figure 13 we have JQKI=Owhere O=I[N]. By
Figure 5 we have ⊢I[N] :S[N]. Thus ⊢O:S[N]
andS[N] = Arr⟨τO⟩. Let ˜C=˜D[N]∈Λ. Then
˜C= (τ, l0=|I[N]|)where S[N] = Arr⟨τ⟩. Therefore
Arr⟨τO⟩=Arr⟨τ⟩. So we have τO=τ. By the definition
of match, τO◁τ. Also the formula l0=|I[N]|∧l0=|O|is SAT because O=I[N]. Based on the above, there
exists an abstract collection ˜C=˜D[N]∈Λs.t.O⊑˜C.
Thus, Theorem 1 for the base case Ω =Nis proved.
2) Inductive case: Ω′=Match (Ω, P)
Suppose that Q′=Match (Q, P),⊢I:S,⊢O′:
Arr⟨τ′
O⟩,JQ′KI=O′,˜D, τE⊢Ω′⇓Λ′.
Suppose that ⊢I:S,⊢O:Arr⟨τO⟩,JQKI=O,˜D, τE⊢
Ω⇓Λ. By the inductive hypothesis, there exists ˜C ∈Λ
s.t.O⊑˜C.
Suppose ˜C= (T, ϕ). Then by Figure 7 we have (T, ϕ∧
lj≤li)∈Λ′. By Figure 13 we have τO=τ′
O,|O′| ≤
|O|.
ByO⊑˜Cwe have τO◁Tandϕ∧li=|O|is SAT.
Therefore τ′
O=τO◁Tandϕ∧lj≤li∧lj=|O′|is
SAT. So there exists a ˜C′= (T, ϕ∧lj≤li)∈Λ′s.t.
O′⊑˜C′.
Thus, Theorem 1 for the inductive case Ω = Match (Ω, P)
is proved.
3) Inductive case: Ω′=Project (Ω,⃗h)
Suppose Q′=Project (Q,⃗h),⊢I:S,⊢O′:Arr⟨τ′
O⟩,
JQ′KI=O′,˜D, τE⊢Ω′⇓Λ′.
Suppose that ⊢I:S,⊢O:Arr⟨τO⟩,JQKI=O,˜D, τE⊢
Ω⇓Λ. By the inductive hypothesis, there exists ˜C ∈Λ
s.t.O⊑˜C.
Suppose ˜C= (T, ϕ). Then by Figure 7 we have
((T −τk)∪(τk∩τE), ϕ∧lj=li)∈Λ′where τk=
ToDocType (T). By Figure 13 we have τ′
O=τO∩τE,
|O|=|O′|.
ByO⊑˜Cwe have τO◁Tandϕ∧li=|O|is SAT.
Therefore τk⊆τOandτO−τk◁T −τk. Thus τO∩τE=
(τk+τO−τk)∩τE= (τk∩τE)∪((τO−τk)∩τE).
By the assumption that newly generated fields can not
be changed and must be all kept in the output, we can
know τO−τkis the newly generated and τO−τk⊆τE.
So we have ((τO−τk)∩τE) = ( τO−τk)◁(T −τk).
Thus τ′
O◁(T −τk)∪(τk∩τE). We also have ϕ∧lj=
li∧lj=|O′|is SAT. So there exists ˜C′= ((T −τk)∪
(τk∩τE), ϕ∧lj=li)∈Λ′s.t.O′⊑˜C′.
Thus, Theorem 1 for the inductive case Ω′=
Project (Ω,⃗h)is proved.
4) Inductive case: Ω′=AddFields (Ω,⃗h,⃗E)
Suppose Q′=AddFields (Q,⃗h,⃗E),⊢I:S,⊢O′:
Arr⟨τ′
O⟩,JQ′KI=O′,˜D, τE⊢Ω′⇓Λ′.
Suppose that ⊢I:S,⊢O:Arr⟨τO⟩,JQKI=O,˜D, τE⊢
Ω⇓Λ. By the inductive hypothesis, there exists ˜C ∈Λ
s.t.O⊑˜C.
Suppose ˜C= (T, ϕ). Then by Figure 7 we have (T ∪{?+
0:
Any}, ϕ∧lj=li)∈Λ′. By Figure 13 we have |O|=
|O′|andτO⊆τ′
Owhere τO̸=τ′
O.
ByO⊑˜Cwe have τO◁Tandϕ∧li=|O|is SAT. Thus
τ′
O−τO◁{?+
0:Any}. Therefore τ′
O◁T ∪{?+
0:Any}. We
also have ϕ∧lj=li∧lj=|O′|is SAT. So there exists
˜C′= (T ∪{?+
0:Any}, ϕ∧lj=li)∈Λ′s.t.O′⊑˜C′.
Thus, Theorem 1 for the inductive case Ω′=
AddFields (Ω,⃗h,⃗E)is proved.5) Inductive case: Ω′=Unwind (Ω, h)
Suppose Q′=Unwind (Q, h),⊢I:S,⊢O′:Arr⟨τ′
O⟩,
JQ′KI=O′,˜D, τE⊢Ω′⇓Λ′.
Suppose that ⊢I:S,⊢O:Arr⟨τO⟩,JQKI=O,˜D, τE⊢
Ω⇓Λ. By the inductive hypothesis, there exists ˜C ∈Λ
s.t.O⊑˜C.
Suppose ˜C= (T, ϕ). Then by Figure 7 we have
{(T[τ/aA], ϕ∧lj≥li)|aA∈ T ∧ ∀ p.∀q.aA̸=?q
p} ⊆Λ′
where Type(aA) =Arr⟨τ⟩andNotInArr (aA). By Figure
13 we have |O′| ≥ | O|andτ′
O=τO[τh/ah]where
⊢ah:Arr⟨τh⟩,ah∈τOandahis fully qualified by
access path h.
ByO⊑˜Cwe have τO◁Tandϕ∧li=|O|is SAT.
There must exist an attribute aA∈ T such that aA=
ah, and Arr⟨τ⟩=Arr⟨τh⟩andaAis not a placeholder.
Therefore τ=τhand we have τO[τh/ah]◁T[τ/aA]. We
also have ϕ∧lj≥li∧lj=|O′|is SAT. So there exists
˜C′= (T[τ/aA], ϕ∧lj≥li)s.t.O′⊑˜C′.
Thus, Theorem 1 for the inductive case Ω′=
Unwind (Ω, h)is proved.
6) Inductive case: Ω′=Lookup (Ω, h, h, N, a )
Suppose Q′=Lookup (Q, h, h, N, a ),⊢I:S,⊢O′:
Arr⟨τ′
O⟩,JQ′KI=O′,˜D, τE⊢Ω′⇓Λ′.
Suppose that ⊢I:S,⊢O:Arr⟨τO⟩,JQKI=O,˜D, τE⊢
Ω⇓Λ. By the inductive hypothesis, there exists ˜C ∈Λ
s.t.O⊑˜C.
Suppose ˜C= (T, ϕ). Then by Figure 7 we have
{(T ∪{?1
j:Arr⟨τF⟩}, ϕ∧lj=li)|τF∈F} ⊆Λ′where
F={ToDocType (˜D[N]T)|N∈dom(˜D)}. By Figure 13
we have |O′|=|O|andτ′
O=τO∪ {a:S[NF]}where
NF∈dom(S).
ByO⊑˜Cwe have we have τO◁Tandϕ∧li=
|O|is SAT. By the definition of I⊑˜Dwe have
S[NF] = Arr⟨˜D[NF]T⟩and there are no placeholders
in˜D[NF]T. Then there must exist a τF∈Fsuch
thatτF=ToDocType (˜D[NF]T) = ˜D[NF]T. Thus
S[NF] = Arr⟨τF⟩and we have τO∪ {a:S[NF]}◁
T ∪{?1
j:Arr⟨τF⟩}. We also have ϕ∧lj=li∧lj=|O′|is
SAT. So there exists ˜C′= (T ∪{?1
j:Arr⟨τF⟩}, ϕ∧lj=li)
s.t.O′⊑˜C′.
Thus, Theorem 1 for the inductive case Ω′=
Lookup (Ω, h, h, N, a )is proved.
7) Inductive case: Ω′=Group (Ω,⃗h,⃗ a,⃗A)
Suppose Q′=Group (Q,⃗h,⃗ a,⃗A),⊢I:S,⊢O′:
Arr⟨τ′
O⟩,JQ′KI=O′,˜D, τE⊢Ω′⇓Λ′.
Suppose that ⊢I:S,⊢O:Arr⟨τO⟩,JQKI=O,˜D, τE⊢
Ω⇓Λ. By the inductive hypothesis, there exists ˜C ∈Λ
s.t.O⊑˜C.
Suppose ˜C= (T, ϕ). Then by Figure 7 we have
{({_id: τK} ∪τg, ϕ∧lj< li)|τK⊆ToDocType (T)∧
τg∈G} ⊆ Λ′where G={{?+
j:Num},{}}. By
Figure 13 we have |O′|<|O|andτ′
O={_id :{b1:
τ1, . . . , b m:τm}} ∪ { a1:Num, . . . , a n:Num}where
all the access paths in {b1:τ1, . . . , b m:τm}is⃗h,
{b1:τ1, . . . , b m:τm} ⊆τO, and ⃗ a= [a1, . . . , a n].ByO⊑˜Cwe have we have τO◁Tandϕ∧li=|O|
is SAT. By the assumption that newly generated fields
can not be changed and must be all kept in the out-
put, we can know there are no placeholders in Tthus
T=ToDocType (T)and there are newly generated
fields in τO. So we have τO=T. There must exist a
τK⊆ToDocType (T)such that τK={b1:τ1, . . . , b m:
τm}. Ifn= 0 then there exists a τg={}such
that{a1:Num, . . . , a n:Num}◁ τgbecause {a1:
Num, . . . , a n:Num}is an empty document type now.
Otherwise if n >0the there exists a τg={?+
j:Num}
such that {a1:Num, . . . , a n:Num}◁τgby the definition
of match. Thus we have {_id :{b1:τ1, . . . , b m:
τm}} ∪ { a1:Num, . . . , a n:Num}◁{_id: τK} ∪τg.
We also have ϕ∧lj< li∧lj=|O′|is SAT. So there
exists ˜C′= ({_id: τK} ∪τg, ϕ∧lj< li)s.t.O′⊑˜C′
Thus, Theorem 1 for the inductive case Ω′=
Group (Ω,⃗h,⃗ a,⃗A)is proved.
Proof of Theorem 2. Given a database schema S, a sketch Ω,
and input-output examples ⃗E, if D EDUCE (S,Ω,⃗E)returns ⊥,
then there is no completion QofΩsuch that for all (I, O)∈⃗E,
JQKI=O.
Proof. Prove by contradiction. Suppose if D EDUCE (S,Ω,⃗E)
returns ⊥, then there is a completion QofΩsuch that for all
(I, O)∈⃗E,JQKI=O. Therefore by Theorem 1, we can know
for all example Ej= (Ij, Oj)∈⃗E, there exists an abstract
collection ˜C ∈Λjsuch that Oj⊑˜C. Then by the procedure
DEDUCE , we can know D EDUCE (S,Ω,⃗E)returns ⊤. Thus
there is a contradiction. So Theorem 2 is proved.
Proof of Theorem 3 (Soundness). LetSbe a database
schema, ⃗Ebe input-output examples, and Nbe a
collection name. Suppose C OMPLETE SKETCH is sound,
if S YNTHESIZE (S,⃗E, N)returns a query Q, then Qsatisfies
examples ⃗E.
Proof. By the procedure S YNTHESIZE we can know that if
SYNTHESIZE (S,⃗E, N)returns a query Q, then Q ̸=⊥. By
the soundness of C OMPLETE SKETCH we have Qsatisfies
examples ⃗E. And there must exist a sketch Ωsuch that Qis a
completion of Ω. By Theorem 2, D EDUCE (S,Ω,⃗E)return ⊤.
Thus this Qcan be really returned. So Theorem 3 (Soundness)
is proved.
Proof of Theorem 4 (Completeness). LetSbe a database
schema, ⃗Ebe input-output examples, and Nbe a col-
lection name. Suppose C OMPLETE SKETCH is complete, if
there exists a query accepted by the grammar in Figure 6
that is over collection Nand satisfies examples ⃗E, then
SYNTHESIZE (S,⃗E, N)does not return ⊥.
Proof. If there exists a query Qaccepted by the gram-
mar in Figure 6 that is over collection Nand satisfies
examples ⃗E, then Qmust be a completion of a sketch Ω.
By Theorem 2, D EDUCE (S,Ω,⃗E)returns ⊤, thus Q=COMPLETE SKETCH (S,Ω,⃗E). By the completeness of C OM-
PLETE SKETCH ,Q ̸=⊥. Thus Qwill be returned, whichmeans that S YNTHESIZE (S,⃗E, N)does not return ⊥. So
Theorem 4 (Completeness) is proved.