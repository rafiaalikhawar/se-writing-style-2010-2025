Empirical Review of Automated Analysis Tools on 47,587
Ethereum Smart Contracts
Thomas Durieux
INESC-ID and IST, University of Lisbon, Portugal
thomas@durieux.meJoão F. Ferreira
INESC-ID and IST, University of Lisbon, Portugal
joao@joaoff.com
Rui Abreu
INESC-ID and IST, University of Lisbon, Portugal
rui@computer.orgPedro Cruz
INESC-ID and IST, University of Lisbon, Portugal
pedrocrvz@gmail.com
ABSTRACT
Overthelastfewyears,therehasbeensubstantialresearchonauto-
matedanalysis,testing,anddebuggingofEthereumsmartcontracts.
However,itisnottrivialtocompareandreproducethatresearch.
Toaddressthis,wepresentanempiricalevaluationof9state-of-the-
art automated analysis tools using two new datasets: i) a datasetof 69 annotated vulnerable smart contracts that can be used toevaluate the precision of analysis tools; and ii) a dataset with all
the smart contracts in the Ethereum Blockchain that have Solidity
sourcecodeavailableonEtherscan(atotalof47,518contracts).The
datasets are part of SmartBugs, a new extendable execution frame-
workthatwecreatedtofacilitatetheintegrationandcomparison
betweenmultipleanalysistoolsandtheanalysisofEthereumsmart
contracts. We used SmartBugs to execute the 9 automated analysis
toolsonthetwodatasets.Intotal,weran428,337analysesthattookapproximately564daysand3hours,beingthelargestexperimental
setup to date both in the number of tools and in execution time.
Wefoundthatonly42%ofthevulnerabilitiesfromourannotated
datasetaredetectedbyallthetools,withthetool Mythrilhaving
the higher accuracy (27%). When considering the largest dataset,
we observed that 97% of contracts are tagged as vulnerable, thus
suggesting a considerable number of false positives. Indeed, only a
small numberof vulnerabilities (and ofonly two categories) were
detected simultaneously by four or more tools.
CCS CONCEPTS
•Software and its engineering →Software defect analysis ;
Software testing and debugging.
KEYWORDS
Smart contracts, Solidity, Ethereum, Blockchain, Tools, Debugging,
Testing, Reproducible Bugs
ACM Reference Format:
Thomas Durieux, João F. Ferreira, Rui Abreu, and Pedro Cruz. 2020. Em-
pirical Review of Automated Analysis Tools on 47,587 Ethereum Smart
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthe firstpage.Copyrights forcomponentsof thisworkowned byothersthan the
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or
republish,topostonserversortoredistributetolists,requirespriorspecificpermission
and/or a fee. Request permissions from permissions@acm.org.
ICSE ’20, May 23–29, 2020, Seoul, Republic of Korea
© 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-7121-6/20/05...$15.00
https://doi.org/10.1145/3377811.3380364Contracts.In 42ndInternationalConferenceonSoftwareEngineering(ICSE
’20),May23–29,2020,Seoul,RepublicofKorea. ACM,NewYork,NY,USA,
12 pages. https://doi.org/10.1145/3377811.3380364
1 INTRODUCTION
Blockchaintechnologyhasbeenreceivingconsiderableattention
fromindustryandacademia,foritpromisestodisruptthedigital
onlineworldbyenablingademocratic,open,andscalabledigital
economybasedondecentralizeddistributedconsensuswithoutthe
interventionofthird-partytrustedauthorities.Amongthecurrently
available blockchain-based platforms, Ethereum [ 5] is one of the
most popular, mainly because it enables developers to write dis-
tributed applications (Dapps) based on smart contracts—programs
thatareexecutedacrossadecentralisednetworkofnodes.Themain
language used to develop Ethereum smart contracts is Solidity1,a
high-levellanguagethatfollowsaJavaScript-like,object-oriented
paradigm.ContractswritteninSolidityarecompiledtobytecode
that can be executed on the Ethereum Virtual Machine (EVM).
Smart contracts are at the core of Ethereum’s value. However,
asnotedbysomeresearchers[ 3,27],duetotheidiosyncrasiesof
the EVM, writing secure smart contracts is far from trivial. In a
preliminarystudyperformedonnearlyonemillionEthereumsmart
contracts,using oneanalysisframework forverifyingcorrectness,
34,200ofthemwereflaggedasvulnerable[ 32].Also,Luu etal.[27]
proposedthesymbolicexecutiontoolOyenteandshowedthatof
19,366Ethereumsmartcontractsanalyzed, 8,833(around46%)were
flaggedasvulnerable.Famousattacks,suchasTheDAOexploit[ 11]
and the Parity wallet bug [ 37] illustrate this problem and have led
to huge financial losses.
There has been some effort from the research community to
developautomatedanalysistoolsthatlocateandeliminatevulnera-bilitiesinsmartcontracts[
18,27,39,42].However,itisnoteasyto
compareandreproducethatresearch:eventhoughseveralofthe
toolsarepubliclyavailable,thedatasetsusedarenot.Ifadeveloperofanewtoolwantstocomparethenewtoolwithexistingwork,the
current approach is to contactthe authors of alternative tools and
hope that they give access to their datasets (as done in, e.g., [35]).
The aim of this paper is twofold. First, to be able to execute
and compare automated analysis tools, hence setting the groundfor fair comparisons, we provide two datasets of Solidity smart
contracts.Thefirstdatasetcontains69manuallyannotatedsmart
contracts that can be used to evaluate the precision of analysis
tools.Theseconddatasetcontainsallavailablesmartcontractsin
1Interested readers on Solidity, refer to https://solidity.readthedocs.io.
5302020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE)
theEthereumBlockchainthathaveSoliditysourcecodeavailable
on Etherscan (a total of 47,518 contracts) at the time of writing.
We have executed 9 state-of-the-art automated analysis tools on
the two datasets and analyzed the results in order to provide a fair
point of comparison for future smart contract analysis tools. In
total,theexecutionofallthetoolsrequired564daysand3hours
to complete 428,337 analyses.
Second, tosimplify research on automated analysistechniques
for smart contracts, we provide a novel, extendable, and easy-to-
use execution framework, called SmartBugs, to execute these tools
on the same execution environment. This framework currently
contains 9 configured smart contract analysis tools.
In summary, the contributions of the paper are: (1) A dataset of
annotatedvulnerableSoliditysmartcontracts;(2)Adatasetthatcon-
tainsalltheavailablesmartcontractsfromtheEthereumblockchain
thathaveSoliditysourcecodeavailableinEtherscan;(3)Anexe-cution framework that includes 9 pre-configured smart contractanalysis tools; and (4) An analysis of the execution of 9 tools on
47,587 smart contracts.
Ourstudydemonstratesthatthereareseveralopenchallenges
that need to be addressed by future work to improve the quality
ofexistingtoolsandtechniques.Wereportthatthecurrentstate-
of-the-artisnotabletodetectvulnerabilitiesfromtwocategories
of DASP10: Bad Randomness andShort Addresses. Also, the tools
are only able to detect together 42% of the vulnerabilities fromour dataset of annotated vulnerable smart contracts (48 out of
115). The most accurate tool, Mythril, is able to detect only 27% of
the vulnerabilities. When considering the largest dataset, 97% of
contracts are tagged as vulnerable, thus suggesting a considerable
number of false positives. In conclusion, we show that state-of-
the-art techniques are far from being perfect, still likely producing
too many false positives. On the positive side, the best performing
techniques do so at a marginal execution cost.
SmartBugs is available at
https://smartbugs.github.io
2 STUDY DESIGN
Blockchain technologies are getting more and more attention from
theresearchcommunityand also,more importantly,fromindus-
try. Asmore blockchain-basedsolutions emerge, thereis ahigher
reliance on the quality of the smart contracts. The industry and
the research community came up with automatic approaches that
analyzesmartcontractstoidentifyvulnerabilitiesandbadpractices.
Themaingoalofthispaperistoreportthecurrentstateoftheartof
currentlyavailableautomatedanalysistoolsforsmartcontracts.To
facilitatereproducibility andcomparisonbetweentools, thestudy
is performed using a new extendable execution framework that we
call SmartBugs (see Section 2.4).
In this section, we present the design of our study, including
the research questions, the systematic selection of the tools and
datasets of smart contracts, the execution framework, and the data
collection and analysis methodology.
2.1 Research Questions
In this study, we aim to answer the following research questions:RQ1.[Effectiveness] What is the effectiveness of current analysis
tools in detecting vulnerabilities in Solidity smart contracts?
In this first research question, we are interested in deter-mining how precise state-of-the-art analysis tools are in
detecting vulnerabilities in known faulty smart contracts.
RQ2.[Production] How many vulnerabilities are present in the
Ethereum blockchain?
In this research question, we investigate the vulnerabilities
that are detected in contracts pulled from the Ethereum
blockchain.Weconsiderthemostpopularvulnerabilities,theevolution of the vulnerabilities over time, and the consensus
among different combinations of automated analysis tools.
RQ3.[Performance] How long do the tools require to analyze the
smart contracts?
And finally, we compare the performance of the analysis
tools. The goal is to identify which tool is the most efficient.
2.2 Subject Tools
In order to discover smart contract automated analysis tools, we
startedoffbyusingthesurveyofAngelo etal.[12]andweextended
their list of tools by searching the academic literature and theinternet for other tools. We ended up with the 35 tools that are
listed in Table 1.
Notalltheidentifiedtoolsarewellsuitedforourstudy.Onlythe
tools that met the following three inclusion criteria were included
in our study:
•Criterion #1. [Available and CLI] The tool is publicly available
and supports a command-line interface (CLI). The CLI facilitates
the scalability of the analyses.
•Criterion#2. [CompatibleInput]ThetooltakesasinputaSolidity
contract. This excludes tools that only consider EVM bytecode.
•Criterion#3. [OnlySource]Thetoolrequiresonlythesourcecode
of the contract to be able to run the analysis. This excludes tools
that require a test suite or contracts annotated with assertions.
•Criterion#4. [VulnerabilityFinding]Thetoolidentifiesvulnera-
bilities or bad practices in contracts. This excludes tools that are
describedasanalysistools,butonlyconstructartifactssuchas
control flow graphs.
After inspecting all 35 analysis tools presented in Table 1, we
found 9 tools that meet the inclusion criteria outlined. Table 2
presentstheexcludedandincludedtools,andfortheexcludedones,
it also shows which criteria they did not meet.
HoneyBadger[41] isdevelopedbyagroupofresearchersatthe
University of Luxembourg and is an Oyente-based (see below) tool
thatemployssymbolicexecutionandasetofheuristicstopinpoint
honeypotsin smartcontracts.Honeypots aresmart contractsthat
appearto have an obvious flaw in their design, which allows an
arbitrary user to drain Ether2from the contract, given that the
user transfers a priori a certain amount of Ether to the contract.
WhenHoneyBadgerdetectsthatacontract appearstobevulnerable,
it means that the developer of the contract wanted to make the
contract look vulnerable, but is not vulnerable.
Maian[32] ,developedjointlybyresearchersfromtheNational
University of Singapore and University College London, is also
based on the Oyente tool. Maian looks for contracts that can be
2Ether is the cryptocurrency of Ethereum.
531Table 1: Tools identified as potential candidates for this
study.
# Tools Tool URLs
1 contractLarva [2] https://github.com/gordonpace/contractLarva
2 E-EVM [33] https://github.com/pisocrob/E-EVM3 Echidna https://github.com/crytic/echidna
4 Erays [44] https://github.com/teamnsrg/erays5 Ether [26] N/A
6 Ethersplay https://github.com/crytic/ethersplay7 EtherTrust [19] https://www.netidee.at/ethertrust8 EthIR [1] https://github.com/costa-group/EthIR
9 FSolidM [28] https://github.com/anmavrid/smart-contracts
10 Gasper [9] N/A
11 HoneyBadger [41]
https://github.com/christoftorres/
HoneyBadger
12 KEVM [21] https://github.com/kframework/evm-
semantics
13 MadMax [17] https://github.com/nevillegrech/MadMax14 Maian [32] https://github.com/MAIAN-tool/MAIAN15 Manticore [30] https://github.com/trailofbits/manticore/16 Mythril [31] https://github.com/ConsenSys/mythril-classic17 Octopus https://github.com/quoscient/octopus
18 Osiris [40] https://github.com/christoftorres/Osiris19 Oyente [27] https://github.com/melonproject/oyente20 Porosity [38] https://github.com/comaeio/porosity21 rattle https://github.com/crytic/rattle
22 ReGuard [25] N/A
23 Remix https://github.com/ethereum/remix
24 SASC [43] N/A
25 sCompile [6] N/A
26 Securify [42] https://github.com/eth-sri/securify27 Slither [16] https://github.com/crytic/slither28 Smartcheck [39] https://github.com/smartdec/smartcheck29 Solgraph https://github.com/raineorshine/solgraph
30 Solhint https://github.com/protofire/solhint
31 SolMet [20]
https://github.com/chicxurug/SolMet-
Solidity-parser
32 teEther [23] https://github.com/nescio007/teether33 Vandal [4] https://github.com/usyd-blockchain/vandal34 VeriSol [24] https://github.com/microsoft/verisol35 Zeus [22] N/A
Table 2: Excluded and included analysis tools based on our
inclusion criteria.
Inclusion criteria Tools that violate criteriaExcluded
(26)Available and CLI (C1) Ether, Gasper, ReGuard, Remix,
SASC, sCompile, teEther, Zeus
Compatible Input (C2) MadMax, VandalOnly Source (C3) Echidna, VeriSolVulnerability Finding (C4)
contractLarva, E-EVM, Erays, Ether-
splay, EtherTrust, EthIR, FSolidM,
KEVM, Octopus, Porosity, rattle, Sol-
graph, SolMet, SolhintIncluded
(9)HoneyBadger, Maian, Manticore, Mythril, Osiris, Oyente,
Securify, Slither, Smartcheck
self-destructedordrainedofEtherfromarbitraryaddresses,orthat
accept Ether but do not have a payout functionality. A dynamicanalysis in a private blockchain is then used to reduce the number
of false positives.
Manticore [30] ,developedbyTrailOfBits,alsousessymbolic
execution to find execution paths in EVM bytecode that lead to
reentrancy vulnerabilities and reachable self-destruct operations.
Mythril[31] ,developedbyConsenSys,reliesonconcolicanaly-
sis,taintanalysisandcontrolflowcheckingoftheEVMbytecodeto
prune the search space and to look for values that allow exploiting
vulnerabilities in the smart contract.
Osiris [40] , developed by a group of researchers at the Univer-
sityofLuxembourg,extendsOyentetodetectintegerbugsinsmart
contracts.
Oyente [27] , developed by Melonport AG, is one of the first
smartcontractanalysistools.Itisalsousedasabasisforseveral
other approaches like Maian and Osiris. Oyente uses symbolic
execution on EVM bytecode to identify vulnerabilities.
Securify[42] ,developedbyICECenteratETHZurich,statically
analyzesEVMbytecodetoinferrelevantandprecisesemanticinfor-
mation about the contract using the Souffle Datalog solver. It then
checks compliance and violation patterns that capture sufficient
conditions for proving if a property holds or not.
Slither[16] ,developedbyTrailOfBits,isastaticanalysisframe-
work that converts Solidity smart contracts into an intermediate
representation called SlithIR and applies known program analysis
techniquessuchasdataflowandtainttrackingtoextractandrefine
information.
Smartcheck [39] ,developedbySmartDec,isastaticanalysis
tool thatlooks for vulnerabilitypatterns and badcoding practices.
It runs lexical and syntactical analysis on Solidity source code.
2.3 Datasets of Smart Contracts
For this study, we crafted two datasets of Solidity smart contracts
withdistinctpurposes.Thefirstdataset, sbcurated,consistsof69
vulnerable smart contracts (see Section 2.3.1). Contracts in this
datasetareeitherrealcontractsthathavebeenidentifiedasvulner-ableorhavebeenpurposelycreatedtoillustrateavulnerability.The
goalofthisdatasetistohaveasetofknownvulnerablecontracts
labelled with the location and category of the vulnerabilities. Thisdataset can be used to evaluate the effectiveness of smart contract
analysis tools in identifying vulnerabilities.
The second dataset is named sbwild(see Section 2.3.2) and con-
tains47,518contractsextractedfromtheEthereumblockchain.The
set of vulnerabilities of those contracts is unknown; however, this
datasetcan beusedto identifyrealcontracts thathave (potential)
vulnerabilities and have an indication of how frequent a specific
problemis.Itcanalsobeusedtocompareanalysistoolsinterms
of metrics such as performance.
2.3.1 sbcurated: A Dataset of 69 Vulnerable Smart Contracts.
Goal.Our objective in constructing this dataset is to collect a
set of Solidity smart contracts with known vulnerabilities, from
deployed contracts in the Ethereum network to examples provided
to illustrate vulnerabilities, that can serve as a dataset suite for
researchinthesecurityanalysisofSoliditysmartcontracts.Weuse
thetaxonomypresentedintheDASP3todescribevulnerabilitiesof
3Decentralized Application Security Project (or DASP): https://dasp.co
532Ethereumsmartcontracts(seeCategoriesinTable3).Eachcollected
contract is classified in one of the ten categories. We also manually
taggedthelinesthatcontainthevulnerability.Thisclassification
allows for new smart contract analysis tools to be easily evaluated.
Collection Methodology. This dataset has been created by collect-
ingcontractsfromthreedifferentsources:1.GitHubrepositories,
2.blogpoststhatanalyzecontracts,and3.theEthereumnetwork.
80%ofthecontractswerecollectedfromGitHubrepositories.We
identifiedGitHubrepositoriesthatmatchrelevantsearchqueries
(‘vulnerable smart contracts’, ‘smart contracts security’, ‘solidity vul-
nerabilities’ ) and contain vulnerable smart contracts. We searched
Google using the same queries. We found several repositories with
vulnerablesmartcontractssuchas not-so-smart-contracts4andSWC
Registry5. The latter is a classification scheme for security weak-
nesses in Ethereum smart contracts that is referenced in Mythril’s
GitHubrepository.Wealsoextractedvulnerabilitiesthatcomefrom
trusted entities in blog posts where smart contracts are audited,tested or discussed such as Positive.com
6and Blockchain.unica7.
And finally, we used Etherscan8to collect smart contracts that are
deployed on the Ethereum network and are known to contain vul-
nerabilities(e.g.theoriginalSmartBillionscontract).Notethatall
thecontractswerecollectedfromtrustedentitiesinthefield.We
also ensure the traceability of each contract by providing the URL
from which they were taken and its author, where possible.
Dataset Statistics. The dataset contains 69 contracts and 115
tagged vulnerabilities, divided into ten categories of vulnerabilities.
Table 3 presents information about the 69 contracts. Each line
contains a category of vulnerability. For each category, we provide
a description, the level at which the attack can be mitigated, thenumberofcontractsavailablewithinthatcategory,andthetotal
number of lines of code in the contracts of that category.
Dataset Availability. The dataset is available in the reposi-
tory of SmartBugs [ 14]. The dataset is divided into ten folders
named withthe DASP categories, andthe folders contain thecon-
tracts of that category. Moreover, the dataset contains the file
vulnerabilities.json which contains the details of each vul-
nerable contract. It details the name, the origin URL, the path, and
the lines and the category of the vulnerabilities.
2.3.2 sbwild: 47,518 Contracts from the Ethereum Blockchain.
Goal.The goal of this second dataset is to collect as many smart
contracts as possible from the Ethereum blockchain, in order to
have a representative picture of the practice and (potential) vulner-
abilities that are present in the production environment.
Collection Methodology. The data collection for the second
dataset follows a different strategy. In this dataset, we collect all
the different contracts from the Ethereum blockchain. Etherscan
allowsdownloadingthesourcecodeofacontractifyouknowits
address.Therefore,wefirstlyuseGoogleBigQuery[ 29]tocollect
the Ethereum contract addresses that have at least one transaction.
WeusedthefollowingBigQueryrequesttoselectallthecontract
4not-so-smart-contracts: https://github.com/crytic/not-so-smart-contracts
5SWC Registry: https://smartcontractsecurity.github.io/SWC-registry
6Positive.com: https://blog.positive.com
7Blockchain.unica: http://blockchain.unica.it/projects/ethereum-survey/
8Etherscan: https://etherscan.ioaddresses and count the number of transactions that are associated
with each contract9:
SELECT contracts.address, COUNT(1) AS tx_count
FROM `ethereum_blockchain.contracts` AS contracts
JOIN `ethereum_blockchain.transactions` AS transactions
ON (transactions.to_address = contracts.address)
GROUP BY contracts.addressORDER BY tx_count DESC
After collecting all the contract addresses, we used Etherscan
and its API to retrieve the source code associated with an address.
However,Etherscandoesnothavethesourcecodeforeverycon-
tract.Therefore,attheendofthisstep,weobtainedaSolidityfile
foreachcontractthathasitssourcecodeavailableintheEtherscan
platform.
The finalstep wasto filterthe set ofcontracts toremove dupli-
cates.Indeed,weobservethat95%oftheavailableSoliditycontracts
are duplicates. We consider that two contracts are duplicates when
the MD5 checksums of the two source files are identical after re-
moving all the spaces and tabulations.
DatasetStatistics. Table4presentsthestatisticsofthisdataset.
The query on Google BigQuery retrieved 2,263,096 smart contract
addresses. We then requested Etherscan for the Solidity source
codeofthosecontracts,andweobtained972,975Solidityfiles.This
means that 1,290,074 of the contracts do not have an associated
sourcefileinEtherscan.Thefilteringprocessofremovingduplicate
contractsresultedin47,518uniquecontracts(atotalof9,693,457
lines).AccordingtoEtherscan,47contractsthatwerequesteddo
not exist (we labelled those as Unaccessible).
Dataset Availability. The dataset is available on GitHub [ 15].
The dataset contains the Solidity source code of each of the 47,518
contracts.Thecontractsarenamedwiththeaddressofthecontract.
We also attached with this dataset additional information in order
to use this dataset for other types of studies. It contains: •the
nameofthecontract; •theSolidityversionthathasbeenusedto
compilethecontract; •theaddressesoftheduplicatedcontracts;
•the number of transactions associated with the contract; •the
sizeofthecontractinlinesofSoliditycode; •thedateofthelast
transactionsforthe2,263,096contracts; •thedateofcreationfor
the 2,263,096 contracts; and •the Ethereum balance of 972,975
contracts that have their source code available.
2.4 The Execution Framework: SmartBugs
WedevelopedSmartBugs,anexecutionframeworkaimingatsimpli-
fying the execution of analysis tools on datasets of smart contracts.
SmartBugs has the following features: •A plugin system to easily
add new analysis tools, based on Docker images; •Parallel exe-
cution of the tools to s peed up the ex ecution time; •An output
mechanism that normalizes the way the tools are outputting the
results, and simplify the process of the output across tools.
SmartBugs currently supports 9 tools (see Section 2.2).
9The query isalso available at the followingURL: https://bigquery.cloud.google.com/
savedquery/281902325312:47fd9afda3f8495184d98db6ae36a40c
533Table 3: Categories of vulnerabilities available in the dataset sbcurated. For each category, we provide a description, the level
atwhichtheattackcanbemitigated,thenumberofcontractsavailablewithinthatcategory,andthetotalnumberoflinesof
code in the contracts of that category (computed using cloc 1.82).
Category Description Level Contracts Vulns LoC
Access Control Failure to use function modifiers or use of tx.origin Solidity 17 19 899
Arithmetic Integer over/underflows Solidity 14 22 295
Bad Randomness Malicious miner biases the outcome Blockchain 8 31 1,079
Denial of service The contract is overwhelmed with time-consuming computations Solidity 6 7 177
Front running Twodependent transactionsthat invokethe same contractare includedin oneblock Blockchain 4 7 137
Reentrancy Reentrant function calls make a contract to behave in an unexpected way Solidity 7 8 778
Short addresses EVM itself accepts incorrectly padded arguments EVM 1 1 18
Time manipulation The timestamp of the block is manipulated by the miner Blockchain 4 5 76
Unchecked low level
callscall(), callcode(), delegatecall() or send() fails and it is not checked Solidity 5 12 225
Unknown Unknowns Vulnerabilities not identified in DASP 10 N/A 3 3 115
Total 69 115 3,799
Table 4: Statistics on the collection of Solidity smart con-
tracts from the Ethereum blockchain.
Solidity source not available 1,290,074
Solidity source available 972,975
Unaccessible 47
Total 2,263,096
Unique Solidity Contracts 47,518
LOC 9,693,457
2.4.1 Architecture. SmartBugs is composed of five main parts:
(1)Thefirstconsistsofthecommand-lineinterfacetouseSmart-
Bugs (see Section 2.4.2). (2) The second part contains the tool plug-
ins.Eachtoolplugincontainstheconfigurationofthetools.Theconfiguration contains the name of the Docker image, the nameof the tool, the command line to run the tool, the description of
thetool,andthelocationoftheoutputofresults.(3)TheDocker
imagesthatarestoredonDockerHub.WeuseDockerimagesof
the tools when a Docker image is already available; otherwise, wecreate our own image (all Docker images are publicly available on
Docker Hub, including our own). (4) The datasets of smart con-
tracts(seeSection2.3).(5)TheSmartBugs’runnerputsalltheparts
ofSmartBugstogethertoexecutetheanalysistoolsonthesmart
contracts.
2.4.2 DatasetInterfaceDetails. SmartBugsprovidesacommand-
line interface that simplifies the execution of the smart contract
analysistools.IttakesasetoftoolnamesandapathtoSolidityfiles
to analyze and produces two files per execution: 1) a result.log
filethatcontainsthestdoutoftheexecutionand2)a result.json
file that contains the results of the analysis in a parsable format.
Moreover,weprovidescriptsthatprocessthoseoutputsandrender
them in readable tables such as the one presented in this paper.
2.5 Data Collection and Analysis
Toanswerourresearchquestions,weusedSmartBugstoexecute
the9toolsonthetwodatasetsdescribedinSection2.3.Wecollected
the output and used it for further analysis. In this section, wedescribethesetupofthetools(Section2.5.1)andtheirexecution
(Section 2.5.2).
2.5.1 Tools’ Setup. For this experiment, we set the time budget to
30 minutes per analysis. In order to identify a suitable time budget
foroneexecutionofonetooloveronecontract,wefirstexecuted
allthetoolson sbcurateddataset.Wethenselectedatimebudget
that is higher than the average execution time (one minute and 44
seconds). If the time budget is spent, we stop the execution and
collect the partial results of the execution. During the execution of
our experiment, Manticore was the only tool that faced timeouts.
2.5.2 Large-scale Execution. To our knowledge, we present the
largest experimental study on smart contract analysis, both in the
numberoftoolsandinexecutiontime.Intotal,weexecuted9anal-
ysis tools on 47,518 contracts. This represents 428,337 analyzes,
which took approximately 564 days and 3 hours of combined ex-
ecution,morethanayearofcontinuousexecution.Weusedtwocloud providers to rent the servers required for this experiment.
The first provider was Scaleway
10, where we used three servers
with32vCPUswith128GBofRAM.Weaddedabudgetof500 e,
and we spent 474.99 e.
ThesecondproviderwasGoogleCloud11,wherewealsoused
threeserverswith32vCPUswith30GBofRAM.Wespent1038.46 e
with Google Cloud. In total, we spent 1513.45 eto execute the
experiments discussed in this paper. We used two cloud providers
due to administrative restrictions on our budget line. We were
initiallytargetingScalewaybecauseitischeaperthanGoogleCloud,
but we were not able to spend more than 500 ewith this provider.
All the logs and the raw results of the analysis are available at [ 13].
3 RESULTS
The results of our empirical study, as well as the answers to our
research questions, are presented in this section.
3.1 Precision of the Analysis Tools (RQ1)
Toanswerthefirstresearchquestion,weused sbcurated,thedataset
of69contractsdescribedinSection2.3.1.Sinceeachcontractofthis
10Scaleway: https://www.scaleway.com
11Google Cloud: https://cloud.google.com
534Table5:Vulnerabilitiesidentifiedpercategorybyeachtool.Thenumberofvulnerabilitiesidentifiedbyasingletoolisshown
in brackets.
Category HoneyBadger Maian Manticore Mythril Osiris Oyente Securify Slither Smartcheck Total
Access Control 0/19 0% 0/19 0% 4/19 21% 4/19 21% 0/19 0% 0/19 0% 0/19 0% 4/19 21% (1) 2/19 11% 5/19 26%
Arithmetic 0/22 0% 0/22 0% 4/22 18% 15/22 68% 11/22 50% (2) 12/22 55% (2) 0/22 0% 0/22 0% 1/22 5% 19/22 86%
Denial Service 0/7 0% 0/7 0% 0/7 0% 0/7 0% 0/7 0% 0/7 0% 0/7 0% 0/7 0% 0/7 0% 0/ 7 0%
Front Running 0/7 0% 0/7 0% 0/7 0% 2/7 29% 0/7 0% 0/7 0% 2/7 29% 0/7 0% 0/7 0% 2/ 7 29%
Reentrancy 0/8 0% 0/8 0% 2/8 25% 5/8 62% 5/8 62% 5/8 62% 5/8 62% 7/8 88% (2) 5/8 62% 7/ 8 88%
Time Manipulation 0/5 0% 0/5 0% 1/5 20% 0/5 0% 0/5 0% 0/5 0% 0/5 0% 2/5 40% (1) 1/5 20% (1) 3/ 5 60%
UncheckedLowCalls 0/12 0% 0/12 0% 2/12 17% 5/12 42% (1) 0/12 0% 0/12 0% 3/12 25% 4/12 33% (3) 4/12 33% (1) 9/12 75%
Other 2/3 67% 0/3 0% 0/3 0% 0/3 0% 0/3 0% 0/3 0% 0/3 0% 3/3 100% (1) 0/3 0% 3/ 3 100%
Total 2/115 2% 0/115 0% 13/115 11% 31/115 27% 16/115 14% 17/115 15% 10/115 9% 20/115 17% 13/115 11% 48/115 42%
Table 6: Total number of detected vulnerabilities by each tool, including vulnerabilities not tagged in the dataset.
Category HoneyBadger Maian Manticore Mythril Osiris Oyente Securify Slither Smartcheck Total
Access Control 010 28 24 0 0 620 3 91
Arithmetic 0 0 11 92 62 69 0 0 23 257
Denial of Service 0 0 0 027 11 0 2 19 59
Front Running 0 0 0 21 0 0 55 0 0 76
Reentrancy 0 0 4 16 5 5 32 15 7 84
Time Manipulation 0 0 4 0 4 5 0 5 2 20
Unchecked Low Level Calls 0 0 4 30 0 0 21 13 14 82
Unknown Unknowns 5 2 25 32 0 0 028 8100
Total 512 76 215 98 90 114 83 76 769
dataset is categorized in one of the ten DASP categories, we can
compute the ability of the 9 tools in detecting the vulnerabilities
present in the69 contracts. Themethodology that we followedto
answerthisresearchquestionwasthefollowing:(1)Weexecuted
the 9 tools on the 69 contracts. The result of this execution is avail-
able on GitHub [ 13]. (2) We extracted all the vulnerabilities that
were detected by the tools into a JSON file. (3) We mapped the de-
tectedvulnerabilitiestoacategoryofvulnerabilities(seeTable3).Toachievethistask,wemanuallyannotatedallthevulnerabilitytypes
thathavebeendetectedintooneofthetenDASPcategories.For
example,Oyentedetectsavulnerabilitycalled Integer Overflow
that we link to the category Arithmetic. In total, we identify 141
vulnerability types, and 97 of them have been tagged in one of the
ten categories. The remaining 44 do not fit the DASP taxonomy
(for example, some tools warn about the use of inline assembly,
which is considered a bad practice but does not necessarily lead to
vulnerablecontracts)12(4)Atthispoint,wewereabletoidentify
which vulnerabilities the tools detect. Unfortunately, we found out
that none of the 9 tools were able to detect vulnerabilities of the
categories Bad Randomness andShort Addresses. This is unsurpris-
ing: it is expected that tools do not detect vulnerabilities of certain
categories, since they are not designed to identify all types of vul-
nerabilities. Despite not seeing this as a limitation of the studied
tools, we argue that our analysis gives insight on opportunities to
improve them, since it provides an overview on how tools perform
with respect to the taxonomy used.
TheresultsofthisfirststudyarepresentedinTable5andTable6.
Thefirsttablepresentsthenumberofknownvulnerabilitiesthat
12The mapping that we created is available at: https://github.com/smartbugs/
smartbugs/wiki/Vulnerabilities-mapping.have been identified. A vulnerability is considered as identified
whenatooldetectsavulnerabilityofaspecificcategoryataspecific
line, and it matches the vulnerability that has been annotated in
thedataset.EachrowofTable5representsavulnerabilitycategory,
and each cell presents the number of vulnerabilities where the
tooldetectsavulnerabilityofthiscategory.SomecellsinTable5
have numbers enclosed in brackets: these denote the number of
vulnerabilities identified by a single tool. This table summarizes
the strengths and weaknesses of the current state of the art of
smartcontractanalysistools.Itshowsthatthetoolscanaccuratelydetectvulnerabilitiesofthecategories Arithmetic, Reentrancy, Time
manipulation, Unchecked Low Level Calls, and Unknown Unknowns.
Withrespecttothecategory UnknownUnknowns,thetoolsdetected
vulnerabilities such as the presence of uninitialized data and the
possibilityoflockingdownEther.However,theyw erenotaccurate
in detecting vulnerabilities of the categories Access Control, Denial
ofservice,and Frontrunning.Thecategories BadRandomness and
Short Addresses are not listed, since none of the tools are able to
detectvulnerabilitiesofthesetypes.Thisshowsthatthereisstill
room for improvement and, potentially, for new approaches to
detect vulnerabilities of the ten DASP categories.
Table5alsoshowsthatthetoolsofferdistinctaccuracies.Indeed,
thetoolMythrilhasthebestaccuracyamongthe9tools. Mythril
detects27%ofallthevulnerabilitieswhentheaverageofalltools
is 12%. The ranking of the tools is comparable to the one observed
by Parizi et al.[34]. However, the average accuracy is lower on
our benchmark sbcurated. Moreover, Mythril,Manticore, Slither,
andSmartcheck are the tools that detect the largest number of
differentcategories(5categories).Wecanalsoseethat Slitheristhe
tool that uniquely identifies more vulnerabilities (8 vulnerabilities
535across5categories).Despiteitsgoodresults, Mythrilisnotpowerful
enoughtoreplaceallthetools:bycombiningthedetectionabilities
ofallthetools,wesucceedtodetect42%ofallthevulnerabilities.
However, depending on the available computing power, it might
not be realistic to combine all the tools.
Therefore, we suggest the combination of MythrilandSlither.
Thiscombinationdetects42(37%)uniquevulnerabilities.Thiscom-
binationoffersagoodbalancebetweenperformanceandexecution
cost.Thiscombinationisthebestpossiblecombinationbyaconsid-
erable margin. The second best combination, MythrillandOyente,
only succeeds to detect 33 (29%) of all the vulnerabilities.
Wenowconsiderallthevulnerabilitydetectionsandnotonlythe
ones that have been tagged in sbcurated. Table 6 presents the total
numberofvulnerabilitiesdetectedbythetools.Thistableallows
thecomparisonofthetotalnumberofdetectedvulnerabilitieswith
the number of detected known vulnerabilities shown in Table 5.
The tools that are performing the best are also producing much
more warnings (i.e., their output is more noisy), making it difficult
for a developer to exploit their results.
Answer to RQ1 .What is the accuracy of current analysis
tools in detecting vulnerabilities on Solidity smart con-tracts?
By combining the 9 tools together, they are only able
todetect42%ofallthevulnerabilities.Thisshowsthatthereis
stillroomtoimprovetheaccuracyofthecurrentapproachesto
detectvulnerabilitiesinsmartcontracts.Weobservethatthetools
underperform to detect vulnerabilities in the following three cat-
egories:Access Control, Denial of service, and Front running. They
areunable todetect by designvulnerabilities from Bad Random-
nessandShort Addresses categories. We also observe that Mythril
outperformstheothertoolsbythenumberofdetectedvulnerabil-
ities (31/115, 27%) and by the number of vulnerability categories
thatittargets(5/9categories).Thecombinationof Mythriland
Slitherallows detecting a total of 42/115 (37%) vulnerabilities,
which is the best trade-off between accuracy and execution costs.
3.2 Vulnerabilities in Production Smart
Contracts (RQ2)
To answer the second research question, we analyzed the ability of
the9selectedtoolstodetectvulnerabilitiesinthecontractsfrom
the dataset sbwild(described in Section 2.3.2). We followed the
same methodology asin the previous research question, however,
forsbwild, we do not have an oracle to identify the vulnerabilities.
Table7presentstheresultsofexecutingthe9toolsonthe47,518
contracts. It shows that the 9 tools are able to detect eight different
categories of vulnerabilities.Note that the vulnerabilities detected
byHoneyBadger arecontractsthatlookvulnerablebutarenot.They
are designed to look vulnerable in order to steal Ether from people
thattriestoexploitthevulnerability.Intotal,44,589contracts(93%)
have at least one vulnerability detected by one of the 9 tools.
Suchahighnumberofvulnerablecontractssuggeststhepres-
enceofaconsiderablenumberoffalsepositives. Oyenteistheap-
proachthatidentifiesthehighestnumberofcontractsasvulnerable
(73%),mostlyduetovulnerabilitiesinthe Arithmetic category.This
observation is coherent with the observation of Parizi et al.[34],050100Honeybadger1234+
050100Maian
050100Manticore
050100Mythril
050100Osiris
050100Oyente
050100Securify
050100Slither
050100Smartcheck
Access Control
Arithmetic
Denial of Service
Front Running
Reentrancy
Time Manipulation
Unchecked Calls
Unknown Unknowns050100Total
Figure 1: Proportion of vulnerabilities identified by exactlyone (1), two (2) or three (3) tools, and by four tools or more
(4+).
536Table 7: The total number of contracts that have at least one vulnerability (analysis of 47,518 contracts).
Category HoneyBadger Maian Manticore Mythril Osiris Oyente Securify Slither Smartcheck Total
Access Control 0 0% 44 0% 47 0% 1,076 2% 0 0% 2 0% 614 1% 2,356 4% 384 0% 3,801 8%
Arithmetic 1 0% 0 0% 102 0% 18,515 39% 13,922 29% 34,306 72% 0 0% 0 0% 7,430 15% 37,597 79%
Denial of Service 0 0% 0 0% 0 0% 0 0% 485 1% 880 1% 0 0% 2,555 5% 11,621 24% 12,419 26%
Front Running 0 0% 0 0% 0 0% 2,015 4% 0 0% 0 0% 7,217 15% 0 0% 0 0% 8,161 17%
Reentrancy 19 0% 0 0% 2 0% 8,454 17% 496 1% 308 0% 2,033 4% 8,764 18% 847 1% 14,747 31%
Time Manipulation 0 0% 0 0% 90 0% 0 0% 1,470 3% 1,452 3% 0 0% 1,988 4% 68 0% 4,069 8%
Unchecked Low
Calls0 0% 0 0% 4 0% 443 0% 0 0% 0 0% 592 1% 12,199 25% 2,867 6% 14,656 30%
Unknown Un-
knows26 0% 135 0% 1,032 2% 11,126 23% 0 0% 0 0% 561 1% 9,133 19% 14,113 29% 28,355 59%
Total 46 0% 179 0% 1,203 2% 22,994 48% 14,665 30% 34,764 73% 8,781 18% 22,269 46% 24,906 52% 44,589 93%
sincetheydeterminethat Oyentehasthehighestnumberoffalse
positives when compared to Mythril,Securify, and Smartcheck.
Since we observed a potentially large number of false positives,
weanalyzedtowhatextentthetoolsagreeinvulnerabilitiesthey
flag. The hypothesis is that if a vulnerability is identified exclu-
sively by a single tool, the probability of it being a false positive
increases. Figure 1 presents the results of this analysis. This figure
shows the proportion of detected vulnerabilities that have been
identified exclusively by one tool alone, two tools, three tools, and
finallybyfourormoretools. HoneyBadger hasapeculiar,butuseful
role: ifHoneyBadger detects a vulnerability, it actually means that
thevulnerabilitydoesnotexist.So,consensuswith HoneyBadger
suggests the presence of false positives.
It is clear from the figure that the large majority of the vulnera-
bilities have been detected by one tool only. One can observe that
there are 71.25% of the Arithmetic vulnerabilities found by more
than one tool. It is also the category with the highest consensus
betweenfourandmoretools:937contractsareflaggedashavingan
Arithmetic vulnerability with a consensus of more than three tools.
It is followed by the Reentrancy category with 133 contracts receiv-
ing a consensus of four tools or more. These results suggest that
combiningseveralofthesetoolsmayyieldmoreaccurateresults,
with fewer false positives and negatives.
The toolHoneyBadger is different: instead of detecting vulnera-
bilities, it detects malicious contracts that try to imitate vulnerable
contracts in order to attract transactions to their honeypots. There-
fore, when HoneyBadger is detecting a Reentrancy vulnerability, it
means that the contract looks vulnerable to Reentrancy but it is
not. Figure 1 shows that 15 contracts identified by HoneyBadger
withvulnerabilitiesoftype Reentrancy havebeendetectedbythree
other tools as Reentrancy vulnerable.
Wealsoanalyzedtheevolutionofthevulnerabilitiesovertime.
Figure 2 presents the evolution of the number of vulnerabilities by
category. It firstly shows that the total number of unique contracts
started to increase exponentially at the end of 2017 when Ether
wasatitshighestvalue.Secondly,wecanobservetwomaingroups
of curves. The first one contains the categories Arithmetic and
Unknown Unknowns. These two categories follow the curve of the
total number of contracts. The second group contains the othercategories. The growing number of vulnerable contracts seemsto slow down from July 2018. Finally, this figure shows that the
evolutionofcategories Reentrancy andUncheckedLowLevelCalls is2015-07 2016-01 2016-07 2017-01 2017-07 2018-01 2018-07 2019-01 2019-07
Creation date010000200003000040000 # Contracts# Unknown Unknowns
# Access Control
# Arithmetic
# Denial of Service
# Front Running
# Reentrancy
# Time Manipulation
# Unchecked Low Level Calls
# Contracts
Figure 2: Evolution of number of vulnerabilities over time.
Figure3:Correlationbetweenthenumberofvulnerabilitiesand balance in Wei (one Ether is 10
18Wei).
extremelysimilar(thegreenlineof Reentrancy isalsohiddenbythe
blue line of Unchecked Low Level Calls ). This suggests a correlation
between vulnerabilities in these two categories.
Andlastly,Figure3presentsthecorrelationbetweenthenumber
ofvulnerabilitiesandthebalanceofthecontracts.Itshowsthatthe
contracts that have a balance between 1014Wei and 1020Wei have
morevulnerabilitiesthanothercontracts.Hence,therichestandthemiddle class seem to be less impacted. Per category, we have
not observed any significant differences worth reporting.
537Answer to RQ2 .How many vulnerabilities are present in
the Ethereumblockchain? The 9 tools identify vulnerabilities
in 93% of the contracts, which suggests a high number of false
positives. Oyente, alone, detects vulnerabilities in 73% of the con-
tracts. By combining the tools to create a consensus, we observe
thatonlyafewnumberofvulnerabilitiesreceivedaconsensusof
four or more tools: 937 for Arithmetic and 133 for Reentrancy.
3.3 Execution Time of the Analysis Tools (RQ3)
In this section, we present the execution time required by the tools
to analyze the 47,518 of the sbwilddataset (see Section 2.3.2). In
ordertomeasurethetimeoftheexecution,werecordedforeach
individualanalysiswhenitstartedandwhenitended.Theduration
of the analysisis the difference betweenthe starting time andthe
ending time. An individual execution is composed of the following
steps:1)starttheDockerimageandbindthecontracttotheDocker
instance; 2) clean the Docker container; and 3) parse and output
the logs to the results folder.
Table8presentstheaverageandtotaltimesusedbyeachtool.
The average execution time is per contract. It considers the execu-
tion of the tool on a contract, including compilation, construction
of IR/graphs,analysis andparsing theresults. In thetable, wecan
observethreedifferentgroupsofexecutiontime:thetoolsthattake
a few seconds to execute, the tools that take a few minutes, and
Manticore that takes 24 minutes. Oyente,Osiris,Slither,Smartcheck,
andSolhintaremuchfastertoolsthattakebetween5and30sec-
onds on average to analyze a smart contract. HoneyBadger, Maian,
Mythril,and Securifyareslowerandtakebetween1m24sand6m37s
toexecute.Finally,Manticoretakes24m28s.Thedifferenceinexecu-tiontimebetweenthetoolsisdependentonthetechniquethateach
tool uses. Pure static analysis tools such as Smartcheck andSlither
are fast since they do not need to compile nor execute contracts to
identify vulnerabilities and bad practices.
Securify,Maian,Mythril,and Manticore analyzetheEVMbyte-
codeofthecontracts.Itmeansthatthosetoolsrequirethecontract
tobecompiledbeforedoingtheanalysis.Theadditionalcompila-
tionstepslowsdowntheanalysis. Manticore istheslowestofallthe
tools because this tool only analyzes an internal contract at a time
(Soliditysourcefilescancontainanarbitrarynumberofcontract
definitions). Consequently, this tool has the major drawback of
having the compilation overhead for each internal contract that it
analyzes.
Theaverageexecutiontimedoesnotreflectthecompletepicture
of the performance of a tool. For example, MaianandManticore
use several processes, and Maianuses up to 16GB of RAM. Conse-
quently,MaianandManticore aredifficulttoparallelize.Wewere
abletorunonlyfour,andtenparallelexecutionsforrespectively
MaianandManticore on a 32-core server with 30GB of RAM. This
alsoexplainswhywewerenotabletoexecutethosetwotoolson
the complete dataset of 47,518 smart contracts.
Interestingly, the slowest tools do not have better accuracy (see
Section 3.1). Mythril, for example, which has the best accuracy
accordingtoourevaluation,takesonaverageof1m24stoanalyzeacontract.Itismuchfasterthan Manticore thatonlyhasanaccuracy
of 11% compared to the 27% of Mythril.Table 8: Average execution time for each tool.
# ToolsExecution time
Average Total
1 Honeybadger 0:01:38 23 days, 13:40:00
2 Maian 0:05:16 49 days, 10:06:15
3 Manticore 0:24:28 184 days, 01:59:02
4 Mythril 0:01:24 46 days, 07:46:55
5 Osiris 0:00:34 18 days, 10:19:01
6 Oyente 0:00:30 16 days, 04:50:11
7 Securify 0:06:37 217 days, 22:46:26
8 Slither 0:00:05 2 days, 15:09:36
9 Smartcheck 0:00:10 5 days, 12:33:14
Total 0:04:31 564 days, 3:10:39
Theexecutiontimeof Maianissurprisingcomparedtotheresults
that have been presented in the Maianpaper [32]. Indeed, the
authors claimed that it takes on average 10 seconds to analyze a
contractwhileweobservethatittakes5m16sinourexperimentonsimilarhardware.The difference inexecution timescanpotentiallybeexplainedbythedifferenceofinputusesinthetwoexperiments.
Weusethesourcecodeofthecontractasinput,and Maian’sauthors
use the bytecode. The overhead for the compilation of the contract
seems to be the major cost of execution for this tool.
Answer to RQ3 .How long do the tools require to analyze
the smart contracts? On average, the tools take 4m31s to an-
alyze one contract. However, the execution time largely varies
between the tools. Slitheris the fastest tool and takes on average
only5secondstoanalyzeacontract. Manticore istheslowesttool.
Ittakesonaverage24m28stoanalyzeacontract.Wealsoobserve
thattheexecutionspeedisnottheonlyfactorthatimpactsthe
performance of the tools. Securifytook more time to execute
thanMaian, but Securifycan easily be parallelized and therefore
analyze the 47,518 contracts much faster than Maian. Finally, we
have not observed a correlation between accuracy and execution
time.
4 DISCUSSION
Wediscussthepracticalimplicationsofourfindingsfromtheprevi-
ous section, as well as outline the potential threats to their validity.
4.1 Practical Implications and Challenges
Despitetheadvancesinautomaticanalysistoolsofsmartcontracts
during the last couple of years, the practical implication our study
highlightsisthatthereremainseveralopenchallengestobetack-
led by future work. We identify four core challenges: increasingand ensuring the quality of the analysis, extending the scope of
problemsaddressedbythesetools,integratingtheanalysisintothe
development process, and extending the current taxonomy.
Quality:Thischallengeisaboutincreasingthelikelihoodthat
a tool identifies real vulnerabilities, yielding close to zero false
positivesandfalsenegatives.Ourstudydemonstratesthatthisis
far from being the case, and future work should be invested inimproving the quality of the tools. Addressing this challenge is
perhaps an important step toward real-life adoption of these tools
and techniques.
538Scope:Although there might not be a technique that finds all
sorts of vulnerabilities, this challenge is about further extending
existing techniquesso thatmore real vulnerabilitiescan be found.
In the previous section, we briefly discussed a potential way to
address thischallenge: craftinga noveltechnique combiningcom-
plementarytools.Combiningstaticwithdynamicanalysismight
also be an interesting avenue for future work.
Developmentprocess: Thischallengeisaboutintegratingthese
toolsintothedevelopmentprocess,thuscontributingtoreal-life
adoption. To ease the interaction of developers with these tools,
hencemakingthemusefulduringthedevelopmentlife-cycle,the
following could bring added value:integration with other orthog-
onal techniques (such as bug detection tools, dynamic analysis
techniques, and generic linters), integration with popular IDEs, in-
teractivereports(e.g.,highlightvulnerablecode),andexplainable
warnings.
Taxonomy: Anotherpracticalimplicationofourworkisthatthe
current state-of-the-art set of 10 categories in DASP10 does not
seem to be comprehensive enough to cover all vulnerabilities that
affect smart contracts deployed in Ethereum. DASP10 includes the
category Unknown Unknowns, because as the creators of the DASP
taxonomyobserved, aslongasinvestorsdecidetoplacelargeamounts
ofmoneyoncomplexbutlightly-auditedcode,wewillcontinuetosee
newdiscoveriesleadingtodireconsequences.Ourworkshedslight
on potential new categories that could extend DASP10, such as
Dependence on environment data andLocked Ether. The latter could
includenotonlythecaseswhereEtherislockedindefinitely,but
also cases of Honeypots as defined by Torres et al.[41] (since Ether
becomes locked, except for the attacker). Our findings suggest new
categoriescomparabletothoseproposedintherecentsurveyby
Chenet al.[7] (available online on August 13, 2019).
4.2 Threats to Validity
A potential threat to the internal validity is that, due to the com-
plexityoftheSmartBugsframework,theremayremainanimple-
mentation bug somewhere in the codebase. We extensively tested
theframeworktomitigatethisrisk.Furthermore,theframework
andtherawdataarepubliclyavailableforotherresearchersand
potential users to check the validity of the results.
Apotentialthreattotheexternalvalidityisrelatedtothefactthat
thesetofsmartcontractswehaveconsideredinthisstudymaynot
beanaccuraterepresentationofthesetofvulnerabilitiesthatcan
happen during development. We attempt to reduce the selectionbias by leveraging a large collection of real, reproducible smartcontracts. Another potential threat is that we may have misseda tool or failed to reproduce a tool that excels all other tools. To
mitigatethisrisk,wecontactedtheauthorsofthetoolsifnosource
code was found. We also aim to reduce threats to external validity
andensurethereproducibilityofourevaluationbyprovidingthe
source of our instrumentation tool, the scripts used to run the
evaluation, and all data gathered.
Apotentialthreattotheconstructvalidityrelatestothefactthat
we needed to manually label the vulnerable smart contracts into
one of the DASP categories, and these could be mislabeled. This
riskwas mitigated asfollows:all authorslabeledthe contracts, andthen disagreements were discussed to reach a consensus. Another
potential threat to the validity is the timeout used for the analysis:
30 minutes. This threat was mitigated by executing all the tools on
the sbcurateddataset.
The analysis based on the dataset sbwildis valuable for it gives
a sense of the potential noise that tools might generate whenanalysing contracts. However, with suc h a large dataset, the dis-
cussiononthenumberoffalsepositivesischallengingandthere
is a risk that too many false positives are identified. To mitigate
this risk, we decided to use consensus as a proxy: the hypothesis isthat the greater the number of tools identifying a vulnerability, the
more likely that vulnerability is a true positive.
5 RELATED WORK
As discussed in Section 2.2, there are several automated analysis
toolsavailable.Notwithstanding,despitetherecentincreaseinterest
in the analysis of smart contracts, to the best of our knowledge,
ourworkisthefirstsystematiccomparisonofrecentlyproposed
techniques to better understand their real capabilities.
Datasets and Repositories: Reproducibility is enabled by a bench-
mark containing smart contracts that other researchers canuseoff-the-shelf. There are just a few repositories of smart
contracts available to the research community, such as VeriS-
martBench13,evm-analyzer-benchmark-suite14,EthBench15,smart-
contract-benchmark16, andnot-so-smart-contracts17. These, how-
ever,areessentiallycollectionsofcontractsandarenotdesignedtoenablereproducibilitynortofacilitatecomparisonofresearch.
Our dataset sbcuratedoffers a known vulnerability taxonomy, po-
sitioning itself as a reference dataset to the research community.
Empiricalstudies: Chenetal.[8]discussedanempiricalstudyon
codesmellsforEthereumsmartcontracts.BasedonpostsfromStack
Exchange and real-world smart contracts, they defined 20 distinct
code smells for smart contracts and categorized them into security,
architecture,andusabilityissues.Furthermore,theymanuallyla-
beledadatasetofsmartcontracts.18Pinnaetal.[36]performeda
comprehensive empirical study of smart contracts deployed on the
Ethereum blockchain with the objective to provide an overviewofsmartcontractsfeatures,suchastypeoftransactions,theroleof the development community, and the source code characteris-tics. Parizi et al.[
34] carried out an experimental assessment of
static smart contracts security testing tools. They tested Mythril,
Oyente,Securify,andSmartcheckontenreal-worldsmartcontracts.
Concerning the accuracy of the tools, Mythril was found to be the
most accurate.Our results corroboratethe findings,but in amore
systematic and comprehensive manner.
Execution Frameworks: Execution frameworks to simplify and
automate the execution of smart contract analysis tools are scarce.
Solhydra [ 10] is a CLI tool to analyze Solidity smart contracts with
several static analysis tools. It generates a report with results of
13VeriSmartBench: https://github.com/soohoio/VeriSmartBench
14evm-analyzer-benchmark-suite: https://github.com/ConsenSys/evm-analyzer-
benchmark-suite
15EthBench: https://github.com/seresistvanandras/EthBench
16smart-contract-benchmark: https://github.com/hrishioa/smart-contract-benchmark
17not-so-smart-contracts: https://github.com/crytic/not-so-smart-contracts
18CodeSmell: https://github.com/CodeSmell2019/CodeSmell
539thetoolanalysis.UnlikeSmartBugs,whichwasdesignedtoease
the addition of new analysis tools, Solhydra does not offer thisflexibility. Furthermore, Solhydra has not been updated in more
than a year.
6 CONCLUSION
In this paper, we presented an empirical evaluation of 9 automated
analysistoolson69annotatedvulnerablecontractsandon47,518
contracts taken from the Ethereum’s network. The goal of thisexperiment was to obtain an overview of the current state of au-
tomatedanalysistoolsforEthereumsmartcontracts.Duringthis
empiricalevaluation,weconsideredallavailablesmartcontracts
analysis tools and all the available Ethereum contracts that haveat least one transaction. We used the DASP10 category of smart
contract vulnerabilities as the reference to classify vulnerabilities.
We found out that the current state of the art is not able to
detectvulnerabilitiesfromtwocategoriesofDASP10: BadRandom-
nessandShort Addresses. Also, the tools are only able to detect
together 48/115 (42%) of the vulnerabilities from our sbcurated
dataset.Mythrilis the tool that has the higher accuracy and is able
to detect 31/115 (27%) of the vulnerabilities.
During the evaluation of the 9 tools on sbwild, we observe that
97% of the contracts are identified as vulnerable. This suggests a
considerable number of false positives. Oyenteplays an important
roleinthis,sinceitdetectsvulnerabilitiesin73%ofthecontracts,
mostly due to Arithmetic vulnerabilities (72%). Finally, we observe
that the tools (4 or more) succeed to find a consensus for 937 Arith-
meticvulnerabilities and 133 Reentrancy vulnerabilities.
Wearguethattheexecutionframeworkandthetwonewdatasets
presentedherearevaluableassetsfordrivingreproducibleresearch
in automated analysis of smart contracts.
ACKNOWLEDGMENTS
Thisworkhasbeenco-fundedbytheEuropeanUnion’sHorizon
2020 research and innovation programme under the QualiChainproject, Grant Agreement No 822404 and supported by national
funds through FCT, Fundação para a Ciência e a Tecnologia, under
projects UIDB/50021/2020 and PTDC/CCI-COM/29300/2017.
REFERENCES
[1]ElviraAlbert,PabloGordillo,BenjaminLivshits,AlbertRubio,andIlyaSergey.
2018. EthIR: A Framework for High-Level Analysis of Ethereum Bytecode. In
AutomatedTechnologyforVerificationandAnalysis,ShuvenduK.LahiriandChao
Wang (Eds.). Springer International Publishing, Cham, 513–520.
[2]Shaun Azzopardi, Joshua Ellul, and Gordon J. Pace. 2018. Monitoring Smart
Contracts: ContractLarva and Open Challenges Beyond. In Runtime Verification,
Christian Colombo and Martin Leucker (Eds.). Springer International Publishing,
Cham, 113–137.
[3]Karthikeyan Bhargavan,Antoine Delignat-Lavaud, CédricFournet, AnithaGol-
lamudi, Georges Gonthier, Nadim Kobeissi, Natalia Kulatova, Aseem Rastogi,
Thomas Sibut-Pinote, Nikhil Swamy, et al .2016. Formal verification of smart
contracts:Shortpaper.In Proceedingsofthe2016ACMWorkshoponProgramming
Languages and Analysis for Security. ACM, New York, NY, USA, 91–96.
[4]LexiBrent,Anton Jurisevic,MichaelKong,EricLiu,Francois Gauthier,Vincent
Gramoli, Ralph Holz, and Bernhard Scholz. 2018. Vandal: A scalable security
analysis framework for smart contracts. arXiv:1809.03981
[5]VitalikButerinetal .2013. Ethereumwhitepaper. GitHubrepository 1,GitHub
(2013), 22–23.
[6]JialiangChang,BoGao,HaoXiao,JunSun,andZijiangYang.2018. sCompile:
Critical path identification and analysis for smart contracts. arXiv:1808.00624
[7]Huashan Chen, Marcus Pendleton, Laurent Njilla, and Shouhuai Xu. 2019. A
Survey on Ethereum Systems Security: Vulnerabilities, Attacks and Defenses.arXiv:1908.04507
[8]Jiachi Chen, Xin Xia, David Lo, John Grundy, Daniel Xiapu Luo, and Ting Chen.
2019. Domain Specific Code Smells inSmart Contracts. arXiv:arXiv:1905.01467
[9]TingChen,XiaoqiLi,XiapuLuo,andXiaosongZhang.2017. Under-optimizedsmartcontractsdevouryourmoney.In 2017IEEE24thInternationalConference
on Software Analysis, Evolution and Reengineering (SANER). IEEE, Klagenfurt,
Austria, 442–446.
[10]Blockchain Company. 2018. Solhydra. https://github.com/BlockChainCompany/
solhydra.
[11]PhilDaian.2016. AnalysisoftheDAOexploit. http://hackingdistributed.com/
2016/06/18/analysis-of-the-dao-exploit/.
[12]M.diAngeloandG.Salzer.2019.ASurveyofToolsforAnalyzingEthereumSmart
Contracts. In 2019 IEEE International Conference on Decentralized Applications
and Infrastructures (DAPPCON). IEEE, Newark, CA, USA, USA, 69–78. https:
//doi.org/10.1109/DAPPCON.2019.00018
[13]Thomas Durieux, João F. Ferreira, Rui Abreu, and Pedro Cruz. 2019. SmartBugs
execution results. https://github.com/smartbugs/smartbugs-results.
[14]Thomas Durieux, João F. Ferreira, Rui Abreu, and Pedro Cruz. 2019. SmartBugs
repository. https://github.com/smartbugs/smartbugs.
[15]Thomas Durieux, João F. Ferreira, Rui Abreu, and Pedro Cruz. 2019. SmartBugs
Wild dataset. https://github.com/smartbugs/smartbugs-wild.
[16]JosselinFeist,GustavoGreico,andAlexGroce.2019. Slither:AStaticAnalysis
FrameworkforSmartContracts.In Proceedingsofthe2NdInternationalWorkshop
onEmergingTrendsinSoftwareEngineeringforBlockchain (WETSEB’19).IEEE
Press, Piscataway, NJ, USA, 8–15. https://doi.org/10.1109/WETSEB.2019.00008
[17]Neville Grech, Michael Kong, Anton Jurisevic, Lexi Brent, Bernhard Scholz, and
YannisSmaragdakis.2018. Madmax:Survivingout-of-gasconditionsinethereum
smart contracts. Proceedings of the ACM on Programming Languages 2, OOPSLA
(2018), 116.
[18]Ilya Grishchenko, Matteo Maffei, and Clara Schneidewind. 2018. A Semantic
Framework for the Security Analysis of Ethereum Smart Contracts. In Principles
of Security and Trust, Lujo Bauer and Ralf Küsters (Eds.). Springer International
Publishing, Cham, 243–269.
[19]Ilya Grishchenko, Matteo Maffei, and Clara Schneidewind. 2018. A Semantic
Framework for the Security Analysis of Ethereum Smart Contracts. In Principles
of Security and Trust, Lujo Bauer and Ralf Küsters (Eds.). Springer International
Publishing, Cham, 243–269.
[20]Peter Hegedus. 2019. Towards analyzing the complexity landscape of solidity
based ethereum smart contracts. Technologies 7, 1 (2019), 6.
[21]EverettHildenbrandt, ManasviSaxena, NishantRodrigues, XiaoranZhu, Philip
Daian,DwightGuth,BrandonMoore,DaejunPark,YiZhang,AndreiStefanescu,etal
.2018. KEVM:Acompleteformalsemanticsoftheethereumvirtualmachine.
In2018 IEEE 31st Computer Security Foundations Symposium (CSF). IEEE, Oxford,
UK, 204–217.
[22]Sukrit Kalra, Seep Goel, Mohan Dhawan, and Subodh Sharma. 2018. ZEUS:
Analyzing Safety of Smart Contracts. In 25th Annual Network and Distributed
System Security Symposium, NDSS 2018, San Diego, California, USA, February
18-21, 2018. NDSS, San Diego, California, USA, 1–15.
[23]Johannes Krupp and Christian Rossow. 2018. teEther: Gnawing at Ethereum
toAutomaticallyExploitSmartContracts.In 27thUSENIXSecuritySymposium
(USENIX Security 18). USENIX Association, Baltimore, MD, 1317–1333. https:
//www.usenix.org/conference/usenixsecurity18/presentation/krupp
[24]Shuvendu K Lahiri, Shuo Chen, Yuepeng Wang, and Isil Dillig. 2018. For-mal Specification and Verification of Smart Contracts for Azure Blockchain.
arXiv:1812.08829
[25]ChaoLiu,HanLiu,ZhaoCao,ZhongChen,BangdaoChen,andBillRoscoe.2018.
Reguard:findingreentrancybugsinsmartcontracts.In Proceedingsofthe40th
International Conference on Software Engineering: Companion Proceeedings . ACM,
New York, NY, USA, 65–68.
[26]Han Liu, Chao Liu, Wenqi Zhao, Yu Jiang, and Jiaguang Sun. 2018. S-gram:
towards semantic-aware security auditing for ethereum smart contracts. In Pro-
ceedingsofthe33rdACM/IEEEInternationalConferenceonAutomatedSoftware
Engineering. ACM, New York, NY, USA, 814–819.
[27]Loi Luu, Duc-Hiep Chu, Hrishi Olickel, Prateek Saxena, and Aquinas Hobor.
2016. Makingsmartcontractssmarter.In Proceedingsofthe2016ACMSIGSAC
conference on computer and communications security. ACM, New York, NY, USA,
254–269.
[28]AnastasiaMavridouandAronLaszka.2018. ToolDemonstration:FSolidMfor
DesigningSecureEthereumSmartContracts.In PrinciplesofSecurityandTrust,
Lujo Bauer and Ralf Küsters (Eds.). Springer International Publishing, Cham,
270–277.
[29]Evgeny Medvedev. 2018. Ethereum in BigQuery: a Public Dataset for smartcontract analytics. https://cloud.google.com/blog/products/data-analytics/
ethereum-bigquery-public-dataset-smart-contract-analytics.
[30]Mark Mossberg, Felipe Manzano, Eric Hennenfent, Alex Groce, Gustavo Grieco,
Josselin Feist, Trent Brunson, and Artem Dinaburg. 2019. Manticore: A User-
Friendly Symbolic Execution Framework for Binaries and Smart Contracts.
arXiv:1907.03890
540[31]Bernhard Mueller. 2018. Smashing ethereum smart contracts for fun and real
profit.In 9thAnnualHITBSecurityConference(HITBSecConf) .HITB,Amsterdam,
Netherlands, 54.
[32]IvicaNikolić, AashishKolluri, IlyaSergey, PrateekSaxena,and AquinasHobor.
2018. Finding the greedy, prodigal, and suicidal contracts at scale. In Proceedings
ofthe34thAnnualComputerSecurityApplicationsConference.ACM,NewYork,
NY, USA, 653–663.
[33]RobertNorvill,BeltranBorjaFizPontiveros,RaduState,andAndreaCullen.2018.
Visual emulation forEthereum’s virtual machine. In NOMS 2018-2018 IEEE/IFIP
Network Operations and Management Symposium. IEEE, Taipei, Taiwan, 1–4.
[34]Reza M. Parizi, Ali Dehghantanha, Kim-Kwang Raymond Choo, and Amritraj
Singh. 2018. Empirical Vulnerability Analysis of Automated Smart Contracts
Security Testing on Blockchains. In Proceedings of the 28th Annual International
Conference on Computer Science and Software Engineering (CASCON ’18). IBM
Corp.,Riverton,NJ,USA,103–113. http://dl.acm.org/citation.cfm?id=3291291.
3291303
[35]Daniel Perez and Benjamin Livshits. 2019. Smart Contract Vulnerabilities: Does
Anyone Care? arXiv:1902.06710
[36]Andrea Pinna, Simona Ibba, Gavina Baralla, Roberto Tonelli, and Michele March-
esi. 2019. A Massive Analysis of Ethereum Smart Contracts Empirical Study and
Code Metrics. IEEE Access 7 (2019), 78194–78213.
[37]MattSuiche.2017. The$280MEthereum’sParitybug. https://blog.comae.io/the-
280m-ethereums-bug-f28e5de43513.
[38]Matt Suiche. 2017. Porosity: A decompiler for blockchain-based smart contracts
bytecode. DEF con25 (2017), 11.[39]Sergei Tikhomirov, Ekaterina Voskresenskaya, Ivan Ivanitskiy, Ramil Takhaviev,
Evgeny Marchenko, and Yaroslav Alexandrov. 2018. Smartcheck: Static analysis
of ethereum smart contracts. In 2018 IEEE/ACM 1st International Workshop on
Emerging Trends in Software Engineering for Blockchain (WETSEB). IEEE, Gothen-
burg, Sweden, Sweden, 9–16.
[40]ChristofFerreiraTorres,JulianSchütte,etal .2018. Osiris:Huntingforinteger
bugsinethereumsmartcontracts.In Proceedingsofthe34thAnnualComputer
Security Applications Conference. ACM, New York, NY, USA, 664–676.
[41]Christof Ferreira Torres, Mathis Steichen, and Radu State. 2019. The Art of The
Scam:DemystifyingHoneypotsinEthereumSmartContracts.In 28thUSENIX
Security Symposium (USENIX Security 19). USENIX Association, Santa Clara, CA,
1591–1607. https://www.usenix.org/conference/usenixsecurity19/presentation/
ferreira
[42]Petar Tsankov, Andrei Dan, Dana Drachsler-Cohen, Arthur Gervais, Florian
Buenzli, andMartin Vechev. 2018. Securify:Practical security analysis ofsmart
contracts.In Proceedingsofthe2018ACMSIGSACConferenceonComputerand
Communications Security. ACM, New York, NY, USA, 67–82.
[43]E. Zhou, S. Hua, B. Pi, J. Sun, Y. Nomura, K. Yamashita, and H. Kurihara. 2018.
Security Assurance for Smart Contract. In 2018 9th IFIP International Conference
on New Technologies, Mobility and Security (NTMS). IEEE, Paris, France, 1–5.
https://doi.org/10.1109/NTMS.2018.8328743
[44]YiZhou,DeepakKumar,SuryaBakshi,JoshuaMason,AndrewMiller,andMichaelBailey.2018. Erays:ReverseEngineeringEthereum’sOpaqueSmartContracts.In27thUSENIXSecuritySymposium(USENIXSecurity18).USENIXAssociation,Bal-
timore,MD, 1371–1385. https://www.usenix.org/conference/usenixsecurity18/
presentation/zhou
541