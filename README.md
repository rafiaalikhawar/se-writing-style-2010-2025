# se-writing-style-2010-2025

Reproducible code + derived metrics for readability, passive voice, and basic-3000 coverage.

Below is a **clean, professional, MSR-ready, FAIR-compliant, reproducible** README written exactly for your repository **se-writing-style-2010-2025**.

It follows **FAIR principles**, clearly explains how to run your dataset + tool, includes environment setup, spaCy download, directory layout, pipeline steps, and citation instructions.

You can **copyâ€“paste this directly into your README.md**.

---

# ğŸ“˜ *SE Writing Style 2010â€“2025*

### Dataset + Reproducible Analysis Pipeline

**Authors:** Rafia Ali, Aleena Shahid
**Track:** MSR 2026 â€“ Data & Tool Showcase

---

## ğŸ§© Overview

This repository provides a **fully reproducible dataset and analysis pipeline** for examining how **software engineering research writing** has changed over time (2010â€“2025), with a focus on the period **before vs. after the introduction of ChatGPT (Nov 2022)**.

The tool and dataset support the reproduction of results in our MSR paper, including:

* **Readability shifts** (Flesch-Kincaid, Gunning Fog, SMOG, etc.)
* **Passive voice usage** (spaCy dependency-based detection)
* **Vocabulary simplicity** (Basic English 3000 coverage)
* **Pre- vs. post-ChatGPT comparisons**
* **Longitudinal trends across 2010â€“2025**

The pipeline is **transparent, modular, and FAIR-compliant** â€” all code, intermediate artifacts, and instructions for regeneration are provided.

---

# ğŸ“ Repository Structure

```
se-writing-style-2010-2025/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # PDFs or text files BEFORE preprocessing
â”‚   â”œâ”€â”€ raw2/                # Additional text-extracted files
â”‚   â”œâ”€â”€ processed/           # Cleaned text output (generated)
â”‚   â””â”€â”€ resources/
â”‚       â””â”€â”€ basic_english_3000.txt
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ clean_texts.py       # Converts PDFs/TXT â†’ cleaned plain text
â”‚   â”œâ”€â”€ convert_pdfs.py      # Optional PDF â†’ text extraction helper
â”‚   â”œâ”€â”€ metrics_readability.py
â”‚   â”œâ”€â”€ metrics_passive.py
â”‚   â”œâ”€â”€ metrics_basiccov.py
â”‚   â”œâ”€â”€ stats_readability.py
â”‚   â”œâ”€â”€ stats_passive.py
â”‚   â””â”€â”€ stats_basiccov.py
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_spacy_model.sh
â”‚   â””â”€â”€ setup_env.sh
â”‚
â”œâ”€â”€ results/
â”‚   â””â”€â”€ metrics/             # Output CSVs generated by pipeline
â”‚
â”œâ”€â”€ samples/                 # Tiny sample for testing
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ CITATION.cff
â”œâ”€â”€ LICENSE
â”œâ”€â”€ Makefile
â””â”€â”€ README.md
```

---

# ğŸ”§ Installation

### 1ï¸âƒ£ Create and activate a virtual environment

```bash
python3 -m venv venv
source venv/bin/activate
```

### 2ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Download the required spaCy model

```bash
bash scripts/download_spacy_model.sh
```

---

# ğŸš€ How to Run the Pipeline

You may run each step individually **or** use the provided **Makefile**.

---

## **Step 1 â€” Place your PDFs / text files**

Put your dataset into:

```
data/raw/
```

Or if you already have text files:

```
data/raw2/
```

---

## **Step 2 â€” Convert PDFs to text (optional)**

```bash
python src/convert_pdfs.py
```

This generates:

```
data/processed/*.txt
```

---

## **Step 3 â€” Clean texts**

```bash
python src/clean_texts.py
```

---

## **Step 4 â€” Compute metrics (RQ1)**

### Readability

```bash
python src/metrics_readability.py
```

### Passive voice

```bash
python src/metrics_passive.py
```

### Basic English vocabulary coverage

```bash
python src/metrics_basiccov.py
```

Each produces a CSV in:

```
results/metrics/
```

---

## **Step 5 â€” Statistical analysis (RQ2)**

### Readability analysis

```bash
python src/stats_readability.py
```

### Passive voice analysis

```bash
python src/stats_passive.py
```

### Vocabulary change analysis

```bash
python src/stats_basiccov.py
```

---

# ğŸ§ª Quick Test With Sample

Test end-to-end using provided small files:

```bash
make test
```

---

# ğŸ“Š Reproducing the Figures / Graphs

You can load the generated `results/*.csv` into a notebook or visualization tool.

If using Python:

```python
import pandas as pd
df = pd.read_csv("results/metrics/readability_2010_2025.csv")
df.head()
```

Graphs can be created with:

* `matplotlib`
* `seaborn`
* `plotly`

(All already included if needed.)

---

# ğŸ“¦ How to Cite the Dataset and Tool

The repository includes a **CITATION.cff** file.
GitHub automatically generates a citation + DOI when archived.

For now, cite as:

```
Ali, R., & Aleena. (2025). SE Writing Style 2010â€“2025 Dataset & Analysis Pipeline.
GitHub: https://github.com/rafiaalikhawar/se-writing-style-2010-2025
```

After Zenodo deposits, the DOI will appear here.

---

# ğŸ” FAIR Compliance

### **Findable**

* Public repository with clear naming.
* Standard CITATION.cff enabling automatic Zenodo DOI minting.
* Structured folders and machine-readable metadata.

### **Accessible**

* No proprietary dependencies.
* All steps documented in README.
* SpaCy model downloaded via included script.

### **Interoperable**

* Outputs are plain `.txt` and `.csv`.
* Metrics are described and reproducible.
* Code uses standard Python libraries.

### **Reusable**

* Full pipeline provided (PDF â†’ text â†’ metrics â†’ statistics).
* Open-source license included.
* Reproduction instructions provided (Makefile + scripts).

---

# ğŸ¤– Notes for MSR Reviewers

This repository includes:

âœ” The **complete dataset** used in the study
âœ” The **full pipeline** to regenerate metrics
âœ” Clear documentation on tool setup
âœ” Open-source license
âœ” FAIR compliance
âœ” Running example via `/samples/`
âœ” Requirements file
âœ” Scripts for reproducibility

---

# ğŸ“¨ Contact

For questions, improvements, or dataset extensions, please contact:

**Rafia Ali**
FAST NUCES Islamabad
Email: rafiaali098@gmail.com

